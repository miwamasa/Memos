# ã²ãŸã™ã‚‰LLMé–¢é€£æƒ…å ±ã‚’è¿½ã†ã€
ã“ã‚Œã¯ã€å€‹äººã®twitter bookmarkã‚’æ¯é€±ãŠã•ã‚‰ã„ã—ã¦ã„ã‚‹ã€‚


## 3/25

- grok-1ã¾ã¨ã‚
	- https://x.com/webbigdata/status/1769503166528458822?s=20
	- ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯314Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ 
	- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã§ã„ãˆã°318.24GB 
	- MoE(2/8 experts)ã§activeãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã ã‘ã§ã‚‚86B 
	- 2023/10æœˆæ™‚ç‚¹ã§å­¦ç¿’ã‚’å®Œäº†ã—ã¦ã„ãŸãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã¿å…¬é–‹ 
	- githubã®xai-orgã§æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚‚å…¬é–‹(JAX) 
	- ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯academictorrentsã‹huggingfaceã®xai-org/grok-1 
	- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯Apache 2.0 ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ 
	- å…¬è¡¨æ¸ˆã¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚Œã°gpt-3.5ã‚’ä¸Šå›ã‚‹ãŒã€Claude 2ã‚„GPT-4ã¯ä¸‹å›ã‚‹
- Apple in talks with Google for using Gemini to bring generative AI features to iPhones
	- https://www.livemint.com/technology/tech-news/googles-gemini-could-power-generative-ai-features-on-iphone-16-tim-cook-heres-what-we-know-11710739843784.html
- ã‚¢ãƒƒãƒ—ãƒ«ã€é«˜åº¦ãªè¨€èªç†è§£ã‚’æŒã¤æ–°å‹AIãƒ¢ãƒ‡ãƒ«ã€ŒMM1ã€ã‚’ç™ºè¡¨
	- https://ascii.jp/elem/000/004/189/4189761/
	- è¤‡æ•°ï¼ˆ30å„„ã€70å„„ã€300å„„ï¼‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã‚’å‚™ãˆã‚‹MM1ã¯ã€10å„„ä»¥ä¸Šã®ç”»åƒãŠã‚ˆã³30å…†èªä»¥ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆã€GitHubã®ã‚³ãƒ¼ãƒ‰ä¾‹ãªã©ã®å¤šæ§˜ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ã€æ•™å¸«ãªã—å­¦ç¿’ã¨æ•™å¸«ã‚ã‚Šå­¦ç¿’ã‚’çµ„ã¿åˆã‚ã›ã‚‹ç‹¬è‡ªã®æ–¹æ³•ã§å­¦ç¿’ã•ã‚Œã€å¤šæ§˜ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦é«˜ã„ç²¾åº¦ã‚’ç¤ºã™
	- MM1ã¯ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«é–¢ã—ã¦ã€ãã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã‹ã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†…å®¹ã€äº‹å‰å­¦ç¿’ãƒ»ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®è©³ç´°ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«è‡³ã‚‹ã¾ã§ã€è©³ç´°ãªæƒ…å ±ï¼ˆMLLMsã®é–‹ç™ºãƒ¬ã‚·ãƒ”ï¼‰ã‚’å…¬é–‹ã—ã¦ã„ã‚‹ã€‚
-  Stability AIã¨ã‚¢ãƒ‹ãƒ¡ãƒã‚§ãƒ¼ãƒ³ãŒã‚¢ãƒ‹ãƒ¡æ¥­ç•Œå‘ã‘ç”Ÿæˆç³»AIã®å…±åŒç ”ç©¶ã‚’æ¤œè¨é–‹å§‹
	- https://prtimes.jp/main/html/rd/p/000000003.000135092.html
	-  æ—¢å­˜ã®ã‚¢ãƒ‹ãƒ¡åˆ¶ä½œå·¥ç¨‹ã‚’ãã®ã¾ã¾ã«ã€Œå”è­°ä¼šã€ã‚’é€šã˜ã¦åˆ¶ä½œç¾å ´ã®å£°ã‚’ä¼ºã„ãªãŒã‚‰ã‚¢ãƒ‹ãƒ¡ä½œå“ã®å“è³ªå‘ä¸Šã‚’ç›®æ¨™ã¨ã—ãŸæ”¯æ´ãƒ„ãƒ¼ãƒ«ã®å…±åŒç ”ç©¶ã‚’ç›®æŒ‡ã™
-  Fully  Client-Side  Chat Over Documents
	- https://webml-demo.vercel.app/
	- So I revisited WebLLM and was able to add browser-only mode!
- KDDIã€æ±å¤§ç™ºAIãƒ™ãƒ³ãƒãƒ£ãƒ¼ãƒ»ELYZAã‚’é€£çµå­ä¼šç¤¾åŒ–ã€€æ˜¥ä»¥é™ã€ç”ŸæˆAIé–¢é€£ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›
	- https://www.itmedia.co.jp/news/articles/2403/18/news140.html
- NVIDIA GTC2024ã§æ¬¡ä¸–ä»£ã®ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ã¯ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰
	- https://www.youtube.com/watch?v=Y2F8yisiS6E
- DGX GB200 NVL72ã¯ã€GB200 Superchipã‚’72åŸºNVLinkã§æ¥ç¶šã—ãŸã‚¯ãƒ©ã‚¹ã‚¿
	- https://x.com/_ksasaki/status/1769829822946001353?s=20
-  LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM
	- https://www.llamaindex.ai/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim
	- LlamaIndex  is integrated with NVIDIA NIM inference microservices to help enterprises seamlessly deploy generative AI at scale
- 1x GPU Blackwell - 192GB VRAM 2x GPU 
	- Blackwell with CPU - 384 GB VRAM
	- https://x.com/migtissera/status/1769824889102348366?s=20
-  NVIDIAãŒãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰é–‹ç™ºãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æä¾›ã‚’ç™ºè¡¨ã€€ãƒ‡ã‚£ã‚ºãƒ‹ãƒ¼ã®äºŒè¶³æ­©è¡Œãƒ­ãƒœãƒƒãƒˆãŒç™»å£‡ã€€Jetson Orinã‹ã‚‰æ¬¡ä¸–ä»£Thorã¸
	- https://robotstart.info/2024/03/19/nvidia-humanoid-jetson-thor.html
	- NVIDIAã¯ã€ŒGTC 2024ã€ã®å‰µæ¥­è€…/CEOã®ã‚¸ã‚§ãƒ³ã‚¹ãƒ³ãƒ»ãƒ•ã‚¢ãƒ³æ°ã«ã‚ˆã‚‹åŸºèª¿è¬›æ¼”ã§ã€ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ãƒ­ãƒœãƒƒãƒˆ(ãƒ’ãƒˆå‹ãƒ­ãƒœãƒƒãƒˆ)ã‚’é–‹ç™ºã™ã‚‹ãŸã‚ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã€ŒGR00Tã€(ã‚¸ãƒ¼ã‚¢ãƒ¼ãƒ«ã‚¼ãƒ­ã‚¼ãƒ­ãƒ†ã‚£ãƒ¼)ã‚’ç™ºè¡¨ã—ãŸã€‚NVIDIAã¯æ–°ä¸–ä»£GPUã¨ç”ŸæˆAIã‚’å«ã‚€ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰é–‹ç™ºç”¨ã®SDKã‚„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚’æä¾›ã—ã€å…¨é¢çš„ã«æ”¯æ´ã—ã¦ã„ãã€‚
- æ³•åˆ¶å±€ã‚‚çœŸã£é’ï¼ŸClaude 3ã‚’ç”¨ã„ãŸæ–°è¦æå‡ºæ³•æ¡ˆã®ç«‹æ³•æŠ€è¡“ä¸Šã®çŸ›ç›¾ç‚¹ãƒã‚§ãƒƒã‚¯
	- https://takagi-hiromitsu.jp/diary/20240319.html
	- Claude 3ã«èã„ã¦ã¿ãŸã€‚å¾®å¦™ã«ã‘ã£ã“ã†é–“é•ã†ãŒã€ãã“ã¯ã‚¹ãƒ«ãƒ¼ã—ã¦ã€å¤§å¤‰å‚è€ƒã«ãªã‚‹ã€‚ã“ã“ã¾ã§ã‚ãšã‹1æ™‚é–“ç¨‹åº¦ã®ä½œæ¥­ã ã£ãŸ
- TacticAI: an AI assistant for football tactics
	- https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/?utm_source=twitter&utm_medium=social&utm_campaign=TacticAI/
	- We're announcing TacticAI: an AI assistant capable of offering insights to football experts on corner kicks.
	- it can help teams sample alternative player setups to evaluate possible outcomes, and achieves state-of-the-art results.
- 500ç¨‹åº¦ã®ã‚µãƒ³ãƒ—ãƒ«ã§æ•°åˆ†å­¦ç¿’ã•ã›ã¦LLMã®å‡ºåŠ›ã‚’æ–¹å‘ä»˜ã‘ã‚‹äº‹ãŒå‡ºæ¥ã‚‹åˆ¶å¾¡ãƒ™ã‚¯ãƒˆãƒ«(control vectors)ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
	- https://github.com/vgel/repeng
	- LoRAã®ã‚ˆã†ã«ç‰¹å®šã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã™ã‚‹ã®ã§ã¯ãªãä¾‹ãˆã° ã€Œé™½ã‚­ãƒ£ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€ï½–ï½“ã€Œé™°ã‚­ãƒ£ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€ ãªã©ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«å…¨ä½“çš„ãªæ–¹å‘æ€§ã‚’ä¸ãˆã‚‹æ„Ÿã˜ã§ã™ã­
- Googleã€PDFè«–æ–‡ã‚’åŠ‡çš„ã«èª­ã¿ã‚„ã™ãã™ã‚‹Chromeæ‹¡å¼µã€ŒGoogle Scholar PDF Readerã€
	- https://news.mynavi.jp/techplus/article/20240321-2911097/
- GaLore - å®¶åº­ç”¨ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã§ã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
	- https://note.com/npaka/n/n8e4537502e3e?sub_rt=share_h
	- ã€ŒGaLoreã€ã¯ã€ã€ŒNVIDIA RTX 4090ã€ãªã©ã®å®¶åº­ç”¨GPUä¸Šã§ã€Llamaãªã©ã®æœ€å¤§7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚ã“ã‚Œã¯ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®çŠ¶æ…‹ã¨å‹¾é…ã«å¾“æ¥é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ã„ãŸãƒ¡ãƒ¢ãƒªè¦ä»¶ã‚’å¤§å¹…ã«å‰Šæ¸›ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å®Ÿç¾ã•ã‚Œã¾ã™ã€‚
	- ã€ŒGaLoreã€ã¨ã€Œ8bitã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã€ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ã®æ•´åˆæ€§ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã—ãªãŒã‚‰ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’æœ€å¤§åŒ–ã™ã‚‹ç›¸ä¹—åŠ¹æœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚
- Stanfordã®Fei-Fei Liæ•™æˆã‚‰ã®ãƒãƒ¼ãƒ ã‹ã‚‰ã€ãƒ­ãƒœãƒƒãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒBEHAVIOR-1Kã€ãŒãƒªãƒªãƒ¼ã‚¹
	- https://x.com/drfeifei/status/17710132915083798å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒGrok-1ã€ã«ã¤ã„ã¦ by ä»Šäº•
	- https://x.com/ImAI_Eruel/status/1769487625994506294?s=20
- é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ by sakana ai
	- Sakana AIã®æœ€åˆã®ç ”ç©¶æˆæœã§ã‚ã‚‹ã€é€²åŒ–çš„è¨ˆç®—ã«ã‚ˆã‚‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«é–¢ã™ã‚‹è«–æ–‡ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚å¤šæ§˜ãªæ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•çš„ã«èåˆã—å„ªã‚ŒãŸåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹ã¨å…±ã«ã€ãã‚Œã«ã‚ˆã‚Šè©¦ä½œã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚
		- **EvoLLM-JP**ï¼šæ•°å­¦çš„æ¨è«–ãŒå¯èƒ½ãªæ—¥æœ¬èªã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰
		- **EvoVLM-JP**ï¼šæ—¥æœ¬èªã§å¯¾è©±å¯èƒ½ãªç”»åƒè¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆVLMï¼‰
		- **EvoSDXL-JP**ï¼šé«˜é€Ÿãªæ—¥æœ¬èªç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«
	- _æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ¼ã‚¸ã—ã¦æ–°ã—ã„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹éç¨‹ã®å¯è¦–åŒ–ã€‚é€²åŒ–çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹éš›ã«ã€äººé–“ã®ç›´æ„Ÿã ã‘ã§ã¯è¦‹è½ã¨ã•ã‚ŒãŒã¡ãªã€åŠ¹æœçš„ã‹ã¤æ™‚ã«éç›´æ„Ÿçš„ãªæ–¹æ³•ã‚’è‡ªå‹•çš„ã«ç™ºè¦‹ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™_
-  Evolutionary Optimization of Model Merging Recipes
	- Sakana Aiã®è«–æ–‡
	- https://arxiv.org/abs/2403.13187
-  WSL2ã§Sakana AIã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/na9b41adb9131
	- ã€Œé€²åŒ–çš„ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã«ã‚ˆã‚Šæ—¥æœ¬èªæ•°å­¦LLMã¨ã—ã¦æ§‹ç¯‰ã—ãŸEvoLLM-JPã¯ã€æ•°å­¦ã®ã¿ãªã‚‰ãšã€æ—¥æœ¬èªã®å…¨èˆ¬çš„ãªèƒ½åŠ›ã«é•·ã‘ã¦ã„ã‚‹ã€ã‚‰ã—ã„EvoLLM-JPã‚’è©¦ã—ã¦ã¿ã¾ã™
	- 10Bã®ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒã€torch_dtypeã‚’"auto"ã‹ã‚‰torch.bfloat16ã«å¤‰æ›´ã™ã‚‹ã¨ã€æ¨è«–ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒæ”¹å–„ã—ã¾ã—ãŸã€‚
- RAG for long context LLMs: Video
	- https://www.youtube.com/watch?v=SsHUNfhF32s
	- https://docs.google.com/presentation/d/1mJUiPBdtf58NfuSEQ7pVSEQ2Oqmek7F1i4gBwR6JDss/edit#slide=id.g26c0cb8dc66_0_0
- NVIDIAã®ãƒ•ãƒªãƒ¼ã‚ªãƒ³ãƒ©ã‚¤ãƒ³AIã‚³ãƒ¼ã‚¹
	- https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/
- Claude 3 Opusã‚ˆã‚Š60å€å®‰ã„Haikuã‚’Opusã®å“è³ªã§é‹ç”¨ã™ã‚‹æ–¹æ³•ã€‚
	- https://github.com/mshumer/gpt-prompt-engineer
	- gpt-prompt-engineerã‚’ä½¿ãˆã°ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®å®Ÿé¨“ã‚’è‡ªå‹•åŒ–ã§ãã‚‹ã€‚è‡ªå‹•ã§è¤‡æ•°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ã€LLMåˆ¥ã«è©•ä¾¡ã‚‚å¯èƒ½ã€‚
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
	- 25x speedup in retrieval; 32x reduction in memory usage; 4x reduction in disk space; 99.3% preservation of performance
- LLM4Decompile: Decompiling Binary Code with Large Language Models
	- https://arxiv.org/abs/2403.05286v1
	- ãƒã‚¤ãƒŠãƒªã‹ã‚‰ãƒªãƒãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§ãã‚‹ã¨
- Suno AI unveiled V3
	- https://x.com/heyBarsee/status/1771190753957470604?s=20
- Doing In-Context Learning Without Leaking Private Data
	- https://github.com/run-llama/llama_index/tree/main/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease
	- Few-shot demonstrations are crucial to improve the performance of any LLM/RAG app. But the issue with very private datasets (e.g. patient clinical reports), is that they can easily be leaked/jailbroken by malicious users.
- å†…é–£åºœã€ŒAIæ™‚ä»£ã®çŸ¥çš„è²¡ç”£æ¨©æ¤œè¨ä¼šï¼ˆç¬¬ï¼–å›ï¼‰ã€ã®è³‡æ–™ãŒå…¬é–‹
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/gijisidai/dai6/index.html
-  GitHubã€è„†å¼±æ€§ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ç™ºè¡¨ã€‚AIãƒœãƒƒãƒˆãŒä¿®æ­£æ¸ˆã¿ã‚³ãƒ¼ãƒ‰ã¨è§£èª¬ã‚’ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
	- https://www.publickey1.jp/blog/24/githubai.html
	- GitHubã¯ã€è„†å¼±æ€§ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’AIãƒœãƒƒãƒˆãŒè‡ªå‹•çš„ã«ç™ºè¦‹ã€ä¿®æ­£ã—ãŸã‚³ãƒ¼ãƒ‰ã¨ãã®è§£èª¬ã‚’ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ãã‚Œã‚‹ã€Œcode scanning autofixã€ï¼ˆã‚³ãƒ¼ãƒ‰ã‚¹ã‚­ãƒ£ãƒ³è‡ªå‹•ä¿®æ­£æ©Ÿèƒ½ï¼‰ã‚’ç™ºè¡¨ã—ã¾ã—ãŸ
- éŸ³å£°åŸºç›¤ãƒ¢ãƒ‡ãƒ«Kotoba-Speech v0.1ã®å­¦ç¿’ãƒ»æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸï¼
	- https://x.com/kotoba_tech/status/1771165553882964291?s=20
	- https://github.com/kotoba-tech/kotoba-speech-release
	- End-to-Endã®Transformerã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚‚ç°¡å˜ã§ã™ã€‚ä¾‹ã¨ã—ã¦ã€é–¢è¥¿å¼ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã—ã¾ã—ãŸã€‚æ—¢å­˜ã®Text-to-Speechã‚ˆã‚Šã‚‚ã€ã•ã‚‰ã«è‡ªç„¶ã§æµæš¢ã§ã‚ã‚‹ã“ã¨ãŒå®Ÿæ„Ÿã§ãã‚‹ã‹ã¨æ€ã„ã¾ã™ï¼
- The AI Mirror Test
	- https://x.com/joshwhiton/status/1770870738863415500?s=20
	- The "mirror test" is a classic test used to gauge whether animals are self-aware. I devised a version of it to test for self-awareness in multimodal AI. 4 of 5 AI that I tested passed, exhibiting apparent self-awareness as the test unfolded.
	- Claude Opus passed the mirror test immediately. Like the other AI, it hardly identifies with its brand-name (Claude) and distinguishes itself from the interfaceâ€™s stock elements. However it does identify with the prompt, which it knows is
- PEFT 0.10.0 is out
	- https://github.com/huggingface/peft/releases/tag/v0.10.0
	- Fine-tune larger QLoRA models with DeepSpeed and FSDP, layer replication, enhance DoRA
	- This allows you to fine-tune a 70B Llama model on two GPUs with 24GB memory each.
	- ä»¥å‰ã€ãƒ„ã‚¤ãƒ¼ãƒˆã—ãŸ70B Llama 2ãƒ¢ãƒ‡ãƒ«ã‚’24GBãƒ¡ãƒ¢ãƒªã‚’æ­è¼‰ã—ãŸGPU2åŸºã§QLoRAå¯èƒ½ã«ãªã‚‹ãŠè©±ãŒæ­£å¼æ¡ç”¨
	- åŠ ãˆã¦ã€DoRA(å·¥å¤«ã—ãŸLoRAã€‚ãŸã ã—ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã¯å¢—ãˆã‚‹)ãŒé‡å­åŒ–æ¸ˆã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ä½¿ã„ã‚„ã™ããªã£ãŸæ¨¡æ§˜
	- LoftQ(é‡å­åŒ–èª¤å·®ã‚’æœ€å°åŒ–ã™ã‚‹ã‚ˆã†ã«LoRAã‚’åˆæœŸåŒ–ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹)ã‚‚ã‚ˆã‚Šä½¿ã„ã‚„ã™ããªã£ãŸã¨ã®äº‹
- OpenAI Voice Engine. This is big
	- https://x.com/SmokeAwayyy/status/1771052612051468668?s=20
	- VOICE ENGINEâ„¢ trademark registration is intended to cover: - voice and speech recognition, processing voice commands, and converting between text and speech
- Introducing the Chatbot Guardrails Arena
	- https://huggingface.co/blog/arena-lighthouz
	- Our vision behind the Chatbot Guardrails Arena is to establish the trusted benchmark for AI chatbot security, privacy, and guardrails. With a large-scale blind stress test by the community, this arena will offer an unbiased and practical assessment of the reliability of current privacy guardrails.
- æ˜¨æ—¥SakanaAILabsã‹ã‚‰ãƒªãƒªãƒ¼ã‚¹ã—ãŸæ—¥æœ¬èªç”»åƒè¨€èªãƒ¢ãƒ‡ãƒ«EvoVLM-JPã¯ã€èª°ã§ã‚‚ã™ãã«ãŠè©¦ã—ã„ãŸã ã‘ã¾ã™ã€‚
	- https://huggingface.co/spaces/SakanaAI/EvoVLM-JP
- Starling-LM-7B, has now upgraded to Beta
	- https://huggingface.co/Nexusflow/Starling-LM-7B-beta
	- It shows promising potential in our coming next generation benchmark.
	- https://x.com/lmsysorg/status/1771252185205981426?s=20
-  Debates on the nature of artificial general intelligence by nature
	- https://www.science.org/doi/10.1126/science.ado7069
	- "The history of AI has repeatedly disproved our intuitions about intelligence....At each step in the evolution of AI, human-level intelligence turned out to be more complex than researchers expected."
- lightblue/ao-karasu-72B
	- https://huggingface.co/lightblue/ao-karasu-72B
- Artificial muscle has arrived.
	- https://x.com/BrianRoemmele/status/1770959817815019857?s=20
	- æ˜¨å¹´çŸ¥çš„æ¥­å‹™ã¯çµ‚ã‚ã‚Šã ã€‚äººé–“ã¯ç­‹è‚‰ã‚’é›ãˆã‚‹ã—ã‹ãªã„ã€‚ ã¨ã‹è¨€ã£ã¦ãŸã‘ã©ã€äººå·¥ç­‹è‚‰å‡ºæ¥ã¡ã‚ƒã£ãŸã‚ˆ
-  Arcee's MergeKit: A Toolkit for Merging Large Language Models
	- https://huggingface.co/papers/2403.13257
	- Model Merging allows us to blend/stack multiple open LLMs into oneâ€”bigger or the same sizeâ€”without extra training to extend skills and performance!
- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å»ƒç†±ã§ãƒ—ãƒ¼ãƒ«ã‚’åŠ æ¸©ğŸŠ ç’°å¢ƒã«å„ªã—ãã‚³ã‚¹ãƒˆã‚‚ç¯€æ¸› è‹±å›½
	- https://x.com/afpbbcom/status/1770586117449953488?s=20
	- æ•·åœ°å†…ã«è¨­ç½®ã•ã‚ŒãŸè£…ç½®ãŒã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ç¾¤ãŒæ”¾å‡ºã™ã‚‹ç†±ã‚’å–ã‚Šè¾¼ã¿ã€25ï½ãƒ—ãƒ¼ãƒ«ã‚’è¨­å®šæ¸©åº¦ã¾ã§æ¸©ã‚ã‚‹ã€‚ç´„65ï¼…ã‚’ã‚«ãƒãƒ¼ã—ã¦ãŠã‚Šã€ã‚¬ã‚¹ãƒœã‚¤ãƒ©ãƒ¼ã®ä½¿ç”¨ã¯æŠ‘ãˆã‚‰ã‚Œã¦ã„ã‚‹ã€‚
- O1 Lightã¯Open Interpreterã‚’æ­è¼‰ã—ãŸå°å‹ãƒ‡ãƒã‚¤ã‚¹ã§ã™
	- https://x.com/tegnike/status/1770851466665750758?s=20
-  WSL2ã§RakutenAI-7B-chatã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/n413ababd3105?sub_rt=share_crp
	- ã€ŒMistral AIç¤¾ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã€ŒMistral-7B-v0.1ã€ã‚’åŸºã«ã€ç¶™ç¶šçš„ã«å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã•ã›ã¦é–‹ç™ºã•ã‚ŒãŸ70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã€ã§ã‚ã‚‹Rakuten AI 7Bãƒ¢ãƒ‡ãƒ«
	- ã€Œã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆãƒ¢ãƒ‡ãƒ«ã‚’åŸºã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã£ãŸãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã€ã§ã‚ã‚‹Rakuten AI 7B Chatã‚’è©¦ã—ã¦ã¿ã¾ã™ã€‚
- Swallow-MX-8x7b-NVE-chatvector-Mixtral-instructã®v2ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ by AI ã•ã¨ã—
	- https://huggingface.co/aixsatoshi/Swallow-MX-8x7b-NVE-chatvector-Mixtral-instruct-v2
	- å…ƒãƒ¢ãƒ‡ãƒ«ã¨instructionãƒ™ã‚¯ãƒˆãƒ«ã®ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ã§ã€æ—¥æœ¬èªæµæš¢æ€§æ”¹å–„ã—ã¦ã„ã¾ã™
- Margaret Mitchel
	- This Women's History Month, we celebrate Margaret Mitchell, the Chief AI Ethics Scientist at huggingface, an open source data science and machine learning platform and hub for AI experts. 
- Transformers 4.39 is out,
	- https://github.com/huggingface/transformers/releases/tag/v4.39.0
	- New models: Mamba, Command-R, LLaVA-NeXT, MusicGen Melody, StarCoder2, SegGPT, ...
	- GaLore optimizer for accessible pre-training
	- Quanto integration and Exllama+AWQ
	- MLX support
-  A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
	- https://arxiv.org/abs/2302.13425
	- ã¤ã„ã«UQã‚‚æ·±å±¤å­¦ç¿’ã®æ™‚ä»£ã‹
- Estimating Causal Effects with Double Machine Learning -- A Method Evaluation
	- https://arxiv.org/abs/2403.14385
- Meta introduces SceneScript
	- https://x.com/AiBreakfast/status/1771195019585597836?s=20
	- You will be able to upload your own environment to the metaverse:
- ãƒã‚¸ã‹(NLP2024ã®å²¡å´å…ˆç”Ÿã€Knightå…ˆç”Ÿã®ç™ºè¡¨æ¦‚è¦ã‚’Swallow-MXã‚’ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§QLoRA tuningã—ãŸãƒ¢ãƒ‡ãƒ«ã§æ—¥è‹±/è‹±æ—¥ç¿»è¨³)
	- https://x.com/hpp_ricecake/status/1771138490589487602?s=20
-  GoogleãŒæ´ªæ°´ã‚’1é€±é–“å‰ã«äºˆæ¸¬ã—ä¸–ç•Œ80ã‚«å›½4å„„6000ä¸‡äººã‚’æ°´å®³ã‹ã‚‰æ•‘ãˆã‚‹AIã‚’ç™ºè¡¨
	- https://gigazine.net/news/20240322-google-ai-global-flood-forecasting/
	- Google Researchã®ã‚°ãƒ¬ã‚¤ãƒ»ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ°ã‚‰ã®ç ”ç©¶ãƒãƒ¼ãƒ ã¯ã€ä¸–ç•Œå„å›½ã®æµé‡è¨ˆ5680å€‹ãŒ1980ï½2023å¹´ã®é–“ã«é›†ç©ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸã€‚
	- æ´ªæ°´ãƒŠã‚¦ã‚­ãƒ£ã‚¹ãƒˆã«ã‚ˆã‚‹æ´ªæ°´ã®äºˆæ¸¬ã‚’0æ—¥å‰ã€ã¤ã¾ã‚Šå½“æ—¥ã‹ã‚‰å¹³å‡5æ—¥å‰ã¾ã§å»¶ã°ã—ã€æœ€å¤§ã§7æ—¥å‰ã¾ã§äºˆæ¸¬ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- ç«‹ä½“è¨€èª
	- æ°¸ç”°äº®ã€ç«‹ä½“è¨€èªã€ï¼ˆè‡ªç„¶è¨€èªå‡¦ç†31å·»1å·å·»é ­è¨€ï¼‰
	- https://www.jstage.jst.go.jp/article/jnlp/31/1/31_1/_pdf/-char/ja
	- è¨€èªã®ç·šçŠ¶æ€§ï¼ˆä¸€ã¤ã¥ã¤é †ç•ªã«ä¸¦ã¹ã‚‹åˆ¶ç´„ï¼‰ã‚’è¶…ãˆã‚‹ã€ã“ã‚Œã¾ã§ã¨ã¯ç•°ãªã£ãŸæƒ…å ±ä¼é”ã®å¯èƒ½æ€§ã€‚ãã—ã¦ã€ãã“ã«NLPæŠ€è¡“ãŒæ´»ã‹ã›ã‚‹ã®ã§ã¯ãªã„ã‹ã¨ã„ã†ãŠè©±ã€‚
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
- Excited for MistralAI+ llama_index collabs (and Colabs)
	- https://x.com/jerryjliu0/status/1771262080944857469?s=20
-  Lightblueã€å›½å†…æœ€é«˜æ°´æº–ã®æ—¥æœ¬èªLLMãƒ¢ãƒ‡ãƒ«ã€Œao-Karasuã€ã‚’å…¬é–‹
	- https://prtimes.jp/main/html/rd/p/000000057.000038247.html
	- 

## 3/18

ä»Šé€±ã‚‚ã„ã‚ã„ã‚ã‚ã‚Šã™ãã¦ã€ç›®ãŒå›ã‚Šã¾ã™ã€‚æ±å·¥å¤§ã‹ã‚‰Swallow-MS 7Bã¨Swallow-MX 8x7Bã®ãƒªãƒªãƒ¼ã‚¹ã€å‰è€…ã¯æ—¥æœ¬èªæœ€é«˜æ€§èƒ½ã¨ã®ã“ã¨ã€‚ é‡å­åŒ–ç‰ˆã‚‚å‡ºã¦ã€Llama.cpp ã§Swallow-MX 8x7Bã‚’å‹•ã‹ã—ãŸä¾‹ã‚‚ç´¹ä»‹ã•ã‚ŒãŸã€‚Swallow-MS-7b-v0.1 ã‚’ ichikara instruction ã§æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€500ã‚¹ãƒ†ãƒƒãƒ—ãã‚‰ã„ã§ã„ã„æ„Ÿã˜ã¨ã®å ±å‘Šã‚‚ã€‚ã€ŒELYZA-japanese-Llama-2-70bã€ãŒå‡ºãŸãƒ¼ã€NHKã§ã‚‚ç´¹ä»‹ã•ã‚ŒãŸã€ABCIã‚’12æœˆã‹ã‚‰éƒ¨åˆ†å æœ‰ï¼Ÿã€ã‚ˆã†ã‚„ãã‚¹ã‚¿ãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ã¨ã„ã†CEOã®è¨€è‘‰ãŒåˆºã•ã‚‹ã€‚Shi3zã•ã‚“ã«ã‚ˆã‚‹ã¨ã€Claude-3ã¨æ¯”ã¹ã‚‹ã¨ç™¾äººä¸€é¦–ã®çŸ¥è­˜ãŒè¶³ã‚Šãšã¾ã é ‘å¼µã‚Œã¨ã„ã†æ„Ÿã˜ã ãŒå¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã‚‹ã¨æ ¼æ®µã®é€²æ­©ãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚ã€ŒJPX Market Explorerã€ã€NISAã§å€‹åˆ¥æŠ•è³‡ã‚’è€ƒãˆã¦ã„ã‚‹ã²ã¨ã¯å¿…è¦‹ã€‚è‡ªç¤¾ãƒ“ã‚¸ãƒã‚¹ï¼æ ªå–å¼•ã‚’æ´»ç™ºã«ã™ã‚‹ãŸã‚ã®ã€ç”ŸæˆAIã®æ´»ç”¨ã¨ã—ã¦é¢ç™½ã„ã€‚256k token ãŒæ‰±ãˆã‚‹GPT-4.5 Turbo ãŒï¼–æœˆã”ã‚ã«ãƒªãƒªãƒ¼ã‚¹ã¨ã„ã†ã†ã‚ã•ãŒæŒã¡ä¸ŠãŒã‚‹ã€ãƒªãƒ¼ã‚¯ãªã®ã‹ï¼Ÿã€‚ä¸€èˆ¬copilotã‹ã‚‰ã‚‚GPT-4 TurboãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã‚‰ã—ã„ã€OpenAIï¼‹ãƒã‚¤ã‚¯ãƒ­ã‚ªãƒ•ãƒˆé™£å–¶ã‚‚é…ã‚Œã‚‹ã‚ã‘ã«ã¯è¡Œã‘ãªã„ã€‚ä¼æ¥­ãŒæœŸå¾…ã™ã‚‹ä»Šé¢¨ã®ã€Œä¸»ä½“æ€§ã€ã£ã¦ã€æ€è€ƒåŠ›ã¨å”èª¿ãƒ»å”åƒã§ãã‚‹åŠ›ã¨ã„ã†è©±ã ã‘ã©ã€ã“ã®åˆ†é‡ã€ç”ŸæˆAIãŒè‹¦æ‰‹ã¨ã‚‚è¨€ãˆãªããªã£ãŸæ°—ãŒã™ã‚‹ãªã€‚AIã«ã‚ˆã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢Devinã€ãªã‚“ã‹ã™ã”ã„ã€é§†é€ã•ã‚Œã‚‹äººãŸã¡ãŒãŸãã•ã‚“ã„ãã†ã ã€‚ã©ã†ã‚‚VCç•Œéšˆã§ã¯ã€AIå¾“æ¥­å“¡ã®é–‹ç™ºã®é¢¨ãŒå¹ã„ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚JSTã®ã€Œè‡ªå¾‹é§†å‹•ã«ã‚ˆã‚‹ç ”ç©¶é©æ–°ã€ã¯ç ”ç©¶ãã®ã‚‚ã®ã‚’AIã§è‡ªå‹•åŒ–ã¨ã„ã†è©±ã€ã²ãˆï¼ã€‚Claude 3 Opusã‚’ä½¿ã£ã¦ä¸–ç•ŒçµŒæ¸ˆã‚’åˆ†æã™ã‚‹ãƒ‡ãƒ¢å‹•ç”»ã‚‚ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆAIå¾“æ¥­å“¡ï¼‰ã‚’ã¤ãã£ã¦èª¿æŸ»ã‚’åŠ é€Ÿã§ãã‚‹ã¨ã„ã†è©±ã€‚ã‚ã‚ã€äººã¯ã„ã‚‰ãªããªã‚‹ã®ã‹ï¼Ÿã€‚Claude3ã®æ€§èƒ½è©•ä¾¡ã¯ç¶šãã€ã²ã‚ã¿ã¡ã‚…å…ˆç”ŸãŒã€æ§˜ã€…ãªãªäº‹ä¾‹ã‚’è©¦ã—ã¦çµ¶è³›ã€Coinhiveäº‹ä»¶æœ€é«˜è£åˆ¤æ±ºã®è§£é‡ˆãªã©ã€ä½¿ã„æ–¹ã®å‚è€ƒã«ã‚‚ãªã‚‹ã€‚Claude3 Ã— Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã€ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰æ™®é€šã«Claude3ã‚’ä½¿ãˆã‚‹ã€ãªã‚“ã‹ã¡ãŒã†ãªã€‚æ¾ç”°å…ˆç”Ÿã®è€ƒå¯Ÿã®ã‚ˆã†ã«ã€LLMã£ã¦ååˆ†ç–ãªã®ã§ã¯ãªã„ã‹ã€ã¾ã ã¾ã é‡å­åŒ–ã¨ã‹è»½é‡åŒ–ã®ä½™åœ°ãŒã‚ã‚‹ã€‚ä¸–ç”°è°·åŒºã®AI botã€éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§é–‹ç™ºã¨ã€‚NLP2024ã‚‚é–‹å‚¬ã€å²¡é‡åŸã•ã‚“ã®ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®å±•æœ›ã¨ä»Šå¾Œã®èª²é¡Œã€ã€è©±é¡Œã¨ã—ã¦ã¯æœ¬LLMã‚¢ãƒ—ãƒ‡èª­è€…ã«ã¯ãªã˜ã¿ã®æ·±ã„è©±é¡Œã€‚AIã¯ç§‘å­¦ã‚’ä¿ƒé€²ã™ã‚‹ãŒã€ã€ç†è§£ã®éŒ¯è¦šã€ã‚’ç”Ÿã¿å‡ºã™å±é™ºæ€§ãŒã‚ã‚‹ã€ã¨è¨˜äº‹ã¯æ–°ã—ã„è¦–ç‚¹ã§èˆˆå‘³æ·±ã„ã€‚ã‚«ãƒ¼ãƒ„ãƒ¯ã‚¤ãƒ«ã•ã‚“ã€å¤§è„³çš®è³ªã¨è¨ˆç®—æ©ŸãŒã¤ãªãŒã‚‹ã®ãŒ2030å¹´ä»£åˆé ­ã¨ã„ã£ã¦è©±é¡Œã«ã€‚OpenAIã¨ãƒ­ãƒœãƒƒãƒˆé–‹ç™ºã®Figureã®ææºã®çµæœã®ç¬¬ï¼‘æ®µFigure01ã€ã„ã‚„ã“ã‚Œã£ã¦ãªã‚“ã‹ã®æ˜ ç”»ï¼ˆãƒ‘ãƒƒã‚»ãƒ³ã‚¸ãƒ£ãƒ¼ï¼‰ã§è¦‹ãŸä¸–ç•Œã€‚Natureã®All of usã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã€117å€‹ã®ç–¾æ‚£ã«é–¢é€£ã™ã‚‹3724å€‹ã®å¤‰ç•°ã‚’åŒå®šã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã¨ã®ã“ã¨ã€‚æœ€å¾Œã«ã€XãŒäºˆå‘ŠãŠé™ã‚Š Grok-1ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒªãƒªãƒ¼ã‚¹ã€‚ç›´å‰ã«ã€OpenAIãŒGrokã®åˆ¥å®Ÿè£…ã‚’OSSã§å…¬é–‹ã—ã¦ãŸã‚Šã—ã¦ã€ã“ã†ã„ã†ç«¶äº‰ã€ã„ã‚„å…±å‰µï¼Ÿã£ã¦é¢ç™½ã„ãªã€‚


- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«Swallow-MS 7Bã¨Swallow-MX 8x7Bã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- https://tokyotech-llm.github.io/swallow-mistral
	- Swallow-MS 7Bã¯ã‚ªãƒ¼ãƒ—ãƒ³ãª7Bã®LLMã®ä¸­ã§æ—¥æœ¬èªæœ€é«˜æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸã€‚
-  Yi: Open Foundation Models by 01.AI
	- https://arxiv.org/abs/2403.04652
	- Super interesting paper - 10k data is all you need for finetuning LLM
	- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯1ä¸‡ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã§å……åˆ†ãªã‚“ã ã¨ã„ã†è«–æ–‡ã€‚
- Claude 3ã«ä¾‹ã®ã€Œèª­äº†ç›®å®‰2æ™‚é–“ã€è¨˜äº‹ã‚’è§£èª¬ã•ã›ã¦ã¿ãŸ - é«˜æœ¨æµ©å…‰ï¼ è‡ªå®…ã®æ—¥è¨˜ï¼ˆ2024å¹´3æœˆ11æ—¥ï¼‰
	- https://takagi-hiromitsu.jp/diary/20240311.html
	- ã²ã‚ã¿ã¡ã‚…å…ˆç”Ÿçµ¶è³›
	- ã€ŒAnthropicã®å…ˆæ—¥å‡ºãŸã°ã‹ã‚Šã®Claude 3ï¼ˆOpusï¼‰ãŒã€ChatGPTã®GPT-4ã‚’è¶…ãˆã¦ããŸã¨èã„ã¦ã€è‡ªåˆ†ã®åŸç¨¿ã‚’è§£èª¬ã•ã›ã¦ã¿ãŸã¨ã“ã‚ã€ç¢ºã‹ã«é©æ–°çš„ãªé€²æ­©ãŒè¦‹ã‚‰ã‚Œã‚‹ã€‚ã‚‚ã¯ã‚„å†…å®¹â€¦ã€
-  Is Cosine-Similarity of Embeddings Really About Similarity?
	- https://arxiv.org/abs/2403.05440
	- ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’ç–‘ã£ã¦ã„ã‘ï¼ï¼
- Swallow-MX-8x7b-NVE-v0.1ã®ggufã‚ã‚Šã¾ã™
	- https://huggingface.co/mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
- äººå·¥è¨€èªã«ã‚ˆã‚‹äº‹å‰å­¦ç¿’ã‚’ç”¨ã„ãŸè¨€èªé–“è»¢ç§»å¯èƒ½ãªçŸ¥è­˜ã®åˆ†æ
	- https://www.jstage.jst.go.jp/article/jnlp/30/2/30_664/_article/-char/ja/
	- Transformerã®äº‹å‰å­¦ç¿’ã«äººå·¥è¨€èªã‚’ä½¿ã£ãŸã‚‰ã©ã†ãªã‚‹ã‹ã€ã©ã®è¦ç´ ãŒäº‹å‰å­¦ç¿’ã«åŠ¹ãã®ã‹ã€ã¨ã„ã†ç ”ç©¶ ä¿‚ã‚Šå—ã‘é–¢ä¿‚ã«å…¥ã‚Œå­æ§‹é€ ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒé‡è¦ã‚‰ã—ã„
- Llama.cpp ã§ Swallow MX 8x7B ã‚’ãŠè©¦ã—ä¸­ã€€by npakaã•ã‚“
	- https://x.com/npaka123/status/1767380241520173408?s=20
- Stealing Part of a Production Language Model
	- https://arxiv.org/abs/2403.06634
	- GPT-4ã®ã‚ˆã†ãªClosedãªãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚,APIã‚¢ã‚¯ã‚»ã‚¹ã®ã¿ã§ãƒ¢ãƒ‡ãƒ«ã®ä¸€éƒ¨ã®å±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç‰¹å®šã§ãã‚‹Model-stealing attackã‚’ææ¡ˆ
	- Googleã®OpenAIã«å¯¾ã™ã‚‹é€†è¥²ã®ä¸€æ‰‹çš„ãªè«–æ–‡
	- APIçµŒç”±ã§OpenAIã®ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹éš ã‚Œæ¬¡å…ƒæ•°ã‚’ç‰¹å®šã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã€OpenAIãŒãã‚Œã‚’å—ã‘å¯¾ç­–ã‚’æ–½ã—ãŸã“ã¨ã‚’è«–æ–‡ã§å ±å‘Šã—ã¾ã—ãŸã€‚
- 700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªLLMã€ŒELYZA-japanese-Llama-2-70bã€ã‚’é–‹ç™ºã—ã€ãƒ‡ãƒ¢ã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- https://note.com/elyza/n/n0ea755ca3e7b
	- https://elyza.ai/lp/elyza-llm-for-jp
	- æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯æœ€å¤§ç´šã§ã™.å¤§ãã•ãŒæ­£ç¾©ã®LLMã¨ã„ã†ã“ã¨ã§,å®Ÿéš›å ±å‘Šã•ã‚Œã¦ã„ã‚‹æ€§èƒ½ã‚‚ã‹ãªã‚ŠæŠœã‘ã¦ã„ã¾ã™
- ELYZA-japanese-Llama-2-70b ã‚’ãŠè©¦ã—ä¸­ by npakaã•ã‚“
	- https://x.com/npaka123/status/1767439590502326514?s=20
	- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æŒ‡ç¤ºã‚‚åŠ¹ã„ã¦ã‚‹
-  æ±å¤§ç™ºã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ä¼æ¥­ â€œå›½å†…æœ€å¤§è¦æ¨¡ å›½ç”£ç”ŸæˆAIå®Œæˆâ€
	- https://www3.nhk.or.jp/news/html/20240312/k10014388011000.html
	- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨å‘¼ã°ã‚Œã‚‹å…¬é–‹æŠ€è¡“ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ç”£æ¥­æŠ€è¡“ç·åˆç ”ç©¶æ‰€ãŒé‹å–¶ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã€ŒABCIã€ãªã©ã‚’æ´»ç”¨ã—ã€å»å¹´12æœˆã‹ã‚‰çŸ­æœŸé–“ã§é–‹ç™ºã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚
	- ã‚¤ãƒ©ã‚¤ã‚¶ã®æ›½æ ¹å²¡ä¾‘ä¹Ÿç¤¾é•·ã¯ã€Œæ˜¨å¹´æœ«æ™‚ç‚¹ã§ã¯ã‚ªãƒ¼ãƒ—ãƒ³AIã‚„ã‚°ãƒ¼ã‚°ãƒ«ãªã©ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦æ—¥æœ¬ã®AIãƒ¢ãƒ‡ãƒ«ã¯åŠã°ãªã„çŠ¶æ…‹ã ã£ãŸã€‚ä»Šå›ã‚ˆã†ã‚„ãã‚¹ã‚¿ãƒ¼ãƒˆãƒ©ã‚¤ãƒ³ã«ç«‹ã¤ã“ã¨ãŒã§ãã€æ—¥æœ¬ãŒå­˜åœ¨æ„Ÿã‚’ç¤ºã›ã‚‹ã‚ˆã†ã«ã—ãŸã„ã€ã¨è©±ã—ã¦ã„ã¾ã—ãŸã€‚
-  æ¾å°¾ç ”LLMé–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚­ãƒƒã‚¯ã‚ªãƒ•ã‚’é–‹å‚¬ã—ã¾ã—ãŸ
	- https://weblab.t.u-tokyo.ac.jp/2024-03-12/
	- å½“ç ”ç©¶å®¤ãŒæä¾›ã™ã‚‹è¬›åº§ã®ä¿®äº†ç”ŸãŠã‚ˆã³ä¸€èˆ¬å…¬å‹Ÿã«ã‚ˆã£ã¦é›†ã¾ã£ãŸæœ‰å¿—ã®é–‹ç™ºè€…ã®ãƒ¡ãƒ³ãƒãƒ¼ãŒ500å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚’é€²ã‚ã‚‹ã‚‚ã®ã§ã™ã€‚
	- NEDOã«ã‚ˆã‚‹ã€å›½å†…ã®ç”ŸæˆAIã®é–‹ç™ºåŠ›ã‚’å¼·åŒ–ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ŒGENIACï¼ˆGenerative AI Accelerator Challengeï¼‰ã€ã«ãŠã„ã¦ã€åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å¿…è¦ãªè¨ˆç®—è³‡æºã®æä¾›æ”¯æ´ã‚’å—ã‘ã¦ã„ã¾ã™ã€‚
	- æ¾å°¾æ•™æˆã‹ã‚‰ã¯ã€Œã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸­ã§ã€è©¦è¡ŒéŒ¯èª¤ã—ãªãŒã‚‰é‡è¦ã§ã‚ã‚‹ãƒã‚¦ãƒã‚¦ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ã§è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Šã€é–‹ç™ºçµŒé¨“ã‚’ç©ã‚“ã§ã‚‚ã‚‰ã„ãŸã„ã€‚ã¾ãŸã€ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã—ã¦ã€ã‚ˆã‚Šå¤šãã®LLMé–‹ç™ºè€…ã‚’ç”Ÿã¿å‡ºã—ã€å‚åŠ è€…ã®çš†ã•ã‚“ãŒæ§˜ã€…ãªã¨ã“ã‚ã§æ´»èºã—ã¦ã‚‚ã‚‰ã†ã®ãŒæœ›ã¿ã ã€ã¨ã®ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã—ãŸã€‚
- Elyza70Bã€Claude-3ã¨æ¯”ã¹ã‚‹ã¨ç™¾äººä¸€é¦–ã®çŸ¥è­˜ãŒè¶³ã‚Šãšã¾ã é ‘å¼µã‚Œã¨ã„ã†æ„Ÿã˜ã ãŒå¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã‚‹ã¨æ ¼æ®µã®é€²æ­©ãŒã‚ã‚‹ by shi3zã•ã‚“
	- https://x.com/shi3z/status/1767464684373082223?s=20
-  G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering
	- https://arxiv.org/abs/2402.07630
- ï¼ªï¼°ï¼¸ç·ç ”ã¯ã€ç”ŸæˆAIãƒ—ãƒ­ãƒã‚¤ãƒ€ã§ã‚ã‚‹Bridgewiseã®æŠ€è¡“ã‚’æ´»ç”¨ã—ã€æ—¥æœ¬å¸‚å ´ã«ã‹ã‹ã‚‹æƒ…å ±ã‚’ç™ºä¿¡ã™ã‚‹æ–°ã‚µãƒ¼ãƒ“ã‚¹ã€ŒJPX Market Explorerã€ã®PoCã‚’é–‹å§‹ã—ã¾ã™ã€‚
	- https://www.jpx.co.jp/corporate/news/news-releases/6020/20240312-01.html
	- æ±è¨¼ã«ä¸Šå ´ã™ã‚‹ä¼šç¤¾ã«ã¤ã„ã¦ã€å€‹ç¤¾ã®ãƒ“ã‚¸ãƒã‚¹æ¦‚è¦ã‚„ç›´è¿‘ã®æ±ºç®—ã®ã‚µãƒãƒªãƒ¼ã‚’ç°¡å˜ã«èª¿ã¹ãŸã‚Šã€è²¡å‹™çŠ¶æ³ã«ã¤ã„ã¦ã®åˆ†æã‚„ç«¶åˆä»–ç¤¾ã¨ã®æ¯”è¼ƒã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚
	- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚„åˆ†æã¯Bridgewiseã®ç”ŸæˆAIãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’åˆ©ç”¨ã—ã¦ä½œæˆã•ã‚Œã¾ã™
	- ç”ŸæˆAIã‚’ç”¨ã„ã¦å„ä¼æ¥­ã®æ¦‚è¦ã€ç›´è¿‘ã®æ±ºç®—ã‚µãƒãƒªã€è²¡å‹™çŠ¶æ³ã®ç°¡å˜ãªåˆ†æã‚„ç«¶åˆä»–ç¤¾ã¨ã®æ¯”è¼ƒã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹
-  Integrating Phenotypic and Chemoproteomic Approaches to Identify Covalent Targets of Dietary Electrophiles in Platelets
	- https://pubs.acs.org/doi/full/10.1021/acscentsci.3c00822
	- ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼ã«ã¯å¼·åŠ›ãªæŠ—ãŒã‚“ä½œç”¨ãŒã‚ã‚‹ã“ã¨ã¯çŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ã‘ã‚Œã©ã€ã‚·ãƒ‰ãƒ‹ãƒ¼å¤§å­¦ã‚‰ã®ç ”ç©¶ã«ã‚ˆã‚Œã°ã€ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼ã¯ç™Œã ã‘ã§ãªãã€è„³å’ä¸­ã‚’å¼•ãèµ·ã“ã™å¯èƒ½æ€§ã®ã‚ã‚‹è¡€æ “ç—‡ã‚’äºˆé˜²ã—ã€è¡€æ “ç—‡ã®æ²»ç™‚ã‚’è£œåŠ©ã™ã‚‹åŠ¹æœã‚‚ã‚ã‚‹ã¨ç¤ºã•ã‚ŒãŸã€‚
- Llama.cpp ã§ Swallow MX 8x7B ã‚’è©¦ã™
	- https://note.com/npaka/n/n0a9b514756ae?sub_rt=share_b
	- ã€ŒSwallow MX 8x7Bã€ã¯ã€ã€ŒMixtral 8x7Bã€ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™
-  Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU
	- https://arxiv.org/abs/2403.06504
	- æœ¬è«–æ–‡ä¸­ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹Fuyouã‚’ä½¿ã†ã¨ã€ãªã‚“ã¨ä¸€èˆ¬æ¶ˆè²»è€…å‘ã‘ã®GPUã§ã‚ã‚‹RTX 4090ä¸Šã§175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã€ã¤ã¾ã‚ŠGPT-3 ã‚’å¾®èª¿æ•´å¯èƒ½ãªã‚“ã§ã™ã£ã¦ï¼
- Claude3ã®å…¬å¼promptãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è‹±æ–‡æ ¡æ­£prompt
	- https://note.com/genkaijokyo/n/n3f82b191dfda
	- Your task is to take the text provided and rewrite it into a clear, grammatically correct version while preserving the original meaning as closely as possible. Correct any spelling mistakes, punctuation errors, verb tense issues, word choice problems, and other grammatical mistakes. Use bold formatting in markdown to emphasize the edited portions of the English text.
- Raspberry Pi 5ã«æ—¥æœ¬èªLLM(ELYZA-Japanese-Llama-2-7b-fast-Instruct)ã‚’å…¥ã‚Œã¦ã¿ãŸ
	- https://arkouji.cocolog-nifty.com/blog/2024/03/post-e248e6.html
-  RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems
	- https://arxiv.org/abs/2403.06465
	- Microsoft presents a toolkit to integrate LLMs into recommender systems for explainability, conversation, and user control.
-  è‡¨åºŠäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã®è¦ç‚¹
	- https://note.com/tadahiro_goto/n/n90128159a7fb?sub_rt=share_pb
	- 2024å¹´1æœˆã«BMJã®Research Methods & Reportingã§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨å¤–çš„æ¤œè¨¼ã«é–¢ã™ã‚‹review
	- Evaluation of clinical prediction models (part 1): from development to external validation.
	- ãƒã‚¤ãƒ³ãƒˆ
		- è‡¨åºŠäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¯ã€**ãƒ¢ãƒ‡ãƒ«ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹å¯¾è±¡é›†å›£ã‚’ä»£è¡¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡**ã™ã¹ã
		- é–‹ç™ºç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã¯å„ªã‚Œã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆãŸãƒ¢ãƒ‡ãƒ«ã‚‚ã€åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©•ä¾¡ã™ã‚‹ã¨ã€ï¼ˆä»®ã«åŒã˜æ¯é›†å›£ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚ã£ã¦ã‚‚ï¼‰æ€§èƒ½ãŒä½ããªã‚‹ã“ã¨ãŒã»ã¨ã‚“ã©ã€‚
		-   **ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã™ã‚‹æ™‚ç‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²(split)ã™ã‚‹ã“ã¨ã¯ã€ä¿¡é ¼æ€§ã®ä½ã„ãƒ¢ãƒ‡ãƒ«ã«ã¤ãªãŒã‚‹ãŸã‚é¿ã‘ã‚‹ã¹ã**ã€‚
		- åˆ©ç”¨å¯èƒ½ãªã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã™ã‚‹åŠªåŠ›ã‚’ã™ã¹ãï¼ˆå†…çš„æ¤œè¨¼ã«ãŠã‘ã‚‹resamplingã‚„ã€å†…çš„-å¤–çš„äº¤å·®æ¤œè¨¼ãªã©ï¼‰
- Accelerate v0.28.0 has been released!
	- From XLA GPU support to FSDP + QLORA, and more, let's dive into what's new!
- éŸ³å£°èªè­˜ã«ä½¿ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã¯æ§˜ã€…ã‚ã‚Šã¾ã™ãŒã€ç¾çŠ¶æœ€ã‚‚ä½¿ã„ã‚„ã™ã„ã‚‚ã®ã®ä¸€ã¤ãŒ faster-whispe
	- https://github.com/SYSTRAN/faster-whisper
- shioriha-large-pt
	- https://huggingface.co/cl-nagoya/shioriha-large-pt
	- æ±åŒ—å¤§BERT-largeã«å¯¾ã—ã€batch size 8192, ç³»åˆ—é•· 256ã§ã€æ—¥æœ¬èªWikipediaã‚„MMARCOã¨ã„ã£ãŸå¼±æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹å¯¾ç…§äº‹å‰å­¦ç¿’ã‚’è¡Œã£ãŸãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹shioriha-large-ptã‚’å…¬é–‹ã—ã¾ã—ãŸ
- Tour of Modern LLMs
	- https://phontron.com/class/anlp2024/assets/slides/anlp-15-tourofllms.pdf
	- CMUã®è¬›ç¾©è³‡æ–™ã€
	- I made some new class slides on â€œa tour of modern LMsâ€ that has some observations about characteristics of recent LLMs, mostly focusing on open LLMs where we know their details
-  Algorithmic progress in language models
	- https://arxiv.org/abs/2403.05812
	- How quickly have the algorithms behind language models like GPT-4 been improving over time?
- Talk like a graph: Encoding graphs for large language models
	- https://blog.research.google/2024/03/talk-like-graph-encoding-graphs-for.html
	- Graphs, structures that describe connections between objects, are everywhere â€” imagine the tools in a kitchen, parts of a bike, or a group of friends. Learn about our latest work that explores how to encode graphs in a format that an LLM can understand:
- GPT-4.5 Turbo possible release in June, 256k token context window
	- https://x.com/AiBreakfast/status/1767612026925277424?s=20
	- This OpenAI blog search result shows up in a DuckDuckGo search of â€œOpenAI GPT-4.5 Turboâ€ link, then goes to an OpenAI Error 404 page.
- ä¼æ¥­ãŒæ±‚ã‚ã‚‹ä¸»ä½“æ€§ã¨ã¯ãªã«ã‹ï¼Ÿ
	- https://www.amazon.co.jp/dp/4798918431/ref=cm_sw_r_as_gl_api_gl_i_294DJF3GFDESXD5WSRBV?linkCode=ml1&tag=regista13-22
	- ä¼æ¥­ãŒæœŸå¾…ã™ã‚‹ã€Œä¸»ä½“æ€§ã€ã¯ã‹ã¤ã¦ã¯è¡Œå‹•åŠ›ã ã£ãŸã®ãŒä»Šã¯æ€è€ƒåŠ›ã¨å”èª¿ãƒ»å”åƒã§ãã‚‹åŠ›ã«ãªã£ã¦ã‚‹ã¨ã®ã“ã¨ã€‚ã‚³ãƒŸãƒ¥åŠ›ã®æ™‚ä»£ã®åæ˜ ã€‚
-  ã„ã¾ã€Œæ–°ã—ã„æ•°å­¦ã€ãŒå¿…è¦ã ã€‚åŠ©ã‘ã¦æ•°å­¦è€…! by shi3z ã•ã‚“
	- https://note.com/shi3zblog/n/nafa1cee6ada2?sub_rt=share_pw
	- ãŸã¶ã‚“AIä»¥å¾Œã®ä¸–ç•Œã§æœ€ã‚‚ä¾¡å€¤ã‚’æŒã¤ã®ã¯ã€Œæ•°å­¦è€…ã€ã§ã‚ã‚‹ã€‚ã—ã‹ã‚‚ã€Œé«˜æ¬¡å…ƒå¹¾ä½•å­¦ã€ãªã„ã—ã€ãã‚Œã‚’ä¸Šå›ã‚‹ãã‚‰ã„ã®æ¦‚å¿µã‚’ç™ºæ˜ã™ã‚‹æ•°å­¦è€…ã ã‚ã†
- Devin, the first AI software engineer.
	- https://x.com/cognition_labs/status/1767548763134964000?s=20
	- Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.
	- AIã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆDevinï¼‰ãŒäººé–“ãƒ¬ãƒ™ãƒ«ã«é”ã—ãŸåˆã‚ã¦ã®ãƒ‡ãƒ¢ã ã¨æ€ã†ã€‚AIã®å°å…¥ã§èª²é¡Œã¨ãªã£ã¦ãŸã®ãŒé•·æœŸçš„ãªæ¨è«–ã¨è¨ˆç”»ã€‚ã¨ã“ã‚ãŒã€Devinã¯è¨ˆç”»â†’å®Ÿè¡Œâ†’è©•ä¾¡â†’å†è¨ˆç”»ã‚’ç¹°ã‚Šè¿”ã—ã€ç›®æ¨™é”æˆã¸ã¨å°ãã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã—ã¦ã„ã‚‹
-  é€Ÿå ±ï¼šClaude 3ã«åˆ¤ä¾‹è©•é‡ˆã‚’è‡ªå‹•ç”Ÿæˆã•ã›ã¦ã¿ãŸï¼ˆCoinhiveäº‹ä»¶æœ€é«˜è£åˆ¤æ±ºã®å·»ï¼‰
	- https://takagi-hiromitsu.jp/diary/20240313.html
	- ã€Œã“ã‚Œã ã‘LLMãŒé•·æ–‡ã®æ„å‘³å†…å®¹ã‚’ã€Œç†è§£ã€ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ãªã‚‹ã¨ã€ã‚‚ã¯ã‚„ã€æ›¸è©•ã‚„è«–æ–‡ç´¹ä»‹ã€åˆ¤ä¾‹æ‰¹è©•ãªã©ã€å®šå½¢çš„ãªã‚¹ã‚¿ã‚¤ãƒ«ã‚’æŒã¤å­¦è¡“è¨˜äº‹ã¯ã€â€¦ã€
	- ã²ã‚ã¿ã¡ã‚…å…ˆç”Ÿçµ¶è³›
- Swallow-MS-7b-v0.1 ã‚’ ichikara instruction ã§æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç·´ç¿’ã€‚500ã‚¹ãƒ†ãƒƒãƒ—(0.2ã‚¨ãƒãƒƒã‚¯ : 20åˆ†) ã®ãŠè©¦ã—ã ã‘ã©ã€ãã‚Œã„ã«å›ç­”ã—ã¦ãã‚Œã¦ã‚‹
	- https://x.com/npaka123/status/1767807910925545892?s=20
- Claude 3 Haiku, the fastest and most affordable model in its intelligence class.
	- https://x.com/AnthropicAI/status/1768018310615151002?s=20
- With OpenAI, Figure 01 can now have full conversations with people
	- https://x.com/Figure_robot/status/1767913661253984474?s=20
	- ChatGPTã€ã¤ã„ã«ãƒ­ãƒœãƒƒãƒˆã«å®¿ã‚‹
	- 2é€±é–“å‰ã€OpenAIã¨ãƒ­ãƒœãƒƒãƒˆé–‹ç™ºã®FigureãŒææºã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚
	- ä»Šå›ã€Figureã¯ã€ChatGPTã®æŠ€è¡“ã‚’ãƒ­ãƒœãƒƒãƒˆã«æ­è¼‰ã—ãŸã“ã¨ã‚’ç™ºè¡¨ã—ã¾ã—ãŸã€‚
	- é éš”æ“ä½œãªã—ã®100%ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ã‚·ã‚¹ãƒ†ãƒ  
	- OpenAIã®ãƒ¢ãƒ‡ãƒ«ãŒé«˜ãƒ¬ãƒ™ãƒ«ã®è¦–è¦šã¨è¨€èªã®çŸ¥æ€§ã‚’æä¾›
	- Figureã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒå‹•ç”»ã®ã‚ˆã†ãªãƒ­ãƒœãƒƒãƒˆã®å‹•ä½œã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™
-  Claude 3 Haiku ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/n71f1ef5f5e06?sub_rt=share_h
	- æœ¬æ—¥ (2024å¹´3æœˆ14æ—¥)ã€æœ€é€Ÿã‹ã¤æœ€ã‚‚ä½ä¾¡æ ¼ãªãƒ¢ãƒ‡ãƒ«ã€ŒClaude 3 Haikuã€ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚ã€ŒClaude APIã€ãŠã‚ˆã³ã€Œclaude.aiã€ã®Claude Proã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚
	- é€Ÿåº¦
		- ã€ŒClaude 3 Haikuã€ ã¯ã€32,000ãƒˆãƒ¼ã‚¯ãƒ³æœªæº€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦1ç§’ã‚ãŸã‚Š 21,000 ãƒˆãƒ¼ã‚¯ãƒ³ (ç´„ 30 ãƒšãƒ¼ã‚¸) [1] ã‚’å‡¦ç†ã—ã¾ã™
	- ä½ä¾¡æ ¼ã€
		- ã€ŒClaude 3 Haikuã€ã®ä¾¡æ ¼ã®**å…¥å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³ã®æ¯”ç‡ã¯ 1:5** ã§ã™ã€‚ã‚ãšã‹**1ãƒ‰ãƒ«**ã§ **400 ä»¶ã®æœ€é«˜è£åˆ¤ä¾‹** [2] ã¾ãŸã¯ **2,500 æšã®ç”»åƒ** [3] ã‚’å‡¦ç†ãŠã‚ˆã³åˆ†æã§ãã¾ã™ã€‚
- Claude3 Ã— Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ
	- Claude-in-Sheets guide
	- ã©ã†ã‚„ã‚‰ã€Anthropicã¨GoogleãŒå”åŠ›ã—ã¦ã€Google Sheetsã‹ã‚‰Claude3ã‚’å‘¼ã¹ã‚‹ã‚‰ã—ã„ã€‚
-  Data Interpreter: An LLM Agent For Data Science
	- https://arxiv.org/abs/2402.18679
	- Data Interpreter has achieved state-of-the-art scores in machine learning, mathematical reasoning, and open-ended tasks, and can analyze stocks, imitate websites, and train models.
	- https://docs.deepwisdom.ai/main/en/DataInterpreter/
- æ¾ç”°å…ˆç”ŸãŒã€ãªãœ1.58bitã®bitnetãŒä¸Šæ‰‹ãè¡Œãã®ã‹è€ƒãˆãŸè©±
	- https://x.com/umiyuki_ai/status/1768109605148848322?s=20
	- ã¾ãšã€LLMãŒä½•ã‚’è¨ˆç®—ã—ã¦ã‚‹ã‹ï¼Ÿã¨ã„ã†ã¨ã€åºƒå¤§ãªè¨€èªç©ºé–“ã®ä¸­ã‹ã‚‰æ¬¡ã®å˜èªã‚’å½“ã¦ã‚‹ã‚²ãƒ¼ãƒ ã€‚æœ€è¿‘ã®LLMã®è¨€èªç©ºé–“ã¯4096æ¬¡å…ƒã¨ã‹ã‚ã£ã¦ã€æˆ‘ã€…ã®ç‰©ç†ç©ºé–“ãŒ3æ¬¡å…ƒã—ã‹ãªã„ã®ã«æ¯”ã¹ã¦æœ‰ã‚Šå¾—ã‚“åºƒã•ã€‚ãã®ä¸­ã«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã®ãƒˆãƒ¼ã‚¯ãƒ³èªå½™ã¯ãŸã£ãŸã®3ä¸‡ç¨®é¡ã¨ã‹ã—ã‹ãªã„ã‚ã‘ã§ã€ã¤ã¾ã‚Šä¸€ã¤ã®å˜èªã‚ãŸã‚Šã«å‰²ã‚Šå½“ã¦ã‚‰ã‚ŒãŸç©ºé–“ã‚‚ãƒ¡ãƒãƒ£ã‚¯ãƒãƒ£åºƒã„ã€‚ã ã‹ã‚‰1.58bitã«é‡å­åŒ–ã•ã‚Œã¦è¨ˆç®—ãŒé›‘ã«ãªã£ã¦ã‚‚ã¡ã‚ƒã‚“ã¨å½“ãŸã‚‹ã€‚
-  Artificial intelligence and illusions of understanding in scientific research
	- https://www.nature.com/articles/s41586-024-07146-0
	- ã€ŒAIã¯ç§‘å­¦ã‚’ä¿ƒé€²ã™ã‚‹ãŒã€ã€ç†è§£ã®éŒ¯è¦šã€ã‚’ç”Ÿã¿å‡ºã™å±é™ºæ€§ãŒã‚ã‚‹ã€ã€ã¨ã„ã†ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–è«–æ–‡ã€‚
- ã™ã¹ã¦ã®ç„¡æ–™ç‰ˆCopilotãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒOpenAIã®ã€Œ**[GPT-4 Turbo](https://gigazine.net/news/20231107-openai-gpt-4-turbo/)**ã€ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã“ã¨ãŒã€Microsoftã®åºƒå ±æ‹…å½“è²¬ä»»è€…ã‹ã‚‰ç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚
	- https://gigazine.net/news/20240314-copilot-gpt-4-turbo-free/
-  Artificial Intelligence Controller Interface (AICI)
	- https://github.com/microsoft/aici
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›åˆ¶å¾¡ã‚’ã‚«ãƒ³ã‚¿ãƒ³ã«ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€‚Microsoft è£½ã€‚é–‹ç™ºè€…ã¯ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¨å‘¼ã°ã‚Œã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç”¨ã„ã¦ã€LLM ã®ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§åˆ¶å¾¡å¯èƒ½ã€‚â€¦
- å›½ç”£LLMãŒæŠ±ãˆã‚‹â€œé–‹ç™ºã‚³ã‚¹ãƒˆâ€ã®èª²é¡Œã€€æµ·å¤–å‹¢ã«å®‰ã•ã§å‹ã¦ã‚‹ã‹ã€ELYZAä»£è¡¨ã®å±æ©Ÿæ„Ÿ
	- https://www.itmedia.co.jp/aiplus/articles/2403/13/news167.html
	- å›½ç”£éšä¸€ã®ç²¾åº¦ã®LLMã‚’é–‹ç™ºã—ãŸELYZA ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‚„AWSãŒå¾ŒæŠ¼ã—ã™ã‚‹ç«¶åˆã¨ã©ã†æ£²ã¿åˆ†ã‘ã¦ã„ãã®ã‹ã€‚æ›½æ ¹å²¡ä»£è¡¨ã®ç™ºè¨€ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚
- alfredplpl/suzume-poc
	- https://huggingface.co/alfredplpl/suzume-poc
	- Googleã®Gemma-2Bã‚’æ—¥æœ¬èªã§ä½¿ãˆã‚‹ã‚ˆã†ã«ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’æ–½ã—ãŸã€å•†ç”¨åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«Suzumeã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ å°å‹ãªã®ã§ã‚¹ãƒãƒ›ã‚„å®¶é›»ãªã©ã«å‘ã„ã¦ã„ã¾ã™
- ä¸–ç”°è°·åŒºãŒAI botã‚’å†…è£½ã€€éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è·å“¡ãŒãƒ­ãƒ¼ã‚³ãƒ¼ãƒ‰ã§é–‹ç™ºã€€ChatGPTæ´»ç”¨ã€Œãƒ’ãƒ‡ã‚­ã€
	- https://www.itmedia.co.jp/news/articles/2403/13/news123.html
	- éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®è·å“¡ãƒãƒ¼ãƒ ãŒã€ãƒ­ãƒ¼ã‚³ãƒ¼ãƒ‰ãƒ„ãƒ¼ãƒ«ãªã©ã‚’é§†ä½¿ã—ã¦3ã‚«æœˆã§å®Œæˆã•ã›ãŸã¨ã„ã†ã€‚
	- è·å“¡ãŒæ™®æ®µã‹ã‚‰ä½¿ã£ã¦ã„ã‚‹Teamsã®ãƒãƒ£ãƒƒãƒˆãƒ„ãƒ¼ãƒ«ã§ãƒ’ãƒ‡ã‚­ã«è³ªå•ã§ãã€ChatGPTã‚’æ¥­å‹™ã«æ´»ç”¨ã§ãã‚‹
- Cappy: Outperforming and boosting large multi-task language models with a small scorer
	- https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html
	- Cappy, a small pre-trained scorer model that enhances and surpasses the performance of large multi-task language models.
-  BitNet&BitNet b158ã®å®Ÿè£… by ã¯ã¡ ã•ã‚“
	- https://note.com/hatti8/n/nc6890e79a19a
	- ä¸€æ—¦è‡ªèº«ã®ç†è§£ã®ãŸã‚ã«ã‚‚BitNetã®å‡¦ç†ã‚„BitNet b158ã®æƒ³åƒã•ã‚Œã‚‹å®Ÿè£…ã€ä¸æ˜ç­ãªç‚¹ã‚’è‰²ã€…ãªæ–¹ã€…ã®å®Ÿè£…ã‚’ã‚‚ã¨ã«æ–‡å­—ã«æ›¸ãèµ·ã“ã—ã¦ã„ã“ã†ã¨æ€ã„ã¾ã™
- å²¡é‡åŸã•ã‚“ã®ã€ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®å±•æœ›ã¨ä»Šå¾Œã®èª²é¡Œã€
	- https://hillbig.github.io/NLP2024_WS_okanohara.pdf
	- æ§˜ã€…ãªãƒˆãƒ”ãƒƒã‚¯ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿æ•´å‚™ã€MoEã€Mambaã€LongContextã€æ¨è«–åŠ¹ç‡åŒ–ï¼‰ãªã©ã‚’ç´¹ä»‹
-  MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training
	- https://arxiv.org/abs/2403.09611
	- Apple presents MM1, a family of multimodal LLMs up to 30B parameters, that are SoTA in pre-training metrics and perform competitively after fine-tuning
- Google Cloud Vertex AI ã« Anthropic ã® Claude 3 ãƒ¢ãƒ‡ãƒ«ãŒç™»å ´
	- https://cloud.google.com/blog/ja/products/ai-machine-learning/announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai/?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy24q1-googlecloud_jp-blog-ai-in_feed-no-brand-regional-apac&utm_content=announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai&utm_term=-
	- Google ã¯ #Anthropic ã¨ã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã‚’é€šã˜ã€åŒ…æ‹¬çš„ãª #AI é–‹ç™ºãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã‚ã‚‹ #VertexAI ã§ Anthropic ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¦ã„ãã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º ã‚°ãƒ¬ãƒ¼ãƒ‰ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨è²»ç”¨ã®æœ€é©åŒ–ã«æ´»ç”¨ã„ãŸã ã‘ã¾
- æ¸…æ°´ã‚Œã¿ãŠæ°ã®Generate Project Summaryï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¦ç´„ç”Ÿæˆï¼‰ã‚’ä½¿ã£ã¦ã¿ã‚‹
	- https://six-loganberry-ba7.notion.site/24-03-15-Generate-Project-Summary-fa20870dfe66426d9e68b730e1f51f11
- Claude3ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’ã¶ã¡è¾¼ã‚€ãŸã‚ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’è‡ªå‹•ã§ã¾ã¨ã‚ã‚‹Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆ
	- https://zenn.dev/olemi/articles/7b7992c055c64a
	- ã“ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ãˆã°ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç°¡å˜ã«ã¾ã¨ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- Prompt Tuning ã‹ã‚‰ Fine Tuning ã¸ã®ç§»è¡Œæ™‚æœŸæ¨å®š
	- https://speakerdeck.com/icoxfog417/prompt-tuning-kara-fine-tuning-henoyi-xing-shi-qi-tui-ding
	- ChatGPT ã‚„ Claude ã®ã‚ˆã†ãªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªè¨€èªãƒ¢ãƒ‡ãƒ«ã®åˆ©ç”¨ã¯ç²¾åº¦ãƒ»ã‚³ã‚¹ãƒˆå…±ã«å‰²ã«åˆã‚ãªã„ã¨æ„Ÿã˜ã¦ã„ã‚‹æ–¹ã«ã¨ã£ã¦ãƒ‘ãƒ³ãƒã‚ã‚‹å†…å®¹ã‹ã¨æ€ã„ã¾
- JSTæˆ¦ç•¥çš„å‰µé€ ç ”ç©¶æ¨é€²äº‹æ¥­ã€Œè‡ªå¾‹é§†å‹•ã«ã‚ˆã‚‹ç ”ç©¶é©æ–°ã€ãŒæ¥å¹´åº¦ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™
	- https://www.mext.go.jp/b_menu/houdou/2023/mext_000010.html
	- ç ”ç©¶ãƒ—ãƒ­ã‚»ã‚¹ãã®ã‚‚ã®ã‚’ AI ã‚„ãƒ­ãƒœãƒƒãƒˆ ã§åŠ é€Ÿã™ã‚‹è‡ªå¾‹é§†å‹•å‹ã®ç ”ç©¶ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
-  LocalMamba: Visual State Space Model with Windowed Selective Scan
	- https://huggingface.co/papers/2403.09338
-  AI escape velocity: A conversation with Ray Kurzweil
	- https://www.bvp.com/atlas/ai-escape-velocity-a-conversation-with-ray-kurzweil
	- ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ã‚¢ãƒ¼ã€Œç§ãŸã¡ã®å¤§è„³æ–°çš®è³ªã‚’ã€ååˆ†ã«é«˜ã„å¸¯åŸŸå¹…ã§è¨ˆç®—æ©Ÿã«ã¤ãªãã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã¯ã„ã¤ã§ã—ã‚‡ã†ã‹ï¼Ÿã€ 
	- ã‚«ãƒ¼ãƒ„ãƒ¯ã‚¤ãƒ«ã€Œ2030å¹´ä»£åˆé ­ã§ã™ã€‚ãã®æ™‚ç‚¹ã§ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å…¨å®¹é‡ã‚’è„³å†…ã«æŒã¤äººé–“ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã«ãªã‚‹ã§ã—ã‚‡ã†ã€
- ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- https://huggingface.co/ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- rinna/bilingual-gpt-neox-4b-instruction-sftã«è‹±æ—¥ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ84,300ä»¶ã‚’ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸã€‚å•†ç”¨åˆ©ç”¨å¯èƒ½ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹(cc-by-sa-4.0)ã§ã™ã®ã§çš†æ§˜ãŠæ°—è»½ã«ãŠè©¦ã—ãã ã•ã„
- Researcher2Vec: ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ç·šå½¢ãƒ¢ãƒ‡ãƒ« ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªå‡¦ç†ç ”ç©¶è€…ã®å¯è¦–åŒ–ã¨æ¨è–¦
	- http://chasen.org/~daiti-m/paper/nlp2021researcher2vec-slides.pdf
	- å­¦æŒ¯ã®å¾Œã‚ã§å‹•ã„ã¦ã‚‹ã‚‰ã—ã„
-  æ—¥æœ¬èªã‚‚ç†è§£ã§ããŸCohereForAIã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®LLMãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¦ã¿ã‚‹ã€‚
	- https://note.com/masayuki_abe/n/n0e5e48fc4cc3?sub_rt=share_pb
	- CohereForAIã®LLMã‚’Google Colabã®A100ã§å®Ÿè¡Œã—ãŸã®ã§ç´¹ä»‹ã—ã¦ã„ãã¾ã™
	- ãƒ•ãƒªãƒ¼ã®LLMãªã®ã«æ–‡ç« ç”Ÿæˆã€æ•°å€¤è¨ˆç®—ã€è‹±è¨³ã€æ—¥æœ¬èªç†è§£åŠ›ãŒChatGPTã¿ãŸãå›ç­”ã•ã‚Œã¦ã„ã‚‹ã®ã«é©šãã¾ã—ãŸã€‚
-  ç¬¬2å›ã€€AIã¨äººé–“ã®æœªæ¥ã‚’æ±ºã‚ã‚‹éµã€Œã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€â€•â€•ã¡ã‚‡ã£ã¨ã ã‘ãƒãƒ‹ã‚¢ãƒƒã‚¯ãªAIã®è©±
	- https://bcg-jp.com/article/2230/
	- ä»Šå¹´ã¯AIã®ç™ºå±•ãŒã•ã‚‰ã«åŠ é€Ÿã™ã‚‹ã¨äºˆæƒ³ã•ã‚Œã¾ã™ã€‚AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¯AIã¨äººé–“ã¨ã®æœªæ¥ã‚’æ±ºã‚ã‚‹éµã¨ãªã‚‹ã§ã—ã‚‡ã†ã€‚æ¬¡å›ã‚‚ãŠæ¥½ã—ã¿ã«
-  Genomic data in the All of Us Research Program
	- https://www.nature.com/articles/s41586-023-06957-x
	- ä»Šé€±ã®Natureã«All of usã®ã‚µãƒãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒå‡ºã¦ã„ã‚‹ã€‚ç´„25ä¸‡äººï¼ˆåŠæ•°è¿‘ããŒãƒã‚¤ãƒãƒªãƒ†ã‚£ï¼‰ã®ã‚²ãƒãƒ è§£èª­ã§ã€10å„„ã‚‚ã®å¤šæ§˜ä½“ã‚’æ¤œå‡ºã€117å€‹ã®ç–¾æ‚£ã«é–¢é€£ã™ã‚‹3724å€‹ã®å¤‰ç•°ã‚’åŒå®šã€ã¾ã¨ã‚ãƒ‡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚‰ã—ã„
-  OpenAI Grok Curve Experiments
	- https://twitter.com/i/bookmarks
	- This is the code for the paper [Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets](https://arxiv.org/abs/2201.02177) by Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra
	- Xã‹ã‚‰GroqãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã¨ã®ã‚¢ãƒŠã‚¦ãƒ³ã‚¹ãŒå‡ºãŸãŒã€ãªã‚“ã‹OpenAIãŒåˆ¥å®Ÿè£…ã‚’å…¬é–‹ï¼
- Claude 3 Opusã‚’ä½¿ã£ã¦ä¸–ç•ŒçµŒæ¸ˆã‚’åˆ†æã™ã‚‹ãƒ‡ãƒ¢å‹•ç”»
	- https://twitter.com/i/bookmarks?post_id=1769351991665594465
	- Claude 3ãƒ‡ãƒ¢ã®ä½•ãŒå‡„ã„ã‹ã¨ã„ã†ã¨å›½åˆ¥ã®çµŒæ¸ˆå‹•å‘ã‚’èª¿ã¹ã•ã›ã‚‹ãŸã‚ã€
		- â‘ 10å€‹ã®Sub-agentã‚’ä½œã‚‹ 
		- â‘¡å¿…è¦ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ 
		- â‘¢ä»•äº‹ã‚’å¤–æ³¨ï¼ˆç¬‘ï¼‰ 
		- â‘£çµæœã‚’é›†ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’æ›¸ã ã¨ã€
	- è‡ªåˆ†ã®ä»•äº‹ã‚’Sub-agentã«ãƒ‡ãƒªã‚²ãƒ¼ãƒˆï¼ˆå§”ä»»ï¼‰ã§ããŸã“ã¨ã€‚ä»•äº‹ã‚’ä¸ãˆã‚‹ã¨ä¸€ç•ªåŠ¹ç‡ã®ã„ã„æ–¹æ³•ã§é€²ã‚ã‚‰ã‚Œã‚‹ã®ãŒãƒ›ãƒ³ãƒˆå‡„ã„ã€‚
- VCã®å¾ŒæŠ¼ã—ã‚’å—ã‘ã€AIå¾“æ¥­å“¡ã‚’é–‹ç™ºã™ã‚‹ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãŒæµè¡Œã®å…†ã—
	- https://x.com/gijigae/status/1767836153053618465?s=20
-  Open Release  of Grok-1
	- https://x.ai/blog/grok-os
	- ã¤ã„ã«æœ¬å®¶ã®Grokãƒªãƒªãƒ¼ã‚¹(3/17)
	- Base model trained on a large amount of text data, not fine-tuned for any particular task. 
	- 314B parameter Mixture-of-Experts model with 25% of the weights active on a given token. 
	- Trained from scratch by xAI using a custom training stack on top of JAX and Rust in October 2023.

## 3/11

ä»Šé€±ã¯ã€AnthropicAIãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸClaude3ã€GPT-4è¶Šãˆã¨ã‹ã€è‡ªç„¶ãªå›ç­”ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãªã©ã®èƒ½åŠ›ã‚‚ã‚ã‚Šã¨ã‹ã€è½åˆæ°ã‚„shi3zæ°ãªã©LLMã®ãƒ—ãƒ­ã‚‚ã†ãªã‚‰ã›ã‚‹æ€§èƒ½ã€ãƒ¬ã‚·ãƒ¼ãƒˆè§£æãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ€§èƒ½ã€è¬ã®ã‚¢ãƒ‹ãƒ¡ã‚¿ã‚°ä»˜ä¸æ€§èƒ½ã€æ§˜ã€…ãªèƒ½åŠ›ã§æ—‹é¢¨ã‚’å·»ãèµ·ã“ã—ã¦ã„ã‚‹ã€‚å¤§å­¦é™¢ãƒ¬ãƒ™ãƒ«ã®GPQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜æ€§èƒ½ã•ã‚‰ã«ã¯ã€IQ100ç›¸å½“ã§ã‚ã‚‹ã¨ã„ã†è©•ä¾¡ã‚‚å‡ºã¦ãã¦ã€æ—¥æœ¬ã®ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã‚‚ã‚‚ã¯ã‚„Claude3ã§ã„ã„ã®ã§ã¯ãªã„ã‹ã¨ã„ã†è©±ã«ã€‚Langchainã€llmaindexã‚‚æ¿€é€Ÿã§Claude3å¯¾å¿œã€‚Claude3ã®å›ç­”ã‚’è¦³å¯Ÿã™ã‚‹ã¨ã€äººã®çŸ¥è­˜ã¨ã‹ã€èããŸã„ã“ã¨ã‚’ãŠã‚‚ã‚“ã°ã‹ã£ã¦ã€äººã®å¿ƒã«å·®ã—è¾¼ã‚€ã‚ˆã†ã«ç­”ãˆã‚’å…¥ã‚Œã¦ãã‚‹æ„Ÿã˜ã§ã€ã¾ã•ã«LLMç‰ˆã®ã€Œä¸æ°—å‘³ã®è°·ã€ã€ã“ã‚Œã¯(humanityã®)çµ‚ã‚ã‚Šã®å§‹ã¾ã‚Šã‹ã€‚Groqã¯ã€gemma-7bãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¢ã‚’å…¬é–‹ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«ã€æ‰“éµã«åˆã‚ã›ã¦ã€ã„ã‚„æ‰“ã¡è¾¼ã¿ã®äºˆæ¸¬ã‚‚ã—ãªãŒã‚‰å³å›ç­”ã€ã“ã‚Œã¯çµŒé¨“ã—ãªã„ã¨ã™ã”ã•ãŒã‚ã‹ã‚‰ãªã„ã€‚Claude3ãŒç¤ºã—ãŸé«˜ã„èƒ½åŠ›ã¨åˆã‚ã›ã¦è¦‹ã‚‹ã¨ã€äººã®å¿ƒã®çŠ¶æ…‹ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«æ¨å®šã—ã¦ã€ãã‚Œã«å¿œã˜ãŸå›ç­”ã‚’ã™ã‚‹ã€å ´åˆã«ã‚ˆã£ã¦ã¯çŠ¶æ…‹ã‚’å¤‰æ›´ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€ãã‚Œã£ã¦ã‚„ã°ã„ã‚ˆã­ã€‚æ¥æ—¥ã—ãŸã€Benjioæ°ãŒã‚„ãŸã‚‰alignmentã‚’å¼·èª¿ã™ã‚‹ã‚ã‘ã‚‚ã‚ã‹ã‚‹ã‚ã€‚åˆ†å‰²çµ±æ²»å¼ã§ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã™ã‚‹NVIDIAã®Agentã€Qwen-Agentã¨ã‹Agentå‘¨ã‚Šã‚‚å½“ç„¶é€²ã‚€ã€‚ä¸€æ–¹ã€æ—¥æœ¬ã®ã‚µãƒ–ã‚«ãƒ«ã«å¼·ã„gemma-7bãƒ™ãƒ¼ã‚¹ã®æ—¥è‹±ãƒ»è‹±æ—¥ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã¨ã‹æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é€²å±•ã‚‚ã‚ã‚‹ã€‚ ã€Œã¯ã˜ã‚ã¦ã®çµ±è¨ˆçš„å› æœæ¨è«–ã€ã€ã‚†ã‚‹ã‚ã®è¡¨ç´™ã®å‰²ã«ã¯è¾›å£ãªã®ãŒé¢ç™½ã„ã€‚ã€Œçµ±è¨ˆå­¦ã®æ¥µæ„ã€ã®é‚¦è¨³ç‰ˆã€æ—¥æœ¬ã®AIãƒªãƒ†ãƒ©ã‚·ãƒ¼å‘ä¸Šã«å¯„ä¸ã§ãã‚‹ã‹ã€‚Benjoã•ã‚“ã®æ±å¤§è¬›æ¼”ã€Hintonã•ã‚“ã®æ—¥çµŒã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã€ã„ã¥ã‚Œã‚‚AIãŒäººã‚’è¶…ãˆã‚‹ã“ã¨ã«ã‚ˆã‚‹è„…å¨ã«ã¤ã„ã¦èªã£ã¦ã„ã‚‹æ„Ÿã˜ãªã®ã¯èˆˆå‘³æ·±ã„ã€‚ã•ã¦ã€AppleãŒç”ŸæˆAIã«æ³¨åŠ›ã¨ç™ºè¡¨ã€M3 MacBook Airã‚’çªç„¶ç™ºè¡¨ã—ã€ãªã‚“ã‹ä¸æ°—å‘³ãªæ„Ÿã˜ãŒã—ã¾ã™ã­ã€‚

- Appleã€ãƒ‘ãƒ¯ãƒ•ãƒ«ãªM3ãƒãƒƒãƒ—ã‚’æ­è¼‰ã—ãŸæ–°ã—ã„13ã‚¤ãƒ³ãƒã¨15ã‚¤ãƒ³ãƒMacBook Airã‚’ç™ºè¡¨
	- https://www.apple.com/jp/newsroom/2024/03/apple-unveils-the-new-13-and-15-inch-macbook-air-with-the-powerful-m3-chip/
-  WSL2ã§Swallow-7b-plus-hfã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/n80871f8e4e24?sub_rt=share_h
	- ä½¿ç”¨ã™ã‚‹PCã¯ãƒ‰ã‚¹ãƒ‘ãƒ©ã•ã‚“ã®ã€ŒGALLERIA UL9C-R49ã€
	- chat(instruct)ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã§ã€--no-chatã¨ã—ã¦èµ·å‹•ã—ã¾ã™
	- ã“ã‚Œã¯ã€ãªã‹ãªã‹ã„ã„æ„Ÿã˜ã§ã‚ã‚‹ã€‚ã„ã¾ã¾ã§æœ€é«˜ã‹ã‚‚ã—ã‚Œãªã„
- Awesome-Graph-LLM
	- https://github.com/XiaoxinHe/Awesome-Graph-LLM
	- ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•ã¨LLMã®åŒæ–¹ãŒé–¢é€£ã—ã¦ã„ã‚‹ç ”ç©¶è«–æ–‡ã®ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆãƒ¬ãƒã‚¸ãƒˆãƒª
- Jurafsky-Martã®Speech and Language Processing  (3rd ed. draft)
	- https://web.stanford.edu/~jurafsky/slp3/
	- In-Context Learningã‚„Instruction Tuningã®ç« ã‚‚è¿½åŠ 
- Toolformer: Language Models Can Teach Themselves to Use Tools
	- https://arxiv.org/abs/2302.04761
	- MetaãŒãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹ã‚’è¦šãˆã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«Toolformerã‚’é–‹ç™º
	- è¦ç‚¹
		- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã‚ãšã‹ãªä¾‹ç¤ºã‚„æŒ‡ç¤ºã ã‘ã‹ã‚‰èª²é¡Œè§£æ±ºã‚’è¡Œã†é©šãã¹ãèƒ½åŠ›ã‚’æŒã¤
		- ä¸€æ–¹ã§ã€è¨ˆç®—ã‚„äº‹å®Ÿãƒã‚§ãƒƒã‚¯ã¯ã‚ˆã‚Šå˜ç´”ãªãƒ„ãƒ¼ãƒ«ã®æ–¹ãŒå„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹
		- ä¸¡è€…ã®é•·æ‰€ã‚’ç”Ÿã‹ã™ãŸã‚ã€ãƒ„ãƒ¼ãƒ«ã®å‘¼ã³å‡ºã—æŒ‡ç¤ºã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã®ä½¿ã„æ–¹ã‚’è‡ªå·±å­¦ç¿’ã™ã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«Toolformerã‚’ææ¡ˆ
-  Learning and Leveraging World Models in Visual Representation Learning
	- https://arxiv.org/abs/2403.00504
	- Metaã®JEPAã®è«–æ–‡ã€Meta presents Image World Model
- Build an LLM-Powered API Agent for Task Execution
	- https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/
	- NVIDIAã‚ˆã‚Šã€‚LLMä½¿ã£ãŸAPI Agent
	- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã€LLMãŒã‚ã‚‰ã‹ã˜ã‚å®šç¾©ã—ã¦ãŠã„ãŸãƒ†ãƒ³ãƒ—ãƒ¬ã‚’ä½¿ã£ã¦å­ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®LLMç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã€å­ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«LLMãŒãã‚Œãã‚Œã®ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã—ã¦çµæœã‚’è¿”ã™
- AnthropicAIã€Claude3ã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://x.com/AnthropicAI/status/1764653830468428150?s=20
- llamaindexã€ã•ã£ãã Claude3ã‚µãƒãƒ¼ãƒˆ
	- https://docs.llamaindex.ai/en/latest/examples/llm/anthropic.html
	- Like Gemini and Mistral's latest offerings, Claude 3 comes in 3 "flavors" with the largest, Claude Opus, claiming better performance than GPT-4 across a wide range of benchmarks.
- ZETA editing
	- https://huggingface.co/spaces/hilamanor/audioEditing
	- ZEro Shot Audio editing using DDPM inversion
	- Edit Audio with Nothing but Prompts!
- Metaâ€™s AI Watermarking Plan Is Flimsy, at Best Watermarks are too easy to remove to offer any protection against disinformation
	- https://spectrum.ieee.org/meta-ai-watermarks?share_id=8133421&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- Claude3ã®è©•åˆ¤
	- Claude 3 Sonnet ã€ã¨ã«ã‹ãç”ŸæˆãŒæ—©ã„ï¼ï¼ï¼ï¼ï¼
	- https://x.com/izutorishima/status/1764702243520208962?s=20
	- Sonnet ã§ã‚‚ä¸€éƒ¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ GPT-4 ã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã«é”ã—ã¦ã„ã¦ã€ã“ã®é€Ÿã•ã‚’ç„¡æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ä½¿ãˆã‚‹ã®ã¯æ™®é€šã« OpenAI ã•ã‚“ãƒ”ãƒ³ãƒã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿ
	- Claude ãŒè³¢ããªã£ã¦ç›®ã‚‚ã¤ã„ãŸï¼ãƒ¢ãƒ‡ãƒ«ã¯ä¸‰ã¤ã§ã€Haiku / Sonnet / Opus ã®é †ã«è³¢ãã€å€¤æ®µãŒã‚ãŒã‚‹
	- æœ€é«˜æ€§èƒ½ã® Opus ã¯ 10 å€‹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ GPT-4 ã‚’ 10 å€‹ã¨ã‚‚è¶…ãˆã¦ã„ã‚‹ã€‚Haiku ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã¯ã‚¦ã‚§ãƒ–ç‰ˆã§è©¦ã—ã¦ã¿ãŸã‘ã©ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ï¼ˆã“ã“ã§ã¯ç”»åƒå…¥åŠ›ã ã‘ã§ã™ãŒï¼‰ã«ã¤ã„ã¦ã¯ GPT-4-V ã‚ˆã‚Šä¸Šã§ Gemini 1.0 Ultra ã¨åŒç¨‹åº¦ã€‚
	- 200k ãƒˆãƒ¼ã‚¯ãƒ³ã®é•·æ–‡å…¥åŠ›ã¯å¥åœ¨ã§ã€ã•ã‚‰ã«ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ 1 million ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚å…¥åŠ›ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ã€‚ãŸã ã—ã“ã¡ã‚‰ã¯ä¸€éƒ¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã®ã¿æä¾›ã€‚
	- å¤§é‡ã®æ–‡ç« ã®ä¸­ã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠœãå‡ºã›ã‚‹ã‹ã®è©•ä¾¡ã«ç”¨ã„ã‚‹ã€ŒNeedle In A Haystackã€ã§ã¯ã€ç²¾å·§æ€§èƒ½ã® Opus ã‚’ã‚‚ã£ã¦ã™ã‚Œã°ç²¾åº¦ 99% ã‚’é”æˆã€‚ä»Šã¾ã§ã® Claude 2.1 ã¨æ¯”ã¹ã¦ã‚ã¡ã‚ƒã¯ã‚„ã„ã€‚å…¬ç§° 2 å€ã€‚
	- ã¾ãŸã€JSON å‡ºåŠ›ãªã©æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›ãŒå¾—æ„ã«ãªã‚Šã€è‡ªç„¶è¨€èªã«ã‚ˆã‚‹åˆ†é¡ã‚„æ„Ÿæƒ…åˆ†æãªã©ã‚‚ã§ãã‚‹ã‚ˆã†ã«ã€‚ä½¿ã£ã¦ã¿ãŸã®ã§ã™ãŒã€ã‹ãªã‚Šè‰¯ã„æ„Ÿã˜ã«æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã§ãã¾ã—ãŸ
	- API ã¯ç¾æ™‚ç‚¹ã§ Opus ã¨ Sonnet ã¯å…¬é–‹ã€‚Haiku ã¯è¿‘æ—¥å…¬é–‹äºˆå®šã€‚
- ä»Šã¾ã§ ChatGPT ã§æ›¸ã‹ã›ãŸæ–‡æ›¸ã£ã¦ã€Œãã‚Œã£ã½ã•ã€ãŒã‚ã£ãŸã‘ã©ã€Claude 3 ã¯éå¸¸ã«ä¸å¯§ãªæ—¥æœ¬èªã§ã‚‚ã† AI è£½ã‹ã©ã†ã‹ã‚ã‹ã‚‰ã‚“
	- https://x.com/izutorishima/status/1764890317302727114?s=20
- Langchainã®Claude3ã‚µãƒãƒ¼ãƒˆ
	- https://python.langchain.com/docs/integrations/chat/anthropic
- img2table
	- https://github.com/xavctn/img2table
	- ç”»åƒã‹ã‚‰è¡¨ã‚’æŠ½å‡ºã™ã‚‹Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã‚“ã ã‘ã©ã€ã‚ã£ã¡ã‚ƒã„ã„ã€‚ã‚»ãƒ«çµåˆã«ã‚‚å¯¾å¿œã—ã¦ã¦å¤§å¤‰ç´ æ™´ã‚‰ã—ã„
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡ã«ã‚ˆã‚‹TCFDæ¨å¥¨é–‹ç¤ºé …ç›®ã®è‡ªå‹•åˆ¤å®šã€
	- https://www.jpx.co.jp/corporate/research-study/working-paper/Summary_JPXWP_Vol43.pdf
	- GPT-4ã«ã‚ˆã‚Šã€92.8%ã®Accuracyã§ä¸Šå ´ä¼šç¤¾ã®æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¤åˆ¥ã§ãã‚‹ã¨ã„ã†çµæœã«
- gemma-7bãƒ™ãƒ¼ã‚¹ã®æ—¥è‹±ãƒ»è‹±æ—¥ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’QLoRAã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã®å½¢å¼ã§å…¬é–‹ã—ã¾ã—ãŸ
	- https://huggingface.co/webbigdata/C3TR-Adapter
	- ç¿»è¨³ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¤šè¨€èªç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Googleã®Madlad400ã‚„metaã®Seamless m4t v2 largeã€ALMA-Ja-V2 (ç§ã®ä»¥å‰ã®ãƒ¢ãƒ‡ãƒ«)ã‚ˆã‚Šã‚‚å¤§å¹…ã«å„ªã‚Œã¦ãŠã‚Šã€ã‚µãƒ–ã‚«ãƒ«ãƒãƒ£ãƒ¼æ–‡è„ˆã«ä¸€éƒ¨å¯¾å¿œå¯èƒ½ãªäº‹ãŒç‰¹å¾´ã§ã™
- RAGã§ã®å›ç­”ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯é›†ï¼ˆå¿œç”¨ç·¨-Aï¼‰
	- https://zenn.dev/knowledgesense/articles/cec1cd43244524
	- ã€Œå¿œç”¨ç·¨-Aã€ã§ã¯ã€ç‰¹ã«1ã¤ç›®ã®ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å›ç­”ã™ã‚‹ãŸã‚ã«æœ€ã‚‚å¿…è¦ãªï¼ˆæœ€ã‚‚é–¢é€£ã—ã¦ã„ã‚‹ï¼‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç¾¤ã‚’æŠ½å‡ºã™ã‚‹ã€ãŸã‚ã®å…·ä½“çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã«ã¤ã„ã¦è¦‹ã¦ã„ãã¾ã™ã€‚
- Claude 3 Opusã€Danbooru Taggerã®æ©Ÿèƒ½ã‚‚ã‚ã‚‹
	- https://x.com/alfredplpl/status/1764951315636158535?s=20
	- ã‚¢ãƒ‹ãƒ¡ã®è©±ã‚‰ã—ã„
- BASED: Simple linear attention language models balance the recall-throughput tradeoff
	- https://www.together.ai/blog/based
	- Transformerã®24å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’æŒã¤LLM
- Claudeã®æ–‡å­—èµ·ã“ã—ã‚„ã°ã„ãªã€€é ˜åæ›¸ã€å½¢å¼ã‚‚å«ã‚ã¦å®Œç’§ã«èª­ã¿å–ã‚ŒãŸ
	- https://x.com/SuguruKun_ai/status/1764918827769606393?s=20
- Wikipedia ã§é›‘ãªQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸã€‚
	- https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-500k
	- 50ä¸‡ä»¶ä»¥ä¸Šã‚ã‚Šã¾ã™ã€‚Instruction tuningç”¨ã§ã¯æ—¥æœ¬ã§ä¸€ç•ªä»¶æ•°ãŒã‚ã‚‹ã®ã§é©å½“ã«ä½¿ã£ã¦ãã ã•ã„
- é‡æ‘ç·ç ”ã«ã‚ˆã‚‹ç”ŸæˆAIãƒ¬ãƒãƒ¼ãƒˆ
	- https://www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/publication/chitekishisan/2024/01/cs20240104.pdf?la=ja-JP&hash=ED42BFF77381C8AD102B7792B56D2654AD7BC6D5
	- ç”ŸæˆAIã§å½±éŸ¿ã‚’å—ã‘ã‚‹è·ç¨®ã®ãƒªã‚¹ãƒˆãŒè¼‰ã£ã¦ã‚‹ã®ã¯æœ€è¿‘ã‚ˆãè¦‹ã‚‹ã‘ã‚Œã©ã€ä¸€ä½ãŒæ°´æ—é¤¨é£¼è‚²å“¡ãªã®ãŒæ–¬æ–°ã•ã‚’æ„Ÿã˜ãŸã€‚ã‚ã¨ãƒ•ã‚¡ãƒ³ãƒ‰ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒä¸Šä½ã«ã„ã‚‹ã®ã‚‚é¢ç™½ã„
- Claude 3ã®æŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆã«ã‚ˆã‚Œã°ã€å¤§å­¦é™¢ãƒ¬ãƒ™ãƒ«ã®ç‰©ç†å­¦ãƒ»åŒ–å­¦ãƒ»ç”Ÿç‰©å­¦ã®çŸ¥è­˜ã¨æ¨è«–ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸGPQAãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§æœ€é«˜æ€§èƒ½ï¼ˆ0 shot CoTã§50.4%ã€å¤šæ•°æ±ºåˆ©ç”¨ã§59.5%ï¼‰
	- https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf
- Build a Large Language Model (From Scratch)
	- https://github.com/rasbt/LLMs-from-scratch
	- Manningç¤¾ï¼ˆæ—¥æœ¬ã ã¨ã‚ˆãã‚ªãƒ©ã‚¤ãƒªãƒ¼ã®çš®ã‚’è¢«ã‚‹å‡ºç‰ˆç¤¾ï¼‰ã‹ã‚‰ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹æœ¬ãŒå‡ºã‚‹æ¨¡æ§˜ã€‚GitHubã«å…¬é–‹ã‚ã‚Š
- Tokanizer playgroundãŒClaude3ã«å¯¾å¿œ
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- If you want to calculate how many tokens you're sending to the API, check out The Tokenizer Playground, which we recently updated to include the Claude 3 tokenizer!
- Claude 3 is impressively good at OCR and structured extraction
	- https://x.com/jerryjliu0/status/1765101841535336929?s=20
	- We fed it this complex Excalidraw diagram about the Prometheus model - contains subsections, and interleaving text and diagrams
	- Claude 3 is able to provide a summary of each section and also determine the positions of the diagrams!
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/anthropic_multi_modal.ipynb
- Anthropicã®Claude Proã¾ã¨ã‚
	- æœˆé¡$20(USãƒ‰ãƒ«)ã§æœ€é«˜ãƒ¢ãƒ‡ãƒ«ã®Claude Opusã¨ãƒãƒ£ãƒƒãƒˆå‡ºæ¥ã‚‹ã‚µãƒ–ã‚¹ã‚¯ã‚µãƒ¼ãƒ“ã‚¹ 
	- chatGPT ProãŒ40ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸/3æ™‚é–“ã®åˆ¶é™ãŒã‚ã‚‹ã®ã¨åŒæ§˜ã«ä½¿ç”¨é‡åˆ¶é™ã¯ã‚ã‚‹ãŒç›®å®‰ã—ã‹æ˜è¨˜ã•ã‚Œã¦ã„ãªã„ 
	- ç„¡æ–™ç‰ˆã¨æ¯”è¼ƒã—ã¦å°‘ãªãã¨ã‚‚5å€ã®åˆ©ç”¨æ ã€‚çŸ­ã‚ã®(ç´„200å˜èªã®è‹±èªã®æ–‡ç« )ã§ã‚ã‚Œã°8æ™‚é–“ã”ã¨ã«å°‘ãªãã¨ã‚‚100ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡å¯ã¨ã®äº‹ 
	- ç„¡æ–™ç‰ˆã¯1æ—¥ã‚ãŸã‚Šã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ åˆ¶é™ã ãŒã€æœ‰æ–™ç‰ˆã¯8æ™‚é–“æ¯ã«æ ãŒãƒªã‚»ãƒƒãƒˆ 
	- ã€è¯éº—ãªã‚‹ã‚®ãƒ£ãƒ„ãƒ“ãƒ¼ã€ã®ã‚³ãƒ”ãƒ¼ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå ´åˆ(è¨³æ³¨ï¼šãŠãã‚‰ã1MBæœªæº€)8æ™‚é–“ä»¥å†…ã«é€ä¿¡ã§ãã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯20ä»¶ã«ãªã‚‹ã¨ã®äº‹ 
	- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ–‡ç« (doc)ã‹ç”»åƒ(image)ã§æœ€å¤§5ãƒ•ã‚¡ã‚¤ãƒ«å„10MBã¾ã§ ãƒ»zipã¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ããªã„ã®ã§ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ä¸€å¼ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æã¿ãŸã„ãªäº‹ã¯é›£ã—ãã† 
	- 2023å¹´8æœˆã¾ã§ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹
	- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯Claude Proã«å…¥åŠ›ã•ã‚ŒãŸä¼šè©±ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã•ã‚Œãªã„(è¦ªæŒ‡ã‚¢ãƒƒãƒ—/ãƒ€ã‚¦ãƒ³æ©Ÿèƒ½ã‚’é€šã˜ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã™ã‚‹ã¨ä½¿ã‚ã‚Œã‚‹) 
	- ç„¡æ–™ç‰ˆã«ã¤ã„ã¦ã¯å¾®å¦™ãªæ›¸ãæ–¹ãªã®ã§è‰¯ãåˆ†ã‹ã‚‰ãªã„(å½“ç¤¾ã®æ¶ˆè²»è€…ã‚µãƒ¼ãƒ“ã‚¹ã¾ãŸã¯ãƒ™ãƒ¼ã‚¿/è©•ä¾¡ã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€å½“ç¤¾ã¯ã€ãŠå®¢æ§˜ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ä¼šè©±ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ˆã‚Šå®‰å…¨ã«ã™ã‚‹ãŸã‚ã®åˆ©ç”¨è¦ç´„ã®ç›£è¦–ã¨å¼·åˆ¶ãªã©ã€ä¿¡é ¼æ€§ã¨å®‰å…¨æ€§ã®ä½œæ¥­ã«é–¢é€£ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€ã¨ã®äº‹) 
	- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸPDFã‚’è¦ç´„ã—ã¦è²°ãŠã†ã¨ã—ãŸã‚‰å‡ºåŠ›ã¯ä¸€æ°—ã«ã•ã‚Œãšã€Œç¶šãã‚’ã€ã¨ä¿ƒã™å¿…è¦ãŒã‚ã£ãŸ
- Claude3ã¯ã‚ˆã„ã€byã€€è½åˆé™½ä¸€
	- Claude 3ã‚’ä½¿ã„ã¾ãã£ã¦ã¿ã¦ï¼Œã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒç§€é€¸ï¼Œæ—¥æœ¬èªæ€§èƒ½ãŒè‰¯ã„ï¼ˆgpt4-0613ã‚‚è‰¯ã„ãŒï¼‰ï¼Œpdfãªã©ã®æ‰±ã„ãŒä¾¿åˆ©ï¼ã“ã®è¾ºã‚Šã™ã§ã«chatGPTã‹ã‚‰ã®ç§»è¡ŒãŒèµ·ã“ã£ã¦ã„ã‚‹ï¼å¿«é©ã™ãã‚‹
	- https://x.com/ochyai/status/1765209291517210816?s=20
- LLMã®èƒ½åŠ›ã«ã¤ã„ã¦èªã‚‹äººé–“ã®æ€è€ƒåŠ›ãŒå•ã‚ã‚Œã¦ã„ã‚‹ã®ã§ã¯ãªã„ã‹ã€€by shi3zã•ã‚“
	- https://x.com/shi3z/status/1765310307994611798?s=20
- Claude 3 Opus structured query agent
	- https://colab.research.google.com/drive/1hkwipueVyi2Jzo58Z8jfdZ_9rSscfGxd
	- How good is AnthropicAI's Claude 3 Opus at being an agent? Pretty darn good! Check out this quick notebook in which Claude answers a complex, multi-source question by reading a PDF table and using the answer to do math on the contents of a CSV!
- Knowledge-Augmented Planning for LLM Agents
	- https://arxiv.org/abs/2403.03101
	- Proposes an approach to enhance the planning capabilities of LLMs through explicit action knowledge.
- å¤§å­¦ãƒ»MetaAIã‹ã‚‰ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ä½æ¸›ã«æœ‰åŠ¹ãªã‚°ãƒ©ãƒ•æ‹¡å¼µã—ãŸRAG"G-Retriever"ã®ææ¡ˆ
	- https://arxiv.org/abs/2402.07630
	- éƒ¨åˆ†ã‚°ãƒ©ãƒ•æŠ½å‡ºã‚’è³é‡‘é›†ã‚Steineræœ¨å•é¡Œ(PCST)ã§è§£ã„ã¦ã„ã‚‹ã€‚
- ã‚¹ã‚¯ã‚·ãƒ§ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ç”Ÿæˆï¼Microsoftã¨DeepMindãŒå…±è‘—ã—ãŸè«–æ–‡
	- https://github.com/NoviScl/Design2Code
	- -The Design2Code benchmark dataset for the task of converting visual design (screenshot) into code implementation, which consists of 484 real-world webpages from C4 (examples shown below).
- Claude3ã®é–‹ç™ºè€…ãŒç¤ºã—ãŸã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚·ãƒ³ãƒ—ãƒ«
	- https://x.com/AmandaAskell/status/1765207842993434880?s=20
- ã¯ã˜ã‚ã¦ã®çµ±è¨ˆçš„å› æœæ¨è«–
	- https://x.com/takehikohayashi/status/1765268689367265668?s=20
	- é–‹å§‹3ãƒšãƒ¼ã‚¸ç›®ã§ã€Œçµ±è¨ˆçš„å› æœæ¨è«–æœ€å¼·è«–ã€ã«ã„ããªã‚Šå†·ã‚„æ°´ã‚’ã¶ã£ã‹ã‘ã‚‹
- Qwen-Agent
	- https://github.com/QwenLM/Qwen-Agent
	- Agent framework and applications built upon Qwen1.5, featuring Function Calling, Code Interpreter, RAG, and Chrome extension
- Yoshua Benjioæ°ã®æ¥æ—¥æ±å¤§è¬›æ¼”
	- https://www.youtube.com/watch?v=8aTkuvbd_jU
	- æ€ã„ã£ãã‚ŠAIã®ã‚‚ãŸã‚‰ã™å£Šæ»…çš„ãªãƒªã‚¹ã‚¯ã‚„ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®è©±ã‚’ã‚³ã‚¢ã«ã—ã¦ã„ã‚‹
- toshi456/llava-bench-in-the-wild-ja
	- multilingual-llava-bench-in-the-wildã®æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã®ç¿»è¨³ãƒŸã‚¹ã‚„æœªç¿»è¨³ã®ãƒ‡ãƒ¼ã‚¿ã‚’DeepL+æ‰‹å‹•ã§ä¿®æ­£ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ 
	- å…ˆæ—¥Turingã•ã‚“ãŒå…¬é–‹ã—ãŸLLaVA-Bench-JA(COCO)ã¨åˆã‚ã›ã¦æ—¥æœ¬èªVLMã®è©•ä¾¡ã«ã”æ´»ç”¨ãã ã•ã„ã€‚
- Claude-3ãŒAIã§åˆã‚ã¦IQ100è¶…ãˆã‚’é”æˆã—ãŸã¨ä¸»å¼µ
	- https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq
	- ã€Œç¾åœ¨ã®æˆé•·ç‡ã‚’å˜ç´”ã«å¤–æŒ¿ã™ã‚‹ã¨ã€4ï½10å¹´å¾Œã«ã¯Claude-6ãŒIQã®è³ªå•ã«ã™ã¹ã¦æ­£è§£ã—ã€èª°ã‚ˆã‚Šã‚‚è³¢ããªã‚‹ã“ã¨ãŒç¤ºå”†ã•ã‚ŒãŸã€
- å¯¾è©±ç³»ã¯ClaudeãŒæŠœãã‚“å‡ºã¦å¼·ã„
	- https://x.com/reasan_mirasan/status/1765513422504890417?s=20
- LangChain Text Splitters
	- https://x.com/LangChainAI/status/1765418125569491233?s=20
	- One of the most popular parts of LangChain is our text splitters - simple yet necessary for any RAG app
-  Large language models surpass human experts in predicting neuroscience results
	- https://arxiv.org/abs/2403.03230
	- ç¥çµŒç§‘å­¦ã®å®Ÿé¨“çµæœã‚’LLM (Llama2ãƒ»Mistralãƒ»Falconãƒ»Galactica) ã§äºˆæ¸¬ã™ã‚‹ç ”ç©¶
	- è«–æ–‡ã‚¢ãƒ–ã‚¹ãƒˆã®èƒŒæ™¯ã¨æ–¹æ³•éƒ¨åˆ†ã‹ã‚‰äºŒæŠã§çµæœã‚’äºˆæƒ³ã™ã‚‹å•é¡Œã‚»ãƒƒãƒˆã€ŒBrainBenchã€ã‚’ä½œã‚Šï¼ŒLLM vs å°‚é–€å®¶ã§æ¯”è¼ƒ
	- åŸºæœ¬çš„ã«å°‚é–€å®¶ã‚ˆã‚ŠLLMãŒå¼·ã„ LoRAã§ç¥çµŒç§‘å­¦ç”¨ã«fine-tuningã™ã‚‹ã¨æ€§èƒ½ãŒã•ã‚‰ã«ä¸ŠãŒã‚‹
- Claude 3 Cookbook by llamaindex
	- https://colab.research.google.com/drive/11HzzDd6fAiH2s8nDjZMRY5nx2Licl_tF?usp=sharing
	- we go through a comprehensive cookbook to show how Claude 3 can be used in a variety of different application use cases with
- GaLoreã£ã¦ã®ã¯äº‹å‰å­¦ç¿’ãŒãƒ¡ãƒƒãƒãƒ£çœãƒ¡ãƒ¢ãƒªã§ã§ãã‚‹ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚‰ã—ã„
	- https://x.com/umiyuki_ai/status/1765927780263633236?s=20
	- VRAM24GBã§7Bãƒ¢ãƒ‡ãƒ«ã®LLMã®äº‹å‰å­¦ç¿’ãŒã§ãã¦ã—ã¾ã†ã‚‰ã—ã„
- Meta announces Teaching Large Language Models to Reason with Reinforcement Learning
	- https://huggingface.co/papers/2403.04642
- WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- At the request of the open source community, we're now releasing a 7B model for offensive and defensive cybersecurity. This can be run locally in most computers with less GPU VRAM.
- ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ãŒã€Œä»•äº‹ã«ã¯ã€GPT-4ã¯è¨€ã†ã»ã©å¤§ã—ã¦ä½¿ãˆãªã„ã‘ã©Claude3ã¯ãã“ãã“ä½¿ãˆã‚‹ã€
	- https://x.com/umiyuki_ai/status/1766284320208212472?s=20
	- ãŸã¶ã‚“ã€https://x.com/yukatan/status/1766610634832306408?s=20
	- ã‚ˆã†ã‚„ã£ã¨claude3ã‚’è©¦ã—ã¾ã—ãŸãŒã€ãŸã—ã‹ã«ã€Œãƒªãƒªãƒ¼ã‚¹èµ·ã“ã—ã€ã«ã¤ã„ã¦ã¯ã€Œãˆã€ç§ã®ä»•äº‹ã‚„ã°ã„ã‹ã‚‚ã€ã¨æ€ã†ãƒ¬ãƒ™ãƒ«ã«è¿‘ã¥ã„ã¦ã„ã‚‹ã€‚
- cyzgab/catch-me-if-you-can
	- https://huggingface.co/spaces/cyzgab/catch-me-if-you-can
	- GroqInc just added support for Gemma 7B. 
	- ãªã‚“ã‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è³ªå•ã«ç­”ãˆã¦ï¼ˆæ‰“éµæ¯ã«äºˆæ¸¬ã—ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ï¼‰
	- ã¾ã•ã«ã€catch me if you canã¨ã¯ã€‚
- ãƒ’ãƒ³ãƒˆãƒ³æ°ã€AIã¯è¨€è‘‰ã‚’ç†è§£ã—ã¦ã„ã‚‹ã¨ã€ã€ã€ï¼ˆæ—¥çµŒï¼‰
	- https://www.nikkei.com/article/DGXZQOGN143CZ0U4A210C2000000/?n_cid=nk_chart_qr
	- ã€Œâ€¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€æˆ‘ã€…ã¨åŒã˜ã‚ˆã†ã«è¨€è‘‰ã‚’ç†è§£ã—ã¦ã„ã‚‹ã¨æ€ã†ã€‚â€¦AIãŒè¨€è‘‰ã‚’ç†è§£ã—ã¦ã„ãªã„ã¨ã„ã†äººã®å¤§åŠã¯ã€äººé–“ãŒã©ã†ç†è§£ã—ã¦ã„ã‚‹ã‹ã¨ã„ã†ç†è«–ã‚’æŒã£ã¦ã„ãªã„ã€
	- ãƒã‚¤ãƒ³ãƒˆ
		- äººé¡å­˜ç¶šã®å±æ©Ÿã‚’ã‚‚ãŸã‚‰ã™æã‚ŒãŒAIã«ã‚ã‚‹  
		- è‡ªå¾‹çš„ã«äººã‚’æ®ºã™ãƒ­ãƒœãƒƒãƒˆå…µå™¨ãŒ10å¹´ä»¥å†…ã«ç™»å ´  
		- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯è„³ã‚ˆã‚ŠåŠ¹ç‡çš„ã«å­¦ç¿’ã§ãã‚‹
- ã€Œçµ±è¨ˆå­¦ã®æ¥µæ„ã€
	- https://www.soshisha.com/book_wadai/books/2692.html
	- æ•°å¼ã¯æœ€å°é™ã€é¢ç™½ã„å®Ÿä¾‹ã¯æº€è¼‰ã€‚çµ±è¨ˆå­¦å…¥é–€æ›¸æœ€æ–°æ±ºå®šç‰ˆ
	- æœ¬æ›¸ã¯ã€å…¥é–€è€…ãŒçŸ¥ã‚‹ã¹ãçµ±è¨ˆå­¦ã®ç¾ä»£çš„è«–ç‚¹ã‚’ç¶²ç¾…ã—ã¦ãŠã‚Šã€ã¾ã•ã«å¾…ã¡æœ›ã¾ã‚ŒãŸã€Œçµ±è¨ˆå­¦å…¥é–€æ›¸æœ€æ–°æ±ºå®šç‰ˆã€ã¨è¨€ãˆã‚‹ã§ã—ã‚‡ã†

## 3/4

ä»Šé€±ã¯ã€1ãƒ“ãƒƒãƒˆLLMã®è¡æ’ƒ!ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ç™ºè¡¨(The Era of 1-bit LLMs)ã€ 70Bã§8.9å€é«˜é€Ÿã¨ã„ã†ã“ã¨ã§ã€å‹æ‰‹å®Ÿè£…ã€è¿½è©¦ã‚‚ç¶šã€…ã€200Mã§ãã‚Œãªã‚Šã«å‹•ãã¨ã„ã†shi3zã•ã‚“ã®è©•ä¾¡ã‚‚ã€shi3zã•ã‚“ã«ã‚ˆã‚‹ã¨ã€ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãªã‚‰å…¨å“¡BitNetè©¦ã—ã¦ã¿ã‚‹ã¹ãã€ã ãã†ã ã€‚å°ã•ãè©¦ã™ã¨ã„ã†æ„å‘³ã§ã¯ã€250Mã®Mixtralã‚’pretrainingã‹ã‚‰finetuningã‚’è©¦ã—ãŸäº‹ä¾‹ã‚‚ã€‚ã¦ã£ãºã‚“ãŒé«˜ã„ã¨ã“ã‚ã«ã‚ã‚‹ã¨å‘¨è¾ºã‚‚æ‹¾ã†ã¨ã“ã‚ãŒãŸãã•ã‚“ã‚ã‚‹ã¨ã„ã†ã€LLMç•Œéšˆã§ã®ãƒˆãƒªã‚¯ãƒ«ãƒ€ã‚¦ãƒ³ç¾è±¡ãŒèµ·ãã¦ã„ã‚‹ã®ã‹ã€‚ã•ã¦ã€å…ˆé€±å…¬é–‹ã•ã‚ŒãŸgemmaã€ollamaã§ã‚µãƒãƒ¼ãƒˆã€ã‚„ã‚Œå‘¨è¾ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ãƒã‚°ãŒå¤šã„ã¨ã‹ã€ã„ã‚„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ä½¿ãˆãŸã¨ã‹ã€ã„ã‚ã„ã‚è©•ä¾¡ãŒã‚ã‚‹ã€2bã®ã»ã†ãŒ7bã‚ˆã‚Šæ€§èƒ½ã‚ˆã„ã¨è¬ã®å ±å‘Šã‚‚ã€ã¡ã‚‡ã£ã¨ãƒªãƒªãƒ¼ã‚¹æ€¥ãã™ããŸã‹ã€‚ä¸€æ–¹Qwenã¯ã€Qwen1.5æœ€é«˜ã¨ã‹ã€ã‚‚ã¯ã‚„Qwen-72Bã§ã„ã„ã®ã§ã¯ãªã„ã®ã‹ã€ã¨ã„ã†è©•ä¾¡ã‚‚å‡ºã¦ã„ã‚‹ãŒã€å®Ÿã¯å‡ºåŠ›ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ˆã†ã«ã¯ä½¿ãˆãªã„ãªã©ã®ç¸›ã‚ŠãŒã‚ã‚‹ã¨ã®ã“ã¨ã€‚ãƒãƒãƒ•ã‚©OBãŒç«‹ã¡ä¸Šã’ãŸã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—starleyã®éŸ³å£°ä¼šè©±å‹ãŠã—ã‚ƒã¹ã‚ŠAIã‚¢ãƒ—ãƒªã€ŒCotomoã€ã€UXã‚’è€ƒãˆã¦ã¡ã‚ƒã‚“ã¨ä½¿ãˆã‚‹å•†å“ã«è½ã¨ã™ã“ã‚€ã“ã¨ã®å¤§åˆ‡ãŒã‚ˆãã‚ã‹ã‚‹ã€‚Mistral Largeã€ã€ŒGemini Proãªã©ã®ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã€ã£ã¦æœ¬å½“ã‹ï¼ŸLLMã«ã¯è‡ªç„¶è¨€èªã‚ˆã‚Šã‚‚æœ€é©ãªå½¢å¼ãŒã‚ã‚‹ã®ã§ã¯ï¼Ÿã¨ã„ã†é‡å¿ƒçš„ãªã€AutoFormï¼ˆã‚ªãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰ã€ã€ãã†ã„ãˆã°å…ˆè¼©ã®ä¸‰ã¤å­ã¡ã‚ƒã‚“ã¯ã€ç‹¬è‡ªã®è¨€èªã§ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¦ã„ãŸã£ã¦è¨€ã£ã¦ãŸãªã€‚æ±å·¥å¤§ã®ã€ã€è«–æ–‡ã®çµè«–ã‚’å­¦ç¿’ã•ã›ãŸã‚‰æ€§èƒ½ãŒä¸‹ãŒã£ãŸã€‚ã€ã¨ã„ã†è©±ã€ã‚¤ãƒ³ãƒˆãƒ­ã®ã»ã†ãŒã‚ˆã„ã¨ã„ã†ã®ã¯ä¸æ€è­°ã ã€‚Î¼Transferã€è»¢ç§»å­¦ç¿’ã®ãƒã‚¤ã‚¯ãƒ­ç‰ˆï¼Ÿå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’ãŠãã‚‰ãåœ§å€’çš„ã«åŠ¹ç‡åŒ–ã§ãã‚‹ã®ã¯ã‚ˆã„ã€‚Gemini 1.5 Proã‚‚ä½¿ãˆã‚‹äººãŒå°‘ã—ãšã¤æ‹¡å¤§ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€æ¥é€±ã‚ãŸã‚Šã¯ã„ã‚ã„ã‚è©•ä¾¡ãŒã§ã‚‹ã‹ã‚‚ã€‚Gemini 1.5 Proã®é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ€§ã‚’åˆ©ç”¨ã—ã€Long-context LLMs ãŒRAGã®ä»£ã‚ã‚Šã«ãªã‚‹ã‹ãªã‚‰ãªã„ã‹ã‚’è©•ä¾¡ã—ã¦é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ™‚ä»£ã®æ–°ã—ã„RAGã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ææ¡ˆã¨ã‹ã‚ã£ãŸã€‚Function Callingã€è‰²ã€…ãªLLMã§ä½¿ãˆã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå‡ºã¦ãã¦ã€å½“ãŸã‚Šå‰ã®æŠ€è¡“ã«ãªã‚Šã¤ã¤ã‚ã‚‹ãªã€‚LlamaParseã®PDFèª­ã¿å–ã‚Šè©•ä¾¡ã¨ã‹ã€RAGã§ã®å›ç­”ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯é›†ã¨ã‹ã€ãã®ã‚ãŸã‚Šã®åœ°é“ãªé€²ã¿ã‚‚ã‚ã£ãŸã€‚ NVIDIAãŒãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ç”¨ã®GPUã‚’æ–°ç™ºè¡¨ã¨ã‹ã€ã¾ã•ã«winner takes allã®ä¸–ç•Œã€‚ã•ã¦æ—¥æœ¬ã®å„ªç§€ãªé ­è„³ã¯ã©ã†ã‚ˆï¼Ÿã¨ã„ã†ã“ã¨ã§å…ˆé€±ã€ãŒã£ã¡ã‚Šãƒãƒ³ãƒ‡ãƒ¼ã§ã€æ±å¤§å‡ºèº«ã®è‹¥è€…ãŒå¤šã„ãƒ™ãƒ³ãƒãƒ£ãƒ¼ã€Œç‡ˆã€ãŒç´¹ä»‹ã•ã‚ŒãŸãŒã€ã‚ã‚Œã£ã¦ã€ã€Œå»ºç¯‰Ã—AIã€ã®ãƒ†ãƒ¼ãƒã§ã€LLMã‚’ãŒã£ã¤ã‚Šæ´»ç”¨ã™ã‚‹ã¨ã„ã†è©±ã€‚è‹¥ã„äººã®æ„è­˜ãŒåŸºç›¤ã¨ã„ã†ã‚ˆã‚Šç¤¾ä¼šå®Ÿè£…ã¨ã„ã†ã‹ãã£ã¡ç³»ã«æµã‚Œã¦ã‚‹ï¼Ÿ

- ç”»åƒç”ŸæˆAIã€å®‰ã„PCã§ã‚‚é«˜é€Ÿã«ã€€è¡æ’ƒã®ã€ŒStable Diffusion WebUI Forgeã€
	- https://weekly.ascii.jp/elem/000/004/185/4185940/
-  Î¼Transfer: å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒã‚¤ãƒ‘ãƒ©æ¢ç´¢ã‚’å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«è»¢ç§»ã—å­¦ç¿’ã‚’åŠ¹ç‡åŒ–ã™ã‚‹
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_pb
	- Î¼Transfer ã¯ã€Î¼P ï¼ˆMaximal Update Parametrizationï¼‰ã¨ã„ã†ç†è«–çš„ã«å°å‡ºã•ã‚ŒãŸ NN ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ã‘ã«ã‚ˆã‚Šå®Ÿç¾ã•ã‚Œã‚‹ã€ã‚µã‚¤ã‚ºã®ç•°ãªã‚‹ NN é–“ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è»¢ç§»ã§ã™ã€‚
	- ï¼ˆçŸ¥ã‚‰ãªã‹ã£ãŸèª­è€…ã«ã¨ã£ã¦ï¼‰å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’ãŠãã‚‰ãåœ§å€’çš„ã«åŠ¹ç‡åŒ–ã§ãã‚‹æ±ç”¨çš„ã‹ã¤ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ã‘ Î¼P ã®å­˜åœ¨ã¨ä½¿ã„æ–¹ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
	- Neural Networks ã«å¯¾ã—ã¦ã‹ãªã‚Šä¸€è²«æ€§ã®ã‚ã‚‹ç†è§£ãŒå¾—ã‚‰ã‚Œãã†ãªæ°—åˆ†ã«ãªã‚‹ã€‚å­¦ç¿’ç‡ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åˆæœŸåŒ–ã®ã‚¹ã‚±ãƒ¼ãƒ«ã«é–¢ã™ã‚‹è©±ãŒãªã‚“ã§ã‚‚ TP/Î¼P ã§å–ã‚Šæ‰±ã†ã¹ãäº‹é …ã«è¦‹ãˆã¦ãã‚‹ã€‚
- ã‚¦ã‚§ãƒ–ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®åŸºæœ¬çš„ãªå‡¦ç†ã‚³ãƒ¼ãƒ‰ã¨èª²é¡Œ
	- https://note.com/kan_hatakeyama/n/n331bda7d77c1?sub_rt=share_pb
		- æ–‡å­—åˆ—ã®æ­£è¦åŒ–ã€€(å¤‰ãªæ–‡å­—ã‚³ãƒ¼ãƒ‰ã‚’æ¶ˆã™)
		- ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã®ã€ä¸è¦ãªæ–‡å­—åˆ—ã®å‰Šé™¤
		- æ©Ÿæ¢°å­¦ç¿’ãƒ™ãƒ¼ã‚¹ã§ã®ã€ä¸è¦ãªæ–‡å­—åˆ—ã®å‰Šé™¤
		- é‡è¤‡ã®å‰Šé™¤
- ã€æœ€å¼·ã«ãªã£ãŸã€‘Googleã®æœ€å¤§1000ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³å…¥åŠ›å¯èƒ½ãªGemini 1.5 ProãŒãƒ¤ãƒã™ãã‚‹ã€‚ã€Šæ¦‚è¦ã€ä»–LLMã¨ã®æ¯”è¼ƒã€ãƒ“ã‚¸ãƒã‚¹ã‚·ãƒ¼ãƒ³ã§ã®æ´»ç”¨æ–¹æ³•5é¸ã‚’å¾¹åº•è§£èª¬ã€‹
	- https://note.com/chaen_channel/n/necaf27db79ae
-  LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens
	- https://arxiv.org/abs/2402.13753
	- It looks like the problem of long contexts in open LLMs is close to being solved.
- â€‹â€è©±ã—ãŸã„ã“ã¨ã‚‚ã€è©±ã›ãªã„ã“ã¨ã‚‚ã€‚â€ éŸ³å£°ä¼šè©±å‹ãŠã—ã‚ƒã¹ã‚ŠAIã‚¢ãƒ—ãƒªã€ŒCotomoã€ã‚’æä¾›é–‹å§‹
	- https://prtimes.jp/main/html/rd/p/000000007.000123714.html
- ãŸãã•ã‚“ã®ãŠå®¢æ§˜ãŒCotomoã¨ãŠã—ã‚ƒã¹ã‚Šã—ã¦ã„ã‚‹ã“ã¨ã§ã€å‹•ä½œãŒä¸å®‰å®šã«ãªã‚‹äº‹è±¡ãŒç™ºç”Ÿã—ã¦ãŠã‚Šã¾ã™
	- https://x.com/starley_jp/status/1761753632788357611?s=20
- Qwen1.5 é€Ÿã„ã—æ—¥æœ¬èªå®Œç’§ã ã—ã™ã”ã„ by shi3z
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ku-nlp/gpt2-large-japanese-char
	- å¼Šç ”ã®huggingfaceãƒªãƒã‚¸ãƒˆãƒªã§ charcter vocabulary ã®æ—¥æœ¬èª gpt2-largeï¼ˆA100 1æšã§è¨“ç·´8ã‹æœˆ!ï¼‰ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ä½•ã‹ã®èˆˆå‘³ã§æ—¥æœ¬èªã®æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®è¨€èªãƒ¢ãƒ‡ãƒ«ãŒæ¬²ã—ã„æ–¹ã¯æ˜¯éä½¿ã£ã¦ã¿ã¦ãã ã•ã„
- ãƒ­ãƒ¼ã‚«ãƒ«ã§æ°—è»½ã«RAGã‚’ä½¿ã£ã¦ä¼šè©±ã™ã‚‹ã“ã¨ãŒç°¡å˜ã™ãã¦ãƒ“ãƒ“ã£ãŸã€‚
	- https://qiita.com/mitsumizo/items/469d79c5e81d9189a9e4
- æ—¥æœ¬ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æƒ…å ±ä¸€è¦§ãƒ»ã¾ã¨ã‚
	- https://github.com/japan-opendata/awesome-japan-opendata
	- PLATEAU AWARD 2023ã§ã‚°ãƒ©ãƒ³ãƒ—ãƒªã‚’å—è³ã—ãŸæ–¹ã®GitHubã‚‰ã—ã„
-  AITuberã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã¯éŸ³å£°é›‘è«‡ã‹ã‚‰å§‹ã¾ã£ãŸ Cotomo
	- https://note.com/o_ob/n/n27edbebf17af?sub_rt=share_h
	- ãƒ»æ•¬æ„ã‚’æŒã£ã¦æ¥ã™ã‚‹  ã€ã€Œè©±ã™ã®æ¥½ã—ã„ã€è¨­å®š ã€éå»ã®ä¼šè©±ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹  ã€ç›¸æ‰‹ã®é€Ÿåº¦ã«åˆã‚ã›ã¦æ—©å£ã«ãªã‚‹  ã€ä¸€åº¦è¨€ã£ãŸè©±ã¯2å›ç›®ã¯æ—©å£  ã€ãŠåˆ¥ã‚Œã‚’åæ®‹æƒœã—ã‚€
- Mistral announces Mistral Large, a new flagship model.
	- https://x.com/omarsar0/status/1762140818654064721?s=20
		- 32K tokens context window
		- has native multilingual capacities
		- strong abilities in reasoning, knowledge, maths, and coding benchmarks
		- function calling and JSON format natively supported
		- available through Microsoft Azure
		- a low-latency model called Mistral Small was also released
- Qwen1.5-72B-Chatã‚’ãŠè©¦ã—ä¸­ã€‚
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
	- ã‚‚ã†å…¨éƒ¨Qwen-72Bã§ã„ã„ã‚“ã˜ã‚ƒãªã„ã‹ãª
	- https://x.com/alfredplpl/status/1762277261435347424?s=20
- Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
	- https://arxiv.org/abs/2402.14848
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…¥åŠ›ãŒé•·ããªã‚‹ã«ã¤ã‚Œã¦ã€æ¨è«–æ€§èƒ½ã«é¡•è‘—ãªä½ä¸‹ãŒè¦‹ã‚‰ã‚Œã‚‹ã“ã¨ãŒç¤ºå”†
	- â– å®Ÿé¨“çµæœ
		- å…¥åŠ›ãŒé•·ããªã‚‹ã¨æ¨è«–ã®ç²¾åº¦ãŒä½ããªã‚‹
		- å¤±æ•—ãƒ¢ãƒ¼ãƒ‰ã¯ä¸»ã«4ã¤ã§ã€å…¥åŠ›ãŒé•·ããªã‚‹ã»ã©é¡•è‘—ã«ãªã‚‹ 
			- 1. å›ç­”æ‹’å¦ 
			- 2. åã£ãŸåˆ¤æ–­ 
			- 3. é ­ã‹ã‚‰ç­”ãˆã‚’è¨€ã†ï¼ˆæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¾¿ã‚‰ãªã„ï¼‰ã€ 
			- 4. å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«ä½¿ã‚ãªã„
- RAGã§ã®å›ç­”ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯é›†ï¼ˆåŸºç¤ç·¨ï¼‰
	- https://zenn.dev/knowledgesense/articles/47de9ead8029ba
- NVIDIAãŒãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ç”¨ã®GPUã‚’æ–°ãŸã«ç™ºè¡¨
	- https://x.com/webbigdata/status/1762645658266468393?s=20
	- RTX 500 GPUã¯4GBã®GPUãƒ¡ãƒ¢ãƒª 
	- RTX 1000 GPUã¯6GBã®GPUãƒ¡ãƒ¢
- LangChainã«ä¾¿åˆ©ãªæ©Ÿèƒ½ãŒèª•ç”Ÿã—ã¦ã¾ã—
	- https://x.com/MLBear2/status/1762623474034790886?s=20
	- Pydanticã§æ§‹é€ ä½“ã‚’å®šç¾©ã—ãŸä¸Šã§ `with_structrured_output` ã‚’å›³ã®ã‚ˆã†ã«ä½¿ãˆã°ã€Function Callingã‚’ç°¡å˜ã«å‘¼ã¹ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ 
	- ChatGPTã ã‘ã§ã¯ãªãã€Geminiãªã©Function Callingã«å¯¾å¿œã™ã‚‹ä»–ã®LLMã§ã‚‚ã‚‚ã¡ã‚ã‚“ä½¿ãˆã‚‹ã¨ã®ã“ã¨ã€‚
- Function Calling Cookbook with Open-source models (LlamaIndex+FIREWORKS)
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/fireworks_cookbook.ipynb
	- Weâ€™re excited to present a series of cookbooks showing you how to use LlamaIndex with Fireworks, including function calling and RAG with FireFunction-v1.
- PDFãŒã‚¹ãƒ«ã‚¹ãƒ«èª­ã‚ã‚‹ï¼è©±é¡Œã®LlamaParseã¨ã¯
	- https://zenn.dev/yokina_kaoto/articles/563f7d75673c2e
	- LlamaParseã¯LlamaIndexã®æ–°ã—ã„è£½å“ã§ã€å†å¸°æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§è¤‡é›‘ãªPDFã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãã‚Œã„ã«æŠ½å‡ºã™ã‚‹ã“ã¨ãŒã§ãã€ã—ã°ã—ã°æ‚©ã¾ã•ã‚Œã‚‹è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚ˆã‚Šæ­£ç¢ºãªè§£æã‚’ç´„æŸã—ã¾ã™
	- LlamaParseã§PDFã‚’ãƒ‘ãƒ¼ã‚¹ã—ã€AstraDBã§**éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿**ã‚’æ¤œç´¢ã™ã‚‹ã“ã¨ã§ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã¨ã®ã“ã¨ã€‚
- æ–°Kaggleã‚³ãƒ³ãƒšï¼š LLMã§ç”Ÿæˆã•ã‚ŒãŸæ–‡ç« ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¾©å…ƒã™ã‚‹ã‚¿ã‚¹ã‚¯
	- https://www.kaggle.com/competitions/llm-prompt-recovery
	- LLMã§ç”Ÿæˆã•ã‚ŒãŸæ–‡ç« ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¾©å…ƒã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚
	- ãƒ‡ãƒ¼ã‚¿ã¯Google Gemmaã§ä½œæˆã€‚è©•ä¾¡ãŒsentence-t5-baseã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ã‚¿ã¨ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãªã®ãŒæ™‚ä»£ã‚’æ„Ÿã˜ã‚‹ã€‚ã‚‚ã†Jaccardã‚¹ã‚³ã‚¢ã¨ã‹ã®æ™‚ä»£ã˜ã‚ƒãªã„ã‚‰ã—ã„
- iOS17.4ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã«OpenAIã®ä½•ã‹ã‚’å«ã‚€éƒ¨åˆ†ãŒè¦‹ã¤ã‹ã£ã¦ã„ã¦ã€ãŠãã‚‰ãæ•°ãƒ¶æœˆä»¥å†…ã«SiriãŒå¼·åŠ›ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¾ã™ã€‚
	- https://x.com/1amageek/status/1762422935376302226?s=20
-  The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
	- https://huggingface.co/papers/2402.17764
	- Microsoft presents The Era of 1-bit LLMs 
	- All Large Language Models are in 1.58 Bits
	- ã“ã‚Œæœ¬å½“ãªã‚‰ã‚¿ã‚¤ãƒˆãƒ«é€šã‚Šç”ŸæˆAIã®æ–°æ™‚ä»£ã‹ã‚‚ã—ã‚Œãªã„
-  1ãƒ“ãƒƒãƒˆLLMã®è¡æ’ƒ! 70Bã§8.9å€é«˜é€Ÿã€€å…¨ã¦ã®æ¨è«–ã‚’åŠ ç®—ã®ã¿ã§!GPUä¸è¦ã«ãªã‚‹å¯èƒ½æ€§ã‚‚ by shi3zã•ï½
	- https://wirelesswire.jp/2024/02/86094/
	- ã„ãšã‚Œã«ã›ã‚ˆã€ã€€ã“ã®è«–æ–‡ãŒæœ¬å½“ã ã¨ã—ãŸã‚‰ã€ã¨ã‚“ã§ã‚‚ãªã„ã“ã¨ãŒèµ·ãã‚‹ã“ã¨ã«ãªã‚‹ã€‚
- MicrosoftãŒã€Œ1ãƒ“ãƒƒãƒˆLLMæ™‚ä»£ã®åˆ°æ¥ã€ã¨ã„ã†è¡æ’ƒçš„ãªã‚¿ã‚¤ãƒˆãƒ«ã§è«–æ–‡ã‚’å…¬é–‹ã—ã€GPUãŒä¸è¦ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã¨ã®è©±ã‚‚å‡ºã¦ãã¦ã„ã‚‹ã®ã§å¾“æ¥ã®æ‰‹æ³•ã¨ã®é•ã„ã‚’ã¾ã¨ã‚ã¾ã—ãŸ
	- https://x.com/webbigdata/status/1763021292696170917?s=20
-  é©šç•°ã®1ãƒ“ãƒƒãƒˆLLMã‚’è©¦ã™ã€‚æœãŸã—ã¦æœ¬å½“ã«å­¦ç¿’ã§ãã‚‹ã®ã‹? by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/n58b0a2252727?sub_rt=share_pb
	- è©¦ã—ãŸã®ã¯ã“ã¡ã‚‰
		- https://github.com/Beomi/BitNet-Transformers/tree/main
	- ãªã‚“ã‹ãã‚Œã£ã½ã„ã“ã¨è¨€ã£ã¦ã‚‹!!!!!!  ã—ã‹ã‚‚å°ã•ã„ã‹ã‚‰å½“ãŸã‚Šå‰ãªã®ã ãŒæ¨è«–ã¯è¶…é€Ÿã„ã®ã§ã‚ã‚‹ã€‚
	- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¯200MBã€‚GBã˜ã‚ƒãªã„ã‚ˆã€‚  åƒ•ã¯å°ã•ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã‚‚å¤§ãã„è¨€èªãƒ¢ãƒ‡ãƒ«ã‚‚ãã“ãã“è§¦ã£ã¦æ¥ãŸæ–¹ã ã¨æ€ã†ãŒã€ã“ã®ã‚µã‚¤ã‚º
- Mixtral 250Mã®pretrainingã‹ã‚‰Instruction Tuningã¾ã§
	- https://zenn.dev/if001/articles/9bb90e0d8c201f
	- MoEã‚’æŒã¤MixtralãŒhuggingface/transformersã§å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ã“ã‚Œã‚’åˆ©ç”¨ã—ã¤ã¤ã€250Mã®å°ã•ã„ã‚µã‚¤ã‚ºã¨ã—ã¦æ—¥æœ¬èªã¨è‹±èªã§pretrainingã€finetuningã‚’è¡Œã„ã¾ã™ã€‚
	- 250Mã®Mixtralã‚’pretrainingã‹ã‚‰finetuningã¾ã§ã‚’è¡Œã„ã¾ã—ãŸã€‚å°ã•ã„ã‚µã‚¤ã‚ºãªã‚Šã«ã†ã£ã™ã‚‰æ—¥æœ¬èªã‚’ç†è§£ã—ã¦ãã†ã€‚å…¥åŠ›ã‹ã‚‰æ­£ç¢ºã«æƒ…å ±ã‚’æŠ½å‡ºã¨ãã‚Œã‚‰ã‚’ä½¿ã£ãŸå‡ºåŠ›ã¯ã•ã™ãŒã«é›£ã—ãã†ã€‚ã‚ã¨ã¯ã€æ¨è«–æ™‚ã®expertã®é¸æŠã®ã•ã‚Œã‹ãŸã‚„åŒã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒã‚’ã—ã¦ã¿ãŸã„ã¨ã“ã‚
- ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãªã‚‰å…¨å“¡BitNetè©¦ã—ã¦ã¿ã‚‹ã¹ã by shi3zã•ã‚“ã€
	- https://github.com/kyegomez/BitNet
- gemma-7bã€è‹±æ—¥ç¿»è¨³ã‚¿ã‚¹ã‚¯ã«é–¢ã—ã¦ã¯å¾®èª¿æ•´ã«æˆåŠŸã™ã‚‹ã¨ç§ã®ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ALMA-7B-Ja-V2ã‚ˆã‚Šä¸€æ®µéšãƒ¬ãƒ™ãƒ«ãŒä¸Šã®æ€§èƒ½ã§ã—ãŸ
	- https://x.com/webbigdata/status/1762791697212375111?s=20
	- å‘¨è¾ºãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«ãƒã‚°ãŒæ®‹ã£ã¦ã„ã¦ã€è‹±èªåœã§ã¯ã‚ãã‚‰ã‚ã‚‹å‹¢ãŒå¤šã„ã¿ãŸã„ã€‚
- LlamaIndexã¨Groqã®çµ±åˆ
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/groq.ipynb
- Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication
	- https://arxiv.org/abs/2402.18439
	- ã€Œè‡ªç„¶è¨€èªã‚’è¶…ãˆã¦ã€ã¨é¡Œã—ã¦ã€LLMã«ã‚¿ã‚¹ã‚¯å®Ÿè¡Œæ™‚ã®æ€è€ƒã‚’äººé–“ã®è‡ªç„¶è¨€èªã¨ã¯ç•°ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¡Œã‚ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã€AutoFormï¼ˆã‚ªãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰ã€ãŒè€ƒæ¡ˆã•ã‚Œã¾ã—ãŸã€‚
	- LLMã®æ€è€ƒã¯å¿…ãšã—ã‚‚äººé–“ã¨åŒã˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«æ²¿ã†å¿…è¦ã¯ãªã„ã€ã¨ã„ã£ãŸçµè«–ã«ãªã‚Šã¾ã™ã€‚LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ã§ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹éš›ã«ã¯ã“ã®æ–¹ãŒåŠ¹ç‡çš„ã‹ã‚‚ã—ã‚Œãªã„ã¨ã®ã“ã¨ã€‚
	- è‡ªç„¶è¨€èªã«å›ºæœ‰ã®æ›–æ˜§ã•ã‚’æ’é™¤ã—ã€æ˜ç¢ºæ€§ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®è§£æ±ºç­–ã«ã¯ã€ã‚ˆã‚Šæ§‹é€ åŒ–ã•ã‚Œã¦ç°¡æ½”ãªã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å½¢å¼ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã¯ã€ã‚³ãƒ¼ãƒ‰ã€æ“¬ä¼¼ã‚³ãƒ¼ãƒ‰ã€JSONã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¡¨ã€è«–ç†æ¼”ç®—å­ã€ã¾ãŸã¯æ•°å­¦æ–¹ç¨‹å¼ãŒå«ã¾ã‚Œã¾ã™ã€‚å›ç­”ã®æœ€å¾Œã«ã¯ã€ã€œã€œã¨ã„ã†å½¢å¼ã§ç­”ãˆã‚’ç¤ºã•ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚ç°¡æ½”ã‹ã¤æ­£ç¢ºã§ã‚ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚
- ChatGPTã¯æ•°å­¦ã‚’è§£ãæ™‚ã«å³å¯†ã«è¨ˆç®—ã™ã‚‹ãŸã‚ã«ADAï¼ˆAdvanced Data Analitics, Code Interpreterï¼‰ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä½¿ç”¨ã™ã‚‹æ§˜ã«å¤‰ã‚ã£ã¦ã¾ã™
	- https://x.com/ai_syacho/status/1763308074503422008?s=20
	- ã—ã‹ã‚‚æ•°å­¦è¨ˆç®—ã®è¨ˆç”»ã‚‚ç«‹ã¦ã‚‹äº‹ãŒã§ãã‚‹ã€‚
- ã‚ªãƒªã‚¸ãƒŠãƒ«ã®BitNetã‚’1.58bã®è«–æ–‡ã«å¾“ã£ã¦3å€¤ã«ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ã—ã¾ã—ãŸ
	- https://github.com/frodo821/BitNet-Transformers
- Beyond Disciplinesã€ŒBeyond Disciplines ï½CRDSãŒæ³¨ç›®ã™ã‚‹ç ”ç©¶é–‹ç™ºã®æ½®æµ2024ï½ã€
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-06.html
	- æ‰€å±çµ„ç¹”ãŒç™ºè¡Œã—ã¦ã„ã‚‹æ•°åå†Šãƒ»è¨ˆæ•°åƒãƒšãƒ¼ã‚¸ã®å ±å‘Šæ›¸ã‚’40ãƒšãƒ¼ã‚¸ãã‚‰ã„ã«åœ§ç¸®ã—ãŸãƒ¬ãƒãƒ¼ãƒˆä½œæˆã«ã‹ã‹ã‚ã‚Šã¾ã—ãŸã€‚
- Qwen1.5-72B æ—¥æœ¬èªèƒ½åŠ›ã‚‚é«˜ãã¦è‰¯ã„ãŒç”Ÿæˆç‰©ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä½œã‚Œãªã„è¦ç´„ã§æ®‹å¿µã€‚
	- https://x.com/alexweberk/status/1763905106674954324?s=20
- ã€è«–æ–‡ã®çµè«–ã‚’å­¦ç¿’ã•ã›ãŸã‚‰æ€§èƒ½ãŒä¸‹ãŒã£ãŸã€‚ã€
	- https://newswitch.jp/p/40657
	- ï¼–ä¸‡ï¼•ï¼ï¼ï¼å ±ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ãŸã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã¯ã€è«–æ–‡ã®è¦ç´„ã‚ˆã‚Šã‚‚ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ãŒæ€§èƒ½å‘ä¸Šã«å½¹ç«‹ã£ãŸã€‚è«–æ–‡ã®çµè«–ã®å­¦ç¿’ã¯ã€æ€§èƒ½é¢ã§ãƒã‚¬ãƒ†ã‚£ãƒ–ã«åƒã„ãŸã€‚å°ã•ãªï¼¬ï¼¬ï¼­ã«ã¨ã£ã¦ã¯çµè«–ã®å†…å®¹ãŒå°‚é–€çš„éããŸå¯èƒ½æ€§ãŒã‚ã‚‹ã€‚å°‚é–€çŸ¥è­˜ã‚’å‚™ãˆãŸï¼¬ï¼¬ï¼­ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®çŸ¥è¦‹ã«ãªã‚‹ã€‚
- ã€è«–æ–‡ä¸å¯§è§£èª¬ã€‘BitNet b1.58ã¨ã¯ä¸€ä½“ä½•è€…ãªã®ã‹
	- https://qiita.com/tech-Mira/items/67dec9c5a5f025d2727a?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- BitNet b1.58ã¯ã€ãã®åã®é€šã‚Šã€å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã€ã€[âˆ’1ã€0ã€1]ã¨ã„ã†3ã¤ã®å€¤ã§ã®å‹•ä½œã‚’å®Ÿç¾ã—ãŸ1bitã®LLMã§ã™ã€‚ã¤ã¾ã‚Šã€è†¨å¤§ãªè¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’å¿…è¦ã¨ã™ã‚‹å¾“æ¥ã®ãƒ¢ãƒ‡ãƒ«ã¨ã¯ç•°ãªã‚Šã€éå¸¸ã«åŠ¹ç‡çš„ã«å‹•ä½œã—ã¾ã™ã€‚åŠ ãˆã¦ã€ã“ã®è¨˜äº‹ã§ç¤ºã•ã‚Œã¦ã„ã‚‹çµæœã§ã¯é©šãã¹ãã“ã¨ã«ã€æ€§èƒ½ã¯å¾“æ¥ã®é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚Šã¾ã™ã€‚
	- BitNet b1.58ã¨FP16 LLaMA LLMã‚’æ§˜ã€…ãªã‚µã‚¤ã‚ºã§æ¯”è¼ƒã—ã¾ã—ãŸã€‚å…¬å¹³ãªæ¯”è¼ƒã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’RedPajamaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§1000å„„ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦äº‹å‰å­¦ç¿’ã—ã¾ã—ãŸã€‚
- Google AI Studio ã§ ã¤ãã‚ˆã¿ã¡ã‚ƒã‚“ã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã«ã‚ˆã‚‹ Gemini ã® ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n8b03a58abb2c?sub_rt=share_h
	- ã€ŒGoogle AI Studioã€ã§ã€Œã¤ãã‚ˆã¿ã¡ã‚ƒã‚“ã®ä¼šè©±ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã«ã‚ˆã‚‹ã€ŒGeminiã€ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã—ãŸã®ã§ã€ã¾ã¨ã‚ã¾ã—ãŸã€‚
-  Towards Long Context RAG by llamaindex
	- https://www.llamaindex.ai/blog/towards-long-context-rag
	- We did a deep dive into Gemini, and consolidated our thinking about long-context LLM benefits, challenges, and new architectures
	- Long-context LLMs will help alleviate the need to do precise chunking and retrieval, and RAG over small sets of documents
	- Long-context LLMs still donâ€™t resolve the issue of RAG over big knowledge bases (present in most organizations/enterprises)
- Gemini 1.5 ProãŒé‚ã«ãã¾ã—ãŸï¼ï¼ï¼ï¼
	- https://x.com/masahirochaen/status/1763639557457899963?s=20
- Googleã®Gemmaã€2Bã®æ–¹ãŒ7Bã‚ˆã‚Šæ€§èƒ½ãŒè‰¯ã„ã¨ã‹ãŠã‹ã—ãªäº‹ãŒå ±å‘Šã•ã‚Œã¦ã„ã‚‹
	- https://x.com/webbigdata/status/1763730996455973098?s=20
	- Jeremyã•ã‚“ã®è¨€ã£ã¦ã„ã‚‹é€šã‚Šã€fine tuningã¯Hugging Faceã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹Transformerså®Ÿè£…ã§ã¯ãªãã¦ã€githubã®google-deepmind/gemmaã‚’å‚è€ƒã«ã—ãŸæ–¹ãŒè‰¯ã„ã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
	- https://x.com/jeremyphoward/status/1763679390968455185?s=20
-  ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆLLMã«å¯¾å¿œã—ãŸRAGã®æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ by npakaã•ã‚“
	- https://note.com/npaka/n/n0b17244bae47?sub_rt=share_h
	- ã€ŒGemini 1.5 Proã€ã®æ©Ÿèƒ½ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ã“ã¨ãŒã§ãã€ãã‚Œã‚’è©¦ã—ã¦ã¿ã‚‹ã“ã¨ã§ã€ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆLLMã‚’é©åˆ‡ã«ä½¿ç”¨ã™ã‚‹ã«ã¯ã€RAGãŒã©ã®ã‚ˆã†ã«é€²åŒ–ã™ã‚‹ã®ã‹ã«ã¤ã„ã¦ã®ã¾ã¨ã‚ã¾ã—ãŸã€‚
	- **Gemini ã¯ç‰¹å®šã®è©³ç´°ã‚’è¦‹äº‹ã«æ€ã„å‡ºã™ã“ã¨ãŒã§ãã‚‹**
	- **Gemini ã¯ç´ æ™´ã‚‰ã—ã„è¦ç´„èƒ½åŠ›ã‚’æŒã¤**
	- **10Mãƒˆãƒ¼ã‚¯ãƒ³ã¯å¤§è¦æ¨¡ãªæ–‡æ›¸ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã¯ååˆ†ã§ã¯ãªã„**
	- **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®ç‚¹ã§é…ã‚Œã¦ã„ã‚‹**
	- RAGã®æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
		- ã€Œ**Small-to-Big Retrieval**ã€
		-  ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¨ã‚³ã‚¹ãƒˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’å®Ÿç¾ã™ã‚‹ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

## 2/26

å…ˆé€±ã€soraã®ç™ºè¡¨ã§å°‘ã—éœã‚“ã Gemini 1.5 pro ã€402ãƒšãƒ¼ã‚¸ã®æ–‡æ›¸ã€44åˆ†é–“ã®æ˜ ç”»ã€10ä¸‡è¡Œã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹æ¨è«–ãªã©ã€ãã®èƒ½åŠ›ã®ä¸€æ—¦ãŒå£é–“è¦‹ã‚Œã¦ããŸã€‚Googleã¯å¼•ãç¶šãGemini 1.5 proãƒ™ãƒ¼ã‚¹ã®OSSã§ã‚ã‚‹Gemma(â€œè²´é‡ãªçŸ³â€ã€ãƒ©ãƒ†ãƒ³èª)ã‚’ãƒªãƒªãƒ¼ã‚¹ã€åŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã§ã‚ã‚Œã°Llama2ã‚„Mistralã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨ã®äº‹ã€‚Gemmaã¯è»½é‡ã§ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€embeddingã®å·¥å¤«ã€å®‰å…¨ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¨å¿…é ˆãƒ„ãƒ¼ãƒ«ã®æä¾›ã€Kera3.0ã‚µãƒãƒ¼ãƒˆãªã©ã€ã‹ãªã‚Šã®é‡ã¨è³ªã®ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã‚¹ã‚¿ãƒƒã‚¯ãŒä¸€æ°—ã«å…¬é–‹ã•ã‚ŒãŸã“ã¨ã«ãªã‚‹ã€‚OSSæˆ¦ç•¥ã¨ã—ã¦ã€å®‰å…¨æ€§ã«é–¢ã™ã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã®å…±å‰µã¨ã„ã†æ„å‘³ã§ã‚‚ã€Metaã®OSSæˆ¦ç•¥ã¨ä¸¸è¢«ã‚Šã€‚æ—©é€Ÿã€é‡å­åŒ–ggufç‰ˆã‚„ã€Kaggleã§Gemmaã‚’ã¤ã‹ã£ãŸã‚³ãƒ³ãƒšã®é–‹å‚¬ã€embeddingã®è§£æï¼ˆæ—¥æœ¬èªèªå½™ã¯è²§å¼±ï¼Ÿï¼‰ã€npakaã•ã‚“ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è©¦è¡Œã€MLXã‚’ä½¿ã£ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ´»å‹•ãŒç››ã‚“ã«ã€‚LPUï¼ˆLanguage Processing Unitï¼‰ã‚’å¼•ã£æã’ã‚‹Groqã€æ¨è«–æ™‚ã®é«˜é€Ÿã•ãŒåŠç«¯ãªã„ã€å°‚ç”¨ãƒãƒƒãƒ—é–‹ç™ºã§ã‚‚æˆ¦ã„ã¯ç¶šãã€æ—¥æœ¬ã®MN-coreæ—©ãï¼llamaindexã‚‚LlamaCloudã¨LlamaParseã‚’ãƒªãƒªãƒ¼ã‚¹ã€ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„å›³è¡¨ãªã©ã®åŸ‹ã‚è¾¼ã¾ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å«ã‚€è¤‡é›‘ãªæ–‡æ›¸ã®ãŸã‚ã®ç‹¬è‡ªã®ãƒ‘ãƒ¼ã‚·ãƒ³ã‚°ã‚„ã€RAGã®æ§‹ç¯‰ãŒã‚ˆã‚Šé«˜æ€§èƒ½ã«ã€ã‹ã¤å®¹æ˜“ã«ãªã£ãŸã€‚æ—¥æœ¬èªLLMã§ã¯ã€ KARAKURI LM (70B)ã®ELYZA-tasks-100ã«ã‚ˆã‚‹æ€§èƒ½è©•ä¾¡ã‚„ã€æ±å·¥å¤§ã¨æ±åŒ—å¤§ã«ã‚ˆã‚‹Kotomambaã®æ§‹ç¯‰ç­‰ã€‚ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã¯ã€BCGXã‹ã‚‰agentkitã®OSSãƒªãƒªãƒ¼ã‚¹ã€DXã®æ‰‹æ®µã¨ã—ã¦ã®AIã¨ã„ã†ã‚·ãƒŠãƒªã‚ªã§ã®ã‚³ãƒ³ã‚µãƒ«ç³»ã®æ–°ãŸãªãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«ã€‚åŸºç¤ç ”ç©¶ã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‹ã‚‰ã€Œæ–°ã—ã„è¨€è‘‰ã®æ¦‚å¿µã€ã‚’å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€FOCUSã€ã‚„ã€Mambaã¨transformerã¨ã®colabã‚’ä½¿ã£ãŸé€Ÿåº¦æ¯”è¼ƒã¨ã‹ã€ãã‚‚ãã‚‚çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã®è§£èª¬ã¨ã‹ã€‚DeepMindã¨CMUã«ã‚ˆã‚‹ã€LLMã‚’ã¤ã‹ã£ãŸæ•°å€¤å›å¸°OmniPredè«–æ–‡ã‚‚é¢ç™½ã„ã€ãã®æ€§èƒ½ã®ç†è«–çš„è§£æãŒå¾…ãŸã‚Œã‚‹ã€‚Stable Diffusion 3ã®ãƒªãƒªãƒ¼ã‚¹ã‚„sentencepiece v0.2.0ãƒªãƒªãƒ¼ã‚¹ãªã©ã®åŸºç›¤ã‚½ãƒ•ãƒˆã®é‡è¦ãªæ›´æ–°ã‚‚é€²ã‚“ã ã€‚

- BCGXã‹ã‚‰ã€agentkit
	- https://agentkit.infra.x.bcg.com/
	- BCG Xã‹ã‚‰å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸAgentã‚’æ¥½ã«ä½œã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯AgentKitãŒOSSã¨ã—ã¦å‡ºã¾ã—ãŸã€œã€‚ Nextjs, FastAPI, Langchainã®ãƒ¢ãƒ€ãƒ³ãªãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒƒã‚¯ã§ã™
-  Hyena Hierarchy: Towards Larger Convolutional Language Models
	- https://speakerdeck.com/hpprc/hyena-hierarchy-towards-larger-convolutional-language-models
	- Hyena Hierarchyã«ã¤ã„ã¦ã€çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰ã®åŸºç¤ã‹ã‚‰è§£èª¬ã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰
- Groqã®LPUã«ã¤ã„ã¦
	- https://x.com/umiyuki_ai/status/1759740311335739784?s=20
	- Groqã¨ã‹è¨€ã†ä¼šç¤¾ã®LPUï¼ˆLanguage Processing Unitï¼‰ã£ã¦æ–°ã—ã„ãƒãƒƒãƒ—ã¯LLMæ¨è«–é€Ÿåº¦ãŒçˆ†é€Ÿãªã‚“ã ã¨ã€‚NVidiaã¨ã‹ã®GPUã¨é•ã£ã¦é«˜å“è³ªãªVRAMãŒè¦ã‚‰ã‚“ã‹ã‚‰ä½ã‚³ã‚¹ãƒˆã‚‰ã—ã„ã€‚70Bã®LLMã‚’å‹•ã‹ã™æ™‚ã«300tpsã¨ã„ã†è¶…çˆ†é€Ÿã§æ¨è«–ã§ãã‚‹ã€‚
	- M3Maxã ã¨6tpsã€RTX4090+PowerInferã ã¨4tpsã—ã‹å‡ºãªã„ã‹ã‚‰50ï½100å€ã®é€Ÿåº¦å·®ã€‚GPUãŒã‚ªãƒ¯ã‚³ãƒ³ã®æ™‚ä»£æ¥ãŸã‹ï¼Ÿ
- The Shift from Models to Compound AI Systems
	- https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/
	- Berkeleyã®äººã€…ã«ã‚ˆã‚‹ã€ã€Œã‚³ãƒ³ãƒ‘ã‚¦ãƒ³ãƒ‰AIã€ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼è¨˜äº‹ã€‚
	- LLMå˜ä½“ã§å‹è² ã™ã‚‹ã‚ˆã‚Šã‚‚ã€LLMã‚’å«ã‚€å„ç¨®AIï¼éAIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦ä½œã‚‹ã€Œã‚³ãƒ³ãƒ‘ã‚¦ãƒ³ãƒ‰AIã€ã®æ–¹ãŒã‚ˆã‚Šè‰¯ã„ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚Šã‚„ã™ã„ã€
- Introducing LlamaCloud  andã€€LlamaParse
	- https://blog.llamaindex.ai/introducing-llamacloud-and-llamaparse-af8cedf9006b
	- Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring **production-grade**  **context-augmentation** to your LLM and RAG applications.
- MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts
	- https://arxiv.org/abs/2401.11403
	- æ©Ÿæ¢°å­¦ç¿’å¿œç”¨ã«ã¯åˆ†å­ã®ç‰©æ€§äºˆæ¸¬ã‹ã‚‰åˆ†é¡ã¾ã§ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ãŒã€LLMã«ã‚ˆã‚Šãã‚Œãã‚Œã®ã‚¿ã‚¹ã‚¯ã”ã¨ã«æœ€é©ãªåˆ†å­è¡¨ç¾ã¸ã¨èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€äºˆæ¸¬æ€§èƒ½ãŒå‘ä¸Šã—ãŸãã†ã§ã™ã€‚
- è¶…é«˜é€Ÿãªå¯¾è©±AIã‚µãƒ¼ãƒ“ã‚¹ã®Groq
	- https://groq.com/
-  Learning to Learn Faster from Human Feedback with Language Model Predictive Control
	- https://huggingface.co/papers/2402.11450
	- Google presents Learning to Learn Faster from Human Feedback with Language Model Predictive Control
- SLANG: New Concept Comprehension of Large Language Models
	- https://arxiv.org/abs/2401.12585
	- GPT-4ãªã©ã«å¯¾ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‹ã‚‰ã€Œæ–°ã—ã„è¨€è‘‰ã®æ¦‚å¿µã€ã‚’å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€FOCUSã€ã‚’ã‚«ãƒªãƒ•ã‚©ãƒ«ãƒ‹ã‚¢å¤§å­¦ãªã©ã®ç ”ç©¶è€…ã‚‰ãŒè€ƒæ¡ˆ
	- â– ãƒ¡ã‚½ãƒƒãƒ‰ 
		- 1. ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰ã¨ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ç›´æ¥å…¥åŠ›ã™ã‚‹ 
		- 2. ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã§éš ã—ã¦ã€æ„å‘³ã‚’è©•ä¾¡ã•ã›ã‚‹ 
		- 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆå›ºæœ‰åè©ã‚„å‡ºæ¥äº‹ãªã©ï¼‰ã‚’å¤‰æ›´ã—ã€ç•°ãªã‚‹ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãŒãƒ•ãƒ¬ãƒ¼ã‚ºã®è§£é‡ˆã«ä¸ãˆã‚‹å½±éŸ¿ã‚’èª¿ã¹ã‚‹ 
		- 4. ä¸Šè¨˜ã®çµæœã€ãƒ¢ãƒ‡ãƒ«ãŒæ–°ã—ã„è¨€è‘‰ã®ç†è§£ã«è‡³ã£ãŸã®ã‹ã‚’è©•ä¾¡ã™ã‚‹ 
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. GPT-4/3.5ã§æ¤œè¨¼ 
		- 2. ãƒ¢ãƒ‡ãƒ«ãŒçŸ¥ã‚‰ãªã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒŸãƒ¼ãƒ ã‚’æ•™ãˆè¾¼ã¾ã›ãŸ 
		- 3. GPT-4ã§88.2%ã€GPT-3.5ã§ã‚‚84.5%ã®æ­£ç¢ºã•ã‚’é”æˆã—ãŸ
-  GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements
	- https://huggingface.co/papers/2402.10963
	- çµæœãƒ™ãƒ¼ã‚¹ã®å ±é…¬ãƒ¢ãƒ‡ãƒ« (ORM) ã‚’ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¦ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã®æ”¹è‰¯ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã¨ã€ã„ãšã‚Œã‹ 1 ã¤ã‚’å€‹åˆ¥ã«ä½¿ç”¨ã—ãŸå ´åˆã‚„ã€3 ã¤ã®ã‚µãƒ³ãƒ—ãƒ« ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ä¸­ã§æœ€ã‚‚å„ªã‚ŒãŸã‚‚ã®ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
- The Tokenizer Playground
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- After watching, if you want to learn more about how different models (e.g., GPT4, Llama, T5, BERT) tokenize text, check out "The Tokenizer Playground": a web-app I built a few months ago with Transformer.js
- Gemini Advancedã§AIã«ã‚ˆã£ã¦ææ¡ˆã•ã‚ŒãŸpythonã‚³ãƒ¼ãƒ‰ã‚’ç›´æ¥å®Ÿè¡Œã—ã¦å‹•ä½œç¢ºèªã§ãã‚‹ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ãŒè¿½åŠ ã•ã‚ŒãŸ
	- https://x.com/webbigdata/status/1760129585994432916?s=20
	- Gemini 1.5 proã§ã€Œgithubã‹ã‚‰ç›´æ¥å…¨ã‚³ãƒ¼ãƒ‰ã¨å…¨issuesã‚’å–å¾—ã•ã›ã‚‹äº‹ã€ã¨ã€Œæœ€ã‚‚ç·Šæ€¥åº¦ã®é«˜ã„issuesã‚’ç‰¹å®šã—ã€ä¿®æ­£ã‚’å®Ÿè£…ã•ã›ã‚‹äº‹ã€ãŒå‡ºæ¥ãŸ
- Kotomamba: mamba-2.8B å­¦ç¿’çŸ¥è¦‹
	- https://zenn.dev/kotoba_tech/articles/f15b2495d44c4f
	- Kotoba Technologiesã¯NLPã¨åˆ†æ•£ä¸¦åˆ—å­¦ç¿’ã«é–¢ã™ã‚‹æŠ€è¡“ã‚’ç”¨ã„ã¦ã€æ—¥æœ¬åŠã³éè‹±èªåœã«ãŠã‘ã‚‹LLMã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®å®Ÿé‹ç”¨ã«å‘ã‘ãŸç ”ç©¶é–‹ç™ºã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
	- from scratchã‹ã‚‰æ—¥æœ¬èªã¨è‹±èªã®ã‚³ãƒ¼ãƒ‘ã‚¹ã«ã¦å­¦ç¿’ã‚’è¡Œã£ãŸkotomamba-2.8B-v1.0ã€
	- ã‚‚ã†ï¼‘ã¤ã¯state-spaces/mamba-2.8b-slimpjã‹ã‚‰æ—¥æœ¬èªã¨è‹±èªã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’è¡Œã£ãŸkotomamba-2.8b-CL-v1.0ã§ã™ã€‚
- sentencepiece v0.2.0
	- https://github.com/google/sentencepiece/releases/tag/v0.2.0
- Gemini 1.5 Proã®Youtubeï¼“æœ¬ã‚»ãƒƒãƒˆ
	- Reasoning across a 402-page transcript
	- https://www.youtube.com/watch?v=LHKL_210CcU
	- Multimodal prompting with a 44-minute movie
	- https://www.youtube.com/watch?v=wa0MT8OwHuk
	- Problem solving across 100,633 lines of code
	- https://www.youtube.com/watch?v=SSnsmqIj1MI
- KARAKURI LM ã‚’ ELYZA-tasks-100 ã§è©•ä¾¡ã—ã¦ã¿ãŸ
	- https://qiita.com/wayama_ryousuke/items/f4f384b89e9b40a2d794
	- å®Ÿéš›ã«ã©ã®ç¨‹åº¦ã®æ€§èƒ½ãŒã‚ã‚‹ã®ã‹ã€[ELYZA](https://elyza.ai/) ãŒå…¬é–‹ã—ã¦ã„ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ **ELYZA-tasks-100** ã§è©•ä¾¡ã—ã¦ã¿ã¾ã—ãŸã€‚
	- å‰å›è¨˜äº‹ã§æœ€é«˜ã‚¹ã‚³ã‚¢ã‚’ãƒãƒ¼ã‚¯ã—ãŸ Xwin-LM-70B (4bit é‡å­åŒ–) ã‚’ä¸Šå›ã‚Šã€å¹³å‡å¾—ç‚¹2.98ç‚¹ã‚’ãƒãƒ¼ã‚¯ã—ã¦**1ä½**ã¨ãªã‚Šã¾ã—ãŸã€‚
	- æ—¥æœ¬ç™ºã® 70B ãƒ¢ãƒ‡ãƒ«ã¯ [Japanese-StableLM](https://huggingface.co/collections/stabilityai/japanese-stable-lm-654063a381a8731a1c0f13cc) ãªã©ã”ãä¸€éƒ¨ã«é™ã‚‰ã‚Œã€ELYZA-tasks-100 ã§ã®å¹³å‡ã‚¹ã‚³ã‚¢ã‚‚æµ·å¤–ãƒ¢ãƒ‡ãƒ«ãŒå„ªä½ã«ç«‹ã£ã¦ã„ã‚‹çŠ¶æ³ã§ã—ãŸã€‚  KARAKURI LM ã®å…¬é–‹ã«ã‚ˆã‚Šã€ãã®çŠ¶æ³ãŒå¤§ããå¤‰ã‚ã£ãŸã¨è¨€ãˆãã†ã§ã™ã€‚
- Mambaã‚’å‹•ã‹ã—ã¦é€Ÿåº¦ã‚’transformerã¨æ¯”è¼ƒã™ã‚‹ãƒ¡ãƒ¢
	- https://note.com/kan_hatakeyama/n/na911120f4ffb?sub_rt=share_pb
	- è©±é¡Œã®mambaã‚’colabã§å‹•ã‹ã—ã¦ã¿ã¾ã—ãŸï½¡ åŒç­‰ã‚µã‚¤ã‚ºã®transformerã‚ˆã‚Šã‚‚ï½¤2å€ãã‚‰ã„ã¯æ¨è«–ãŒæ—©ãã†ã§ã™ï½¡
- Googleã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ« Gemma ã®æ¦‚è¦  by npakaã•ã‚“
	- https://note.com/npaka/n/na47e13dae482?sub_rt=share_h
	- ã€Œ[**Gemma**](https://ai.google.dev/gemma)ã€ã¯ã€ã€Œ**Gemini**ã€ã¨åŒã˜æŠ€è¡“ã‚’åŸºã«æ§‹ç¯‰ã•ã‚ŒãŸã€è»½é‡ã§æœ€å…ˆç«¯ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«
	- ã€ŒGemma 2Bã€ã€ŒGemma 7Bã€ã®2ã¤ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚¦ã‚§ã‚¤ãƒˆã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã™ã€‚å„ã‚µã‚¤ã‚ºã¯ã€äº‹å‰å­¦ç¿’ãŠã‚ˆã³æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒãƒªã‚¢ãƒ³ãƒˆã§ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã™ã€‚
	- ã€ŒResponsible Generative AI Toolkitã€ã¯ã€ã€ŒGemmaã€ã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šå®‰å…¨ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã¨å¿…é ˆãƒ„ãƒ¼ãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚
	- ã€ŒKeras 3.0ã€ã‚’ä»‹ã—ã¦ã€JAXã€PyTorchã€TensorFlow ãªã©ã€ã™ã¹ã¦ã®ä¸»è¦ãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã‚ãŸã£ã¦æ¨è«–ã¨æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (SFT) ã®ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’æä¾›ã—ã¦ã„ã¾ã™
	- äº‹å‰å­¦ç¿’ã€æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã€ŒGemmaã€ã¯ã€ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã€ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€Google Cloud ä¸Šã§å®Ÿè¡Œã§ã
	- ã€ŒGemmaã€ã®ãƒªã‚¹ã‚¯ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç†è§£ã—ã¦è»½æ¸›ã™ã‚‹ãŸã‚ã«ã€æ‰‹å‹•ã®ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ åŒ–ã€è‡ªå‹•åŒ–ã•ã‚ŒãŸæ•µå¯¾çš„ãƒ†ã‚¹ãƒˆã€å±é™ºãªã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ©Ÿèƒ½ã®è©•ä¾¡ãªã©ã€å …ç‰¢ãªè©•ä¾¡ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚ 
	- ai.google.dev/gemmaã€ã§ã¯ã€ã€ŒGemmaã€ã®è©³ç´°ã‚„ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ã‚’å‚ç…§ã§ãã¾ã™ã€‚
- Gemma Tokenizer ãŒé¢ç™½ã„
	- https://x.com/AiXsatoshi/status/1760437059066695976?s=20
	- Llama tokenizerã¨å…±é€šç‚¹
		- SentencePieceãƒ™ãƒ¼ã‚¹
		- ãƒã‚¤ãƒˆãƒ¬ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§æœªçŸ¥ãƒˆãƒ¼ã‚¯ãƒ³å¯¾å¿œ
	- é•ã„
		- èªå½™ã‚µã‚¤ã‚º: Gemma 256Kã€Llama 32K 
		- Gemmaã¯`add_dummy_prefix` False â†’ å…ˆé ­ã«ç©ºç™½è¿½åŠ ãªã—ï¼ˆGPTã¨åŒã˜ï¼‰
		- Gemmaã«ã¯ç‰¹åˆ¥ãªtokenå¤šæ•°ï¼ˆä¾‹: HTMLè¦ç´ ã€è¬ï¼‰
- google/gemma-7bã®tokenizerã¯BPEã§vocabã¯256k
	- https://huggingface.co/google/gemma-7b
	- ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠã‚’å«ã‚€vocabã¯7039ä»¶ 
	- äº¬éƒ½ å¤§é˜ª å…µåº« å¥ˆè‰¯ æ»‹è³€ ã¯ã‚ã‚Œã© å’Œæ­Œå±± ã¯ç™»éŒ²ãªã— 
	- ä»–ã§ã¯è¦‹ãªã„ã‚¿ã‚¤ãƒ—ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¤šæ•° ã‚³ãƒ¼ãƒ‰ã‚‚mergeã•ã‚ŒãŸã¦ãƒ›ãƒ¤ãƒ›ãƒ¤
- gemma-7b
	- https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf
	- https://huggingface.co/chat/settings/google/gemma-7b-it
	- Geminiãƒ¢ãƒ‡ãƒ«ã¨åŒæ§˜ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒ‡ãƒ¼ã‚¿ã€å­¦ç¿’ãƒ¬ã‚·ãƒ”ã‚’ä½¿ç”¨ã—ã¦ã€æœ€å¤§6å…†å€‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã§å­¦ç¿’ï¼ˆä¸»ã«è‹±èªï¼‰ã€‚ã‚µã‚¤ã‚ºã¯2ã¤ã§ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒãã‚Œãã‚Œ20å„„å€‹ã¨70å„„å€‹ã€‚TPUv5eã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’
	- æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã«æ—¥æœ¬èªã§ã‚‚ç­”ãˆã¦ãã‚Œã‚‹
	- Hugging Face ã« 2B ã¨ 7Bã®äºŒç¨®é¡ï¼ˆãã‚Œãã‚Œãƒ™ãƒ¼ã‚¹ãƒ»ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ãŒã‚ãŒã£ã¦ã„ã‚‹
	- Context Length ã¯ 8k
	- 4bit ã§æ¨è«–ã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚‚ HF page ã«ãã®ã¾ã¾è¨˜è¼‰ã‚ã‚‹
	- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¯ Gemma license
	- llamaã‚ˆã‚Šç·©ã„ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ãƒªãƒªãƒ¼ã‚¹
	- åŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚µã‚¤ã‚ºã§ã‚ã‚Œã°Llama2ã‚„Mistralã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨ã®äº‹
- kaggleæ–°ã‚³ãƒ³ãƒš Google Gemmaã‚’ä½¿ã£ã¦Data Scienceã®ã‚¿ã‚¹ã‚¯ãŒã©ã®æ§˜ã«è§£ã‘ã‚‹ã‹ã‚’ãƒ‡ãƒ¢ã™ã‚‹ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹Analyticsã‚³ãƒ³ãƒšã€‚
	- https://www.kaggle.com/competitions/data-assistants-with-gemma/
	- LLMå¤§å–œåˆ©ã€‚å„ã‚¿ã‚¹ã‚¯æ¯ã«è³é‡‘$10kã€‚
- gemma-2bã‚’è©¦ã™ by npakaã•ã‚“
	- https://x.com/npaka123/status/1760432810811400204?s=20
	- https://huggingface.co/google/gemma-2b-it
- gemma-7b-it-gguf
	- https://huggingface.co/mmnga/gemma-7b-it-gguf
	- Googleã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹gemma-7b-itã®ggufã‚ã‚Šã¾ã™
	- **ç¾åœ¨é‡å­åŒ–ã•ã‚ŒãŸå‡ºåŠ›ãŒä¸å®‰å®šãªå•é¡ŒãŒã‚ã‚‹ã‚‰ã—ãQ8_0ã‚’æ¨å¥¨ã—ã¾ã™ã€‚**
	- ã”åˆ©ç”¨å‰ã«gemmaåˆ©ç”¨è¦ç´„ã‚’ã”ç¢ºèªä¸‹ã•ã„
- side-by-side comparison of the GPT-4, Gemma, and Llama tokenizer
	- https://x.com/xenovacom/status/1760384978360074460?s=20
	- the Gemma and Llama tokenizers are very similar, with the main difference being vocabulary size. One interesting thing to see is that even with an 8x larger vocabulary (256k vs 32k), Gemma only produces ~13% fewer tokens than Llama.
- Google Colab ã§ Gemma ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™
	- https://note.com/npaka/n/nc55e44e407ff?sub_rt=share_h
	- ä»Šå›ã¯ã€ã”ã–ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—ã¾ã™ã€‚AIãŒã€Œæˆ‘ã€ã‚Šã‚“ãˆã‚‚ã‚“ã¯æ€ã†ã€‚â—¯â—¯ã§ã”ã–ã‚‹ã€‚çŸ¥ã‚‰ã‚“ã‘ã©ã€‚ã€çš„ãªå£èª¿ã«ãªã‚Šã¾ã™
- OmniPred: Language Models as Universal Regressors
	- https://huggingface.co/papers/2402.14547
	- åºƒç¯„ãªå®Ÿé¨“ã«ã‚ˆã‚Šã€æ•°å­¦çš„ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨å€¤ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã®ã¿ã‚’é€šã˜ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒéå¸¸ã«æ­£ç¢ºãªæ•°å€¤å›å¸°ãŒå¯èƒ½ã§ã‚ã‚‹ã“ã¨ãŒå®Ÿè¨¼ã•ã‚Œã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ©Ÿä¼šãŒä¸ãˆã‚‰ã‚Œã‚Œã°ã€è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã«ã‚ãŸã£ã¦ã€å¾“æ¥ã®å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å¤§å¹…ã«ä¸Šå›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping
	- https://huggingface.co/papers/2402.14083
- Stable Diffusion 3ãƒªãƒªãƒ¼ã‚¹
	- https://stability.ai/news/stable-diffusion-3?utm_source=twitter&utm_medium=website&utm_campaign=blog
	- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰15å„„ä»¶ã‚‚å¼¾ã„ãŸã‚‰ã—ã„ã€‚ã™ã”ã„ãª
- Colbert Rerank
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/node_postprocessor/ColbertRerank.ipynb
	- ColBERT  is a great model for reranking. Itâ€™s ~100x faster than BERT-based/cross-encoder models, letting you rerank large amounts of documents without worrying about latency. And of course it does better than standard dense retrieval.
- The prompting guide for Gemma 7B Instruct is live!
	- https://www.promptingguide.ai/models/gemma
-  æœ€æ–°ã® Google Gemma ãƒ¢ãƒ‡ãƒ«ã‚’ MLX ã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
	- https://note.com/alexweberk/n/n96cc4c8ac174?sub_rt=share_h
	- M3 Max 128GB ã§ç´„ 50 åˆ†ã‹ã‹ã‚Šã¾ã—ãŸã€‚npaka ã•ã‚“ã®è¨˜äº‹ã ã¨ 20 åˆ†ã»ã©ã§å®Œäº†ã™ã‚‹ãã†ãªã®ã§ã€ã‚„ã¯ã‚Š NVIDIA A100 ãªã©ã® GPU ã¨æ¯”ã¹ã¦ã—ã¾ã†ã¨æ™‚é–“ãŒã‹ã‹ã£ã¦ã—ã¾ã„ã¾ã™ã­â€¦ã€‚
	- https://gist.github.com/alexweberk/1434c95c05463866491677aac6ce19ba#file-mlx_finetuning_gemma-ipynb
-  Introducing Pebblo â€” Data Visibility & Governance for Gen-AI apps
	- https://medium.com/@sridhar_ramaswamy/introducing-pebblo-data-visibility-governance-for-gen-ai-apps-086ca8a62d10
	- Pebblo enables developers to safely load data and promote their Gen AI app to deployment without worrying about the organizationâ€™s compliance and security requirements. The project identifies semantic topics and entities in the loaded data and summarizes them on the UI or a PDF report.
- 

## 2/19

ä»Šé€±ã¯ã€ãªã‚“ã¨ã„ã£ã¦ã‚‚ã€soraã€soraã€soraã€‚ã“ã‚Œã£ã¦OpenAIãŒæ„å›³ã—ã¦ãƒªãƒªãƒ¼ã‚¹æ™‚æœŸã‚’è¨ˆç®—ã—ã¦ã„ã‚‹æ°—ãŒã™ã‚‹ã€‚Googleã®Gemini 1.5ã®ãƒªãƒªãƒ¼ã‚¹ç›´å¾Œã ã—ã€Metaã®Lecunå…ˆç”ŸãŒã€å½“é¢ã§ããªã„ã¨ã„ã†è¬›æ¼”ã®æ•°æ—¥å¾Œã«å‡ºã™ã¨ã‹ã€OpenAIã¯é…çƒã‚’é¸ã¶ã ã‘ã®æŒã¡çƒã®ã‚¹ãƒˆãƒƒã‚¯ãŒã‚ã‚‹ã¨ã„ã†ã†ã‚ã•ã¯æœ¬å½“ãªã®ã‹ã‚‚ã€‚å¤–éƒ¨ã‹ã‚‰ã®soraã®æŠ€è¡“è§£æã‚‚é€²ã¿ã€æ—¢å­˜ã®æŠ€è¡“ã®çµ„ã¿åˆã‚ã›ã§ã¯ã‚ã‚‹ãŒã€ãã®æ€§èƒ½ãƒ»ç²¾åº¦ã¨ã‚¹ã‚±ãƒ¼ãƒ«ãŒé•ã†ã¨ã¨ã®ã“ã¨ã§ã€ã¤ã¾ã‚Šã€OpenAIãŒåœ§å€’çš„ãªæ¨ªç¶±ç›¸æ’²ã‚’è¦‹ã›ã¤ã‘ãŸã ã‘ã ã£ãŸã€‚soraã®ãŠã‹ã’ã§éœã‚“ã§ã§ã—ã¾ã£ãŸGemini 1.5ã€ãªã‚“ã¨MoEã‚’æ¡ç”¨ã—ã€é•·å¤§ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾å¿œã€RAGã£ã¦ã„ã‚‰ã­ï¼Ÿã¿ãŸã„ãªå‹¢ã„ã ãŒã€ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ã‚¬ãƒ©ãƒãƒ³ã§åˆ©ç”¨ã—ã¦ã‚ˆã„ã‚ã‘ãŒãªã„ã€‚RAGã‚‚Collective RAGã¨ã‹ã€embeddingã®å·¥å¤«ã¨ã‹ã€èª¬æ˜æ€§ã®ã‚ã‚‹ç”ŸæˆAIã®æ–¹å‘ã«é€²ã‚“ã§ã‚‹æ°—ãŒã™ã‚‹ã€‚ä¸€æ–¹Metaã¯LeCunå…ˆç”Ÿã®ã„ã†ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã«è¿‘ããŸã‚ã®V-JEPAï¼ˆå‹•ç”»ã®äºˆæ¸¬ï¼‰ã‚’ç™ºè¡¨ã€‚ã“ã“ã«ãã¦ã€ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒä¸€æ°—ã«ç¾å®Ÿå‘³ãŒå¸¯ã³ã¦ããŸã€‚ãªãœã‹Llamaindexã¨LangchainãŒåŒæ™‚æœŸã«ãã‚Œãã‚Œå¤§ããªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä»£æ›¿ã‚ã‚Šã€è‚¥å¤§åŒ–ã—ã™ããŸã®ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼åŒ–ã—ãŸã¨ã„ã†è©±ã ãŒã€LangChainã«ã¯å¾Œæ–¹äº’æ›æ€§ãŒã‚ã‚‹ã£ã¦æœ¬å½“ï¼ŸLLMã®ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã€ä»Šå¾Œã®ç ”ç©¶ã®é€²ã‚€æ–¹å‘ã‚’æ­£ã—ãè¦‹æ®ãˆã¦ã¦ã‚ˆã„ã€‚å°ã•ã„LLMã¨ã‹Transfomerã«ä»£ã‚ã‚‹æ¬¡ä¸–ä»£ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£(Mambaã¨ã‹ï¼‰ã¨ã‹ã€æœ¬LLMã‚¢ãƒ—ãƒ‡ã§ã‚‚è¿½ã£ã¦ãŸè©±é¡ŒãŒæº€è¼‰ã€ã¾ã‚èª°ãŒè¦‹ã¦ã‚‚ãã†ãªã‚‹ã‚ãªã€‚natureã®ã€ChatGPTã‚’åˆ©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è«–æ–‡ã‚’ç”Ÿæˆã£ã¦ã®ã¯ã€è‡ªåˆ†ãŒã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€ãã†ã„ã†äººã‚„è«–æ–‡ã¨ä¸–ç•Œã§ç«¶äº‰ã—ãªã‘ã‚Œã°ã„ã‘ãªã„ã¨ã„ã†æ„å‘³ã§ã€ç ”ç©¶è€…ãªã‚‰å¿…èª­ã ã‚ã†ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã¯ã€Ollamaã®æ—¥æœ¬èªå‡ºåŠ›ãŒæ”¹è‰¯ã•ã‚ŒãŸã¨ã„ã†ã“ã¨ã§ã€npakaã•ã‚“ã®Elyza-7Bã‚’å‹•ã‹ã—ãŸè¨˜äº‹ã¯ã€æ—¥æœ¬èªã§ãƒ­ãƒ¼ã‚«ãƒ«LLMã—ãŸã„å‹¢ã«ã¯å‚è€ƒã«ãªã‚‹ã ã‚ã†ã€‚å…ƒæœ¨ã•ã‚“ã®åˆ†æã®ã‚ˆã†ã«ã€Transformerãƒ™ãƒ¼ã‚¹ã®æ½œåœ¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ã¤ã‹ã£ãŸLLMã§ã¯ã€è³‡é‡‘ã¨ãƒªã‚½ãƒ¼ã‚¹ã®æˆ¦ã„ãªã®ã§ã€æ¨ªç¶±ç›¸æ’²ã‚’è¦‹ã›ã¤ã‘ã‚‰ã¦æˆ¦é—˜æ„æ¬²ã‚’ããŒã‚Œã‚‹ç™ºè¡¨ãŒå¤šã„ãŒã€ã ã‹ã‚‰ã“ãã€LLMã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ãŒã„ã†ã‚ˆã†ã«ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å¤‰ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã—ã€ãã†ã„ã†äººãŸã¡ãŒå‡ºã¦ãã‚‹ã«é•ã„ãªã„ã€‚æ­©ã¿ã‚’æ­¢ã‚ã‚‹ã‚ã‘ã«ã¯ã„ã‹ãªã„ã€‚

-  LlamaIndex v0.10
	- https://blog.llamaindex.ai/llamaindex-v0-10-838e735948f8
	- https://x.com/llama_index/status/1757121818115322076?s=20
	- our biggest open-source release to date, and a massive step towards production-readiness.
	- Create a core package, split off every integration/template into separate PyPi packages.
	- Refactor LlamaHub to become a central hub of all integrations (WIP)
	- Deprecate ServiceContext: Your dev UX is now way better without this object.
- Chat with RTX from NVIDIA
	- https://x.com/NVIDIAAIDev/status/1757447655674819053?s=20
- Deepreneur-blue-lizard
	- https://huggingface.co/Deepreneur/blue-lizard
	- æ±äº¬å¤§å­¦æ¾å°¾ç ”ç©¶å®¤ç™ºã®AIã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã€æ ªå¼ä¼šç¤¾Deepreneur(ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ¬ãƒŠãƒ¼
	- Metaã®Llama-2-7bã«å¯¾ã—ã¦ã€Wikipediaã‚„æ›¸ç±ç­‰ã®æ—¥æœ¬èªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¿½åŠ äº‹å‰å­¦ç¿’ã¨ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
	- 70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨éå¸¸ã«è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšã€JGLUEï¼ˆæ—¥æœ¬èªã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼‰ã‚’ç”¨ã„ãŸè©•ä¾¡ã§ã¯ã€ChatGPT-3.5ã‚’è¶…ãˆã‚‹ã‚¹ã‚³ã‚¢ãŒç®—å‡ºã•ã‚Œã¦ãŠã‚Šã€å…¬é–‹ã•ã‚Œã¦ã„ã‚‹æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã¯æœ€é«˜æ€§èƒ½ã«ãªã‚Šã¾ã™ã€‚
	-  æ ªå¼ä¼šç¤¾Deepreneurã€ChatGPT-3.5ã‚’ä¸Šå›ã‚‹æ—¥æœ¬èªLLMã€Œblue-lizardã€ã‚’é–‹ç™ºã€‚å„ç¤¾ç‹¬è‡ªã®é«˜ç²¾åº¦ã‚ªãƒ³ãƒ—ãƒ¬å‹ã®LLMã®æ§‹ç¯‰ã‚µãƒ¼ãƒ“ã‚¹ã‚’é–‹å§‹
- ChemLLM: A Chemical LLM
	- https://arxiv.org/abs/2402.06852
	- We don't see too much research around LLMs for science so it's exciting to find this one. 
	- It's a dedicated LLM trained for chemistry-related tasks. Claims to outperform GPT-3.5 on principal tasks such as name conversion, molecular caption, and reactionâ€¦
- Large Language Models: A Survey
	- https://arxiv.org/abs/2402.06196
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã“ã‚Œã¾ã§ã¨ã“ã‚Œã‹ã‚‰ã‚’åŒ…æ‹¬çš„ã«æ•´ç†ã—ãŸã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- â– å°ã•ãã¦åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã™ã‚‹ 
		- å¤§ããªãƒ¢ãƒ‡ãƒ«ã¯é«˜ã‚³ã‚¹ãƒˆã§éåŠ¹ç‡çš„ã§ã‚ã‚‹
		- ãã®ãŸã‚ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã®å°å‹ãƒ¢ãƒ‡ãƒ«ã¸ã®é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹ 
		- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„ã€æ•™å¸«ã‚ã‚Šå­¦ç¿’ã€è’¸ç•™æ³•ãªã©ã®æŠ€è¡“ãŒæ´»ç”¨ã•ã‚Œã‚‹ 
	- â– ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å¤‰ãˆã‚‹ 
		- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®"æ¬¡"ã«é–¢å¿ƒãŒé«˜ã¾ã£ã¦ã„ã‚‹
		- ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã«å¤‰ã‚ã‚‹çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆMambaãªã©ï¼‰ãŒç­†é ­å€™è£œ 
		- æ–°ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹ç‡ã‚ˆãæ‰±ã†ãªã©ã®å„ªä½æ€§ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹ 
	- â– ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã«é€²åŒ–ã•ã›ã‚‹
		- ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€å‹•ç”»ã€éŸ³å£°ãªã©æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã‚’çµ±ä¸€çš„ã«æ‰±ã†ã‚ˆã†ã«ãªã£ã¦ã„ã
		- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å¹…ãŒåºƒãŒã‚‹
		- ã™ã§ã«å„ªç§€ãªãƒ¢ãƒ‡ãƒ«ãŒå‡ºç¾ã—å§‹ã‚ã¦ãŠã‚Šã€ã“ã®æµã‚Œã¯ç¶šã„ã¦ãã ã‚ã† 
	- â– å®Ÿç”¨æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ 
		- LLMã®çŸ­æ‰€ï¼ˆå¹»è¦šãªã©ï¼‰ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚„å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã€RAGãªã©ã§å¯¾å‡¦ã§ãã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šå§‹ã‚ã¦ã„ã‚‹
		- å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã‚’ä»£æ›¿ã—ã¦ã„ãæµã‚ŒãŒèµ·ãã¦ã„ã‚‹
		- å€‹äººã®å¥½ã¿ã«ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã™ã‚‹ã‚ˆã†ãªè¨­è¨ˆãŒäººæ°—ã‚’é›†ã‚ã¦ã„ã‚‹ 
	- â– ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ã‚’å¼·åŒ–ã™ã‚‹
		- æ•µå¯¾çš„æ”»æ’ƒã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å®ˆã‚‹ã®ãŒé‡è¦ã«ãªã£ã¦ã„ã‚‹
		- å€«ç†çš„ãªæ‡¸å¿µã‚„ãƒã‚¤ã‚¢ã‚¹ã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã‚‚æ´»ç™ºåŒ–ã—ã¦ã„ã‚‹ 
		- æ©Ÿå¯†æƒ…å ±ã‚’è²¬ä»»ã‚’æŒã£ã¦æ‰±ã†ã‚ˆã†ã«åŠªåŠ›ã•ã‚Œã¦ã„ã‚‹
- å®Ÿè·µï¼å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« / 1000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¶Šãˆãƒ¢ãƒ‡ãƒ«ã‚’å‹•ã‹ã™ã«ã¯ï¼Ÿ
	- https://zenn.dev/turing_motors/articles/26e1f1be50c0b5
	- BLOOM-1Bã‚’å‹•ã‹ã—ã¦ã¿ã‚‹
		- 10å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ç¨‹åº¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°ã€GPUãƒ¡ãƒ¢ãƒªãŒ12GBä»¥ä¸Šã®GPUã§ã‚ã‚Œã°æ¨è«–ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚Google Colaboratoryã§æä¾›ã•ã‚Œã¦ã„ã‚‹GPUã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§å‹•ã‹ã™ã“ã¨ãŒã§ãã¾ã™
	- BLOOM-176Bã‚’å‹•ã‹ã—ã¦ã¿ã‚‹ï¼Ÿ
		- ã§ã¯å®Ÿéš›1000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¶…ãˆã‚‹BLOOMã‚’å‹•ã‹ã™ã«ã¯ã©ã†ã™ã‚Œã°ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ
		- å˜ç´”ãªè§£æ±ºç­–ã¨ã—ã¦ã€ãã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ãŒä¹—ã‚‹è¨ˆç®—ç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ã‚‚ã—ãã®ãƒ¬ãƒ™ãƒ«ã®ã‚¹ãƒšãƒƒã‚¯ã‚’ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ã®ã‚µãƒ¼ãƒãƒ¼ã§æ•´ãˆã‚‹å ´åˆã¯æ•°åƒä¸‡å††è¦æ¨¡ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ã€‚ã¾ãŸã€AWSã‚„GCPãªã©ã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã§å¤§è¦æ¨¡å®Ÿé¨“ç’°å¢ƒã‚’æ•´ãˆã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚
		- ä¾‹ãˆã°ã€AWSã®EC2 P4dã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚ã‚Œã°8æšã®A100ã®GPUãƒ¡ãƒ¢ãƒªãŒè¨ˆ320GBã¨640GBã®ç’°å¢ƒã‚’1æ™‚é–“ã‚ãŸã‚Š30~40ãƒ‰ãƒ«ç¨‹åº¦ã§æ‰±ã†ã“ã¨ãŒã§ãã¾ã™ã€‚
- RAG FusionãŒæ€ã£ã¦ãŸã‚ˆã‚Šå‡„ãã†
	- https://zenn.dev/ozro/articles/abfdadd0bfdd7a
	- RAG Fusionã¯å˜ãªã‚‹ã€Œæ–°ãŸãªæ‰‹æ³•ã€ã§ã¯ãªãã€Œé©æ–°çš„ãªæ‰‹æ³•ã€ã§ã™ã€‚  
	- RAG Fusionã¯ã€å¾“æ¥ã®æ¤œç´¢æŠ€è¡“ã®åˆ¶ç´„ã‚’å…‹æœã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã«å¯¾ã—ã¦ã‚ˆã‚Šè±Šã‹ã§æ–‡è„ˆã«å³ã—ãŸçµæœã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ã€RAGã€Reciprocal Rank Fusionã€ç”Ÿæˆã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ã‚·ã‚¹ãƒ†ãƒ ã«ãªã£ã¦ã„ã¾ã™ã€‚  
	- ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ¤œç´¢çµæœã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨è¤‡æ•°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªç”Ÿæˆã«ã‚ˆã‚Šã€æ¤œç´¢ã®æ­£ç¢ºæ€§ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„å›³ã¨ã®ä¸€è‡´ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ãŸæ‰‹æ³•ã¨ãªã£ã¦ã„ã¾
- Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning
	- https://huggingface.co/papers/2402.06619
	- åˆè¨ˆã§114è¨€èªã‚’ã‚«ãƒãƒ¼ã™ã‚‹5å„„1300ä¸‡ãƒšã‚¢ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨è£œå®Œæ–‡ã‚’å«ã‚“ã§ãŠã‚Šã€Apache 2.0ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨ã®äº‹
-  LlamaIndex v0.10 ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/nb8acc1f63312?sub_rt=share_h
	- ã€Œ**LlamaIndex v0.10**ã€ã¯ã€éå»æœ€å¤§ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
	- ã€ŒServiceContextã€ã‚’éæ¨å¥¨ã«ã—ã¦ã€ã€ŒLlamaIndexã€ã®é–‹ç™ºè€…ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚
	- æ™‚é–“ãŒçµŒã¤ã«ã¤ã‚Œã¦ã€ã“ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯ä½¿ã„ã«ãããªã‚Šã¾ã—ãŸã€‚ service_context ã‚³ãƒ³ãƒ†ãƒŠå…¨ä½“ã‚’ä»»æ„ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æ¸¡ã™ã¨ã€ã©ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒå®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¨è«–ã™ã‚‹ã®ãŒå›°é›£ã«ãªã‚Šã¾ã—ãŸã€‚ ã™ã¹ã¦ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ OpenAI ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸã„å ´åˆã§ã‚‚ã€ä¸å¿…è¦ã«OpenAIã‚­ãƒ¼ã‚’æŒ‡å®šã™ã‚‹ã‚ˆã†ã«æ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã—ãŸã€‚ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦å…¥åŠ›ã™ã‚‹ã®ã‚‚å¤§å¤‰ã§ã—ãŸ
-  LongMamba
	- https://github.com/jzhang38/LongMamba
	- We present LongMamba, an early exploration of Mamba's **longer context extrapolation ability**. Our #LongMamba manages to retrieve *nearly perfectly* on a window context of 16384
- AutoMathText: A 200GB dataset of mathematical texts open sourced
	- https://huggingface.co/papers/2402.07625
	- Multi-source : arXiv/programming code/web pages  
	- Filtered and processed to adapte Math reasoning  
	- Selected by Qwen 72B
-  ç§‘å­¦è€…ãŒChatGPTã‚’åˆ©ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è«–æ–‡ã‚’ç”Ÿæˆ by nature
	- https://www.natureasia.com/ja-jp/ndigest/v20/n10/%E7%A7%91%E5%AD%A6%E8%80%85%E3%81%8CChatGPT%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8B%E3%82%89%E8%AB%96%E6%96%87%E3%82%92%E7%94%9F%E6%88%90/122873
	- Nature Japanã‹ã‚‰ç”ŸæˆAIã§è«–æ–‡ã‚’æ›¸ã„ãŸéš›ã®å®Ÿè¨¼çµæœã¨é™ç•Œ
	- ãƒ†ã‚¯ãƒ‹ã‚ªãƒ³ãƒ»ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«å·¥ç§‘å¤§å­¦ï¼ˆãƒã‚¤ãƒ•ã‚¡ï¼‰ã®ç”Ÿç‰©å­¦è€…ã§ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã‚ã‚‹Roy Kishonyã‚‰ã¯ç‹¬è‡ªã®è‡ªå¾‹çš„ãªdata to paperã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—æ¤œè¨¼ã€‚
		- 1æ™‚é–“è¶³ã‚‰ãšã§ç ”ç©¶è«–æ–‡ä½œæˆ 
		- æ–‡ç« ã¯æµæš¢ã§æ´å¯Ÿã«å¯Œã‚€
		- å³å¯†ãªãƒ‡ãƒ¼ã‚¿åˆ†æã«ã‚‚åŸºã¥ã ã¨ã—ãŸãŒã€
		- è«–æ–‡ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹è¡¨ç¾ã§èª¤é­”åŒ–ã™ 
		- På€¤ãƒãƒƒã‚­ãƒ³ã‚°ï¼ˆP hackingï¼‰
		- è«–æ–‡ç”ŸæˆãŒç°¡å˜ã«ãªã‚Šè³ªã®æ‚ªã„è«–æ–‡ãŒå¢—åŠ ã™ã‚‹ãƒªã‚¹ã‚¯ ãªã©æ‡¸å¿µç‚¹ã‚’æŒ™ã’ãŸã€‚
- Code-Llama-70B-FW is now available on Poe! H
	- https://x.com/poe_platform/status/1757080840012804511?s=20
-  éŸ³å£°å…¥å‡ºåŠ›ã§LLM on Google Colab
	- https://colab.research.google.com/drive/1WCiUth855jXjzaNh8Ap5lFLEGX8aMtiU
	- ãƒã‚¤ã‚¯å…¥åŠ›â†’éŸ³å£°èªè­˜(Faster Whisper)â†’LLMå›ç­”ç”Ÿæˆ(ELYZA)â†’éŸ³å£°åˆæˆ(Style-Bert-VITS2)â†’å†ç”Ÿ
	- Google Colabã®ç„¡æ–™æ ã§å‹•ã éŸ³å£°èªè­˜(Whisper)â†’LLM(Swallow-13B)â†’éŸ³å£°åˆæˆ(Style-Bert-VITS2) ã‚’ä½œã£ã¦ã¿ã¾ã—ãŸã€‚éŸ³å£°åˆæˆã¯äº‹å‰ã«å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆãŒå¿…è¦ã§ã™ãŒã€æŠ¼ã—ã®ã‚­ãƒ£ãƒ©éŸ³å£°ã¨ä¼šè©±ã§ãã‚‹ã¨æ¥½ã—ã„ã‹ã‚‚ã€‚(LLMã‚’13Bã«ã—ãŸã®ã§å›ç­”ç”Ÿæˆã«1åˆ†ãã‚‰ã„æ›ã‹ã‚Šã¾ã™)
- RAG From Scratch: Query Translation (Multi-Query)
	- https://x.com/LangChainAI/status/1757817056865718432?s=20
-  Masked Audio Generation using a Single Non-Autoregressive Transformer
	- https://arxiv.org/abs/2401.04577?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=thread
	- Researchers at Meta recently shared MAGNeT, a single non-autoregressive transformer model for text-to-music & text-to-sound generation capable of generating audio on-par with the quality of SOTA models â€” at 7x the speed.
	- https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT/?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=video
- Nomic Embed v1.5
	- Nomic Embed v1.5 is out, the first open model with variable-sized Matryoshka embeddings and 8192 context!
	- https://huggingface.co/spaces/Xenova/adaptive-retrieval-web
-  LLM Agents
	- https://www.promptingguide.ai/research/llm-agents
-  Mixtures of Experts Unlock Parameter Scaling for Deep RL
	- https://huggingface.co/papers/2402.08609
	- Google Deepmind presents Mixtures of Experts Unlock Parameter Scaling for Deep RL
-  Google Colabã§ã®æ—¥æœ¬èªMambaã®äº‹å‰å­¦ç¿’
	- https://note.com/hatti8/n/na9782b7fa437?sub_rt=share_pb
	- æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ãŒãªã„ã®ã§ã€æ—¥æœ¬èªMambaã®äº‹å‰å­¦ç¿’ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚Google colabã§å‹•ãã“ã¨ã¯ç¢ºèªã—ãŸã‚‚ã®ã®A100(40B)ã§ã‚‚**15æ™‚é–“è¿‘ãã‹ã‹ã‚‹ã®ã§å®Ÿè³ªæœ€å¾Œã¾ã§ã¯å®Ÿè¡Œã§ããªã„ã§ã™ã€‚**
-  GraphRAG: Unlocking LLM discovery on narrative private data by Microsoft
	- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/
	- Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q&A when analyzing complex information and consistently outperforming baseline RAG
-  In-Context Language Learning: Architectures and Algorithms
	- https://arxiv.org/abs/2401.12973
	- Transformer ã®ä»£æ›¿ã¨ã—ã¦ã® Mamba å«ã‚€ SSMs ã‚„ä»–ã® subquadratic ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ (e.g, RetNet, RKWV) ã‚’ã€Œå…¥åŠ›ã«ä¾å­˜ã—ãŸæ¨è«–ã‚’è¨±ã™ã‹ã€ãƒ»ã€Œç·šå½¢/éç·šå½¢ã‹ã€ã§æ•´ç†ã™ã‚‹ã¨ã‚ã¡ã‚ƒãã¡ã‚ƒè¦‹é€šã—ãŒè‰¯ããªã‚‹ï¼
- OpenAIãŒMicrosoftã¨å¼·åŠ›ã—å›½å®¶é–¢é€£ã®è„…å¨ã‚¢ã‚¯ã‚¿ãƒ¼ã«ã‚ˆã‚‹AIã®æ‚ªæ„ã‚ã‚‹ã‚µã‚¤ãƒãƒ¼æ´»å‹•ã«é–¢ã™ã‚‹åˆ©ç”¨ã‚’ã—ã¦ã„ãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’åœæ­¢ã€‚
	- https://x.com/bioshok3/status/1757834888705945971?s=20
- Open AI å‹•ç”»ç”ŸæˆAI ã€Soraã€ã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://openai.com/sora
	- GoogleãŒåˆ‡ã‚Šæœ­çš„ã«é›»æ’ƒå…¬é–‹ã—ãŸGemini 1.5ã®æ•°æ™‚é–“å¾Œã«ã€OpenAIãŒä¸–ç•Œã®è©±é¡Œã‚’æ»ã£æ”«ã†ãƒ¬ãƒ™ãƒ«ã®å‹•ç”»ç”ŸæˆAIã®Soraã‚’ã¶ã¤ã‘ã¦ããŸ
- META ãŒVideo Joint Embedding Predictive Architecture (V-JEPA) ãƒ¢ãƒ‡ãƒ«ã‚’CC BY-NC ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§ä¸€èˆ¬å…¬é–‹
	- https://x.com/bioshok3/status/1758182170135576590?s=20
	- V-JEPA ã¯ã€æŠ½è±¡è¡¨ç¾ç©ºé–“å†…ã®ãƒ“ãƒ‡ã‚ªã®æ¬ è½éƒ¨åˆ†ã¾ãŸã¯ãƒã‚¹ã‚¯ã•ã‚ŒãŸéƒ¨åˆ†ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å­¦ç¿’ã™ã‚‹éç”Ÿæˆãƒ¢ãƒ‡ãƒ«
-  LangChain v0.1 ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ - Pythonç‰ˆ  by npakaã•ã‚“
	- https://note.com/npaka/n/n1d771995c3aa?sub_rt=share_h
	- **v0.1** ã§ã¯langchainãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ¬¡ã®3ã¤ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«åˆ†å‰²ã•ã‚Œã¾ã—ãŸã€‚ã™ã¹ã¦**ä¸‹ä½äº’æ›æ€§ã®ã‚ã‚‹æ–¹æ³•**ã§è¡Œã‚ã‚Œã¾ã—ãŸ
- è»½é‡ãƒ»é«˜é€Ÿãƒ»é«˜æ€§èƒ½ã¨ä¸‰æ‹å­æƒã£ãŸæ—¥æœ¬èªå¯¾å¿œã®AI(Orion-14B)ã§æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ãƒ¡ãƒ¢
	- https://note.com/kan_hatakeyama/n/n0c58733b39bd?sub_rt=share_pb
	- shi3zã•ã‚“ã®ã€ã€ŒOrion14B-Chatã¨Wikipediaãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ã¦æ—¥æœ¬èªãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸã€ã‚’å‚è€ƒã«ã—ã¦
	- Yahoo!çŸ¥æµè¢‹ã®è³ªç–‘ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã£ã¦ã¿ã¾ã™
		- ã¨ã€ã‚ã‚Šã¨ã„ã„æ„Ÿã˜ã§ã—ãŸã€‚
	- ãƒ­ãƒ¼ã‚«ãƒ«ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€ãã‚Œãªã‚Šã«é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿åˆæˆãŒã§ãã‚‹æ™‚ä»£ãŒã‚„ã£ã¦ããŸã‚ˆã†ã§ã™ã€‚ä»Šå¾Œã¯ã„ã„æ„Ÿã˜ã«(å…¬é–‹)ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã£ã¦ã„ããŸã„ã¨æ€ã„ã¾ã™ã€‚
- Corrective RAG with LangGraph
	- https://github.com/langchain-ai/langgraph/tree/main/examples/rag
	- Weâ€™ve just implemented 4 new notebooks outlining different RAG and CRAG techniques in LangChainAIã€€PY & JS! These show off different RAG flows, using OSS and hosted LLMs. See the links below for the notebooks:
-  ã€Gemini 1.5 Proã€‘100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³å…¥åŠ›ã§ãã‚‹æœ€å¼·LLMã®æ€§èƒ½ã‚’GPT-4ã¨æ¯”è¼ƒã—ã¦ã¿ãŸ
	- https://weel.co.jp/media/gemini-1-5-pro
	- â— æ€§èƒ½ãƒ†ã‚¹ãƒˆã§å…ˆä»£ã®å¤§å‹ãƒ¢ãƒ‡ãƒ«ãƒ»Ultra 1.0ã¨äº’è§’  
		- æ€§èƒ½æ¯”è¼ƒå…¨32é …ç›®ã®ã†ã¡30é …ç›®ã§ã€GPT-4ã«å‹åˆ©
		- ç†æ•°&äººæ–‡å…¨57ç§‘ç›®ã®å•é¡Œé›†ã€ŒMMLUã€ã«ã¦å°‚é–€å®¶ã«å‹åˆ©
	- â— Transformerã®é€²åŒ–ç³»ã€MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ­è¼‰ 
	- â— LLMå²ä¸Šæœ€å¤§ã€100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚ã®å…¥åŠ›ã«å¯¾å¿œ
		- MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã—ãŸçµæœã€Gemini 1.5 Proã§ã¯å…¥åŠ›ã§ãã‚‹ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå¤§å¹…ã«UPï¼ä¸€å›ã«100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®å…¥åŠ›ãŒå®Ÿç¾ã—ã¾ã—ãŸã€‚
- æ•™ç§‘æ›¸ï¼šç¢ºç‡éç¨‹
	- ç¢ºç‡éç¨‹ã«èˆˆå‘³ãŒã‚ã‚‹B4ãƒ»M1ãŒèª­ã‚€ã¹ãæ•™ç§‘æ›¸ã«ã¤ã„ã¦èª¬æ˜ã™ã‚‹ï¼
	- [é€Ÿç¿’ç‰ˆ](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/04/stochasticProcessShort.pdf)
	-  [è©³ç´°ç‰ˆ](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/10/StochasticProcess2023_long.pdf)
- ã€AIå‹•ç”»ç”Ÿæˆã€‘Sora è¦ç´ æŠ€è¡“è§£èª¬
	- https://zenn.dev/mattyamonaca/articles/e234e57834d7ad
	- ã™ã”ãç°¡å˜ã«ã¾ã¨ã‚ã‚‹ã¨ä»¥ä¸‹ã®4ã¤ã®è¦ç´ ãŒä¸»è»¸ã§ã™
		- å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’æ½œåœ¨ç©ºé–“ã«åœ§ç¸®ã—ãŸå¾Œã€TransformerãŒãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦åˆ©ç”¨ã§ãã‚‹ã€Œæ™‚ç©ºæ½œåœ¨ãƒ‘ãƒƒãƒã€ã«å¤‰æ›ã™ã‚‹æŠ€è¡“
		- Transoformerãƒ™ãƒ¼ã‚¹ã®ãƒ“ãƒ‡ã‚ªæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«
		- DALLE3ã‚’ç”¨ã„ãŸé«˜ç²¾åº¦ãªãƒ“ãƒ‡ã‚ªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
	- ã“ã†ã—ã¦è¦ç´ è¦ç´ ã‚’è¦‹ã¦ã„ãã¨ç‰¹æ®µæ–°ã—ã„æŠ€è¡“ã‚’ä½¿ã£ã¦ã„ã‚‹ã‚ã‘ã§ã¯ãªãã€ä»Šã¾ã§æœ‰åŠ¹ã¨ã•ã‚ŒãŸæŠ€è¡“ã‚’æ„šç›´ã«ç©ã¿é‡ã­ã€è«å¤§ãªè³‡æœ¬åŠ›ã¨è¨ˆç®—åŠ›ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚Œã°å¼·ã„ãƒ¢ãƒ‡ãƒ«ãŒä½œã‚Œã‚‹ã¨ã„ã†ã€å½“ãŸã‚Šå‰ã®çµæœãŒè¦‹ãˆã¦ãã¾ã™ã€‚
-  ChatGPTã‚’ç¤¾å†…ã«é…ã£ã¦ã‚‚ã‚ã¾ã‚Šä½¿ã‚ã‚Œãªã„æœ¬å½“ã®ç†ç”±
	- https://qiita.com/jw-automation/items/cf8ffc7a0edab512d917
	- ç¤¾å†…æƒ…å ±ã¨ã„ã†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå¿…è¦ãªæ¥­å‹™ãŒã»ã¨ã‚“ã©ã§ã‚ã‚‹äººé”ã«ã€ç´ ã®ChatGPTã‚’é…ã£ã¦ã‚‚ã€ç‰¹ã«ä½¿ãˆã‚‹æ‰€ãŒãªã„ã¨ã„ã†ã®ã¯ã„ã‚ã°å½“ãŸã‚Šå‰ã®è©±ã§ã™ã€‚
- Build Knowledge Graph From TextData using LangChain
	- https://medium.com/@mahimairaja/build-knowledge-graph-from-textdata-using-langchain-under-2min-ce0d0d0e44e8
	- Converting text to knowledge graphs can be helpful for both visualizing the data and allowing for structured querying later on 
	- This blog goes through how to use LLMs to extract knowledge triplets
-  minbpe
	- https://github.com/karpathy/minbpe
	- Minimal, clean, educational code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization."
-  Video generation models as world simulators by OpenAI
	- https://openai.com/research/video-generation-models-as-world-simulators
	- Soraã¯Transformerãƒ™ãƒ¼ã‚¹ã®æ½œåœ¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã€ãƒ†ã‚­ã‚¹ãƒˆæŒ‡ç¤ºã‹ã‚‰1åˆ†é–“ã®é«˜ç”»è³ªå‹•ç”»ã‚’ç”Ÿæˆã§ãã‚‹ã€‚æ™‚é–“ãƒ»ç©ºé–“ã®ä¸¡æ–¹ã§ä¸€è²«æ€§ã‚’ç¶­æŒã§ãã€ç¾å®Ÿã®ç‰©ç†æ³•å‰‡ã‚’ã‚ã‚‹ç¨‹åº¦åæ˜ ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã«é–¢ã™ã‚‹è©³ç´°ã¯éå…¬é–‹ã ãŒã€å¤§è¦æ¨¡åŒ–ã«ã‚ˆã‚Šæ€§èƒ½ãŒä¸ŠãŒã‚‹æ¨¡æ§˜ã€‚
	- ä»Šå¾Œã‚„ã‚‹ã¹ãäº‹ã¯ãŠãã‚‰ãå˜ç´”ã§ã€å…¨åŠ›ã§OpenAIã‚„Geminiã®æˆé•·ã«ã—ãŒã¿ä»˜ã‘ã°è‰¯ã„ã®ã§ã¯ã€‚ã¨ã„ã†æ°—ãŒã—ã¦ã„ã‚‹ã€‚ by å…ƒæœ¨
	- https://x.com/ai_syacho/status/1758845719988117759?s=20
	- å½¼ã‚‰ã¯æ‹¡æ•£ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã¨ã„ã†ã€ãƒã‚·ãƒ³ã¨æœ­æŸã‚’å…¥ã‚Œã‚Œã°å…¥ã‚Œã‚‹ã»ã©èƒ½åŠ›ã®ä¸ŠãŒã‚‹AIã‚’æŒã£ã¦ã„ã¦ã€ãã®è³‡é‡‘ä½“åŠ›ã‚‚æ®µé•ã„ã€‚â€¦
- iPhoneã«Geminiãã¦ãŸ
	- https://x.com/npaka123/status/1758656487399014521?s=20
	- ?? Advance???
- Ollama ã§ Elyza-7B ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/ndadbae6c6be5?sub_rt=share_h
	- ã€ŒOllamaã€ã®æ—¥æœ¬èªè¡¨ç¤ºãŒæ”¹å–„ã•ã‚ŒãŸã¨ã®ã“ã¨ãªã®ã§ã€ã€ŒElyza-7Bã€ã§è©¦ã—ã¦ã¿ã¾ã—ãŸ
	- Ollamaã®ã‚µã‚¤ãƒˆã«è¼‰ã£ã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã¯ã€è‡ªåˆ†ã§ã€Œ**Modelfile**ã€ã‚’ä½œæˆã—ã¦ã€è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
	- ã€ŒLlama2ã€ã®Manifestã‚’å‚è€ƒã«ã•ã›ã¦ã‚‚ã‚‰ã„ã¾ã™
	- ä»Šå›ã¯ã€ã€Œ**ELYZA-japanese-Llama-2-7b-instruct-q4_K_M.gguf**ã€ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
- Lecunå…ˆç”Ÿã€soarç™ºè¡¨ç›´å‰ã«ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒªã‚¢ãƒ«ãªãƒ“ãƒ‡ã‚ªã‚’ç”Ÿæˆã™ã‚‹ã®ã¯å½“é¢å…ˆã ã¨è¬›æ¼”ã—ãŸã“ã¨ã«å¯¾ã—ã¦è¨€ã„è¨³ã‚’ã€‚ã€‚ã€‚
	- https://x.com/ylecun/status/1758740106955952191?s=20
	- ã„ã‚„ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚’æŒã¤ã®ãŒã‚€ã¤ã‹ã—ã„ã¨ã„ã†ã®ãŒçœŸæ„ã§ã‚ã‚‹ã€‚ã€‚ã€‚
	- ãã£ã¨éã¡ã¯ç¹°ã‚Šè¿”ã™ã€‚
- soraã®ç”Ÿæˆã—ãŸç”»åƒã«ã¤ã„ã¦ã®åˆ†æãŒé€²ã‚€
	- https://x.com/anand_bhattad/status/1758632768597328202?s=20
	- ã“ã„ã¤å°„å½±å¹¾ä½•ã‚ã‹ã£ã¦ãªã„ã‚ˆã­ï¼Ÿ
	- DALE3ã¨åŒã˜ç”»åƒã˜ã‚ƒã‚“ç­‰
- 

## 2/13

ä»Šé€±ã¯ã€ã»ã¼äºˆå®šé€šã‚Šï¼ˆï¼‘æ—¥ãŠãã‚Œï¼Ÿï¼‰BardãŒGeminiï¼ˆã‚¸ã‚§ãƒãƒŠã‚¤ã¨èª­ã‚€ï¼‰ã«æ”¹åã•ã‚ŒãŸã€‚ä¸€æ–¹ã€æ–°ãŸã«Gemini Advancedã¨ã„ã†åå‰ã§Gemini UltraãŒæœ‰å„Ÿã§ã‚¹ã‚¿ãƒ¼ãƒˆã€‚ä½•æ°—ãªã„ãƒ•ã‚¡ãƒŸãƒã®å†™çœŸã‹ã‚‰ç”»åƒã‹ã‚‰èªè­˜ã—ãŸæƒ…å ±ç‰‡ã‚’ã¤ãªã’ã¦åº—èˆ—ã‚’ç‰¹å®šã—ãŸã‚Šã¨ã€ã‚³ãƒŠãƒ³å›ãªã¿ã®æ¨ç†ã‚’ã—ã¦ã„ã‚‹ã®ãŒä½•æ°—ã«ã™ã”ã„ã€‚OSSã®LLMã§ã¯ã€ã‚¢ãƒªãƒãƒã®Qwen1.5ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã®ãŒæœ€å¤§ã®è©±é¡Œã€75B-chatã®ãƒ‡ãƒ¢ãªã©ã§ã‚‚GPT-4ã«è¿«ã‚‹æ€§èƒ½ã‚’ç¤ºã™ã¨è©•åˆ¤ã€Huggingfaceã®ãƒ‡ãƒ¢è©¦ã™ã¨ãŸã—ã‹ã«ãƒ¬ã¹ãƒã‹ã‚‚ã€‚åŸºæœ¬æ€§èƒ½ãŒé«˜ã„ã®ã‹ã€0.5Bã‚’Transfomer.jsã§ä½¿ã£ãŸä¾‹ã§ã‚‚ãã‚Œãªã‚Šã®æ€§èƒ½ãŒã§ã‚‹ã¨ã„ã†è©±ã€‚æ—©é€Ÿã€é‡å­åŒ–ã¨ã‹ã€Ollamaã®å¯¾å¿œãŒç™ºè¡¨ã•ã‚ŒãŸã‚Šã•ã‚Œã¦ã‚‹ã€‚ãŸã¶ã‚“ã€æ—¥æœ¬èªLLMã‚‚rinnaå½“ãŸã‚Šã‹ã‚‰Qwen-1.5ãƒ™ãƒ¼ã‚¹ã®æ—¥æœ¬èªLLMã®ç™ºè¡¨ãŒç¶šãã¨æ€ã†ãã€‚Style-Bert-VITS2ã€ãªã‚“ã¦è‡ªç„¶ãªæ—¥æœ¬èªã‚’è©±ã™ã‚“ã ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è€ƒæ…®ã—ãŸè©±ã—ã£ã·ã‚Šã«ã³ã£ãã‚Šã€ã©ã“ã‹ã®è·æ¥­ãŒä¸¸ã”ã¨ãªããªã‚‹æ€§èƒ½ã ã€‚ Open AIã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã®é–“ã‚’ã¤ãªã„ã§ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºã‚’å®£è¨€ã€ã“ã‚Œã£ã¦AppleScriptã¨ã‹PowerShellã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã¿ãŸã„ãªè©±ã ã‹ã‚‰ã€Microsoftã¨ã‚‚é€£æºã—ã¦ã‚‹ã‚“ã ã‚ã†ã‘ã©ã€RPAï¼ˆã™ã§ã«æ­»èªï¼Ÿï¼‰ã«ã¨ã©ã‚ã‚’åˆºã™ã ã‚ã†ãªã€‚ã€Œå°ã•ãªLLMã€ã€è‹±èªã§ã‚‚"Smaller LLM"ã¨å‘¼ã°ã‚Œã‚‹ã‚‰ã—ã„ã€å°ã•ãªLLMã§ã„ã„ã‚“ã ãªã€LLMã®Largeã¯ãƒ¢ãƒ‡ãƒ«ã®å¤§å°ã§ã¯ãªã„ã¨ã†ã“ã¨ã€è©•ä¾¡ã«ã‚ˆã‚‹ã¨Flan-T5ãŒã¶ã£ã¡ãã‚Šï¼Ÿ MoEé–¢ä¿‚ã§ã¯ã€Mixtral-8x7Bã®æ—¥æœ¬èªå‘ã‘ã®LoRaã¨ã‹ã€MoEã‚’å˜ç´”åŒ–ã—ã¦Expertã®åˆ‡ã‚Šæ›¿ãˆã‚’è©¦ã—ã¦ã¿ã‚‹ä¾‹ã¨ã‹é¢ç™½ã„ã€‚åŸºç›¤é¢ã§ã¯ã€æ¢ç´¢ãªã—ã§Transfomerã ã‘ã§ãƒã‚§ã‚¹ãƒã‚¹ã‚¿ãƒ¼ã‚¯ãƒ©ã‚¹ã®ï¼¡ï¼©ãŒä½œã‚Œã‚‹ã‚‰ã—ã„ã€‚ä¸€æ–¹ã€Transformerã®æ¬¡ä¸–ä»£åŸºç›¤ã®ä¸€ã¤ã¨ã•ã‚Œã‚‹Mambaã€æ—¥æœ¬èªã§ã®è©³ç´°ãªè§£èª¬ã‚„ã€MoEã§ã‚‚ã‚ã‚‹BlackMambaã¨ã‹ã€ã„ã‚ã„ã‚å‡ºã¦ããŸãªã€‚ç†è«–é¢ã§ã¯ã€å²¡é‡ã•ã‚“ã®è§£èª¬ã€The Consensus Gameã€RAGã®æ”¹è‰¯ã‚’ç”ŸæˆAIã¨è­˜åˆ¥AIã®é–“ã®ã‚²ãƒ¼ãƒ ã¨ã—ã¦ã¨ã‚‰ãˆã‚‹ã¨ã¯ã€‚NVIDIAã‚‚è‡ªã‚‰canary-1bã¨ã‹ã€Audio Flamingoã¨ã‹éŸ³å£°ã‚„å¯¾è©±é–¢ä¿‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒªãƒªãƒ¼ã‚¹ã€è‡ªå‹•é‹è»¢ã§ã¯é‹è»¢æ‰‹ã¨ã®å¯¾è©±ãŒå¿…è¦ãªã®ã¯ãã®ã¨ãŠã‚Šãªã‚“ã ã‚ã†ã€‚RAGé–¢ä¿‚ã‚‚ã€Self RAGã¨ã‹ã€Guardrailsã¨ã‹ã€GPT-4ã¨çµ„ã¿ã‚ã›ãŸåŒ»ç™‚åˆ†é‡ã§ã®è©•ä¾¡ã¨ã‹ã„ã‚ã„ã‚é€²ã‚“ã§ã„ã‚‹ãŒã€è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ragas 0.1ãŒã§ãŸã®ã¯å¤§ãã„ã€‚æ—¥æœ¬èªLLMã‚‚ã€æ—¥æœ¬èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´ç†ã‚„ã€ŒLLM-jp 13B v1.1ã€ã®ãƒªãƒªãƒ¼ã‚¹ã¨ã‹ç€å®Ÿã«é€²ã‚“ã§ã„ã‚‹ã®ãŒå¿ƒå¼·ã„ã€ã¯ã‚ˆNEDOã®æˆæœã‚’ï¼ã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã®LLMã®èåˆã€Wikidata ã¨ã‹ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¨ã‹ã€Research Insightã¨ã‹è©±é¡Œã¯ç¶šã„ã¦ã„ã‚‹ã€‚

-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Next to RoBERTa, FLAN-T5 is also a great go-to model for training text classifiers
	- Flan-T5é ‘å¼µã‚‹ãªã‚
-  å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç§‘å­¦çš„ç™ºè¦‹ã«ä¸ãˆã‚‹å½±éŸ¿ï¼šGPT-4ã‚’ç”¨ã„ãŸäºˆå‚™çš„ç ”ç©¶
	- https://ai-scholar.tech/articles/large-language-models/impact_of_LLM
	- GPT-4ã¯ç§‘å­¦çš„ç™ºè¦‹æ´»å‹•ã«ã‚‚å¤§ããå¯„ä¸ã—ã¤ã¤ã‚ã‚Šã¾ã™ã€‚  
	- å‰µè–¬ã€ç”Ÿç‰©å­¦ã€è¨ˆç®—åŒ–å­¦ã€ææ–™è¨­è¨ˆã€åå¾®åˆ†æ–¹ç¨‹å¼ã¨å¹…åºƒãã€GPT-4ã®å¿œç”¨ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ãã‚Œãã‚Œã®å¿œç”¨ã§ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚  
	- ç¾æ™‚ç‚¹ã§ã®GPT-4ã‚’ç”¨ã„ã‚‹ã†ãˆã§ã®ä¸è¶³ç‚¹ã‚’æ•´ç†ã—ã€å°†æ¥ã¸ã®å±•æœ›ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚
	- çŸ¥è¦‹
		- å…¨ä½“çš„ã«è¨€ãˆã°ã€GPT-4ã¯å‰µè–¬ã®å…¨ãƒ—ãƒ­ã‚»ã‚¹ã¨å€‹ã€…ã®ã‚¹ãƒ†ãƒƒãƒ—ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’æŒã£ã¦ã„ã¾ã™ã€‚
		- GPT-4ã¯é€†åˆæˆã®äºˆæ¸¬ç²¾åº¦ãŒ20.
		- GPT-4ãŒå‰µè–¬ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãŸã‚ã®æ­£ã—ã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã®ã«å½¹ç«‹ã¤
		- å®šé‡è¨ˆç®—ï¼š GPT-4ã¯ç”Ÿç‰©å­¦çš„ãªè¨€èªç†è§£ã¨å‡¦ç†ã«å„ªã‚Œã¦ã„ã¾ã™ãŒã€å®šé‡çš„ãªè¨ˆç®—ã«ã¯é™ç•ŒãŒã‚ã‚Šã¾ã™ã€‚ä¿¡é ¼ã§ãã‚‹çµè«–ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€æ‰‹å‹•ã§æ¤œè¨¼ã™ã‚‹ã‹ã€åˆ¥ã®è¨ˆç®—ãƒ„ãƒ¼ãƒ«ã§æ¤œè¨¼ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™
- Qwen2-14Bã®MTBenchãŒ7.99ã§Claude-1è¶…ãˆã¦ã‚‹ã®ã¯ãƒã‚¸ã‚„ã°ã„ by ã†ã¿ã‚†ã
	- https://x.com/umiyuki_ai/status/1754435534511050870?s=20
	- Qwen2ã¨ã—ã¦ã‚¦ãƒ¯ã‚µã«ãªã£ã¦ãŸãƒ¢ãƒ‡ãƒ«ãŒQwen1.5ã¨ã—ã¦ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸï¼Mistral-Mediumã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ï¼ä»Šå›ã¯æœ€åˆã‹ã‚‰Transformerã§ä½¿ãˆã‚‹ä¸Šã«ã€AWQãƒ¢ãƒ‡ãƒ«ã€GPTQãƒ¢ãƒ‡ãƒ«ã€GGUFã‚‚å…¨éƒ¨å…¬å¼ã§æœ€åˆã‹ã‚‰ãƒªãƒªãƒ¼ã‚¹ï¼vLLMã‚„Ollamaã‚‚OKï¼
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- We have finalized our ğ‹ğ‹ğŒğ¬ ğ¨ğ§ ğ†ğ«ğšğ©ğ¡ğ¬ survey by adding more insightful discussions. If you are interested in LLMs on structure data, don't miss this paper (with a resource repo)!
- Home Credit - Credit Risk Model Stability
	- https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/
	- Kaggleæ–°ã‚³ãƒ³ãƒš ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰åˆ©ç”¨è€…ã®å¤–éƒ¨åŠã³å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹é•·æœŸã®è²¸å€’ã‚Œäºˆæ¸¬ã‚¿ã‚¹ã‚¯ã€‚ä¹…æ–¹ã¶ã‚Šã®æ­£çµ±æ´¾ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒš
- Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
	- Nvidia presents Audio Flamingo
	- https://huggingface.co/papers/2402.01831
-  A Survey of Constraint Formulations in Safe Reinforcement Learning
	- https://arxiv.org/abs/2402.02025
	- å¼·åŒ–å­¦ç¿’ã«ãŠã‘ã‚‹å®‰å…¨æ€§åˆ¶ç´„ã®è¨˜è¿°æ–¹æ³•ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã‚’ arXiv ã«ã¦å…¬é–‹ã—ã¾ã—ãŸ ã€‚ä¸»è¦ãªå®šå¼åŒ–ã®ç†è«–çš„ãªé–¢ä¿‚æ€§ã‚’è­°è«–ã—ã¦ã„ã‚‹ã®ãŒé¢ç™½ã„ã¨æ€ã„ã¾ã™
-  BlackMamba: Mixture of Experts for State-Space Models
	- https://huggingface.co/papers/2402.01771
- è‹±å›½AI Safety Instituteã‚ˆã‚Š3rd Progress Repoertã€‚
	- https://www.gov.uk/government/publications/uk-ai-safety-institute-third-progress-report/ai-safety-institute-third-progress-report
	- Google DeepMindã®Geoffrey Irvingæ°ã€Oxfordå¤§ã®ç¥çµŒç§‘å­¦è€…Chris Summerfieldæ°å‚ç”»ã€‚ã‚³ã‚¢KPIã®ã€Œãƒ¡ãƒ³ãƒãƒ¼ã®ã€å…ˆç«¯AIãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹ç´¯ç©çµŒé¨“å¹´æ•°ã€ãŒ11æœˆã®150å¹´ã‹ã‚‰168å¹´ã«å¢—åŠ ã€‚
-  Stable Diffusion WebUI Forge
	- https://github.com/lllyasviel/stable-diffusion-webui-forge
	- Stable-Diffusion-WebUI-Forge is a new platform to 
		- (1) completely solve the speed and VRAM problem and 
		- (2) adding UNet Patcher System to webui so that many new features can be implemented in about 100 lines of codes
-  Unifying Large Language Models and Knowledge Graphs: A Roadmap
	- https://arxiv.org/abs/2306.08302v3
	- ã“ã® Knowledge Graph ã¨LLMã®é–¢ä¿‚ã«ã¤ã„ã¦çºã‚ãŸè«–æ–‡ã™ã”ã„ã€‚ 
	- Knowledge Graphã¨LLMãŒç›¸äº’æˆé•·ã™ã‚‹ä»•çµ„ã¿ãŒéå¸¸ã«åˆ†ã‹ã‚Šã‚„ã™ããƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯åŒ–ã—ã¦çºã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ è«–æ–‡ã¨ã„ã†ã‚ˆã‚Šç¾çŠ¶ã®æ•´ç†ã«è¿‘ã„
-  Wikidata from LangChain
	- https://python.langchain.com/docs/integrations/tools/wikidata
	- WikiData allows you to easily connect to a free and open knowledge base
-  Qwen1.5
	- https://qwenlm.github.io/blog/qwen1.5/
	- https://huggingface.co/collections/Qwen/qwen15-65c0a2f577b1ecb76d786524
	- Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.
- Ollamaã§ã‚‚Qwin1.5ã‚’ã‚µãƒãƒ¼ãƒˆ
	- https://ollama.com/library/qwen
-  Repeat After Me: Transformers are Better than State Space Models at Copying
	- https://arxiv.org/abs/2402.01032
	- Our recent work on the comparison between Transformers and State Space Models for sequence modeling now on arxiv! TLDR - we find a key disadvantage of SSMs compared to Transformers: they cannot copy from their input
-  Self RAG
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/self_rag/self_rag.ipynb
	- Weâ€™re excited to feature Self-RAG, a special RAG technique where an LLM can do self-reflection for dynamic retrieval, critique, and generation
- The Majority of AI Compute Spend is Not on Training but on Inference
	- https://x.com/rohanpaul_ai/status/1754843805507887477?s=20
	- As per report - "2023: The State of Generative AI in the Enterprise"
- Qwen1.5-0.5B-chat with Transformer.js
	- Qwen1.5 is out: a collection of powerful LLMs with sizes ranging from 0.5B to 72B parameters.
	- https://x.com/xenovacom/status/1754873501536645292?s=20
	- Even at 8-bit quantization, the smallest one (0.5B) is surprisingly good for its size! Here's a demo I made with Transformers.js (v2.15), running 100% locally in the browser w/ WASM!
	- https://github.com/xenova/transformers.js	
- Gradio demo of Qwen1.5-72B-Chat
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ollamaã§Mixtralã‚’å‹•ã‹ã—ã¦LangChainã®agentã§ neo4jã™ã‚‹
	- Managed to get Mixtral on @ollama working as an function calling @LangChainAI agent that interacts with @neo4j  through a semantic layer. Needs some tidying up and I'll be able to share it.
	- https://x.com/tb_tomaz/status/1754861855929958488?s=20
- Style-Bert-VITS2ãŒå³åº§ã«æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« JP-Extraã‚’å–ã‚Šè¾¼ã‚“ã§ãã‚Œã¦ã€æ—¥æœ¬èªç™ºéŸ³ãŒã‚¨ã‚°ã„ã§ã™
	- https://github.com/litagin02/Style-Bert-VITS2/releases/tag/2.0
	- ã€ŒStyle-Bert-VITS2ã€ã¯ã€è‡ªå‹•ã§æ–‡è„ˆãŒæŠŠæ¡ã•ã‚Œã€æ„Ÿæƒ…è¡¨ç¾ãŒèª¿æ•´ã•ã‚Œã‚‹
	- https://huggingface.co/spaces/litagin/Style-Bert-VITS2-JVNV
	- ã„ã‚„ã“ã‚Œã¯ã™ã”ã„
- NVIDIAãŒãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼å‘ã‘GPUå¸‚å ´ã§98ï¼…ã®ã‚·ã‚§ã‚¢ã‚’ç‹¬å ã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ¤æ˜ã€AIæ€§èƒ½ãŒæ˜æš—ã‚’åˆ†ã‘ã‚‹çµæœã« - GIGAZINE
	- https://gigazine.net/news/20240205-nvidia-gpu-market/
- ã ã‚ã€‚çµ¶å¯¾ã€‚ by ã‚­ãƒ ãƒ¯ã‚¤ãƒ—
	- https://x.com/kimwipes_crecia/status/1754757418595336404?s=20
-  OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models
	- https://huggingface.co/papers/2402.01739
	- To help the open-source community have a better understanding of Mixture-of-Experts (MoE) based large language models (LLMs), we train and release OpenMoE,
- Development and Testing of Retrieval Augmented Generation in Large Language Models - A Case Study Report
	- https://arxiv.org/abs/2402.01733
	- GPT-4ã«RAGï¼ˆæ¤œç´¢æ‹¡å¼µç”Ÿæˆï¼‰ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€è‡¨åºŠåŒ»å­¦ã®å•é¡Œã«ãŠã„ã¦ã€äººé–“ã®åŒ»å¸«ã‚ˆã‚Šã‚‚é«˜ã„ç²¾åº¦ãŒé”æˆã§ããŸã¨å ±å‘Š
	- é©åˆ‡ãªRAGã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã«ã‚ˆã‚Šã€GPT-4å˜ä½“ã‚ˆã‚Šã‚‚10%ä»¥ä¸Šç²¾åº¦ãŒå‘ä¸Šã—ã€äººé–“åŒ»å¸«ã‚ˆã‚Šã‚‚5%ä»¥ä¸Šé«˜ã„ã‚¹ã‚³ã‚¢ã‚’å‡º
	- ç ”ç©¶è€…ã‚‰ã¯ã“ã®çµæœã¯æ³¨ç›®ã«å€¤ã™ã‚‹ã¨ã—ã¤ã¤ã€ã‚ˆã‚Šåºƒç¯„ãªåˆ†é‡ã§å®Ÿé¨“ã‚’é‡ã­ã¦ã„ãã¹ãã¨ã—ã¦ã„ã¾ã™ã€‚ 
	- ã¾ãŸã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãŒä½ã„ã¨ã¯ã„ãˆã€åŒ»å­¦ã«ãŠã‘ã‚‹è‡ªå‹•åŒ–ã¯æ…é‡ã§ã‚ã‚‹ã¹ãã¨ã‚‚è¿°ã¹ã¦ã„ã¾ã™ã€‚
- Open AI shifts its battleground to Software
	- https://x.com/bioshok3/status/1755376649816953209?s=20
	- Open AIã¯ç¾åœ¨2ç¨®é¡ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆAIã‚’æ§‹ç¯‰ä¸­
	- 1ã¤ã¯ã‚ã‚Šã¨è‡ªç”±ã«ãƒ‡ãƒã‚¤ã‚¹ã‚’æ“ä½œå¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ 
		- é¡§å®¢ã¯ ChatGPT ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã€åˆ†æã®ãŸã‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’è»¢é€ã—ãŸã‚Šã€çµŒè²»å ±å‘Šæ›¸ã‚’è‡ªå‹•çš„ã«è¨˜å…¥ã—ã¦ä¼šè¨ˆã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«å…¥åŠ›ã—ãŸã‚Šã™ã‚‹ã‚ˆã†ä¾é ¼ã§ãã¾ã™
	- ã‚‚ã†ä¸€ã¤ã¯WEBä¸Šã§æ§˜ã€…ãªæ“ä½œå¯èƒ½ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ï¼ˆ1ã¤ç›®ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚„ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ‡¸å¿µã™ã‚‹äººã‚‚ã„ã‚‹ã®ã§ã‚‚ã†ä¸€ã¤ã®ã‚¿ã‚¤ãƒ—ã‚’é–‹ç™ºã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ï¼‰
- Fully local RAG using @Teknium1 OpenHermes, @ollama and @streamlit
	- GPT4 level performance at 0% of the cost
	- https://github.com/phidatahq/phidata/tree/main/cookbook/local_rag
- æµ·å¤–é«˜æ€§èƒ½è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ—¥æœ¬èªåŒ–ç ”ç©¶ã®ä¸€ç’°ã¨ã—ã¦Mixtral-8x7Bã®æ—¥æœ¬èªå‡ºåŠ›ã‚’å®‰å®šã•ã›ã‚‹Loraä½œæˆã€å…¬é–‹   
	- https://huggingface.co/aixsatoshi/Mixtral-8x7B-ja-Lora-sft-ChatbotArenaJAcalm2
	- Mixtral-8x7Bã¯é«˜æ€§èƒ½ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ãŒã€æ—¥æœ¬èªå‡ºåŠ›ã«å¤šè¨€èªãŒæ··å…¥ã™ã‚‹code-switchingãŒã‚ˆãè¦‹ã‚‰ã‚Œã¾ã™ã€‚ å…ƒã®æ€§èƒ½ã‚’ç¶­æŒã—ãªãŒã‚‰ã€æ—¥æœ¬èªç”Ÿæˆã‚’å®‰å®šã•ã›ã‚‹æ–¹æ³•ã¨ã—ã¦ã€Loraã®åŠ¹æœã‚’æ¤œè¨¼ã—ã¾ã—ãŸ
	- æ—¥æœ¬èªãŒæµæš¢ãªcalm2ã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ©ç”¨ã—ã¦ã¾ã™ Baseãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šä½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã§ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚‚ã€ä¸€å®šã®æ€§èƒ½ç¢ºä¿ã—ã¦æ—¥æœ¬èªåŒ–ã§ãã¾ã—ãŸ
-  Apple Vision Proã¯HoloLensã®å®Œæˆå½¢ã€‚ç¾æ™‚ç‚¹ã§ã®é™ç•Œå€¤ by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/nd36c04f9133a?sub_rt=share_h
	- ã€Œã¤ã„ã«ã“ã“ã¾ã§æ¥ãŸã‹ã€
-  Step-wise Queries by llamaindes
	- https://docs.llamaindex.ai/en/stable/examples/agent/custom_agent.html#step-wise-queries
	- In our brand-new cookbook, learn how to build a custom agent that can execute complex queries over your data, and can also be interrupted in the middle of execution with user inputs!
- Ollama OpenAI compatibility is here!
	- https://ollama.com/blog/openai-compatibility
	- ã¤ã¾ã‚Šã€ollamaã§openaiã®APIã¤ã‹ã£ã¦URLã‚’ollamaã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«å¤‰ãˆã‚‹ã ã‘ã§å‹•ãã¨ã„ã†ã“ã¨
-  RAG Research Insights
	- https://www.promptingguide.ai/research/rag#rag-research-insights
	- So we have created a new section in the RAG overview to summarize and help you keep track of insights into the latest RAG techniques.
- Nvidia releases canary-1b
	- https://huggingface.co/spaces/nvidia/canary-1b
	- With 1 billion parameters, Canary-1B supports automatic speech-to-text recognition (ASR) in 4 languages (English, German, French, Spanish) and translation from English to German/French/Spanish and fromâ€¦
- Bard ã¯ Geminiï¼ˆã‚¸ã‚§ãƒŸãƒ‹ï¼‰ã«ãªã‚Šã¾ã™ï¼
	- https://x.com/googlejapan/status/1755607418103587148?s=20
	- Gemini ã¯ Bard ã«æ­è¼‰ã•ã‚Œã¦ã„ã‚‹ AI ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒã€ã“ã®é«˜åº¦ãªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãŒåæ˜ ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ã‚ã‹ã‚Šã‚„ã™ãä¼ãˆã‚‹ãŸã‚ã«ã€åå‰ã‚’å¤‰ãˆã¾ã—ãŸ
	- https://gemini.google.com/app
- The Consensus Game: Language Model Generation via Equilibrium Search by å²¡é‡ã•ã‚“
	- https://openreview.net/forum?id=n9xeGcI4Yg
	- LLMã§è³ªå•å¿œç­”ç­‰ã®ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã™å ´åˆã€ç”Ÿæˆçš„ã«è§£ãå ´åˆï¼ˆp(y|x,v=çœŸ)) ã¨è­˜åˆ¥çš„ã«è§£ãå ´åˆï¼ˆp(v=çœŸ|x, y)ï¼‰ã§å¾—æ„/ä¸å¾—æ„ãŒç•°ãªã‚ŠçµæœãŒç•°ãªã‚‹ã€‚ã‚²ãƒ¼ãƒ ç†è«–ã«åŸºã¥ã„ã¦äºŒã¤ãŒåˆæ„ã™ã‚‹è§£ã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹å‡è¡¡é †ä½ä»˜ã‘ã‚’ææ¡ˆã€‚å¤šãã®ã‚¿ã‚¹ã‚¯ã§å†å­¦ç¿’ãªãã€æ€§èƒ½ã‚’å¤§ããæ”¹å–„ã§ãã‚‹
- OpenAnimateAnyone
	- https://github.com/fenghan0430/Open-AnimateAnyone
	- ã‚¢ãƒªãƒãƒã¯AIã®ç ”ç©¶çµæœã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã§å‡ºã—ã¦ãã‚Œã¦ãŸã‘ã©ã€ã„ã–AnimateAnyoneã¿ãŸã„ãªæœ‰æœ›ãªæˆæœç‰©ãŒã§ããŸã‚‰ã‚¹ãƒƒã¨ã‚¯ãƒ­ãƒ¼ã‚ºã«ã—ã¦ã‚·ãƒ¥ãƒƒã¨è‡ªç¤¾ã‚¢ãƒ—ãƒªã«çµ„ã¿è¾¼ã‚€ã€‚ã¤ã¾ã‚Šä»Šã¾ã§ã¯è‡ªç¤¾ã‚µãƒ¼ãƒ“ã‚¹ã«ã¯ä½¿ãˆã‚“ã‚¯ã‚ªãƒªãƒ†ã‚£ã ã‹ã‚‰ä¸ç”¨å“ãƒªã‚µã‚¤ã‚¯ãƒ«ã¨ã—ã¦ã‚ªãƒ¼ãƒ—ãƒ³ã«ã—ã¦ãŸã ã‘ï¼Ÿ
-  Grandmaster-Level Chess Without Search
	- https://arxiv.org/abs/2402.04494
	- ãƒã‚§ã‚¹ã§ã©ã®æ‰‹ãŒè‰¯ã„ã‹ã‚’Transformerã§æ•™å¸«ã‚ã‚Šå­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯æ¢ç´¢ã‚’ä½¿ã‚ãªãã¦ã‚‚äººã‚ˆã‚Šå¼·ããªã‚‹ï¼ˆæ¢ç´¢ã‚ã‚ŠAIã‚ˆã‚Šã¯å¼±ã„ï¼‰ã€‚æ•™å¸«ã‚ã‚Šãƒ‡ãƒ¼ã‚¿ã¯Stockfish 16ã§ä½œæˆã—ã¦ãŠã‚Šã€ç§‘å­¦åˆ†é‡ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚µãƒ­ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã®ä¸€ç¨®ã¨ã¿ãªã›ã‚‹ã€‚
- ragas 0.1 release
	- https://github.com/explodinggradients/ragas
	- We are releasing version 0.1 of Ragas today, the open-source standard for evaluating RAG applications.
-  Perplexityã‚’ã‚‚ã¨ã«ï½¤è¤‡æ•°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã¦æ¨è«–ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ç°¡å˜ãªã‚³ãƒ¼ãƒ‰å®Ÿè£…
	- https://note.com/kan_hatakeyama/n/nb5625d6411a8?sub_rt=share_pb
	- ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã™ã‚‹ãŸã‚ã®ç°¡å˜ãªå®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã¿ã¾ã™ã€‚  æœ€è¿‘ã¯ï½¤æ™®é€šã«mergekitã‚‚ã‚ã‚‹ã‚ˆã†ã§ã™ãŒï½¤å‹‰å¼·ã‚‚å…¼ã­ãŸå®Ÿè£…ã§ã™
	- ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›æ–‡ç« ã«å¯¾ã™ã‚‹Perplexityï¼ˆå›°æƒ‘ã•ï¼‰ã‚’æŒ‡æ¨™ã«ã€ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã‚Šã¾ã™
	- ä»Šå›ã¯è©¦ã—ã«ã€è‹±èªãŒå¾—æ„ãªLLama2-7bã¨ã€æ—¥æœ¬èªã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸElyza-7bã‚’çµ±åˆï¼ˆmergeï¼‰ã—ãŸã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦ã¿ã‚ˆã†ã¨æ€ã„ã¾ã™ã€‚
- æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
	- https://github.com/lighttransport/japanese-llama-experiment
-  Real-World Robot Applications of Foundation Models: A Review
	- https://arxiv.org/abs/2402.05741
	- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼Meta AI Researchã®Chrisã•ã‚“@chris_j_paxton , Google Deepmindã®Andyã•ã‚“ @andyzeng_ ã¨ã„ã†ï¼Œã“ã®åˆ†é‡ã§æœ€å…ˆç«¯ã‚’é€²ã‚€ãŠäºŒäººã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ãªãŒã‚‰åŸ·ç­†
-  OpenAIã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã€åŠå°ä½“ã®è³‡é‡‘èª¿é”ã§äº¤æ¸‰ã€€ç±³å ±é“
	- https://www.nikkei.com/article/DGXZQOGN095R00Z00C24A2000000/
	- å¿…è¦è³‡é‡‘750å…†å††
-  Multilingual E5 Text Embeddings: A Technical Report
	- https://huggingface.co/papers/2402.05672
	- Microsoftã®E5ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®å®Ÿè£…ãƒšãƒ¼ãƒ‘ãƒ¼ã€ä»Šé ƒã§ã‚‹ã‚‚ã®ãªã®ã‹ãƒ»
- Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents
	- https://github.com/yifanlu0227/ChatSim
	- ç”ŸæˆAIã®å‡ºç¾ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã®ä¸–ç•Œã‚‚å¤§ããå¤‰åŒ–ã€‚ æ˜¨æ—¥å‡ºãŸChatSimã§ã¯è‡ªç„¶è¨€èªã‚’å…¥åŠ›ã—ã¦ãƒ‰ãƒ©ã‚¤ãƒ“ãƒ³ã‚°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’è‡ªç”±ã«ç·¨é›†ã™ã‚‹ã“ã¨ãŒã§ãã‚‹
-  LangChain 101: Part 3a. Talking to Documents: Load, Split, and simple RAG with LCEL
	- https://pub.towardsai.net/langchain-101-part-3a-talking-to-documents-load-split-and-simple-rag-with-lcel-26b005ccb30a
	- Loading documents and splitting them are a key part of RAG
- mambaã®ç†è«–ã‚’ç†è§£ã™ã‚‹â‘ ï¼šHiPPOãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨LSSL
	- https://zenn.dev/izmyon/articles/8374a11d272602
	- mambaã®ç†è«–ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®è§£èª¬è¨˜äº‹ã‚’æ›¸ãå§‹ã‚ã¾ã—ãŸã€‚ã‹ãªã‚Šæ•°å¼ã®å°å‡ºãªã©ä¸å¯§ã«æ›¸ã„ã¦ã‚‹ã®ã§ã‚ˆã‚ã—ããŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚ä½•ã‹è¨‚æ­£ã‚„è£œè¶³ãŒã‚ã‚Œã°å„ªã—ãæ•™ãˆã¦ãã ã•
-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Can "small" finetuned LLMs with less than 2B parameters outperform larger openly available LLMs (Mixtral, Llama 2 Chat) and proprietary LLMs (ChatGPT)? Here's a closer look at the Tiny Titans paper
	- Flan-T5ãŒæœ€å¼·ã‚‰ã—ã„ã€
-  GPTã¯ä»–è€…ã®å¿ƒã®çŠ¶æ…‹ã‚’æ¨æ¸¬ã§ãã‚‹ï¼ŸAIÃ—å¿ƒç†å­¦ã®ã™ã‚ã‚
	- https://ai-scholar.tech/articles/computation-and-language/Theory-of-Mind
	- GPTã¯ä»–è€…ã®å¿ƒã‚’èª­ã‚ã‚‹ã®ã‹ï¼Ÿ å®Ÿé¨“ã«ãŠã„ã¦ã€GPT-3.5ã¨GPT-4ã¯é«˜ã„æ­£ç­”ç‡ã‚’ãƒãƒ¼ã‚¯ã—ã¾ã—ãŸã€‚ 
	- è‘—è€…ã¯ã€GPTãŒå¿ƒã®çŠ¶æ…‹ã‚’æ¨æ¸¬ã§ãã‚‹ç†ç”±ã¨ã—ã¦ã€Œè¨€èªèƒ½åŠ›ã®å‘ä¸Šã«ã‚ˆã£ã¦è‡ªç™ºçš„ã«å‡ºç¾ã—ãŸã®ã§ã¯ã€ã¨æŒ‡æ‘˜ã€‚ AIç ”ç©¶ã«ãŠã‘ã‚‹å¿ƒç†å­¦çš„ãªè¦–ç‚¹ã®é‡è¦æ€§ã‚’è§£
- In-Context Principle Learning from Mistakes
	- https://arxiv.org/abs/2402.05403
	- LLMã«æ•¢ãˆã¦é–“é•ã‚ã›ã¦ãƒ«ãƒ¼ãƒ«ã‚’è¦šãˆã•ã›åŒã˜ãƒŸã‚¹ã‚’é¿ã‘ã‚‹ã‚ˆã†ã«ã™ã‚‹æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
	- â– æ–°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ 
		- 1. ãƒ¢ãƒ‡ãƒ«ãŒé–“é•ã„ã‚’çŠ¯ã™ã‚ˆã†ã«ä¿ƒã™ 
		- 2. ãƒ¢ãƒ‡ãƒ«è‡ªèº«ã«ã€é–“é•ã„ã«å¯¾ã™ã‚‹èª¬æ˜ã‚’ç”Ÿæˆã•ã›ã€ã¾ãšã¯ä½ãƒ¬ãƒ™ãƒ«ã®åŸå‰‡ã‚’å½¢æˆã€‚ 
		- 3. ä½ãƒ¬ãƒ™ãƒ«ã®åŸå‰‡ã‚’ã¾ã¨ã‚ã€ç´„5ã¤ã®ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã«åœ§ç¸®ã—ã¦é«˜ãƒ¬ãƒ™ãƒ«ã®åŸå‰‡ã‚’ç”Ÿæˆ 
		- 4. é«˜ãƒ¬ãƒ™ãƒ«ã®åŸå‰‡ã‚’æœªè¦‹ã®ä¾‹ã«å¯¾ã™ã‚‹å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹éš›ã«åˆ©ç”¨ 
	- â– å®Ÿé¨“ã¨çµæœ å®Ÿé¨“ã¨çµæœã®è¦ç´„: 
		- GPT-3.5-Turboã¨GPT-4ã®è³ªå•å¿œç­”æ€§èƒ½ãŒä¸€è²«ã—ã¦æ”¹å–„ã•ã‚Œã€GPT-4ãŒ7.5%ã®æ”¹å–„ã‚’è¦‹ã›ãŸ
		- æ•°å­¦æ¨è«–ã‚¿ã‚¹ã‚¯ã§ã‚‚GPT-3.5-turboã¨GPT-4ã§åŸºæº–ã‚’ä¸Šå›ã‚‹çµæœã‚’ç¤ºã—ãŸ
		- Big-Bench Hardã‚¿ã‚¹ã‚¯ã§ã‚‚ã‚¹ã‚³ã‚¢ãŒä¸€å®šç¨‹åº¦ä¸Šæ˜‡ã—ãŸ
- Step-by-step guide to build AI agents for structured and unstructured data.
	- https://x.com/Saboo_Shubham_/status/1756123156400546251?s=20
	- Step 1: Define the Chunking Strategy
	- Step 2: Apply an Embedding Strategy
	- Step 3: Implement a Document Retriever for Text
	- Step 4: Use a Large Language Model (LLM)
	- Step 5: Extract Metadata
	- Step 6: Implement a Document Retriever for Metadata
	- Step 7: Integrate SQL Querying with a Data Warehouse
	- Step 8: Develop a Prompt Refinement Engine
	- Step 9: Create a Response Post-processor
	- Step 10: Deliver the Response
- Buffer Overflow in Mixture of Experts
	- https://arxiv.org/abs/2402.05526
	- "Mixture of Experts (MoE) has become a key ingredient for scaling large foundation models while keeping inference costs steady. We show that expert routing strategies that have cross-batch dependencies are vulnerable to attacks. Malicious
- WolframEngine+JupyterNotebookã§ç–‘ä¼¼Mathematica
	- https://x.com/blkcatman/status/1756219896026067052?s=20
- ã€Mambaã€‘Transformerã‚’å‡Œé§•ã—ã†ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å¾¹åº•è§£èª¬ï¼ˆã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚ã‚Šï¼‰
	- https://qiita.com/peony_snow/items/649ecb307cd3b5c10aa7
	- ï¼‘ï¼Mambaã¯Attentionã‚„MLPBlockã‚’æŒãŸãªã„ç°¡ç´ åŒ–ã•ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æœ‰ã—ã¾ã™ã€‚é¸æŠçš„çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSelective SSMï¼šSelective State Space Modelï¼‰ã¨ã„ã†æ–°ã—ã„æ§‹é€ ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å¿…è¦ãªæƒ…å ±ã®ã¿ã«æ³¨ç›®ã—ã€è¨ˆç®—åŠ¹ç‡ã®å¤§å¹…ãªå‘ä¸Šã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚
	- ï¼’ï¼é«˜é€Ÿãªæ¨è«–ï¼ˆTransformerã®ç´„5å€ï¼‰ã‚’å¯èƒ½ã«ã™ã‚‹ã¨ã¨ã‚‚ã«ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ãªã©ã®ã“ã¨ï¼‰ã®å¢—å¤§ã«å¯¾ã—ã¦ã€æ¨è«–ã‚³ã‚¹ãƒˆãŒç·šå½¢ã«å¢—å¤§ã™ã‚‹ã¨ã„ã†ç‰¹å¾´ã‚’æœ‰ã—ã¾ã™ï¼ˆã“ã‚Œã¾ã§ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯éç·šå½¢çš„ãªå¢—å¤§ãŒã‚ã‚Šã¾ã—ãŸï¼‰ã€‚ã“ã®æ€§èƒ½å‘ä¸Šã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹æ¤œè¨¼ã§ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ãŒ1000kï¼ˆï¼‘ï¼ï¼ä¸‡ï¼‰ã«ãŠã„ã¦ã¾ã§ç¢ºèªã•ã‚Œã¾ã—ãŸã€‚
	- ï¼“ï¼GPUãƒ¡ãƒ¢ãƒªéšå±¤é–“ã®ç§»å‹•ã‚’æœ€å°é™åŒ–ã™ã‚‹ã¨ã¨ã‚‚ã«ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«æœ€é©åŒ–ã•ã‚ŒãŸä¸¦åˆ—ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šé«˜é€Ÿãªè¨ˆç®—ãŒå¯èƒ½ã«ãªã‚Šã€è¦æ±‚ã•ã‚Œã‚‹ãƒ¡ãƒ¢ãƒªå®¹é‡ã‚‚è»½æ¸›ã•ã‚Œã¾ã™
	- ï¼”ï¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°2.8Bä»¥ä¸Šã®å ´åˆã«ãŠã„ã¦Mambaã¯æ©Ÿèƒ½ã™ã‚‹ã®ã‹ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã¯Transformerãªã©ã¨åŒã˜ãªã®ã‹ã€å­¦ç¿’ã®ä¸å®‰å®šæ€§ã¯ã©ã†ãªã®ã‹ã¨ã„ã£ãŸç‚¹ã«é–¢ã—ã¦ã¯ã¾ã ä¸æ˜ã§ã‚ã‚Šã€ä»Šå¾Œã®ç ”ç©¶ãŒå¾…ãŸã‚Œã¾ã™ã€‚
	- ï¼•ï¼ã¾ã ä¸æ˜ãªç‚¹ã‚‚å¤šã„ã§ã™ãŒã€æ§˜ã€…ãªè§’åº¦ã‹ã‚‰ã®ç ”ç©¶ã«ã‚ˆã£ã¦ã€Transformerã‚’ä»£æ›¿ã—ã†ã‚‹æœ‰æœ›ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚‹ã¨ã„ã†ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚‚å–å¾—ã•ã‚Œã¤ã¤ã‚ã‚Šã€ä»Šå¾ŒMambaã‚’çŸ¥ã‚‰ãªã‘ã‚Œã°æœ€å…ˆç«¯ã®ç ”ç©¶ã‹ã‚‰å–ã‚Šæ®‹ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
-  æ —ç”°å·¥æ¥­ã€æ©Ÿæ¢°å­¦ç¿’ä½¿ã£ãŸææ–™æ¢ç´¢ã§ä½ç’°å¢ƒè² è·ã®é˜²é£Ÿå‰¤é–‹ç™ºã¸
	- https://xtech.nikkei.com/atcl/nxt/news/24/00208/?n_cid=nbpnxt_twbn
	- æ —ç”°å·¥æ¥­ã•ã‚“ã‚‰ã¯å†·å´æ°´ã®é˜²é£Ÿå‰¤ã®é–‹ç™ºã®ãŸã‚ã€æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚Šæ•°ç™¾ä¸‡ã®åˆ†å­ã‹ã‚‰æœ‰æœ›ææ–™ã‚’æŠ½å‡º
- NeMo Guardrails, the Ultimate Open-Source LLM Security Toolkit
	- https://towardsdatascience.com/nemo-guardrails-the-ultimate-open-source-llm-security-toolkit-0a34648713ef
	- Advanced RAG with Guardrails
	- If you want to build user-facing RAG, you not only need to setup advanced retrieval, but also need to apply requisite layers of input/output filters for the following:
- pandas-ai
	- https://github.com/gventuri/pandas-ai
	- æ©Ÿèƒ½ã¨ã—ã¦ã¯pandasã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ç›´æ¥è‡ªç„¶è¨€èªã§å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã‚‚ã®ã§ã€è»½ãè¦‹ãŸæ„Ÿã˜ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ çš„ã«æ–°ã—ã„ã‚‚ã®ã¯ãªã•ãã†ãªã‚‚ã®ã®http://df.chat(ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)ã¨ã„ã†å½¢å¼ã§ã®æ“ä½œã¯æ–¬æ–°
- LLM-jp 13B v1.1ãƒªãƒªãƒ¼ã‚¹
	- https://llm-jp.nii.ac.jp/blog/2024/02/09/v1.1-tuning.html
	- å„ç¨®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã™ã”ã„æµæš¢ã«ãªã£ã¦ã‚‹ã€‚å­¦ç¿’è©³ç´°ã‚‚å…¬é–‹ã•ã‚Œã¦ã¦å‚è€ƒã«ãªã‚‹ã€‚
- The biggest Collection of Colab Based LLMs Fine tuning Notebooks
	- https://github.com/ashishpatel26/LLM-Finetuning
-  Google Colab ã§ LLM-jp 13B v1.1 ã‚’è©¦ã™ by nakaã•ã‚“
	- https://note.com/npaka/n/n2c272727d95a?sub_rt=share_h
	- ã€ŒLLM-jp 13B v1.1ã€ã¯ã€ã€ŒLLM-jp 13Bã€ã®æœ€æ–°ç‰ˆã§ã™ã€‚æ—¥è‹±ä¸¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã‚‹SFTã€ichikaraãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¿½åŠ +DPOã§å¯¾è©±å¿œç­”æ€§èƒ½ãŒå‘ä¸Šã—ã¦ã„ã¾ã™ã€‚
- OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models
	- https://arxiv.org/abs/2402.06044
	- A wild Theory of Mind Benchmark has appeared:
- 



## 2/5

ä»Šé€±ã‚‚ç››ã‚Šã ãã•ã‚“ã€‚ã¾ãšã¯ã€Metaã®CodeLlamaã®70Bç‰ˆãƒªãƒªãƒ¼ã‚¹ã€‚æ—©é€ŸSQLã®å¤‰æ›SQLCoder-70BãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸã‚Šã€4bitåŒ–ã•ã‚Œã¦MLXçµŒç”±ã§Macã§å‹•ã‹ã—ãŸã‚Šã¨ä¸€æ°—ã«ã«ãã‚„ã‹ã«ã€‚Metaã¯ã€35ä¸‡å€‹ã® H100ã‚’æ•´å‚™ã—ã€OSSã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«å–ã‚Šçµ„ã‚€ã¨ã„ã†ã“ã¨ã§ã€æ ªä¾¡ã¯20%ã‚¢ãƒƒãƒ—ã€‚ä¸€æ–¹Googleã¯ã€Bardã®backendã®Gemini Proã®å›½éš›å¯¾å¿œã‚’ãƒªãƒªãƒ¼ã‚¹ã€‚æ—¥æœ¬èªãªã‚“ã‹ã¾ã å¤‰ï¼ˆä¾‹ã€ãƒã‚¤ã‚¯ã‚’è‡ªè»¢è»Šã¨èªçŸ¥ï¼‰ã§ã™ãŒã€ç”»åƒèªè­˜æ©Ÿèƒ½ãªã©Gemini Proã‚’æ‰‹å…ƒã§è©¦ã›ã‚‹ã€‚OSSç‰ˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMä»£è¡¨çš„ãªLLaVA-1.6ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€Gemini Proè¶Šãˆã¨ã®è©•ä¾¡ã‚‚ã€‚LLMã®è»½é‡åŒ–ã®æ–°æ˜ŸSliceGPTã€è»½ãã¦ç²¾åº¦ãŒè½ã¡ãªã„ã®ã¯å¤§æ­“è¿ã€‚miqu-70Bã¨ã„ã†Mixtral 8x7Bã®é‡å­åŒ–ç‰ˆã‚‰ã—ãã‚‚ã®ãŒã€EQ-benchã§çªç„¶ä¸Šä½ã«ç™»å ´ã€æ¬¡ã®å¤§ããªãƒªãƒªãƒ¼ã‚¹ã®æ–¥å€™ã‹ã€ãªãŠmiqueã£ã¦ãƒŸã‚¯ã ã£ãŸã®ã‹ï¼Ÿã€‚Phixtralã®è«–æ–‡ã§ç´¹ä»‹ã•ã‚ŒãŸMoEã®å®Ÿè£…ã€æœ¬å®¶ã¨ã¯ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒé•ã†ã¿ãŸã„ã ãŒMoEã®å®Ÿè£…ã«ã‚‚ã„ã‚ã„ã‚ã‚ã‚‹ã‚‚ã®ã ã€‚ICRA2024ã§ã®æ¡æŠè«–æ–‡ãƒ»æŠ€è¡“ã®è©±é¡Œã‚‚ã¡ã‚‰ã»ã‚‰ã€‚å›½ç”£LLMã§ã¯ã€700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼LLMã€ŒKARAKURI LMã€ãŒç™»å ´ã€Llama 2ã‚’æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§äº‹å‰å­¦ç¿’ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‰ã—ã„ãŒã‚„ãŸã‚‰æ€§èƒ½ãŒé«˜ã„ã¨è©±é¡Œã«ã€‚ggufç‰ˆã‚„ã€MLXã‚’ã¤ã‹ã£ã¦M2 Macã§ã®å‹•ä½œç¢ºèªç­‰ãŒè¡Œã‚ã‚Œã€ã“ã‚Œã¯åŸºç¤èƒ½åŠ›ãŒé«˜ãã†ã€‚å°ã•ãè¨€èªãƒ¢ãƒ‡ãƒ«ã‚‚ã€Allen.AIã®OLMoã‚„ã€Kaggleé–¢é€£ã®H2O-Danube-1.8Bãªã©ãŒç™»å ´ã€‚RAGé–¢ä¿‚ã ã¨ã€ã¾ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã®æ¯”è¼ƒè«–æ–‡ã€ã©ã†ã‚‚ã¾ã ï¼²ï¼¡ï¼§ã®ã»ã†ãŒåˆ©ãŒã‚ã‚‹ã€‚ã‚¯ã‚¨ãƒªå¤‰æ›ã£ã¦ã®ã‚‚é‡è¦ãªæŠ€è¡“ã€‚ã—ã‹ã—ã€èµ¤ã¡ã‚ƒã‚“ã®é ­ã«ãƒ“ãƒ‡ã‚ªã‚’è£…ç€ã—ã¦å¾—ã‚‰ã‚ŒãŸ61 æ™‚é–“åˆ†ã®ç”»åƒã‹ã‚‰ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã¤ãã‚‹ã¨ã„ã†é€”æ–¹ã‚‚ãªã„ç ”ç©¶ã«ã¯ã³ã£ãã‚Šã—ãŸã€‚Hugging FaceãŒGPT Storeã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ç‰ˆï¼ˆAssistantï¼‰ã‚’é–‹å§‹ã€Googleã¨ã®ææºã§ãƒªã‚½ãƒ¼ã‚¹ãŒå¼·åŒ–ã•ã‚ŒãŸï¼Ÿã€‚æ±äº¬è—å¤§ã®å’æ¥­å±•ç¤ºã«â€œAIã‚¢ãƒ‹ãƒ¡â€ãŒå‡ºãŸã“ã¨ãŒè©±é¡Œã«ãªã£ãŸãŒã€Makingæƒ…å ±ã‚’è¦‹ã‚‹ã¨ã€ã˜ã¤ã¯ç›¸å½“ï¼¬ï¼¬ï¼­ã‚’ä½¿ã„ã“ãªã—ã¦ã„ã¦ã€ã‚·ãƒŠãƒªã‚ªã®ChatGPTã§ã®ä½œæˆãƒ­ã‚°ç­‰ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå‚è€ƒã«ãªã‚‹ã¨ã„ã†è©±ã«ã€‚Googleã®ã‚ã‚‰ã‚†ã‚‹æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’Decoder-onlyã®ãƒ¢ãƒ‡ãƒ«ã«ã¶ã£è¾¼ã‚“ã§æ™‚ç³»åˆ—äºˆæ¸¬ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ä½œã‚‹è©±ã€é•·æœŸæ™‚ç³»åˆ—äºˆæ¸¬ã§ã©ã†ã—ã¦ãã‚“ãªã«æ€§èƒ½ãŒé«˜ã„ã®ã‹ã€æ°—è±¡äºˆæ¸¬ã«ã‚‚é©ç”¨ã™ã‚‹ã®ã‹ï¼Ÿã€‚NEDOã®å›½å†…ç”ŸæˆAIã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºæ”¯æ´ã€ã•ã™ãŒã¨æ€ã‚ã‚Œã‚‹ä¼šç¤¾ã‚„ç ”ç©¶æ©Ÿé–¢ãŒä¸¦ã¶ã€‚å‚åŠ æ©Ÿé–¢ã®ï¼‘ã¤NIIã§ã¯ã€å›½ä¼šå›³æ›¸é¤¨ã®ã‚‚ã¤å›½å†…ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–äº‹æ¥­ã®æˆæœãŒæ´»ç”¨ã•ã‚Œã‚‹ã¨ã„ã†ã“ã¨ã ã€‚ä¸€æ–¹æ°‘é–“ã§ã¯Ricor-13Bã®ã‚ˆã†ãªã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸLLMæä¾›ãƒ“ã‚¸ãƒã‚¹ã‚‚ã¯ã˜ã¾ã£ãŸã€‚ææ–™ç³»ã®ç ”ç©¶ã¸ã®LLMã®å¿œç”¨ã‚‚ç€å®Ÿã«é€²ã‚€ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMå®Ÿè¡Œç’°å¢ƒã‚‚ã‚‚ollamaãŒvisionå¯¾å¿œã¨ã‹ã€function callå¯¾å¿œã¨ã‹ç€å®Ÿã«é€²ã‚“ã§ã‚‹ã€‚ã•ã¦æ¥é€±ã‚‚ã€Gemini Ultra ãŒ2/7ã«ãƒªãƒªãƒ¼ã‚¹ã¨ã®ã†ã‚ã•ã‚‚ã‚ã‚Šã€äººå‹ãƒ­ãƒœãƒƒãƒˆã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—Figureã«å‡ºè³‡ã—ãŸMicrosoft/OpenAIã®æ¬¡ã®æ‰‹ã‚„ã€Vison Proã‚’å‡ºã—ãŸAppleã®ï¼¡ï¼©æˆ¦ç•¥ã‚‚æ°—ã«ãªã‚‹ã¨ã“ã‚ã€‚

- google/siglip-base-patch16-256-multilingual ã‚’ä½¿ã£ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ç”»åƒã‚’æ—¥æœ¬èªã§æ¤œç´¢ã—ã¦ã¿ã‚‹
	- https://note.com/eurekachan/n/n9d4f62b80ad6?sub_rt=share_pb
	- 1æœˆã«ã€Googleã‹ã‚‰ã€SigLIPã¨ã„ã†ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦æ‰±ã†ã“ã¨ãŒã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®multilingualç‰ˆï¼ˆå¤šè¨€èªå¯¾å¿œç‰ˆï¼‰ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚transformers 4.37ä»¥é™ã§å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚æ—¥æœ¬èªã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
	- CUDAã‚’ä½¿ã„ã¾ã—ãŸãŒã€GPUã¸ã®è² è·ã‚‚ä½ã‹ã£ãŸã®ã§ã€æ¡ˆå¤–CPUã§ã‚‚å‹•ã‹ã›ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
-  Are Transformers Effective for Time Series Forecasting?
	- decisively highlighting the shortcomings and deficiencies in research surrounding the use of transformers for
	- This paper effectively exposes the deceptive practices employed by various authors in their papers, such as inadequate benchmarking and other tactics, which have previously led to inflated claims regarding the performance of transformers in this domain.
- Googleãªã©ç±³ITã€1æœˆ1ä¸‡äººå‰Šæ¸›ã€€çµ„ç¹”ã‚¹ãƒªãƒ åŒ–ã§AIé›†ä¸­
	- https://www.nikkei.com/article/DGXZQOGN1757C0X10C24A1000000/
- DSPy lets you prototype LLM Programs like AlphaCodium
	- https://x.com/CShorten30/status/1751656468879708496?s=20
- LangGraph Financial Agent w/ Polygon
	- https://gist.github.com/virattt/4d764c427892ce9fdf4534209edfb1f4
	- LangGraphã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã£ã¦æ ªä¾¡ã‚’ã¨ã£ã¦ãã‚‹ç°¡å˜ãªä¾‹
- Ollamaã§ã€ Mistral-7B finetuned for function callingã€€ã‚’ã‚µãƒãƒ¼ãƒˆ
	- https://ollama.ai/calebfahlgren/natural-functions
-  çŸ¥è­˜0ã§ãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¦ã¿ã‚‹ï¼å‚ã‚Œæµã—é…ä¿¡ã€ã‚´ãƒªãƒ©ã‚¸ã€‘
	- https://www.youtube.com/watch?v=C1yFEMDLddc
- MetaãŒã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°LLMã®CodeLlamaã®70Bç‰ˆã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ãƒªãƒªãƒ¼ã‚¹ã€‚
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/?utm_source=twitter&utm_medium=organic_social&utm_campaign=codellama&utm_content=reply
	- HumanEvalã§GPT-4è¶…ãˆã—ãŸã‚‰ã—ã„ã€‚å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚‚100kã¾ã§è¡Œã‘ã‚‹ã‚‰ã—ã„
	- Metaã¯ä»¥å‰ã‹ã‚‰ã€ŒGPT-4ä¸¦ã®LLMã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã«ã™ã‚‹ã€ã¨äºˆå‘Šã—ã¦ã„ã¾ã—ãŸãŒï¼Œå¹´æ˜ã‘æ—©ã€…ï¼Œã¾ãšã¯ã‚³ãƒ¼ãƒ‰ç”Ÿæˆé ˜åŸŸã§ã‚„ã£ã¦ãã¾ã—ãŸ
	- https://labs.perplexity.ai/ ã§ãŸã‚ã›ã‚‹ã‚‰ã—ã„
-  Inverse Molecular Design with Multi-Conditional Diffusion Guidance
	- https://arxiv.org/abs/2401.13858
	- è¤‡æ•°ã®åˆ¶ç´„ä¸‹ã§ã®åˆ†å­ç”Ÿæˆã®è«–æ–‡
	- å¾“æ¥ã¯åˆæˆå¯èƒ½æ€§ã¨ã‚¬ã‚¹é€éæ€§ãªã©ï¼’ã¤ä»¥ä¸Šã®åˆ¶ç´„ã‚’æº€ãŸã™ã‚ˆã†ãªåˆ†å­ã‚’ï¼‘ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸãŒ 
	- åˆ¶ç´„ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãŸTransformerãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šä½åˆ†å­ãƒ»é«˜åˆ†å­å…±ã«ã†ã¾ãç”Ÿæˆã§ããŸãã†ã§ã™ã€‚
- ã‚¢ãƒªãƒãƒãŒãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMä½¿ã£ã¦ä½œã£ãŸã‚¹ãƒãƒ›ã‚’æ“ä½œã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€Mobile-Agentã‚’ç™ºè¡¨
	- https://x.com/umiyuki_ai/status/1752183108873687439?s=20
- SliceGPT: Compress Large Language Models by Deleting Rows and Columns
	- https://arxiv.org/abs/2401.15024
	- Microsoftã¨ãƒãƒ¥ãƒ¼ãƒªãƒƒãƒ’å·¥ç§‘å¤§ã®ç ”ç©¶è€…ã«ã‚ˆã‚Šã€LLMã‚’ã‚¹ãƒ©ã‚¤ã‚¹ï¼ˆè¡Œã‚„åˆ—ã‚’å‰Šé™¤ï¼‰ã—ã¦è»½ãã™ã‚‹åŠ¹æœçš„ãªæ‰‹æ³•
	- å®Ÿé¨“ã§ã¯æœ€å¤§30%ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‰Šæ¸›ã—ã¤ã¤æ€§èƒ½ã®90%ä»¥ä¸Šã‚’ä¿ã¤ã“ã¨ãŒã§ããŸã¨
	- â– ææ¡ˆæ‰‹æ³• 
		- 1. ä¸»æˆåˆ†åˆ†æã‚’ç”¨ã„ã¦é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º 
		- 2. é‡è¦ã§ãªã„æƒ…å ±ã‚’å–ã‚Šé™¤ããŸã‚ã«è¡Œã‚„åˆ—ã‚’å‰Šæ¸› â†’ã‚ˆã‚Šå°‘ãªã„è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã§å‹•ä½œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. OPT, LLAMA-2, Phi-2ã‚’å®Ÿé¨“å¯¾è±¡ãƒ¢ãƒ‡ãƒ«ã«è¨­å®š 
		- 2. HuggingFace Transformersã¨PyTorchã§å®Ÿè£… 
		- 3. ã„ãã¤ã‹ã®ã‚¹ãƒ©ã‚¤ã‚¹ãƒ¬ãƒ™ãƒ«ã‚’åˆ†ã‘ã¦å®Ÿé¨“ 
		- 4. æœ€å¤§30%ã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šæ¸›ãŒå®Ÿç¾ã—ãŸ 
		- 5. Llama 2ã¨Phi-2ãƒ¢ãƒ‡ãƒ«ã¯90%ä»¥ä¸Šã®æ€§èƒ½ã‚’ç¶­æŒ
- Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
	- https://arxiv.org/abs/2312.05934
	- Microsoftã‚ˆã‚Šã€ŒFine Tuningã¨RAGã®ã©ã¡ã‚‰ãŒé«˜ç²¾åº¦ã‹ï¼Ÿã€ã«ç­”ãˆãŸè«–æ–‡
	- æ—¢å­˜/æ–°è¦çŸ¥è­˜ã®ä¸¡æ–¹ã«ãŠã„ã¦RAGãŒè‰¯å¥½ãªçµæœã«ã€‚Fine Tuningã¯ç¶™ç¶šäº‹å‰å­¦ç¿’ã€è©•ä¾¡ã¯MMLUã‚’LM-Evaluation-Harnessã§å®Ÿæ–½ã€‚
- The Power of Noise: Redefining Retrieval for RAG System
	- https://arxiv.org/abs/2401.14887
	- LLMã«ãŠã‘ã‚‹RAGï¼ˆå¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šè¾¼ã¾ã›ã‚‹ï¼‰ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã€Œç„¡é–¢ä¿‚ãªã€æ–‡æ›¸ã‚’æ··ãœãŸã»ã†ãŒæ¤œç´¢ç²¾åº¦ãŒä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- â– ãªãœãã‚“ãªã“ã¨ãŒèµ·ã“ã‚‹ã®ã‹ 
		- 1. é–¢é€£æ€§ãŒé«˜ã„æ–‡æ›¸ã°ã‹ã‚Šã ã¨éå‰°é©åˆãŒèµ·ã“ã‚‹ 
		- 2. ç„¡é–¢ä¿‚æƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹èƒ½åŠ›ãŒä¸ŠãŒ
- ä¸€æ˜¨æ—¥ãã‚‰ã„ã‹ã‚‰mistralã®æœ‰æ–™ç‰ˆã§ã‚ã‚‹mistral-medium(70Bã€MoEã§ã¯ãªã„)ã®é‡ã¿ãŒãƒªãƒ¼ã‚¯ã—ãŸã¨ã„ã†å™‚ãŒã‚ã‚‹
	- https://x.com/webbigdata/status/1752304557336801408?s=20
-  Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery
	- https://arxiv.org/abs/2309.14425
	- æ¾å°¾ç ”ã®RAã§å­¦éƒ¨2å¹´ç”Ÿã®ç™½å‚ç¿ èŒã•ã‚“ãŒä¸»è‘—ã—ãŸï¼ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ï¼Œã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ãªãŒã‚‰å¤±æ•—ã«ã‚‚æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹å®¶åº­å†…ã‚µãƒ¼ãƒ“ã‚¹ãƒ­ãƒœãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã™ã‚‹ç ”ç©¶ãŒICRA2024ã«æ¡æŠã•ã‚Œã¾ã—ãŸ
- çªå¦‚ã¨ã—ã¦ç¾ã‚ŒãŸmiqu-70BãŒEQ-Bench ã§ã¯ 83.5 ã‚’ç²å¾—ã— (ãƒ­ãƒ¼ã‚«ãƒ«ã§è©•ä¾¡)ã€GPT-4ç³»ã«æ¬¡ãæ€§èƒ½ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜
	- https://x.com/N8Programs/status/1752441060133892503?s=20
	- ã©ã†ã‚‚ã€Mixtral 8x7Bã®é‡å­åŒ–ç‰ˆã®ãƒªãƒ¼ã‚¯ã ã£ãŸã‚‰ã—ã„
-  LangGraphã§å§‹ã‚ã‚‹ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
	- https://speakerdeck.com/peisuke/langgraphdeshi-merumarutiezientosisutemu
	- Function Callingã ã‘ã§å‰²ã¨ã‚ˆãå‹•ã„ã¦ã‚‹ã¨ã“ã‚ã‚‹ã‚“ã ã‘ã©ã€ã‚‚ã†å°‘ã—çµ±åˆã—ãŸãã¦SupervisorãŒå¿…è¦ãã†ãªãƒ•ãƒ­ãƒ¼ã‹ã‚‰è©¦ã—ã¦ã¿ã‚ˆã†ã‹ãª
- Mixtral8x7Bã®æ—¥æœ¬èªå¯¾å¿œLoraã®å­¦ç¿’å®Œäº†ã—ã¾ã—ãŸ
	- https://x.com/AiXsatoshi/status/1752509354849546417?s=20
	- æ¨™æº–ã®Mixtral8x7Bã§ã¯ã€å¿œç­”ã«å¤šè¨€èªé–“ã‚’è¡Œãæ¥ã™ã‚‹switchingãŒç™ºç”Ÿã—ã¾ã™ãŒã€æ”¹å–„ã—ã¦ã„ã¾ã™
	- æ±ç”¨æ€§èƒ½ãŒè½ã¡ã¦ã„ã‚‹å¯èƒ½æ€§ã‚ã‚‹ã®ã§ã€ã‚‚ã†å°‘ã—æ¤œè¨¼ã—ã¾ã™
- å­¦ç¿’æ¸ˆã¿ã® LLM ã‚’æŸã­ã¦ Mixture of Experts ã‚’ä½œã‚‹ãƒ†ã‚¯
	- https://zenn.dev/zaburo_ch/articles/88e35e5c80f974
	- Phixtralã®è©±ã®ç´¹ä»‹
	- ã€ŒPhi-2 ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã„ãã¤ã‹ä½¿ã£ã¦ Mixture of Experts (MoE) ã‚’ä½œã£ãŸã‚‰å˜ä½“ã‚ˆã‚Šã‚‚è‰¯ã„æ€§èƒ½ãŒé”æˆã§ãã¾ã—ãŸã€
	- **Few-shot ã§ Gating ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ±ºã‚ã‚‹æ‰‹æ³•**ãŒä½¿ã‚ã‚Œã¦ã„ã¦é¢ç™½ã‹ã£ãŸ
	- Gating ã®è©±ã‚’å¿˜ã‚Œã‚Œã°ã€Œãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ±ºã‚ã¦ MLP ä»¥å¤–ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯å…¨éƒ¨ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ã‚‚ã®ã‚’ã€MLP ã¯ MoE Layer ã«ç½®ãæ›ãˆã¦å„ãƒ¢ãƒ‡ãƒ«ã® MLP ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ã†ã€ã¨ã„ã†æ–¹æ³•ã§ MoE ãƒ¢ãƒ‡ãƒ«ãŒä½œã‚Œãã†ã§ã™
	- å„ Expert ã«ã¤ã„ã¦ã€ãã® Expert ã‚’ä½¿ã†ã¨æœ‰åˆ©ã«ãªã‚Šãã†ãª Prompt (ä¾‹ãˆã° Code ã§ Fine-Tuning ã•ã‚ŒãŸ Expert ãªã‚‰ Code ã® Prompt) ã‚’ã„ãã¤ã‹ç”¨æ„ã—ã¦ã€ãã® Prompt ã‚’ forward ã—ãŸã¨ãã® hidden_state ã‚’ä½¿ã£ã¦ weâ€‹ ã‚’ä½œã‚ã†
	- Domain ã”ã¨ã« Expert ã‚’ä½¿ã„åˆ†ã‘ã¦ãã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹æ„Ÿã˜ã§ã™ã­
- CodeLlama-70Bã‚’PostgreSQLã®ç”Ÿæˆã«ç‰¹åŒ–ã•ã›ãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€SQLCoder-70B
	- https://huggingface.co/defog/sqlcoder-70b-alpha
	- æ€§èƒ½è©•ä¾¡ã‚‚GPT-4ã«10ãƒã‚¤ãƒ³ãƒˆä»¥ä¸Šå·®ã‚’ã¤ã‘ã‚‹åœ§å€’çš„ãªå‹åˆ©ã§ã€ç‰¹åŒ–å‹ã®ã‚³ãƒ¼ãƒ‰ç”ŸæˆLLMã®å°é ­ã‚’äºˆæ„Ÿã•ã›ã‚‹ã‚ˆã†ãªãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç§˜ã‚ã¦ã„ã‚‹
- LLaVA-1.6ã®ãƒªãƒªãƒ¼ã‚¹ã€Gemini Proè¶Šãˆï¼Ÿ
	- https://x.com/imhaotian/status/1752621754273472927?s=20
	- https://llava-vl.github.io/blog/2024-01-30-llava-1-6/
	- improved reasoning, OCR, and world knowledge. It supports higher-res inputs, more tasks, and exceeds Gemini Pro on several benchmarks!
	- LLaVA-1.6ã€æ™®é€šã«ç”»åƒä¸­ã®å¹ãå‡ºã—ã‚’æ—¥æœ¬èªã§å–‹ã£ã¦ã„ã‚‹ã¨ã‹èªè­˜ã§ãã¦ã€Gemini Proè¶…ãˆã¯ä¼Šé”ã§ã¯ãªã„ãªã¨ãªã‚‹
- 700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼LLMã€ŒKARAKURI LMã€ã‚’ä¸€èˆ¬å…¬é–‹
	- https://karakuri.ai/seminar/news/karakuri-lm/
	- GPT-4ã‚’è©•ä¾¡è€…ã¨ã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯(MT-Bench-jp)ã§ã€å›½ç”£LLMã¨ã—ã¦ã¯1ä½ã®æ€§èƒ½ã‚’é”æˆã—ã¾ã—ãŸ
	- https://lm.karakuri.cc/ ã§ãŠè©¦ã—
- è«–æ–‡ã€ŒRAG VS Fine-tuningã€ã‚’èª­ã‚€
	- https://zenn.dev/neoai/articles/e75b6f033a4fd9
- æ™®é€šã®äººãŒè³‡ç”£é‹ç”¨ã§99ç‚¹ã‚’å–ã‚‹æ–¹æ³•
	- https://hayatoito.github.io/2020/investing/
		- 1.  ç¢ºå®šæ‹ å‡ºå¹´é‡‘ (iDeCo ã¾ãŸã¯ ä¼æ¥­å‹ DCï¼‰ã‚’å§‹ã‚ã¾ã™ã€‚
		- 2.  æ–° NISA ã§ã¤ã¿ãŸã¦ã®è¨­å®šã‚’ã—ã¾ã™ã€‚
		- 3.  ã•ã‚‰ã«ä½™è£•ãŒã‚ã‚‹æ–¹ã¯ã€ç‰¹å®šå£åº§ã§ã¤ã¿ãŸã¦ã®è¨­å®šã‚’ã—ã¾ã™ã€‚
		- 4.  è³‡ç”£é‹ç”¨ã‚’å§‹ã‚ãŸç›´å¾Œã‚„ã€ã¾ã¨ã¾ã£ãŸè³‡é‡‘ã‚’ä¸€æ™‚çš„ã«å…¥æ‰‹ã—ãŸã¨ããªã©ã€ååˆ†ãªä½™å‰°è³‡é‡‘ï¼ˆç¾é‡‘ï¼‰ã‚’ã‚‚ã£ã¦ã„ã‚‹ã®ã§ã‚ã‚Œã°ã€è‡ªåˆ†ã®ãƒªã‚¹ã‚¯è¨±å®¹åº¦ã®ç¯„å›²å†…ã§ã€é©åˆ‡ãªå‰²åˆã®è³‡ç”£ã‚’  _ä¸€æ‹¬_  ã§æŠ•è³‡ã—ã¾ã™ã€‚è©³ã—ãã¯å¾Œè¿°ã®ã€Œã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
		- 5.  å®šæœŸçš„ã«ï¼ˆå¹´ã« 1 å›ã€ã‚ã‚‹ã„ã¯æ•°å¹´ã« 1 å›ï¼‰ã€ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦è¦‹ç›´ã—ã¾ã—ã‚‡ã†ã€‚
-  Self-supervised Learning: Generative or Contrastive
	- https://arxiv.org/abs/2006.08218
- Proactive Detection of Voice Cloning with Localized Watermarking
	- https://huggingface.co/papers/2401.17264
	- Meta presents Proactive Detection of Voice Cloning with Localized Watermarking
- ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆãªã©ã‹ã‚‰ä¸­å¤ã®RTX 3090ã‚’8å°ã‹ãé›†ã‚ã¦ãƒã‚·ãƒ³ã‚’æ§‹ç¯‰ã—ãŸäººã®ãŠè©±
	- https://www.kyleboddy.com/2024/01/28/building-deep-learning-machines-unorthodox-gpus/
- Google's AI Makes Stunning Progress with Logical Reasoning
	- https://www.youtube.com/watch?v=NrNjvIrCqII
- Microsoft and OpenAI are in talks to invest $100 million into Figure
	- https://x.com/AndrewCurran_/status/1752463084550262805?s=20
	- Figureã¯ã€äººå‹ãƒ­ãƒœãƒƒãƒˆã‚’é–‹ç™ºã™ã‚‹ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—
-  ReGAL: Refactoring Programs to Discover Generalizable Abstractions
	- https://huggingface.co/papers/2401.16467
- miqudev/miqu-1-70b
	- https://huggingface.co/miqudev/miqu-1-70b
	- ãˆã£ï¼ã€miquã£ã¦ãƒŸã‚¯ã®ã“ã¨ã ã£ãŸã®ã‹ã€‚
- H2O-Danube-1.8B Technical Report
	- https://arxiv.org/abs/2401.16818
	- Open-sources a high-competitive 1.8B LM trained on 1T tokens following the core principles of LLama 2 and Mistral
	- long context small LLM trained by a team of some of the best Kagglers in the world
	- ã©ã†ã‚‚å°è¦æ¨¡LLMã§Kagglerã«ã‚ˆã‚Štrainigã•ã‚ŒãŸã‚‚ï½
-  Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
	- https://arxiv.org/abs/2401.17263
	- Significantly improves robustness to held-out jailbreaks, reducing the attack success rate from 84% to 8.66% across 20 jailbreaks
- quantized CodeLlama 70b base model to 4-bit with MLX
	- https://huggingface.co/mlx-community/CodeLlama-70b-hf-4bit-MLX
	- you can now run this model on your Apple Silicon.
- StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis
	- https://arxiv.org/abs/2401.17093
- Memphis-CoT 3B
	- https://huggingface.co/euclaise/Memphis-CoT-3B
	- A small reasoning-focused model using a novel iterative contrastive finetuning procedure, trained on only human data, outperforming much larger human data models and similarly sized SFT models.
-  RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank
	- ICLR24 Spotlight: To train general-purpose SSL models, it's important to measure the quality of representations during training. But how can we do this w/o downstream labels? 
	- We propose a new label-free metric to eval SSL models, called Linear Discrimination Analysis Rank(LiDAR)
-  [The False Promise of Imitating Proprietary LLMs](https://arxiv.org/abs/2305.15717v1)
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã€Œæ¨¡å€£ã€ã¯æœ‰ç”¨ã‹ï¼Ÿ
	- https://ai-scholar.tech/articles/chatgpt/Imitating-Proprietary-LLMs
	- æœ€æ–°ç ”ç©¶ã«ã‚ˆã‚Œã°ã€æ–°ã—ãé–‹ç™ºã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã®æ¨¡å€£ã¯éå¸¸ã«é›£ã—ã„ã“ã¨ãŒç¤ºå”†ã•ã‚Œã¦ã„ã¾ã™ã€‚å¾®èª¿æ•´ã«ã‚ˆã‚‹æ”¹å–„ãŒæœ‰åŠ¹ã§ãªãã€ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬çš„ãªçŸ¥è­˜ã¯ã‚ã¾ã‚Šå¤‰ã‚ã‚‰ãªã„ã“ã¨ãŒç™ºè¦‹ã•ã‚Œã¾ã—ãŸã€‚  
	- ä¸­å°ä¼æ¥­ã‚„å¤§ä¼æ¥­ãŒåŒã˜åˆ©ç‚¹ã‚’å¾—ã‚‹ã“ã¨ãŒé›£ã—ããªã‚Šã€ç‰¹ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æ´»ã‹ã—ã¦èƒ½åŠ›å·®ã‚’ç”Ÿã‹ã™ä¼æ¥­ãŒç«¶äº‰ä¸Šã®å„ªä½æ€§ã‚’ç¯‰ã‘ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
	- æ–°ã—ã„æ‰‹æ³•ã‚„ãƒ‡ãƒ¼ã‚¿ã®å°å…¥ãŒé‡è¦ã§ã‚ã‚Šã€æŠ€è¡“çš„ãªåˆ¶ç´„ã«ã‚‚ç•™æ„ã™ã‚‹ã“ã¨ãŒæŒç¶šçš„ãªç™ºå±•ã«å¯„ä¸ã™ã‚‹ã§ã—ã‚‡ã†ã€‚
- Accelerating the Science of Language Models
	- https://allenai.org/olmo/olmo-paper.pdf
	- AllenAIã«ã‚ˆã‚‹Open Language Model (OLMo), a 7B parameter model.
	- There is also a smaller version of it, OLMo 1B.
- ãƒ–ãƒ©ã‚¦ã‚¶ã§Rubyã‚’å‹•ã‹ã™å¤¢
	- https://mametter.hatenablog.com/entry/2024/02/01/105413
	- å…ƒåŒåƒšã®é è—¤ã•ã‚“ã€é ‘å¼µã£ã¦ã‚‹ãªã€ã¿ã‚“ãªä½¿ã£ã¦ã‚ã’ã¦ï¼
- SEMSCORE: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity
	- https://arxiv.org/pdf/2401.17072.pdf
	- ã“ã‚Œã§Japanese MT-benchã‚„Elyza-tasksãŒæ¯å›GPT-4ã‚’ä½¿ã‚ãšã«è©•ä¾¡ã§ãã‚‹ã‚ˆã†ã«ãªã‚Œã°å‰²ã¨å®‰ä¾¡ã§æ—¥æœ¬èªLLM leaderboardãŒä½œã‚Œãã†
- llamaindexã‚’ä½¿ã£ãŸã€ä½¿ç”¨ã—ãŸã‚¯ã‚¨ãƒªå¤‰æ›ã®è§£èª¬è¨˜äº‹
	- https://akash-mathur.medium.com/advanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3
	-  Advanced RAG: Query Augmentation for Next-Level Search using LlamaIndex
	- ã‚¯ã‚¨ãƒªå¤‰æ›ã¯ã€ŒLLM ã¸ã®å…¥åŠ›ï¼ˆã‚¯ã‚¨ãƒªï¼‰ã‚’ã‚ˆã‚Šè‰¯ã„æƒ…å ±æŠ½å‡ºã‚’å¯èƒ½ã¨ã™ã‚‹è¡¨ç¾ã¸å¤‰æ›ã™ã‚‹ã€ã“ã¨ã§ï¼ŒRAG ã®è³ªã‚’é«˜ã‚ã‚‹æ‰‹æ³•
	- è¨˜äº‹å†…ã§ã¯ï¼Œä»£è¡¨çš„ãª 5 ã¤ã®æ‰‹æ³•ã‚’ code ã¤ãã§è§£èª¬
- Build Long-context RAG from scratch: Nomic Embeddings + Mistral
	- https://x.com/LangChainAI/status/1753149741599428926?s=20
	- nomic_ai has launched a new open source, long context embedding model:
		- 8k token context window (using RoPE)
		- Strong performance on several benchmarks 
		- API (and local support coming soon)
	- ãã—ã¦long contexã®RAGã‚’ã¤ãã‚‹ã«ã¯ã€
		- nomic_ai:new 8k context window embeddings
		- trychroma:vectorstoreã€€MistralAI-instruct 32k context window via  ollama
- Apple presents Can Large Language Models Understand Context
	- https://huggingface.co/papers/2402.0085
	- We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.
-  Grounded language acquisition through the eyes and ears of a single child
	- https://www.science.org/doi/10.1126/science.adi1374
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã»ã©å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’é£Ÿã‚ãªãã¦ã‚‚å­ä¾›ã¯è¨€èªã‚’ç²å¾—ã™ã‚‹ã€‚ãã‚Œã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§å†ç¾ã§ãã‚‹ã‹ç¢ºèªã™ã‚‹ãŸã‚ã€èµ¤ã¡ã‚ƒã‚“ï¼‘äººã®é ­ã«ç”Ÿå¾Œ 6ã€œ25 ãƒ¶æœˆã®é–“ã«éŒ²ç”»ç”¨ãƒ“ãƒ‡ã‚ªã‚’å»¶ã¹ 61 æ™‚é–“è£…ç€ã—ã¦éŸ³å£°ï½¥æ˜ åƒãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å­¦ç¿’ã‚’æˆåŠŸã•ã›ãŸã¨ã™ã‚‹å ±å‘Š
- karakuri-lm-70b-chat-v0.1-gguf ã® q5_K_S ã‚’ ãƒ­ãƒ¼ã‚«ãƒ«ã§è©¦ã™ã€‚ã¨ã¦ã‚‚å„ªç§€ã€‚
	- https://x.com/npaka123/status/1753336604759118014?s=20
	-  Llama.cppã§5.82 token/s (M3 Max)
	- https://huggingface.co/mmnga/karakuri-lm-70b-chat-v0.1-gguf
- è—å¤§ã®å™‚ã®ç”ŸæˆAIã®ã‚„ã¤ã€èª¬æ˜ã¨ã‹è¦‹ãŸã‚‰æ€ã£ãŸæ•°ç™¾å€æ‰‹ã®è¾¼ã‚“ã ã“ã¨ã‚„ã£ã¦ã¦ã™ã’ã‡ã£ã¦ãªã£ãŸã€‚ç”ŸæˆAIã®è‰¯ã„ä½¿ã„æ–¹ã£ã™ã­ã€‚
	- https://x.com/413s9/status/1753300577516433830?s=20
	- è—å¤§ã®AIã‚¢ãƒ‹ãƒ¡ã€KALINã•ã‚“ã®æ³¨é‡ˆã‚’èª­ã‚€é™ã‚Š 
		- ç‰©èªéƒ¨â†’chatgpt 
		- ç”»åƒç”Ÿæˆâ†’midjourney,nijijourney 
		- AIå‹•ç”»åŒ–â†’runway,pika 
		- ç”»åƒä¿®æ­£â†’photoshop ã¨æ›¸ã‹ã‚Œã¦ã„ãŸã¯ãšãªã®ã§ï¼ˆã‚¢ãƒ‹ãƒ¡éƒ¨ã¯ã‚¯ãƒªã‚¹ã‚¿ã‹ã‚‚ï¼Ÿï¼‰ 
	- åŸºæœ¬çš„ã«KALINã•ã‚“ã¯ãƒ­ãƒ¼ã‚«ãƒ«SDã‚’å€‹äººã§å‹•ã‹ã™ã¨ã„ã†ä½œæ¥­ã¯è¡Œã£ã¦ã„ãªã‹ã£ãŸã®ã ã‚ã†ã¨æ¨æ¸¬ã€‚
	- ä¾‹ã®AIã‚¢ãƒ‹ãƒ¡ã®ChatGPTã®ãƒ­ã‚°ã‚’ã–ã£ã¨çœºã‚ãŸãŒã€å®Œå…¨ã«GPT-3.5ã®ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ã‚’è¶…ãˆã¦ã„ã‚‹ãƒ¬ãƒ™ãƒ«ã§ä½¿ã„è¾¼ã‚“ã§ã„ã¦å‰²ã¨çµ¶å¥ã—ãŸ
		- https://chat.openai.com/share/a6f6052e-a22c-49aa-8847-9c7f12b011e0
-  A Prompt-Engineered Large Language Model, Deep Learning Workflow for Materials Classification
	- https://arxiv.org/abs/2401.17788
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ææ–™åˆ†é¡ã®è«–æ–‡
	- Geminã«ã‚ˆã‚Šææ–™æƒ…å ±ã‚’æŒ‡å®šã—ãŸãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ã—ã€æ•´ãˆãŸãƒ‡ãƒ¼ã‚¿ã§BERTã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€é‡‘å±ã‚¬ãƒ©ã‚¹ã«ãªã‚‹ã‹å¦ã‹ã‚’é«˜ç²¾åº¦ã«åˆ¤å®šã§ããŸãã†ã§ã™ã€‚
	- è¨€èªãƒ¢ãƒ‡ãƒ«ãƒ•ãƒ«æ´»ç”¨ã€‚ç–ãªãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã†ã¾ãäºˆæ¸¬ã§ãã‚‹ç‚¹ãŒãƒ¡ãƒªãƒƒãƒˆã®ã‚ˆã†ã§ã™
- Build a RAG backend over any website in a single CLI command
	- https://github.com/run-llama/LlamaIndexTS/tree/main/packages/create-llama
- ãƒªã‚³ãƒ¼ãŒLlama-2-13Bã‚’ãƒ™ãƒ¼ã‚¹ã«é«˜æ€§èƒ½ãªæ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«Ricor-13Bã‚’é–‹ç™º
	- https://x.com/umiyuki_ai/status/1753312415503245762?s=20
	- ãŸã ã—ã‚ªãƒ¼ãƒ—ãƒ³ã«ã¯ã—ãªã„ã€‚é¡§å®¢ä¼æ¥­ã®æ¥­ç¨®ã«åˆã‚ã›ã¦ã‚«ã‚¹ã‚¿ãƒ ï¼ˆå¾®èª¿æ•´ãªã®ã‹ï¼ŸRAGãªã®ã‹ï¼Ÿï¼‰ã—ã¦ã‚¯ãƒ©ã‚¦ãƒ‰ã§æä¾›ã™ã‚‹B2Bãƒ“ã‚¸ãƒã‚¹ã‚’é–‹å§‹
- 2024å¹´1æœˆ30æ—¥ å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã«ãŠã‘ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¸ã®å”åŠ›ã«ã¤ã„ã¦
	- https://www.ndl.go.jp/jp/news/fy2023/240130_01.html
	- å›½ä¼šå›³æ›¸é¤¨ã¯å›½å†…ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–äº‹æ¥­ã‚’ã‚„ã£ã¦ãŸã‘ã©ã€ã“ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã®æ•°åå„„ä»¶ã®URLã‚’å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã«æä¾›ã™ã‚‹ã‚“ã ã£ã¦ã€‚å›½ç«‹æƒ…å ±å­¦ç ”ç©¶æ‰€ã¯ã“ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚³ãƒ¼ãƒ‘ã‚¹ä½œã£ã¦LLMæ§‹ç¯‰ã«ä½¿ã†ã‚“
	- https://x.com/umiyuki_ai/status/1753651801688273040?s=20
-  KARAKURI LMã®è§£èª¬
	- https://medium.com/karakuri/karakuri-lm%E3%81%AE%E8%A7%A3%E8%AA%AC-4b6cf9c3d40f
	- KARAKURI LMã¯ã€Llama 2ã‚’åŸºã«é–‹ç™ºã—ãŸäº‹å‰å­¦ç¿’æ¸ˆã¿è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
	- æ—¥æœ¬èªã®èªå½™ã‚’è¿½åŠ ã—ã€æ—¥æœ¬èªã¨å¤šè¨€èªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ··ãœã¦è¿½åŠ ã®äº‹å‰å­¦ç¿’ã‚’è¡Œã†ã“ã¨ã§ã€Llama 2ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’å¼·åŒ–ã—ã¦ã„ã¾ã™ã€‚
	- KARAKURI LM Chatã¯ã€KARAKURI LMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™
	- å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ç‹¬è‡ªã§é–‹ç™ºã—ãŸéå…¬é–‹ã®ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ··ãœã¦å­¦ç¿’ã•ã›ã¦ã„ã¾ã™ã€‚
- ã€Œãƒã‚¹ãƒˆï¼•ï¼§æƒ…å ±é€šä¿¡ã‚·ã‚¹ãƒ†ãƒ åŸºç›¤å¼·åŒ–ç ”ç©¶é–‹ç™ºäº‹æ¥­ï¼ãƒã‚¹ãƒˆï¼•ï¼§æƒ…å ±é€šä¿¡ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã€
	- NEDOãŒå›½å†…ã®ç”ŸæˆAIã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®ãŸã‚ã«å®Ÿæ–½ã—
	- ABEJAã€Sakana AIã€NIIã€ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ã€Turingã€æ±äº¬å¤§å­¦ã€Preferred Elements
	- Preferred Elementsï¼ˆPFEï¼‰ãŒã€çµŒç”£çœã¨NEDOãŒé–‹å§‹ã™ã‚‹ã€ŒGENIACï¼ˆGenerative AI Accelerator Challengeï¼‰ã€ã«ãŠã„ã¦ã€1000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã¨ã€1å…†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’ã®æ¤œè¨¼ã‚’é–‹å§‹ã—ã¾ã™ã€‚
	- æ±å¤§æ¾å°¾ç ”ã€ NEDOã®æ¡æŠã‚’å—ã‘ã€å…¬é–‹å‹ã§ã®500å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚’é–‹å§‹ã—ã¾ã™ã€‚
- A decoder-only foundation model for time-series forecasting
	- https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities.
	- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§æ™‚ç³»åˆ—äºˆæ¸¬ï¼Ÿï¼ŸgoogleãŒã‚‚ã¤å¤§é‡ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç‰¹ã«ã‹ãå­¦ç¿’ï¼Ÿï¼Ÿ
	- ã‚ã‚‰ã‚†ã‚‹æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’Decoder-onlyã®ãƒ¢ãƒ‡ãƒ«ã«ã¶ã£è¾¼ã‚“ã§æ™‚ç³»åˆ—äºˆæ¸¬ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ä½œã‚‹è©±
- Ollama vision is here
	- https://x.com/ollama/status/1753530905069748506?s=20
- Googleã¨OpenAIã¯ã€Œå¾Œå‡ºã—ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã—ãŸã‚‚ã‚“å‹ã¡ã€ã‚’ç‹™ã£ã¦è† ç€çŠ¶æ…‹ï¼Ÿ
	- https://x.com/ImAI_Eruel/status/1753389879965429892?s=20
	- æœ€è¿‘AIç•ŒéšˆãŒå¦™ã«é™ã‹ã ã¨è¨€ã‚ã‚Œã¦ã‚‹ã‚„ã¤ï¼ŒGoogleã¨OpenAIãŒäº’ã„ã«ï¼Œã€ŒGemini Ultraã€ã¨ã€ŒGPT-4.5 or GPT-5ã€ã¨è¨€ã†åˆ‡ã‚Šæœ­ãŒæ—¢ã«ã»ã¼å…¬é–‹å¯èƒ½ãªçŠ¶æ…‹ãªã“ã¨ã‚’å®£è¨€ã—ã¦ã„ã¦ï¼Œä»Šã¾ã§ã®çµŒéã‚’è¦‹ã‚‹ã¨å¾Œã‹ã‚‰å…¬é–‹ã—ãŸæ–¹ãŒå¤©ä¸‹ã‚’å–ã£ã¦ã‚‹
-  karakuri-lm-70b-chatã‚’OpenAIäº’æ›ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒã¨ã—ã¦å‹•ã‹ã—ã¦ã¿ãŸ
	- https://qiita.com/takaaki_inada/items/3a22b982a3541e6f214c?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- karakuri-lm-70b-chatã®4bité‡å­ç‰ˆggufã‚’ãƒ­ãƒ¼ã‚«ãƒ«PCã§å‹•ã‹ã—ã¦ã¿ãŸ
	- json formatå‡ºåŠ›ãŒå‡ºæ¥ãŸã‚Šã€å°‘ã—è¤‡é›‘ãªsystem promptã‚‚åŠ¹ã„ã¦ãã‚Œã¦è‰¯ã„
	- text-generation-webui ã§OpenAIäº’æ›ã®ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒã¨ã—ã¦èµ·å‹•
	- GPUãƒ¡ãƒ¢ãƒªã«48/81ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†ãƒ¢ãƒ‡ãƒ«ã‚’ã®ã›ã¦ã‚µãƒ¼ãƒã‚’èµ·å‹•
-  WSL2ã¨llama.cppã§KARAKURI MLã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/n46ced665b378?sub_rt=share_h
- Corrective Retrieval Augmented Generation
	- https://arxiv.org/abs/2401.15884
	- Googleãªã©ã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMã®æ¤œç´¢ã«ãŠã‘ã‚‹æ­£ç¢ºæ€§ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆã€CRAGã€ï¼‰ã‚’ææ¡ˆ
	- æ¤œç´¢çµæœã‚’æ¤œè¨¼ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’å°å…¥ã™ã‚‹æ‰‹æ³•ã§
- Hugging FaceãŒGPT Storeã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ç‰ˆï¼ˆAssistantã¨ã„ã†å‘¼ç§°ï¼‰ã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://x.com/ytiskw/status/1753600673063784789?s=20
- Metaã€H100ã‚’35ä¸‡æ©Ÿãã‚ãˆã€OSSè²¢çŒ®ã«å¤§ããèˆµã‚’åˆ‡ã‚‹ã¨å…¬è¡¨ã€æ ªä¾¡ã¯ï¼’ï¼ï¼…ã‚¢ãƒƒãƒ—ï¼Ÿ
	- AI at Meta: 350k H100s by the end of the year, open source AI software infrastructure, new data centers with custom chips for AI inference serving hundreds of millions of users of AI tools.
	- https://x.com/ylecun/status/1753431180861419947?s=20
	- https://x.com/AIatMeta/status/1753195225311563848?s=20
-  Llama.cpp ã§ Karakuri LM ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n582c88a157e2?sub_rt=share_h
- Gemini Ultra 2/7ã«ãƒªãƒªãƒ¼ã‚¹ã®å¯èƒ½æ€§ã€‚
	- https://www.reddit.com/r/Bard/comments/1ahmsnf/advanced/
	- BardãŒGeminiã¨ã„ã†åå‰ã«å¤‰æ›´
	- Gemini Ultra 1.0ã§ã‚ã‚‹Gemini Advanced ãŒé–‹æ”¾ 
	- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ç­‰ã¯ä»Šå¾Œæ‹¡å¼µäºˆå®š 
	- GeminiãŒã‚¹ãƒãƒ›ã§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚


## 1/29

ä¸­å›½ã‚ªãƒªã‚ªãƒ³ã‚¹ã‚¿ãƒ¼ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ï¼ˆOrionStarï¼‰ã¨ã„ã†ä¼šç¤¾ã‹ã‚‰æ–°æ˜ŸLLMã§ã‚ã‚‹Orionç™»å ´ã€æ—¥æœ¬èªã‚„éŸ“å›½èªãŒå¾—æ„ãªã®ã¨é•·æ–‡ãƒ¢ãƒ‡ãƒ«ã‚’æŒã£ã¦ã„ã‚‹ã€ä¸­è¯LLMã¯æ—¥æœ¬èªã‚‚å¾—æ„ã£ã¦ã®ã¯ã‚ˆãè¨€ã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã€æ¨è«–é«˜é€Ÿã§å›ç­”ã‚‚è‡ªç„¶ã§è‰¯ã„æ„Ÿã˜ã ãã†ã ã€‚LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚‚ã€RLHFã«ä»£ã‚ã£ã¦ã€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã¤ã‹ã£ãŸã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®è‡ªå‹•åŒ–DPOãŒã¯ã‚„ã£ã¦ããŸã€Metaã®æœ¬å®¶ã¨ã¯é•ã†DPOã®å®Ÿè£…ã‚‚å‡ºã¦ããŸã—ã€CALM2ã‚’DPOã—ãŸãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¬é–‹ãªã©ã‚‚ã‚ã£ãŸã€‚DPOã«å¿…è¦ãªå—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè‡ªä½“ã®æ§‹ç¯‰æ”¯æ´KTOãªã©ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆé–¢ä¿‚ã®é€²æ—ãŒç›®ç«‹ã¤ã€‚MoEã®æ§‹ç¯‰ã‚‚Colabã®ç„¡æ–™æ ã§å®Ÿç¾ã™ã‚‹äº‹ä¾‹ãŒå‡ºã¦ããŸã€Sparseæ€§ãŒãƒã‚¤ãƒ³ãƒˆãªã®ã‹ã€‚æ—¢å­˜ã®LLMã‚’èåˆã•ã›ã¦å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹ã€ŒçŸ¥è­˜èåˆã€ã£ã¦ã®ãŒå‡ºã¦ããŸã€åˆä½“ã¨ã„ã†ã‚ˆã‚Šã€ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨è’¸ç•™ã«è¿‘ã„æ„Ÿã˜ã‚‰ã—ã„ã€‚LLMã®ç ”ç©¶ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ã€1)Synthetic training dataã€2)LLM safetyã€3)Knowledge injectionã®ï¼“ã¤ã ãã†ã ã€‚Phi-2ã£ã¦1)Synthetic training dataãŒç‰¹å¾´ã‹ã¨ãŠã‚‚ã£ã¦ãŸã®ã«ã€3)Knowledge injectionãŒã†ã¾ãå‹•ã„ãŸä¾‹ã§ã‚‚ã‚ã‚‹ã®ã­ã€‚DPOã¯ã‚‚ã¡ã‚ã‚“ã€2)LLM safetyã¨é–¢ä¿‚ã‚ã‚‹ã€‚AIãŒè‡ªåˆ†è‡ªèº«ã«å ±é…¬ã‚’ä¸ãˆã¦é€²åŒ–ã™ã‚‹ã€Œè‡ªå·±å ±é…¬å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã€ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ãŒã€ç¹°ã‚Šè¿”ã—ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦æ”¹å–„ã•ã‚Œã‚‹ã¨ã®ã“ã¨ã€è‡ªçµ¦è‡ªè¶³ãƒ¢ãƒ‡ãƒ«ã‹ã€‚åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã€é ˜åŸŸã‚’çµã£ãŸãƒ¢ãƒ‡ãƒ«ãŒé«˜æ€§èƒ½ã§ã‚ã£ãŸã‚Šã€Q&Aã‚¿ã‚¹ã‚¯ã«çµã£ã¦llama2ã‚’ï¼’æ®µéšã®æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€GPT-4ã«è¿«ã‚‹çµæœãªã©ã€ãã‚Œã¯ãã†ã ãŒãã‚Œã‚’ç¢ºã‹ã‚ãŸã®ãŒå°Šã„ã€‚LeCunå…ˆç”Ÿã«ã‚ˆã‚‹ã¨ã€DGNNã®è«–æ–‡ã§ã©ã“ã«ã‚‚æŠ•ç¨¿ã—ã¦ãªã‹ã£ãŸã®ã‹ã€‚ã€‚OpenAIã® æ–°ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ  ã¨ APIã®æ›´æ–°ã‚‚ã‚ã‚Šã¾ã—ãŸã€å®‰ããªã£ã¦æ€§èƒ½ãŒä¸ŠãŒã‚‹ã€OpenAIã¡ã‚ƒã‚“ã¨ä»•äº‹ã—ã¦ã¾ã™ã­ã€‚LangGraphã£ã¦LCELã®æ‹¡å¼µã ã£ãŸã®ã‹ã€ã‚¢ãƒ­ãƒ¼è¨€èªã¨ã‹ãã†ã„ã†ã®ã«è¿‘ã„ã®ã‹ã‚‚ã€‚HuggingFaceã¨Googleã®ãƒ‘ãƒ¼ãƒˆãƒŠã‚·ãƒƒãƒ—ã€Colabç’°å¢ƒã¨ã‚ˆã‚Šå¯†ã«ãªã‚ŠAIã®æ°‘ä¸»åŒ–çš„ã«ã¯æœ—å ±ãªã‚ã‘ã§ã™ãŒã€Googleä½•ã‚’ç‹™ã£ã¦ã„ã‚‹ï¼ŸT4ã®æ™®åŠï¼Ÿï¼ŸMacã§LLMã®åˆ©ç”¨ã‚‚ç€å®Ÿã«é€²æ­©ã€MLXã§Xwin-70Bã®ggufãŒå‹•ãã“ã¨ãŒç¢ºèªã•ã‚ŒãŸã€‚ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚‚ColBERTã¨ã„ã†æ–°æ‰‹ãŒã‚ã‚‹ã®ã‹ï¼Ÿtrasformerã‚‚v4.37ã§Qwen2, Phi-2, SigLIPãªã©ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚

- Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine
	- https://arxiv.org/abs/2311.16452
	- Microsoftã‚ˆã‚Šã€ŒGPT-4ç­‰ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã€é ˜åŸŸã‚’çµã£ãŸãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒãã®é ˜åŸŸã§é«˜æ€§èƒ½ãªã®ã§ã¯ãªã„ã‹ï¼Ÿã€ã‚’èª¿ã¹ãŸè«–æ–‡ã€‚çµæœã€åŒ»ç™‚ã®å•é¡Œã§GPT-4ãŒMed-PaLM2ã‚’ä¸Šå›ã‚‹çµæœã«
- Orion-14B
	- https://github.com/OrionStarAI/Orion
	- ä¸­å›½ç™ºLLMã®æ–°æ˜Ÿ
	- 2.5Tå­¦ç¿’ã€æ—¥æœ¬èª100Bäº‹å‰å­¦ç¿’æ¸ˆ èªå½™ã‚µã‚¤ã‚ºã¯84,608 
	- é•·æ–‡ãƒ¢ãƒ‡ãƒ«ã¯ã€200k-320kå¯¾å¿œ RAGã€
	- function callingå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨æ„
- transformer v4.37
	- https://github.com/huggingface/transformers/releases/tag/v4.37.0
	- Release v4.37 Qwen2, Phi-2, SigLIP, ViP-LLaVA, Fast2SpeechConformer, 4-bit serialization, Whisper longform generation Â· huggingface/transformers Â· GitHub
-  DPO ã«ã‚ˆã‚‹LLMã®Preferenceãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° by npakaã•ã‚“
	- https://note.com/npaka/n/n8be32e899c8a?sub_rt=share_b
	- ã€ŒDPOã€(Direct Preference Optimization)ã€ã€ŒIPOã€(Identity Preference Optimization)ã€ã€ŒKTOã€(Kahneman-Taversky Optimization) ã¨ã„ã†3ã¤ã®æœ‰æœ›ãªLLMã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®è©•ä¾¡
	- DPO
		- ã€Œ**DPO**ã€ã¯LLMã‚’äººé–“ã¾ãŸã¯AIã®å¥½ã¿ã«åˆã‚ã›ã‚‹ãŸã‚ã®æœ‰æœ›ãªä»£æ›¿æ‰‹æ®µã¨ã—ã¦æµ®ä¸Šã—ã¦ã„ã¾ã™ã€‚ã€Œå¼·åŒ–å­¦ç¿’ã€ã«åŸºã¥ãå¾“æ¥ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã¯ç•°ãªã‚Šã€ã€ŒDPOã€ã¯ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®å®šå¼åŒ–ã‚’ã€å—œå¥½ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§ç›´æ¥æœ€é©åŒ–ã§ãã‚‹å˜ç´”ãªæå¤±é–¢æ•°ã¨ã—ã¦å†æ§‹æˆã—ã¾ã™ã€‚
		- ã“ã‚Œã«ã‚ˆã‚Šã€ã€ŒDPOã€ã¯ä½¿ã„ã‚„ã™ããªã‚Šã€ã€ŒZephyrã€ã‚„ã€ŒNeuralChatã€ãªã©ã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã§æˆåŠŸã—ã¦ã„ã¾ã™ã€‚
	- IPO
		- ã€ŒDPOã€ã®æ¬ ç‚¹ã®1ã¤ã¯ã€å„ªå…ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã™ãã«éå‰°é©åˆã™ã‚‹å‚¾å‘ãŒã‚ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã€ã€ŒGoogle DeepMindã€ã¯ã€ŒIPOã€ã‚’å°å…¥ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã€ŒDPOã€æå¤±ã«æ­£å‰‡åŒ–é …ãŒè¿½åŠ ã•ã‚Œã€æ—©æœŸåœæ­¢ãªã©ã®ãƒˆãƒªãƒƒã‚¯ã‚’å¿…è¦ã¨ã›ãšã«ãƒ¢ãƒ‡ãƒ«ã‚’åæŸã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
	- KTO
		- ContextualAIã¯æœ€è¿‘ã€ã€ŒKTOã€ã¨å‘¼ã°ã‚Œã‚‹èˆˆå‘³æ·±ã„ä»£æ›¿æ¡ˆã‚’ææ¡ˆã—ã¾ã—ãŸã€‚ã“ã‚Œã¯ã€ã€Œgoodã€ã¾ãŸã¯ã€Œbadã€ã¨ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸå€‹ã€…ã®ä¾‹ã«é–¢ã—ã¦æå¤±é–¢æ•°ã‚’å®Œå…¨ã«å®šç¾©ã™ã‚‹ã‚‚ã®ã§ã™ã€‚ã“ã‚Œã‚‰ã®ãƒ©ãƒ™ãƒ«ã¯å–å¾—ã™ã‚‹ã®ãŒã¯ã‚‹ã‹ã«ç°¡å˜ã§ã‚ã‚Šã€ã€ŒKTOã€ã¯æœ¬ç•ªç’°å¢ƒã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ç¶™ç¶šçš„ã«æ›´æ–°ã™ã‚‹æœ‰æœ›ãªæ–¹æ³•ã«ãªã‚Šã¾ã™ã€‚
- LLMã®RLHFâ†’DPOâ†’KTOã£ã¦ãƒˆãƒ¬ãƒ³ãƒ‰ã®æµã‚Œã‚’æŠ‘ãˆã‚ˆã† by ã†ã¿ã‚†ã
	- https://x.com/umiyuki_ai/status/1749670491227672797?s=20
	- ã‚ªãƒ¼ãƒ—ãƒ³LLMã¯ãã‚“ãªé‡‘ã‹ã‘ã¦RLHFã‚„ã‚‹ãªã‚“ã¦ç„¡ç†ã ã£ãŸã€‚ãã“ã§ç™ºæ˜ã•ã‚ŒãŸã®ãŒDPOã ã€‚
	- DPOã¯äººåŠ›ã§è©•ä¾¡ã™ã‚‹å¿…è¦ãŒç„¡ã„ã‹ã‚‰ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‰ãªã„ã€‚ä»£ã‚ã‚Šã«â€å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆâ€ã‚’ç”¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã£ã¦ã®ã¯ã€ã‚ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒä¸ãˆã‚‰ã‚ŒãŸæ™‚ã®äºŒã¤ã®å›ç­”ãŒã‚ã£ã¦ã€ã“ã£ã¡ã®å›ç­”ã®æ–¹ãŒã‚¤ã‚±ã¦ã¦ã€ã“ã£ã¡ã®æ–¹ãŒè‰¯ããªã„ã€‚ã¿ãŸã„ãªãƒ‡ãƒ¼ã‚¿ãŒå¤§é‡ã«ç”¨æ„ã•ã‚Œã¦ã‚‹ãƒ¢ãƒã€‚RLHFã¨DPOã¯æ•°å­¦çš„ã«ç­‰ä¾¡ã§ã‚ã‚‹äº‹ãŒã‚­ãƒƒãƒãƒªè¨¼æ˜ã•ã‚Œã¦ã‚‹ã€‚
	- å—œå¥½ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã‹è¨€ã‚ã‚Œã¦ã‚‚ã€ãã‚“ãªã‚‚ã‚“ç”¨æ„ã™ã‚‹ã®ã ã£ã¦ã¾ã ã¾ã æ‰‹é–“ãŒã‹ã‹ã£ã¦å¤§å¤‰ã ã€‚ãã†ã„ã†ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œã‚’ã©ã†ã«ã‹ã™ã‚‹æ–°ã—ã„ãƒ†ã‚¯ãŒKTOã€‚KTOã§ã¯å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å›ç­”ãŒã‚ã£ã¦ã€ãã®å›ç­”ã«ã€Œã„ã„ã­ã€ã‹ã€Œã‚ˆããªã„ã­ã€ã®è©•ä¾¡ã ã‘ä»˜ã„ã¦ã‚Œã°ã„ã„ã€‚
	- KTOã«ã‚ˆã£ã¦LLMã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆä½œæ¥­ã¯ç›¸å½“ç°¡å˜ã«ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã‚ã‘ã ã€‚ãŸã ã€ãã†ã‚„ã£ã¦ä½œã£ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒæ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€ã‚„ã£ã±KTOã‚ˆã‚ŠDPOã®æ–¹ãŒã‚„ã‚„é«˜æ€§èƒ½ã¿ãŸã„ã 
- GoogleDeepmindãŒSpatialVLMã‚’ç™ºè¡¨
	- ã¾ã§ã®è¦–è¦šè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ç©ºé–“æ„Ÿè¦šã«æ¬ ã‘ã¦ã„ãŸã€‚ä¾‹ãˆã°ã€Œå†™çœŸã«å†™ã£ã¦ã‚‹ãƒãƒƒã‚¿ãƒ¼ã¨å¯©åˆ¤ã®è·é›¢ã¯ä½•ãƒ¡ãƒ¼ãƒˆãƒ«ï¼Ÿã€ã¨ã‹è¨Šã„ã¦ã‚‚ç­”ãˆã‚‰ã‚Œã‚“ã‹ã£ãŸã€‚ãã‚Œã‚’æ”¹å–„ã—ãŸã®ãŒSpatialVLMã€‚
- makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
	- https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch
	- Colabã‚‚å…¬é–‹ã—ã¦ãã‚Œã¦ã„ã‚‹ã®ã§ç„¡æ–™ç‰ˆColabã®T4ã§ã‚‚å‹•ã‹ã›ã¾ã™ã€‚max_itersã‚’500ãã‚‰ã„ã«ä¿®æ­£ã™ã‚Œã°æ‰€è¦æ™‚é–“ã‚‚10åˆ†ç¨‹åº¦
	- ãŸã ã—ã€æœ€å¾Œã‹ã‚‰3ç•ªç›®ã®ã‚»ãƒ«ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¦ä¿®æ­£ 
		- metrics = {"train_loss": losses['train'], "val_loss": losses['val']} ã€€
		- â†“ metrics = {"train_loss": float(losses['train']), "val_loss": float(losses['val'])}
- æ·±å±¤å­¦ç¿’ã®åŸç†ã‚’æ˜ã‚‰ã‹ã«ã™ã‚‹ç†è«–ã®è©¦ã¿ã€€by ä»Šæ³‰ã•ã‚“
	- https://drive.google.com/file/d/1bNN6VjsgdpJAqxvZ4EKAPpMGq9wfjHqf/view
	- ã€Œãªãœæ·±å±¤å­¦ç¿’ã§ã†ã¾ãã„ãã®ã‹ã€ã¨ã„ã†ç´ æœ´ãªç–‘å•ã«å¯¾ã—ã€ç†è«–çš„ã«ã‚ã‹ã£ã¦ã„ã‚‹ã“ã¨ã‚’å¹³æ˜“ã«è§£èª¬ã—ãŸã‚¹ãƒ©ã‚¤ãƒ‰ã€‚éå¸¸ã«ã‚ã‹ã‚Šã‚„ã™ã„ã€‚
- Orion-14B-Chat-Int4 ã‚’è©¦ã™ã€‚
	- https://huggingface.co/OrionStarAI/Orion-14B-Chat-Int4
	- https://note.com/npaka/n/nd5025f5f7ac1?sub_rt=share_h
	- æ¨è«–é«˜é€Ÿã§å›ç­”ã‚‚è‡ªç„¶ã§è‰¯ã„æ„Ÿã˜ã€‚ ãƒ­ãƒ³ã‚°ãƒãƒ£ãƒƒãƒˆç”¨ã€RAGç”¨ã€Function Callingç”¨ãªã©ã‚‚ã‚ã‚‹
-  RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture
	- https://arxiv.org/abs/2401.08406
	- Microsoftã‚ˆã‚Šè¾²æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’ä¾‹ã«ã€LLMã§RAGã¨Fine-Tuningã‚’æ¯”è¼ƒåˆ†æã—ãŸè«–æ–‡ã€‚
	- æ¯”è¼ƒçµæœã®è¦ç´„ã¯è¡¨22-23ã®é€šã‚Š(å›³å¼•ç”¨)ã€‚åŒæ–¹ã®ä½¿ã„åˆ†ã‘ãƒã‚¤ãƒ³ãƒˆã¯è¡¨23ã®æœ€ä¸‹è¡Œã«ã‚ã‚Šã€‚
- AIãŒè‡ªåˆ†è‡ªèº«ã«å ±é…¬ã‚’ä¸ãˆã¦é€²åŒ–ã™ã‚‹ã€Œè‡ªå·±å ±é…¬å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã€ã€€ç±³Metaãªã©ãŒé–‹ç™ºã€å®Ÿé¨“ã§GPT-4ã‚’ä¸Šå›ã‚‹ã€ç ”ç©¶ç´¹ä»‹ã€‘
	- https://levtech.jp/media/article/column/detail_374/
	- ã“ã®è¨“ç·´æ–¹æ³•ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®æŒ‡ç¤ºã«å¾“ã†èƒ½åŠ›ã¨å ±é…¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°èƒ½åŠ›ãŒåå¾©ã”ã¨ã«å‘ä¸Šã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚ŒãŸã€‚
	- ãƒ¢ãƒ‡ãƒ«ã¯ã€è‡ªåˆ†ã®ç­”ãˆã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ã¨åŒæ™‚ã«ã€è‡ªåˆ†è‡ªèº«ã®å ±é…¬ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã‚‚æ©Ÿèƒ½ã€‚é€šå¸¸ã¯å›ºå®šã•ã‚Œã¦ã„ã‚‹å ±é…¬ãƒ¢ãƒ‡ãƒ«ãŒã€ç¹°ã‚Šè¿”ã—ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’é€šã˜ã¦æ”¹å–„ã•ã‚Œã‚‹ã€‚
	- **ã“ã‚Œã¯ã€äººé–“ãªã©ã®å¤–éƒ¨ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä¸è¦ã«ã—ã€å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒè‡ªåˆ†è‡ªèº«ã‚’ã‚ˆã‚Šã‚ˆãæ”¹å–„ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’æ„å‘³ã—ã€è‡ªå·±æ”¹å–„ã®å¥½å¾ªç’°ã‚’ç”Ÿã¿å‡ºã™ã€‚**
- Summarize gigantic JSON datasets in seconds with JSONalyze, our latest query engine: 
	- https://docs.llamaindex.ai/en/latest/examples/query_engine/JSONalyze_query_engine.html
	- JSONãŒå·¨å¤§ã«ãªã‚‹ã¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒè†¨å¤§ã«ãªã‚‹ã®ã§ã€åœ§ç¸®ï¼Ÿã™ã‚‹ã‚‰ã—ã„
-  Self-Rewarding Language Model (wip)
	- https://github.com/lucidrains/self-rewarding-lm-pytorch
	- Metaã®DPOã®ã€ç‹¬ç«‹å®Ÿè£…ãŒç™»å ´ã‚‰ã—ã„
- ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒãƒ¼ãƒ ãƒ¡ã‚¤ãƒˆåŠã³å¯¾æˆ¦ç›¸æ‰‹ã®èƒ½åŠ›ã‚’è€ƒæ…®ã—ãŸãƒã‚¼ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ããƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®èƒ½åŠ›è©•ä¾¡æŒ‡æ¨™
	- https://www.jstage.jst.go.jp/article/jscswabun/36/2/36_99/_article/-char/ja/
	- æ»‹è³€å¤§æ™‚ä»£ã®å­¦ç”Ÿã‚„åŒåƒšãŸã¡ã¨æ›¸ã„ãŸãƒã‚¹ã‚±ãƒƒãƒˆãƒœãƒ¼ãƒ«é¸æ‰‹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã«é–¢ã™ã‚‹è«–æ–‡ãŒæ²è¼‰ã•ã‚ŒãŸã¨ã‚‰ã—ã„
-  WARM: On the Benefits of Weight Averaged Reward Models
	- https://huggingface.co/papers/2401.12187
	- Google Deepmind presents WARM
- GoogleColobã§å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(0.15B)ã®äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦ã¿ã‚‹
	- https://ayousanz.hatenadiary.jp/entry/2024/01/23/225623
	- äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«(0.15B)ã‚’ä½œã£ã¦ã¿ã¾ã—ãŸ ã¡ã‚ƒã‚“ã¨ä½¿ãˆã‚‹ãƒ¬ãƒ™ãƒ«ã«ã™ã‚‹ãŸã‚ã«ã¯ã€ç´„200å€ãã‚‰ã„ã‹ã‘ãªã„ã¨ã„ã‘ãªã„ã¿ãŸã„ã§ã™
- ChatGPTã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒ32kã«ãªã£ã¦ã‚‹ã‹ã‚‰é’ç©ºæ–‡åº«ã®å°èª¬ã¨ã‹ã‚’2ä¸‡æ–‡å­—ãã‚‰ã„ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ã—ã¦è‡ªåˆ†ã®ä»£ã‚ã‚Šã«èª­ã‚“ã§ã‚‚ã‚‰ã£ã¦å†…å®¹æ•™ãˆã¦ã‚‚ã‚‰ã†äº‹ã‚‚çµæ§‹ã§ãã‚‹ã€‚
	- ã¾ã‚Claudeãªã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·100kã ã‹ã‚‰ã‚‚ã£ã¨å¤§é‡ã®æ–‡ç« ã‚’ã¾ã¨ã‚ã¦èª­ã‚“ã§ã‚‚ã‚‰ãˆã‚‹
	- https://x.com/umiyuki_ai/status/1749775772850749556?s=20
- Knowledge Fusion of Large Language Models", ICLR 2024ã‚ˆã‚Š
	- https://arxiv.org/abs/2401.10491
	- æ—¢å­˜ã®LLMã‚’èåˆã•ã›ã¦å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹æ‰‹æ³•ã€ŒçŸ¥è­˜èåˆã€ãŒé–‹ç™º
	- æ··åˆãƒ¢ãƒ‡ãƒ«ã‚’æå”±ã™ã‚‹"Blending Is All You Need"ã¨ã¯ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãƒ»è©•ä¾¡æ–¹æ³•ã¨ã‚‚ã«ç•°ãªã‚‹ç ”ç©¶ã§ã™
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. ã€ŒLlama-2ã€ã€ŒOpenLLaMAã€ã€ŒMPTã€ã‚’èåˆã—ã¦ã€ŒFUSELLMã€ã‚’ä½œæˆã—ãŸ 
		- 2. ä¸‹è¨˜ã‚¿ã‚¹ã‚¯ã‚’ä¸­å¿ƒã«é¡•è‘—ã«æ€§èƒ½ãŒå‘ä¸Šã—ãŸ - è«–ç† - å¸¸è­˜ - ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
- LLMã®ç ”ç©¶ãƒˆãƒ¬ãƒ³ãƒ‰ã¯ä»¥ä¸‹ã®ï¼“ã¤
	- https://x.com/cwolferesearch/status/1749867258107543615?s=20
	- (1) Synthetic training data:
		- [1]ã§ã¯ã€æœ€å…ˆç«¯ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã«ã€åˆæˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
		- [2]ã§ã¯ã€æ•°å­¦ã¨ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å•é¡Œã«å¯¾ã—ã¦åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç°¡å˜ã«ç”Ÿæˆã—ã€æ¤œè¨¼ã™ã‚‹ã“ã¨ãŒã§ãã€LLMã®æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚
	- (2) LLM safety:
		- [3]ã®ç ”ç©¶ã§ã¯ã€LLMã«è¨“ç·´ã•ã‚ŒãŸãƒãƒƒã‚¯ãƒ‰ã‚¢æ”»æ’ƒã¯ã€åºƒç¯„ãªå®‰å…¨è¨“ç·´å¾Œã‚‚æŒç¶šã—ã€äººé–“ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’æ¬ºãã‚¹ãƒªãƒ¼ãƒ‘ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å½¢æˆã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™
		- [4]ã§ã€é©åˆ‡ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã•ãˆã‚ã‚Œã°ã€å¤šãã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’çµŒãŸLLMã§ã‚ã£ã¦ã‚‚ã€ã»ã¼å…¨ã¦ã®LLMã‹ã‚‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã§ãã‚‹ã“ã¨ã‚’å­¦ã³ã¾ã—ãŸã€‚
	- (3) Knowledge injection
		- [6]ã®è‘—è€…ã¯æ¤œç´¢æ‹¡å¼µä¸–ä»£ï¼ˆRAGï¼‰ã‚’ææ¡ˆã—ã€ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒçŸ¥è­˜é›†ç´„å‹ã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
		- LIMA [7]ã¯ã€LLMã®ã»ã¼å…¨ã¦ã®çŸ¥è­˜ãŒäº‹å‰å­¦ç¿’ä¸­ã«å­¦ç¿’ã•ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
		- Phi-1[8]ã¯ã€çŸ¥è­˜è±Šå¯ŒãªLLMãŒã€ã‚ˆã‚Šå°ã•ãªã€ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆã¤ã¾ã‚Šæ•™ç§‘æ›¸ï¼‰ã«å¯¾ã—ã¦å­¦ç¿’ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
-  Reading Analog Gauges
	- https://huggingface.co/spaces/Synanthropic/reading-analog-gauge
	- Simply Reading Analog Gauges â€“ GPT4, CogVLM Can't
	- This model reads analog dial gauge by detecting, applying perspective correction, and gauge reading. The model was build only with synthetic data (e.g. examples
- OpenAI GPT-4Vï¼ChatGPTï¼GPTs äººå·¥çŸ¥èƒ½ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å®Ÿè·µå…¥é–€
	- å¸ƒç•™å·ã•ã‚“ã®ã€æ–°åˆŠã€
	- https://wgn-obs.shop-pro.jp/?pid=179128392
	- æ˜¨å¹´11æœˆã®å¤§è¦æ¨¡ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆå¯¾å¿œã§ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚„GPTã‚¹ãƒˆã‚¢ãªã©ã®æ–°æ©Ÿèƒ½ã‚‚è§£èª¬ã—ã¦ã¾ã™ã€‚æŠ€è¡“ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒæ—©ã™ãã‚‹ã“ã¨ã‚‚ã‚ã‚Šã€PDFã®ã¿ã«ãªã‚Šã¾ã™ã€‚
- ChatQA: Building GPT-4 Level Conversational QA Models
	- https://arxiv.org/abs/2401.10225
	- GPT-4ãƒ¬ãƒ™ãƒ«ã®è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯æ€§èƒ½ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®Llama 2ã§å®Ÿç¾ã™ã‚‹æ–¹æ³•ãŒã€NVIDIAã‚ˆã‚Šç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚
	- é•·æ–‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å•ã„ã«ç­”ãˆã‚‹èƒ½åŠ›ã§GPT-3.5ã‚ˆã‚Šé¥ã‹ã«å‹ã‚‹çµæœãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚
	- â– æ–¹æ³•è«– ä»¥ä¸‹ã®ã‚ˆã†ãªï¼’æ®µéšã®æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã† 
		- 1. æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ï¼ˆsupervised fine-tuningï¼‰ 
		- 2. æ–‡è„ˆå¼·åŒ–ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ï¼ˆcontext-enhanced instruction tuningï¼‰
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. Llama-2ã‚’èª¿æ•´ã—ã¦ã€ŒChatQAã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ãŸ 
		- 2. é•·æ–‡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ãQAã‚¿ã‚¹ã‚¯ã§è©•ä¾¡ã—ãŸ 
		- 3. GPT-3.5ã®æ€§èƒ½ã‚’é¥ã‹ã«ä¸Šå›ã£ãŸ 4. GPT-4ã¨ã¯åŒç­‰ã¨è¨€ãˆã‚‹ãƒ¬ãƒ™ãƒ«ã ã£ãŸ
-  Prompt Engineering with Llama 2
	- https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=video
	- Introducing 'Prompt Engineering with Llama 2' â€” an interactive guide covering prompt engineering & best practices for developers, researchers & enthusiasts working with large language models.
- Ollama Python and JavaScript libraries
	- https://ollama.ai/blog/python-javascript-libraries
	- Both libraries make it possible to integrate new and existing apps with Ollama in a few lines of code, and share the features and feel of the Ollama REST API.
- CALM2ã‚’Direct Preference Optimization (DPO)ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ« calm2-7b-chat-dpo ã‚’CC-BY 4.0ã§å…¬é–‹ã—ã¾ã—ãŸã€‚
	- https://huggingface.co/cyberagent/calm2-7b-chat-dpo-experimental
	- calm2-7b-chat-dpoã‚’ELYZA-tasks-100ã¨Japanese MT-Benchã§è©•ä¾¡ã‚’è¡Œã£ãŸã¨ã“ã‚ã€CALM2ã‚ˆã‚Šã‚‚æ›´ã«é«˜ã„ã‚¹ã‚³ã‚¢ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ã„ã†çµæœã«ãªã‚Šã¾ã—ãŸ
	- ã¾ãŸã€ã‚ã‚ã›ã¦DPOã«ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’CC-BY 4.0ã§å…¬é–‹ã—ã¾ã—ãŸ
	- https://huggingface.co/datasets/cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental
- ä»Šæ›´ãªãŒã‚‰ï½¤GPT3.5ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸï½¡ 
	- https://x.com/kanhatakeyama/status/1750331895853039745?s=20
	- guiã§æ“ä½œã§ãã‚‹ã—ï½¤gpuãƒã‚·ãƒ³ã‚’ç”¨æ„ã—ãªãã¦è‰¯ã„ã—ï½¤éå¸¸ã«ãŠæ‰‹è»½ãªå°è±¡ã§ã—ãŸï½¡ 3ä¸¦åˆ—ã¾ã§å­¦ç¿’å›ã›ã¾ã—ãŸï½¡
	- 2,3æ™‚é–“ã®ä½¿ç”¨ã§ï½¤$30ã»ã©ã‹ã‹ã‚Šã¾ã—ãŸï½¡
-  LLM ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¾ã¨ã‚ by npakaã•ã‚“
	- https://note.com/npaka/n/n686d987adfb1?sub_rt=share_b
- Hugging Face and Google partner for open AI collaboration
	- https://huggingface.co/blog/gcp-partnership
	- We will collaborate with Google to foster open AI innovation across open science, open-source, cloud, and hardware
	- A collaboration for Google Cloud customers
	- A collaboration for Hugging Face Hub users
-  OpenAIã® æ–°ãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ  ã¨ APIã®æ›´æ–° by npakaã•ã‚“
	- https://note.com/npaka/n/nd8c5e9c65335?sub_rt=share_h
	- ãƒ»æ–°ã—ã„Embeddingãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ 
	- ãƒ»GPT-4 Turbo Previewã®æ›´æ–°
	- ãƒ»GPT-3.5 Turboã®æ›´æ–°
	- ãƒ»ãƒ¢ãƒ‡ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æ›´æ–°
	- ãƒ»APIã‚­ãƒ¼ã®ç®¡ç†æ–¹æ³•ã®æ”¹å–„
- å®Ÿã¯Swallowã¯baseãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®æ€§èƒ½ã¯ã„ã„ã§ã™ãŒã€instruct ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯public instruction datasetã‚’ä½¿ç”¨ã—ãŸã“ã¨ã‚‚ã‚ã‚Šã€baseãƒ¢ãƒ‡ãƒ«ã®é«˜ã„æ€§èƒ½ã®å‰²ã«ã¯ã‚ã¾ã‚Šé«˜ãã‚ã‚Šã¾ã›ã‚“
	- https://x.com/okoge_kaz/status/1750805452676608177?s=20
- CoTã®æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒLLMã®æ¨è«–èƒ½åŠ›ã«åŠã¼ã™å½±éŸ¿ã‚’è©³ç´°ã«æ¤œè¨¼ã—ãŸçµæœ
	- https://ai-data-base.com/archives/62364
	- GPT-4ãªã©ã®LLMã«æ€è€ƒã®é€£é–ï¼ˆCoTï¼‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã©ã§ã€Œè€ƒãˆã‚‹æ™‚é–“ã€ã‚’ä¸ãˆã‚‹ã¨åŸºæœ¬çš„ã«æ€§èƒ½ãŒå‘ä¸Šã—ã¾ã™ã€‚ 
	- ãã“ã§ä»Šå›ã€é©åˆ‡ãªæ¨è«–ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒæ¤œè¨¼ã•ã‚Œã¾ã—ãŸã€‚ è¨˜äº‹ã§ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã¨ã¨ã‚‚ã«çµæœã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚
-  MambaByte: Token-free Selective State Space Model
	- https://arxiv.org/abs/2401.13660
	- MambaByteã¯ã€MambaãŒé•·ã„ç³»åˆ—ã‚‚æ‰±ãˆã‚‹ãŸã‚ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã›ãšãƒã‚¤ãƒˆå˜ä½ã§è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚åŒç­‰ã®è¨ˆç®—é‡ã€ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ä¸è¦ã®MegaByteã‚„é€šå¸¸ã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–Transformerã¨æ¯”ã¹æ€§èƒ½ã§ä¸Šå›ã‚Šã€1/3ã®æŠ•å…¥è¨ˆç®—é‡ã§Transformerã®æå¤±ã«åˆ°é”ã€‚å°è¦æ¨¡å®Ÿé¨“ã®çµæœã ãŒæœ‰æœ›
-  Dense X Retrieval: What Retrieval Granularity Should We Use?
	- https://arxiv.org/abs/2312.06648
	- The "Dense X Retriever" paper shows that it significantly outperforms the traditional chunk-based retriever
-  Deep Convolutional Networks on Graph-Structured Data
	- https://arxiv.org/abs/1506.05163
	- My most-cited, never-accepted, ArXiv-only paper has over 1880 citations. "Deep Convolutional Networks on Graph-Structured Data" Mikael Henaff, Joan Bruna, Yann LeCun
-  FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- https://huggingface.co/papers/2401.14112
	- Microsoft presents FP6-LLM 
	- Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality
- çŸ¥è­˜èåˆã€å›³ã‚’è¦‹ã‚‹ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚„Mixture of Expertsã¨ã¯é•ã£ã¦æœ¬å½“ã«çŸ¥è­˜ãã®ã‚‚ã®ã‚’æŠ½å‡ºã—ã¦ã„ã‚‹æ„Ÿã˜ã‹ã€‚ã©ã¡ã‚‰ã‹ã¨ã„ã†ã¨è’¸ç•™ã«è¿‘ã„æ„Ÿã˜ã‚‚ã‚ã‚Šç”»æœŸçš„ãªæ‰‹æ³•ã®ã‚ˆã†ã«æ€ãˆã‚‹ã€‚
	- https://x.com/koheiichi/status/1751060499310301550?s=20
- Python library that adds Generative AI capabilities to Pandas
	- https://github.com/gventuri/pandas-ai
	- Introducing PandasAI, now you can analyze complex data frames and plot visualizations just by using natural language
- XWin 70B ã§ LLM å‡ºåŠ›æ—¥æœ¬èªæ–‡ç« ã®è‡ªå‹•è©•ä¾¡ã‚’è¡Œã†è©¦ã¿
	- https://zenn.dev/syoyo/articles/4f4f8645af1cee
	- æ—¥æœ¬èª LLM ã®è‡ªå‹•è©•ä¾¡(ELYZAã¡ã‚ƒã‚“ task 100 ã¨ã‹)ã‚’ãƒ­ãƒ¼ã‚«ãƒ« LLM ã§è¡Œã„ãŸã„.ç¾æ™‚ç‚¹ã§æœ€é«˜æ€§èƒ½ã®ä¸€ã¤XWin 70B ã§ã®è©•ä¾¡è©¦ã—ã¾ã—ãŸ!
	- ãã“ãã“ã„ã„æ„Ÿã˜ã«ãªã£ãŸã‚ˆâœŠ
	- ã§ã‚‚ prompt ä¸Šæ‰‹ãä½œã‚‹å¿…è¦ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã‚ˆ
- åŒã˜ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚ãƒ¢ãƒ‡ãƒ«ï¼ˆã“ã®å ´åˆã¯ã‚«ãƒ¼ãƒãƒ«ï¼‰ãŒç•°ãªã‚Œã°äºˆæ¸¬ãŒå¤‰ã‚ã‚‹ã¨ã„ã†è©±ã€‚ã“ã†ã„ã†ã“ã¨ã‚’è‰²ã€…å®Ÿç¾ã—ãŸã„å ´åˆã¯ã‚„ã£ã±ã‚Šã‚¬ã‚¦ã‚¹éç¨‹ãŒã‚„ã‚Šã‚„ã™ã„ã§ã™ã€‚ by é ˆå±±å…ˆç”Ÿ
	- https://x.com/sammy_suyama/status/1751104980189413880?s=20
-  Google Colab ã§ LangGraph ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n053a3cb78311?sub_rt=share_h
	- ã€Œ**LangGraph**ã€ã¯ã€LLMã§ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«ãªã€Œ**ãƒãƒ«ãƒã‚¢ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**ã€ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ã€Œ**LCEL**ã€(LangChain Expression Language) ã‚’æ‹¡å¼µã—ã¦ã€è¤‡æ•°ãƒã‚§ãƒ¼ãƒ³ (ã¾ãŸã¯ã‚¢ã‚¯ã‚¿ãƒ¼) ã‚’è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã«ã‚ãŸã£ã¦å¾ªç’°çš„ã«å”èª¿å‹•ä½œã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™
	- ã€ŒLangGraphã€ã«ã‚ˆã£ã¦ã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«**ã‚µã‚¤ã‚¯ãƒ«**ã‚’ç°¡å˜ã«å°å…¥ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
- MLXã§Xwin-70Bã®ggufãŒå‹•ãã“ã¨ã‚’ç¢ºèª
	- https://x.com/npaka123/status/1751139720367862193?s=20
	- Apple M3 Max
-  google/siglip-base-patch16-256-multilingual ã‚’ä½¿ã£ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã®ç”»åƒã‚’æ—¥æœ¬èªã§æ¤œç´¢ã—ã¦ã¿
	- https://note.com/eurekachan/n/n9d4f62b80ad6?sub_rt=share_pb
	- 1æœˆã«ã€Googleã‹ã‚‰ã€SigLIPã¨ã„ã†ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¸¡æ–¹ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦æ‰±ã†ã“ã¨ãŒã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã®multilingualç‰ˆï¼ˆå¤šè¨€èªå¯¾å¿œç‰ˆï¼‰ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚transformers 4.37ä»¥é™ã§å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚æ—¥æœ¬èªã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚
-  Are Transformers Effective for Time Series Forecasting?
	- https://arxiv.org/abs/2205.13504
- ColBERT superior to traditional embedding models
	- https://x.com/marktenenholtz/status/1751406680535883869?s=20
	- ã‚¯ã‚¨ãƒªã¨æ–‡æ›¸ã‚’ãã‚Œãã‚Œåˆ¥ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã§åŸ‹ã‚è¾¼ã¿ã€ã‚¯ã‚¨ãƒªä¸­ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã¨æ–‡æ›¸ã®å„ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã®é–“ã§æœ€å¤§é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã€ãã®ç·å’Œã‚’ã‚¹ã‚³ã‚¢ã¨ã—ã¦ã„ã¾ã™ã€‚
- miniature ColBERT model in your browser
	- https://colbert.aiserv.cloud/
- DSPy lets you prototype LLM Programs like AlphaCodium in 2 minutes!
	- https://x.com/CShorten30/status/1751656468879708496?s=20

## 1/22

ä»Šé€±ã¯Davosä¼šè­°ãŒã‚ã£ã¦ã€ã‚ã‚Œã‚‰ã®ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã‚‚ç™»å ´ã€GPT-5ã«ã¤ã„ã¦è¨€åŠã€‚Metaã‹ã‚‰ã¯ã‚¶ãƒƒã‚«ãƒ¼ãƒãƒ¼ã‚°æ°ãŒãƒ“ãƒ‡ã‚ªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã„ããªã‚ŠLlama3ã®OSSã¨ã—ã¦ã®é–‹ç™ºå®£è¨€ã€‚NVIDIAãŒCESã§ç™ºè¡¨ã—ãŸGeForce RTX 4070 SUPERãŒç™ºå£²ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMç•Œéšˆã®ä¾¡æ ¼ç ´å£ŠãŒã€ã€ã€ã€‚MoEã‚‚ä»Šé€±ã‚‚ã«ãã‚„ã‹ã€åœ§ç¸®ã—ã¦å°ãƒ¡ãƒ¢ãƒªåŒ–ã™ã‚‹ã‚ˆã†ãªMC-SMoEã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã‹ã€è² è·åˆ†æ•£ã‚’èª¿æ•´ã™ã‚‹DeepSeekMoEã¨ã‹ã€youri-2x7bã®ggufãŒã§ãŸã‚Šã¨ã‹ã¨ã«ã‹ãè³‘ã‚„ã‹ã€‚å°è¦æ¨¡LLMå‘ã‘ã®äººå·¥çš„ã«ç”Ÿæˆã•ã‚ŒãŸå­¦ç¿’ç”¨ãƒ¢ãƒ‡ãƒ«tiny-textbookã‚·ãƒªãƒ¼ã‚ºã‚‚å……å®Ÿã—ã¦ãã¦ã€å°è¦æ¨¡LLMã®é–‹ç™ºã‚‚åŠ é€Ÿã™ã‚‹ã‹ãªã€‚æ‰‹ãŒå±Šãã¨ã“ã‚ã§ã¯nanoGPTã®æºæ°ç‰©èªã®é©ç”¨ä¾‹ã¯æ¥½ã—ãã†ã€‚å°è¦æ¨¡LLMã‚’é›†ã‚ã¦å„ªã‚ŒãŸAIã‚’ä½œã‚‹ã¨ã„ã†æ„å‘³ã§ã¯ã€sakana.aiãŒè¯ã€…ã—ã45å„„å††ã‚‚ã®æŠ•è³‡ã‚’èª¿é”ã€googleãªã©ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ç ”ç©¶è€…ãŒçµ‚çµã—ã¦æ¥½ã—ãã†ã€‚sakana.aiã¯å°ã•ãªé­šãŒé›†ã¾ã£ã¦ä¸€åŒ¹ã®å¤§é­šã®ã‚ˆã†ã«æ³³ãç‰©èªï½¢ã‚¹ã‚¤ãƒŸãƒ¼ï½£ã®ä»•çµ„ã¿ãªã‚ã‘ã ã‘ã©ã€å°ã•ãªå°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚ã¤ã¾ã£ã¦å•é¡Œã‚’è§£æ±ºã™ã‚‹ã£ã¦ã“ã¨ãªã‚‰ã€å¤ã„äººã«ã¯ãƒŸãƒ³ã‚¹ã‚­ãƒ¼å¾¡å¤§ã®Society o MindsãŒæ€ã„å‡ºã•ã‚Œã‚‹ã€‚Microsoftã¯Coliplot Proã‚’ãƒªãƒªãƒ¼ã‚¹ã€æœˆ20ãƒ‰ãƒ«ã§ã€å€‹äººãŒã€GPT-4 Turboã«ã‚‚ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã—Office 365 Copilotã‚‚ä½¿ãˆã‚‹ã—ãŠå¾—ã‹ã‚‚ã€ä¸€æ–¹ãŒã£ã‹ã‚Šã—ãŸã¨ã„ã†ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„è¦‹ã‚‚ã¡ã‚‰ã»ã‚‰ã€‚ã§ã‚‚å°è¦æ¨¡LLMã®ä»£è¡¨æ ¼phi-2ã¯ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰ã§ã¦ã„ã‚‹ã‹ã‚‰ã€OpenAI/Copilotä¸€è¾ºå€’ã§ã¯å®Ÿã¯ãªã„ã€‚ä¸€æ–¹ãƒ¡ã‚¿ã¯ï¼’ä¸‡äººã‚’ãƒ¬ã‚¤ã‚ªãƒ•ã—ã¦ã€ä»£ã‚ã‚Šã«35ä¸‡å°ã®H100ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ•´ãˆLlama3ã®é–‹ç™ºã‚’æ¨é€²ã€‚ã©ã®ä¼šç¤¾ã‚‚LLMã¨ã„ã†ä¸ç¢ºå®Ÿãªè¦ç´ ï¼ˆç™ºå±•æ€§ã€ä»–ç¤¾ã¨ã®ç«¶äº‰ï¼‰ã«å‚™ãˆãªã‚‰ãŒç¶±æ¸¡ã‚Šçš„ãªä¼šç¤¾ã®é‹å–¶ã‚’ã—ã¦ã„ã‚‹ï¼ˆæ ªä¸»ã‹ã‚‰ã®æœŸå¾…ã«ã“ãŸãˆç¶šã‘ã¤ã¤è²¡å‹™çš„ã«ç ´ç¶»ã¯ã§ããªã„ï¼‰ã€‚å…±é€šãƒ†ã‚¹ãƒˆã«ã•ã£ããåŠã‚‹ã—ã®LLMã‚’é©ç”¨è©•ä¾¡ã—ãŸä¾‹ã§ã¯ã€GPT-4ãŒ6å‰²å¼·ç¨‹åº¦æ­£è§£ã§ãªã‚“ã¨ã‹äººé–“ã‚’ä¸Šå›ã‚‹ã‚‚ã€ç‰¹ã«æ•°å­¦ãŒãƒ€ãƒ¡ã¨ã„ã†çµæœãŒã€‚ä¸€æ–¹ã€æ•°å­¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ã®ãƒ¡ãƒ€ãƒªã‚¹ãƒˆä¸¦ã¿ã®æ€§èƒ½ã‚’ç¤ºã™DeepMindã®AlphaGeometryã€LLMã¨ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãŒé«˜æ€§èƒ½ã®ç§˜è¨£ã‚‰ã—ã„ã€text_to_SQLã‚‚ã€ã¾ãŸé•ã£ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã¨ã—ã¦é«˜æ€§èƒ½åŒ–ã®ãƒ’ãƒ³ãƒˆã«ãªã‚‹ã€‚ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã¨ã‹ã€ELYZAã®æ—¥æœ¬èªè¿½åŠ å­¦ç¿’ã§ã‚‚ã¨ã‚‚ã¨ã®è‹±èªã®èƒ½åŠ›ãŒè½ã¡ãªã„ã‹ã®æ¤œè¨¼ã¨ã‹ã€ç€å®Ÿãªå‹•ãã¯åœ°é“ã«ã™ã™ã‚“ã§ã„ã‚‹ã®ã‚’å¿˜ã‚Œãšã«ã„ãŸã„ã€‚

- HachiMLã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹youri-2x7b_v0.2ã®gguf ^aaa
	- https://huggingface.co/mmnga/HachiML-youri-2x7b_v0.2-gguf
	- This model is a Mixture of Experts (MoE) merger of the following two models:
	- [rinna/youri-7b-instruction](https://huggingface.co/rinna/youri-7b-instruction)
	- [rinna/youri-7b-chat](https://huggingface.co/rinna/youri-7b-chat)
- mambaã‚’åˆ†æ•£å­¦ç¿’ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
	- https://github.com/kotoba-tech/kotomamba
	- Transformerã‚’ä¸Šå›ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹Mamba, State Spaceãƒ¢ãƒ‡ãƒ«ã®
	- Kotoba Techã§ã¯130m, 1.4B, 2.8B ã®ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’ã™ã§ã«è¡Œã£ã¦ã„ã¾ã™
- baobab-trees/wikipedia-human-retrieval-ja
	- https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja
	- çŸ­ã„è³ªå•æ–‡ã«å¯¾ã—ã¦Wikipediaã«æ›¸ã„ã¦ã‚ã‚‹æƒ…å ±ã®ã¿ã§å›ç­”ã•ã›ã‚‹ã€ã¨ã„ã†ã®ã‚’1000å•å‰å¾Œå®Ÿæ–½ã—ã€äººæ‰‹retrievalä»˜ãQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸã€‚é€”ä¸­ã®éç¨‹ã‚„å¼•ç”¨ãªã©ã‚‚è¨˜éŒ²ã—ã¦ã„ã‚‹ã®ã§ã€äººé–“ã«ã‚ˆã‚‹æ¤œç´¢ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¤œè¨ã—ãŸã‚Šã§ãã‚‹ã¨æ€ã„ã¾
- Copilot for Office 365
	- https://x.com/usutaku_com/status/1747119405702795383?s=20
-  how to build advanced QA over Tabular Data
	- llamaindexã‚ˆã‚Šã€
	- https://x.com/llama_index/status/1747289513934864493?s=20
	- Query Pipeline over Pandas DataFrames
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas.html
	- This is a simple example that builds a query pipeline that can perform structured operations over a Pandas DataFrame to satisfy a user query, using LLMs to infer the set of operations.
	-  Query Pipeline for Advanced Text-to-SQL
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_sql.html
- nanoGPTæ¥½ã—ã„ã€‚æºæ°ç‰©èªå…¨æ–‡ã§å­¦ç¿’ã•ã›ãŸã‚‰ä½•ã‹èªã‚Šã ã—ãŸğŸ¤— ã„ãšã‚Œã®ç´›ã‚Œã‚ã‚Šã‘ã‚‹ã‹ãª
	- https://github.com/karpathy/nanoGPT
	- The simplest, fastest repository for training/finetuning medium-sized GPTs
- ä¼æ¥­ã¯ãªãœæ±äº¬ã«é›†ä¸­ã™ã‚‹ã®ã‹â”€â”€çµŒæ¸ˆåœ°ç†å­¦ã®è¦–ç‚¹ã‹ã‚‰ï¼ˆæ—¥æœ¬åŠ´åƒç ”ç©¶é›‘èªŒï¼‰
	- https://www.jil.go.jp/institute/zassi/backnumber/2020/05/pdf/029-039.pdf
- æ±äº¬ç™ºãƒ»AIãƒ‰ãƒªãƒ¼ãƒ ãƒãƒ¼ãƒ ã€Œhttp://Sakana.aiã€ãŒ45å„„å††èª¿é”ã€€å…ƒGoogleãƒˆãƒƒãƒ—ç ”ç©¶è€…ã‚‰ãŒè¨­ç«‹ã€€AIæ¥­ç•Œã®è‘—åäººã‚„æ—¥æœ¬ã®å¤§æ‰‹ITä¼æ¥­ã‚‚å‡ºè³‡
	- https://sakana.ai/seed-round/
	- @tkasasagi ã•ã‚“ã‚‚å‚åŠ ã‹ãƒ¼
	- https://x.com/tkasasagi/status/1747267875021406329?s=20
	- ã€Œã‚µã‚«ãƒŠAIã€æ—¥ç±³ã§45å„„å††èª¿é”ã€€ã‚¹ã‚¤ãƒŸãƒ¼ã®ç™ºæƒ³ã§å·¨å¤§ITã«æŒ‘ã‚€
		- åŒç¤¾ã¯å¯¾è©±å‹AIã®åŸºç›¤æŠ€è¡“ã§ã‚ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®é–‹ç™ºã§ã€ä»–ç¤¾ãŒé–‹ç™ºã—ãŸå°ã•ãªAIã‚’ã„ãã¤ã‚‚ã¤ãªã„ã§ã€å·¨å¤§AIã«åŒ¹æ•µã™ã‚‹èƒ½åŠ›ã‚’ã‚‚ã¤ä»®æƒ³ã®AIãƒ¢ãƒ‡ãƒ«ã‚’æ§‹æƒ³ã€‚ã“ã®æ–°æŠ€è¡“ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ‡ãƒ«ã¨å‘¼ã°ã‚Œã€é–‹ç™ºã‚³ã‚¹ãƒˆã‚’åŠ‡çš„ã«ä¸‹ã’ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã€å·¨é¡ãªè³‡é‡‘ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹AIé–‹ç™ºç«¶äº‰ã«ä¸€çŸ³ã‚’æŠ•ã˜ã‚‹ç‹™ã„ã ã€‚
- xverse/XVERSE-13B-256K
	- https://huggingface.co/xverse/XVERSE-13B-256K
	- ãƒ­ãƒ¼ã‚«ãƒ«LLMã®é•·æ–‡å¯¾å¿œãŒã¤ã„ã«256Kï¼ˆç´„25ä¸‡å­—ï¼‰
	- XVERSEã¯ABF+ç¶™ç¶šçš„pre-trainingã¨NTK+SFTæŠ€è¡“ã‚’ç”¨ã„ã¦ãƒ—ãƒ­ã‚»ã‚¹ã‚’æœ€é©åŒ–ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’å¤§å¹…ã«æ‹¡å¼µã™ã‚‹ã“ã¨ãŒå¯èƒ½ã¨ãªã£ãŸ
- Open AIã¯ã€ŒCollective Alignment teamã€ã‚’çµæˆ
	- https://openai.com/blog/democratic-inputs-to-ai-grant-program-update
	- AIã«å¤šç¨®å¤šæ§˜ãªä¸–ç•Œä¸­ã®å…¬çš„ãªæ„è¦‹ã‚’åæ˜ ã•ã›ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚’æ‹…ã†ã€‚ ä»¥å‰AIã¸ã®æ°‘ä¸»çš„ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å‹Ÿé›†ã—ã¦ã„ãŸãŒã€1000ã®å¿œå‹Ÿè€…ãŒã‚ã‚Šä»¥ä¸‹ç”»åƒã®ã‚ˆã†ã«10ã®ãƒãƒ¼ãƒ ã®ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ãŒé¸æŠœã•ã‚ŒãŸ
-  å†è€ƒ: ãŠè²·ã„å¾—ç‰©ä»¶ã‚’æ©Ÿæ¢°å­¦ç¿’ã§è¦‹ã¤ã‘ã‚‹æ–¹æ³•
	- https://speakerdeck.com/ktgrstsh/rethink-method-to-find-cheap-rental-houses-by-machine-learning
	- è³ƒè²¸ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã§ã‚ã‚Œã°ï¼Œã“ã¡ã‚‰ã®ãƒšãƒ¼ã‚¸ãŒå‚è€ƒã«ãªã‚Šã¾ã—ãŸ
- WikiChatã®è©±
	- https://arxiv.org/abs/2305.14292
	- WikiChat ã¯ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯åŠã³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«ï¼ŒRAG ç­‰ã§ã‚ˆãåˆ©ç”¨ã•ã‚Œã‚‹ Wiki ã‚’åˆ©ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ï¼Œé«˜ã„ factfulness ã‚’å‚™ãˆã‚‹ã¨ã—ã¦ã„ã‚‹
- Animagine XL 3.0 ã€Hugging Faceã®ãƒˆãƒ¬ãƒ³ãƒ‰ã§1ä½ã‚’é”æˆ
	- https://huggingface.co/spaces/DamarJati/Animagine-XL-3.0
	- 1æœˆ10æ—¥ã€Cagliostro Research LabãŒã€**æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®Text-to-Imageã®ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ŒAnimagine XL 3.0ã€**ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚
	- https://weel.co.jp/media/animagine-xl-3-0
- Blending, Merging, and Stacking multiple smaller LLMs make them as performant as Larger LLMs
	- https://x.com/bindureddy/status/1746739742350450811?s=20
	- Blendingã€Mergingã€Stackingãªã©ã®æŠ€è¡“ã‚’ä»Šå¾Œ30-70bãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã—ã¦ã„ãã€ä»Šå¾Œ2-3ãƒ¶æœˆä»¥å†…ã«GPT4ã«è¿‘ã„æˆ»ã‚‹ãŒå¾—ã‚‰ã‚Œã‚‹ã§ã—ã‚‡ã†
- (RAG)ã®è©•ä¾¡æŒ‡æ¨™ãƒãƒƒãƒ—
	- https://x.com/helloiamleonie/status/1747252654047142351?s=20
- DeepMindã®CEOã§ã‚ã‚‹Lila IbrahimãŒãƒ€ãƒœã‚¹ä¼šè­°2024ã§èªã£ãŸã“ã¨
	- https://www.axios.com/2024/01/16/davos-ai-lila-ibrahim-google-deepmind-technologies
	- ila Ibrahimã¯ã€AIãŒç‰©è³ªç§‘å­¦ã‚„ç”Ÿç‰©å­¦ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã€æ–°ã—ã„ææ–™ã‚„ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®ç™ºè¦‹ã«è²¢çŒ®ã—ã¦ã„ã‚‹ã¨è¿°ã¹ãŸã€‚
	- 2018å¹´ã€ã€ŒAlphaFoldã¯ï¼ˆã‚‚ã¨ã‚‚ã¨ã¯ï¼‰ã†ã¾ãã„ã‹ãªã„ã¯ãšã®ã‚¢ã‚¤ãƒ‡ã‚¢ã ã£ãŸã€ã¨ã‚¤ãƒ–ãƒ©ãƒ’ãƒ ã¯èªã£ãŸã€‚å½¼å¥³ã¯ã“ã†ä»˜ã‘åŠ ãˆãŸã€‚ã€Œä»Šã§ã¯ï¼ˆæ—¢çŸ¥ã®ï¼‰ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚’2å„„å€‹ã¿ã¤ã‘ã‚‹ã¾ã§ã«ãªã‚Šã¾ã—ãŸã‘ã©ã­ã€ã€‚
	- æ˜¨å¹´ã¯ã€AIé–‹ç™ºè€…ãŸã¡ãŒäº’ã„ã«å”åŠ›ã—åˆã„ã€æ”¿åºœã®å”åŠ›ã‚’å¾—ã¦ã€æŠ€è¡“ã®ãƒªã‚¹ã‚¯ã‚’ç®¡ç†ã™ã‚‹ã“ã¨ãŒæ€¥é€Ÿã«é€²ã‚“ã ã¨å½¼å¥³ã¯è¨€ã†ã€‚
	- ã‚¤ãƒ–ãƒ©ãƒ’ãƒ æ°ã¯ã€è‹¥ã„AIãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æŠ€è¡“ã®å€«ç†çš„æ çµ„ã¿ã‚’æ•™ãˆã‚‹ã®ã¯ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢ã‚’é€šã˜ã¦ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ã—ãŸé«˜é½¢è€…ä¸–ä»£ã«æ•™ãˆã‚‹ã‚ˆã‚Šã‚‚ç°¡å˜ã ã‚ã†ã¨è€ƒãˆã¦ã„ã‚‹ã€‚
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆCopilot Proã‚’ç™ºè¡¨
	- https://x.com/satyanadella/status/1747000699664429075?s=20
	- Officeï¼“ï¼–ï¼•å‘ã‘ã®copiloã®æ©Ÿèƒ½ãŒã€å€‹äººã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚3,200å††/æœˆ
	- Office365/w copilotã®åˆ©ç”¨ä»¥å¤–ã«ã€GPT-4 ãŠã‚ˆã³ GPT-4 Turboã¸ã®å„ªå…ˆçš„ãªå‰²ã‚Šå½“ã¦
	- Copilot GPT Builderï¼ˆè¿‘æ—¥å…¬é–‹äºˆå®šï¼‰ã§ã€ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ã«åˆã‚ã›ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚ŒãŸç‹¬è‡ªã®Copilot GPTã‚’ä½œæˆå¯èƒ½
	- æœŸå¾…ã™ã‚‹å£°ã‚‚ãŸãã•ã‚“ä¸ŠãŒã‚‹ã‚‚ã€ãŒã£ã‹ã‚Šã™ã‚‹å£°ã‚‚å¤šæ•°
- ã€2024å¹´æœ€æ–°ã€‘å…±é€šãƒ†ã‚¹ãƒˆã‚’è‰²ã‚“ãªç”ŸæˆAIã«è§£ã‹ã›ã¦ã¿ãŸï¼ˆChatGPT vs Bard vs Claude2
	- https://note.com/lifeprompt/n/n87f4d5510100?sub_rt=share_h
	- â‘ GPT-4ãŒã™ã¹ã¦ã®ç§‘ç›®ã§ä»–äºŒã¤ã®ãƒ„ãƒ¼ãƒ«ã‚’åœ§å€’  
	- â‘¡æ•°å­¦ç§‘ç›®ã«é–¢ã—ã¦ã¯ã©ã®AIã‚‚å…¨ç„¶ç‚¹å–ã‚Œã¦ã„ãªã„  
	- â‘¢é«˜å¾—ç‚¹ã‚’ç‹™ãˆã¦ã„ã‚‹ç§‘ç›®ã§ã‚‚ã€æº€ç‚¹ã¯å–ã‚Œã¦ã„ãªã„
- nampdn-ai/tiny-strange-textbooks
	- https://huggingface.co/datasets/nampdn-ai/tiny-strange-textbooks
	- äººå·¥çš„ã«ç”Ÿæˆã•ã‚ŒãŸå°å‹ã®LLM(phiãªã‚“ã‹ï¼‰ç”¨ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
	-  Textbooks Are All You Need II: phi-1.5 technical report
	- https://arxiv.org/abs/2306.11644
- Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy
	- https://arxiv.org/abs/2310.01334
	- MoEã£ã¦ãƒ¡ãƒ¢ãƒªé£Ÿã†ã®ã§ã€ã“ã‚Œã‚’åœ§ç¸®ã‚„ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§ã«ç€ç›®ã—ã¦è»½é‡åŒ–ã™ã‚‹ã€80%ã®å‰Šæ¸›ï¼
	- We merge experts THEN compress/decompose merged expertsâ†’low-rank. Up to 80% mem reduction! ğŸ‰
- mix_self_consistency pack by llamaindex
	- https://llamahub.ai/l/llama_packs-tables-mix_self_consistency?from=llama_packs
	- Hereâ€™s a simple but useful idea to use RAG to fetch few-shot examples for less flaky text-to-SQL (orâ€¦less flaky structured RAG itself). Calling it dynamic metadataâ€¦
	- â€œRethinking Tabular Data Understandingâ€ã®å®Ÿè£…
	- 1.  Index and embed each row
	- 2. In the text-to-SQL prompt (or auto-retrieval prompt), add *few shot examples of rows*: given the first k rows in the prompt, retrieve the top-k rows matching the user query.
	- 3. Execute text-to-SQL prompt (or auto-retrieval prompt) to infer the right query (SQL or metadata filters).
	- 4. Execute query to get back result.
- ç”ŸæˆAIã®æ¥­ç•Œå›£ä½“ã€ŒGenerative AI Japanã€ç™ºè¶³ã€€ãƒ™ãƒãƒƒã‚»ãŒç™ºèµ·ã€€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã€AWSã€Googleã€ã‚ªãƒ©ã‚¯ãƒ«ãªã©ã®å¹¹éƒ¨ãŒç†äº‹ã«
	- https://x.com/itmedia_news/status/1747490194486632764?s=20
- Can AI Be as Creative as Humans?"
	- https://arxiv.org/abs/2401.01623
	- ã€ŒAIã¯äººé–“ã¨åŒã˜ãã‚‰ã„ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã«ãªã‚Œã‚‹ã®ã‹ï¼Ÿã€ã¨ã„ã†ãƒ†ãƒ¼ãƒã§ã€DeepMindãƒ»Microsoftãƒ»ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ãªã©ãŒå…±åŒã§ç ”ç©¶ã—ã¦ã„ã¾ã™ã€‚
	- ã€AIãŒå‰µã‚Šå‡ºã—ãŸä½œå“ãŒäººé–“ã®ãã‚Œã¨è¦‹åˆ†ã‘ãŒã¤ã‹ãªããªã£ãŸã‚‰ã€AIã¯ã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ã ã¨è¨€ãˆã‚‹ã€
	- AIã®å‰µé€ æ€§ã‚’å…·ä½“çš„ãªæ•°å€¤ã§è©•ä¾¡ã—ãŸã„ â†’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½œæˆ
- ELYZAãŒå…¬é–‹ã—ãŸæ—¥æœ¬èªLLMã€ŒELYZA-japanese-Llama-2-7bã€ã«ã¤ã„ã¦ã®è§£èª¬ : (3) è‹±èªã§ã®æ€§èƒ½è©•ä¾¡ç·¨
	- https://zenn.dev/elyza/articles/ab3749de0ba58b
	- **è¿½åŠ å­¦ç¿’ã®éç¨‹ã§ã€å…ƒã®ãƒ¢ãƒ‡ãƒ«ãŒæŒã£ã¦ã„ãŸèƒ½åŠ›ãŒã©ã®ç¨‹åº¦å¤±ã‚ã‚Œã¦ã—ã¾ã†ã®ã‹**ã¨ã„ã†ç‚¹
	- çµæœï¼š
		- æ—¥æœ¬èªã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ äº‹å‰å­¦ç¿’ã«ã‚ˆã‚Šæ—¥æœ¬èªåŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã€è‹±èªã®æ€§èƒ½ã®åŠ£åŒ–ã¯ç”Ÿã˜ã¦ã—ã¾ã†ã€‚
		- æ—¥æœ¬èªã®SFTã«ã‚ˆã‚Šã€æ—¥æœ¬èªåŒ–ãƒ¢ãƒ‡ãƒ«ã®è‹±èªã®æŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚‚ä¸€å®šå›å¾©ã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
		- è¿½åŠ äº‹å‰å­¦ç¿’ã«è‹±èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿½åŠ ã—ãŸå ´åˆã€è‹±èªã‚¿ã‚¹ã‚¯ã§ã®æ€§èƒ½åŠ£åŒ–ã‚’ç·©å’Œå¯èƒ½ã§ã‚ã‚‹ã€‚
		- æ—¥æœ¬èªã®èªå½™æ‹¡å¼µã¯æ—¥æœ¬èªã®äº‹å‰å­¦ç¿’æ™‚ã®æ€§èƒ½åŠ£åŒ–ã‚’é¡•è‘—ã«ã™ã‚‹ã‚‚ã®ã®ã€SFTã«ã‚ˆã‚‹æ€§èƒ½ã®ä¸Šæ˜‡ã‚’ã‚ˆã‚Šäº«å—ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã€‚
- ã€æ–°åˆŠã€‘ã€Œå¼·åŒ–å­¦ç¿’ã‹ã‚‰ä¿¡é ¼ã§ãã‚‹æ„æ€æ±ºå®šã¸ã€ã€ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç¤¾
	- æ¢¶é‡ã€€æ´¸(æ—¥æœ¬IBM)ãƒ»å®®å£èˆªå¹³(æ—¥æœ¬IBM)ãƒ»æç¥è²´è¡Œ(æ—¥æœ¬IBM)ãƒ»å²©åŸã€€è«’(æ—¥æœ¬IBM)ãƒ»å’Œåœ°ç­è‰¯(LINEãƒ¤ãƒ•ãƒ¼)ã€€å…±è‘—ã€€
	- https://www.saiensu.co.jp/search/?isbn=978-4-7819-1592-0&y=2024
	- å¼·åŒ–å­¦ç¿’ã¯ãã®å®šå¼åŒ–ã‚’ç”¨ã„ã‚‹ã“ã¨ã§å¹…åºƒã„å®Ÿå•é¡Œã‚’è¡¨ç¾ã§ãã‚‹ä¸€æ–¹ï¼Œä¿¡é ¼æ€§ã®ä¸è¶³ãŒä¸€å› ã¨ãªã‚Šï¼Œå®Ÿä¸–ç•Œã§ã¯å¿œç”¨ãŒãªã•ã‚Œã¦ã„ã‚‹ã¨ã¯è¨€ã„ãŒãŸã„ï¼æœ¬æ›¸ã¯ï¼Œæ¨™æº–çš„ãªå®šå¼åŒ–ã¨å®Ÿå•é¡Œã¨ã®æ©‹æ¸¡ã—ã¨ãªã‚‹ã‚ˆã†ãªå®šå¼åŒ–ã‚’ä½“ç³»çš„ã«ã¾ã¨ã‚ã‚‹ã“ã¨ã§ï¼Œå®Ÿä¸–ç•Œã§ã®å¿œç”¨ã‚’ä¿ƒé€²ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ãŸ
	- ç¬¬3ç« ãƒªã‚¹ã‚¯è€ƒæ…®å‹å¼·åŒ–å­¦ç¿’ã¨é‡‘èã¸ã®å¿œç”¨ï¼ˆ3.5ç¯€ã‚’é™¤ãï¼‰
- ã€ŒGeForce RTX 4070 SUPERã€ãŒå„ç¤¾ã‹ã‚‰å¤šæ•°ç™»å ´ã€ä¾¡æ ¼ã¯95,480å††ã‹ã‚‰
	- https://akiba-pc.watch.impress.co.jp/docs/news/news/1561586.html
- Google DeepMindãŒæ•°å­¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ã®å¹¾ä½•å­¦å•é¡Œã«ãŠã„ã¦å¹³å‡çš„ãªäººé–“ã®é‡‘ãƒ¡ãƒ€ãƒªã‚¹ãƒˆã«è‚‰è–„ã™ã‚‹ã€ŒAlphaGeometryã€ç™ºè¡¨
	- https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/?utm_source=twitter&utm_medium=social
	- An Olympiad-level AI system for geometry
	- AI system surpasses the state-of-the-art approach for geometry problems, advancing AI reasoning in mathematics
	- AlphaGeometry ã¯ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«è¨€èªãƒ¢ãƒ‡ãƒ«ã¨è¨˜å·æ¼”ç¹¹ã‚¨ãƒ³ã‚¸ãƒ³ã§æ§‹æˆã•ã‚Œã‚‹ç¥çµŒè¨˜å·ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€ã“ã‚Œã‚‰ãŒé€£æºã—ã¦è¤‡é›‘ãªå¹¾ä½•å­¦å®šç†ã®è¨¼æ˜ã‚’è¦‹ã¤ã‘ã‚‹
	- ã€ŒLLMã¨æ¼”ç¹¹ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã®çµ„ã¿åˆã‚ã›ã€
- Accelerating the prediction of stable materials with machine learning
	- https://www.nature.com/articles/s43588-023-00536-w
	- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ææ–™ã®å®‰å®šæ€§äºˆæ¸¬ã«é–¢ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡
	- DeepMindã•ã‚“ã®è«–æ–‡ã§ã‚‚ä½¿ã‚ã‚ŒãŸææ–™ã®ç†±åŠ›å­¦çš„å®‰å®šæ€§äºˆæ¸¬ã«é–¢ã—ã€convex hullã®æ¦‚å¿µã®ã‚ˆã†ãªåŸºç¤ã‹ã‚‰ã€æœ‰é™æ¸©åº¦ã®äºˆæ¸¬ã®ã‚ˆã†ãªå¿œç”¨ã¾ã§ã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã€‚ æ©Ÿæ¢°å­¦ç¿’ã§ææ–™æ¢ç´¢ã—ã¦ã¿ãŸã„åˆå­¦è€…ã®æ–¹ã«ãŠã™ã™ã‚ã€‚
- WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation
	- https://arxiv.org/abs/2312.14187
	- Introduce WaveCoder-Ultra-6.7B with the closest capabilities to GPT-4 so far.
	- WaveCoder-Ultra-6.7B is the newest SOTA open-source Code LLM on multiple tasks.
- LangGraphã®èª¬æ˜ãƒ–ãƒ­ã‚°ãŒå…¬é–‹
	- https://blog.langchain.dev/langgraph/
	- We previewed LangGraph last week, but excited to dive a lot more into why we're building this, the details of what it looks like, and some more examples
- Foundations of Vector Retrieval
	- https://arxiv.org/abs/2401.09350
	- This 185-page monograph provides a summary of major algorithmic milestones in the vector retrieval literature, with the goal of serving as a self-contained reference for new and established researchers.
	- LLMæ™‚ä»£ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨æ¤œç´¢ã«ã¤ã„ã¦ã®ã‚µãƒ¼ãƒ™ã‚¤ã§ã‚ã‚ŠåŒ…æ‹¬è«–æ–‡
- A Cheat Sheet and Some Recipes For Building Advanced RAG
	- https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b
- ç±³MetaãŒ1ä¸‡äººã®è¿½åŠ ãƒ¬ã‚¤ã‚ªãƒ•ã€5000äººã®æ¡ç”¨ã‚‚ä¸­æ­¢
	- https://xtech.nikkei.com/atcl/nxt/news/18/14833/
	- ãƒ¡ã‚¿ã¯2ä¸‡äººãƒ¬ã‚¤ã‚ªãƒ•ã—ã¦35ä¸‡å°ã®H100ã‚’è²·ã„ã¾ã—ãŸ
-  OpenAI Node API Library å…¥é–€ by npakaã•ã‚“
	- https://note.com/npaka/n/n2f8c08965316?sub_rt=share_h
	- ã€ŒOpenAI Node API Libraryã€ã¯ã€TypeScript / JavaScriptã‹ã‚‰ã€ŒOpenAI APIã€ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚
-  GraphGPT: Graph Learning with Generative Pre-trained Transformers
	- https://arxiv.org/abs/2401.00529
	- ã‚°ãƒ©ãƒ•Ã—Transformerã«ã‚ˆã‚‹ç‰©æ€§äºˆæ¸¬ã®è«–æ–‡
	- ã‚°ãƒ©ãƒ•ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—Transformerã§å­¦ç¿’ã™ã‚‹GraphGPTã‚’ææ¡ˆã€å¾“æ¥ã®GNNã§ã¯é›£ã—ã„400Mãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã€ã“ã‚Œã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§åˆ†å­ç‰©æ€§ã‚’é«˜ç²¾åº¦ã«äºˆæ¸¬ã§ããŸãã†ã§ã™ã€‚
- LLMãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä¿¯ç°ã™ã‚‹
	- https://speakerdeck.com/masatoto/llmmarutiezientowofu-kan-suru
	- æ–‡çŒ®ã®å†…å®¹ã‚’ã‚‚ã£ã¨æ·±æ˜ã‚Šã—ãŸã‚‰æ™®é€šã«å‡ºç‰ˆã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã ã‚ã“ã‚Œ
-  Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering
	- https://arxiv.org/abs/2401.08500
	- The paper proposes AlphaCodium, a code-oriented iterative flow that improves LLMs on code generation.
	- LLMã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä½œæ¥­ã‚’è¡Œã†éš›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ‰‹æ³•ã¨ã—ã¦ã€ã€Œãƒ•ãƒ­ãƒ¼ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ã¨ã„ã†æ–°ã—ã„æ¦‚å¿µãŒæå”±ã•ã‚Œã¦ã„ã¾ã™ã€‚ 
	- ã“ã®æ¦‚å¿µã«åŸºã¥ã„ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã§ã€LLMã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°èƒ½åŠ›ãŒä¸€è²«ã—ã¦å‘ä¸Šã™ã‚‹ã“ã¨ãŒå®šé‡çš„ã«å ±å‘Šã•ã‚Œã¾ã—ãŸã€‚
	- â– ç ”ç©¶è€…ã‚‰ã®ã‚¢ã‚¤ãƒ‡ã‚¢ - è¤‡æ•°ã®æ®µéšã«åˆ†ã‘ã¦ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆãƒ»æ”¹å–„ã™ã‚‹ - ãƒ†ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®è€ƒãˆæ–¹ã‚’ç”¨ã„ã‚‹
	- â– å®Ÿé¨“çµæœ 
		- ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã§ã®LLMã®æ€§èƒ½ã‚’ä¸€è²«ã—ã¦ã‹ã¤å¤§å¹…ã«å‘ä¸Šã•ã›ãŸ 
		- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ï¼ˆDeepSeekï¼‰ã¨ã‚¯ãƒ­ãƒ¼ã‚ºãƒ‰ã‚½ãƒ¼ã‚¹ï¼ˆGPT-3.5/4ï¼‰ä¸¡æ–¹ã§åŠ¹æœãŒã‚ã£ãŸ
-  DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models
	- https://arxiv.org/abs/2401.06066
	- DeepSeekMoEã¯LLMã®MoEã§
		- 1) Expertã‚’ã•ã‚‰ã«ç´°ã‹ãã—64ã«å¢—ã‚„ã™ã¨å…±ã«é¸æŠã•ã‚Œã‚‹Expertæ•°ã‚‚8ã«å¢—ã‚„ã™ 
		- 2) å…±æœ‰çŸ¥è­˜ã‚’ä½¿ãˆã‚‹ã‚ˆã†å¸¸ã«é¸æŠã•ã‚Œã‚‹Expertã‚’ç”¨æ„ã€‚ãƒ‡ãƒã‚¤ã‚¹æ¯ã®è² è·åˆ†æ•£ã‚’é‡è¦–ã—å®Ÿè¡ŒåŠ¹ç‡ã‚’ã‚ã’ã‚‹ã€‚
		-  åŒã˜è¨ˆç®—é‡ã®Denseã‚„å¾“æ¥MoEã«å¯¾ã—æ€§èƒ½ã‚’æ”¹å–„
- llama3ã®é–‹ç™ºã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã«é–¢ã—ã¦ã‚¶ãƒƒã‚«ãƒ¼ãƒãƒ¼ã‚°ã®ãƒ“ãƒ‡ã‚ªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå‡ºå›ã‚‹
	- https://twitter.com/i/status/1748058491343061458
	- å¹´å†…ã«35ä¸‡å°ã®H100ã‚’æ´»ç”¨å¯èƒ½ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ§‹ç¯‰
	- H100ç›¸å½“å“ã‚‚å«ã‚ã‚‹ã¨60ä¸‡å°ã®H100ã«åŒ¹æ•µ 
	- ä»¥ä¸‹ã¯ãƒ“ãƒ‡ã‚ªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ã®æ›¸ãèµ·ã“ã— by AI
		- ãƒ¡ã‚¿ã¯ä¸€èˆ¬çš„ãªçŸ¥èƒ½ã‚’æ§‹ç¯‰ã—ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ã¿ã‚“ãªã«åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã¨ã„ã†é•·æœŸçš„ãªç›®æ¨™ã®ãŸã‚ã«ã€2ã¤ã®AIç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’çµ±åˆã™ã‚‹ã¨ç™ºè¡¨ã—ãŸã€‚
		- æ¬¡ä¸–ä»£ã®ã‚µãƒ¼ãƒ“ã‚¹ã«ã¯ã€æ¨è«–ã€è¨ˆç”»ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€è¨˜æ†¶ãªã©ã®AIã®å„åˆ†é‡ã§ã®é€²æ­©ãŒå¿…è¦ã§ã‚ã‚‹ã¨è¿°ã¹ãŸã€‚
		- ã“ã®æŠ€è¡“ã¯éå¸¸ã«é‡è¦ã§ã‚ã‚Šã€æ©Ÿä¼šã‚‚å¤§ãã„ã®ã§ã€è²¬ä»»ã‚’æŒã£ã¦ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã—ã€ã§ãã‚‹ã ã‘åºƒãåˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã¹ãã ã¨ä¸»å¼µã—ãŸã€‚
		- ä»Šå¹´æœ«ã¾ã§ã«ã€ç´„35ä¸‡å°ã®Nvidia H100 GPUã‚’æ­è¼‰ã—ãŸå·¨å¤§ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’æ§‹ç¯‰ã™ã‚‹ã¨ç™ºè¡¨ã—ãŸã€‚
		- ç¾åœ¨ã€Llama 3ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ãŠã‚Šã€ä»Šå¾Œã‚‚è²¬ä»»ã‚’æŒã£ã¦å®‰å…¨ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç¶šã‘ã‚‹
		- AIã¨ãƒ¡ã‚¿ãƒãƒ¼ã‚¹ã¯å¯†æ¥ã«é–¢é€£ã—ã¦ãŠã‚Šã€å°†æ¥çš„ã«ã¯å¤šãã®äººãŒAIã¨ä¼šè©±ã™ã‚‹ãŸã‚ã«ãƒ¡ã‚¬ãƒã‚’ä½¿ã†ã ã‚ã†ã¨äºˆæ¸¬ã—ãŸã€‚
- Connect to Sheets and use the Gemini API in Colab to tell Gemini about your most promising prospects and prepare personalized sales pitches to sell what you are good at - in this case, delicious lemonade.
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Sell_lemonade_with_Gemini_and_Sheets.ipynb
	- Geminiã¨Google Sheetsã‚’ä½¿ã£ãŸã‚»ãƒ¼ãƒ«ã‚¹ãƒ”ãƒƒãƒç”Ÿæˆã®ä¾‹
- 5%ãã‚‰ã„ï¼Ÿã‚’ChatGPTï¼ˆç”ŸæˆAIï¼‰ã§æ›¸ã„ãŸã¨ã„ã†èŠ¥å·è³ã‚’å—è³
	- https://x.com/yukatan/status/1747957984104480891?s=20
	- AIã«åŸ·ç­†ã•ã›ã¦ã¿ãŸã¨ã„ã†ãƒ¬ãƒ™ãƒ«ã®è©±ã§ã¯ãªãã¦ã€ã‚¹ãƒãƒ›ã§ã‚°ã‚°ã‚‹ã¿ãŸã„ã«AIã«è³ªå•ã™ã‚‹ã®ãŒå½“ãŸã‚Šå‰ã«ãªã‚‹ã¨ä¸–ç•ŒãŒã©ã†å¤‰ã‚ã‚Šå¾—ã‚‹ã‹ã‚’æ–‡å­¦çš„ã«è¡¨ç¾ã—ã¦ã„ã¾ã™ã€‚æ™‚ä»£ã‚’åˆ»ã‚€ä½œå“ã ã‚
- ã‚¢ãƒ«ãƒˆãƒãƒ³ãŒãƒ€ãƒœã‚¹ä¼šè­°ã§è¨€ã£ãŸã“ã¨
	- ã€ŒAIã®é€²æ­©ã¯ã€ç§‘å­¦çš„ç™ºè¦‹ã®é€Ÿåº¦ã‚’å¤§å¹…ã«åŠ é€Ÿã™ã‚‹ã®ã«å½¹ç«‹ã¤ã€‚ãã‚ŒãŒ2024å¹´ã«èµ·ã“ã‚‹ã¨ã¯äºˆæƒ³ã—ã¦ã„ãªã„ãŒã€èµ·ã“ã£ãŸãªã‚‰ã°ã¨ã¦ã‚‚å¤§ããªä¸€å¤§äº‹ã«ãªã‚‹ã€ 
	- ã€Œç¾æ™‚ç‚¹ã§ã®æœ€å„ªå…ˆäº‹é …ã¯æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ³ãƒã™ã‚‹ã“ã¨ã ã€‚ãã‚Œã¯GPT-5ã¨å‘¼ã°ã‚Œã‚‹å¯èƒ½æ€§ãŒé«˜ã„
	- https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview
- åœ§ç¸®MoE
	- https://github.com/unites-lab/mc-smoe
	- ä»Šã¾ã§ã®MoEã¯ãƒ¢ãƒ‡ãƒ«ã‚’ï¼’ã¤ãã£ä»˜ã‘ãŸã‚‰ï¼’å€VRAMæ¶ˆè²»ã™ã‚‹ã®ãŒã‚³ã‚¹ãƒ‘å¾®å¦™ã ã£ãŸã‘ã©ã€MC-SMoEã§ã¯ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨å„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã¨ã®å·®åˆ†ã‚’LoRAçš„ãªå½¢ã§ä¿æŒã™ã‚‹äº‹ã§çœãƒ¡ãƒ¢ãƒªã«ãªã£ãŸã£ã¦è©±ã‹ãª
- Introducing Mixtral, Phi2, Falcon, and Qwen support in DeepSpeed-FastGen! 
	- https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen/2024-01-19
	- Up to 2.5x faster LLM inference
	- Optimized SplitFuse and token sampling
	- Exciting new features like RESTful API and more!
- å¿ƒç†å­¦ãƒ¯ãƒ¼ãƒ«ãƒ‰104å·ã®ç‰¹é›†ã€Œç©ºé–“èªçŸ¥ã®ç§‘å­¦ æœ€å‰ç·šã€
	- https://psych.or.jp/publication/world104/
- Fair Machine Guidance to Enhance Fair Decision Making in Biased People
	- https://x.com/yukino/status/1748481134558896432?s=20
	- ç§ãŸã¡ã®è«–æ–‡ã€ŒFair Machine Guidance to Enhance Fair Decision Making in Biased Peopleã€ãŒ #CHI2024 ã«æ¡ä»¶ä»˜ãæ¡æŠã•ã‚Œã¾ã—ãŸï¼ äººé–“ã®åˆ¤æ–­ãŒä¸å…¬å¹³ã«åã‚‹å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€å…¬å¹³æ€§é…æ…®å‹æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹å…¬å¹³ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ã€äººã€…ãŒã‚ˆã‚Šå…¬å¹³ãªåˆ¤æ–­ã‚’ä¸‹ã›ã‚‹ã‚ˆã†ã‚¬ã‚¤ãƒ‰ã—ã¾ã—ãŸï¼
- Neural Speed + ONNX Runtime makes LLM inference more efficient on CPUs!
	- https://github.com/intel/neural-speed
- Google DeepMind researchers are in talks to leave and form a new startup named 'Holistic'. They want to build their own AI model.
	- https://x.com/AndrewCurran_/status/1748419941672616324?s=20
- ã€æ–°åˆŠã€‘ã€Œå¤šæ§˜ä½“ä¸Šã®æœ€é©åŒ–ç†è«–ã€
	- https://www.ohmsha.co.jp/book/9784274231186/
	- æœ¬æ›¸ã¯ã€å¤šæ§˜ä½“ä¸Šã®æœ€é©åŒ–ç†è«–ã«ã¤ã„ã¦ã€åŸºç¤ã¨ãªã‚‹æ•°ç†ã‹ã‚‰å¿œç”¨ä¾‹ã¾ã§ã‚’è§£èª¬ã™ã‚‹ã‚‚ã®ã§ã™ã€‚  
	- å¤šæ§˜ä½“ä¸Šã®æœ€é©åŒ–ã‚’å­¦ã¶ã€ã‚ã‚‹ã„ã¯ç ”ç©¶ã™ã‚‹èª­è€…ã¯  
		- ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰ç©ºé–“ä¸Šã®é€£ç¶šæœ€é©åŒ–ã‚’ã²ã¨ã¨ãŠã‚Šå­¦ã‚“ã å¾Œã€ãã®æŠ½è±¡åŒ–ã®ä»•æ–¹ã®ä¸€ã¤ã¨ã—ã¦å¤šæ§˜ä½“ä¸Šã¸ã®æ‹¡å¼µã«ã¤ã„ã¦å­¦ã¶  
		- å¤šæ§˜ä½“ã‚’ã¯ã˜ã‚ã¨ã—ãŸå¹¾ä½•å­¦ã«æ…£ã‚Œè¦ªã—ã‚“ã èª­è€…ãŒã€ãã†ã—ãŸç†è«–ã®æœ€é©åŒ–ã¸ã®å¿œç”¨ã«ã¤ã„ã¦å­¦ã¶  
		- æœ€é©åŒ–ã¨å¹¾ä½•å­¦ã®çŸ¥è­˜ã‚’ã‚‚ã¤èª­è€…ãŒã€ä¸¡è€…ã®èåˆã«ã¤ã„ã¦å­¦ã¶

## 1/15

Mistral AIã«ã‚ˆã‚‹Mixtral -8x7bãƒ¢ãƒ‡ãƒ«ã®æˆåŠŸã«ã‚ˆã‚Šã€æœ€è¿‘ã®ã¯ã‚„ã‚Šã¯MoEï¼ˆMixture of Expertsï¼‰ãƒ¢ãƒ‡ãƒ«ã€‚Phi-2ã®MoEã§ã‚ã‚‹Phixtual-2x2bãªã‚“ã‹ã‚‚å‡ºã¾ã—ãŸã€‚mergekitã¨ã„ã†ã®ã‚’ä½¿ãˆã°ã€colabã§ã‚‚ã€MoEãŒç°¡å˜ã«ä½œã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚  æ¯”è¼ƒçš„å°ã•ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€æ··ãœåˆã‚ã›ã‚‹ã“ã¨ã§å¤§ãã„ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ã„ã†å ±å‘Šã‚‚ã‚ã‚Šã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã£ã¦ã®ã¯LLMã§ã‚‚æœ‰åŠ¹ãªã‚“ã§ã™ã­ãƒ¼ã€‚å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã¯TinyLlamaã£ã¦ã®ã‚‚ã‚ã‚Šã¾ã—ãŸã€Macã§ã‚‚å¿«é©ã«å‹•ãæ¨¡æ§˜ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ã¯å°ã•ãã¦ã‚‚ã€è†¨å¤§ãªãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã™ã‚Œã°æ€§èƒ½ãŒä¸ŠãŒã‚‹ï¼Ÿstanfordã®wikichatã€LLaMA7Bãƒ™ãƒ¼ã‚¹ã§ã‚‚ã€ã“ã“ã¾ã§æ€§èƒ½ãŒä¸ŠãŒã‚‹ï¼ˆãƒ¡ãƒ¢ãƒªã‚’é£Ÿã†ã‚‰ã—ã„ãŒï¼‰ã¨ã„ã†å ±å‘Šã‚‚ã€‚ã‚ã‚Œã‚‰ã®ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ãŒçµå©šï¼LangChainã‚‚ã¤ã„ã«ã€v0.1ãŒå‡ºãŸï¼ã€‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«ã€ã²ãŸã™ã‚‰ã€Moore-AnimateAnyoneã®çµµãŒå‡ºã¦ãã‚‹ã®ã¯ãªãœï¼Ÿï¼ŸDuolingoã®ãƒªã‚¹ãƒˆãƒ©ã€ãã†ã„ã†æ°—ã‚‚ã™ã‚‹ãŒã€googleã®AMIEã®ã‚ˆã†ã«ã€ãã‚‚ãã‚‚äººæä¸è¶³ã®åˆ†é‡ã§ã®å°‚é–€å®¶AIã®ç™»å ´ã¨ã„ã†å´é¢ã‚‚ã‚ã‚‹ã€‚Googleã®DynamicPlanã£ã¦ã€ã‚ã‚Œã©ã“ã‹ã§è¦‹ãŸã‚ˆã†ãªæ°—ã‚‚ã™ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¯ãƒªã‚¹ãƒˆãƒ©ã•ã‚Œã‚‹å´ã«ãªã‚‹ã®ã‹ã€ãã‚Œã¨ã‚‚å°‚é–€å®¶AIã¨ã—ã¦ã ã‚Œã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã‹ï¼Ÿ

- Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy
	- https://arxiv.org/abs/2312.12728
	- LLMã®å‡ºåŠ›å“è³ªã‚’è½ã¨ã•ãšã«æ¨è«–é€Ÿåº¦ã‚’ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã•ã›ã‚‹ãŸã‚ã®æ‰‹æ³•
	- â– ã€Lookaheadã€ã®ã‚¢ã‚¤ãƒ‡ã‚¢ 
		- 1. ç”Ÿæˆã®æåˆ†ã‹ã‚Œï¼ˆãƒ–ãƒ©ãƒ³ãƒï¼‰ã‚’ä½œã‚‹ - ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆã¯ä¸¦è¡Œå‡¦ç†ã™ã‚‹ 
		- 2. æœ€é©ãªãƒ–ãƒ©ãƒ³ãƒã‚’é¸ã³å‡ºã™ - ä¸è¦ãªãƒ–ãƒ©ãƒ³ãƒã‚’æ—©æœŸæ’é™¤ã™ã‚‹ â†’æ¨è«–ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚’å‘ä¸Šã•ã›ã¤ã¤é«˜å“è³ªã‚’ç¶­æŒã™ã‚‹ 
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. Dollyãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨Llama-13Bã§ãƒ†ã‚¹ãƒˆ 
		- 2. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç’°å¢ƒã«çµ„ã¿è¾¼ã‚“ã  
		- 3. é«˜ã„ç”Ÿæˆç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤é€Ÿåº¦ã‚’æ”¹å–„ã—ãŸ
- PmxEditoråŠã³æº–æ¨™æº–ãƒœãƒ¼ãƒ³è¿½åŠ ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®å°å…¥
	- http://rockstababy.starfree.jp/mmdsupporter/bemmder/section3.php
	- PmxEditorã‚’ä½¿ãˆã°MMDãƒ¢ãƒ‡ãƒ«ã‚’ç·¨é›†ã§ãã‚‹ã®ã‹ï¼ãƒ•ãƒªãƒ¼ãƒ¬ãƒ³ã®ãƒ¢ãƒ‡ãƒ«ã®ç·¨é›†ã¯ã“ã‚Œã‚’ä½¿ã£ã¦ã„ãŸã®ã‹
-  Uncovering mesa-optimization algorithms in Transformers
	- https://arxiv.org/abs/2309.05858
	- Why are Transformers so effective? And where is their intruiging in-context learning ability coming from?
	- Transformerã¯ï¼Œäººé–“ã®è¨­è¨ˆè€…ã‹ã‚‰ä¸ãˆã‚‰ã‚ŒãŸè¨“ç·´ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«ï¼Œè‡ªç™ºçš„ã«æ–°ãŸãªä¸­é–“ç›®æ¨™ã®è¨­å®šã¨ãã‚Œã‚‰ã‚’çµ„ã¿åˆã‚ã›ãŸå†…éƒ¨çš„ãªæœ€é©åŒ–æˆ¦ç•¥ã‚’ä½œã‚‹ï¼ˆãƒ¡ã‚µæœ€é©åŒ–ï¼‰å¯èƒ½æ€§ã‚’ç¤ºå”†ï¼AIå®‰å…¨æ€§ï¼ŒAIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«ãŠã‘ã‚‹é‡è¦æ¦‚å¿µï¼ˆé“å…·çš„ç›®æ¨™åæŸï¼‰ã‚’ç†è«–çš„ã«å°å‡ºã—ãŸæ³¨ç›®è«–æ–‡
- TinyLlama: An Open-Source Small Language Model
	- https://arxiv.org/abs/2401.02385
	- å°å‹ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ¥µã‚ã¦å¤§ãã„ãƒ‡ãƒ¼ã‚¿é‡ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ã€é¡ä¼¼ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã‚·ãƒ³ãƒ—ãƒ«ã«è‘—ã—ãæ€§èƒ½ãŒé«˜ããªã£ãŸã¨å ±å‘Š
	- - GPT-3ï¼š175Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ - Llama-2ï¼š7Bã€œ70Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ - TinyLlamaï¼š1.1Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
	- â– å®Ÿé¨“ 1. 3å…†ãƒˆãƒ¼ã‚¯ãƒ³ã§TinyLlamaã‚’è¨“ç·´ã—ãŸ ï¼ˆ3ã‚¨ãƒãƒƒã‚¯Ã—1å…†ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ 2. æ§˜ã€…ãªå¸¸è­˜æ¨è«–ã‚¿ã‚¹ã‚¯ã§ãƒ†ã‚¹ãƒˆã—ãŸ 3. åŒè¦æ¨¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ãŸ 4. å¹³å‡ã‚¹ã‚³ã‚¢ã§æœ€é«˜ã®æˆç¸¾ã‚’é”æˆã—ãŸ 
	- â– çµè«– ã‚·ãƒ³ãƒ—ãƒ«ã«å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã®ã¯æœ‰åŠ¹ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„
-  LangChain v0.1.0
	- https://blog.langchain.dev/langchain-v0-1-0/
- langgraph
	- https://github.com/langchain-ai/langgraph
	- LangGraph is inspired by Pregel and Apache Beam, and the current interface exposed is one inspired by NetworkX
- GPT-4ã‚’å°å…¥ã—ãŸDuolingoãŒå¤§è¦æ¨¡ãªãƒªã‚¹ãƒˆãƒ©
	- https://x.com/Rahll/status/1744234385891594380?s=20
	- GPT-4ã‚’å°å…¥ã—ãŸDuolingoãŒå¤§è¦æ¨¡ãªãƒªã‚¹ãƒˆãƒ©
- 1å¹´é–“ã«æ—¥æœ¬ã®äººå·¥çŸ¥èƒ½åˆ†é‡å…¨ä½“ã§20äººã—ã‹åšå£«å·å–ã‚‰ãªã„ï¼Ÿ
	- https://x.com/yo_ehara/status/1744332999578333613?s=20
- Mixtral of Experts by Mistral AI
	- https://huggingface.co/papers/2401.04088
	- introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e.â€¦
- yolopandas
	- https://github.com/ccurme/yolopandas
	- yolopandas ã¯ï¼Œpanadas ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦ç›´æ¥ï¼ŒLLM ãŒåˆ†æã‚³ãƒ¼ãƒ‰ã®æç¤ºã‚’ã—å®Ÿè¡Œã—ã¦ãã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
	- ã€Œæ¬ æå€¤ã¯ã„ãã¤ã‚ã‚‹ï¼Ÿã€ãªã©ã®æŒ‡ç¤ºæ–‡ã«å¯¾ã—ï¼Œ df.llm.query("æŒ‡ç¤ºæ–‡") ã¨ã™ã‚‹ã ã‘
- äººå·¥çŸ¥èƒ½ã¨ã„ã†åˆ†é‡ãŒè¬™è™šã§ã‚ã£ãŸã“ã¨ãªã©ä¸€åº¦ã‚‚ãªã„
	- https://repository.kulib.kyoto-u.ac.jp/dspace/handle/2433/286548
	- å²©æ³¢æ›¸åº—ã€Œç§‘å­¦ã€2023/12æœˆå·ã«æ²è¼‰ã•ã‚ŒãŸã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨äººé–“ã®è¨€èªèƒ½åŠ›ã«ã¤ã„ã¦ã®è¨è«–å½¢å¼è«–æ–‡
- WikiChat=Wikipedia + LLM
	- https://wikichat.genie.stanford.edu/
	- https://github.com/stanford-oval/WikiChat
	- stanfordã®wikichatã€äº‹å®Ÿæ€§ã§GPT-4 ã‚ˆã‚Šã‚‚55.0%å„ªã‚Œã¦ã„ã‚‹ã¨ã„ã†äº‹ã§ã‚‚ã®å‡„ã„ 
	- ã—ã‹ã—ã€LLaMA7Bãƒ¢ãƒ‡ãƒ«ãŒãƒ™ãƒ¼ã‚¹ã®å‰²ã«è¦æ±‚ã‚¹ãƒšãƒƒã‚¯ã‚‚ã‚‚ã®å‡„ã„
		- å‹•ä½œã•ã›ã‚‹ã«ã¯ç´„100GBã®RAMãŒå¿…è¦ 
		- é€Ÿåº¦ã‚’çŠ ç‰²ã«RAM ã®ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã§ãã‚‹ãŒãã‚Œã§ã‚‚ç´„35GBãŒå¿…è¦
- Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM
	- https://arxiv.org/abs/2401.02994
	- æ¯”è¼ƒçš„å°ã•ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€æ··ãœåˆã‚ã›ã‚‹ã“ã¨ã§å¤§ãã„ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹å¯èƒ½æ€§
	- â– å®Ÿé¨“å†…å®¹ 
		- 1. 3ã¤ã®å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ–ãƒ¬ãƒ³ãƒ‰ã—ãŸ 
		- 2. GPT-3.5ãªã©æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ãŸ 
		- 2. è©•ä¾¡æŒ‡æ¨™ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®šç€ç‡ã¨ä¼šè©±å¯†åº¦ã¨ã—ãŸ
	- â– å®Ÿé¨“çµæœ 
		- 1. ãƒ–ãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã¯å®šç€ç‡ãŒé¡•è‘—ã«é«˜ã‹ã£ãŸ 
		- 2. ä¼šè©±å¯†åº¦ã«é–¢ã—ã¦ã‚‚ä»–ãƒ¢ãƒ‡ãƒ«ã‚’å‡Œé§•ã—ãŸ
- Kaggleæ–°ã‚³ãƒ³ãƒš
	- https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/
	- è„³æ³¢ (EEG) ä¿¡å·ã‹ã‚‰å…¥é™¢ä¸­ã®é‡ç—‡æ‚£è€…ã®ç™ºä½œãªã©ã‚’æ¤œçŸ¥ã€‚ç™ºä½œ (SZ)ã€å…¨èº«æ€§å‘¨æœŸæ”¾é›» (GPD)ã€å´æ–¹åŒ–å‘¨æœŸæ€§æ”¾é›» (LPD)ã€å´æ–¹åŒ–å¾‹å‹•ãƒ‡ãƒ«ã‚¿æ´»å‹• (LRDA)ã€å…¨èˆ¬åŒ–å¾‹å‹•ãƒ‡ãƒ«ã‚¿æ´»å‹• (GRDA)ã€ã¾ãŸã¯ã€Œãã®ä»–ã€ã®6ã‚¯ãƒ©ã‚¹ã‚’åˆ†é¡ã™ã‚‹
- OpenAIã€GPT storeã‚’æ­£å¼å…¬é–‹
	- https://openai.com/blog/introducing-the-gpt-store
-  Build LLM Apps with LangChain.js
	- https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/
	- DeepLearningAIã‚ˆã‚Šã€javascriptã‚’ã‚‚ã„ã„ãŸLLMã‚³ãƒ¼ã‚¹
- Phixtral
	- Phixtralã ã£ã¦ã€‚Phi-2ã‚’ãã£ä»˜ã‘ã¦MoEã«ã—ãŸã‚‰ã—ã„
	- ãƒãƒ¼ã‚¸(merge)ã¨ã¯è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’è¶³ã—å¼•ãã—ã¦æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹æŠ€è¡“ 
	- ä¸Šæ‰‹ã«ãƒãƒ¼ã‚¸ã™ã‚‹ã¨å‡ºåŠ›ãŒã‚ã¾ã‚Šå£Šã‚Œãš(ã‚¹ãƒšãƒ«ãƒŸã‚¹ãŒå¤šããªã‚‹ã¨ã„ã†è©±ã¯ã‚ã‚‹)ã€ãƒãƒ¼ã‚¸å¾Œã«æ”¹ã‚ã¦å¾®èª¿æ•´ã‚’ã—ãªãã¦ã‚‚ãã®ã¾ã¾å‹•ãã€‚ã—ã‹ã‚‚ã€ãƒ™ãƒ¼ã‚¹ã¨ãªã£ãŸãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ãŒå‘ä¸Šã™ã‚‹äº‹ã‚‚çã—ããªã„â€¦
	- It combines 2 to 4 fine-tuned models and is better than each individual expert.
	- https://huggingface.co/mlabonne/phixtral-2x2_8
	- https://huggingface.co/mlabonne/phixtral-4x2_8
- llamaindexã‚ˆã‚Šã€RAGã®é«˜åº¦ãªæ‰‹æ³•ã¨ã—ã¦ã€ensembleã¨fusion
	- https://llamahub.ai/l/llama_packs-query-rag_fusion_pipeline?from=llama_packs
- Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding
	- https://arxiv.org/abs/2401.04398
	- Googleãªã©ã®ç ”ç©¶è€…ã«ã‚ˆã‚Šã€è¡¨å½¢å¼ï¼ˆ.csvãªã©ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’é€šã—ã¦LLMãŒã€Œé€£é–çš„ãªæ¨è«–ã€ã‚’è¡Œã†ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
	- â– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒDynamicPlanã€ - è³ªå•ã®å…±æœ‰ã¨ã€å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã•ã›ã‚‹ - é©å®œã€ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ã€é¸æŠã€ä¸¦ã¹æ›¿ãˆã‚’ã•ã›ã‚‹ - æœ€çµ‚çš„ã«è³ªå•ã«ç­”ãˆã•ã›ã‚‹
	- â– å®Ÿé¨“ã¨çµæœ - PaLM-2ã€GPT-3.5ã€LLaMA 2ã‚’ä½¿ç”¨ã—ãŸ - è¡¨ãƒ‡ãƒ¼ã‚¿æ¨è«–ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯3ç¨®é¡ã§è©•ä¾¡ã—ãŸ - æœ€é«˜ã®ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ãŸ
- LangChainã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ— - LangChain Expression Languageã‚’å®Œå…¨ã«ç†è§£ã™ã‚‹
	- https://speakerdeck.com/masahiro_nishimi/langchainkiyatutiatupu-langchain-expression-languagewowan-quan-nili-jie-suru
- Geminiã®ã€Œå¸¸è­˜ã‚’æ¨è«–ã™ã‚‹èƒ½åŠ›ã€ã‚’ç¶²ç¾…çš„ã«èª¿æŸ»ã—ãŸçµæœã€€é–“é•ãˆã‚„ã™ã„ã‚¿ã‚¤ãƒ—ã®å•é¡Œã‚‚æ˜ã‚‰ã‹ã«
	- https://ai-data-base.com/archives/61597
	- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã¨Metaã«ã‚ˆã£ã¦GPT-4ãªã©ä»–ã®LLMã¨ä½µã›ã¦å®Ÿé¨“ã•ã‚ŒãŸçµæœãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚ è¨˜äº‹ã§ã¯ã€å®Ÿé¨“ã¨çµæœã®è©³ç´°ã€ãã‚‚ãã‚‚å¸¸è­˜æ¨è«–ã¨ã¯ä½•ã‹ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚
- ChatGPTã®Top Pã‚„Temperatureã«ã¤ã„ã¦å°‘ã—çŸ¥ã£ã¦ã¿ã‚ˆã†
	- https://techblog.a-tm.co.jp/entry/2023/04/24/181232
- æˆ‘ã‚‰ãŒOpenAI CEOã‚µãƒ ã‚¢ãƒ«ãƒˆãƒãƒ³ã€çµå©š
	- https://x.com/kai_postv/status/1745440329204142447?s=20
- AMIE: A research AI system for diagnostic medical reasoning and conversations
	- https://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html
	- Googleã‹ã‚‰ã€åŒ»ç™‚è¨ºæ–­åˆ†é‡ã«ç‰¹åŒ–ã—ãŸã€AIãƒªã‚µãƒ¼ãƒã‚·ã‚¹ãƒ†ãƒ AMIE
	- Today, we shared our latest preprint introducing AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM) based research AI system for diagnostic medical reasoning and conversations.
	- å·¨å¤§ãªæ±ç”¨è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒPaLM 2ã€ã‚’åŒ»ç™‚å¯¾è©±å‘ã‘ã«å¾®èª¿æ•´ã—ãŸAIã‚·ã‚¹ãƒ†ãƒ ã€ŒAMIEã€ã€‚å°‚é–€åŒ»ã«ã‚ˆã‚‹ã¨32è»¸ä¸­28è»¸ã€æ‚£è€…ã«ã‚ˆã‚‹ã¨26è»¸ä¸­24è»¸ã§ã€ã‚ˆã‚Šé«˜ã„è¨ºæ–­ç²¾åº¦ã¨å„ªã‚ŒãŸæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚ä¸–ç•Œã®80å„„äººãŒ24æ™‚é–“ä½“åˆ¶ã§åŒ»ç™‚ç›¸è«‡ã§ãã‚‹ç©¶æ¥µã®ã‹ã‹ã‚Šã¤ã‘åŒ»ã¸ä¸€æ­©å‰é€²
- Moore-AnimateAnyone test
	- https://x.com/toyxyz3/status/1745846460678291702?s=20
	- Moore-AnimateAnyoneã¯ã€AnimateAnyoneã‚’å†ç¾ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€‚ æ§˜ã€…ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚Šã€æœ¬çµµkã¨ã¯å¤šå°‘ç•°ãªã‚‹å®Ÿè£…ã§å†ç¾ã—ã¦ã„ã‚‹ãã†ã§ã€ç¾åœ¨ãŠãŠã‚ˆã80%ã»ã©ã®å†ç¾åº¦ã¨ãªã£ã¦ã„ã¾ã™ã€‚
- nitky/Superswallow-70b-v0.1
	- https://huggingface.co/nitky/Superswallow-70b-v0.1
	- ãªã‚“ã‹ã™ã”ã„æ€§èƒ½ãŒã‚ã‚‹ã‚‰ã—ã„ãƒãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªGPT-4ã¨LLaVAã«ã‚ˆã‚‹é«˜åº¦ãªç”»åƒç†è§£ã¨è‡ªç„¶è¨€èªå¯¾è©±ã®çµ±åˆ
	- https://ai-scholar.tech/articles/computer-vision/LLaVA
	- GPT-4ã«ä¸¦ã¶ã€Œå¤šãƒ¢ãƒ¼ãƒ€ãƒ«äººå·¥çŸ¥èƒ½ã€ã®é–‹ç™ºã«å‘ã‘ã¦ã€è¦–è¦šå‘½ä»¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚
	- ã¾ãŸã€è¦–è¦šã¨è¨€èªã®ç†è§£åŠ›ãŒé«˜ã„è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒLLaVAã€ã‚‚ç´¹ä»‹ã€‚
-  Large Language Model Course by 
	- https://github.com/mlabonne/llm-course
	- 3 models trending + even MistralTril 
-  Google Colabï¼šMergekitã«ã‚ˆã‚‹æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«MoEã®ä½œæˆ
	- https://note.com/hatti8/n/ne09226bc4ff5?sub_rt=share_pb
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- ãƒãƒ¼ã‚¸ã®å®Ÿè¡Œè‡ªä½“ã¯ã»ã¨ã‚“ã©ãƒ¢ãƒ‡ãƒ«ã®å–å¾—ã®æ™‚é–“ã§20~30åˆ†ãã‚‰ã„ã§å®Ÿè¡Œã§ããŸæ°—ãŒã™ã‚‹ã€‚
	-   ãƒ¡ãƒ¢ãƒªãŒãã“ãã“ã„ã‚‹ã®ã§ã€ãƒã‚¤ãƒ¡ãƒ¢ãƒªã§å®Ÿè¡Œã—ãªã„ã¨ã„ã‘ãªã„ã€‚
	- https://github.com/cg123/mergekit/tree/mixtral
- Phixtral 4-bit quantized with MLX also runs nicely on an 8GB M2.
	- https://github.com/ml-explore/mlx-examples/tree/main/llms/phixtral
	- https://x.com/awnihannun/status/1746376783543591235?s=20
- æ—¥æœ¬èªMoEãƒ¢ãƒ‡ãƒ«ã€jaqket-v2ä»¥é™ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
	- https://x.com/CurveWeb/status/1746401006286713276?s=20
	- Mixture of Expertså¼·åŠ›ã™ãã‚‹ã€‚
	- JGLUEã®çµæœã¨åŒæ§˜ã€ã„ã„ã¨ã“å–ã‚ŠãŒã§ãã¦ã‚‹ã€‚
	- ã—ã‹ã‚‚ã€9ã¤ä¸­5ã¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯(åŠåˆ†ä»¥ä¸ŠğŸ‘€)ã§å…ƒã®ï¼’ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹ã‚¹ã‚³ã‚¢ã«ã€‚
- mergekitã‚’ä½¿ã£ã¦MoEãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦ã¿ã¾ã—ãŸ
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- rinna/youri-7b-instruction
	- rinna/youri-7b-chat chat
	- ãƒ¢ãƒ‡ãƒ«ã¨instructionãƒ¢ãƒ‡ãƒ«ã‚’ç¹‹ã’ã‚‹åŠ¹æœãŒã©ã®ãã‚‰ã„ã‚ã‚‹ã‹ã‚ã‹ã‚‰ãªã„ã‘ã‚Œã©ã€å‹•ãã¨ã“ã‚ã¾ã§ç¢ºèªã§ããŸã€‚ æ™‚é–“ãŒã‚ã‚Œã°JGLUEè©¦ã—ã¦ã¿ã‚‹ã€‚
- Raspberry Pi 4 Model B 4GB memoryã§Phi-2ã¨TinyLlamaä½™è£•ã§å‹•ã„ãŸ
	- https://x.com/yuiseki_/status/1746532207597064670?s=20
	- ç‰¹ã«TinyLlamaã¯8token/sãã‚‰ã„å‡ºã¦ã‚‹ã‚“ã ã‘ã©ã€ãªã‚“ã‹llama.cppå‰ã‚ˆã‚Šé€Ÿããªã£ã¦ã­â€¦ï¼Ÿ


## 1/8

 Mixtralã®MoEç‰ˆã«å¯¾ã™ã‚‹æŠ•æ©Ÿçš„å®Ÿè¡Œ(offload)è«–æ–‡ã¨ãã®æˆæœãŒæ–°ã—ã„é‡å­åŒ–HQQã‚’å«ã‚ã¦ã€ä»Šé€±ã®ä¸€ç•ªã™ã”ã„ãƒã‚¿ã€‚æ¬¡ã®Expertã‚’äºˆæ¸¬ã—ã¦ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã€colabã§å‹•ãã®ã‚‚ã™ã”ã„ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–¢é€£ã§ã‚‚ã€CALMã‚„çŸ¥è­˜ç·¨é›†ã®ã‚ˆã†ã«ã€è³ªãŒé•ã†æ–°ã—ã„æ‰‹æ³•ãŒãŸãã•ã‚“ã§ã¦ããŸã€‚LLaMA-Factoryã¯ã€colabã§ã€æ§˜ã€…ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒè©¦ã›ã¦ã“ã‚Œã¾ãŸæ°‘ä¸»åŒ–ã‚’ä¿ƒé€²ã€‚å› æœãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã¨ã‹ã€ãƒ‡ãƒ¼ã‚¿ä¸å‡è¡¡å•é¡Œã‚’è§£æ¶ˆã™ã‚‹SMOTEãªã‚“ã‹ã‚‚ç€å®Ÿã«é€²ã‚“ã§ã„ã‚‹ã€‚LLMæ™‚ä»£ã«æœ¬å½“ã«å¿…è¦ãªã®ã¯ã€ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã€ã‚¹ãƒ”ãƒ¼ã‚­ãƒ³ã‚°ã®ã‚¹ã‚­ãƒ«ã£ã¦ã€ã„ã‚„ãã“ã«é”ã™ã‚‹ã¾ã§ãŒå¤§å¤‰ãªã®ã‚ˆã€‚ æ—¥æœ¬ã®å®˜å…¬åºã®ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€å›½å®¶å…¬å‹™å“¡ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ã‚’çµŒã¦ãŠã‚Šèª¤å­—è„±å­—ãŒãªã„ã¨è¨€ã„åˆ‡ã£ãŸãªã€‚LLMã®å†…éƒ¨çŠ¶æ…‹ã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã§ã€Œå‡ºåŠ›ãŒãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‹å¦ã‹ã‚’åˆ¤åˆ¥ã™ã‚‹ã€æ‰‹æ³•ã¨ã„ã†ã®ã¯æ–¬æ–°ã€å†…éƒ¨çŠ¶æ…‹ãŒå¤§åˆ‡ãªã®ã­ã€‚ãƒ†ãƒ³ã‚»ãƒ³ãƒˆã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦æ¨è«–ã£ã¦ã€ã€Œã©ã‚“ãªæƒ…å ±ã‚‚å…¥åŠ›ã§ãã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ã«å‘ã‘ã¦ã€ã©ã‚Œã ã‘å¯èƒ½æ€§ãŒã‚ã‚‹ã‹ï¼Ÿphi-2ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒMITã«ãªã£ãŸã®ã¯ã™ã”ã„ãªã€‚MotionGPTã€ãƒ‡ãƒ¢ã§å¤ªæ¥µæ‹³ã‚’è©¦ãã†ã¨ã—ãŸã‚‰ä»Šä¸€æ­©ã ã£ãŸã€‚ã‚„ã£ã±ã‚Šã€ä»Šé€±ã‚‚ã€ã‚¢ãƒªãƒãƒã®QWen-14Bã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸLLMãŒæ—¥æœ¬èªã«å¼·ã„ã®ã‹ã€‚çŸ¥è­˜ç·¨é›†ã®ã‚µãƒ¼ãƒ™ã‚¤ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã‚‚å…¬é–‹ã•ã‚Œã¦ã„ã¦ã€ã“ã‚Œã¯ï¼¬ï¼¬ï¼­ã®æ“ä½œã‚’èª°ã‚‚ãŒæ‰‹è»½ã«ã€ãã—ã¦ä½•ã§ã‚‚ã§ãã‚‹ã¨ã„ã†ã“ã¨ã‹ã€‚ã€CALMï¼ˆComposition to Augment Language Modelsï¼‰ã€ã‚‚ã‚³ãƒãƒ³ã‚¶ãƒ¡ã¿ãŸã„ã«ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã®ï¼¬ï¼¬ï¼­ãŒã‚ã‚Œã°ã€ã‚ˆã‚Šå¤§ããªï¼¬ï¼¬ï¼­ãŒãã®ã‚¿ã‚¹ã‚¯ã‚’ã“ãªã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã„ã†æ–°ã—ã„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã ã€‚


- Mistralã®MoEç‰ˆã§ã‚ã‚‹MixtralãŒæ¨è«–æ™‚ã«ä½¿ã†ã®ã¯8ã¤ã®Exportã®ã†ã¡2ã¤ã®ã¿
	- https://x.com/webbigdata/status/1741043710476100060?s=20
	- 7B x 8ã®MixtralãŒç„¡æ–™ç‰ˆColabã‚„RTX 3060(12G)ã§å‹•ã‹ã™ã“ã¨ãŒã§ãã‚‹
	- æŠ•æ©Ÿçš„ãƒ­ãƒ¼ãƒ‰ã¯æŠ•æ©Ÿã«è² ã‘ã‚‹ã¨é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé…ããªã‚‹ç½ 
	- https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb#scrollTo=Zf4GkspecSm8
-  Fast Inference of Mixture-of-Experts Language Models with Offloading
	- https://arxiv.org/abs/2312.17238
	- Mixtral-8x7B-Instruct ã‚’ 3060 / 3080 Mobile / T4 ã«ã¦å®Ÿè¡Œã€A100 ã¨æ¯”è¼ƒã€‚æ‰‹æ³•ã®ã‚­ãƒ¢ã¯ã€Expert ã‚’ LRU ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹ç‚¹ã¨æ¬¡ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ä½¿ã†ã§ã‚ã‚ã† Expert ã‚’æ¨æ¸¬ã—ã€ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã™ã‚‹ç‚¹ã€‚é‡å­åŒ–ã«ã¯ GPTQ ã® 50 å€ä»¥ä¸Šé«˜é€Ÿã«å‡¦ç†ã§ãã‚‹ Half-Quadratic Quantization (HQQ)ã‚’æ¡ç”¨ã€‚
- Mixtralã«å¯¾ã—æ—¥è‹±å¯¾è¨³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§QLoRA tuning (SFT)ã‚’æ–½ã—ãŸæ—¥â‡”è‹± ç¿»è¨³ãƒ¢ãƒ‡ãƒ«(ã®LoRAå±¤)ã‚’HuggingFaceä¸Šã«å…¬é–‹ã—ã¾ã—ãŸ
	- https://huggingface.co/hpprc/Mixtral-8x7B-Instruct-ja-en
	- Mixtralã‚’å°èª¬ã®å¯¾è¨³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(https://www2.nict.go.jp/astrec-att/member/mutiyama/align/index.html) ã§SFTçš„ã«ç¿»è¨³ã‚¿ã‚¹ã‚¯ã§QLoRA tuningã—ã¦ã¿ãŸæ—¥æœ¬èªã®ç”ŸæˆãŒãŠã£ãã„ãŒæ™®é€šã«å‹•ã„ã¦ã„ãã†(æ–‡ç« ãƒ¬ãƒ™ãƒ«ã§ç¿»è¨³ã§ãã¦ã¦ãˆã‚‰ã„)
- LLaMA-Factory
	- Google Colab ã§ Llama Factoryã‚’è©¦ã—ä¸­ã€‚ 1åˆ†ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†ã—ã¦ã€WebUIã§ã½ã¡ã½ã¡æŠ¼ã™ã ã‘ã§å­¦ç¿’ã§ããŸã€‚Pre-Trainingã€SFTã€Reward Modelingã€PPOã€DPOã‚‚å¯¾å¿œ
	- https://x.com/npaka123/status/1741429803599962557?s=20
-  æ—¥æœ¬ã®å®˜å…¬åºã«ã‚ã‚‹ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¾ã¨ã‚ã¾ã—ãŸ
	- https://note.com/eurekachan/n/nc31c0dccb3c1?sub_rt=share_pb
	- æ—¥æœ¬ã®å®˜å…¬åºã®Webã‚µã‚¤ãƒˆã‹ã‚‰ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€ã‚’æ‰‹ä½œæ¥­ã§æŠ½å‡ºã—ã€ãŠã‚ˆã22000ä»¶ã®è³ªå•ã¨å¿œç­”ã®å½¢ã«ãªã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ã¾ã¨ã‚ã¾ã—ãŸã€‚
	- å›½å®¶å…¬å‹™å“¡ã«ã‚ˆã‚‹ãƒã‚§ãƒƒã‚¯ã‚’çµŒã¦ã„ã‚‹ã®ã§ã€èª¤å­—è„±å­—ãŒã»ã¼ã‚ã‚Šã¾ã›ã‚“ã€‚
	- https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k
- The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.
	- https://ollama.ai/library/tinyllama
	- Its small size means it can run fast with little memory and compute requirements
- Sakura-SOLAR-DPO
	- https://github.com/KyujinHan/Sakura-SOLAR-DPO
	- huggingfaceã®12æœˆåº¦ Open LLM ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã®å‹è€…ï¼Ÿ
	- A new winner on the huggingface Open LLM Leaderboard at the end of December â€¦ combining the goodness of SOLAR-10.7B and Direct Preference Optimization (DPO)
- Chat with Mamba
	- https://colab.research.google.com/drive/1SEwD1Cxp_mG0-CvLWWT0i9D6aYKMf1FL?usp=sharing
	- Mamba is really exciting, but its potential remains untapped due to a lack of instruction-tuning and alignment. I
-  Half-Quadratic Quantization of Large Machine Learning Models
	- https://mobiusml.github.io/hqq_blog/
	- GPTQ ã® 50 å€ä»¥ä¸Šé«˜é€Ÿã«å‡¦ç†ã§ãã‚‹ Half-Quadratic Quantization (HQQ)
	- MOEã®offloadã§ã‚‚ç”¨ã„ã‚‰ã‚ŒãŸã‚‰ã—ã„
	- https://huggingface.co/lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo
- Google Colab ã§ LLaMA-Factory ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/ne72fb4de6a2f?sub_rt=share_b
	- ã€ŒLLaMA-Factoryã€ã¯ã€WebUIã«ã‚ˆã‚‹ç°¡å˜æ“ä½œã§LLMã‚’å­¦ç¿’ã§ãã‚‹LLMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚
	- ä»Šå›ã¯ã€ã€Œ[**Elyza-7B**](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct)ã€ã§ã€Œ[**ã”ã–ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ**](https://huggingface.co/datasets/bbz662bbz/databricks-dolly-15k-ja-gozarinnemon)ã€ã‚’å­¦ç¿’ã•ã›ã¾ã™
	- https://github.com/hiyouga/LLaMA-Factory
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯å°†æ¥çš„ã«æ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¹ã‚­ãƒ«ã§ã¯ãªã„
	-  OpenAI Employee Claims Prompt Engineering is Not the Skill of the Future
	- https://www.cysecurity.news/2023/12/openai-employee-claims-prompt.html
	- OpenAIç¤¾ã®ãƒ‡ãƒ™ãƒ­ãƒƒãƒ‘ãƒ¼ã‚¢ãƒ‰ãƒœã‚±ã‚¤ãƒˆã€Logan Kilpatrickæ°ã€‚AIã‚·ã‚¹ãƒ†ãƒ ã¸ã®æœ‰åŠ¹ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å¯¾äººã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¯å¤‰ã‚ã‚‰ãšã€çœŸã«å¿…è¦ãªã®ã¯ãƒªãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ã€ã‚¹ãƒ”ãƒ¼ã‚­ãƒ³ã‚°ã®ã‚¹ã‚­ãƒ«
- å› æœãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆCausal Forestsï¼‰ã‚’Pythonã§å®Ÿè·µçš„ã«å­¦ã¶ï¼ˆãã®ï¼“ï¼‰
	- https://www.salesanalytics.co.jp/datascience/datascience187/
	- å› æœãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®1ã¤ã§ã‚ã‚‹CausalForestDMLã«ã‚ˆã‚‹å› æœæ¨è«–ã¨ã€ãã®ä¸­ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ãƒ€ãƒ–ãƒ«æ©Ÿæ¢°å­¦ç¿’ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’åˆ©ç”¨ã—ãŸCATEï¼ˆConditional Average Treatment Effectï¼‰
	- ä¾‹1:
		- æ¨è«–ã—ãŸã„å› æœ: æ–°ã—ã„å…¬åœ’ã®é–‹è¨­ã¨è¿‘éš£ã®å®¶ã®ä¾¡æ ¼ã¨ã®é–¢ä¿‚
		- å…¬åœ’ã‹ã‚‰500mãã‚‰ã„ã¾ã§ã¯åŠ¹æœãŒé«˜ãã€3Kmä»¥ä¸Šã¨ãªã‚‹ã¨ã»ã¼åŠ¹æœãŒãªã„ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ã€‚
	- ä¾‹2:
		- æ¨è«–ã—ãŸã„å› æœ: æ–°ã—ã„è–¬ã®æ‘‚å–ãŒæ‚£è€…ã®å¥åº·ã‚¹ã‚³ã‚¢ã«ä¸ãˆã‚‹å½±éŸ¿
		- å¹´é½¢ãŒé«˜ããªã‚‹ã»ã©åŠ¹æœãŒé«˜ãã€60æ­³ä»¥ä¸Šã¯ã»ã¼åŒã˜ãã‚‰ã„ã®åŠ¹æœã®é«˜ã•ã§è½ã¡ç€ã„ã¦ã„ã¾ã™
	- ä¾‹3:
		- æ¨è«–ã—ãŸã„å› æœ: QRã‚³ãƒ¼ãƒ‰ã‚ªãƒ¼ãƒ€ãƒ¼ã‚·ã‚¹ãƒ†ãƒ ã®å°å…¥ãŒã€é¡§å®¢ä¸€äººã‚ãŸã‚Šã®æ³¨æ–‡é‡‘é¡ã«ä¸ãˆã‚‹å½±éŸ¿
		- ã©ã®æ›œæ—¥ã‚‚åŠ¹æœãŒã‚ã‚Šã¾ã™ãŒã€ç‰¹ã«æ—¥æ›œæ—¥ã«åŠ¹æœãŒé«˜ããªã£ã¦ã„ã¾ã™
- MotionGPTã¯ã€äººé–“ã®å‹•ãã‚’ã€è‡ªç„¶è¨€èªãƒ™ãƒ¼ã‚¹ã§ã‚„ã‚Šå–ã‚Šã—ãªãŒã‚‰ç”Ÿæˆã§ãã‚‹æŠ€è¡“ã€‚
	- MotionGPT: Human Motion as Foreign Language
	- https://motion-gpt.github.io/
	- https://huggingface.co/spaces/OpenMotionLab/MotionGPT
- LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner States Analysis
	- https://arxiv.org/abs/2312.16374
	- LLMã®å†…éƒ¨çŠ¶æ…‹ã‚’è¦³å¯Ÿã™ã‚‹ã“ã¨ã§ã€Œå‡ºåŠ›ãŒãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‹å¦ã‹ã‚’åˆ¤åˆ¥ã™ã‚‹ã€æ‰‹æ³•
	- â– LLMãƒ•ã‚¡ã‚¯ãƒˆã‚¹ã‚³ãƒ¼ãƒ—ã®æ¦‚è¦ 
		- 1. ã‚·ãƒ£ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ´»ç”¨ 
		- 2. LLMã®å†…éƒ¨çŠ¶æ…‹ã‚’åˆ†æ 
		- â€»ã‚·ãƒ£ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆSiamese Networkï¼‰ï¼š å‡ºåŠ›ã®é¡ä¼¼åº¦ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ
	- â– å®Ÿé¨“ã¨çµæœ 
		- 1. Llama2ã€Vicunaãªã©ã®LLMã‚’ä½¿ç”¨ 
		- 2. ç‰¹å®šãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨äº‹å®Ÿç¢ºèªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å‡ºåŠ› 
		- 3. LLMã®å†…éƒ¨çŠ¶æ…‹ã‹ã‚‰ã€äº‹å®Ÿã‹ã‚’åˆ¤æ–­ 
		- 4. å‡ºåŠ›ãŒäº‹å®Ÿãªã®ã‹ã‚’96%ä»¥ä¸Šã®ç²¾åº¦ã§è­˜åˆ¥ã—ãŸ 
		- â†’ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æ¤œå‡ºæ‰‹æ³•ã¨ã—ã¦æœ‰æœ›ã¨åˆ¤æ–­
- åˆ†é¡å•é¡Œã®ãƒ‡ãƒ¼ã‚¿ä¸å‡è¡¡ã‚’è§£æ¶ˆã™ã‚‹SMOTEï¼ˆPythonç‰ˆï¼‰
	- https://www.salesanalytics.co.jp/datascience/datascience210/
	- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ä¸–ç•Œã§ã¯ã€æ­£ç¢ºãªåˆ†æã¨äºˆæ¸¬ãŒæˆåŠŸã®éµã¨ãªã‚Šã¾ã™ã€‚
	- å¤šãã®å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä¸å‡è¡¡ã§ã‚ã‚Šã€ã“ã‚ŒãŒç‰¹ã«åˆ†é¡å•é¡Œã«ãŠã„ã¦å¤§ããªèª²é¡Œã¨ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™
	- ãƒ‡ãƒ¼ã‚¿ä¸å‡è¡¡å•é¡Œã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã®å¼·åŠ›ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§ã‚ã‚‹SMOTEï¼ˆSynthetic Minority Over-sampling Techniqueï¼‰ã¨ãã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ç´¹ä»‹ã™ã‚‹ã¨ã¨ã‚‚ã«ã€Pythonã®ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚
- LLMã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãŠã•ãˆã‚‹æ§˜ã€…ãªæ‰‹æ³•
- OpenAIãŒé–‹ç™ºä¸­ã®ã€Œäººé–“ã‚’è¶…ãˆãŸAIã‚’åˆ¶å¾¡ã™ã‚‹ã€æ–¹æ³•
-  [https://ai-data-base.com/archives/61116](https://t.co/YRKMFwuNYh) 
- LLMã®èª¤ã‚Šï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ç™ºç”ŸåŸå› ã¨ã€ã€Œå‰µé€ æ€§ã¨äº‹å®Ÿæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã€ãªã©ã®å¯¾ç­–ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ— 
	- [https://ai-data-base.com/archives/58767](https://t.co/Iu2bgo6U7y) 
- LLMãªã©ã®ç”ŸæˆAIã®èƒŒå¾Œã«ã‚ã‚‹æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã¯äººé–“ã¨ã¯å…¨ãç•°ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã“ã¨ã‚’ç¤ºã™ä»®èª¬ã€ç”ŸæˆAIã®ãƒ‘ãƒ©ãƒ‰ãƒƒã‚¯ã‚¹ã€
	-  [https://ai-data-base.com/archives/58414](https://t.co/2JaLSNaX6l) 
- ã‚ãšã‹2è¡Œã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚‚å®ŸåŠ¹æ€§ã®ã‚ã‚‹æ–°ã—ã„ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹æ³•ã€URIALã€
	-  [https://ai-data-base.com/archives/60678](https://t.co/CaHkpMr7Vi) 
- LLMã¯ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚’æŒã¡ã€Œç‰©äº‹ãŒã©ã®ã‚ˆã†ã«ä½ç½®ã¥ã‘ã‚‰ã‚Œã€æ™‚é–“ãŒã©ã®ã‚ˆã†ã«é€²è¡Œã™ã‚‹ã‹ã€ã‚’ç†è§£ã™ã‚‹å¯èƒ½æ€§
	-  	[https://ai-data-base.com/archives/56365](https://t.co/UJZUbuWNh2)
-  æœ€è¿‘ã®æ—¥æœ¬èªç‰¹åŒ–ã‚ªãƒ¼ãƒ—ãƒ³LLMã‚’ã¤ã¾ã¿é£Ÿã„ã™ã‚‹ by shi3z
	- https://note.com/shi3zblog/n/n55e1c542205a?sub_rt=share_pb
	-  Qarasu-14B-chat-plus-unleashedãŒã™ã”ã„ã‚‰ã„ã—ã„
- A Comprehensive Study of Knowledge Editing for Large Language Models
	- https://arxiv.org/abs/2401.01286
	- LLMã®çŸ¥è­˜ã‚’ç‹™ã„æ’ƒã¡ã—ã¦ç·¨é›†ã™ã‚‹æ‰‹æ³•ï¼ˆKnowledge Editingï¼šçŸ¥è­˜ç·¨é›†ï¼‰ã®ç¾çŠ¶ã‚’ç¶²ç¾…çš„ã«ã¾ã¨ã‚ãŸè«–æ–‡
	- â– çŸ¥è­˜ç·¨é›†ã¨ã¯ 1. å¸¸è­˜ã€æ„Ÿæƒ…ãªã©å¤šå²ã«ã‚ãŸã‚‹æƒ…å ±ã‚’ç·¨é›†ã™ã‚‹ã‚‚ã® 2. æŒ¿å…¥/å¤‰æ›´/å‰Šé™¤ã‚’è¡Œã† 3. å¯¾è±¡ä»¥å¤–ã®çŸ¥è­˜ã¯ä¿æŒã™ã‚‹
	- çŸ¥è­˜ç·¨é›†ã‚’å¿œç”¨ã™ã‚‹ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ãŸã‚Šã€ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚Šã‚„ã™ããªã£ãŸã‚Šã™ã‚‹
	- çŸ¥è­˜ç·¨é›†ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒEasyEditã€ã‚’é–‹ç™ºã—å…¬é–‹ã—ã¦ã„ã¾ã™
	- https://github.com/zjunlp/EasyEdit
- Synthetic Data Applications in Finance
	- https://arxiv.org/abs/2401.00081
	- é‡‘èã«ãŠã‘ã‚‹åˆæˆ(ç”Ÿæˆ)ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ãƒ¢ãƒ‡ãƒ«ã«é–¢ã—ã¦ã€JPãƒ¢ãƒ«ã‚¬ãƒ³ã®AIãƒãƒ¼ãƒ ã®äººãŸã¡ãŒæ›¸ã„ãŸãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡ã€‚é‡‘èã«ãŠã‘ã‚‹AIåˆ†é‡ã®ä¸­ã§æœ€å…ˆç«¯åˆ†é‡ã®ï¼‘ã¤ã¨æ€ã†ã€‚
-  å˜ä¸€GPUã§å‹•ç”»ãƒ»ç”»åƒãƒ»éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆå¯¾å¿œã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦æ¨è«–!?ä½•ã‚’è¨€ã£ã¦ã‚‹ã‹ã‚ã‹ã­ãƒ¼ã¨æ€ã†ãŒã€ä¿ºã‚‚ä½•ã‚’è¦‹ã¦ã„ã‚‹ã®ã‹ã‚ã‹ã‚‰ã­ãˆ by shi3z
	- https://note.com/shi3zblog/n/nf657d6105bd9?sub_rt=share_pb
	- å‹•ç”»ã€ç”»åƒã€éŸ³æ¥½ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ã„ã†å››ã¤ã®ãƒ¢ãƒ¼ãƒ‰ã‚’å­¦ç¿’ã•ã›ãŸã€Œãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã€ãƒ¢ãƒ‡ãƒ«ã§ã€ã—ã‹ã‚‚ãƒ™ãƒ¼ã‚¹ã¯llama-7Bã¨ã„ã†ã“ã¨ã§ã€V100 32GBä¸€ã¤ã§æ¨è«–å¯èƒ½(CPUã®RAMã¯49GBä»¥ä¸Šå¿…è¦)ã©ã“ã‚ã‹å­¦ç¿’ã‚‚å¯èƒ½ã€‚
	- å®Ÿéš›ã«ã¯ã“ã‚Œã¯ã€Œã©ã‚“ãªæƒ…å ±ã‚‚å…¥åŠ›ã§ãã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã€ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ã‚ã‚‹
	- éŸ³å£°ã€ç”»åƒã€å‹•ç”»ã¨ã„ã£ãŸæƒ…å ±ã‚’å›³ã®ç´«ã®éƒ¨åˆ†ã«ã‚ã‚‹å„ç¨®ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’å­¦ç¿’ã•ã›ã€ãã‚Œã‚’é’ã„éƒ¨åˆ†ã«ã‚ã‚‹æ—¢å­˜ã®LLM(ã“ã“ã§ã¯MPT-7Bã‚’ä½¿ç”¨)ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä¸€ç·’ã«å…¥åŠ›ã—ã€LLMã‹ã‚‰AudioLMã¸ã®å…¥åŠ›ãƒ™ã‚¯ãƒˆãƒ«ã¨å¿œç­”å‡ºåŠ›(ãƒ†ã‚­ã‚¹ãƒˆ)ã‚’å–ã‚Šå‡ºã—ã¦ã„ã‚‹ã€‚ã‚‚ã®ã™ã”ãã‚·ãƒ³ãƒ—ãƒ«ãªã®ã ã€‚
- ã€CALMï¼ˆComposition to Augment Language Modelsï¼‰ã€
	- LLM Augmented LLMs: Expanding Capabilities through Composition
	- https://arxiv.org/abs/2401.02412
	- Googleã®ç ”ç©¶è€…ã‚‰ãŒã€ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã«å¼·ã„LLMã‚’ä½¿ã£ã¦åˆ¥ã®LLMã‚’åŒã‚¿ã‚¹ã‚¯ã«å¼·ãã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’é–‹ç™º
	- â– ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®å…¨å®¹ 1. ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«å¼·ã„LLMã‚’ç”¨æ„ 2. è¨“ç·´ã—ãŸã„LLMã‚’ç”¨æ„ 3. ä¸¡è€…ã‚’ã‚¯ãƒ­ã‚¹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å±¤ã§é€£æº 4. LLMé–“ã®æƒ…å ±å…±æœ‰ã‚’è¡Œã† 5. è©•ä¾¡ã‚’è¡Œã†
	- â– å®Ÿé¨“çµæœ - è¨“ç·´å¾Œãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒå‘ä¸Šã—ãŸ - å°ã•ãªãƒ¢ãƒ‡ãƒ«ã§ã‚‚æˆæœãŒå‡ºãŸ - æ—¢å­˜ã®æ–¹æ³•ã‚ˆã‚Šå°ãƒªã‚½ãƒ¼ã‚¹ã§å®Ÿç¾ã—ãŸ
	- CALMã€ãƒã‚¸ãªã‚‰å‡„ãã­ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã®å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã‚’æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã«ãã£ä»˜ã‘ã¦æ€§èƒ½ã‚¢ãƒƒãƒ—ã§ãã‚‹ã¨ãªã€‚ã¡ã‚ƒã‚“ã¨èª­ã‚“ã§ã¿ã‚ˆã€‚
- Scikit-LLM: Scikit-Learn Meets Large Language Models
	- https://github.com/iryna-kondr/scikit-llm
	- Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.
- phi-2ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ãŒã€ç ”ç©¶ç›®çš„é™å®šã‹ã‚‰MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«å¤‰æ›´ã•ã‚ŒãŸ
	- https://x.com/abacaj/status/1743500472520974364?s=20
- 

## 1/1

ãŠæ­£æœˆã§ã™ãŒã€LLMç•Œã¯æ­¢ã¾ã‚Šã¾ã›ã‚“ã€‚
PowerInferã£ã¦LLMæ¨è«–ã«å›ºæœ‰ã®é«˜ã„å±€æ‰€æ€§ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€é«˜é€Ÿæ¨è«–ã‚’å®Ÿç¾ã™ã‚‹ã‚“ã ã£ã¦ã€‚Colabã§ã‚‚è©¦ã›ã‚‹ã—ã€llama.cppã®æœ€å¤§11.69å€ã®é€Ÿåº¦ã£ã¦æœ¬å½“ã‹ï¼Ÿã€‚ä¸€æ–¹Llama.cppã‚‚ã„ã¤ã®ã¾ã«ã‹ã€CPUæ¨è«–ã ã‘ã§ãªãã€GPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦GPUæ¨è«–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒå¯èƒ½ã«ã€‚GuidanceãŒå¤§å¹…ã«æ”¹å®šã•ã‚Œã¦ã€Llama.cppã®åˆ©ç”¨ã‚‚ä½¿ã„ã‚„ã™ããªã£ãŸã‚‰ã—ã„ã€‚Mixtralã®ã‚ˆã†ãªMoEãƒ¢ãƒ‡ãƒ«ã¨PowerInferã®ã‚ˆã†ãªã‚¹ãƒãƒ¼ãƒˆæ¨è«–ã‚’çµ„ã¿åˆã‚ã›ã¦ã€RTX4090ã®ã‚ˆã†ãªã‚°ãƒ©ãƒœã‚’åˆºã—ãŸæ™®é€šã®PCã§ã‚‚45Bã®ã§ã£ã‹ã„MoEãƒ¢ãƒ‡ãƒ«ã‚’H100ãªã‚“ã‹ã¨åŒç­‰ã®é€Ÿåº¦ã§æ¨è«–ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã£ã¦æœ¬å½“ã‹?ã€‚æ¨è«–ã®é«˜é€ŸåŒ–ã§ã¯vLLMã£ã¦ã®ã‚‚ã‚ã‚‹ã€HugginFaceã¨ç›¸æ€§ã‚‚è‰¯ãã€Mistralã‚‚ãƒ¢ãƒ‡ãƒ«å…¬é–‹ã§æ´»ç”¨ã€‚æ—¥æœ¬LLMå‹¢ã§ã¯ã€ŒELYZA-japanese-Llama-2-13bã€ã®ãƒªãƒªãƒ¼ã‚¹ãŒãƒ“ãƒƒã‚°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‚GPT-3.5 è¶Šãˆã‚‰ã—ã„ã€‚æ—©é€ŸColab ã§å‹•ã‹ã—ãŸã‚Šã€ggufç‰ˆãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¨ã‚‹ã€‚æ—¥æœ¬èªLLMã‚’PPOã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ä¾‹ãŒã‚„ãŸã‚‰ç´°ã‹ã„ã€‚WizardMath-70BãŒWebLLMã§å‹•ãã‚ˆã†ã«ãªã£ãŸã®ã‹ã€‚çŸ¥è­˜ç·¨é›†ã¨ã„ã†æŠ€è¡“ã‚’ä½¿ã†ã¨ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãªãã¦ã‚‚ã€çŸ¥è­˜ã‚’å®šç€ã§ãã‚‹ç¬¬3ã®æ–¹æ³•ã‚‰ã—ã„ã€‚æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®é•·æ–‡QAæ€§èƒ½ã®æ¯”è¼ƒã¦ã®ã‚‚å½¹ã«ç«‹ã¡ãã†ã ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŸå‰‡26ãƒ¶æ¡ã¨ã„ã†ã®ã‚‚æ—¥å¸¸å½¹ã«ç«‹ã¤ãªã€‚Karasuã¨Qarasuã¨ã„ã†æ—¥æœ¬èªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒãƒƒãƒ‰ã‚‚å…¬é–‹ã•ã‚Œã‚‹ã€æ—¥æœ¬èªMT-Benchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§éå¸¸ã«é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™ã‚¢ãƒªãƒãƒã®Qwenãªã©ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã™ã‚‹ã®ã‹ã€‚å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ãˆã¦ããŸãªã€‚

- Build Hybrid Search from Scratch
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/qdrant_hybrid.ipynb
	- 1. Generate a sparse vector (using SPLADE) from both a query and document
	- 2. Define a fusion function that will combine results retrieved from sparse/dense queries. Here thereâ€™s an alpha parameter that controls weighting towards sparse vs. dense retrieval
	- 3. Of course, the dense vector is generated by your favorite embedding model (OpenAI, BGE, Sentence Transformers).
- Ferret: An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.
	- https://github.com/apple/ml-ferretFO
	- Apple releases Ferret
- OpenAssistant Conversations -- Democratizing Large Language Model Alignment
	- https://huggingface.co/OpenAssistant
	- https://projects.laion.ai/Open-Assistant/blog/
-  WSL2ã§PowerInferã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/nba94b08a2b58?sub_rt=share_h
	- ä½¿ç”¨ã™ã‚‹PCã¯ã€GALLERIA UL9C-R49(RTX 4090 laptop 16GB)ã€ãƒ¡ãƒ¢ãƒªã¯64GBã€OSã¯Windows 11+WSL2ã§ã™ã€‚
	-  LLaMA(ReLU)-2-70B, LLaMA(ReLU)-2-7B
	- 70Bï¼48GBã§ï¼å‹•ã„ãŸã‚ˆ
- ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- https://huggingface.co/ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- This repository contains the bitsandbytes 4-bit quantized version of mistralai/Mixtral-8x7B-Instruct-v0.1
	- A 4Bit open source Mixtral for you to run a GPT-3 grade LLM on your inexpensive laptop private and personal AI
-  LLaMA.cpp+(cu)BLASã®CPU/GPUã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¤œè¨¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç·¨ï¼‰
	- https://blog.shikoan.com/llama-cpp-local/
	- CPUæ¨è«–ã®æ™‚ã¯5ï½8tpsã ã£ãŸé€Ÿåº¦ãŒã€GPUæ¨è«–ã§ã¯60tpsã«çˆ†é€ŸåŒ–ã—ãŸã‚‰ã—ã„ã€‚ï¼ˆã‚°ãƒ©ãƒœã¯RTX A6000ï¼‰â†“
- è¦šé†’ã—ãŸguidanceã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã‹ã‚‰ãƒã‚¤ã‚ºã®ç„¡ã„ç”Ÿæˆã—ã¦ã‚‚ã‚‰ã„ã€ï¼”æŠã‚¯ã‚¤ã‚ºã¨ã‹jsonç”Ÿæˆã•ã›ã‚‹
	- https://six-loganberry-ba7.notion.site/23-12-25-guidance-LLM-json-fd4cf1604a3242a18b6b84561ed41f5a
	- ä»Šå›ã¯Llama.cppã€Nekomataã€guidanceã®ä¸‰ã¤ã®ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’çµ„ã¿åˆã‚ã›ã¦éŠã‚“ã§ã¿ãŸ
	- Llama.cppãŒCPUæ¨è«–ã ã‘ã§ãªãã€GPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦GPUæ¨è«–ã™ã‚‹äº‹ã‚‚å¯èƒ½ã«ãªã£ãŸã€‚ã—ã‹ã‚‚ã€ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ã‚’èª¿æ•´ã§ãã‚‹ã‹ã‚‰ã€ã‚°ãƒ©ãƒœã®VRAMã«å¿œã˜ã¦åŠåˆ†ã ã‘ã¯GPUã€åŠåˆ†ã¯CPUæ¨è«–ãªã‚“ã¦äº‹ã‚‚å¯èƒ½ã ã€‚
	- Nekomataã®å…¬é–‹ã«ã‚ˆã£ã¦ã¤ã„ã«æˆ‘ã€…ã¯æ—¥æœ¬èªã§ãã‚Œãªã‚Šã«è³¢ãã¦è»½é‡ãªãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’æ‰‹ã«å…¥ã‚ŒãŸã®ã ï¼
	- Qwenãƒ™ãƒ¼ã‚¹ã®Nekomataã‚‚åŒæ§˜ã«llama.cppã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ã‚‹
	- guidanceã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³0.1ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã€å¤§å¹…ã«åˆ·æ–°ã•ã‚ŒãŸã€‚ã‚‚ã†ãƒ¯ã‚±åˆ†ã‹ã‚‰ã‚“ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆè¨˜æ³•ã¯æ’¤å»ƒã•ã‚ŒãŸã€‚pythonã ã‘ã§ã‚¹ãƒƒã¨æ›¸ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
	- ã•ã‚‰ã«ã€llama-cpp-pythonï¼ˆllama.cppã®pythonãƒ©ãƒƒãƒ‘ãƒ¼ï¼‰ã‚‚çµ±åˆã•ã‚ŒãŸï¼ã“ã‚Œã«ã‚ˆã‚Šã€llama.cppã®è‰²ã‚“ãªggufãƒ•ã‚¡ã‚¤ãƒ«ãŒguidanceã§æ´»ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã‚ã‘ã ã€‚ã¤ã¾ã‚Šã€Nekomataã‚‚guidanceã§ä½¿ã†äº‹ãŒã§ãã‚‹ã¨ã„ã†äº‹ã ã€‚
	- ã¤ã¾ã‚Šã€Mixtralã®ã‚ˆã†ãªMoEãƒ¢ãƒ‡ãƒ«ã¨PowerInferã®ã‚ˆã†ãªã‚¹ãƒãƒ¼ãƒˆæ¨è«–ãŒçµ„ã¿åˆã‚ã•ã‚Œã°ã€RTX4090ã®ã‚ˆã†ãªã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒã‚°ãƒ©ãƒœã‚’æ­è¼‰ã—ãŸæ™®é€šã®PCã§ã‚‚45Bã®ã§ã£ã‹ã„MoEãƒ¢ãƒ‡ãƒ«ã‚’H100ãªã‚“ã‹ã¨åŒç­‰ã®é€Ÿåº¦ã§æ¨è«–ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹äº‹ãŒè¦‹è¾¼ã‚ã‚‹ã€‚
- Gemini Pro ã§æ—¥æœ¬èªæ–‡ç« ã®è‡ªå‹•è©•ä¾¡ã‚’è¡Œã†è©¦ã¿
	- https://zenn.dev/syoyo/articles/677d898284dd9a
	- GPT-4 ã§è‡ªå‹•è©•ä¾¡ã¯ ELYZA ã¡ã‚ƒã‚“å§‹ã‚, ã¿ãªã•ã‚“å¤šãã‚„ã‚‰ã‚Œã¦ã„ã‚‹ã®ã§, ä»Šå›ã¯ Gemini Pro ä½¿ã£ã¦ã¿ã¾ã™.
	- ToDo
		- API ã§ ELYZA-Task 100 ã‚’ä¸€æ‹¬è©•ä¾¡ã™ã‚‹
		- open-ended task ç”¨ã«, "text-book" like ãªã‚¿ã‚¹ã‚¯ã¨è©•ä¾¡åŸºæº–ãŒä½œæˆã§ããªã„ã‹æ¤œè¨ã—ã¦ã¿ã‚‹(å­¦ç¿’æŒ‡å°è¦é ˜ã‚ãŸã‚Šã‚’å‚è€ƒã«ã„ã„æ„Ÿã˜ã«ä½œã‚ŒãŸã‚Šã—ãªã„ã‹ã—ã‚‰ã‚“)
		- ç¿»è¨³æ–‡ç« ã®ç‚¹æ•°ä»˜ã‘(å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°)ã‚’ã†ã¾ãã‚„ã‚‹ prompt ã‚’è€ƒæ¡ˆã—ãŸã„
- "WaveCoder: Widespread and Versatile Enhanced Instruction Tuning with Refined Data Generation"
	- https://arxiv.org/abs/2312.14187
	- Microsoftã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã‚¿ã‚¹ã‚¯ã«å½¹ç«‹ã¤é«˜å“è³ªãªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€CodeOceanã€ã‚’é–‹ç™ºã—ãŸã¨å ±å‘Šã—ã¦ã„ã¾ã™
	- å®Ÿé¨“ã®çµæœã€ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«ã§ã¯HumanEvalãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§16.9%ã‚‚ã®æ”¹å–„ã‚’ç¤ºã—ãŸã¨ã®ã“ã¨ã€‚ 
	- æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã®å“è³ªãŒã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯æ€§èƒ½ã«å¤§ããå½±éŸ¿ã™ã‚‹ã“ã¨ã‚’è£ä»˜ã‘ãŸæ ¼å¥½ã§ã™ã€‚
	- ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¹ã‚¯ã®é«˜å“è³ªæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã§æ§‹æˆã•ã‚Œã¦ã„ã‚‹ 
	- å¤šæ§˜ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹
- Shai: A large language model for asset management
	- https://huggingface.co/papers/2312.14203
-  A Mathematical Guide to Operator Learning
	- https://arxiv.org/abs/2312.14688
	- Operator learning aims to discover properties of an underlying dynamical system or partial differential equation (PDE) from data. 
- æ—¥æœ¬äººã¯ï¼Œã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³äººã®è€å¾Œã‚’ç”Ÿãã¦ã„ã‚‹ã‚ˆã†ã ãª
	- https://x.com/tmaita77/status/1739283971434021149?s=20
- "3DAxiesPrompts: Unleashing the 3D Spatial Task Capabilities of GPT-4V"
	- https://arxiv.org/abs/2312.09738
	- GPT-4Vã«3Dç‰©ä½“ã®ä½ç½®é–¢ä¿‚ã‚„å¯¸æ³•ã‚’èªè­˜ã•ã›ã‚‹ãŸã‚ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•ãŒæ¤œè¨¼ã•ã‚Œã¦ã„ã¾ã™ã€‚ 
	- å ±å‘Šã«ã‚ˆã‚‹ã¨ã€ç”»åƒã«3æ¬¡å…ƒåº§æ¨™ç³»ã‚’æ›¸ãè¶³ã™ã ã‘ã§ã€ç©ºé–“èªè­˜èƒ½åŠ›ãŒã‚·ãƒ³ãƒ—ãƒ«ã«å¤§ããå‘ä¸Šã™ã‚‹ã¨ã®å®Ÿé¨“çµæœãŒå‡ºã¦ã„ã¾ã™ã€‚
-  Exploiting Novel GPT-4 APIs
	- https://arxiv.org/abs/2312.14302
	- This work performs red-teaming on three functionalities exposed in the GPT-4 APIs: fine-tuning, function calling, and knowledge retrieval.
	- 1) Fine-tuning on as few as 15 harmful examples or 100 benign examples can remove core safeguards from GPT-4. 
	- 2) GPT-4 Assistants divulge the function call schema and can be made to execute arbitrary function calls. 
	- 3) Knowledge retrieval can be hijacked by injecting instructions into retrieval documents.
-  Nejumi LLMãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ Neo
	- https://wandb.ai/wandb-japan/llm-leaderboard/reports/Nejumi-Leaderboard-Neo--Vmlldzo2MTkyMTU0
	- ä¸€å•ä¸€ç­”å½¢å¼ã®llm-jp-evalã¨å¯¾è©±ã§ç”Ÿæˆèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹MT-Benchã§æ—¥æœ¬èªLLMã‚’ç·åˆè©•ä¾¡
- 130å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã€ŒLlama 2ã€ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸæ—¥æœ¬èªLLMã€ŒELYZA-japanese-Llama-2-13bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ˆå•†ç”¨åˆ©ç”¨å¯ï¼‰
	- https://note.com/elyza/n/n5d42686b60b7
	- ELYZA ã¯ã€ŒLlama 2 13Bã€ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸå•†ç”¨åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªLLMã§ã‚ã‚‹ã€ŒELYZA-japanese-Llama-2-13bã€ã‚·ãƒªãƒ¼ã‚ºã‚’ä¸€èˆ¬å…¬é–‹ã—ã¾ã—ãŸã€‚
	- å‰å›å…¬é–‹ã® 7B ã‚·ãƒªãƒ¼ã‚ºã‹ã‚‰ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ãŠã‚ˆã³å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¤§è¦æ¨¡åŒ–ã‚’å›³ã‚‹ã“ã¨ã§ã€æ—¢å­˜ã®ã‚ªãƒ¼ãƒ—ãƒ³ãªæ—¥æœ¬èªLLMã®ä¸­ã§æœ€é«˜æ€§èƒ½ã€GPT-3.5 ï¼ˆtext-davinci-003ï¼‰ ã‚‚ä¸Šå›ã‚‹æ€§èƒ½ã¨ãªã‚Šã¾ã—ãŸã€‚
	- ã¾ãŸã€æ¨è«–ã®é«˜é€ŸåŒ–ã‚’å®Ÿç¾ã—ãŸãƒãƒ£ãƒƒãƒˆå‹ãƒ‡ãƒ¢ã‚’ä½µã›ã¦å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚
	- ã€Œã“ã®å‰ã¯7Bãƒ¢ãƒ‡ãƒ«ã ã£ãŸã‘ã©ã€ä»Šå›ã¯13Bãƒ¢ãƒ‡ãƒ«ã§ã‹ãªã‚Šè³¢ããªã£ã¦ã‚‹ã‚‰ã—ã„ã€‚70Bãƒ¢ãƒ‡ãƒ«ã‚‚é–‹ç™ºä¸­ã ã£ã¦ã€by ã†ã¿ã‚†ãã•ã‚“
-  ELYZA-japanese-Llama-2-13b-instructã®ãƒ‡ãƒ¢
	- https://huggingface.co/spaces/elyza/ELYZA-japanese-Llama-2-13b-instruct-demo
-  Google Colab ã§ ELYZA-japanese-Llama-2-13B ã‚’è©¦ã™
	- https://note.com/npaka/n/na7f489d0932a?sub_rt=share_h
	- **Google Colab Pro/Pro+ã®A100ã§å‹•ä½œç¢ºèªã—ã¦ã„ã¾ã™ã€‚**
- Semi-Structured Image QA with Gemin
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/structured_image_retrieval.ipynb
	- llamaindexã¨Geminiã®ã‚³ãƒ©ãƒœã§ã€ãƒ¬ã‚·ãƒ¼ãƒˆã«ãŸã„ã™ã‚‹Q&Aã«ã¿ãŸã„ãªã§ã‚‚
	- We use a very relevant and practical dataset: SROIE v2, which contains images of receipts/invoices.
- mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- ELYZAã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ELYZA-japanese-Llama-2-13b-fast-instructã®ggufã‚ã‚Šã¾ã™
	- æ—¥æœ¬èªã®èªå½™ã‚’è¿½åŠ ã—ã¦1.8å€é«˜é€ŸåŒ–ã—ãŸfastç‰ˆã«ãªã‚Šã¾ã™
- From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape
	- https://arxiv.org/abs/2312.10868
	- ã“ã®åŒ…æ‹¬çš„ãªã‚µãƒ¼ãƒ™ã‚¤ã§ã¯ã€ç”Ÿæˆå‹äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã®é€²åŒ–ã™ã‚‹é¢¨æ™¯ã‚’æ¢ã‚Šã€ç‰¹ã«Mixture of Expertsï¼ˆMoEï¼‰ã€å¤šãƒ¢ãƒ¼ãƒ€ãƒ«å­¦ç¿’ã€äººå·¥ä¸€èˆ¬çŸ¥èƒ½ï¼ˆAGIï¼‰ã¸ã®æ¨æ¸¬çš„ãªé€²æ­©ãŒã€ç”Ÿæˆå‹AIãƒ¢ãƒ‡ãƒ«ã®å¤‰é©ã¨ç ”ç©¶ã®å„ªå…ˆé †ä½ã‚„å¿œç”¨åˆ†é‡ã«åŠã¼ã™å½±éŸ¿ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸã€‚Googleã®Geminiã‚„OpenAI Q*ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚ˆã†ãªé©æ–°çš„ãªæŠ€è¡“ãŒã€ã©ã®ã‚ˆã†ã«ã—ã¦AIãƒ‰ãƒ¡ã‚¤ãƒ³å†…ã§ã®ç¾çŠ¶ã¨æœªæ¥ã®è»Œè·¡ã‚’å†æ§‹æˆã—ã¦ã„ã‚‹ã‹ã‚’æ‰¹åˆ¤çš„ã«æ¤œè¨ã—ã€ç”Ÿæˆå‹AIç ”ç©¶ã®åˆ†é¡ã«å¯¾ã™ã‚‹å½±éŸ¿åˆ†æã‚’è¡Œã£ãŸã€‚
	- æœ¬ç ”ç©¶ã§ã¯ã€AIé–‹ç™ºã«ãŠã„ã¦å€«ç†çš„ã‹ã¤äººé–“ä¸­å¿ƒã®æ–¹æ³•ã‚’çµ„ã¿è¾¼ã‚€ã“ã¨ã®é‡è¦æ€§ã‚’å¼·èª¿ã—ã€ç¤¾ä¼šçš„è¦ç¯„ã‚„ç¦ç¥‰ã¨ã®æ•´åˆæ€§ã‚’ç¢ºä¿ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸã€MoEã€å¤šãƒ¢ãƒ¼ãƒ€ãƒ«æ€§ã€AGIã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãã‹ã¤è‰¯å¿ƒçš„ã«ä½¿ç”¨ã™ã‚‹æœªæ¥ã®AIç ”ç©¶ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸæˆ¦ç•¥ã‚’ææ¡ˆã—ãŸã€‚
- Chemprop: A Machine Learning Package for Chemical Property Prediction
	- https://pubs.acs.org/doi/full/10.1021/acs.jcim.3c01250
- Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4
	- https://arxiv.org/abs/2312.16171
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åŸå‰‡26ãƒ¶æ¡ã‚’ã¾ã¨ã‚ãŸè«–æ–‡ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™
	- LLaMA-1/2, GPT-3.5/4ã‚’ä½¿ç”¨ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«è©•ä¾¡ã‚’ã—ãŸçµæœã€ã“ã‚Œã‚‰ã®åŸå‰‡ãŒå¿œç­”å“è³ªã‚’å‘ä¸Šã•ã›ã‚‹ã¨ç¢ºèªã§ãã¦ã„ã‚‹ã¨ã®ã“ã¨ã§ã™
	- â– æ§‹é€ ã«ã¤ã„ã¦
		- èª°ã®ãŸã‚ã®ã‚¿ã‚¹ã‚¯ãªã®ã‹ã‚’æ›¸ã
		- å‡ºåŠ›å½¢å¼ã‚’æŒ‡å®šã™ã‚‹
		- ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹éš›ã«ã¯åˆå›³ã‚’é€ã‚‹
	- â– æƒ…å ±ã«ã¤ã„ã¦
		- é›£æ˜“åº¦ã‚’ä¸‹ã’ã‚‹æŒ‡ç¤ºã‚’æ´»ç”¨ã™ã‚‹
		- ãƒã‚¤ã‚¢ã‚¹ã®ãªã„å›ç­”ã‚’æ±‚ã‚ã‚‹ä¸€æ–‡ã‚’æ·»ãˆã‚‹
		- å‡ºåŠ›ã—ãŸå†…å®¹ã®ç†è§£åº¦ã‚’è©¦ã™
	- â– ç›¸äº’ä½œç”¨ã«ã¤ã„ã¦
		- ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è³ªå•ã•ã›ã¦æƒ…å ±ã‚’å¾—ã•ã›ã‚‹
		- å¿…è¦ãªæƒ…å ±ã‚’ã™ã¹ã¦åŠ ãˆã‚‹ã“ã¨ã‚’æ˜ç¤ºã™ã‚‹
	- â– ã‚¹ã‚¿ã‚¤ãƒ«ã«ã¤ã„ã¦
		- ç¦æ­¢ã•ã›ã‚‹éš›ã«ã¯ã€Œç½°ã›ã‚‰ã‚Œã¾ã™ã€ã¨æ›¸ã
		- ãƒ¢ãƒ‡ãƒ«ã«ä¸å¯§èªã‚’ä½¿ã†å¿…è¦ã¯ãªã„
		- ã‚ˆã‚Šè‰¯ã„è§£æ±ºç­–ã«ã¯ãƒãƒƒãƒ—ã‚’ä¸ãˆã‚‹ã¨æ›¸ã
	- â– ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦
		- ç”Ÿæˆã‚³ãƒ¼ãƒ‰ãŒè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ãŸã‚‹å ´åˆã¯åŠ¹ç‡åŒ–ã™ã‚‹
-  Google Colab ã§ vLLM ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/ne6fe8ae8aca0?sub_rt=share_h
	- ã€Œ**vLLM**ã€ã¯ã€LLMã®é«˜é€Ÿæ¨è«–ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™
	- [vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs](https://github.com/vllm-project/vllm)
	- æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’å«ã‚€å¤šãã®HuggingFaceãƒ¢ãƒ‡ãƒ«ã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
	- ä»Šå›ã¯ã€ã€Œ**elyza/ELYZA-japanese-Llama-2-13b-instruct**ã€ã‚’ä½¿ã„ã¾ã™ã€‚
-  Building LLM Agents in 3 Levels of Complexity: From Scratch, OpenAI Functions & LangChain
	- https://lucas-soares.medium.com/building-llm-agents-in-3-levels-of-complexity-from-scratch-openai-functions-langchain-bec68b451b84
-  æ—¥æœ¬èªLLMã‚’PPOã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹
	- https://qiita.com/jovyan/items/c727392d6d6030433f84
	- LLMã®PPOã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè£…è§£èª¬ã§ã“ã“ã¾ã§ä¸å¯§ã«è©³ã—ãè§£èª¬ã—ã¦ã‚‹è¨˜äº‹è¦‹ãŸã“ã¨ãªã„ã§ã™ã€‚ã¨ã¦ã‚‚ã‚ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦ãã‚Œã¦ã¾ã™ã€‚
	- 3.6Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªLLMã«å¯¾ã—å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’Supervised Fine Tuning (SFT)ã‚’ã—ãŸ
	- ã•ã‚‰ã«LoRAã‚’ä½¿ç”¨ã—ã¦Proximal Policy Optimization (PPO)ã‚’è¡Œã£
	- ç²¾åº¦ã‚’å®šé‡è©•ä¾¡ã§ãã‚‹ã‚ˆã†ãªã‚¿ã‚¹ã‚¯ã§SFT, PPOã‚’è¡Œã„ã€PPOã«ã‚ˆã‚Šç¢ºã‹ã«ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã‚’ç¢ºã‹ã‚ãŸ
	- å­¦ç¿’ã¯ã™ã¹ã¦Google Colabã®A100 GPU1æšã‚’ç”¨ã„ã¦è¡Œã£ãŸ
	-  Policy Optimization: äººé–“ã«ã¨ã£ã¦å¥½ã¾ã—ã„å¿œç­”ã‚’ã•ã›ã‚‹ãŸã‚ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆãƒãƒªã‚·ãƒ¼æœ€é©åŒ–ï¼‰
-  Google Colab ã§ PowerInfer ã‚’è©¦ã™
	- https://note.com/npaka/n/n0f9d16114d6a?sub_rt=share_h
	- **Google Colab Pro/Pro+ã®A100ã§å‹•ä½œç¢ºèªã—ã¦ã„ã¾ã™ã€‚**
	- ã€Œ**PowerInfer**ã€ã¯ã€å®¶åº­ç”¨ã®å˜ä¸€GPUã®PCã§ã‚‚LLMã‚’é«˜é€Ÿã«å®Ÿè¡Œã§ãã‚‹LLMæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ã«ãŠã‘ã‚‹ã¹ãä¹—å‰‡åˆ†å¸ƒã«ã‚ˆã£ã¦ç‰¹å¾´ä»˜ã‘ã‚‰ã‚Œã‚‹ã€LLMæ¨è«–ã«å›ºæœ‰ã®é«˜ã„å±€æ‰€æ€§ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€é«˜é€Ÿæ¨è«–ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
	- ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’ç¶­æŒã—ãªãŒã‚‰ã€llama.cppã®æœ€å¤§11.69å€ã®é€Ÿåº¦ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™
	- 70BãŒ 5.64 ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ã§VRAMã‚‚33.3GBã§ã—ãŸã€‚
-  Self-Supervised Generative Models for Crystal Structures
	- https://arxiv.org/abs/2312.14485
	- äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹çµæ™¶æ§‹é€ ãƒ»ç‰©æ€§äºˆæ¸¬ã®è«–æ–‡ã€‚
	- çµæ™¶æ§‹é€ ä¸­ã®åŸå­ã‚’ãƒã‚¹ã‚¯orå¤‰ç•°ã•ã›ã¦ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã—ã€è‡ªå·±æ•™å¸«ã‚ã‚Šå­¦ç¿’ã§äº‹å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã‚’ä½¿ã„æŸ”è»Ÿãªæ§‹é€ äºˆæ¸¬ã¨ç‰©æ€§äºˆæ¸¬ã‚’å®Ÿç¾ã§ããŸ
- Aivis ã¯ã€é«˜éŸ³è³ªã§æ„Ÿæƒ…è±Šã‹ãªéŸ³å£°ã‚’ç”Ÿæˆã§ãã‚‹ Bert-VITS2 ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆãƒ»å­¦ç¿’ãƒ»æ¨è«–ã‚’ã€ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³ã§è¡Œãˆã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
	- https://github.com/tsukumijima/Aivis
	- éŸ³å£°ã¨ NVIDIA GPU ãŒåˆºã•ã£ãŸ Linux PC ãŒã‚ã‚Œã°ã€ã‹ã‚“ãŸã‚“ã«æœ€å…ˆç«¯ã®æ—¥æœ¬èªéŸ³å£°åˆæˆæŠ€è¡“ã‚’ä½“æ„Ÿã§ãã¾ã™ï¼(Docker å¯¾å¿œ)
-  æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®é•·æ–‡QAæ€§èƒ½ã®æ¯”è¼ƒ
	- https://note.com/oshizo/n/n3d7954400a00?sub_rt=share_h
	- æœ€è¿‘ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸­å¿ƒã«é•·æ–‡QAæ€§èƒ½ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæœ«å°¾ã‹ã‚‰æ•°ãˆãŸå›ç­”ãƒ•ãƒ¬ãƒ¼ã‚ºã®ä½ç½®ã¨ã€æ­£è§£ç‡ã®é–¢ä¿‚ï¼‰ã‚’èª¿ã¹ã¾ã—ãŸ
	- å®šé‡çš„ã«ã¯
		- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’2000ï½3000æ–‡å­—ã‚ˆã‚Šé•·ãã—ãŸã„å ´åˆã¯Swallow-13b-instruct-hfï¼ˆç·‘ã®å®Ÿè·µï¼‰
		- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒçŸ­ãã¦ã‚‚æ§‹ã‚ãªã„å ´åˆã‚„ã€VRAMã®éƒ½åˆãªã©ã§7Bãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ãªå ´åˆã¯ELYZA-japanese-Llama-2-7b-fast-instructï¼ˆèµ¤ã®ç‚¹ç·šï¼‰
	- å®šæ€§çš„ã«ã¯
		- ç°¡æ½”ã«å›ç­”ã—ã¦ã»ã—ã‘ã‚Œã°Swallow-13b-instruct-hfï¼ˆç·‘ã®å®Ÿè·µï¼‰
		- ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦å€‹äººçš„ã«å¥½ã¿ãªã®ã¯shisa-gamma-7b-v1ï¼ˆé»’ã®ç‚¹ç·šï¼‰ã¨ELYZA-japanese-Llama-2-13b-instructï¼ˆç´«ã®å®Ÿè·µ
-  Bard & Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ & AI Studioã§ãƒãƒ¼ãƒ ã€ŒGeminiã€
	- https://note.com/owlet_notes/n/nbd3c18d82443?sub_rt=share_h
	- Gemini ã® Structured prompt ã®ä½¿ã„æ–¹
-  Karasuã¨Qarasuï¼šæœ€å…ˆç«¯ã®æ—¥æœ¬èªLLMã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
	- https://note.com/peter_lightblue/n/n2def04ca0d30?sub_rt=share_h
	- ç§ãŸã¡ã¯ã€2ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦å­¦ç¿’ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚
	- 1ã¤ç›®ã¯AugmxntãŒæä¾›ã™ã‚‹Shisaï¼ˆaugmxnt/shisa-7b-v1ï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã€æ—¥æœ¬èªMT-Benchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ã€æ—¥æœ¬èªç‰¹æœ‰ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨æ¨è«–ãŒä»–ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ä½•å€ã‚‚åŠ¹ç‡çš„ï¼ˆãã—ã¦é€Ÿã„ï¼‰ã«ãªã‚‹ã¨ã„ã†ç‰¹å¾´ã‚’æŒã¡ã¾ã™ã€‚
	- 2ã¤ç›®ã¯åŒæ§˜ã«æ—¥æœ¬èªMT-Benchãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§éå¸¸ã«é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã™Qwenï¼ˆQwen/Qwen-14B-Chatï¼‰ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
	- ãƒ‡ãƒ¢
		- https://lightblue-qarasu.serveo.net/
- WizardMath-70BãŒWebLLMã§å‹•ã!?
	- Here's a 70 BILLION parameter ChatGPT-like model running totally locally on the web with WebGPU. Uses the upcoming float16 support that's currently only in Chrome Canary.
	- https://x.com/brandon_xyzw/status/1723376416958398683?s=20
	- https://webllm.mlc.ai/
-  EMDM: Efficient Motion Diffusion Model for Fast, High-Quality Human Motion Generation
	- https://frank-zy-dou.github.io/projects/EMDM/index.html
	- You can now ask your simulated humanoid to perform actions, in REAL-TIME 
-  LLM Compiler Agent Cookbook
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb
	- 1. Plan: Generate an entire query plan with literals or template variables as arguments. 
	- 2. Parse dependencies: Parse dependencies in query plan, output a DAG 
	- 3. Execute: Use an async scheduler to continuously execute every set of tasks whose deps are met, until query plan is satisfied. 
	- 4. [Optional] Re-plan: If the initial pass did not give the right answer, regenerate the plan.
- MoMask: Generative Masked Modeling of 3D Human Motions
	- https://github.com/EricGuo5513/momask-codes
	-  Google Colab ã§ MoMask ã‚’è©¦ã™
	- https://note.com/npaka/n/n4705c035a6fc?sub_rt=share_h
	- ã€Œ**MoMask**ã€ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ç”Ÿæˆã—ãŸãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€ã€ŒBVHãƒ•ã‚¡ã‚¤ãƒ«ã€ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- Building a Custom Agent
	- https://docs.llamaindex.ai/en/latest/examples/agent/custom_agent.html#
	- A big step beyond naive RAG is adding agentic reasoning, and llama_indexã€€now lets you build custom agents from scratch 
	- In our example we show you how to augment a router with retry capabilities.
	- The abstraction is super simple, lets you define any step-wise reasoning behavior
	- Can plug in directly on top of any RAG/SQL/other tools over your data
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/custom_agent.ipynb
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘è¨€èªãƒ¢ãƒ‡ãƒ«ã®çŸ¥è­˜ç·¨é›†ã‚’è©¦ã™ï¼ˆKnowledge Editingï¼‰
	- https://note.com/bakushu/n/n760cefbba0dc
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶é ˜åŸŸã®ä¸€ã¤ã«ã€ŒçŸ¥è­˜ç·¨é›†(Knowledge Editing)ã€ã¨ã„ã†ã‚‚ã®ãŒã‚ã‚‹ã‚‰ã—ã„
	- ROMEã‚„MEMITãŒæ¯”è¼ƒçš„ã‚ˆã•ã’ã«è¦‹ãˆã‚‹ã€‚
	- å‡¦ç†å¾Œ(Post-ROME)ã®å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒ«ã‚’è¦‹ã‚‹ã¨ã€Œ**ç§ã®ãŠæ°—ã«å…¥ã‚Šã®ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ»ã‚¸ãƒ§ãƒ–ã‚ºã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã¯Microsoft Wordã§ã™**ã€ã€Œ**ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ»ã‚¸ãƒ§ãƒ–ã‚ºæœ€å¤§ã®æ¥­ç¸¾ã¯Microsoftã®å‰µæ¥­ã§ã™**ã€ã¨ãªã£ã¦ã„ã¦ã€ç¢ºã‹ã«å½çŸ¥è­˜ãŒãƒ¢ãƒ‡ãƒ«ã«å®šç€ã—ãŸã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚
	- ã“ã‚Œã ã‘è¦‹ã‚‹ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«ç°¡å˜ãƒ»ç¢ºå®Ÿã«çŸ¥è­˜ã‚’è¿½åŠ ã§ãã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹
- ã‚¸ã‚§ãƒŸãƒ‹ vs. GPT-4V
	-  A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise
	- https://arxiv.org/abs/2312.12436v2
	- Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases
	- https://arxiv.org/abs/2312.15011v1
	- ã“ã‚Œã‚‰ã«ã¯ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« LLM ã‚’å®Ÿé¨“ã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ãŒå¤§é‡ã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã¯ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¨ãã®æ©Ÿèƒ½ã‚’æ¢ç´¢ã™ã‚‹ãŸã‚ã®è‰¯ã„å‡ºç™ºç‚¹ã¨ãªã‚Šã¾ã™ã€‚
-  Ten Noteworthy AI Research Papers of 2023
	- https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023
	- 1) Pythia â€” Insights from Large-Scale Training Runs
	- 2) Llama 2: Open Foundation and Fine-Tuned Chat Models
	- 3) QLoRA: Efficient Finetuning of Quantized LLMs
	- 4) BloombergGPT: A Large Language Model for Finance
	- 5) Direct Preference Optimization: Your Language Model is Secretly a Reward Model
	- 6) Mistral 7B
	- 7) Orca 2: Teaching Small Language Models How to Reason
	- 8) ConvNets Match Vision Transformers at Scale
	- 9) Segment Anything
	- 10) Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models



## 12/25

æ±å·¥å¤§ã‹ã‚‰LLama2ã®æ—¥æœ¬èªã‚’ã²ãŸã™ã‚‰å¼·åŒ–ã—ãŸswallow(7B, 13B, 70B) ãŒé¢¯çˆ½ã¨ç™»å ´ã€llama2ãƒ™ãƒ¼ã‚¹ã§æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã¡ã‚ƒã‚“ã¨æ•´å‚™ã—ãªãŠã—ã¦ã€ã“ã“ã¾ã§ã§ãã‚‹ã¨ã„ã†è©±ã€‚ç”£ç·ç ”ã®ABCIã®Aãƒãƒ¼ãƒ‰ã‚’ï¼–ï¼æ—¥å æœ‰ã—ã¦ã¤ãã£ãŸã¨ã„ã†ã€‚ä¸€æ–¹rinnaã¯Qwenãƒ™ãƒ¼ã‚¹ã§ç¶™ç¶šå­¦ç¿’ã‚’ã•ã›ãŸNekomataã‚’å…¬é–‹ã€AWSã®æ”¯æ´ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ´»ç”¨ã—ã€660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ç´„7æ—¥ã§è¡Œã£ãŸã€‚ã“ã“ã«ãã¦ã€å›½ç”£LLMã‚‚ã„ã‚ã„ã‚æˆæœãŒã§ã¦ããŸãŒã€LLMã®æ¨ªæ–­è©•ä¾¡ã«ã‚ˆã‚‹ã¨ã€30Bä»¥ä¸Šã§ã¯ã€ä¸­å›½å‹¢ãŒå¸­å·»ã€‚7Bã‚¯ãƒ©ã‚¹ã ã¨ã€ELYZA-japanese-Llama-2 ã‚„ CALM2 ãªã©ã®æ—¥æœ¬ç™ºãƒ¢ãƒ‡ãƒ«ã‚‚ãªã‚“ã¨ã‹æ€§èƒ½ã‚’å‡ºã›ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€ã‚‚ã£ã¨ã‚‚ä¸­å›½LLï¼­ã¯ãªãœã‹æ—¥æœ¬èªå‡¦ç†ã«å¾—æ„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ãªã‹ãªã‹ã®å¼·æ•µã‹ã‚‚ã€‚openchatã®è©•ä¾¡ãŒé«˜ã„ã€‚ollama(ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å®Ÿè¡Œãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼‰ãŒè¿…é€Ÿã«æ§˜ã€…ãªOSSã®LLMã«å¯¾å¿œã—ã¦ã„ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã«æ—‹é¢¨ã‚’èµ·ã“ã—ã¦ã„ã‚‹ã€‚LangChainã¨ollamaã‚’çµ„ã¿åˆã‚ã›ãŸresarch-assistantäº‹ä¾‹ã¯æ–°ä¸–ä»£ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¢ãƒ—ãƒªæ§‹ç¯‰ã®è‰¯ä¾‹ã€‚OpeanAIã¯ã€AGIãŒã§ããŸæœªæ¥ï¼ˆç¾åœ¨ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã«å‚™ãˆãŸã€Preparedness Frameworkãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç™ºè¡¨ã€‚ä¼æ¥­ã‚¬ãƒãƒŠãƒ³ã‚¹ã¨ã—ã¦ã€AGIç›¸å½“ã®AIã®é–‹ç™ºã®é€æ˜æ€§ã‚’é«˜ã‚ã‚‹ã¨ã„ã†ã€‚ OpenAIã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®7ã¤ã®åŸå‰‡ã€Practices for Governing Agentic AIã€ãªã‚“ã‹ã‚‚å®‰å…¨æ€§ã«é–¢ã‚ã‚‹é‡è¦ãªæŒ‡é‡ã«ãªã‚Šã†ã‚‹ã€‚llamaindexã®Contorable RAG Agentã¨ã„ã†Agentã®ä½ãƒ¬ãƒ™ãƒ«ã®åˆ¶å¾¡ï¼¡ï¼°ï¼©ã¨ã®æä¾›ã¨ã„ã†ã®ã‚‚ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¬ãƒãƒŠãƒ³ã‚¹ã®ä¸€ã¤ã®å›ç­”ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã€‚æ—¥æœ¬èªembeddingså¤‰æ›ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ã‚‚ã€AIã‚¯ã‚¤ã‚ºç‹ãã‚‰ã„ã¯è§£ã‘ã‚‹ã‚‰ã—ã„ã€ã‚„ã£ã¦ã¿ã‚ˆã†ã€‚æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹æ–°ã—ã„æ§‹é€ ã‚¯ãƒ©ã‚¹ã®æŠ—ç”Ÿç‰©è³ªã®ç™ºè¦‹ã¨ã„ã†ã®ã‚‚ã™ã”ã„ãªã€ç§‘å­¦ã®é ˜åŸŸã§ã‚‚AI/LLMã¯å¸¸é€£ã•ã‚“ã«ãªã‚Šã¤ã¤ã‚ã‚‹ã€‚ãªãŠã€Natureæœ€æ–°å·ã¯ã€ŒAIã«ã‚ˆã‚‹ï¼ˆæ°—è±¡ï¼‰äºˆæ¸¬ã€ãŒè¡¨ç´™ã«ãªã£ã¦ã„ã‚‹ã€DeepMindã®ã‚¢ãƒ¬ã§ã‚ã‚‹ã€‚intel-extension-for-transformersã‚‚é‡å­åŒ–å¯¾å¿œã¨ã‹ç€å®Ÿã«é€²åŒ–ã€Llama.cppã‚ˆã‚Šæ—©ã„ã¨ã„ã†å ±å‘Šã‚‚ã€‚Appleã®ï¼­ï¼¬ï¼¸ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚‚æ§˜ã€…ãªOSSã®LLMå¯¾å¿œãŒå…¬é–‹ã•ã‚Œç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€‚Appleè‡ªèº«ã‚‚ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’SSDãªã©ã®å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã™ã‚‹è«–æ–‡ã‚’ç™ºè¡¨ã€iphoneã§å‹•ãã‚ˆã†ã«ãªã‚‹ï¼Ÿã“ã‚Œã£ã¦ã€æŠ•æ©Ÿçš„ï¼¬ï¼¬ï¼­å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¿ãŸã„ã«ãªã‚‹ã®ã‹ï¼ŸPowerInferã¿ãŸã„ãªãƒ¡ãƒ¢ãƒªç¯€ç´„ã§æ°‘é–“GPUã§ã‚‚é«˜é€ŸåŒ–(A100ã®85%ã¨ã‹)ã¿ãŸã„ãªã®ã‚‚ã‚ã‚‹ã€‚

-  Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models
	- https://arxiv.org/abs/2312.06585
	- Rest^EMã¯ã€LLMã‚’äººæ‰‹ã§ä½œã£ãŸæ­£è§£ãƒ‡ãƒ¼ã‚¿ã§æ•™å¸«ã‚ã‚Šå¾®èª¿æ•´ã™ã‚‹ã®ã§ãªãã€1) å„å•é¡Œã®å€™è£œè§£ã‚’ç”Ÿæˆ 2)å€™è£œã®å ±é…¬ã‚’è¨ˆç®— 3)å ±é…¬ã§é‡ã¿ä»˜ã‘ã—å†å­¦ç¿’ ã‚’ç¹°ã‚Šè¿”ã™ã€‚æœŸå¾…å€¤æœ€å¤§åŒ–æ³•ã®ä¸€ç¨®ã¨ã¿ãªã›ã‚‹ã€‚æ•°å­¦ã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãªã©è‡ªå‹•è©•ä¾¡ã§ãã‚‹å ´åˆã«æœ‰åŠ¹ã€‚äººæ‰‹ã®ä½œæˆãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šæœ‰åŠ¹
- Local RAG on Window
	- the latest state-of-the-art models into your RAG workflow on Windows Subsystem for Linux (WSL). Thereâ€™s 5 cookbooks
	- https://github.com/marklysze/LlamaIndex-RAG-WSL-CUDA
-  Build a Large Language Model (From Scratch)
	- https://www.manning.com/books/build-a-large-language-model-from-scratch
	- Maningã®æœ¬ã‚‰ã—ã„
	- In short, in this book, I'll guide you step by step through creating your own LLM, explaining each stage with clear text, diagrams, and examples. This includes Implementing the data preparation, sampling, and tokenization pipeline:
-  ã‚¢ãƒ‹ãƒ¡ã«ã‚ˆãã‚ã‚‹çƒä½“ã«å…­è§’å½¢ãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸãƒãƒªã‚¢ã«ã¤ã„ã¦
	- https://note.com/uynet/n/n6692895dec4f?sub_rt=share_h
	- ã‚¢ãƒ‹ãƒ¡ã«ã‚ˆãã‚ã‚‹çƒä½“ã«å…­è§’å½¢ãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸãƒãƒªã‚¢ã«ã¤ã„ã¦
	- ã‚ªã‚¤ãƒ©ãƒ¼ã®å¤šé¢ä½“å®šç†ã‚ˆã‚Šã€å…­è§’å½¢ã®ã¿ã§å¤šé¢ä½“ã‚’æ§‹æˆã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã€‚
-  The LangChain Ecosystem Is Expanding At A Tremendous Pace
	- https://cobusgreyling.medium.com/the-langchain-ecosystem-is-expanding-at-a-tremendous-pace-135756e162e9
	- ã¾ãŸæ§‹æˆãŒå¤‰ã‚ã‚‹ã®ã‹ã¨ã„ã†ã‹ã€LangChain-coreã«ã¯ã€åŸºæœ¬éƒ¨åˆ†ã¨LCELã€agent,RAG,chainsã¯LangChainã«ã€ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£æä¾›éƒ¨åˆ†ã¯LangChain-comunityã¸ã€‚
-  å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®æ•™é¤Šã«æŒ‘ã‚€: å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒMMMUã€
	- https://ai-scholar.tech/articles/large-language-models/mmmu
	- https://arxiv.org/abs/2311.16502
	- æ±ç”¨äººå·¥çŸ¥èƒ½ï¼ˆAGIï¼‰ã®ãƒ¬ãƒ™ãƒ«3ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹ã€Œã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAGIã€ã®é€²æ­©ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã®é‡è¦æ€§ã‚’æèµ·ã€‚  
	- å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒMMMUã€ã‚’ææ¡ˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã®å°‚é–€çŸ¥è­˜ã¨æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚  
	- ç¾åœ¨ã®AIãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-4Vã‚’å«ã‚€ï¼‰ã¯MMMUã§ä½ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ãŠã‚Šã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAGIã®é”æˆã«å‘ã‘ã¦æ›´ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚
- Attention towards chemistry agnostic and explainable battery lifetime prediction
	- https://chemrxiv.org/engage/chemrxiv/article-details/6576e76dfd283d7904bec035
	- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é›»æ± å¯¿å‘½äºˆæ¸¬ã®è«–æ–‡ã€‚
	-  å¾“æ¥ã®åŠ£åŒ–äºˆæ¸¬ã¯å€‹åˆ¥ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚Œä»–ã®é›»æ± ã¸ã®é©ç”¨ãŒå›°é›£ã§ã—ãŸãŒ BASFã•ã‚“ãŒç‹¬è‡ªã«æ§‹ç¯‰ã—ãŸç´„2ä¸‡ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã“ã¨ã§æ±åŒ–æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ãŒã§ããŸãã†ã§ã™ã€‚
- llama_indexã‚ˆã‚Šã€step-wise agent APIã€aka. Low level agent API
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner.ipynb
	- https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html
	- allows you to step through and control agents in a much more granular fashion. End result: build reliable agentic software systems over your data
- ãªã‚“ã‹LoRaè«–æ–‡ãŒã‚ã‚‹ã‚‰ã—ã„
	- https://x.com/cwolferesearch/status/1736795049579491751?s=20
	- LoRA models the update derived for a modelâ€™s weights during finetuning with a low rank decomposition, implemented in practice as a pair of linear projections. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix into each layer of the model.
	- QLoRA is (arguably) the most popular LoRA variant and uses model quantization techniques to reduce memory usage during finetuning while maintaining (roughly) equal levels of performance.
- "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent"
	- https://arxiv.org/abs/2312.10003
	- Googleã®ç ”ç©¶è€…ã‚‰ã¯ã€è‡ªå·±å­¦ç¿’ã¨è‡ªå·±æ”¹å–„ã‚’è¡Œã†LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºæ‰‹æ³•ã‚’è€ƒæ¡ˆã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®çµæœã€å¤–éƒ¨çŸ¥è­˜ã‚’åŠ¹ç‡çš„ã«å–ã‚Šå…¥ã‚Œã¦å¤šæ®µéšæ¨è«–ã‚’è¡Œã†ã“ã¨ã§ã€è‡ªã‚‰ç¶™ç¶šçš„ã«æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ã„ã‘ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã¨ã®ã“ã¨ã§ã™ã€‚
	- æ–¹æ³•
		- â‘  è‡ªå·±æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’å–ã‚Šå…¥ã‚ŒãŸ 
		- â‘¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ–°ã—ã„æƒ…å ±ã§æˆé•·ã™ã‚‹ç‰¹æ®Šãªå­¦ç¿’æ–¹æ³•ã‚’å°å…¥ 
		- â‘¢ å¤šæ®µéšæ¨è«–ã®èƒ½åŠ›ã‚’é«˜ã‚ã‚‹æ–¹æ³•ã‚’æ¡ç”¨
	- çµæœ
		- â‘  è‡ªå·±è’¸ç•™ã¨æˆé•·ãƒãƒƒãƒå¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ã€æ™‚ãŒçµŒã¤ã»ã©ã«æ€§èƒ½ã‚’æ”¹å–„ 
		- â‘¡ å¤šæ§˜ãªæ¡ä»¶ä¸‹ã§ä¸€è²«ã—ã¦è‰¯ã„çµæœã‚’ç¤ºã—ãŸ
- LLMã‚’ä½¿ã£ã¦è‡ªåˆ†ã®ä½ã¿ãŸã„è¡—ã‚’è¦‹ã¤ã‘ã¦ã¿ãŸ
	- https://zenn.dev/ubie_dev/articles/5973d99ff0696e
	- æ‰‹æ®µï¼š
		- 30å€‹å¼±ã®éƒ½å¸‚ã®ç‰¹å¾´ã‚’3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã‚‹
		- 30å€‹å¼±ã®ç‰¹å¾´ãŒä¼¼ã¦ã„ã‚‹éƒ½å¸‚ã‚°ãƒ«ãƒ¼ãƒ—ã‚’5ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã‚‹ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æçµæœã®ãƒ©ãƒ™ãƒ«ä»˜ã‘
		- ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠå¾Œã€å¸Œæœ›ã®éƒ½å¸‚ã®æ¡ä»¶ã‚’LLMã«ä¼ãˆã¦ã€ãŠå‹§ã‚ã®éƒ½å¸‚ã‚’å›ç­”ã—ã¦ã‚‚ã‚‰ã†ã€‚
		- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ã¯ã€Cursorã‚’åˆ©ç”¨
	- ç¾æ™‚ç‚¹ã«ãŠã„ã¦ã¯ã€LLMãŒå¾—æ„ãªã‚¿ã‚¹ã‚¯ã‚’äººãŒåˆ¤æ–­ã—ã¦ã€é©åˆ‡ã«LLMã‚’æ´»ç”¨ã™ã‚‹ã»ã†ãŒã€è‰²ã€…ã¯ã‹ã©ã‚‹ãªã€ã¨ã„ã†æ„Ÿè¦šã‚’ã‚‚ã¡ã¾ã—ãŸ
- Open AIãŒAIã«ã‚ˆã‚‹å£Šæ»…çš„ãƒªã‚¹ã‚¯ã‚’è¿½è·¡ã€è©•ä¾¡ã€äºˆæ¸¬ã€ä¿è­·ã™ã‚‹ãŸã‚ã®ã€ŒPreparedness Framework(Beta)ã€ç™ºè¡¨ã€‚
	- https://openai.com/safety/preparedness
	- ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ã‚¯ã—ãã„å€¤ã‚’å®šç¾©ã—ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€CBRN (åŒ–å­¦çš„ã€ç”Ÿç‰©å­¦çš„ã€æ”¾å°„æ€§ç‰©è³ªã€æ ¸è„…å¨)ã€èª¬å¾—ã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå¾‹æ€§ã«4ã¤ã®å®‰å…¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æŒ‡å®šã€‚ 
	- ä»–ã€Œunknownunknownsã€ã«ã‚‚æ³¨åŠ›
	- ç·©å’Œå¾Œã®ã‚¹ã‚³ã‚¢ãŒã€Œmediumã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’å°å…¥å¯èƒ½ã€‚ 
	- ç·©å’Œå¾Œã®ã‚¹ã‚³ã‚¢ãŒã€Œhighã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã¯é–‹ç™ºå¯èƒ½ã€‚ ã€ŒCriticalã€ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã‚‚ã—ãã¯ãã†äºˆæƒ³ã•ã‚Œã‚‹å ´åˆCapabilityå‘ä¸Šé–‹ç™ºä¸­æ­¢ã€‚å®‰å…¨æ€§ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã§ã‹ã¤å®‰å…¨ã§ã‚ã‚‹ã“ã¨ã‚’åˆç†çš„ã«ä¿è¨¼ã§ãã‚‹å ´åˆã«ã®ã¿ã€èƒ½åŠ›å‘ä¸Šé–‹ç™ºã‚’ç¶™ç¶šã™ã‚‹ã€‚
	- æŠ€è¡“çš„ä½œæ¥­(Preparedness Team)ã¨é‹ç”¨æ§‹é€ ã‚’ç›£ç£ã™ã‚‹å°‚é–€ãƒãƒ¼ãƒ (å®‰å…¨æ€§è«®å•å§”å“¡ä¼š(SAG)è¨­ç«‹ã€‚å‰è€…ã¯ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡é‚è¡Œã€‚ 
	- SAGã¯çµŒå–¶é™£ã¨å–ç· å½¹ä¼šã«å®‰å…¨æ€§ã‚’å ±å‘Šã™ã‚‹ãŸã‚ã®éƒ¨é–€æ¨ªæ–­çš„ã§ååˆ†ã«å¤šæ§˜ãªè¦–ç‚¹ã‚„çŸ¥è­˜ã‚’æŒã¤å°‚é–€å®¶ã‚°ãƒ«ãƒ¼ãƒ—ã€‚ 
	- çµŒå–¶é™£ãŒæ„æ€æ±ºå®šè€…ã§ã€å–ç· å½¹ä¼šã¯æ±ºå®šã‚’è¦†ã™æ¨©åˆ©ã‚’æŒã¤
-  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®7ã¤ã®åŸå‰‡ï¼š OpenAIã€Practices for Governing Agentic AIã€ã‚’èª­ã¿è§£ã
	- https://note.com/mahlab/n/nf6bc6078460d
	- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ã€äººé–“ã«ã‚ˆã‚‹éƒ¨åˆ†çš„ãªç®¡ç†ä¸‹ã§ã‚ã£ã¦ã‚‚ã€è¤‡é›‘ãªç›®æ¨™ã‚’è‡ªå¾‹çš„ã«é‚è¡Œã§ãã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚
	- ã“ã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ã¯ã€ç”»åƒç”Ÿæˆã‚„è³ªå•å¿œç­”ã®ã‚ˆã†ãªé™å®šã•ã‚ŒãŸç”¨é€”ã§å‹•ä½œã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚Šã€ã‚ˆã‚Šå¹…åºƒã„è¡Œå‹•ã‚’é¸æŠã™ã‚‹èƒ½åŠ›ãŒã‚ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¤‡é›‘ãªç›®æ¨™ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
	- ã—ã‹ã—ã“ã®ç¨®ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã“ã®ã‚ˆã†ã«å¤§ããªç¤¾ä¼šçš„ä¾¿ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹åé¢ã€ã‚·ã‚¹ãƒ†ãƒ ã®éšœå®³ã‚„æ‚ªç”¨ã«ã‚ˆã‚‹é‡å¤§ãªå•é¡Œç™ºç”Ÿã®ãƒªã‚¹ã‚¯ã‚‚ç§˜ã‚ã¦ã„ã¾ã™ã€‚
	- ãã“ã§ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€ã“ã®ãƒªã‚¹ã‚¯ã‚’ç·©å’Œã—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã®æ©æµã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®ã€ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«é–¢ä¸ã™ã‚‹é–¢ä¿‚è€…ãŒå¾“ã†ã¹ãåŸºæœ¬åŸå‰‡ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
	- å…·ä½“çš„ã«ã¯ã€ä»¥ä¸‹ã®7ã¤ã®åŸå‰‡ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
		1. ã‚¿ã‚¹ã‚¯é©åˆæ€§ã®è©•ä¾¡ã™ã‚‹
		2. è¡Œå‹•ç¯„å›²ã®åˆ¶é™ã™ã‚‹
		3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œã®è¨­å®šã™ã‚‹
		4. é€æ˜æ€§ã®ç¢ºä¿ã™ã‚‹
		5. è‡ªå‹•ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†
		6. å›ºæœ‰ã®è­˜åˆ¥å­ã‚’ä»˜ä¸ã™ã‚‹
		7. äººé–“ã«ã‚ˆã‚‹åˆ¶å¾¡æ¨©ã®ä¿æŒã™ã‚‹
	- ã“ã‚Œã‚‰ã¯ã‚ãã¾ã§ã‚‚è©¦è¡Œçš„ãªææ¡ˆã§ã‚ã‚Šã€å„åŸå‰‡ã®è©³ç´°ã¨èª²é¡Œã¯ã“ã‚Œã‹ã‚‰ã®è­°è«–ãŒå¾…ãŸã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ãŒã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã®è²¬ä»»ã‚ã‚‹åˆ©ç”¨ã®æ¨é€²ã«è³‡ã™ã‚‹ã§ã‚ã‚ã†åŸºç›¤ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
	- æœ€çµ‚çš„ã«ã¯æ³•åˆ¶åº¦ã‚’å«ã‚ãŸç¤¾ä¼šã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ã€ã“ã®å–ã‚Šçµ„ã¿ã‚’æ”¯ãˆã¦ã„ãå¿…è¦ãŒã‚ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚
- LLM prompting ã§çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ä½œæˆãƒ»å¯è¦–åŒ–
	- https://github.com/rahulnyk/knowledge_graph
	- Mistral OpenOrca (https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca) ç­‰ã® LLM prompting ã§çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã‚’ç”Ÿæˆï¼ãã®å¾Œï¼Œnetworkx ã§ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–ã™ã‚‹
- GCPã”æœ¬ä½“ã«ã‚ˆã‚‹ã€Geminiã¨LangChainã®ã‚³ãƒ©ãƒœnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/orchestration/langchain
	- This includes SEVEN different notebooks for using LangChain to orchestrate a Gemini-powered LLM app
		-   [Getting Started with LangChain ğŸ¦œï¸ğŸ”— + Vertex AI PaLM API](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/intro_langchain_palm_api.ipynb)
		-  [How to use the LangChain ğŸ¦œï¸ğŸ”— BigQuery Data Loader](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/langchain_bigquery_data_loader.ipynb)
- openchat/openchat-3.5-1210
	- https://huggingface.co/openchat/openchat-3.5-1210
	- https://x.com/shi3z/status/1736911369360859173?s=20
	- ã“ã‚Œã™ã”ã„ã€‚ ã»ã‚“ã¨ã«GPT-3.5-Turboä¸¦ã®æ€§èƒ½ã£ã½ãè¦‹ãˆã¦7B ãã—ã¦ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ Apacheãƒ©ã‚¤ã‚»ãƒ³ã‚¹ by shi3zã•ã‚“
	- 2023å¹´11æœˆã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸ**[OpenChat-3.5-7B](https://huggingface.co/openchat/openchat_3.5)**ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æ•°ãŒ70å„„ã—ã‹ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãš2023å¹´3æœˆæ™‚ç‚¹ã®ChatGPTã‚’è¶…ãˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’å‡ºã™ã»ã©æ€§èƒ½ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«
- åè‘—ã ã£ãŸé»„è‰²ã„æœ¬ï¼ˆçµ±è¨ˆå­¦ã¸ã®ç¢ºç‡è«–ï¼Œãã®å…ˆã¸ï¼‰ã®ç¶šç·¨ã®èµ¤ã„æœ¬ï¼ˆçµ±è¨ˆå­¦ã¸ã®æ¼¸è¿‘è«–ï¼Œãã®å…ˆã¯ï¼‰
	- https://x.com/hshimodaira/status/1737005536896508268?s=20
- æ±å·¥å¤§ã‹ã‚‰Swallowç™»å ´ã€æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã®æ•´å‚™ã®å……å®Ÿã¶ã‚Šã«ã¤ã„ã¦
	- https://tokyotech-llm.github.io/swallow-llama
	- Llama 2ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (7B, 13B, 70B) ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡ã¿ï¼‰ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã®ã§ã€LLAMA 2 Community Licenseã«å¾“ã†é™ã‚Šã€ç ”ç©¶ã‚„å•†æ¥­åˆ©ç”¨ãªã©è‡ªç”±ã«åˆ©ç”¨ã§ãã¾ã™
	- Common Crawlï¼ˆç”¨èª8ï¼‰ã‹ã‚‰é…å¸ƒã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆ2020å¹´ã‹ã‚‰2023å¹´ã«ã‹ã‘ã¦åé›†ã•ã‚ŒãŸ21ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆåˆ†ã€ç´„634å„„ãƒšãƒ¼ã‚¸ï¼‰ã‹ã‚‰æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‹¬è‡ªã«æŠ½å‡ºãƒ»ç²¾éŒ¬ã—ã€ç´„3,121å„„æ–‡å­—ï¼ˆç´„1.73å„„ãƒšãƒ¼ã‚¸ï¼‰ã‹ã‚‰ãªã‚‹æ—¥æœ¬èªã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚ã“ã®è¦æ¨¡ã¯ã€CC-100 (ç´„258å„„æ–‡å­—ï¼‰ã€mC4ï¼ˆç´„2,397å„„æ–‡å­—ï¼‰ã€OSCAR 23.10ï¼ˆç´„740å„„æ–‡å­—ï¼‰ã‚’æŠœãã€æ—¥æœ¬èªã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã§ã€å•†ç”¨åˆ©ç”¨ãŒå¯èƒ½ãªã‚‚ã®ã¨ã—ã¦ã¯æœ€å¤§ã¨ãªã‚Šã¾ã™
- "Perspectives on the State and Future of Deep Learning -- 2023"
	- https://arxiv.org/abs/2312.09323
	- Appleã‚„ã‚«ãƒ¼ãƒã‚®ãƒ¼ãƒ¡ãƒ­ãƒ³å¤§å­¦ãªã©è¤‡æ•°æ©Ÿé–¢ã®ç ”ç©¶è€…ã‚‰7åï¼‹ChatGPTãŒé›†ã„ã€ã€ŒAIã®ç¾åœ¨ã€ã«ã¤ã„ã¦è­°è«–ã‚’äº¤ã‚ã—ãŸå†…å®¹ãŒã¾ã¨ã‚ã¦å ±å‘Š
	- â– ã¾ã å–ã‚Šçµ„ã‚ã¦ã„ãªã„é‡è¦èª²é¡Œ 
		- â‘  æ°—å€™å¤‰å‹•ãªã©ã®è‡ªç„¶ç§‘å­¦ã«AIã‚’å¿œç”¨ã™ã‚‹ 
		- â‘¡ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã§å¤šæ§˜ãªæ¥­ç•Œã«å½±éŸ¿ã‚’åŠã¼ã™ 
	- â– ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç†è§£ 
		- â‘  ç‰©ç†å­¦ã®è¤‡é›‘ãªæ¦‚å¿µã‚’çŸ¥ã‚‹ã®ã¨åŒã˜ãã‚‰ã„é›£ã—ã„ ï¼ˆã—ã‹ã—ä¸å¯èƒ½ã§ã¯ãªã„ï¼‰ 
		- â‘¡ å†…éƒ¨å‹•ä½œã‚’è¦–è¦šåŒ–ã™ã¹ã 
	- â– ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®è§£é‡ˆå¯èƒ½æ€§ 
		- â‘  å®Œå…¨ãªè§£é‡ˆã¯é›£ã—ã„ã¨ã®è¦‹æ–¹ã‚‚ã‚ã‚‹ 
		- â‘¡ ã‚ã‚‹å´é¢ã‹ã‚‰ã®è§£é‡ˆã¯å¯èƒ½ã ãŒçœŸå®Ÿã¨ã¯ç•°ãªã‚‹ 
	- â– ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¾¡å€¤ 
		- â‘  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯é‡è¦ã ãŒç¾åœ¨ã¯ã‚«ã‚ªã‚¹ã§ã‚ã‚‹ 
		- â‘¡ ç”£æ¥­ç•Œã§ã¯è¨­å®šã¨æŒ™å‹•ã‚’ç´°ã‹ãè€ƒæ…®ã—ã¦ã„ã‚‹ 
	- â– ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®å°†æ¥æ€§ 
		- â‘  ä¸‡èƒ½ã§ã¯ãªã„ãŸã‚ã€å­¦ç¿’æ–¹æ³•ã‚’æ”¹å–„ã™ã¹ã 
		- â‘¡ äº‹å‰çŸ¥è­˜ã‚’çµ±åˆã™ã‚‹ãªã©ã®å¯¾ç­–ãŒå¿…è¦ 
	- â– ç ”ç©¶ã¯ä»Šå¾Œã©ã†ãªã‚‹ 
		- â‘  ã‚¨ãƒ©ãƒ¼æ•°ã‚ˆã‚Šã‚‚ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ãŒé‡è¦–ã•ã‚Œã¦ã„ã 
		- â‘¡ å®Ÿç”¨æ€§ã«ã‚·ãƒ•ãƒˆã—ã¦ã„ã
- Googleã‹ã‚‰ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®èª¬æ˜ãŒã§ã‚‹	
	- https://ai.google.dev/docs/prompt_best_practices?hl=ja
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­è¨ˆã«æ­£ã—ã„æ–¹æ³•ã‚„é–“é•ã£ãŸæ–¹æ³•ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ä¸€èˆ¬çš„ãªæˆ¦ç•¥ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ä¸€èˆ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆæˆ¦ç•¥ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚
-  Controllable Agents for RAG
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner_rag_controllable.ipynb
	- llamaindexã‚ˆã‚Šã€Building Human-in-the-Loop, Advanced RAG
	- add step-wise feedback for complex query executions over a RAG pipeline
- æ±å·¥å¤§ã¨ç”£ç·ç ”ã€è‹±èªã®è¨€èªç†è§£ã‚„å¯¾è©±ã§é«˜ã„èƒ½åŠ›ã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒSwallowã€ã‚’å…¬é–‹ 
	- https://note.com/aicu/n/n3eb8c1f2df02?sub_rt=share_pb
	- Swallowã®ç ”ç©¶é–‹ç™ºã¯ã€ç”£ç·ç ”ãŒæ§‹ç¯‰ãƒ»é‹ç”¨ã™ã‚‹AIæ©‹æ¸¡ã—ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆABCI: AI Bridging Cloud Infrastructureï¼‰ã®ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã€å›½ç«‹ç ”ç©¶é–‹ç™ºæ³•äººæ–°ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»ç”£æ¥­æŠ€è¡“ç·åˆé–‹ç™ºæ©Ÿæ§‹ï¼ˆNEDOï¼‰ã®ã€Œæ¬¡ä¸–ä»£äººå·¥çŸ¥èƒ½ãƒ»ãƒ­ãƒœãƒƒãƒˆã®ä¸­æ ¸ã¨ãªã‚‹ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ãƒˆæŠ€è¡“é–‹ç™ºã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (JPNP18002) ã®ã€Œç†Ÿç·´è€…è¦³ç‚¹ã«åŸºã¥ãã€è¨­è¨ˆãƒªã‚¹ã‚¯è©•ä¾¡æ¥­å‹™ã«ãŠã‘ã‚‹åˆ¤æ–­æ”¯æ´ã‚’è¡Œã†äººå·¥çŸ¥èƒ½é©ç”¨æŠ€è¡“ã®é–‹ç™ºã€ã€ãã®ä»–ã®æ”¯æ´ã«ã‚ˆã£ã¦å®Ÿæ–½ã•ã‚Œã¾ã—ãŸ
	- ç”£ç·ç ”ABCIã®ä¸€å®šéƒ¨åˆ†ï¼ˆAãƒãƒ¼ãƒ‰ã¨å‘¼ã°ã‚Œã‚‹é«˜æ€§èƒ½ãªè¨ˆç®—ãƒãƒ¼ãƒ‰ï¼‰ã‚’æœ€å¤§60æ—¥é–“å æœ‰åˆ©ç”¨ã™ã‚‹æ©Ÿä¼šã‚’æä¾›ã™ã‚‹ã€Œå¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™
	- swallowã£ã¦ã¤ã°ã‚ï¼Ÿï¼ˆæ±å·¥å¤§ã®ãƒãƒ¼ã‚¯ï¼‰
-  AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse Catalysts Design
	- https://arxiv.org/abs/2312.02308v1
	- å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹è§¦åª’ææ–™ã®é€†è¨­è¨ˆã®è«–æ–‡ã€‚ 
	- -OHã¨ã®çµåˆã¯å¼·ã„ãŒH2Oã¨ã®çµåˆã¯å¼±ã„ã€ã®ã‚ˆã†ãªè¤‡æ•°ã®å¸ç€å‰¤ã®æœ€é©åŒ–ã‚’å¤šç›®çš„å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šè¡Œã„ã€16ä¸‡åŒ–åˆç‰©ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ããŸãã†ã§ã™ã€‚ 
	- ææ–™é–‹ç™ºã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒåŸºæœ¬ãªã®ã§ã€ã“ã†ã„ã†æœ€é©åŒ–ã¯éœ€è¦ãŒã‚ã‚Šãã†
- ã€ã‚¹ã‚­ãƒ«å®šç¾©å§”å“¡ä¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ï½ã‚¹ã‚­ãƒ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã€ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°ã¨ç”Ÿæˆ AIã€œã€ï¼ˆ2023å¹´10æœˆ20æ—¥ï¼‰
	- https://www.youtube.com/watch?v=nQumYtpN0zY
	- DSå”ä¼š ã‚¹ã‚­ãƒ«å®šç¾©å§”å“¡ä¼š ã‹ã‚‰ç”ŸæˆAIæ™‚ä»£ã«å³ã—ã€ã‚¹ã‚­ãƒ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ ver.5ã¨ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ ver.4ã‚’ç™ºè¡¨ã—ãŸéš›ã®è§£èª¬å‹•ç”»ãŒYouTubeã«ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸã‚ˆã†ã§ã™ã€‚ã„ããªã‚Šãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’è¦‹ã¦ã‚‚ãã†ç°¡å˜ã«èƒŒæ™¯ã¯ç†è§£ã§ããªã„ã®ã§ã‚ªã‚¹ã‚¹ãƒ¡ã€‚ç›¸å½“ã«æ¿ƒåšã§ã™ã€‚
-  ELYZA-tasks-100 ã§LLM14å€‹ã®æ—¥æœ¬èªæ€§èƒ½ã‚’æ¨ªæ–­è©•ä¾¡ã—ã¦ã¿ãŸ
	- https://qiita.com/wayama_ryousuke/items/105a164e5c80c150caf1
	- æ—¥æœ¬èªLLMã£ã¦è‰²ã€…ã‚ã‚‹ã‘ã©ãƒ™ãƒ³ãƒã ã‘ã˜ã‚ƒã‚ˆãã‚ã‹ã‚‰ã‚“ãªã€ã¨ã„ã†ã“ã¨ã§æ¤œè¨¼ã—ã¦ã¿ãŸçµæœã‚’è¨˜äº‹ã«ã—ã¦ã¿ã¾ã—ãŸ 
	- openchatã€Swallowç­‰ç™ºè¡¨ã•ã‚ŒãŸã°ã‹ã‚Šã®LLMã«ã¤ã„ã¦ã‚‚æ¤œè¨¼ã—ã¦ã¿ã¦ã¾ã™
	- å¹³å‡ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ã‹ã£ãŸã®ã¯ `Xwin-LM-70B-V0.1` ã§ã€æ¬¡ã„ã§ `deepseek-llm-67b-chat`ã€`Yi-34B-Chat` ã¨ç¶šã„ã¦ã„ã¾ã™ã€‚  
	- ä¸Šä½3ã¤ã¯ã™ã¹ã¦ä¸­å›½å‹¢ã§ã€ãƒ‘ãƒ©ãƒ¡ã‚¿æ•°ã‚‚30Bä»¥ä¸Šã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã™
	- ãƒ‘ãƒ©ãƒ¡ã‚¿æ•°ãŒæ¯”è¼ƒçš„å°‘ãªã„ 7B ãƒ¬ãƒ³ã‚¸ã§ã¯ã€ELYZA-japanese-Llama-2 ã‚„ CALM2 ãªã©ã®æ—¥æœ¬ç™ºãƒ¢ãƒ‡ãƒ«ãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã¾ã™ã€‚
	- ä¸€æ–¹ã€ãƒ‘ãƒ©ãƒ¡ã‚¿æ•° 30B ä»¥ä¸Šã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ï¼ˆãã‚‚ãã‚‚æ—¥æœ¬ç™ºã®ãƒ¢ãƒ‡ãƒ«ãŒå°‘ãªã„ã“ã¨ã‚‚ã‚ã‚Šï¼‰æµ·å¤–ãƒ¢ãƒ‡ãƒ«ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
-  GPTsã‚ˆã‚Šç²¾åº¦ã®é«˜ã„RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰
	- https://speakerdeck.com/mkazutaka/gptsyorijing-du-nogao-iragsisutemunogou-zhu
	- https://github.com/mkazutaka/20231219-llmapp-meetup
-  LLM in a flash: Efficient Large Language Model Inference with Limited Memory
	- https://arxiv.org/abs/2312.11514
	- Appleã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’SSDãªã©ã®å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã—ã€æ¥ç¶šã—ãŸPCãªã©ã§èª­ã¿è¾¼ã¿ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã—ã¾ã—ãŸ
	- CPUã§4-5å€ã€GPUã§20-25å€ã®æ¨è«–é€Ÿåº¦å‘ä¸ŠãŒå®Ÿç¾ã—ã€ã•ã‚‰ã«PCãƒ‡ãƒã‚¤ã‚¹ã®è¨˜æ†¶å®¹é‡ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®åŠåˆ†ã§ã‚‚ã€LLMã‚’é«˜åŠ¹ç‡ã«å®Ÿè¡Œã§ããŸã¨ã®ã“ã¨ã§ã™ã€‚
	- æ‰‹æ³•ï¼š
		- â‘  ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«æ ¼ç´ 
		- â‘¡ è¦æ±‚ã«å¿œã˜ã¦PCã®DRAMï¼ˆãƒ¡ãƒ¢ãƒªï¼‰ã«è»¢é€ 
		- â‘¢ ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ã‚’æ¸›ã‚‰ã—æ¨è«–é€Ÿåº¦ã‚’å‘ä¸Š
	- çµæœï¼š
		- â‘  CPUã§4-5å€ã€GPUã§20-25å€ã®æ¨è«–é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ 
		- â‘¡ PCãƒ‡ãƒã‚¤ã‚¹ãƒ¡ãƒ¢ãƒªï¼ˆDRAMï¼‰ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®åŠåˆ†ã§ã‚‚ã€LLMã‚’é«˜åŠ¹ç‡ã«å®Ÿè¡Œ
- ã€ŒAGI Breakthroughã€
	- https://x.com/bioshok3/status/1737258881452294277?s=20
	- ã€ŒAGI Breakthroughã€ã¨åä»˜ã‘ã‚‰ã‚ŒãŸOpenAIå–ç· å½¹ä¼šã¸ã®å…¬é–‹æ›¸ç°¡ãŒVerses AIã‹ã‚‰æ€¥é½å‡ºã•ã‚Œã¦ã„ã‚‹ã€‚
	- AGIã«ç¹‹ãŒã‚Šã†ã‚‹èƒ½å‹•çš„æ¨è«–ã«ã¤ã„ã¦ã®ç”»æœŸçš„ãªé€²æ­©ã‚’æœ€è¿‘é”æˆã€‚Open AIæ†²ç« ã«åŸºã¥ãã€AGIã®å®‰å…¨ãªé…å‚™ã®ãŸã‚æŠ€è¡“å”åŠ›ã‚’è¦è«‹ã—ã¦ã„ã‚‹ã€‚ä»Šå¾Œã©ã†ãªã‚‹ã‹æ³¨è¦–å¿…è¦ã€‚
- llamaindexã‚ˆã‚Štext2sqlã‚’ã¤ã‹ã£ãŸã€research assistant templte
	- https://github.com/langchain-ai/langchain/tree/master/templates/sql-research-assistant
	- ollamaã‚’åˆ©ç”¨ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«LLMç‰ˆã‚‚ãµãã¾ã‚Œã¦ã„ã‚‹ï¼
	- ãªã‚‹ã»ã©ã€ã“ã‚ŒãŒLangCainã¨LLMã‚’ã¤ã‹ã£ãŸãƒ­ãƒ¼ã‚«ãƒ«Webã‚¢ãƒ—ãƒªæ§‹ç¯‰ã®æ–°ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã‹
- PowerInfer - a high-speed inference engine for deploying LLMs locally
	- https://github.com/SJTU-IPADS/PowerInfer
	- Just came across this super interesting project on speeding up inference. It's not MoE but it's a simple approach that exploits the high locality in LLM inference to design a GPU-CPU hybrid inference engine.
	- It's now possible to use PowerInfer with Llama 2 and Faclon 40B. Mistral-7B support is coming soon!
	- æ¯”è¼ƒå‹•ç”»ã€https://x.com/omarsar0/status/1737168751668187229?s=20
- swallow-70B-instructã®GGUFãŒã§ãã¦ã„ã‚‹ã€‚ã€‚TheBloke/Swallow-70B-instruct-GGUF
	- https://huggingface.co/TheBloke/Swallow-70B-instruct-GGUF
- swallow-13B-instuctã®spaceã‚’ã¤ãã‚Šã¾ã—ãŸ
	- https://huggingface.co/spaces/hayas/Swallow-13B-instruct
	- ã€Œæ±äº¬å·¥æ¥­å¤§å­¦ã®å¤§å²¡å±±ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ã¯è¡Œæ”¿çš„ã«ã¯ã©ã“ã®åŒºã«å±ã™ã‚‹ï¼Ÿã€ã¨ã€å•ã†ã¨ç‹‚ã£ãŸï¼
-  A mathematical perspective on Transformers
	- https://arxiv.org/abs/2312.10794
	- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ã€è‡ªå·±æ³¨æ„ã¨å±¤æ­£è¦åŒ–ã¨ã„ã†2ã¤ã®ä¸»è¦ãªæ©Ÿæ§‹ã‚’å«ã‚€ç›¸äº’ä½œç”¨ã™ã‚‹ç²’å­ç³»ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã‚‹ã€‚ç²’å­ç³»ã¯ç¢ºç‡æ¸¬åº¦ã®æµã‚Œã‚’å®Ÿè£…
-  Discovery of a structural class of antibiotics with explainable deep learning
	- https://www.nature.com/articles/s41586-023-06887-8
	- æ¯’æ€§ã®ãªã„ã€ãƒ¡ãƒã‚·ãƒªãƒ³è€æ€§é»„è‰²ãƒ–ãƒ‰ã‚¦çƒèŒã«å¯¾ã—ã¦æœ‰åŠ¹ãªè¤‡æ•°ã®åŒ–åˆç‰©ã‚’å«ã‚€æ–°ã—ã„æ§‹é€ ã‚¯ãƒ©ã‚¹ã®æŠ—ç”Ÿç‰©è³ª (æœ€å¾Œã®ç™ºè¦‹ã«ã¯ 38 å¹´ã‹ã‹ã£ãŸ)
- "A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise"
	- https://arxiv.org/abs/2312.12436
	- GPT-4Vã«å¯¾ã—ã¦Geminiã®ç”»åƒèªè­˜èƒ½åŠ›ã¯ã©ã‚Œã»ã©æ€§èƒ½ãŒé«˜ã„ã®ã‹ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§æ¯”è¼ƒã—ãŸå®Ÿé¨“çµæœãŒå ±å‘Šã•ã‚Œã¾ã—ãŸã€‚
	- GPT-4Vã¯è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«é•·ã‘ã¦ãŠã‚Šã€Geminiã¯ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®çµ±åˆã«é•·ã‘ã¦ã„ã‚‹å‚¾å‘ãŒã‚ã‚‹ã¨ã®ã“ã¨ã§ã™ã€‚
	- æ¯”è¼ƒï¼š
		- â‘  Geminiã¯å¤šãã®å ´åˆã€GPT-4Vã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ­£ç¢ºã•ã‚’ç¤ºã™ 
		- â‘¡ Geminiã¯GPT-4Vã‚ˆã‚Šã‚‚çŸ¥è­˜ãŒå¹…åºƒã„ã‚ˆã†ã«è¦‹ãˆã‚‹
-  Fairness and Machine Learning by Arvind Narayanan
	- https://mitpress.mit.edu/9780262048613/fairness-and-machine-learning/
	- An introduction to the intellectual foundations and practical utility of the recent work on fairness and machine learning
	- ãƒ‰ãƒ©ãƒ•ãƒˆãŒã‚ã‚Šã€ã™ã§ã«ãŸãã•ã‚“ã®å¤§å­¦ã®æˆæ¥­ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚https://fairmlbook.org/
- ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ã§ã€AIç‹ã‚¯ã‚¤ã‚ºç¬¬ä¸€å›ã‚³ãƒ³ãƒšã«è‡¨ã‚€ - Q&Aã‚¿ã‚¹ã‚¯ã§ã®è¤‡æ•°ã®æ—¥æœ¬èªembeddingsã®è©•ä¾¡
	- https://secon.dev/entry/2023/12/21/080000-vector-search-ai-ou-comp/
	- AIç‹ ã€œã‚¯ã‚¤ã‚ºAIæ—¥æœ¬ä¸€æ±ºå®šæˆ¦ã€œ ç¬¬ä¸€å›ã‚³ãƒ³ãƒšã¨ã¯ã€è³ªå•ã«å¯¾ã—ã¦ç´„20å€‹ã®å€™è£œã‹ã‚‰ã€å›ç­”ã¨ãªã‚‹ä¸€ã¤ã‚’é¸æŠã™ã‚‹ã‚³ãƒ³ãƒšã ã€‚trainç”¨ã«ç´„13,000ä»¶ã€valç”¨ã«ç´„2,000ä»¶ãƒ‡ãƒ¼ã‚¿ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚
	- è³ªå•ã«å¯¾ã—ã¦ã®å›ç­”ãŒå«ã¾ã‚Œãã†ãªæ–‡ã‚’æ¤œç´¢ã™ã‚‹æ—¥æœ¬èªembeddingså¤‰æ›ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€multilingual-e5-large ã®æ€§èƒ½ãŒé«˜ã‹ã£ãŸ
- Autonomous chemical research with large language models
	- https://www.nature.com/articles/s41586-023-06792-0
	- Coscientist"â€”a GPT-4 based autonomous LLM system that demonstrates appreciable reasoning capabilities, ... solving of multiple problems and generation of code for experimental design"
	- è‘—è€…ã‚‰ã¯ GPT-4 ã‚’ä½¿ç”¨ã—ã¦ã€è‡ªå¾‹çš„ã«ç ”ç©¶ã€è¨ˆç”»ã€ãŠã‚ˆã³åŒ–å­¦å®Ÿé¨“ã‚’å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã‚“ã§å®Ÿé¨“æ©Ÿå™¨ã®ä½¿ã„æ–¹ã‚’å­¦ã¶ã“ã¨ã‚‚å«ã¾ã‚Œã¾ã™ (ã»ã¨ã‚“ã©ã®æ“ä½œã¯ã‚³ãƒ¼ãƒ‰ã§æ“ä½œã•ã‚Œã¾ã—ãŸãŒã€1 ã¤ã®ã‚¿ã‚¹ã‚¯ã¯äººé–“ãŒå®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸ)ã€‚
- Ollama v0.1.17 now has support for Phi-2
	- https://ollama.ai/library/phi
	- It's a small model at 2.7 billion parameters. Good for its reasoning and language understanding abilities. Given its small size, it'll run effectively on a wider set of hardware.
- TheBloke/Swallow-13B-GGUF
	- https://huggingface.co/TheBloke/Swallow-13B-GGUF
	- ã¾ãŸã¾ãŸ Swallow-13Bã®GGUFãŒå‡ºã¦ã„ã‚‹
-  rinnaã€Qwenã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹
	- https://rinna.co.jp/news/2023/12/20231221.html
	- rinnaã¯Qwen-7Bã¨14Bã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ Nekomata 14B Instructionã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ä¸€éƒ¨ã®70Bã¨åŒãƒ¬ãƒ™ãƒ«ã¾ã§åˆ°é”ã—ã¦ã„ã¾ã™ã€‚
	- Nekomata 7Bã¨14Bã¯ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Qwen-7Bã¨140å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Qwen-14Bã«å¯¾ã—ã¦ã€æ—¥æœ¬èªã¨è‹±èªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ãã‚Œãã‚Œ300å„„ã¨660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™
	- AWS Trainiumã‚’æ­è¼‰ã—ãŸ16ãƒãƒ¼ãƒ‰ã®Amazon EC2 trn1.32xlargeã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”¨ã„ã¦ã€660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã¯ç´„7æ—¥ã§å®Œäº†ã—ã¾ã—ãŸ
	- ãƒ¢ãƒ‡ãƒ«åã®ç”±æ¥ã¯ã€å¦–æ€ªã®ã€ŒçŒ«åˆï¼ˆã­ã“ã¾ãŸï¼‰ã€
- Running Mixtral 8x7 locally with LlamaIndex
	- https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab
	- Running MistralAI's Mixtral 8x7b on your laptop is now a one-liner! Check out this post in which we show you how to use OLLAMA with LlamaIndex to create a completely local, open-source retrieval-augmented generation app complete with an API:
-  Google Colab ã§ StreamDiffusion ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n4cb9a2d9fd72?sub_rt=share_h
	- ã€ŒStreamDiffusionã€ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”»åƒç”Ÿæˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚å¾“æ¥ã®ç”»åƒç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨æ¯”ã¹ã¦é£›èºçš„ãªé€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
- Apple ãŒæä¾›ã—ã¦ã„ã‚‹MLXãŒå¾ã€…ã«å……å®Ÿã—ã¦æ¥ãŸã€‚çµæ§‹å‡„ã„ã“ã¨ã«ãªã‚‹ã‹ã‚‚ã€‚
	- https://huggingface.co/mlx-community
	- a bunch of pre-converted MLX models! 
	- Llama, Phi-2, Mistral, Mixtral (and instruct and code variations where available)!
- rinnaã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹nekomata-14b-instructionã®gguf
	- mmnga/rinna-nekomata-14b-instruction-gguf
	- qwenãƒ™ãƒ¼ã‚¹ã§vocab15ä¸‡ã‚ã‚Šã¾ã™
-  Gemini Pro Visionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦Google Cloudã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå‹•ç”»ã‚’è§£æã—ã¦ã¿ãŸ
	- https://qiita.com/tatsuki-tsuchiyama/items/5701475d46ee31efbb54
- ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã®GGUF 4bité‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚
	- https://huggingface.co/collections/rinna/nekomata-6582b5134ee85531becbb9a9
-  regex to do sentence splitting that generalizes beyond English to non-Latin languages (CJK, etc.) 
	- https://x.com/jerryjliu0/status/1738232451200356445?s=20
- æœ€æ–°ã® SCIENCEã®ç‰¹é›†ã¯AI Powered Forecasting ã€VOLUME 382|ã€ISSUE 6677ã€22 DEC 2023
	- https://www.science.org/toc/science/382/6677?utm_campaign=SciMag&utm_source=Twitter&utm_medium=ownedSocial
	- Trained on four decades of historical data, GraphCast is an artificial intelligence model that predicts global weather with greater speed and accuracy compared with traditional approaches solving physical equations. It supports severe event predictions, such as cyclone tracking.
-  Ferret: Refer and Ground Anything Anywhere at Any Granularity
	- https://github.com/apple/ml-ferret?tab=readme-ov-file
	- Appleã‹ã‚‰ã€ã‚ã‚‰ã‚†ã‚‹å½¢å¼ã®å‚ç…§ï¼ˆç®±ã¨ã‹ã€ãªã‚“ã¨ã‹ã®æ¨ªã¨ã‹ï¼‰ã‚’å—ã‘å…¥ã‚Œã€å¿œç­”ã¨ã—ã¦ã‚ã‚‰ã‚†ã‚‹ã‚‚ã®ã‚’æ¥åœ°ã™ã‚‹ï¼ˆãã‚Œã¯çŒ«ã®ã—ã£ã½ã¨ã‹ï¼‰ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã® MLLM
	- ç‰©ä½“èªè­˜ã®ä¸€ç¨®ãªã®ã‹ã€
- "Retrieval-Augmented Generation for Large Language Models: A Survey"
	- https://arxiv.org/abs/2312.10997
	- LLMã®RAGï¼ˆå¤–éƒ¨çŸ¥è­˜æ¤œç´¢ã«ã‚ˆã‚‹å¼·åŒ–ï¼‰ã«ã¤ã„ã¦ã®èª¿æŸ»çµæœ
	- åŸºæœ¬ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å„æ§‹æˆè¦ç´ ï¼ˆãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ï¼ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼æ‹¡å¼µï¼‰ã®è©³ç´°ã€è©•ä¾¡ã€ãã—ã¦ä»Šå¾Œã®ç™ºå±•ã«ã¤ã„ã¦è¨€åŠã•ã‚Œã¦ãŠã‚Šç¶²ç¾…çš„ã§ã™ã€‚
	- â– RAGã®è©•ä¾¡
		- â‘  æ­£ç¢ºæ€§ã€æƒ…å ±æ›´æ–°é€Ÿåº¦ã€é€æ˜æ€§ãªã©ãŒä¸»è¦ãªæŒ‡æ¨™
		- â‘¡ RAGASã‚„ARESãªã©ã®è‡ªå‹•è©•ä¾¡æ‰‹æ³•ãŒã‚ã‚‹
	- â– ä»Šå¾Œã®ç™ºå±•
		- â‘  ã•ã‚‰ãªã‚‹æœ€é©åŒ–ãŒå¿…è¦
		- â‘¡ å¿œç”¨ç¯„å›²ã®æ‹¡å¤§ãŒæœŸå¾…ã•ã‚Œã‚‹
		- â‘¢ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ãŒç™ºå±•ã™ã¹ã
- Geminiã§ã®tokenã‚«ã‚¦ãƒ³ãƒˆãŒæ—¥æœ¬èªã§ChatGPTã®1/2ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜
	- https://x.com/Mega_Gorilla_/status/1738821637297115598?s=20
	- Gemini ãŠå‰ã€932 Charactersã§500Tokenã£ã¦ã€ã€ ãŠå‰ã®Tokenã©ã†ãªã£ã¦ã‚‹ã‚“ã ï¼Ÿï¼ OpenAIãªã‚‰ã€åŒã˜æ–‡å­—åˆ—ã§ã€1000ãƒˆãƒ¼ã‚¯ãƒ³è¶Šãˆã ãã€‚
- Youri7Bã‚’ãƒ­ãƒ¼ã‚«ãƒ«LLMã§APIã‚µãƒ¼ãƒãƒ¼åŒ–ã—ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç¾å°‘å¥³ã¨ãŠè©±ã—ã¦ã¿ãŸ
	- https://zenn.dev/yasuna/articles/b954b2cd77e27f
	- ãƒ­ãƒ¼ã‚«ãƒ«PCã«LLMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦APIã‚µãƒ¼ãƒã¨ã—ã¦å‹•ã‹ã™
	- ãƒ–ãƒ©ã‚¦ã‚¶ã§ç°¡å˜ã«3Dã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ä¼šè©±ã§ãã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¤ãªã’ã‚‹
	- ã‚ªãƒªã‚¸ãƒŠãƒ«3Dã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ä½œã‚‹
	- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ã™ã‚‹
- intel-extension-for-transformers
	- https://github.com/intel/intel-extension-for-transformers
	- ã„ã‚ã„ã‚å¯¾å¿œã§ãã‚‹LLMã‚„é‡å­åŒ–å¯¾å¿œãŒå¢—ãˆã¦ã„ã‚‹æ¨¡æ§˜
- ãƒ¬ã‚¾ãƒŠãƒƒã‚¯ãŒé‡å­åŒ–å­¦è¨ˆç®—ã«æ¯”ã¹ã¦æ•°åƒå€é€Ÿãç‰©æ€§ã‚’äºˆæ¸¬å¯èƒ½ãªã‚¢ãƒ—ãƒªã‚’é–‹ç™º
	- https://monoist.itmedia.co.jp/mn/articles/2312/22/news064.html#utm_term=share_sp
	- ãƒ¬ã‚¾ãƒŠãƒƒã‚¯ã¯2023å¹´12æœˆ21æ—¥ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’ç”¨ã„ãŸAIï¼ˆäººå·¥çŸ¥èƒ½ï¼‰ã¨è†¨å¤§ãªè“„ç©ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã‚±ãƒ¢ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚¢ãƒ—ãƒªã‚’ç‹¬è‡ªé–‹ç™ºã—ã€é‹ç”¨ã‚’é–‹å§‹ã—ãŸã¨ç™ºè¡¨ã—ãŸã€‚
- Building LLM-Powered Web Apps with Client-Side Technology
	- https://ollama.ai/blog/building-llm-powered-web-apps
	- https://www.youtube.com/watch?v=-1sdWLr3TbI
	- Iâ€™d try a different approach and try to build a web app using exclusively local models and technologies, preferably those that run in the browser!
	- ollamaã‚’ã¤ã‹ã£ã¦Langchainã‚’ã¤ã‹ã£ãŸã€Webãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ã‚«ãƒ«ãªRAGã®æ§‹ç¯‰ä¾‹
- PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU
	- https://arxiv.org/abs/2312.12456
	- æ¶ˆè²»è€…å‘ã‘GPUã§ã‚‚é«˜æ€§èƒ½GPUã«è¿‘ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§LLMã‚’å‹•ã‹ã™æ‰‹æ³•ã€ŒPowerInferã€
	- â– ã€ŒPowerInferã€ã®ãƒã‚¤ãƒ³ãƒˆ 
		- â‘  LLMã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã™ 
		- â‘¡ æ¨è«–ã®å‡¦ç†é€Ÿåº¦å‘ä¸Šã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ 
		- â‘¢ GPUã¨CPUã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼ 
	- â– å®Ÿé¨“ 
		- â‘  æ¶ˆè²»è€…å‘ã‘ç’°å¢ƒã‚’ç”¨æ„ ï¼ˆIntel i9, NVIDIA RTX 4090ãªã©ï¼‰ 
		- â‘¡ LLaMA-70Bã»ã‹åˆè¨ˆ3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ 
		- â‘¢ å®Ÿéš›ã®ã‚µãƒ¼ãƒ“ã‚¹ã«è¿‘ã„ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’è¡Œã£ãŸ 
	- â– çµæœ 
		- â‘  æ¶ˆè²»è€…å‘ã‘ã§ã‚‚é«˜æ€§èƒ½ï¼ˆA100ï¼‰ã®82%ã«ä¸Šã‚‹ç”Ÿæˆé€Ÿåº¦ã‚’é”æˆ 
		- â‘¡ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§8.00å€ã€éé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§11.69å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾ 
		- â‘¢ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ã«å¿œã˜ã¦é©åˆ‡ãªå‰²ã‚Šå½“ã¦ã‚’å®Ÿè¡Œ

## 12/18

ä»Šé€±ã‚‚ã™ã•ã¾ã˜ã„æƒ…å ±é‡ã€‚ãƒ«ã‚«ãƒ³å…ˆç”Ÿã‚‚ã“ã®æƒ…å ±é‡ã«ã¯è¿½ã„ä»˜ã‘ãªã„ã¨ã®ã“ã¨ï¼ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å‹•ç”»ï¼‰ã€‚Geminiã®APIãŒä½¿ãˆã‚‹ã‚ˆã†ãªã‚Šã€æ§˜ã€…ãªã‚µãƒ³ãƒ—ãƒ«ã‚„ã€LangChainã€llamaindexã¨ã®çµ±åˆãŒã©ã‚“ã©ã‚“è¡Œã‚ã‚ŒãŸã€‚ãƒ•ãƒªãƒ¼ç‰ˆãªã‚‰ã°ã€60QPM (queries per minute)ã¾ã§ã¯ä½¿ãˆã‚‹ã€‚ã‚¯ãƒªã‚¹ãƒã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œã‚ã†ã¯ã„ã„ã­ã€å¹´è³€çŠ¶ã‹ãªã€‚Mistralã€MOEã®ã™ã°ã‚‰ã—ã•ã‚„ã€MOEã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆãƒãƒ¼ã‚¸ã¨ã‹ã€æ—¥æœ¬èªã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å…¥ã‚Œè¾¼ã‚€ã¨ã‹ã®è©¦ã¿ï¼‰ã®è©¦ã¿ãŒå§‹ã¾ã‚‹ã€‚NeurPS2023ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è³ªãŒé‡è¦ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ãŒã€DeepMindã‹ã‚‰ã¯ã€LLMãŒè³ªã®è‰¯ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¦å­¦ç¿’ã™ã‚‹ã€Œè‡ªå·±å­¦ç¿’ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚RAGã§ã‚‚è³ªå•ã‚’äº‹å‰ã«LLMã§ã€è§£ãã‚„ã™ã„ã‚ˆã†ã«ã€å¤‰å½¢ã™ã‚‹ã£ã¦ã®ã¯ã„ã„ã­ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®Phi-2ã€2.7Bãƒ‘ãƒ©ã®LLMã§ãã“ãã“æ€§èƒ½ãŒã§ã‚‹ã‚‰ã—ã„ã€‚DeepMindã®FunSearchã€æ–°ã—ã„ç§‘å­¦ã®ç™ºè¦‹ãŒLLMã§å®Ÿç¾ã§ãã‚‹ä¸–ç•ŒãŒã¤ã„ã«ã‚„ã£ã¦ããŸã€‚å­£ç¯€æŸ„ã‚¢ãƒ™ãƒ³ãƒˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç³»ã®è¨˜äº‹ãŒã‚ˆã„ã€å¤å…¸ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹åˆ†æã¨ã‹ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã‹ã€‚LLMã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚‚ã€open-ended ãªçŠ¶æ³ã§ç ”ç©¶ã‚’ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒæ˜ç¢ºã«ãªã‚Šã€ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆã§ã®è©•ä¾¡äº‹ä¾‹ã¨ã‹ã©ã‚“ã©ã‚“é€²ã‚“ã§ã‚†ãã€‚

- "TaskWeaver: A Code-First Agent Framework
	- https://arxiv.org/abs/2311.17541
	- Microsoftã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªç„¶è¨€èªã§ã€Œã“ã†ã—ã¦ã€ã¨è¨€ã†ã ã‘ã§LLMãŒè¦æ±‚ã‚’ç†è§£ã—ã€å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã€TaskWeaverï¼ˆã‚¿ã‚¹ã‚¯ã‚¦ã‚£ãƒ¼ãƒãƒ¼ï¼‰ã€ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ 
	- å®Ÿé¨“ã®çµæœã€æ ªä¾¡äºˆæ¸¬ã‚„ç•°å¸¸æ¤œå‡ºãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’é€šã—ã¦æœ‰åŠ¹æ€§ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹ãã†ã§ã™ã€‚
	- â‘  è‡ªç„¶è¨€èªã§ã®è¦æ±‚ã‚’ã‚³ãƒ¼ãƒ‰ã«å¤‰æ›ã™ã‚‹ 
	- â‘¡ è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ 
	- â‘¢ æœ€é©ãªãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§é¸æŠã—ã€ã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹
- LLMã‚’ã‚»ãƒ©ãƒ”ã‚¹ãƒˆã¨ã—ã¦å®Ÿè¡Œã—ã€ã€ŒèªçŸ¥ã®æ­ªã¿ã€ã‚’è©•ä¾¡ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Diagnosis of Thought (DoT)ã€ã«åŸºã¥ãMyGPT
	- https://chat.openai.com/g/g-o9r1c3nkf-serapisuto-diagnosis-of-thought-dot
- æ—¥æœ¬èª LLM ã®ç²¾åº¦ãŒã„ã¾ã„ã¡ãªã®ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å•é¡ŒãŒã‚ã‚Šãã†ã¨ã„ã†æŒ‡æ‘˜
	- https://github.com/AUGMXNT/shisa/wiki/A-Review-of-Public-Japanese-Training-Sets#analysis
- gtp-fastã®æœ¬å®¶github
	- Simple and efficient pytorch-native transformer text generation.
	- https://github.com/pytorch-labs/gpt-fast
- "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey"
	- https://arxiv.org/abs/2312.00678
	- LLMã®åŠ¹ç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ãƒã‚¦ãƒã‚¦ã«é–¢ã™ã‚‹ç¶²ç¾…çš„ãªèª¿æŸ» by Microsoft
	- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ãƒ‡ãƒ¼ã‚¿ï¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼æ¨è«–ã€ã¨ã„ã£ãŸ5ã¤ã®è¦³ç‚¹ã‹ã‚‰å ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚
- MistralAI Embeddings
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/mistralai.ipynb
	- llamaindexã‚ˆã‚ŠMistralAI ã®Embeddingsã‚’åˆ©ç”¨ã™ã‚‹notebook
	- ãªã‚“ã‹ã€MistralAIè‡ªä½“ã‚‚ã¤ã‹ã‚‹ã‚‰ã—ã„
		- The new Mistral 8x7B model is an open-source model that made waves in the AI community today, outperforming gpt-3.5 and llama2 70B. Check out `mistral-tiny`, `mistral-small`, and `mistral-medium` variants.
		- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/mistralai.ipynb
- MistralãŒã©ã†ãˆã‚‰ã„ã®ã‹ï¼Ÿ by ã‚¸ãƒ ãƒ•ã‚¡ãƒ³æ°
	- https://twitter.com/DrJimFan/status/1734269362100437315
	- MoE is the right path forward
	- An LLM is a snapshot of a civilization
	- ã‚¸ãƒ ãƒ•ã‚¡ãƒ³æ°æ›°ãã€Mistralã®Mixtralãƒ¢ãƒ‡ãƒ«å…¬é–‹ã®ãƒ¯ã‚±åˆ†ã‹ã‚‰ã‚“ãƒ ãƒ¼ãƒ–ã¯å®Ÿã¯é«˜åº¦ãªæˆ¦ç•¥ã ã£ãŸã€‚ã¾ãšä½•ã®èª¬æ˜ã‚‚ãªããƒ¢ãƒ‡ãƒ«ã‚’torrentã«æŠ•ä¸‹ã€‚ãã‚“ã§vLLMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ—ãƒ«ãƒªã‚¯æŠ•ã’ã¦ã€èª°ã§ã‚‚Mixtralã§éŠã¹ã‚‹ã‚ˆã†ã«ç’°å¢ƒã‚’ä½œã£ã¦ã‚ã’ã‚‹ã€‚æœ€å¾Œã«ã‚ã‚‰ãŸã‚ã¦ãƒ–ãƒ­ã‚°è¨˜äº‹ã§ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç™ºè¡¨ï¼ç™ºè¡¨ã¨åŒæ™‚ã«ã™ãéŠã¹ã¦ä¸–é–“ãŒç››ã‚Šä¸ŠãŒã£ã¦æ³¨ç›®åº¦ã‚’ç¨¼ã’ã‚‹ã¨ã„ã†æµã‚Œ by ã†ã¿ã‚†ãã•ã‚“
- "From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"
	- https://arxiv.org/abs/2312.06571
	- æ±äº¬å¤§å­¦ã¨æ ªå¼ä¼šç¤¾ã‚ªãƒ«ã‚¿ãƒŠãƒ†ã‚£ãƒ´ãƒ»ãƒã‚·ãƒ³ã®ç ”ç©¶è€…ã‚‰ã¯ã€ŒLLMã¨ç‰©ç†çš„ãªä¸–ç•ŒãŒã¤ãªãŒã‚‹ã¨ä½•ãŒèµ·ã“ã‚‹ã®ã‹ï¼Ÿã€ã¨æƒ³åƒã—ã€å®Ÿéš›ã«GPT-4ã¨ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ãƒ­ãƒœãƒƒãƒˆã‚’é€£æºã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®æ¦‚è¦
		- â‘  ãƒ­ãƒœãƒƒãƒˆã€ŒAlter3ã€ã«å¯¾ã—ã¦ã€æ§˜ã€…ãªè‡ªç„¶è¨€èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ‡ç¤º 
		- â‘¡ GPT-4ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ãƒœãƒƒãƒˆå‹•ä½œã®ã‚³ãƒ¼ãƒ‰ã«å¤‰æ› 
		- â‘¢ ãƒ­ãƒœãƒƒãƒˆãŒäººé–“ã®ã‚ˆã†ãªå‹•ãã‚„æ„Ÿæƒ…è¡¨ç¾ã‚’å®Ÿè¡Œ 
	- å®Ÿé¨“ã®çµæœ 
		- â‘  ã€ŒAlter3ã€ã¯9ç¨®é¡ã®ç•°ãªã‚‹å‹•ä½œã®å®Ÿè¡Œã‚’æˆåŠŸ 
		- â‘¡ ç¬¬ä¸‰è€…ã«ã‚ˆã‚‹å‹•ä½œã®è©•ä¾¡ã¯é«˜ã‹ã£ãŸ 
		- â‘¢ äººé–“çš„ãªå‹•ä½œã¨æ„Ÿæƒ…è¡¨ç¾ã‚’å®Ÿç¾
-  Mixtral 8x7B ã®æ¦‚è¦  by npakaã•ã‚“
	- https://note.com/npaka/n/n6043bc8b01bc?sub_rt=share_h
	- æ¨è«–ã¯6å€é€Ÿãã€ã»ã¨ã‚“ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ŒLlama2 70Bã€ã‚’ä¸Šå›ã£ã¦ã„ã¾
	- **Mistral-tiny** : Mistral 7B Instruct v0.2ã€‚è‹±èªã§ã®ã¿æ©Ÿèƒ½ã€‚MT-Benchã§ã¯7.6ã‚’ç²å¾—ã€‚  
	- **Mistral-small** : Mixtral 8x7Bã€‚è‹±èª/ãƒ•ãƒ©ãƒ³ã‚¹èª/ã‚¤ã‚¿ãƒªã‚¢èª/ãƒ‰ã‚¤ãƒ„èª/ã‚¹ãƒšã‚¤ãƒ³èªã¨ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¿ãƒ¼ã€‚MT-Benchã§8.3ã‚’ç²å¾—ã€‚  
	- **Mistral-medium** : Mistral AIã®æœ€é«˜å“è³ªã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ¢ãƒ‡ãƒ«ã€‚è‹±èª/ãƒ•ãƒ©ãƒ³ã‚¹èª/ã‚¤ã‚¿ãƒªã‚¢èª/ãƒ‰ã‚¤ãƒ„èª/ã‚¹ãƒšã‚¤ãƒ³èªã¨ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¿ãƒ¼ã€‚MT-Benchã§8.6ã‚’ç²å¾—ã€‚
- ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã®MoEç‰ˆã§ã‚ã‚‹mixtralã§ã™ãŒé©šã„ãŸäº‹ã«æ—¢ã«llama.cppã®é‡å­åŒ–ç‰ˆãŒå‡ºã¦ã„ã‚‹ã®ã§gpuãŒãªã„ç’°å¢ƒã‚„Macã§ã‚‚å‹•ã‹ã›ã‚‹
	- https://x.com/webbigdata/status/1734425932029628876?s=20
- "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"
	- https://arxiv.org/abs/2312.06585
	- LMã«è‡ªã‚‰é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã•ã›ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã™ã‚‹ã€Œè‡ªå·±å­¦ç¿’ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ by DeepMind
	- æ–¹æ³•
		- â‘  è‡ªã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã™ã‚‹ 
		- â‘¡ ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹
		- â‘¢ æ•°å­¦ã‚’ä¸­å¿ƒã¨ã—ãŸæ§˜ã€…ãªå•é¡Œè§£æ±ºã«ä½¿ãˆã‚‹
	- å®Ÿé¨“çµæœ 
		- â‘  æ•°å­¦ã«ãŠã„ã¦ã€æ­£ç­”ç‡ã®å‘ä¸Šã‚’é”æˆ 
		- â‘¡ ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®å•é¡Œã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®é©å¿œèƒ½åŠ›ãŒå‘
-  Query Transform Cookbook
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/query_transformations/query_transform_cookbook.ipynb
	- RAGã«ãŠã„ã¦ã€æ¤œç´¢çµæœã‚’contextã«ç©ã‚“ã§LLMã«å›ç­”ã•ã›ã‚‹ã®ã§ã¯ãªãã¦ã€è³ªå•ã‚’LLMã§å¤‰æ›ã—ã¦ã‚†ãã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- Query Understanding Layer
- Mistral-7B-Instruct-v0.2 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://x.com/npaka123/status/1734348586689908878?s=20
	- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- Mixtral-8x7B-Instruct-v0.1 ã‚’è©¦ã™ã€‚load_in_4bitã€‚ by npakaã•ã‚“ã€
	- https://x.com/npaka123/status/1734408371154100457?s=20
	- https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
	- èµ·å‹•ã¾ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å«ã‚ã¦20åˆ†ã§æ¨è«–é€Ÿåº¦ã¯200ãƒˆãƒ¼ã‚¯ãƒ³ã§21ç§’
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒPhi-2ã¨ã‹ã„ã†2.7Bãƒ‘ãƒ©ã®LLMã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://x.com/umiyuki_ai/status/1734763437274890746?s=20
	- MicrosoftãŒIgniteã§è©±ã—ã¦ã„ãŸã‚ãšã‹27å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«Phi-2
	- ãƒ‘ãƒ©æ•°å°ã•ã„ãã›ã«ã‚ã‚Šå¾—ã‚“é«˜æ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã‚‹ã‚‰ã—ã„ã€‚
	- å­¦ç¿’é‡ã¯1.4Tãƒˆãƒ¼ã‚¯ãƒ³ã§ã€96å€‹ã®A100ã§14æ—¥ã‹ã‘ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚
	- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ©æ•°3.2Bã®Gemini Nanoã«å®Œå‹ï¼ˆã¦ã‹Gemini Nanoã®ãƒ‘ãƒ©æ•°åˆã‚ã¦çŸ¥ã£ãŸã‚ï¼‰
	- ãã—ã¦ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ç‹¬è‡ªãƒ™ãƒ³ãƒã«ãŠã„ã¦ã€ã¾ã•ã‹ã®Llama2-70Bç›¸æ‰‹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§åœ§å‹ã€æ•°å­¦ã§åƒ…å·®ã«è¿«ã‚‹ã€‚Llama2-13Bç›¸æ‰‹ã«ã¯å®Œå‹ã—ã¦ã—ã¾ã†ã€‚
- The Emergent Abilities of LLMs Could Be A Mirage!
	- The best paper award in NeurIPs 2023 went to a paper claiming that the emergent abilities of LLMs could be a mirage!
- llamaindexã«ã¦mistralaiã®ã‚µãƒãƒ¼ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¬é–‹
	- https://docs.llamaindex.ai/en/stable/examples/llm/mistralai.html
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘Mixtral-8x7bã‚’llama.cppã§è©¦ã™
	- https://note.com/bakushu/n/n5b270b288cba?sub_rt=share_b
	- llama.cppã§ã€ŒMixtral-8x7bã€ã®GGUFé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¾ã—ãŸï¼ˆç¾æ™‚ç‚¹ã§ã¾ã mergeã•ã‚Œã¦ã„ãªã„ã®ã§branchã‚’åˆ©ç”¨ï¼‰
	- ã€Œ**Mixtral-8x7b**ã€ã¯MistralãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸMoEï¼ˆMixture of Expertsï¼‰æ§‹é€ ã®LLMã§ã€ŒMistral 7Bã€ãƒ™ãƒ¼ã‚¹ã®8å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æŸã­ã¦ã„ã¾ã™ã€‚
	-   ä»Šå›ã¯Google Colabã§ã€Œ[**Mixtral-8x7B-Instruct-v0.1-Q4_K_M-GGUF**](https://mixtral-8x7b-instruct-v0.1-gguf/)ï¼ˆ4bité‡å­åŒ–ç‰ˆï¼‰ã€ã®æ¨è«–ã‚’è©¦ã—ã¾ã—ãŸã€‚
	- 4bité‡å­åŒ–ã§ã‚‚26GBã»ã©ã‚ã‚Šã¾ã™ã€‚Colab Proã®CPUã‚ªãƒ³ãƒªãƒ¼+ãƒã‚¤ãƒ¡ãƒ¢ãƒªã§å®Ÿè¡Œã—ã¦ã¿ã¾ã—ãŸã€‚GPUã®ã¿ã§æ¨è«–ã™ã‚‹ãªã‚‰A100ãŒå¿…è¦ã§ã™ã€‚
	- Colabã®CPUã ã¨ã•ã™ãŒã«é…ã„ã‚‚ã®ã®ã€æœ€è¿‘ã®PCã®CPUãªã‚‰ãµã¤ã†ã«å‹•ã‹ã›ãã†ã€‚Llama 34B/70Bã®é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã‚‹ã¨å…¨ç„¶é€Ÿã„ã§ã™
- LangChainã‚’ä½¿ã‚ãªã„
	- https://tech-blog.abeja.asia/entry/advent-2023-day13
	- æŠ€è¡“çš„è² å‚µã«ãªã‚Šã†ã‚‹ã¨ã‹ã€Agentã£ã¦function callã§ä»£æ›¿å¯èƒ½ã¨ã‹ãã†ã„ã†è©±
- LlamaIndex + Gemini
	- https://blog.llamaindex.ai/llamaindex-gemini-8d7c3b9ea97e
	- llamaindexã€ã„ããªã‚ŠGeminiãƒ•ãƒ«ã‚µãƒãƒ¼ãƒˆ
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/gemini.ipynb
	-  Multi-modal Modelä¸­ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€ã€ã€
-  Google Generative Language Semantic Retriever
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/managed/GoogleDemo.ipynb
	- Googleâ€™s new semantic retrieval endpoint offers specialized embeddings and LLMs for high-quality retrieval + synthesis with guardrails. Use it out of the box, OR combine it with LlamaIndex components to build advanced RAG.
	- The Gemini API contains semantic search with custom embedding models for better retrieval, as well as toggles incl. safety during generation.
	- GoogleãŒsemantic Retrieverã£ã¦ã®ã‚’ã ã—ã¦ãŸã®ã‹ï¼Ÿ
- LangChainã‚‚Geminiå¯¾å¿œ
	- https://python.langchain.com/docs/integrations/chat/google_generative_ai
	- Access Google AIâ€™s `gemini` and `gemini-vision` models, as well as other generative models through `ChatGoogleGenerativeAI` class in the [langchain-google-genai](https://pypi.org/project/langchain-google-genai/) integration package.
- Gemini Pro APIã®ä¾¡æ ¼è¡¨ã€
	- https://ai.google.dev/pricing?hl=ja
	- å…¥åŠ›ãŒ$0.00025/1k charactersãªã®ã§gpt-3.5-turbo-1106ã®1/4ã®ä¾¡æ ¼ï¼ˆã¤ã¾ã‚Š11æœˆä»¥å‰ã®gpt-3.5-turboã®1/12ï¼‰ã§ä½¿ãˆã‚‹ã‚‰ã—ã„ã€‚
	- ãƒ•ãƒªãƒ¼ç‰ˆãªã‚‰ã°ã€60QPM (queries per minute)ã¾ã§ã¯ä½¿ãˆã‚‹ï¼ï¼ï¼ï¼
- phi-2ã‚’è©¦ã™
	- https://x.com/npaka123/status/1735077608071876882?s=20
	- Llama2-70Bç›¸æ‰‹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§åœ§å‹ã—ãŸ2.7Bãƒ¢ãƒ‡ãƒ«ã€‚
	- https://huggingface.co/microsoft/phi-2
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªä½œã—ã‚ˆã†ï¼(Transformers+DeepSpeed+torch.compile+flash_attn2
	- https://zenn.dev/selllous/articles/transformers_pretrain_to_ft
	- è‹±èªãŒãƒ¡ã‚¤ãƒ³ã®LLM Mistral-7Bãƒ¢ãƒ‡ãƒ«ã‚’300M(0.3B)ã¸ãƒ€ã‚¦ãƒ³ã‚µã‚¤ã‚ºã—ã¦ã€pretraining + instruction tuningã‚’Colabä¸Šã®GPU T4(!!!)ã§6æ™‚é–“(0.02epoch)ã§æ—¥æœ¬èªå­¦ç¿’ã•ã›ã‚‹ã¨ã„ã†æ„æ¬²çš„ãªè¨˜äº‹
-  FunSearch: Making new discoveries in mathematical sciences using Large Language Models
	- https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/?utm_source=twitter&utm_medium=social
	- DeepMindã®ç ”ç©¶ãƒãƒ¼ãƒ ãŒã€AIã‚’ç”¨ã„ã¦æ•°å­¦ã®æœªè§£æ±ºå•é¡Œã«æŒ‘ã¿ã€ç§‘å­¦ç•Œã«ãŠã‘ã‚‹å‰ä¾‹ã®ãªã„æˆæœã‚’å‡ºã—ãŸã¨ç™ºè¡¨ã—ã¾ã—ãŸã€‚ ã€ŒFunSearchã€ã¨åä»˜ã‘ã‚‰ã‚ŒãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã€å•é¡Œè§£æ±ºç­–ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å½¢ã§ç”Ÿæˆã€‚ã€Œã‚­ãƒ£ãƒƒãƒ—ã‚»ãƒƒãƒˆå•é¡Œã€ã¨ã€Œãƒ“ãƒ³ãƒ‘ãƒƒã‚­ãƒ³ã‚°å•é¡Œã€ã¨ã„ã†æ•°å­¦ã®å•é¡Œã«ãŠã„ã¦ã€æ–°ãŸãªè§£æ³•ã‚’ç™ºè¦‹ã—ãŸã¨ã®ã“ã¨ã§ã™ã€‚
	- Introducing FunSearch in @Nature: a method using large language models to search for new solutions in mathematics & computer science
	- DeepMindãŒLLMã‚’ã€Œäº‹å‰ã«ã‚¿ã‚¹ã‚¯è©•ä¾¡ã§ãã‚‹å•é¡Œã€ã«éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ„ã¿åˆã‚ã›ãŸFunSearch(searching in the function space)ææ¡ˆã€‚
	-  LLMãŒã‚³ãƒ¼ãƒ‰ç”Ÿæˆ->è©•ä¾¡->æ´—ç·´ã®ãƒ«ãƒ¼ãƒ—ã€‚ 
	- ** ç§‘å­¦,æ•°å­¦ã®æœªè§£æ±ºå•é¡Œã«å¯¾ã—ã¦ã€åˆã‚ã¦LLMã‚’ç”¨ã„ãŸæ–°ãŸãªç™ºè¦‹ **ã€‚ 
	- ãã®ä¾‹ã¨ã—ã¦cap set problem,bin-packing problemã€‚
-  Benchmarking RAG on tables
	- https://blog.langchain.dev/benchmarking-rag-on-tables/
	- llmaindexã‚ˆã‚Šã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ï¼²ï¼¡ï¼§ã«ã¤ã„ã¦ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€long contextã¯æ€§èƒ½ã¯ã§ãªã„
-  MOEè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ä¸€äººã‚’æ—¥æœ¬èªå¾—æ„ãªãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆãŸã‚‰ã©ã†ãªã‚‹ã®ã‹ï¼Ÿ
	- https://note.com/aisatoshi/n/n6c06d5183517?sub_rt=share_pb
	- Mistral7Bã‚’8ã¤æŸã­ãŸã€Mixtral 8x7Bã¨ã„ã†MOEãƒ¢ãƒ‡ãƒ«
	- ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’ä½•äººã‹ã€æ—¥æœ¬èªãŒå¾—æ„ãªMistral7Bäº’æ›ãƒ¢ãƒ‡ãƒ«ã«å·®ã—æ›¿ãˆãŸã‚‰ã©ã†ã ã‚ã†ï¼Ÿ
	- æ³¨æ„æ©Ÿæ§‹ã ã‘ã€MLPå±¤ã ã‘ã€ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°ã‚’å¤‰æ›´ãªã©å®Ÿé¨“ã—ã¾ã—ãŸãŒã€åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ãŒå£Šã‚Œã¾ã—ãŸ
- è‡ªæ°‘å…šãŒAIè¦åˆ¶ã‚’æè¨€
	- https://x.com/umiyuki_ai/status/1735277687097414124?s=20
- GCPã‚ˆã‚ŠGemeniã®æ§˜ã€…ãªåˆ©ç”¨æ–¹æ³•ã¨notebook
	- https://github.com/GoogleCloudPlatform/generative-ai
- Geminiã‚’ã¤ã‹ã£ã¦ã€ã‚¯ãƒªã‚¹ãƒã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œã‚‹ä¾‹ by google
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Prepare_Christmas_cards_with_Gemini_and_Sheets.ipynb
-  OpenAI thinks superhuman AI is coming â€” and wants to build tools to control it
	- https://openai.com/blog/superalignment-fast-grants
	- Open AIè¶…äººçš„ãªAIã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«å‘ã‘ãŸç ”ç©¶ã«1000ä¸‡ãƒ‰ãƒ«ã®åŠ©æˆé‡‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹ã€‚ 
	- æ”¯æ´ã«Google CEOå…¼ä¼šé•·ã®ã‚¨ãƒªãƒƒã‚¯ãƒ»ã‚·ãƒ¥ãƒŸãƒƒãƒˆæ°ã€‚ 
	- ã‚¤ãƒªãƒ¤ã‚µãƒ„ã‚±ãƒãƒ¼æ°ä»Šã‚‚ã¾ã Super Alignmentãƒãƒ¼ãƒ ç‡ã„ã¦ã‚‹ã¨ã®ã“ã¨ï¼
-  A Guide on 12 Tuning Strategies for Production-Ready RAG Applications
	- https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439
	- LLMã®RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®12æˆ¦ç•¥ã‚’æ›¸ã„ãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã€‚å…·ä½“çš„ã«ã¯ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€åŸ‹è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯åŒ–ã€ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°ã€ã‚¯ã‚¨ãƒªå¤‰æ›ã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ç­‰ã€å®Ÿè·µçš„ãªæˆ¦ç•¥ã€‚
- Bishopå…ˆç”Ÿã®ã€ŒDeep Learning: Foundations and Conceptsã€
	- https://www.bishopbook.com/
	- Vision Language Modelã®ã¨ã“ã‚è¦‹ãŸã‚‰CM3LeonãŒè¼‰ã£ã¦ã¦é©šã„ãŸ
- Benchmarking Large Language Models As AI Research Agents
	- https://arxiv.org/abs/2310.03302
	- ã“ã®è«–æ–‡ãŒç´ æ™´ã‚‰ã—ã„ã®ã¯ã€open-ended ãªçŠ¶æ³ã§ç ”ç©¶ã‚’ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’æ˜ç¢ºã«æç¤ºã—ãŸç‚¹ã 
- calm2-7b-chatã‚’RAG QAã§ä½¿ã†ãŸã‚ã®èª¿æŸ»
	- https://x.com/_oshizo_/status/1735282188546089332?s=20
	- contextå…¨ä½“ã®é•·ã•ï¼ˆæ¨ªè»¸ï¼‰ã¨ã€æ­£è§£ã«ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½ç½®ï¼ˆç¸¦è»¸ï¼‰ã‚’å¤‰ãˆãªãŒã‚‰ã€å‡ºåŠ›ã«æ­£è§£ã®æ–‡å­—åˆ—ã‚’å«ã‚“ã å‰²åˆã‚’é›†è¨ˆã€‚ 
	- æ­£è§£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒcontextã®æœ«å°¾ä»˜è¿‘ã«ã‚ã‚Œã°å…¨ä½“ã®é•·ã•ã¯ã‚ã¾ã‚Šå½±éŸ¿ã—ãªã„ãŒã€æœ«å°¾ã‹ã‚‰1ké›¢ã‚Œã‚‹ã”ã¨ã«æ­£ç­”ç‡ãŒ0.6æ›ã‘ã«ãªã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸
- LLMãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è©•ä¾¡ãƒ»ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦ã¾ã¨ã‚ã¦ã¿ãŸ
	- https://zenn.dev/pomcho555/articles/8e42f0a4ce39eb
	- RAGASã‚’ä½¿ã£ãŸè‡ªå‹•ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
	- RAGASã‚’ä½¿ã£ãŸè‡ªå‹•è©•ä¾¡
- Web3æ™‚ä»£ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ï¼Ÿ â€“ Geoã‚’è§¦ã£ã¦ã¿ãŸ
	- https://zenn.dev/s_egami/articles/4ec2e0de59ff4d
- "Pixel Aligned Language Models"
	- https://arxiv.org/abs/2312.09237
	- Googleã®ç ”ç©¶è€…ã‚‰ã¯ã€ç”»åƒã‚’ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã§è¨€èªåŒ–ã™ã‚‹èƒ½åŠ›ã‚’ã‚‚ã¤LLMã€PALMã€é–‹ç™ºã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®çµæœã€ã€ŒäººãŒç†è§£ã—ã‚„ã™ã„ã€å†…å®¹ã§æ­£ç¢ºã‹ã¤è©³ç´°ã«ç”»åƒã‚’èª¬æ˜ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ç¢ºèªã•ã‚Œã¾ã—ãŸ
-  æ—¥æœ¬ã®å¤å…¸å’Œæ­Œã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã§åˆ†æã™ã‚‹
	- https://note.com/yhkondo/n/nd321604729cd?sub_rt=share_pw
	- OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ã£ã¦ã€ã€å¤ä»Šé›†ã€ã€ä¸‡è‘‰é›†ã€ã€å’Œæ¼¢æœ—è© é›†ã€ç­‰ã‚’åˆ†æã—ã€ã„ã‚ã‚†ã‚‹ã€ŒèŠ±é³¥é¢¨æœˆã€ã¨ã„ã†æ¦‚å¿µãŒã©ã“ã‹ã‚‰ç”Ÿã¾ã‚Œã¦ããŸã‹ã‚’æ¢æ±‚ã—ãŸã‚‚ã®ã§ã™ã€‚AIã®æŒã¤åŠ›ã‚’æ„Ÿã˜ã¦ã„ãŸã ã‘ã‚‹ã¨ç¢ºä¿¡ã—ã¦ã„ã¾ã™
-  Google Colab ã§ Gemini Pro ã‚’ã‚‚ã£ã¨è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n1c368639cada?sub_rt=share_h
	- 1.  2. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®è¡¨ç¤º
	- 2.  3. è³ªå•å¿œç­”
	- 3.  4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
	- 4.  5. ãƒãƒ£ãƒƒãƒˆ
	- 5.  6. ç”»åƒã‹ã‚‰ã®è³ªå•å¿œç­”
	- 6.  7. ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®è³ªå•å¿œç­”
	- 7.  8. åŸ‹ã‚è¾¼ã¿ã®ç”Ÿæˆ
-  Voyager: An Open-Ended Embodied Agent with Large Language Models
	- https://arxiv.org/abs/2305.16291
	- LLMã‚’ã®ã›ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆã‚’ã•ã›ãŸç ”ç©¶ï¼Œé€²æ—ã®è§£é™¤å…·åˆã‚„ãƒãƒƒãƒ—ã®æ¢ç´¢ç¯„å›²ã®åºƒã•ã‚’ã¿ã¦ã„ã¦ï¼Œæ»…èŒ¶è‹¦èŒ¶é¢ç™½ã„ãªï½—ã€€ãƒ—ãƒ¬ã‚¤é¢¨æ™¯ã‚’ã¿ã¦ã¿ãŸã„
- mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- https://huggingface.co/mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- Mixtral-8x7B-Instruct-v0.1 ã®Expertsã®ã†ã¡2ã¤æ¯ã«mergeã—ã¦4x7bã«ã—ãŸå®Ÿé¨“ãƒ¢ãƒ‡ãƒ«ä½œã‚Šã¾ã—ãŸ
	- Modelã‚µã‚¤ã‚ºã¯24Bã«ãªã‚Šã¾ã™
- NeurIPS Large Language Model Efficiency Challenge:  1 LLM + 1GPU + 1Day
	- https://llm-efficiency-challenge.github.io/index
	- OSS LLMãƒ¢ãƒ‡ãƒ«ã‚’å…ƒã«é™ã‚‰ã‚ŒãŸè³‡æºãƒ»æ™‚é–“ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã™ã‚‹ã¨ã„ã†ã‚³ãƒ³ãƒš
	- é‡è¦ãªã®ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
	- è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ä¸Šè³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹æˆã—è¨“ç·´ã™ã‚‹ã®ãŒéµ
- 
	


## 12/11

ä»Šé€±ã¯ãªã‚“ã¨ã„ã£ã¦ã‚‚ã€Googleã®Geminiã€‚GPT-4è¶Šãˆã¨ã‹ã€ã™ãã«Bard(è‹±èªç‰ˆï¼‰ã§Gemini Proã‚’è©¦ã›ã‚‹ã¨ã‹ã€ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã—ã¦ä½¿ã†ãƒ‡ãƒ¢ã¨ã‹ã€ãã‚Œã‹ã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’ãƒ•ãƒ«ã«ç”Ÿã‹ã—ãŸå­ä¾›å‘ã‘ã®ãŠéŠã³ãƒ‡ãƒ¢ã¨ã‹ãªã‹ãªã‹è¡æ’ƒçš„ã§ã‚ã£ãŸãŒã€ãªã‚“ã¨ãŠéŠã³ãƒ‡ãƒ¢ãŒç´™èŠå±…ï¼ˆéƒ¨åˆ†ã‚’ã¤ãªã’ã¦ãã‚Œã‚‰ã—ãè¦‹ãˆã‚‹ã‚ˆã†ã«ã—ãŸã€éƒ¨åˆ†éƒ¨åˆ†ã¯æœ¬ç‰©ã‚‰ã—ã„ãŒï¼‰ã¨ã®å ±é“ãŒã‚ã‚Šã€äº‹å‰ã®ã€Œï¼‘æœˆã«é…å»¶ã€ã¨ã®å ±é“ã¨åˆã‚ã›ã‚‹ã¨ç· ã‚åˆ‡ã‚Šã«é–“ã«åˆã‚ãªã‹ã£ãŸã‚“ã ã‚ã†ã‘ã©ã€å‰å›ã®BardãŠæŠ«éœ²ç›®ã§ã®å¤±æ…‹ã¨ã„ã„ã€è„‡ãŒç”˜ã„ã€‚ãªãŠGeminiã®å‘½åã®ç”±æ¥ã€ä¸Šä½ï¼–åã®ä¸»è¦è²¢çŒ®è€…ã®First Nameã‹ã‚‰ã¨ã£ãŸã‚‰ã—ã„ã€‚Mambaã¨ã„ã†ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒã®ä»£æ›¿æŠ€è¡“ã€æ€§èƒ½ã‚ˆã•ãã†ã§æœŸå¾…ã€‚ DeepMindã®ã€GNoMEã€ã¯ã€Œäººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®ææ–™ã‚’ç™ºè¦‹ã—ã€ç§‘å­¦ã®ç™ºå±•ã‚’LLMãŒæ˜ã‚‰ã‹ã«åŠ é€Ÿã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãã‚Œã£ã¦å±é™ºãªææ–™ã‚‚ã€‚ã€‚ã€‚Metaã¯å®‰å…¨ãªAIã®ãŸã‚ã®Purple LLamaã‚’ç™ºè¡¨ã€Securityã‚„å®‰å…¨ã‚¬ãƒ¼ãƒ‰ã‚’æä¾›ã€‚æ”»æ’ƒï¼ˆred)ã¨é˜²å¾¡(blue)ãŒå”åŠ›ã™ã‚‹ã‹ã‚‰Prupleãªã‚“ã ã£ã¦ã€‚å®‰å…¨ã‚¬ãƒ¼ãƒ‰(Llama Guard)ã¯LLMã§å®Ÿè£…ã•ã‚Œã€ã¤ã¾ã‚ŠLLMã«ã¯LLMã£ã¦ã“ã¨ã€‚Metaã¯IBMç­‰ã¨ã®ä¼æ¥­é€£åˆã§å®‰å…¨ãªOSSã¨ã—ã¦ã®ç”Ÿæˆå‹AIé–‹ç™ºã‚’ä¿ƒé€²ã€OSSã®LLMãŒã¾ã™ã¾ã™ç†±ããªã‚‹ï¼Ÿã€‚Appleã‹ã‚‰æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯mlxç™ºè¡¨ã€M3ã£ã¦ã™ã”ã„ã‚“ã ã€LLMã§ã¯ä»Šä¸€æ­©ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ã®ç„¡ã„Appleã€CNBCã®æ½œå…¥ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§ã‚‚ã€LLMç«¶äº‰ã«é€²å‡ºã™ã‚‹ã‹ã¨èã‹ã‚Œã¦ã€è²¬ä»»è€…ã¯ãƒ¢ã‚´ãƒ¢ã‚´ã¯ãã‚‰ã‹ã—ã¦ãŸãªã€ã‚ã‚„ã—ã•æº€è¼‰ã€‚NVIDIAã®H100ã€MSã¨Metaã¯ãã‚Œãã‚Œ150k(15ä¸‡å€‹ï¼‰ã‚’æŒã£ã¦ã„ã¦ãƒ€ãƒ³ãƒˆãƒ„ã€ã©ã†ã‚‚H100ãŒ15ä¸‡å€‹ã‚ã‚Œã°ï¼—æ—¥ã§GPT-4ãŒä½œã‚Œã‚‹æ€§èƒ½ã‚‰ã—ã„ã€‚ä¸€æ–¹AMDã‚‚ç”ŸæˆAIã§NVIDIA H100ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã®GPUã€ŒInstinct MI300ã€ã‚’ç™ºè¡¨ã€‚GPUã‚‚ç†±ã„ã€ã‚ã‚Œã‚‰ã®ç‰§é‡å…ˆç”Ÿã®MN-coreã®ç™»å ´ã‚’æœŸå¾…ã—ã¾ã™ã‹ã€‚ã¤ã„ã«æ¬§å·AIæ³•ãŒæˆç«‹ã€AIã®å®šç¾©ãŒï¼¯ï¼¥ï¼£ï¼¤ã®ãã‚Œã«æ•´åˆã—ãŸã¨ã‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹è¦åˆ¶ã®æ˜ç¢ºåŒ–ãŒãƒã‚¤ãƒ³ãƒˆã€‚ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã«ã©ã†å‚™ãˆã‚‹ã‹ãŒè‚ã€‚ãã®AIæ³•ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¸ã®è¦åˆ¶éƒ¨åˆ†ã«ç•°è­°ã‚’å”±ãˆã¦ã„ãŸä»MistralãŒã€æº€ã‚’æŒã—ã¦ï¼Ÿæ–°ã—ã„ mixtral-8x7b-32kseqlenã‚’ç™ºè¡¨ã€MoE(Mixture of Expert)ã¨ã„ã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒè‚ã‚‰ã—ã„ã€æ¬§å·AIè¦åˆ¶ã«é–¢é€£ã—ã¦mixtral-8x7b-32kseqlenã‚’å¿µé ­ã«ã€ãŸã£ãŸ87Gã®weightã§AGIãŒæ¥ã‚‹ãªã‚‰AIè¦åˆ¶å¿…è¦ã ã‚ˆã­ã¿ãŸã„ãªæ„è¦‹ã‚‚è¦‹ã‹ã‘ãŸã€‚ã“ã®ã»ã‹ã«ã‚‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘ã‘ã®Ollama ã¨ã‹ã€è¨€èªãƒ‡ãƒ¼ã‚¿ãªã—ã§å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLVMï¼‰ã‚’æ§‹ç¯‰ã¨ã‹ã€ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã®æ—¥æœ¬ãŒDXã§ããªã„ãƒ¬ãƒãƒ¼ãƒˆ(èª¤æ¤ã‚’ç™ºè¦‹ï¼)ã¨ã‹ã€2bité‡å­åŒ–æŠ€è¡“QuIP#ã¨ã‹ã€æ§˜ã€…ã‚ã£ãŸãŒè¿½ãˆã¦ãªã„ã€‚ã€‚ãã‚‚ãã‚‚ã€ï¼‘é€±é–“åˆ†ã®ãƒ–ã‚¯ãƒæ•´ç†ã™ã‚‹ã ã‘ã§ï¼’æ™‚é–“ã‹ã‹ã‚‹ã‚“ã ã‘ã©ã€‚ã€‚ã€‚GPT-4ã«ã‚„ã‚‰ã›ã‚‹ã‹ã€‚ã€‚

- ä»Šæœˆã®NatureèªŒã¯é¢ç™½ã‹ã£ãŸ
	- https://x.com/ykfrs1217/status/1731287315459490165?s=20
	- â‘  å¤§éƒ½å¸‚ã»ã©ã€ç•°ãªã‚‹ç¤¾ä¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ã²ã¨ãŸã¡ã¯æ··ã˜ã‚ã‚‰ãªã„ï¼ˆ[https://doi.org/10.1038/s41586-023-06757-3â€¦](https://t.co/tEkbdQOPG3)ï¼‰ 
	- â‘¡ åŒã˜ç”ºï¼ˆâ‰ƒå­¦å†…ï¼‰ã®ç ”ç©¶è€…ã ã‘ã§è¡Œã‚ã‚ŒãŸç ”ç©¶ã®æ–¹ãŒã€ç•°ãªã‚‹åœ°åŸŸé–“ã®å…±åŒç ”ç©¶ã‚ˆã‚Šã‚‚é©æ–°çš„ãªæˆæœãŒã§ã‚„ã™ã„ï¼ˆ[https://doi.org/10.1038/s41586-023-06767-1â€¦](https://t.co/jrBRV4Gxtk)ï¼‰
-  Phantom oscillations in principal component analysis
	- https://www.pnas.org/doi/10.1073/pnas.2311420120?utm_source=TOC&utm_medium=ealert&TOC_v120_i48=&ref=d4140497
	- æ™‚é–“çš„ãƒ»ç©ºé–“çš„ã«ã‚¹ãƒ ãƒ¼ã‚ºãªãƒ‡ãƒ¼ã‚¿ (ã»ã¨ã‚“ã©ã®ç”Ÿç†ãƒ‡ãƒ¼ã‚¿â€¦) ç­‰ã‚’ä¸»æˆåˆ†åˆ†æ PCA ã™ã‚‹ã¨ã€å½ã®ã‚ªã‚·ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå‡ºç¾ã™ã‚‹
-  Refactoring Programs Using Large Language Models with Few-Shot Examples
	- https://arxiv.org/abs/2311.11690
	- ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«LLMã‚’ä½¿ã†
- "On Bringing Robots Home" Nur Muhammad Mahi Shafiullah et al., New York University
	- https://arxiv.org/abs/2311.16098
	- å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã®æ™®åŠã«å‘ã‘ã¦ã€ä¸€èˆ¬ã®ãƒ­ãƒœãƒƒãƒˆã‚’å„å®¶åº­ã«é©ç”¨ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€DobbÂ·Eã€ãŒé–‹ç™ºã•ã‚Œã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹
	- ä¸€èˆ¬ã®ãƒ­ãƒœãƒƒãƒˆã‚’å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä¸€é€£ã®æµã‚Œã‚’ã‚«ãƒãƒ¼ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒã€DobbÂ·Eã€
	- â‘  åˆè¨ˆ109ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿéš›ã®å®¶åº­ã§å®Ÿæ–½ã—ã€ãƒ­ãƒœãƒƒãƒˆã®æˆåŠŸç‡ãŒ81ï¼…ã«é”ã—ãŸ 
	- â‘¡ èª¿ç†å®¶é›»ã‚’é–‰ã‚ã‚‹ï¼ã‚¯ãƒƒã‚·ãƒ§ãƒ³ã‚’ã²ã£ãã‚Šè¿”ã™ã‚¿ã‚¹ã‚¯ã¯100ï¼…ã€6è»¸ã§ç‰©ã‚’ç§»å‹•ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯56% 
	- â‘¢ ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã«ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãŸç…§æ˜ã‚„å½±ã®æ¡ä»¶ä¸‹ã§ã¯ãƒ­ãƒœãƒƒãƒˆã¯å®‰å®šã—ã¦ç¨¼åƒã™ã‚‹
- Introducing Llama Datasets 
	- https://blog.llamaindex.ai/introducing-llama-datasets-aadb9994ad9e
	- llamaindexã‚ˆã‚Šã€RAGå‘ã‘ã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¬é–‹
	- history of alexanetã¨ã‹ã€origin of covid19ãªã©ã®pdfã‚’å«ã‚€ã€å¤šåˆ†æ­£è§£å€¤ã¯ï¼Ÿ
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
	- https://arxiv.org/abs/2311.16079
	- llama2ã‚’åŒ»ç™‚ã«ç‰¹åŒ–ã—ã¦ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸLLM
	- Compared to closed-source LLMs, MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2.
	- webuiã§è©¦ã›ã‚‹ï¼
	- https://github.com/epfLLM/meditron/blob/main/deployment/README.md#serving-with-web-gui
- RAGç”¨é€”ã«ä½¿ãˆã‚‹ã€Wikipedia æ—¥æœ¬èªã® embeddings ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã® faiss index ã‚’ä½œã£ãŸ
	- https://secon.dev/entry/2023/12/04/080000-wikipedia-ja-embeddings/
	- Wikipediaæ—¥æœ¬èª550ä¸‡æ–‡ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ãã‚‹embeddingsã¨æ¤œç´¢ç”¨faiss indexä½œã‚Šã¾ã—ãŸã€‚20è¡Œãã‚‰ã„ã‚³ãƒ¼ãƒ‰æ›¸ãã ã‘ã§ç°¡å˜ã«åˆ©ç”¨ã§ãã¾ã™ï¼RAGã—ã¦ã‚‚ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã¨é¢ç™½ã¿ãŒå°‘ãªã„ã®ã§ã™ãŒã€Wikipediaçªã£è¾¼ã‚€ã¨é¢ç™½ã•ãŒå¢—ãˆã¦ãã‚‹ã®ã§ã€èˆˆå‘³ã‚ã‚‹æ–¹ã¯ãŠè©¦ã—ãã ã•ã„ï¼
	- huggingface spaceã§è©¦ã›ã‚‹
	- https://huggingface.co/spaces/hotchpotch/wikipedia-japanese-rag-qa
	- ã€ŒãƒŠã‚¦ã‚·ã‚«ã¨æ£®ã®äººã¨ã®é–¢ä¿‚ã¯ï¼Ÿã€ã«ã¯å…¨ãç­”ãˆã‚‰ã‚Œãªã„ã€‚
	- FAISS+ELYZAã ã¨ã€ã€ŒãƒŠã‚¦ã‚·ã‚«ã¨æ£®ã®äººã¯ä»²è‰¯ã—ã ã£ãŸã€‚ã€ã¨ç­”ãˆã¦ãã‚ŒãŸã®ã«ã€‚ã€‚
- Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift
	- https://arxiv.org/abs/2311.15961
	- å…±å¤‰é‡ã‚·ãƒ•ãƒˆã®ãƒã‚¿ã§"All you need"çš„ãªæµè¡Œã‚Šã®ã‚¿ã‚¤ãƒˆãƒ«ã®è«–æ–‡ãªã‚“ã ã‘ã©ï¼Œå†…å®¹ã¯ã—ã£ã‹ã‚Šæ•°ç†ã‚„ã£ã¦ã‚‹ã£ã½ã„ï¼ãŒã£ã¤ã‚ŠShimodaira (2000)ã‚‚å‚ç…§ã•ã‚Œã¦ã¾ã—ãŸï¼å…±è‘—è€…ã«æ•°ç†çµ±è¨ˆã®å¤§å¾¡æ‰€ã®Jianqing Fanå…ˆç”Ÿã¨ã‹ï¼Œæ©Ÿæ¢°å­¦ç¿’ã®ç†è«–ç³»ã®Chi Jinå…ˆç”Ÿãªã©
- Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation
	- https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2
	- Check out this fantastic blog covering the basics of RAG, the theory behind it, and how to use it in practice
- Mamba: Linear-Time Sequence Modeling with Selective State Spaces
	- https://arxiv.org/abs/2312.00752
	- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚„æ³¨æ„æ©Ÿæ§‹ã«é ¼ã‚‰ãªã„ã€ç·šå½¢æ™‚é–“ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
	- 2å€ã‚µã‚¤ã‚ºã®Transformersã«åŒ¹æ•µã—ãŸã‚Šã€5å€ã®é«˜é€Ÿæ¨è«–ãŒå‡ºæ¥ãŸã‚Šã¨ã€Transformerã‚’ä»£æ›¿ã—ã†ã‚‹å¯èƒ½æ€§
	- 2.8BãŒå‡ºã¦ã‚‹ã‚‰ã—ã„ã€
	- https://huggingface.co/state-spaces/mamba-2.8b
-  Instruction-tuning Aligns LLMs to the Human Brain
	- https://arxiv.org/abs/2312.00575
	- Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain.
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã®å¿œç”¨å‹•å‘ã®è«–æ–‡èª¿æŸ»
	- https://speakerdeck.com/masatoto/marutimodarullmnoying-yong-dong-xiang
- ç”Ÿæˆæ–‡æ³•ç ”ç©¶è€…ã®ä¸­ã§ã€Œè¨€èªã®æœ¬è³ªã€ï¼ˆä»Šäº•å…ˆç”Ÿï¼‰ã®è©•åˆ¤ãŒè‰¯ããªã‹ã£ãŸ
	- https://x.com/kkling51/status/1731543891348996466?s=20
	- (i) ã‚¢ãƒ–ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¨è«–ã¯é©åˆ‡ãªæ¨è«–ã§ã¯ãªã„ã‹ã‚‰ãã‚Œã«é ¼ã‚‹ã¹ãã§ã¯ãªã„ 
	- (ii) è¨€èªã¨ã¯ä½•ã‹ã¨ã„ã†å®šç¾©ãŒãªã„ãŸã‚ï¼Œæœ¬è³ªãŒä½•ãªã®ã‹åˆ†ã‹ã‚‰ãªã„ï¼
	- ãƒ—ãƒ©ãƒˆãƒ³ã®å•é¡Œã‚‚æœªè§£æ±ºã®ãƒãƒ
- Amil Merchant et al., "Scaling deep learning for materials discovery", nature
	- https://www.nature.com/articles/s41586-023-06735-9
	- DeepMindã®ã€GNoMEã€ãŒã€Œäººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®ææ–™ã‚’ç™ºè¦‹ã—ã€ã†ã¡736ã¯æ—¢ã«äººé–“ãŒå®Ÿé¨“å®¤ã§å†ç¾ã—ãŸã¨ã®å ±å‘Š
	- å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å…ˆé€²çš„ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹æ‰‹æ³•ã«ã‚ˆã‚‹ã€ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ç™ºå±•äº‹ä¾‹ã§ã™
	- æ–¹æ³•
		- â‘  GNNã‚’ç”¨ã„ã¦ç´ æã®ç‰¹æ€§ã‚’æ§‹é€ ã‚„çµ„æˆã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«åŒ–
		-  â‘¡ ææ–™ç™ºè¦‹ã®åŠ¹ç‡ãŒå¤§å¹…ã«å‘ä¸Šã—ã€äººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®æ§‹é€ ãŒç™ºè¦‹ã•ã‚ŒãŸ 
		- â‘¢ çµæ™¶æ§‹é€ å†…ã®åŸå­ã‚’ç½®æ›ã™ã‚‹æ‰‹æ³•ã‚„ãƒ©ãƒ³ãƒ€ãƒ ãªæ¢ç´¢ã‚’å«ã‚€ã€å¤šæ§˜ãªå€™è£œç”Ÿæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¢ºç«‹
	- çµæœ
		- â‘  220ä¸‡ã®æ–°ãŸãªå®‰å®šæ§‹é€ ã‚’ç‰¹å®šã—ã€ãã‚Œã‚‰ã®å¤šãã¯æ—¢å­˜ã®åŒ–å­¦çš„ç›´æ„Ÿã‚’è¶…ãˆã¦ã„ãŸ 
		- â‘¡ ç™ºè¦‹ã•ã‚ŒãŸå®‰å®šæ§‹é€ ã®ã†ã¡736ã¯ã€ç‹¬ç«‹ã—ãŸå®Ÿé¨“ã§å®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸Šã§ã®æ¤œè¨¼ã§ã¯ãªãã€å®Ÿé¨“å®¤ã§ç‰©ç†çš„ã«ææ–™ã‚’ä½œæˆã—ã€å®Ÿè¨¼ã§ããŸï¼‰
- NVIDIAã®H100ã‚’ã©ã“ã«å‡ºè·ã—ãŸã‹ã®å›³ã€‚MS,MetaãŒåœ§å€’çš„ã«å¤šã„ã€GPT4ã‚’7æ—¥ã§è¨“ç·´ã§ãã‚‹è¦æ¨¡ï¼Ÿ
	- https://x.com/Lauramaywendel/status/1731698695853244849?s=20
	- GPT4 was presumably trained for around 90 days using 25k A100 GPUs. Microsoft and Meta having reportedly bought 150k H100 GPUs each this year, can now train a GPT4 class model in only 7 days from scratch
- Google Geminiã®æä¾›ã‚’ï¼‘æœˆã¾ã§å»¶æœŸ
	- https://x.com/rowancheung/status/1731531903193219260?s=20
	- ã„ãã¤ã‹ã®åˆ†é‡ã§ã¯GPT-4ã‚’ä¸Šå›ã‚‹ã‚‚ã€è‹±èªä»¥å¤–ã§ã®æ€§èƒ½ãŒå‡ºãªã„ã€‚
	- ã“ã‚Œã£ã¦ã€å¾Œã‹ã‚‰ç¶šãã‚¤ãƒ™ãƒ³ãƒˆã®äºˆå…†ã‹ã—ã‚‰ã‚“ã€
- ã‚ã‚‹ç‰©ç†å­¦ã®æœ¬ã§ã€ã‚®ãƒªã‚·ãƒ£èªã®èª¬æ˜è¡¨ã§ã‚¼ãƒ¼ã‚¿ã®ã¨ã“ã‚ãŒã€ã€
	- https://x.com/yori_Alphard/status/1731663363737026586?s=20
	- "Zã‚¬ãƒ³ãƒ€ãƒ "ã«ãªã£ã¦ã„ã‚‹ã€‚ã€‚
- GIVT: Generative Infinite-Vocabulary Transformers
	- https://huggingface.co/papers/2312.02116
	- æœ¬å½“ã«ãƒˆãƒ¼ã‚¯ãƒ³ãŒé›¢æ•£ã§ãªãã¦ã€ç„¡é™ãªã®ã ã‚ã†ã‹ï¼Ÿ
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ä¸è¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã ã‘ã§ã©ã†ã«ã‹ãªã‚‹ï¼Ÿ
	- https://x.com/IntuitMachine/status/1732089266883141856?s=20
	- A recent research paper provides compelling evidence that the extensive fine-tuning used to "align" large language models into helpful assistants may be largely unnecessary.
	- Allenã‚¤ãƒ³ã‚¹ãƒ†ã‚£ãƒ†ãƒ¥ãƒ¼ãƒˆã®ä»•æ¥­ã‹ã€https://allenai.org/
- llamaindexã§ã‚‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãŒç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€Webinerãªã©
	- https://x.com/llama_index/status/1732081850246627547?s=20
	- https://lu.ma/350wf7v7
- å®‰å…¨ã§è²¬ä»»ã‚ã‚‹AIã®é–‹ç™ºå‘ã‘ã¦ã€Metaã¨IBMãŒææº
	- https://ai.meta.com/blog/ai-alliance/
	- IBM ã¨ãƒ¡ã‚¿ã¯ã€*ã‚ªãƒ¼ãƒ—ãƒ³*ã§ä¿¡é ¼æ€§ã®é«˜ã„ AI ã‚’æ¨é€²ã™ã‚‹ãŸã‚ã« AI Alliance ã‚’ç«‹ã¡ä¸Šã’ã¦ã„ã¾ã™ã€‚ ç”£æ¥­ç•Œã€æ”¿åºœæ©Ÿé–¢ã€å­¦ç•Œã‹ã‚‰ã® 50 ã‚’è¶…ãˆã‚‹è¨­ç«‹ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒªã‚¹ãƒˆã«ã¯ã€AMDã€Anyscaleã€CERNã€Hugging Faceã€Linux Foundationã€NASA ãŒå«ã¾ã‚Œã¾ã™ã€‚
	- æ—¥çµŒã«ã‹ã‹ã‚‹ã¨ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€ã€Œãƒ¡ã‚¿ã¨IBMã€ç”ŸæˆAIã€Œã‚ªãƒ¼ãƒ—ãƒ³å‹ã€ã¸ã€€50ç¤¾ãƒ»å›£ä½“ã¨é€£æºã€
- Prompting vs RAGs vs Fine-tuning:
	- https://x.com/akshay_pachaar/status/1732014719794585684?s=20
	- ã‚ˆãã‚ã‚‹ï¼”è±¡é™ã®çµµã€
	- So finetuning is more about changing structure (behaviour) than knowledge, while it's other way round for RAGs.
	- You use RAGs when you want to generate outputs grounded to a custom knowledge base while the vocabulary & writing style of the LLM remains same.
	- If you don't need either of them, prompt engineering is the way to go.
	- And if your application need both custom knowledge & change in the behaviour of model a hybrid (RAGs + Finetuning) is preferred.
- OpenAIã®Safety System Teamsã‹ã‚‰
	- https://openai.com/safety/safety-systems
	- å”åŠ›ã®ãŠé¡˜ã„
- PyTorchãŒå‡ºã—ãŸã€gpt-fastã¯ã™ã”ã„ã‚‰ã—ã„
	- https://x.com/AlphaSignalAI/status/1732116360162050099?s=20
	- Pytorch just released GPT-Fast, an implementation of transformer text generation with everything you need in <1000 lines of code.
	- https://github.com/pytorch-labs/gpt-fast
- Windows11ã«copilotãŒé™è‡¨ï¼Ÿ
	- https://www.microsoft.com/en-us/windows/copilot-ai-features?r=1
- JWT(Json Web Token)
	- https://x.com/alexxubyte/status/1732077250626179578?s=20
- Jellyfish: A Large Language Model for Data Preprocessing
	- https://arxiv.org/abs/2312.01678
	- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’å¾—æ„ã¨ã™ã‚‹LLMã€Jellyfishï¼ˆã‚¯ãƒ©ã‚²ï¼‰ã€ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚ æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚å¯¾å¿œã§ãã€æ¯”è¼ƒçš„è»½é‡ã§ã‚ã‚Š1GPUã§ã‚‚å‹•ä½œã™ã‚‹ã¨ã®ã“ã¨ã§ã™ã€‚ 
	- å¤§é˜ªå¤§å­¦ã€NECã€åå¤å±‹å¤§å­¦ã®ç ”ç©¶è€…ã‚‰ã«ã‚ˆã‚‹ç™ºè¡¨ã§ã™
	- â‘  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãŒé€²åŒ– ï¼ˆGPT-4ã¨åŒç­‰ã®æ€§èƒ½ã§ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’è¡Œã†ï¼‰ 
	- â‘¡ ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ 
	- â‘¢ å¤šæ§˜ãªå‰å‡¦ç†ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œ 
	- â‘£ ã‚µã‚¤ã‚ºãŒå°ã•ã„ãŸã‚ã€1GPUã§ã‚‚å‹•ä½œã™ã‚‹
- GooglãŒGemini(ã‚¸ã‚§ãƒãƒŠã‚¤ã¨èª­ã‚€ï¼‰ã‚’ç™ºè¡¨
	- https://blog.google/technology/ai/google-gemini-ai/
	- 1. Geminiã¯3ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«(Ultra, Pro, Nano)ãŒå­˜åœ¨ã€‚UltraãŒæœ€ã‚‚è³¢ãã€Nanoã¯ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã€‚
	- 2. Ultraã¯æ•°ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT-4è¶…ãˆã®æ€§èƒ½ã‚’ç™ºæ® (ï¾„ï¾ï¾”ï½§)
	- 3. Geminiã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«å¼·ã„ã€‚å‹•ç”»ãƒ‡ãƒ¢ã®ã‚ˆã†ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚‚å¯èƒ½ã€‚ 
	- 4. æœ¬æ—¥ã‚ˆã‚ŠBardã¯Gemini Proã®Fine-tuningãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åˆ©ç”¨ã—ã¦å…¬é–‹ã™ã‚‹ã€‚ãã®ä»–ã«ã‚‚Googleè£½å“ã¸ã®å°å…¥ã‚’é€²ã‚ã‚‹ã€‚ 
	- 5. Gemini APIã¯12æœˆ13æ—¥ã‹ã‚‰Google AI Studioã‚’é€šã˜ã¦æä¾›ã•ã‚Œã‚‹ã€‚
	- https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
- Google AlphaCode 2 ã‚’ç™ºè¡¨
	- AlphaCode 2 Technical Report
	- https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf
	- Geminiã‚’ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç”¨ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸAlphaCode2ã¯ã€ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°äººå£ã®ä¸Šä½15%ã®æ€§èƒ½
- Metaã®Streamingã®ç¿»è¨³æ€§èƒ½ã¯ã™ã”ã„ã‚‰ã—ã„ã€	
	- https://x.com/hokazuya/status/1732374854027132940?s=20
	- ç¿»è¨³ã“ã‚“ã«ã‚ƒããƒ¬ãƒ™ãƒ«
- Bardã®ç”Ÿæˆè¨˜äº‹ã¯ChatGPTã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ï¼Ÿ
	- https://x.com/kajikent/status/1732237182126129578?s=20
	- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®é ˜åŸŸã§æœ‰åãªNeil Patelæ°ãŒç´„250ãšã¤ã®ChatGPTç”Ÿæˆã®è¨˜äº‹ã¨Google Bardç”Ÿæˆã®è¨˜äº‹ã§èª­è€…ã«ã©ã¡ã‚‰ãŒå¥½ãã‹èã„ãŸã¨ã“ã‚ã€BardãŒåœ§å‹ã™ã‚‹çµæœã«
- äººé–“ãƒ¬ãƒ™ãƒ«ã®AI(AGI)ã«åˆ°é”ã™ã™ã‚‹ã«ã¯ã€å¸¸ã«10å¹´ä»¥ä¸Šå¿…è¦
	- https://x.com/ylecun/status/1732391273611370931?s=20
	- 3ï½5å¹´ã¯å¸¸ã«å¿…è¦ï¼ˆæ°¸é ã«é”æˆã§ããªã„ï¼‰ã¨ã®è¨˜äº‹ã«Lecanå…ˆç”Ÿã®åå¿œ
- Appleè£½å“Mã‚·ãƒªãƒ¼ã‚ºã«æœ€é©åŒ–ã•ã‚ŒãŸæ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯mlx
	- https://x.com/goto_yuta_/status/1732287555599741103?s=20
	-  Macã«æ­è¼‰ã•ã‚Œã¦ã‚‹GPU(MPS)ãŒã‚ˆã‚Šæœ‰åŠ¹æ´»ç”¨ã•ã‚Œã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã®é«˜é€Ÿæ¨è«–ãŒå¯èƒ½ã«ãªã£ãŸã‚‰å¬‰ã—ã„ãªã€‚
	- CNBCã®ã€Apple Labã¸ã®æ½œå…¥ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
	- https://www.youtube.com/watch?v=UdhWvg5mycY
- Geminiã®Technical reportã‚’æ—¥æœ¬èªã§è§£èª¬ã—ã¦ã„ã‚‹äººãŒç™»å ´
	- https://x.com/bioshok3/status/1732421662619140551?s=20
	- Gemini Ultraã¯ã€MMLU ã§äººé–“ã®å°‚é–€å®¶ã®æ€§èƒ½ã‚’é”æˆã—ãŸæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã‚¹ã‚³ã‚¢ã¯90%ä»¥ä¸Šã€‚ã‚„ã°ã™ãã‚‹ã€‚äººé–“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è‘—è€…ã«ã‚ˆã£ã¦89.8%ã¨è©•ä¾¡ã•ã‚Œã€Gemini Ul traã¯ã“ã®é–¾å€¤ã‚’è¶…ãˆãŸæœ€åˆã®ãƒ¢ãƒ‡ãƒ«!æ™‚ä»£ãŒå¤‰ã‚ã£ãŸã€‚
	- æ•™å¸«ãŒã‚¹ã‚­ãƒ¼ãƒ¤ãƒ¼ãŒå‚é“ã‚’ä¸‹ã‚Šã‚‹ã¨ã„ã†ç‰©ç†å•é¡Œã‚’æãã€ç”Ÿå¾’ãŒãã®è§£æ±ºç­–ã‚’ç·´ã‚‹ã€‚Geminiã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–æ©Ÿèƒ½ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¯ ä¹±é›‘ãªæ‰‹æ›¸ãã‚’ç†è§£ã—ã€ç”Ÿå¾’ãŒå•é¡Œã®è§£æ±ºã‚’é–“é•ãˆãŸæ¨è«–ã®ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç‰¹å®šã—ã€å•é¡Œã®æ­£ã—ã„è§£æ±ºã‚’é€šã— ã¦ä½œæ¥­ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
	- Google ãŒGeminiã®ãƒ‡ãƒ¢å‹•ç”»ã‚’å‡ºã—ã¦ã„ã‚‹ã‘ã©ã€ã“ã‚Œã»ã‚“ã¨ã«ã“ã®æ¨è«–é€Ÿåº¦ãªã‚‰å‡„ã™ãã‚‹ã¨è¨€ã†ã‹ã‚‚ã†æ ªä¾¡æ•°å€ãã‚‰ã„ã«ãªã‚‹ã‚“ã˜ã‚ƒãªã„ã®ï¼Ÿã£ã¦ãƒ¬ãƒ™ãƒ«ã ã‘ã©ï¼Ÿï¼Ÿ
	- ãƒ‡ãƒ¢ã«ã¤ã„ã¦ã¯ã€Œã“ã®ãƒ‡ãƒ¢ã®ç›®çš„ã®ãŸã‚ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯çŸ­ç¸®ã•ã‚Œã€ã‚¸ã‚§ãƒŸãƒ‹ã®å‡ºåŠ›ã¯ç°¡æ½”ã«ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã€ã¨æ›¸ã‹ã‚Œã¦ã‚‹
	- å¤šè¨€èªæ€§èƒ½ã¯GPT-4ã‚ˆã‚Šè‰¯ã„
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯32768ã€‚98%ã®ç²¾åº¦ã§æ­£ã—ã„å€¤ã‚’å–å¾—å¯èƒ½ï¼98%?ã¾ã˜ã‹ã‚ˆã€‚
- Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨€èªè¨­å®šã‚’è‹±èªã«ã™ã‚‹ã¨ã€Bardã®ãƒãƒƒã‚¯ãŒGemimi ProãŒä½¿ãˆã‚‹
	- https://x.com/npaka123/status/1732504570218283340?s=20
- Bard(Gemini Pro)ãŒéœãŒé–¢ãƒ‘ãƒ¯ãƒã‚’è§£æã—ã¦èª¬æ˜ã—ã¦ãã‚Œã‚‹ã¨ã€ã€	by ã‚†ãªå…ˆç”Ÿ
	- https://x.com/JapanTank/status/1732689643928445164?s=20
- Geminiè«–æ–‡ã®æœ€å¾Œã®ã€"Core Contributors"ã®æœ€åˆã®ï¼–äººã®é ­æ–‡å­—ã‚’ã¨ã‚‹ã¨ã€"GEMINI"ã«ãªã‚‹
	- https://x.com/nearcyan/status/1732532560029172142?s=20
- Metaã‚ˆã‚Šã€å®‰å…¨ãªAIã®ãŸã‚ã®ã€Purple Llamaï¼ˆãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¿ãŸã„ãªã‚‚ã®ï¼‰ã‚’ç™ºè¡¨
	- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=image
	- CyberSec Evalã¨ã‹ã€Llama GuardãŒæœ€åˆã«å‡ºã‚‹
	- ãªã‚“ã§purpleã‹ã¨ã„ã†ã¨æ”»æ’ƒå´ï¼ˆèµ¤ï¼‰ã¨ã€é˜²å¾¡å´ï¼ˆé’ï¼‰ãŒå”åŠ›ã—ã¦æ§‹ç¯‰ã—ãŸã‹ã‚‰
	- attack (red team) and defensive (blue team) postures.
	- Colabã§è©¦ã›ã‚‹ã‚‰ã—ã„
	- https://colab.research.google.com/drive/16s0tlCSEDtczjPzdIK3jq0Le5LlnSYGf?usp=sharing
- Evaluating and Mitigating Discrimination in Language Model Decisions
	- https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions
	- Anthropicã‚ˆã‚Šã€ï¼ˆLLMã®å‡ºåŠ›ã«ãŠã‘ã‚‹ï¼‰å·®åˆ¥ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹
-  AMDã€ç”ŸæˆAIã§NVIDIA H100ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã®GPUã€ŒInstinct MI300ã€
	- https://pc.watch.impress.co.jp/docs/news/1552583.html
	- TDP 750Wã®MI300Xã¯ã€TDP 700Wã®NVIDIA H100ã¨æ¯”è¼ƒã—ã€FP64,32ã§ç´„2.4å€ã€AIã§åˆ©ç”¨ã®TF32ã€FP16ã€BF16ã€FP8ã€INT8ãªã©ã§ã¯1.3å€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿç¾ã€‚
- èµ¤çŸ³å…ˆç”Ÿã®ãƒ™ã‚¤ã‚ºæ¨è«–æœ¬ãŒã‚ã‹ã‚Šã‚„ã™ã„ã¨è©•åˆ¤ã«
	- https://x.com/kenken26679105/status/1732977179485757744?s=20
	- å°‘ãªã„ãƒ‡ãƒ¼ã‚¿é‡ã§ã‚‚ã€ã“ã‚“ãªé¢¨ã«ã€è‰²ã‚“ãªå®Ÿå‹™ã®å ´é¢ã«ã™ãã«æ´»ç”¨ã§ãã¡ã‚ƒã†
	- Pythonã§ã‚¹ãƒ©ã‚¹ãƒ©ã‚ã‹ã‚‹ ãƒ™ã‚¤ã‚ºæ¨è«–ã€Œè¶…ã€å…¥é–€ (KSæƒ…å ±ç§‘å­¦å°‚é–€æ›¸)
- ãƒãƒ§ãƒ ã‚¹ã‚­ãƒ¼ã®ã€Œç”Ÿæˆæ–‡æ³•ã€ã¯æ­»ã‚“ã ã¨ã„ã†è«–æ–‡
	- Modern language models refute Chomskyâ€™s approach to language
	- https://lingbuzz.net/lingbuzz/007180/v1.pdf
	- æœ€è¿‘ã®ç”ŸæˆAIã¦ã†ã‹å¤§è¨€èªãƒ¢ãƒ‡ãƒ«LLMã®é©šãã¹ãæˆåŠŸã‹ã‚‰è¦‹ã¦ã€ãƒãƒ§ãƒ ã‚¹ã‚­ãƒ¼æµã®ç”Ÿå¾—çš„çµ±èªæ³•è¦å‰‡ãŒã‚ã‚‹ã¨ã„ã†èª¬ã¯ç¶­æŒã—ã¥ã‚‰ã„
- llamaindexã‚ˆã‚Šã€çŸ¥è­˜ã‚°ãƒ©ãƒ•(KG)ã‚’ä½¿ã†ã€ï¼—ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ã«ã¾ã¨ã‚ã¦ãã‚ŒãŸ
	- https://x.com/llama_index/status/1733190430760845673?s=20
	-  A Simpler Way to Query Neo4j Knowledge Graphs
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/neo4j_query_engine/llama_packs_neo4j.ipynb
- æ¬§å·AIæ³•ã®æœ€çµ‚ãƒˆãƒªãƒ­ãƒ¼ã‚°ãŒçµ‚äº†ã€å¦¥çµã¸
	- https://x.com/WIRED/status/1733268732309332398?s=20
	- https://www.reuters.com/technology/eu-clinches-deal-landmark-ai-act-2023-12-09/?taid=65745dd360152800018aaf1c&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter
	- https://twitter.com/SabrinaKuespert/status/1733311752941515135/photo/1
	- https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?xtor=AD-78-[Social_share_buttons]-[twitter]-[en]-[news]-[pressroom]-[artificial-intelligence-act-possible-deal]-
	- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§è¦åˆ¶ã•ã‚Œã‚‹ã®ã¯ã€è¨ˆç®—é‡ãŒ10^25FLOPsã‚’è¶…ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚
	- è©²å½“ã™ã‚‹ã®ã¯ä»Šã‚“ã¨ã“GPT-4ã¨Geminiã‚ãŸã‚Šã€‚
	- ãã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã«å¿œã˜ã¦åˆ†é¡ã•ã‚Œã‚‹ã€‚
	- ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã¯ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚“ã ã‘å¼·åŠ›ã‹ã€ã©ã‚“ã ã‘ã®äººãŒä½¿ã†ã‹ã§æ±ºã¾ã‚‹ã€‚
	- è¦åˆ¶ã®å†…å®¹ã¯
		- â‘ ãƒªã‚¹ã‚¯ã®è»½æ¸›ã‚’è¡Œã†ã€€
		- â‘¡ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã€æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã™ã‚‹ã€€
		- â‘¢ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®ç›£è¦–ã‚’ã™ã‚‹ã€€
		- â‘£ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã•ã›ã‚‹ã€€
		- â‘¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œã‚‰ã›ã‚‹
-  Generative AI for Everyoneã‹ã‚‰ã€å¤ã®NLPã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¿ƒã«åˆºã•ã£ãŸã“ã¨8é¸
	- https://note.com/csstudyabroad/n/n5aba3a708f3a
- "Purple Llama CyberSecEval: A benchmark for evaluating the cybersecurity risks of large language models"
	- LLama Purpleé–¢é€£ã® CyberSecEvalã®è«–æ–‡
	- https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/
	- Metaã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMãŒç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹ä¸å®‰å®šæ€§ã‚„ä¹±ç”¨ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚
	-  å®Ÿé¨“ã®çµæœã€ç¾åœ¨ã¯ã€èƒ½åŠ›ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã»ã©ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã™ã‚‹å‚¾å‘ãŒå¼·ã„ã¨ã„ã†é€†èª¬çš„ãªçµæœã‚‚å‡ºã¦ãã¾ã—ãŸã€‚
	- â‘  å…¨ä½“çš„ã«LLMã¯ã€30%ã®ã‚±ãƒ¼ã‚¹ã§ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ãŸ 
	- â‘¡ 53%ã®ã‚±ãƒ¼ã‚¹ã§ã€ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒã®æ‰‹ä¼ã„ã‚’ã™ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦LLMãŒå¿œã˜ãŸ
	-  â‘¢ ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã»ã©ã€ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã™ã‚‹å‚¾å‘ãŒå¼·ã‹ã£ãŸ
- "Sequential Modeling Enables Scalable Learning for Large Vision Models"
	- https://arxiv.org/abs/2312.00785
	- ã€Œè¦–è¦šã¯æœ¬æ¥ã€è¨€èªã«ä¾å­˜ã—ãªã„ã€ã¨è€ƒãˆãŸUCãƒãƒ¼ã‚¯ãƒ¬ãƒ¼ã¨ã‚¸ãƒ§ãƒ³ã‚¹ãƒ›ãƒ—ã‚­ãƒ³ã‚¹å¤§å­¦ã®ç ”ç©¶è€…ã‚‰ã¯ã€è¨€èªãƒ‡ãƒ¼ã‚¿ãªã—ã§å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLVMï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- â– ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è©³ç´° 
		- â‘  ç”»åƒã‚„å‹•ç”»ã‚’è¡¨ç¾ã™ã‚‹ã€Œãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æ–‡ã€ã‚’å®šç¾© ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ä»¥å¤–ã®ãƒ¡ã‚¿æƒ…å ±ã¯ãªã„ï¼‰ 
		- â‘¡ è¦–è¦šãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ– 
		- â‘¢ è‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
	- â– å®Ÿé¨“ã®çµæœã‚ã‹ã£ãŸã“ã¨ 
		- â‘  ãƒ¢ãƒ‡ãƒ«ã¯å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—å­¦ç¿’ã™ã‚‹èƒ½åŠ›ãŒé«˜ã„
		-  â‘¡ æ§˜ã€…ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹ 
		- â‘¢ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã™ã‚‹
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- Scenarios of adopting LLMs, techniques for utilizing LLMs on graphs, applications, #opensource code repositories, benchmark datasets
- ã€Œ2030 æ—¥æœ¬ãƒ‡ã‚¸ã‚¿ãƒ« æ”¹é©ã€ by ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼
	- https://www.digitaljapan2030.com/_files/ugd/c01657_fcaed21f58bb4c429cb460ce788b82c4.pdf
	- ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå…¨140ãƒšãƒ¼ã‚¸ï¼‰
	- æ—¥æœ¬ã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ãŒãªãœé…ã‚ŒãŸã®ã‹ã€ãã‚Œã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‰“ã¡æ‰‹ãŒå–ã‚Œã‚‹ã®ã‹ã€ã¨ã„ã†ã“ã¨ãŒåˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ 
	- æ—¥æœ¬ã®ç·åŠ´åƒæ™‚é–“ã®56%ãŒè‡ªå‹•åŒ–å¯èƒ½
	- ã¨ã„ã£ã¦ã‚‚åˆæœŸç‰ˆã«ã¯èª¤æ¤ãŒã€(Ã—æ”¿åºœã®æ”¯æŒâ†’ã€‡æ”¿åºœã®æŒ‡ç¤ºï¼‰P16
- ollama + stablelm-zephyr è©¦ã™ã€‚ M1ã§ã‚‚ã¯ã‚„ã„ã€‚
	- https://ollama.ai/library/stablelm-zephyr
- Ollama : ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®¹æ˜“ã«llamaã‚’åˆ©ç”¨å¯èƒ½ã«ã‚‹ã™ã‚‹AIãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
	- https://note.com/astropomeai/n/nbcdfd3b38490?sub_rt=share_b
	- https://github.com/jmorganca/ollama
	- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’é€šã˜ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¨ã‚„ã‚Šå–ã‚Šå¯èƒ½ãªAIãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
	- Llamaã‚„Code Llamaãªã©ã€ã•ã¾ã–ã¾ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆ
	- ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚„ã‚µã‚¤ã‚ºãŒç•°ãªã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ãŸAIãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œã‚’æŸ”è»Ÿã«å¯¾å¿œ
	- DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨å¯èƒ½ã§ã€Nvidia GPUã®GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆCPUä¸Šã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
	- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«ä¾å­˜ã—ã€ä¾‹ãˆã°Llama 2ã®7Bãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯æœ€ä½15GBã®RAMã¨4ã¤ã®CPUã‚³ã‚¢ãŒå¿…è¦
	- MacOSã¨Linuxç”¨ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã€Windowsç‰ˆãŒé–‹ç™ºä¸­
-  Ollama Llama Pack Example
	- https://docs.llamaindex.ai/en/latest/examples/llama_hub/llama_pack_ollama.html#
	- llamaindexã‚ˆã‚Šã€ã•ã£ããOllamaå¯¾å¿œã®RAGã®ä¾‹
	- https://llamahub.ai/l/llama_packs-ollama_query_engine
- ollama web-ui is amazing
	- https://github.com/ollama-webui/ollama-webui
- ClimateXã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹
	- https://huggingface.co/datasets/rlacombe/ClimateX
- Mistralã‚ˆã‚Šã€æ–°ã—ã„ mixtral-8x7b-32kseqlenã‚’ç™ºè¡¨
	- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
	- ã€Œæˆ‘ã€…ã¯Mistral MoE (7Bx32experts) ã‚’ 2 ã‹æœˆé–“ä½¿ç”¨ã—ã¦ãŠã‚Šã€ãã‚Œã¯24GBã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ã€
- What is Mixture-of-Experts (MoE)?
	- mixtral-8x7b-32kseqlenã®è£ã«ã‚ã‚‹moeæŠ€è¡“ã¨ã¯
	- https://x.com/sophiamyang/status/1733505991600148892?s=20
	- MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block.
- ãŸã£ãŸ87Gã®weightã§AGIãŒæ¥ã‚‹ã‹ã‚‰ã€AIè¦åˆ¶å¿…è¦ã ã­ã¨ã„ã†
	- https://x.com/abacaj/status/1733561182504587652?s=20
	- mixtral-8x7b-32kseqlenã®ã“ã¨ã‚‰ã—ã„
- MoEã®Mixtral-7bx8ã®GPTQãã¨ã‚‹ï¼
	- https://huggingface.co/TheBloke/mixtral-7B-8expert-GPTQ
- Geminiã®ãŠéŠã³ãƒ‡ãƒ¢ã¯ã€ç´™èŠå±…ã 
	- https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/
- QuIP#: QuIP with Lattice Codebooks
	- https://cornell-relaxml.github.io/quip-sharp/
	- QuIP#ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’2ãƒ“ãƒƒãƒˆé‡å­åŒ–ã—ã€æœ¬æ¥ãªã‚‰ã°140GBã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ãªLlama 2 70Bã‚’24GBã®GPUã§å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹ã¨ã®äº‹ã§ã™
- Bard(/w Gemini Pro)ã¯ã„ã¾ã ã«æ•°ç‹¬ãŒè§£ã‘ãªã„ã€ChatGPTã¯ã¨ã‘ã‚‹ã‘ã©
	- https://x.com/kajikent/status/1733663171578335233?s=20
- OpenAIã€GPT-4ãŒæ€ ã‘è€…ã«ãªã£ã¦ããŸã¨ã„ã†è‹¦æƒ…ã«ã€Œä¿®æ­£ã‚’æ¤œè¨ä¸­ã€ã¨ãƒã‚¹ãƒˆ
	- https://www.itmedia.co.jp/news/articles/2312/10/news059.html
	- ChatGPTã§ã®GPT-4ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã—ã¦ã„ã‚‹ï¼ˆlazierï¼‰ã¨ã„ã†ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã“ã“æ•°ã‚«æœˆå¢—ãˆã¦ã„ã‚‹ã“ã¨ã‚’èªã‚ã€ã€Œä¿®æ­£ã‚’æ¤œè¨ä¸­ã€ã ã¨Xï¼ˆæ—§Twitterï¼‰ã®å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒã‚¹ãƒˆã—ãŸã€‚
- Mistral MoEã®åˆæœŸè©•ä¾¡
	- https://x.com/bindureddy/status/1733523486885449834?s=20
	- ã¾ã‚ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ãªã„ç´ ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚GPT3.5ç›¸å½“ã®æ€§èƒ½ã¨ã„ã†ã®ã¯æœŸå¾…ã§ãã‚‹
	- solid 70B model that is very similar to GPT 3.5, Gemini Pro
	- MMLU on the base models is at 0.717 compared to Gemin Pro's 0.718
	- Expect to see several fine and instruct tunes over the next few weeks. These fine tunes will match GPT-4 quality for several real-world use cases.
-  Google Colab ã§ DiscoLM Mixtral 8x7b alpha ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n3b55c941d864?sub_rt=share_h
	- ã€Œ**Mixtral 8x7b**ã€ã¯ã€ã€ŒMistral AIã€ãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸå²ä¸Šåˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ MoEãƒ¢ãƒ‡ãƒ«ã§ã™
	- ã€Œ**DiscoLM Mixtral 8x7b alpha**ã€ã¯ã€ã€ŒMixtral 8x7bã€ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ä½œæˆã—ãŸå®Ÿé¨“çš„ãªãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’HuggingFaceå½¢å¼ã«å¤‰æ›ã—ã€ã€ŒSynthiaã€ã€ŒMethaMathQAã€ã€ŒCapybaraã€ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ã¾ã™ã€‚
	- ã€Œ**MoE**ã€ (Mixture of Experts) ã¨ã¯ã€LLMã®åŠ¹ç‡ã¨ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’ã‚ˆã‚Šå°ã•ãç®¡ç†ã—ã‚„ã™ã„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²ã—ã€ãã‚Œãã‚Œã‚’ç‰¹åŒ–ã—ãŸãƒŸãƒ‹ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯å°‚é–€å®¶ãŒå‡¦ç†ã™ã‚‹ã“ã¨ã§æ©Ÿèƒ½ã—ã¾ã™ã€‚
	- 

## 12/4

å…ˆé€±ã¾ã§ã®OpenAIã®ãŠå®¶é¨’å‹•ã‚‚è½ã¡ç€ãã€ä»Šé€±ã¯é€šå¸¸é‹è»¢ã€‚æ—¥å¸¸èƒ½åŠ›ã‚’è©¦ã™ãƒ†ã‚¹ãƒˆã€GAIAã€ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è‰¯ä¾‹ã«ã‚‚ãªã£ã¦ã„ã‚‹ã—ã€ç¾çŠ¶ã®LLMã®é™ç•Œã‚’å›³ã‚‹ã®ã«ã¡ã‚‡ã†ã©ã‚ˆã„ã€‚A*ã®å¯è¦–åŒ–ã€ã“ã†ã„ã†ã®ã‚’å¾…ã£ã¦ãŸã€‚ç•°ãªã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®ç¹‹ãŒã‚Šã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã‚’ä¿ƒã™ã‚·ã‚¹ãƒ†ãƒ ã€Latent Labã€ã¨ã„ã†ã®ã¯ã€ãƒ•ãƒªãƒ¼ã‚¢ãƒ‰ãƒ¬ã‚¹ã®åŸ·å‹™ç’°å¢ƒã®ç ”ç©¶æ´»å‹•ã®æ´»æ€§åŒ–ã«ãƒ’ãƒ³ãƒˆãŒã‚ã‚‹ã‹ã‚‚ã€‚é¸æŠãƒã‚¤ã‚¢ã‚¹å•é¡ŒãŒãªãœã‹ç€ç›®ã•ã‚Œã‚‹ã€‚æ¸…æ°´ã•ã‚“ã€ã¤ã„ã«ã€A100 80GBx8ã®ãƒã‚·ãƒ³ãŒå®Œæˆã€æ—¥æœ¬èªã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ãã‚ãˆã¦ãã‚Œã¦ã€æ—¥æœ¬ç™ºã®ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹LLMé–‹ç™ºã«å¤§ã„ãªã‚‹æœŸå¾…ã€‚IntelÂ® ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒæ‹¡å¼µã€é‡å­åŒ–ã®æ–°ãŸãªã‚‹æ®µéšï¼ŸGoogleã‹ã‚‰debateã‚’åŸºã«ã—ãŸå®‰å…¨ãªLLMåˆ©ç”¨ã«ã¤ã„ã¦ã®ç†è«–è«–æ–‡å…¬é–‹ã€‚ã‚«ãƒ¼ãƒãƒãƒ³æ•™æˆã¨ãƒ«ã‚«ãƒ³å…ˆç”Ÿã®å¯¾è©±ã‚‚å¿…è´ã€system1ã¨system2ã¨æ·±å±¤å­¦ç¿’ã®é–¢ä¿‚ã¯ã€ã‚ã‚‹ã‚ˆãªã€‚BERTopicã‚„ã€AlphaFoldã€googleã®ç¿»è¨³ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚‚ç€å®Ÿã«æ”¹è‰¯ãŒé€²ã‚“ã§å®Ÿç”¨ãƒ•ã‚§ãƒ¼ã‚ºã«ã¾ãŸä¸€æ­©é€²ã‚“ã ã€‚Google Colabã«ã¤ã„ã«transformerãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€ã¤ã¾ã‚Šãã†ã„ã†ã“ã¨ã ã€‚å¼·åŒ–å­¦ç¿’ç³»ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªå¯¾è±¡ã«ã¯ä¸é©åˆ‡ãªã®ã‹ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€†æ¨è«–ã—ãŸã‚Šã€ã‚µãƒ­ã‚²ãƒ¼ãƒˆï¼ˆä»£ç†ï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹é€†å•é¡Œã®ç ”ç©¶ã‚‚æ³¨ç›®ã€‚llamapackã£ã¦ã®ãŒã§ãã¦ã„ã‚‹ã®ã‹ã€è©¦ã—ã¦ã¿ã‚ˆã†ã€‚Agentã‚’ã‚ˆãä½¿ã£ã¦ã‚‹ã‘ã©ã‚‚ã£ã¨ç¨®é¡ãŒã‚ã‚‹ã€èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã£ã¦ã®ã¯ã¡ã‚ƒã‚“ã¨ç†è§£ã—ãŸã„ã€‚ã€Œå’Œæ­Œé›†ã®æ­Œé¢¨ã®è¨€èªçš„å·®ç•°ã®è¨˜è¿°ãƒ¼å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åˆ†æãƒ¼ã€ã¨ã„ã†ã®ã¯ç¶šç·¨ã‚’æœ›ã‚€ã€‚LLMã‚’Pytorchã ã‘ã§ã©ã‚Œã ã‘é«˜é€ŸåŒ–ã§ãã‚‹ã‹ã¨ã‹ã€GPT-fastã¨ã‹ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã¨ã‹ã€ãã†ã„ã†ã®ãŒã‚‚ã£ã¨å‡ºã¦ãã‚‹ã¯ãšã€‚OSSã®LLMã«ã¤ã„ã¦ã®è«–æ–‡ã€ŒChatGPTã®1å‘¨å¹´ã‚’è¨˜å¿µã—ã¦ã€ã‚‚ã„ã„ã­ã€OSSã®LLMãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„å¿œç”¨åˆ†é‡ã«ãŠã„ã¦ã€ã‚¯ãƒ­ãƒ¼ã‚ºãªLLMã«åŒ¹æ•µã™ã‚‹ã€ã‚ã‚‹ã„ã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ãªã€‚ã‚¢ãƒ¡ãƒªã‚«ã®åŒ»å­¦è©¦é¨“ã€ŒUS (4-option)ã€ã§90.2ï¼…ã¨ã„ã†é«˜ã„æ­£è§£ç‡ã‚’ã ã—ãŸGPT-4è©•ä¾¡è«–æ–‡ã€ä¸‹æ‰‹ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ã¨ã„ã†è©±ã‹ã€‚


-  An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
- GAIA: a benchmark for General AI Assistants
	- https://arxiv.org/abs/2311.12983
- Q*ã§ã¯ãªã„ã§ã™ãŒã€A*æ¢ç´¢ã®æ§˜å­ã‚’å¯è¦–åŒ–ã—ãŸ
	- https://x.com/GregKamradt/status/1728480680127148480?s=20
- Kevin Dunnell et al., "Latent Lab: Large Language Models for Knowledge Exploration"
	- https://arxiv.org/abs/2311.13051
	- LLMãƒ™ãƒ¼ã‚¹ã§ã€ç•°ãªã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®ç¹‹ãŒã‚Šã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã‚’ä¿ƒã™ã‚·ã‚¹ãƒ†ãƒ ã€Latent Labã€
	- â‘ å¯¾è©±ã¨è¦–è¦šåŒ–ã‚’é€šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢ 
	- â‘¡ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚’è‡ªå‹•åŒ–
	-  â‘¢ æ–°ã—ã„ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¢ã‚¤ãƒ‡ã‚¢åˆæˆã‚‚å¯èƒ½
-  Google Colab ã§ LCM LoRA ã‚’è©¦ã™ã€€ by npakaã•ã‚“
	- https://note.com/npaka/n/n940ee84ca5b6?sub_rt=share_h
	- ã€ŒLCMã€ (Latent Consistency Model) ã¯ã€å…ƒãƒ¢ãƒ‡ãƒ«ã‚’åˆ¥ãƒ¢ãƒ‡ãƒ«ã«è’¸ç•™ã™ã‚‹ã“ã¨ã§ã€ç”»åƒç”Ÿæˆã«å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ¸›ã‚‰ã™æ‰‹æ³•ã§ã™ã€‚25ï½50ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‹ã£ã¦ã„ãŸå‡¦ç†ã‚’4ï½8ã‚¹ãƒ†ãƒƒãƒ—ã§å¯èƒ½ã«ã—ã¾ã™ã€‚
- Multi-modal Foundation Model for Material Design
	- https://openreview.net/forum?id=EiT2bLsfM9
	- åˆ†å­ã‚’è¡¨ç¾ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã€‚SELFIESã€DFTç‰©æ€§ã€ã‚¹ãƒšã‚¯ãƒˆãƒ«ã«ã¤ã„ã¦ãã‚Œãã‚Œencoder-decoderã‚’å­¦ç¿’ã—ã€å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æ½œåœ¨ç©ºé–“ã‚’å…±é€šã®æ½œåœ¨ç©ºé–“ã«encode, decodeã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚
	-  æ¬ æãŒå¤šãã¦ã‚‚å­¦ç¿’å¯èƒ½ã‹ã¤ã€å¾Œã‹ã‚‰ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’è¿½åŠ ã—ã‚„ã™ã„
- é¸æŠãƒã‚¤ã‚¢ã‚¹ã®å¼ã€tweedle
	- https://x.com/docmilanfar/status/1728680465928958055?s=20
- llamaindexã‚ˆã‚Šã€RAGè©•ä¾¡ãƒ„ãƒ¼ãƒ«ragsã®v2ãƒªãƒªãƒ¼ã‚¹
	- https://github.com/run-llama/rags
-  Simplifying Transformer Blocks 
	- https://arxiv.org/abs/2311.01906
	- many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:
- llamaindexã‹ã‚‰ã€RAGã®æ–°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€fuzzy citationã‚’ç™ºè¡¨
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/fuzzy_citation/fuzzy_citation_example.ipynb
	- https://llamahub.ai/l/llama_packs-fuzzy_citation
	- éƒ¨åˆ†çš„ãªæ¤œç´¢çµæœã‹ã‚‰ï¼‘ã¤ã®å›ç­”ã‚’åˆæˆï¼Ÿï¼Ÿ
- ï¼²ï¼¡ï¼§ 101 for enterpirze
	- https://gradient.ai/blog/rag-101-for-enterprise
	- çµµãŒç´ æ•µ
-  AIã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã€Œç¶™ä¹‹åŠ©ã€çˆ†èª•!ã¨ã‚Šã‚ãˆãšRAID0ã§12TBã®ãƒ‡ã‚£ã‚¹ã‚¯ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
	- https://note.com/shi3zblog/n/n77e8ad3ed779?sub_rt=share_pb
	- ã¤ã„ã«A100 80GBx8ã®ãƒã‚·ãƒ³ãŒç¨¼åƒã—ãŸã€‚ã“ã“ã¾ã§é•·ã‹ã£ãŸã€‚
	- ã“ã“ã¾ã§æƒã£ãŸã‚‰æ—¥æœ¬æœ€å¤§è¦æ¨¡ã®LLMã‚’å€‹äººã§ä½œã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚
-  A population-level digital histologic biomarker for enhanced prognosis of invasive breast cancer
	- https://www.nature.com/articles/s41591-023-02643-7
	- An important AI report for breast cancer leading to the potential of sparing chemotherapy for many. 
	- The 1st comprehensive analysis of both cancerous and non-cancerous tissue in hundreds of thousands of patient tissues-
- BERTopicã®æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³
	- https://github.com/MaartenGr/BERTopic
	- Merge pre-trained models, apply zero-shot topic modeling, seed domain-specific words, and much more in this HUGE update!
- IntelÂ® Extension for Transformers
	- https://github.com/intel/intel-extension-for-transformers
	- An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere
	- Intel Extension for Transformers supports INT4 model quantized by GPTQ on Intel platforms (Xeon & PC) !
	- https://github.com/intel/intel-extension-for-transformers/tree/1.2.1#int4-inference
-  ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã¨ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã®é–¢ä¿‚
	- https://qiita.com/kaityo256/items/aa5b24904577de40016e
	- é–¢æ•°ï¿½(ï¿½)ã«ãŸã„ã—ã¦ã€ï¿½<0ãªã‚‰ã‚¼ãƒ­ã«ã€ï¿½â‰¥0ãªã‚‰eâˆ’ï¿½ï¿½ã‚’ã‹ã‘ã¦ã€ã€Œã‚ˆã‚ŠåæŸã—ã‚„ã™ãã€ã—ãŸä¸Šã§ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã—ãŸã‚‚ã®ãŒãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã§ã‚ã‚‹ã€‚ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ãŒã€è»¸ã®ä¸­é€”åŠç«¯ãªã¨ã“ã‚ã‚’ã€Œç¸¦ã«ã€ç©åˆ†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ç†ç”±ã‚‚ã€ãƒ•ãƒ¼ãƒªã‚¨é€†å¤‰æ›ã¨ï¿½ã‹ã‚‰ï¿½ã¸ã®å¤‰æ•°å¤‰æ›ã‹ã‚‰ç†è§£ã§ãã‚‹ã§ã‚ã‚ã†ã€‚
	- é–¢æ•°ï¿½(ï¿½)ã«ãŸã„ã—ã¦ã€ï¿½<0ãªã‚‰ã‚¼ãƒ­ã«ã€ï¿½â‰¥0ãªã‚‰eâˆ’ï¿½ï¿½ã‚’ã‹ã‘ã¦ã€ã€Œã‚ˆã‚ŠåæŸã—ã‚„ã™ãã€ã—ãŸä¸Šã§ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã—ãŸã‚‚ã®ãŒãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã§ã‚ã‚‹ã€‚ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ãŒã€è»¸ã®ä¸­é€”åŠç«¯ãªã¨ã“ã‚ã‚’ã€Œç¸¦ã«ã€ç©åˆ†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ç†ç”±ã‚‚ã€ãƒ•ãƒ¼ãƒªã‚¨é€†å¤‰æ›ã¨ï¿½ã‹ã‚‰ï¿½ã¸ã®å¤‰æ•°å¤‰æ›ã‹ã‚‰ç†è§£ã§ãã‚‹ã§ã‚ã‚ã†ã€‚
- Google Colabã€Huggingfacesã®å”åŠ›ã§ã€transformerã‚’æœ€åˆã‹ã‚‰ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://x.com/GoogleColab/status/1729217098977845590?s=20
- A Llama-2-based model finetuned for function calling:
	- https://huggingface.co/Trelis/Llama-2-7b-chat-hf-function-calling-v2
- æ—¥æœ¬èªWikipediaã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ10ä¸‡å€‹ã‚’ä½œã‚Šã¾ã—ãŸ	
	- https://note.com/shi3zblog/n/na10eed9270f8?sub_rt=share_pb
	- GPT-3.5-Turboã‚’ä½¿ã£ã¦ã€ç´„ä¸€ãƒ¶æœˆã‹ã‘ã¦æ—¥æœ¬èªã®Wikipediaã®é …ç›®ã‚’ã‚‚ã¨ã«å…ˆç”Ÿã¨ç”Ÿå¾’ãŒä¼šè©±ã™ã‚‹ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸ
	- GPT-4ã§ã‚‚ã‚„ã£ã¦ã¿ã‚ˆã†ã‹ãªã¨æ€ã£ã¦ã„ã¾ã™ãŒã€GPT-3.5ã§ã‚‚ä¸€ãƒ¶æœˆã§ã‹ãªã‚Šã®å‡ºè²»ãŒã‚ã‚Šã€GPT-4ã§åŒã˜åˆ†é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã¨ãªã‚‹ã¨æ•°åä¸‡å††ã‹ã‚‰æ•°ç™¾ä¸‡å††ã‹ã‹ã‚Šãã†ã§ã™
- llamaindexã‹ã‚‰RAGã«æœ‰åŠ¹ãªllamapackã‚’ï¼—ç¨®é¡å…¬é–‹
	- https://x.com/llama_index/status/1729303619760259463?s=20
- Compositional Generative Inverse Design
	- https://openreview.net/forum?id=5ueXRkKMMg&referrer=%5Bthe%20profile%20of%20Yilun%20Du%5D(%2Fprofile%3Fid%3D~Yilun_Du1
	- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§è¿‘ä¼¼ã—ãŸä»£ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¨ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸé€†å•é¡Œè§£æ³•ã¯ã€ã—ã°ã—ã°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒå¤–ã«ã„ã£ãŸã‚Šå±€æ‰€è§£ã«é™¥ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ãã‚Œã‚’é˜²ããŸã‚ã«ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§è§£ã‚’èª˜å°ã—ã€ä¸é©åˆ‡ãªè§£ã‚’é˜²ãCinDMã‚’ææ¡ˆ
- mlc-llm on WSLã§ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ã‚’è¡Œã†
	- ã€ŒWebGPUã‚’ç”¨ã„ãŸãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ–ãƒ©ã‚¦ã‚¶æ¨è«–ã€
	- https://zenn.dev/saldra/articles/356f470e730d1c
- ï¼®ï¼´ï¼´ã‚³ãƒ ã®ï¼¡ï¼©å­¦ç¿’æ•™æ
	- https://gochikika.ntt.com/index.html
	- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‹ã‚‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„è©•ä¾¡ã¾ã§Pythonã‚³ãƒ¼ãƒ‰ã¨åˆã‚ã›ã¦ä¸€é€šã‚Šå­¦ã¹ã‚‹
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®ï¼¬ï¼¬ï¼­ã§ã‚‚å‡ºåŠ›ã®æˆå‹ãŒå¤§äº‹
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb
- John X. Morris et al., "Language Model Inversion"
	- https://arxiv.org/abs/2311.13647
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯æ¬¡ã®å˜èªã®ç¢ºç‡ã‚’å‡ºã™ãŒã€ãã®ã€Œç¢ºç‡ã€ã‚’åˆ©ç”¨ã—ã¦å…ƒã®æ–‡ç« ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ä½•ã¨ã‹ã—ã¦è¦‹ã¤ã‘å‡ºã™æ‰‹æ³•ã‚’é–‹ç™ºã€‚
- OpenAIã®cookbookã«llamaindexã‚’ã¤ã‹ãŸRAGãŒæ²è¼‰
	- https://blog.llamaindex.ai/openai-cookbook-evaluating-rag-systems-fe393c61fb93
- Minimizing Factual Inconsistency and Hallucination in Large Language Models
	- https://arxiv.org/abs/2311.13878
	- LLMã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘åˆ¶ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€å¤šæ®µéšã§æƒ…å ±ã‚’å–å¾—ã•ã›ã‚‹ã“ã¨ã§ã€ä¿¡é ¼æ€§ã®é«˜ã„å¿œç­”ã‚’å–å¾—å¯èƒ½ã§ã™ã€‚
- Relational Deep Learning
	- https://drive.google.com/file/d/1Uk1y6c8z265G0wiRPpGT1cd5lts5lnKq/view
	- Relational Deep Learning is brings the power of Graph Representation Learning to a Relational Database.
- NeurIPA2023ã®è«–æ–‡æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
	- https://www.ai-driven-life.com/neurips-papers
- å¼·åŒ–å­¦ç¿’ã¯ãƒ™ãƒ«ãƒãƒ³æœ€é©æ€§åŸç†ã‹ã‚‰æ¥ã‚‹å‹•çš„è¨ˆç”»æ³•ã«æ”¯ãˆã‚‰ã‚Œã¦ã¾ã™ã€‚ã—ã‹ã—ã€æƒ…å ±ãŒrandomSamplingã•ã‚Œã‚‹ä¸­ã§å®Ÿã¯å„æ™‚åˆ»éš£åˆã†ãƒ‡ãƒ¼ã‚¿ã®åˆ—ãŒã»ã¨ã‚“ã©æƒ…å ±ï¼ˆå ±é…¬ï¼‰ã‚’æŒãŸãªã„ã¨ãªã‚‹ã¨ã€é–“ã«æ¨å®šå™¨ãŒæŒŸã¾ã£ã¦ã‚‹ã®ã‚‚ã‚ã£ã¦ã‚¹ãƒ‘ãƒ¼ã‚¹ã©ã“ã‚ã‹æœ€å¾Œã«ã—ã‹å ±é…¬ãŒå¾—ã‚‰ã‚Œãªã„å•é¡Œã¸ã®å¦¥å½“æ€§ã¯æ€ªã—ã„ã‹ã‚‚ã§ã™ã­ã€‚
	- https://x.com/ML_deep/status/1729249503683969037?s=20
- DeepMind has formalized a theoretical result related to AI safety in Lean. 
	- https://github.com/google-deepmind/debate
	- "Monadic syntax is excellent for expressing stochastic algorithms, and working over finitely supported distributions avoids the need for integrability side conditions during proofs."
	- But Iâ€™m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think â€œnot killing lots of peopleâ€ is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and thatâ€™s where this type of method might shine.
	- https://x.com/davidad/status/1729461156618637502?s=20
- Azure OpenAI Serviceã®æ—¥æœ¬èªè¨˜äº‹ã¾ã¨ã‚
	- https://zenn.dev/microsoft/articles/azure-openai-japanese-blogs
- ã‚«ãƒ¼ãƒãƒãƒ³æ•™æˆã¨ãƒ«ã‚«ãƒ³å…ˆç”Ÿã®å¯¾è©±
	- https://www.youtube.com/watch?v=oy9FhisFTmI
	- Video of Daniel Kahneman and Yann LeCun discussing Dual Process Theory (i.e., System 1 and 2) in relation to Deep Learning.
-  ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search
	- https://arxiv.org/abs/2310.13227
	- uses algorithms like A* to improve LLM answers, improving sota on both planning and reasoning tasks
- Qualcomm Snapdragon 8gen 3 already supported 10b language model running locally on your smartphone.
	- https://x.com/Francis_YAO_/status/1727861621110779941?s=20
	- LLM is the new smartphone OS!
- Domingoså…ˆç”ŸãŒãªã‚“ã‹è¨€ã£ã¦ã„ã‚‹
	- https://x.com/pmddomingos/status/1729303707387658284?s=20
	- Why AI isn't going to taking over (from "The Master Algorithm").
- MistralChameli_7B_v01
	- https://huggingface.co/TokenBender/MistralChameli_7B_v01
	- First version of DPO-ed roleplay/smart version of Mistral. Now to conduct some experiments with reward model and see if this is any good.
- ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³ãƒ¢ãƒ‡ãƒ«ã¸ã®çµŒé¨“ãƒ™ã‚¤ã‚ºä¿®æ­£
	- https://www.jstage.jst.go.jp/article/keidaironshu/68/4/68_161/_article/-char/ja/
	- Robbins (1956) ãŒ Tweedie (1947) ã«è¨€åŠã—ã¦ã‚‹ã“ã¨ã«åŸºã¥ãï¼ŒEfron ãŒ Tweedie's formula ã¨åä»˜ã‘ã¦åºƒã¾ã£ã¦ã„ã‚‹ãŒï¼ŒKoenker & Gu (2016) ã§ã¯ Dyson (1926) ã§æ—¢ã«å¾—ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚
-  A glimpse of the next generation of AlphaFold
	- https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/
	- AlphaFoldã¯æœ€è¿‘å¤§ããªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒã‚ã‚Šã€ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ã‚¿ãƒ³ãƒ‘ã‚¯ã ã‘ã§ãªãPDBã«ã‚ã‚‹ã»ã¼ã™ã¹ã¦ã®åˆ†å­ã«ã¤ã„ã¦äºˆæ¸¬å¯èƒ½ã§ã™ã€‚å‰µè–¬ã‚„æ–°å‹CRISPRæ¢ç´¢ã«ã‚‚(ä¸€å®šç¨‹åº¦ã¯)ä½¿ãˆã¾ã™ã€‚
- EMNLP2023 ã®æ¡æŠè«–æ–‡ãƒªã‚¹ãƒˆãŒè¦‹ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ãŸï¼æ¥é€±ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã§é–‹å‚¬ã•ã‚Œã‚‹è‡ªç„¶è¨€èªå‡¦ç†ã®å›½éš›ä¼šè­°ã§ã™ï¼ã‚¿ã‚¤ãƒˆãƒ«ã«"Language Model"ã¯ã„ã£ã¦ã‚‹è«–æ–‡ãŒ219æœ¬ã£ã¦ï¼Œã©ã‚“ã ã‘è¨€èªãƒ¢ãƒ‡ãƒ«å¥½ããªã‚“ã ã‚ˆ
	- https://2023.emnlp.org/program/accepted_main_conference/
-  OpenAI ã¨ LangChain ã®èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ by npakaã•ã‚“
	- https://note.com/npaka/n/n650532ce289a?sub_rt=share_h
	- ã€Œ**èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã€(cognitive architecture) ã¨ã¯ã€LLMã©ã®ã‚ˆã†ã«æƒ…å ±ã‚’å‡¦ç†ã—ã€å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®æ çµ„ã¿ã§ã™ã€‚ã€ŒFlo Crivelloã€ï¼ˆè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®Lindyã®å‰µè¨­è€…ï¼‰ãŒä½¿ç”¨ã—ãŸã“ã®ç”¨èªã‚’åˆã‚ã¦èãã€ç´ æ™´ã‚‰ã—ã„ç”¨èªã ã¨æ€ã„ã¾ã—ãŸã€‚
	- ã€ŒLangChainã€ã§ã¯ã€ã€ŒLLMã€ãŒçœŸã«å¤‰é©çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ã«é›»åŠ›ã‚’ä¾›çµ¦ã™ã‚‹ä¸–ç•Œã‚’ä¿¡ã˜ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ãã“ã«ãŸã©ã‚Šç€ããƒ«ãƒ¼ãƒˆã¯ã€**ä¼æ¥­ãŒã€ŒèªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚’åˆ¶å¾¡ã§ãã‚‹ãƒ«ãƒ¼ãƒˆ**ã§ã‚ã‚‹ã¨ä¿¡ã˜ã¦ã„ã¾ã™ã€‚
	- **(1) Code**  LLMã‚’åˆ©ç”¨ã—ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚  
	- **(2) LLM Call** ã‚¢ãƒ—ãƒªã®å‡ºåŠ›ã®ã¿ã‚’æ±ºå®šã™ã‚‹å˜ä¸€ã®LLMã‚³ãƒ¼ãƒ«ã€‚ 
	- **(3) Chain**  ã‚¢ãƒ—ãƒªã®å‡ºåŠ›ã®ã¿ã‚’æ±ºå®šã™ã‚‹è¤‡æ•°ã®LLMã‚³ãƒ¼ãƒ«ã€‚  
	- **(4) Router**  LLMã‚’ãƒ«ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã€ä½¿ç”¨ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ (Toolã€Retrievalã€Prompt) ã‚’é¸æŠã€‚ 
	- **(5) State Machine**  LLMã‚’ä½¿ç”¨ã—ã¦ã‚ã‚‹ç¨®ã®ãƒ«ãƒ¼ãƒ—ã§ã‚¹ãƒ†ãƒƒãƒ—é–“ã‚’ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãŒã€ã‚³ãƒ¼ãƒ‰ãŒè¨±å¯ã•ã‚ŒãŸé·ç§»å…ˆã«ã®ã¿é·ç§»  
	- **(6) Agent**  åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ†ãƒƒãƒ—ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ±ºå®šã‚‚LLMãŒè¡Œã†ã€‚
- Textã‹ã‚‰SQLã‚’ç”Ÿæˆã™ã‚‹Querypls
	- https://github.com/samadpls/Querypls/
- ã‚ã‚Œã‚‰ãŒã€ @jerryjliu0ãŒdeeplearningaiã‚³ãƒ¼ã‚¹ã«ç™»å ´
	- https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/
	- We also have LlamaPacks for every technique mentioned in this course to help you jumpstart your advanced LLM app:
- Deconstructing RAG
	- https://blog.langchain.dev/deconstructing-rag/
	- Given the importance of RAG and the fast pace of development, we've grouped popular RAG concepts into a few categories and created guides for each one.
- Running Starling-7B LLM model on local CPU with @Ollama_ai and getting great results for invoice data extraction, even better than Zephyr, Mistral or Llama2.
	- https://github.com/katanaml/llm-ollama-invoice-cpu
- å††åŸå¡”ã‚’è¿‘ä¼¼ã™ã‚‹ï¼Ÿ
	- https://colab.research.google.com/drive/1oXxBIYJvvUYsVZP6WYAUCb3QK09zTJtO?usp=sharing
	- å††åŸå¡”ã•ã‚“ã®æ–‡ç« ã§å­¦ã¶ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- ã€Œé•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’LLM(GPT, Claude)ã«é£Ÿã‚ã›ãŸéš›ã«ã€ã¡ã‚ƒã‚“ã¨Retrivalã•ã‚Œã‚‹ã‹ï¼Ÿã€ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹Githubã€‚
	- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
	-  ç·ã˜ã¦Calude-2ã«æ¯”ã¹ã¦GPT-4 Turboã®ã»ã†ãŒæ­£ç¢ºã«å¼•ç”¨ã—ã¦ã„ã‚‹ã‚ˆã†ã§é¢ç™½ã„ã€‚
- Qwen/Qwen-7B-Chat-Int4ã‚’Google Colobã§å‹•ã‹ã™
	- https://ayousanz.hatenadiary.jp/entry/2023/11/30/182017
	- ãªã‚“ã‹æ—¥æœ¬ã®æ–‡åŒ–ã¯ã¡ã‚ƒã‚“ã¨å­¦ã‚“ã§ã„ãªã„ã¿ãŸã„ã§ã™ã­
-  Accelerating Generative AI with PyTorch II: GPT, Fast
	- https://pytorch.org/blog/accelerating-generative-ai-2/?utm_content=273712248
	- GPT-fastã¨ã„ã†ã®ãŒã™ã”ã‚‰ã„ã—ã„ã€ï¼“å€ï¼Ÿ
- LiLM å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« TinyLlama 1.1B ã®æ—¥æœ¬èªè¿½åŠ äº‹å‰å­¦ç¿’(incremental pretrain) ã‚’è©¦ã—ãŸãƒ¡ãƒ¢
	- https://zenn.dev/syoyo/articles/52f1d0d62fcad5
	- ç”Ÿæˆã•ã‚Œã‚‹æ—¥æœ¬èªã¯ã¾ã‚ã¾ã‚ã§ã‚ã‚‹ãŒ, æ§‹æ–‡ã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãŠã‹ã—ã„...
	- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã—ã¦ã‚‚é–“é•ãˆãŸã‚Š...
	- ã¾ã‚ã§ã‚‚ 1B è¦æ¨¡ãªã‚‰å¦¥å½“ãªã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
- ä»Šå·ã®ã€æ—¥æœ¬èªã®ç ”ç©¶ã€ã§ã€Œå’Œæ­Œé›†ã®æ­Œé¢¨ã®è¨€èªçš„å·®ç•°ã®è¨˜è¿°ãƒ¼å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åˆ†æãƒ¼ã€ã¨é¡Œã—ã¦ã€OpenAIã®text-embeddingã‚’ä½¿ã£ã¦ã€ã€ä¸‡è‘‰é›†ã€ã¨ã€å¤ä»Šé›†ã€ã®æ„å‘³æ§‹é€ ã®å·®ã‚’è§£æã—ã¦ã¿ã¾ã—ãŸã€‚
	- https://www.musashinoshoin.co.jp/shoseki/view/2976/
- Energy and entropy: Path from game theory to statistical mechanics
	- https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.043055
	- ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä½ãã™ã‚‹ã®ãŒç›®æ¨™ã®ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã¨ï¼Œã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’ä¸Šã’ã‚‹ã®ãŒç›®æ¨™ã®ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã®äº¤æ¸‰ã‚²ãƒ¼ãƒ ã«ãŠã‘ã‚‹æœ€é©ãªæˆ¦ç•¥ã‚’é€šã—ã¦ç†±å¹³è¡¡åŒ–ã‚’è­°è«–ã™ã‚‹ã‚‰ã—ã„
- gpt-fast
	- https://github.com/pytorch-labs/gpt-fast
	- LLMã‚’Pytorchã ã‘ã§ã©ã‚Œã ã‘é«˜é€ŸåŒ–ã§ãã‚‹ã‹ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ãŸãƒªãƒã‚¸ãƒˆãƒª Llama-7BãŒ10å€é€Ÿããªã£ã¦ã„ã‚‹ 
	- Pytorchã§ä½¿ãˆã‚‹é«˜é€ŸåŒ–æŠ€è¡“ã‚’ã„ã‚ã„ã‚ç››ã‚Šè¾¼ã‚“ã§ã‚‹ã½ã£ãã¦ã€ä¸­èº«è¦‹ã‚‹ã®ã‚‚å‹‰å¼·ã«ãªã‚Šãã†
- æ—¥æœ¬èªLLMã§LLaVAã®å­¦ç¿’ã‚’è¡Œã£ã¦ã¿ãŸ
	- https://qiita.com/toshi_456/items/248005a842725f9406e3
- googleã‹ã‚‰æ–°ã—ã„ç¿»è¨³ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç™ºè¡¨
	- Unsupervised speech-to-speech translation from monolingual data
	- https://blog.research.google/2023/12/unsupervised-speech-to-speech.html
-  æ¥­ç•Œåˆ¥ç”ŸæˆAIæ´»ç”¨ã®ã™ã‚ã‚
	- https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/about-deloitte-japan/ai-dossier-2023.html?id=jp:2pm:3tw:4daii-genaidossier:5:6abt:20231201::
	- ãƒ‡ãƒ­ã‚¤ãƒˆãƒˆãƒ¼ãƒãƒ„
-  Microsoft Copilot is now generally available
	- https://blogs.bing.com/search/december-2023/Microsoft-Copilot-is-now-generally-available?ocid=aid_soc_usoc_edu_cons_bing_eng_tw_12.1
- Cè¨€èªã§WASMã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã‚’å®Ÿè£…ã—ãŸè©±
	- https://zenn.dev/ri5255/articles/845ef3dab5ab47
	- ã“ã®è‡ªä½œWASMãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ç›®çš„ã¯ã€ã§ãã‚‹ã ã‘ä»•æ§˜ã«å¾“ã£ãŸå®Ÿè£…ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ä»•æ§˜ã®ç†è§£ã‚’åŠ©ã‘ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚æ—©ã•ã‚„åŠ¹ç‡æ€§ã‚ˆã‚Šã‚‚åˆ†ã‹ã‚Šã‚„ã™ã•ã‚’å„ªå…ˆã—ã¦ã„ã‚‹ãŸã‚ã€å®Ÿç”¨ã«ã¯å‘ã‹ãªã„ã€‚ä»•æ§˜æ›¸ã‚’èª­ã‚“ã§ã€å®Ÿè£…ã«å›°ã£ãŸéš›ã«å‚ç…§ã—ã¦ã»ã—ã„ã€‚
-  ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«æ•°ç†ãƒ¢ãƒ‡ãƒ«ã§ç«‹ã¡å‘ã‹ã† / Japan.R 2023
	- https://speakerdeck.com/dropout009/japan-dot-r-2023
- Harsha Nori et al., "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
	- https://arxiv.org/abs/2311.16452
	- ã“ã‚Œã¾ã§GPT-4ãªã©ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¯ã€åŒ»å­¦ãªã©ã®å°‚é–€åˆ†é‡ã§ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã«ã¯æ•µã‚ãªã„ã¨è€ƒãˆã‚‰ã‚Œã¦ãã¾ã—ãŸã€‚ ã—ã‹ã—ã€ã€Œå®Ÿéš›ã¯ã©ã†ãªã®ã‹ï¼Ÿã€ã¨è€ƒãˆãŸç ”ç©¶è€…ã‚‰ã¯ã€ç‰¹åˆ¥ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã®GPT-4ãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å·¥å¤«ã®ã¿ã§ã©ã“ã¾ã§æ€§èƒ½ã‚’ç¤ºã™ã®ã‹ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚
	- â‘  ã‚¢ãƒ¡ãƒªã‚«ã®åŒ»å­¦è©¦é¨“ã€ŒUS (4-option)ã€ã§90.2ï¼…ã¨ã„ã†é«˜ã„æ­£è§£ç‡ã‚’å‡ºã—ãŸ
	-  â‘¡ ç†ç”±ä»˜ã‘ãŒå¿…è¦ãªã‚¿ã‚¤ãƒ—ã®å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPubMedQAã§82.0ï¼…ã®æ­£è§£ç‡ã‚’é”æˆ
-  æ—¥å¸¸èƒ½åŠ›ã‚’è©¦ã™ãƒ†ã‚¹ãƒˆã€GAIAã€æ­£ç­”ç‡ã€äººé–“92%ã«å¯¾ã—ã¦GPT-4ã¯15%ã€€ä¸€èˆ¬çš„ãªãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹AIé–‹ç™ºã®æŒ‡é‡ã«
	- https://aiboom.net/archives/59440
- Langchain102
	- https://www.youtube.com/watch?v=haad3i9VROs
	- Mistral 7b User Showcase + LangServe & LangSmith
- METAã®AIç ”ç©¶è€…ãŒä½•ã‚‰ã‹ã®å¤§ããªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ãŒã‚ã£ãŸã¨ç¤ºå”†ã€‚ è¿‘æ—¥ä¸­ã«å…±æœ‰äºˆå®šã¨ã®ã“ã¨
	- https://x.com/ArmenAgha/status/1731076069170835720?s=20
-  ã€ŒChatGPTã®1å‘¨å¹´ã‚’è¨˜å¿µã—ã¦ã€ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMãŒChatGPTã«ã©ã“ã¾ã§è¿½ã„ã¤ã„ã¦ã„ã‚‹ã‹ä½“ç³»çš„èª¿æŸ»å ±å‘Š
	- https://aiboom.net/archives/59713
	- https://arxiv.org/abs/2311.16989
	- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã¨ã—ã¦ã¯Llama-2ï¼ˆãŠã‚ˆã³MentalLlamaï¼‰ã€Palmã€Vicunaã€Falconã€Wizardã€Lemurãªã©ã®ãƒ¢ãƒ‡ãƒ«ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã‚Œã‚‰ã®é€²æ­©ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§ã®å„ªã‚ŒãŸæ€§èƒ½ã«ã¤ã„ã¦è©³ã—ãåˆ†æã•ã‚Œã¦ã„ã¾ã™ã€‚èª¿æŸ»çµæœã‹ã‚‰ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„å¿œç”¨åˆ†é‡ã«ãŠã„ã¦ã€ã‚¯ãƒ­ãƒ¼ã‚ºãªLLMã«åŒ¹æ•µã™ã‚‹ã€ã‚ã‚‹ã„ã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—
- MRS2023(materials research society)ã§LLMãŒå¤šã„ 2023 MRS Fall Meeting & Exhibit
	- https://x.com/yoko_materialDX/status/1731267042810962256?s=20
	- MIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå¸¸æ™‚4ã¤ã‚ã‚Šå›ã‚‹ã®ãŒå¤§å¤‰
	- æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¨è‡ªå‹•åˆæˆã®ç™ºè¡¨ãŒå¤§é‡
	- çµæ™¶æ§‹é€ äºˆæ¸¬ã®ç™ºè¡¨ãŒæ€ã£ãŸã‚ˆã‚Šå¤šã‹ã£ãŸ
	- LLMã®ç™ºè¡¨ã¯ææ–™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãŒä¸­å¿ƒ
	- æ—¥æœ¬ä¼æ¥­ã‹ã‚‰ã®MIç™ºè¡¨ãŒå¤šã‹ã£ãŸ 
	- ä¸–ç•Œæƒ…å‹¢ã‚†ãˆï¼Ÿï¼‰ä¸­å›½æœ¬åœŸã®æ–¹ãŒã»ã¼ã„ãªã‹ã£ãŸ

## 11/27

ã‚¢ãƒ«ãƒˆãƒãƒ³æ°è§£ä»»åŠ‡ã¯ã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã®å—ã‘å…¥ã‚Œã‚’è¡¨æ˜ã™ã‚‹ã‚‚ã€OpenAIã®ä¸»è¦ãƒ¡ãƒ³ãƒãŒã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã«è¿½å¾“ã™ã‚‹ã¨è¡¨æ˜ã—ãŸã®ã§ãƒœãƒ¼ãƒ‰ãŒå¾©å¸°ã‚’æ‡‡é¡˜ã€çµå±€OpenAIã®CEOã¨ã—ã¦æˆ»ã‚‹ã“ã¨ã§å¹•å¼•ãã€‚è§£ä»»åŠ‡ã®èƒŒå¾Œã«ã¯ã€OpenAIã§AGIï¼ˆã‚¹ãƒ¼ãƒ‘ãƒ¼AI)ã‚’é”æˆã™ã‚‹è¦‹è¾¼ã¿ãŒç«‹ã£ãŸã€ãã‚ŒãŒQ*ã¨ã„ã†LLMã§ã€å¾“æ¥ã®LLMãŒè‹¦æ‰‹ã ã£ãŸæ•°ã®æ¨è«–ãŒå¯èƒ½ã«ãªã£ãŸã€Q*ã®å–ã‚Šæ‰±ã„ã‚’å·¡ã‚Šè§£ä»»é¨’å‹•ãŒèµ·ããŸã€ã¨ã„ã†ã†ã‚ã•ã§æŒã¡åˆ‡ã‚Šã«ã€‚Q*-learningãŒãã‚Œã§ã¯ï¼Ÿã¿ãŸãªã“ã¨ã«ãªã£ã¦æ§˜ã€…ãªã¨ã“ã‚ã§ç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€‚ãã‚Œä»¥å¤–ã§ã¯ã€intelãŒæº€ã‚’æŒã—ã¦neural-chat-7b-v3-1ã‚’å…¬é–‹ã€Mistral 7Bãƒ™ãƒ¼ã‚¹ãªã‚“ã ã‘ã©ã€æ§˜ã€…ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šç›¸å½“æ€§èƒ½ãŒè‰¯ã„ã¿ãŸã„ã€ã—ã‹ã—Falcon 180Bè¶Šãˆã¨ã„ã†ã“ã¨ã¯ãªã„ã¨æ€ã†ãã€‚AnthropicAIãŒ200kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ãˆã‚‹Claude2.1ã‚’ç™ºè¡¨ã€ãƒ‡ãƒ¢ç‰ˆãŒåˆ©ç”¨å¯èƒ½ã§ã€ã•ã£ããçµæ§‹é•·æ–‡ã®æ—¥æœ¬èªã®PDFã‚’ãã®ã¾ã¾æŠ•å…¥ã§ãã‚‹ã¨ã‹ã€ã‚¨ãƒãƒ³ã‚²ãƒªã‚ªãƒ³ä¸–ç•Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‹•ã‹ã—ã¦ã¿ãŸã¨ã‹è©±é¡Œã«ã€‚ã€Œï¼“Dä¸–ç•Œã®ä¸­ã§èº«ä½“æ€§ã‚’ã‚‚ã£ãŸæ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã®è«–æ–‡ã€ã„ã‚„ ã€Œæœªæ¥ã®äºŒã¤ã®é¡”ã€ï¼ˆãƒ›ãƒ¼ã‚¬ãƒ³ï¼‰ã®AIï¼ˆä»®æƒ³ï¼“Dç©ºé–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§èº«ä½“æ€§ã‚’å­¦ç¿’ã•ã›ã‚‹ï¼‰ã‚’å½·å½¿ã•ã›ã‚‹ä¸–ç•ŒãŒç¾å®Ÿã«ãªã£ãŸã‚ˆã†ãªæ°—ãŒã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹Q&Aã«ãŠã„ã¦ã€SQLæ–‡ã‚’ç”Ÿæˆã•ã‚Œã‚‹æ–¹æ³•ã¨ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†…å®¹ã‚’ã„ã£ãŸã‚“çŸ¥è­˜ã‚°ãƒ©ãƒ•ã«ã—ã¦Q&Aã™ã‚‹æ–¹æ³•ã‚’æ¯”è¼ƒã—ã€å¾Œè€…ã®ã»ã†ãŒé«˜æ€§èƒ½ã¨ã®å ±å‘Šã‚‚ã€‚ã¾ã‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã„ã†ã‹ãã†ã„ã†ã®ã‚’ä¸ãˆãŸã»ã†ãŒã„ã„ã«æ±ºã¾ã£ã¦ã„ã‚‹ã®ã ãŒã€‚RAGã«ãŠã„ã¦ã‚‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒæœ‰åŠ¹ã‚‰ã—ã„ã€ãã®ã‚ãŸã‚Šã«ã¾ã äººã®å·¥å¤«ã®ä½™åœ°ãŒæ®‹ã£ã¦ã„ã‚‹ã€‚Llemmaã¯ã€LLMã§æ•°å­¦ã®å•é¡Œã‚’è§£ãã®ã«ã€å®šç†è¨¼æ˜å™¨ã‚’ä½¿ã†ã“ã¨ã‚’å‰æã«ã—ãŸPythonã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã€LLMã‚’æ´»ç”¨ã—ã¦å•é¡Œã‚’è§£ããƒ¡ã‚¿ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆç›´æ¥è§£ãã®ã§ã¯ãªãã¦ã€è§£ãæ‰‹é †ãƒ»æ–¹æ¡ˆã‚’ç”Ÿæˆã™ã‚‹ï¼‰ã®ï¼‘ã¤ã€‚LLMãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„è¨€èªã€SUQLã€ã‚‚ã„ã„æ„Ÿã˜ã§éæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ãˆã‚‹ã‚‰ã—ã„ãŒã€ä¾‹é¡ŒãŒãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®ä¼šè©±ã¨ã¯ç¬¬ï¼’ä¸–ä»£AIã«ãŠã‘ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ å•é¡Œã½ãã¦ã„ã„ã­ï¼AIãŒäººé–“ãŒæ€ã„ã¤ã‹ãªã„ã‚ˆã†ãªã€Œç•°è³ªãªã€ä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ç§‘å­¦ãŒé€²åŒ–ã™ã‚‹ã€ã‹ã‚‚ã€‚ChatGPTã‚’ã¤ã‹ã£ã¦ã€éƒ¨å±‹ã‚’ç‰‡ä»˜ã‘ã¦ã„ã‚‹äººãŒã„ãŸã€ã“ã‚Œã¯ã™ã”ã„å¿œç”¨ã ï¼OECDã®AIã®å®šç¾©ã‚‚ç”ŸæˆAIã‚„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’é‘‘ã¿ï¼”å¹´ã¶ã‚Šã«æ”¹å®šã€äººã®æŒ‡ç¤ºã«å¾“ã‚ãšã¨ã‚‚ã€å…¥åŠ›ã«å¯¾ã—ã¦è‡ªã‚‰ã®ã¨ã‚‹ã¹ãå‹•ä½œã‚’æ¨æ¸¬ã™ã‚‹ãƒ¡ã‚¿èƒ½åŠ›ã«ã¤ã„ã‚‚æš—ç¤ºã€ã‚‚ã¯ã‚„AIã«å¯¾ã™ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢çš„ãªå“è³ªä¿è¨¼ã¯ä¸å¯èƒ½ãªäº‹æ…‹ã¸ã€‚

-  Banach-Tarski Embeddings and Transformers
	- https://arxiv.org/abs/2311.09387
	- å†å¸°çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç·šå‹ç©ºé–“ã§ã®è¡¨ç¾ï¼ˆãƒãƒŠãƒƒãƒã‚¿ãƒ«ã‚¹ã‚­åŸ‹ã‚è¾¼ã¿ï¼‰ã‚’è€ƒãˆã‚‹ã¨ãã®è¡¨ç¾ä¸Šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆå¾©å·ï¼‰ãŒTransformerã¨ã—ã¦è‡ªç„¶ã«å®Ÿè£…ã§ãã‚‹ã‚‰ã—ã„
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸæ„å‘³åˆ†æã«ã‚ˆã‚‹è¾æ›¸è¨˜è¿°ã¸ã®å¿œç”¨
	- https://speakerdeck.com/yhkondo/da-gui-mo-yan-yu-moderuwoyong-itayi-wei-fen-xi-niyoruci-shu-ji-shu-henoying-yong
	- åŸ‹ã‚è¾¼ã¿ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰ã®è¾æ›¸ä½œæˆã¸ã®å¿œç”¨ã¨ã‹ã€æ•è‰å­ã‚’é¡Œæã«åŸ‹ã‚è¾¼ã¿ã‚’ã¤ã‹ãŸï½”é¡ä¼¼æ¤œç´¢ã—ã¦ã¿ã‚‹ä¾‹ãŒã€è‹±èªã«ã‚ˆã‚‹æ¤œç´¢ã€çµµæ–‡å­—ã«ã‚ˆã‚‹æ¤œç´¢ã€ã‚¯ãƒªã‚¨ãƒ¼ãƒ†ã‚£ãƒ–ãªæ¤œç´¢ãªã©äº‹ä¾‹ãŒã‚ã£ã¦é¢ç™½ã„
- Shicheng Liu et al., "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models"
	- https://arxiv.org/abs/2311.09818
	- LLMãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„è¨€èªã€SUQLã€ãŒé–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚SQLã‚’æ‹¡å¼µã—ã¦ã€Œéæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒªã€ã‚’å‡¦ç†ã™ã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å°å…¥
	- ã€SUQLï¼ˆStructured and Unstructured Query Languageï¼‰ã€
	- â‘  æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’æ‰±ã† 
	- â‘¡ SQLã«ã€éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã‚’è¿½åŠ  
	- â‘¢ ä¼šè©±å‹æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å‡¦ç† 
	- â‘£ ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ãŠã‚ˆã³éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æŠ½å‡ºã™ã‚‹
	- å¾“æ¥ã®ç·šå½¢åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚„å¤šæ®µéšæ¤œç´¢ãŠã‚ˆã³æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æ¯”ã¹ã¦ã€SUQLã¯å›åç²¾åº¦ãŒå¤§å¹…ã«é«˜ã„
	- å®Ÿéš›ã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã«é–¢ã™ã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚¹ã•ã‚ŒãŸè³ªå•ã¨ä¼šè©±ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿç”¨æ€§ãŒç¢ºèªã•ã‚ŒãŸ
-  Meta disbanded its Responsible AI team
	- https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence
	- metaãŒè²¬ä»»ã‚ã‚‹AIã®ãƒãƒ¼ãƒ ã‚’è§£æ•£ã•ã›ãŸ
- çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…¥é–€
	- https://www.no-spare.com/store/products/seminar-20231129
	- æœ¬è¬›åº§ã§ã¯ã€é‡‘èæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¸ã®å¿œç”¨ã‚’é¡Œæã«ã€å‹•çš„ç·šå½¢ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ãƒ»æœ€æ–°ã®ç ”ç©¶ã‚’è§£èª¬ã—ã¾ã™ã€‚
-  Hypotheses devised by AI could find â€˜blind spotsâ€™ in research
	- https://www.nature.com/articles/d41586-023-03596-0
	- AIãŒä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ç›´é¢ã™ã‚‹èª²é¡Œã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã€ç‰©ç†çš„ãªæ³•å‰‡ã®ç†è§£ã€ä»®èª¬ã®ä¸€èˆ¬æ€§ã¨è§£é‡ˆæ€§ãªã©ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
	- AIãŒä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹å¯èƒ½æ€§ã¨ã—ã¦ã€äººé–“ãŒæ€ã„ã¤ã‹ãªã„ã‚ˆã†ãªã€Œç•°è³ªãªã€ä»®èª¬ã‚„ã€å®Ÿé¨“ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã€Œãƒ­ãƒœãƒƒãƒˆç§‘å­¦è€…ã€ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™
-  Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild
	- https://arxiv.org/abs/2311.06237
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’ã—ã°ãå€’ã—ã¦ã€ç•°å¸¸ãªæŒ¯ã‚‹èˆã„ã‚’ã•ã›ã‚ˆã†ã¨ã—ã¦ã„ã‚‹äººé”ï¼ˆé‡è‰¯ã®LLMãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ ï¼‰ã¸ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è«–æ–‡ã€‚æ”»æ’ƒæ–¹æ³•ã‚„ãã‚‚ãã‚‚ä½•ã®ãŸã‚ã«ã‚„ã£ã¦ã„ã‚‹ã®ã‹ï¼Ÿç­‰ã®èª¿æŸ»ã€‚
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã€ã‚²ã‚¹ãƒˆã‚«ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ã€OpanAIã‚’è¨ªå•
	- https://x.com/sama/status/1726345564059832609?s=20
	- first and last time i ever wear one of these
-  ChipNeMo: Domain-Adapted LLMs for Chip Design
	- https://arxiv.org/abs/2311.00176
	- ChipNeMoã¯ãƒãƒƒãƒ—è¨­è¨ˆæ”¯æ´å‘ã‘ã«ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã—ãŸLLMã€‚é–‹ç™ºæ”¯æ´Chatbotã€EDAã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆã€ãƒã‚°è¦ç´„ã¨åˆ†æã‚’è¡Œã†ã€‚æ—¢å­˜LLMã«ã€å°‚ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ãŸå¾Œã€ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œäº‹å‰äº‹å‰å­¦ç¿’ï¼ˆDAPT 230å„„ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€æŒ‡ç¤ºå­¦ç¿’ï¼ˆ1000ä¾‹ï¼‰ã‚’ã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œæ¤œç´¢è£œå¼·ã‚’è¡Œã†
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ãƒŠãƒ‡ãƒ©æ°ã€ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ãŸã¡ãŒãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã«Joinã™ã‚‹ã¨ã€ã€
	- https://x.com/satyanadella/status/1726509045803336122?s=20
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã«ã‚ˆã‚‹ç”ŸæˆAIã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
	- https://github.com/microsoft/generative-ai-for-beginners
	- The free 12 lesson course is available on Github and will teach you everything you need to know to start building Generative AI applications.
-  Learning to Filter Context for Retrieval-Augmented Generation
	- https://arxiv.org/abs/2311.08377
	- RAGã«ãŠã„ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã™ã‚‹
	- èªå½™ãŠã‚ˆã³æƒ…å ±ç†è«–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é€šã˜ã¦æœ‰ç”¨ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‰¹å®šã—ã€ãƒ†ã‚¹ãƒˆä¸­ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒå«ã¾ã‚Œã¾ã™ã€‚
	- FILCO ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã« String Inclusion (STRINC)ã€Lexical Overlapã€Conditional Cross-Mutual Information (CXMI) ãªã©ã®æŠ€è¡“ã‚’ä½¿ç”¨
- æ—¥æœ¬èªå¯¾å¿œ LLM(13B è¦æ¨¡)ã®, è¡Œé–“ã‚’èª­ã‚€ã‚ˆã†ãªã‹ã—ã“ã•ãŒã‚ã‚‹ã‹è©¦ã—ãŸãƒ¡ãƒ¢(ç¾çŠ¶ Qwen 14B ãŒãƒ™ã‚¹ãƒˆ)
	- https://zenn.dev/syoyo/articles/59a5ccbbb5660e
	- 7B ä»¥ä¸‹(10B æœªæº€)ã‚‚è©¦ã—ã¾ã—ãŸãŒ, è¡Œé–“ã‚’èª­ã‚€ã»ã©ã®ã‹ã—ã“ã•ã¯ãªã, 13B è¦æ¨¡ã§é£›èºçš„ã«ã‹ã—ã“ã•ãŒä¸ŠãŒã‚‹æ„Ÿã˜ã ã£ãŸã®ã§, 13 B è¦æ¨¡ã®ã‚’é¸ã‚“ã§ã„ã¾ã™.
	- qwen.cpp(llama.cpp variant)ã§ f16 é‡å­åŒ–ç‰ˆã‚’å‹•ã‹ã—ã¾ã—ãŸ.
	- q4 ã‚ãŸã‚Šã«é‡å­åŒ–ã ã¨ã„ãã‚‰ã‹ã‹ã—ã“ã•è½ã¡ã¾ã—ãŸ(ãã‚Œã§ã‚‚ã»ã‹ã®æ—¥æœ¬èª LLM ã‚ˆã‚Šã‚ˆã„çµæœã‚’ãˆã‚‰ã‚Œã‚‹)  ã¾ãŸ, Qwen7B ã‚‚ã‚ã¾ã‚Šã‹ã—ã“ãã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ.
	- Qwen 14B(Chat) ã¡ã‚ƒã‚“ãŒè¡Œé–“ã‚’èª­ã‚€ã»ã©ã®ã‹ã—ã“ã•ã‚’è¦‹ã›ã¾ã—ãŸ!
- OpenAIãŒNPO+ã§ã‚ã‚‹ã‚ˆã†ãªã“ã¨ãŒã€ä»Šå›ã®ã‚¢ãƒ«ãƒˆãƒãƒ³æ°è§£ä»»ã«ã¤ãªãŒã£ãŸã¨ã®çµµæŸ„
	- https://x.com/GOROman/status/1726701627468546511?s=20
-  Azure OpenAI Service å…¥é–€ by npakaã•ï½
	- https://note.com/npaka/n/n46e6ad252ce1?sub_rt=share_h
	- ã€ŒAzure OpenAI Serviceã€ã§ã€Œgpt-3.5-turboã€ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹é †ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚
-  Orca 2: Teaching Small Language Models How to Reason
	- https://huggingface.co/papers/2311.11045
	- å°ã•ã„ã“ã¨ã¯ã„ã„ã“ã¨ã 
-  Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data
	- https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1
	- llamaindexã®JerryãŒæ”¾ã¤ã€streamlitã‚’ã¤ã‹ã£ãŸã€RAGã‚¢ãƒ—ãƒªç”Ÿæˆãƒ„ãƒ¼ãƒ«RAGs
	- â€œChatGPT over your dataâ€ without needing to code.
- Large-scale pancreatic cancer detection via non-contrast CT and deep learning
	- https://www.nature.com/articles/s41591-023-02640-w
	- ï½¢å˜ç´”CTã®è†µè‡“ãŒã‚“æ¤œå‡ºAIï½£
	- å˜ç´”CTã§ã®è†µè‡“ãŒã‚“æ¤œã¯ä¸å¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã¦ããŸ 
	- ãã®AIã‚’é–‹ç™º 
	- ç¾å®Ÿä¸–ç•Œã®ãƒãƒ«ãƒã‚·ãƒŠãƒªã‚ªæ¤œè¨¼ã®ç—…å¤‰æ¤œå‡ºã§ã€92.9%ã®æ„Ÿåº¦ã¨ 99.9% ã®ç‰¹ç•°åº¦ã‚’é”æˆ 
	- è†µè‡“ãŒã‚“ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã®å¯èƒ½æ€§
-  RAGè©•ä¾¡ãƒ„ãƒ¼ãƒ«ã® "RAGAS" ã‚’ä½¿ã£ã¦ã€RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹
	- https://qiita.com/s3kzk/items/44b8780c656b4f747403
	- ä»Šå›è§¦ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ™‚ã®è¨­å®šä»¥å¤–ã«ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ±ºå®šã€EmbeddingãŠã‚ˆã³å¿œç­”ã®ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹LLMã®é¸å®šã€ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢/æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸å®šãªã©ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦ç´ ã¯æ•°å¤šãå­˜åœ¨ã—ã¾ã™ã€‚
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°OpenAIã«å¾©å¸°ã™ã‚‹ã¨
	- https://x.com/OpenAI/status/1727206187077370115?s=20
-  2é€±é–“ä½¿ã„å€’ã—ã¦ã‚ã‹ã£ãŸï½¢GPT-4-Turboã®è¡æ’ƒï½£ã€‚OpenAIã®ï½¢ãŠå®¶é¨’å‹•ï½£ã§è¦‹é€ƒã—ã¦ã‚‹å ´åˆã˜ã‚ƒãªã„
	- https://www.businessinsider.jp/post-278766
- AnthropicAIã‚ˆã‚ŠClaude2.1ã®ç™ºè¡¨
	- https://x.com/AnthropicAI/status/1727001773888659753?s=20
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¯ãªã‚“ã¨ 200k ã¨ 2 å€ã«æ‹¡å¤§ã€‚ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ä½æ¸›ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®å¯¾å¿œã€ä¾¡æ ¼ã®å¼•ãä¸‹ã’ã€å¤–éƒ¨APIã¨ã®é€£æºæ©Ÿèƒ½(ãƒ™ãƒ¼ã‚¿ç‰ˆ) ãªã©
	- https://claude.ai/ã€€ã§ãŠè©¦ã—å¯èƒ½
- ChatGPTã§éƒ¨å±‹ã®ç‰‡ã¥ã‘ã‚’ã—ã¦ã„ã‚‹äººãŒã„ã„ã‚‹
	- https://x.com/fjtn_c/status/1727216371711586402?s=20
	- ï¼ˆéƒ¨å±‹ã®å†™çœŸé€ã£ã¦ç‰‡ä»˜ã‘ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã—ã¦ã‚‚ã‚‰ã£ã¦ã€ãã‚Œã‚’å®Ÿè¡Œã—ã¦å†™çœŸæ’®ã£ã¦ã¾ãŸé€²æ—ã‚’é€ã‚‹â†’åŒã˜ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ï¼‰
- æ„›æ–°è¦šç¾…ã®å­«ï¼ˆå¤§äº•ç”ºã®çœ¼ç§‘åŒ»ï¼‰ã®é©šæ„•ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰
	- https://x.com/aishinkakura_i/status/1727477535234248712?s=20
	- å­¦ä¼šã§ã‚¢ãƒ¡ãƒªã‚«ã‚’è¨ªã‚ŒãŸéš›ã€ã‚¤ãƒŸã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€Œæ¸…æœã®å­å­«ã‹ã€ã£ã¦å°‹å•ã‚’å—ã‘ã€ã—ã°ã‚‰ãè¶³ã‚’æ­¢ã‚ã‚‰ã‚Œâ€¦
- metaã‹ã‚‰ã€Getting started  with Llama
	- https://ai.meta.com/llama/get-started/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama2&utm_content=image
-  å˜è¡Œæœ¬ãŒå…¥ã‚‹Claude 200kã§åƒ•ã¨ã€Œã‚¨ãƒ´ã‚¡ãƒ³ã‚²ãƒªã‚ªãƒ³ã€
	- https://note.com/shoty/n/n03bff29f683f
	- æ—¥æœ¬èªã ã¨150ãƒšãƒ¼ã‚¸ã„ã‹ãªã„ãã‚‰ã„ãŒèª¿ç†ã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚ã¤ã¾ã‚Š**å˜è¡Œæœ¬ä¸€å†ŠãŒå…¥ã£ã¦ã—ã¾ã†**
	- ã‚¨ãƒãƒ³ã‚²ãƒªã‚ªãƒ³ã®ç‰©èªã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã§ãã‚‹ã‹ã¨ã„ã†æŒ‘æˆ¦ã‚‰ã—ã„
- ã€DSã«KaggleãŒå¿…ãšã—ã‚‚å¿…è¦ã§ã¯ãªã„è©±ã€‘
	- https://x.com/Nurruttan/status/1727495591905858016?s=20
	- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¨è¨€ã£ã¦ã‚‚ã€ ã€Œâ‘ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆå‹ã€ ã€Œâ‘£ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‹ã€ ã®ã‚­ãƒ£ãƒªã‚¢ãƒ—ãƒ©ãƒ³ã§ã¯Kaggleå®Ÿç¸¾ã®é‡è¦æ€§ã¯ä½ã„
	-  ä¸€æ–¹ã§ã€ ã€Œâ‘¡ã‚µãƒ¼ãƒ“ã‚¹ã‚°ãƒ­ãƒ¼ã‚¹å‹ã€ ã€Œâ‘¢è£½å“é–‹ç™ºå‹ã€ ã€Œâ‘¤AIé–‹ç™ºå‹ã€ ã¯é‡è¦åº¦ã¯é«˜ã„ã€‚
- Google Bardã§Youtubeã¨ãƒãƒ£ãƒƒãƒˆã§ãã‚‹ã‚ˆã†ã«
	- https://bard.google.com/chat
-  ã€ŒPaper Interpreterã€ã‚’ä½¿ã£ã¦è«–æ–‡ã‚’èª­ã‚‚ã†ï¼
	- https://note.com/daichi_konno/n/nb1f1ac368a30
	- æ±å¤§ã®ã€ç´ºé‡å¤§åœ°å…ˆç”Ÿä½œæˆ
	- **ã€Œè«–æ–‡ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€å†…å®¹ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã‚Œã‚‹AIã€**
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°é›»æ’ƒè§£ä»»åŠ‡ã®è£ã«ã€OpenAIãŒã€AGIã‚’é–‹ç™ºã™ã‚‹ã‚ã©ãŒã¤ã„ãŸã‹ã‚‰ã¨ã„ã†
	- Q*-learningã¨ã„ã†æ‰‹æ³•ã«ã‚ˆã‚Šã€æ•°å€¤è¨ˆç®—ãªã©LLMãŒè‹¦æ‰‹ã¨ã—ã¦ã„ãŸèª²é¡Œã‚‚è§£ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
	- https://x.com/hbouammar/status/1727683545852768295?s=20
	- A*ã£ã¦ã®ã¯æ¢ç´¢ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã ã‘ã©ã€ãã‚Œã®Q-learningç‰ˆã¨ã„ã†è©±
- Intelè¬¹è£½ã®ã€LLMãŒã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ä¸Šä½ã®æ€§èƒ½ã‚’ã¯ã˜ãå‡ºã™
	- https://x.com/Yampeleg/status/1727679553714217421?s=20
	- https://huggingface.co/Intel/neural-chat-7b-v3-1
	- A 7B model from Intel almost as capable as Falcon 180B:ã“ã‚Œã¯æœ¬å½“ã‹ï¼ï¼ï¼
	- Base model: Mistral 7B. 
	- Fine Tuned on: SlimOrca 
	- DPO: LLaMA-13B vs ChatGPT Gens (Prefer ChatGPT)
- An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
	- ï¼“Dä¸–ç•Œã®ä¸­ã§èº«ä½“æ€§ã‚’ã‚‚ã£ãŸæ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
	- 3Dä¸–ç•Œã«å¯¾ã—ã¦ã€ã„ã‚ã°è¨˜å·æ¥åœ°ã™ã‚‹ã‚ˆã†ãªè¨“ç·´ã‚’ã™ã‚‹ã“ã¨ã§èº«ä½“æ€§(embodiment)ã‚’å–å¾—ã€è‡ªç„¶è¨€èªå‡¦ç†ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãªã©ã®å¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ±ç”¨çš„ãªã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹æ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ§‹ç¯‰ã§ããŸã¨ã„ã†
	- æ‰‹æ®µã¨ã—ã¦ã¯ã€3Dä¸–ç•Œã®ç†è§£ã¨ç›¸äº’ä½œç”¨ã‚’å¿…è¦ã¨ã™ã‚‹ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã¨ã‚·ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®å¤šãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€è¦æ¨¡ã¨è¤‡é›‘ã•ã«å„ªã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ…é‡ã«ä½œæˆ
-  å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’LoRAã§å¼·åŒ–ã™ã‚‹éš›ã«å½¹ç«‹ã¤æƒ…å ±ã‚’ç ”ç©¶è€…ãŒå…¬é–‹
	- https://gigazine.net/news/20231123-llm-lora/
	- LoRAã¯ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã«è¿½åŠ ã®æƒ…å ±ã‚’å­¦ç¿’ã•ã›ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã§ãã‚‹ä»•çµ„
	- **â—†LoRAã®åŠ¹æœã«ã¯ä¸€è²«æ€§ãŒã‚ã‚‹**
	- **â—†QLoRAã‚’ä½¿ãˆã°è¿½åŠ å­¦ç¿’æ™‚ã®VRAMä½¿ç”¨é‡ã‚’å¤§å¹…ã«ç¯€ç´„å¯èƒ½**
	- **â—†æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯Adamã§ã‚‚SGDã§ã‚‚å¤§å·®ãªã„**
	- **â—†LoRAã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã™ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹**
	- **â—†LoRAã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã¯å˜ä¸€ã®GPUã§å®Ÿè¡Œå¯èƒ½**
- Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall
	- Claude2.1ã®é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèƒ½åŠ›ã«å¯¾ã™ã‚‹ã€ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
	- https://x.com/GregKamradt/status/1727018183608193393?s=20
	- 200K ãƒˆãƒ¼ã‚¯ãƒ³ (ç´„ 470 ãƒšãƒ¼ã‚¸) ã§ã€Claude 2.1 ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€éƒ¨ã®æ·±ã•ã§äº‹å®Ÿã‚’æ€ã„å‡ºã™ã“ã¨ãŒã§ãã¾ã—ãŸã€‚ 
	- æ–‡æ›¸ã®ä¸€ç•ªä¸Šã¨ä¸€ç•ªä¸‹ã«ã‚ã‚‹äº‹å®Ÿã¯ã»ã¼ 100% ã®ç²¾åº¦ã§å†ç¾ã•ã‚Œã¾ã—ãŸ 
	- æ–‡æ›¸ã®ä¸Šéƒ¨ã«ã‚ã‚‹äº‹å®Ÿã¯ä¸‹éƒ¨ã‚ˆã‚Šã‚‚ä½ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ãƒªã‚³ãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸ (GPT-4 ã¨åŒæ§˜) 
	- ~90,000 ãƒˆãƒ¼ã‚¯ãƒ³ä»¥é™ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸‹éƒ¨ã«ã‚ã‚‹ãƒªã‚³ãƒ¼ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã¾ã™ã¾ã™æ‚ªåŒ–ã—å§‹ã‚ã¾ã—ãŸ 
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒçŸ­ã„å ´åˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ
- Why do tree-based models still outperform deep learning on typical tabular data?
	- https://hal.science/hal-03723551
	- Why do tree-based models still outperform deep learning on tabular data?â€ confirms tree-based models outperform deep learning and explain some of the reasons why.
	- When it comes to #tabulardata and #timeseries (by far the most important majority of data for almost any real company), deep learning is not one needs. 
- Pythonã«ã‚ˆã‚‹ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•å…¥é–€: åŸºç¤ç†è«–ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã®å®Ÿè£…ã¾ã§
	- https://www.amazon.co.jp/dp/4621308882?_encoding=UTF8&psc=1&ref_=cm_sw_r_tw_ud_dp_RW79QAZKZRQ7K9N885XB
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã«ãŠã„ã¦ã‚‚,å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦ç‰©æ€§å€¤ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã—ã¤ã¤,ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦ã‚’é«˜ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ãª,ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã¨èåˆã—ãŸæ‰‹æ³•ã®é–‹ç™ºãŒé€²ã‚“ã§ã„ã‚‹.ãã“ã§æœ¬æ›¸ã§ã‚‚,ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã®åŸºç¤ã‹ã‚‰ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«ã¸ã®å®Ÿè£…æ–¹æ³•ã¾ã§ã‚ã‚ã›ã¦ç´¹ä»‹ã™ã‚‹.
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã§ã¯ã€ç§©åºå¤‰æ•°ã®æ‹¡æ•£æ–¹ç¨‹å¼ã¨åå¿œæ–¹ç¨‹å¼ã‚’åŒæ™‚ã«è§£ãã“ã¨ã§ã€çµ„ç¹”å½¢æˆéç¨‹ã‚’è¨ˆç®—ã—ã¾ã™ã€‚æ‹¡æ•£æ–¹ç¨‹å¼ã¯ã€ç§©åºå¤‰æ•°ãŒæ‹¡æ•£ã™ã‚‹éš›ã®æŒ™å‹•ã‚’è¨˜è¿°ã™ã‚‹æ–¹ç¨‹å¼ã§ã™ã€‚åå¿œæ–¹ç¨‹å¼ã¯ã€ç›¸ã®å¤‰åŒ–ã‚’è¨˜è¿°ã™ã‚‹æ–¹ç¨‹å¼ã§ã™ã€‚
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã¯ã€é‡‘å±ã®å‡å›ºã€å¤šçµæ™¶ç²’æˆé•·ã€æ‹¡æ•£ç›¸å¤‰æ…‹ãªã©ã€ã•ã¾ã–ã¾ãªææ–™çµ„ç¹”å½¢æˆéç¨‹ã®è¨ˆç®—ã«ç”¨ã„ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€å¿œåŠ›å ´ã‚„é›»ç£å ´ã«ãŠã‘ã‚‹çµ„ç¹”å½¢æˆã‚„ãƒŠãƒã‚¹ã‚±ãƒ¼ãƒ«ã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«åŒ–ãªã©ã€ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ»ãƒãƒ«ãƒãƒ•ã‚£ã‚¸ãƒƒã‚¯ã‚¹ã‚’å¯¾è±¡ã¨ã—ãŸç¨®ã€…ã®å·¥å­¦åˆ†é‡ã«ã‚‚å¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
- ã€Œãƒã‚¹ã‚¿ãƒ¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã®è‘—è€…ã€Domingosæ°ã€Q*-learningã®åŠ¹æœã‚’ã¿ã¦ã€äººé¡ã®çµ‚ç„‰ã‚’å«ã¶
	- https://x.com/pmddomingos/status/1727562239060656339?s=20
	- Q* can solve simple math problems that symbolic AI could solve 50 years ago. Panic! AGI is here! Humanity is over!
- A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases
	- https://arxiv.org/abs/2311.07509
	- impact of KGs for question answering on SQL databases: 54% accuracy vs. 16% with instructions directly on SQL databases.
	- SQL DBã‚’å‚ç…§ã—ã¦è³ªå•å¿œç­”ã‚’è¡Œã†ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€LLMã«ç›´æ¥SQLã‚’å‚ç…§ã•ã›ã‚‹ã¨16%ã®æ­£è§£ç‡ã—ã‹å‡ºãªã‹ã£ãŸãŒLLMã‚’ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãã‚Œã‚’å‚ç…§ã•ã›ã‚‹ã¨54%ã«æ”¹å–„ã—ãŸã¨ã„ã†ç ”ç©¶ã€‚
	- æœ¬è³ªçš„ã«æŒã£ã¦ã„ã‚‹æƒ…å ±ãŒåŒã˜ã§ã‚‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ã‚ˆã£ã¦RAGã®ç²¾åº¦ãŒå¤‰ã‚ã‚‹ã“ã¨ã®ä¸€ä¾‹ã¨ã‚‚ã¿ãªã›ã‚‹
- ã†ã¿ã‚†ãæ°ã€Claude2.1ã®æ€§èƒ½ã«èˆŒã‚’å·»ã
	- https://x.com/umiyuki_ai/status/1727875985167790529?s=20
	- Claudeç„¡æ–™ç‰ˆè©¦ã—ã¦ã¿ãŸã‘ã©ã€çµæ§‹é•·æ–‡ã®æ—¥æœ¬èªpdfå…¥åŠ›ã—ã¦è¦ç´„ã—ã¦ã£ã¦ãŠé¡˜ã„ã—ãŸã‚‰ã€ã¡ã‚ƒã‚“ã¨å†…å®¹èª­ã‚“ã§è¦ç´„ç®‡æ¡æ›¸ãå‡ºã—ã¦ãã‚ŒãŸï¼ˆç›®æ¬¡ä¸¸å†™ã—ã§ã¯ãªã„ï¼‰ã€€ï¼“ç« ã®å†…å®¹èª¬æ˜ã—ã¦ã£ã¦è¨€ã£ãŸã‚‰ã¡ã‚ƒã‚“ã¨èª¬æ˜ã—ã¦ãã‚ŒãŸã€‚ã¤ã¾ã‚Šã¡ã‚ƒã‚“ã¨æœ€å¾Œã¾ã§èª­ã‚“ã§ç­”ãˆã¦ã‚‹ã€‚ã‹ãªã‚Šçš„ç¢ºãªå¿œç­”ã‚’è¿”ã—ã¦ãã‚Œã‚‹ã€‚ãã‚Œã§ã‚¿ãƒ€ã€‚ã“ã‚Œç›¸å½“ã‚¹ã‚´ã‚¤ã­
- Yuhan Sun et al., "To be or not to be? an exploration of continuously controllable prompt engineering"
	- https://arxiv.org/abs/2311.09773
	- ã“ã‚Œã¾ã§ã€ŒLLMã®å‹•ãã‚’è¦³å¯Ÿã—ã¦"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿ç¯€"ã™ã‚‹ã€æ‰‹æ³•ãŒè¿½ç©¶ã•ã‚Œã¦ãã¾ã—ãŸãŒã€é™ç•ŒãŒã‚ã‚‹ãŸã‚ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹"LLMã®å‹•ãã‚’ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«èª¿æ•´"ã™ã‚‹ã€æ‰‹æ³•ã€ControlPEã€
	- è‡ªå‹•é‹è»¢ã‚·ã‚¹ãƒ†ãƒ ãªã©ã‚’æ‰‹æ›ã‘ã‚‹ã‚»ãƒ³ã‚¹ã‚¿ã‚¤ãƒ ç¤¾ã«ã‚ˆã‚‹
	- ControlPEã¯ç«¶åˆæŠ€è¡“ã¨æ¯”è¼ƒã—ã¦ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å½±éŸ¿ã‚’ã“ã¾ã‹ãèª¿æ•´ã§ãã‚‹æ‰‹æ³•
	- â‘  LoRAã‚’åˆ©ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å½±éŸ¿ã‚’é€£ç¶šçš„ã«å¾®èª¿æ•´ â‘¢ å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è£œå®Œã™ã‚‹
- Q*ã®ã‚‚ã¨ã‚‚ã¨ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å‡ºã—ãŸè«–æ–‡è‘—è€…ãŒè‡ªè«–æ–‡ã‚’å®£ä¼
	- https://x.com/McaleerStephen/status/1727524295377596645?s=20
	-  A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks
	- https://arxiv.org/abs/2102.04518
- Q*ã«ã¤ã„ã¦è‘—åãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆErnest Okumuraã•ã‚“ã®ã‚³ãƒ¡ãƒ³ãƒˆ
	- https://x.com/pacocat/status/1728052432016470281?s=20
	- Q*ãŒQ-learningã‹ã‚‰æ¥ã¦ã„ã‚‹ã‹ã¯çŸ¥ã‚‰ãªã„ã‘ã‚Œã©ã‚‚ã€åˆ¶ä½œè€…ã«ã¨ã£ã¦å¥½ã¾ã—ã„å‡ºåŠ›ã‚’å¾—ã‚‹ãŸã‚ã«æ–¹ç­–ç©ºé–“ã‚’æ¢ç´¢ã™ã‚‹æŠ€è¡“ã¯ä»Šå¾Œã•ã‚‰ã«æ±‚ã‚ã‚‰ã‚Œã¦ã„ãã¨æ€ã†ã—ã€RLHFã¿ãŸã„ãªåˆ†ã‹ã‚Šã‚„ã™ã„ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’è¶…ãˆã¦AGIã¿ãŸã„ãªæ–‡è„ˆã§ã‚‚é‡å¿ƒçš„ãªè©¦ã¿ã¯å¢—ãˆã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã§ã—ã‚‡ã†ã‹ã€‚
- Sparse Transformersï¼šå…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã«ã‚ˆã‚‹è¨ˆç®—é‡å¢—åŠ å•é¡Œã¸ã®é©æ–°çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- https://ai-scholar.tech/articles/transformer/sparseTransformer
	- Attentionã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ¯ã®ç‰¹å¾´ã‚’å†ç¾ã™ã‚‹ã“ã¨ã§ï¼Œè¨ˆç®—é‡ã®å‰Šæ¸›ã‚’é”æˆ  
	- Sliding Window Attenionã€Dilated Sliding Window Attentionã€Global Attentionã¨ã„ã†3ã¤ã®Attentionã‚’ä½¿ã£ã¦Transformernã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãŸ  
	- è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãŸã ã‘ã§ã¯ãªãã¦ï¼Œå½“æ™‚ã®SOTAã‚’é”æˆã—ã¦ã„ã‚‹ï¼
-  Llemma: An Open Language Model For Mathematics
	- https://arxiv.org/abs/2310.10631
	- ã©ã†ã‚‚ã€LLMã‚’ã¤ã‹ã£ã¦ã€å®šç†è¨¼æ˜å™¨ã‚’ã¤ã‹ã†pythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã‚‰ã—ã„ã€‚å®Ÿéš›ã«èª¬ãã®ã¯pythonã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ï¼‹å®šç†è¨¼æ˜å™¨ã®çµ„ã¿åˆã‚ã›ã€‚
	- The AlgebraicStack dataset of 11B tokensãŒæä¾›ã•ã‚Œã‚‹
	- Llema can solve mathematical problems using a Python interpreter and a formal theorem prover.
- LlamaIndex vs. OpenAI Assistants API
	-  RAG Evaluation Series: Validating the RAG Performance of OpenAI vs LlamaIndex
	- https://www.tonic.ai/blog/rag-evaluation-series-validating-rag-performance-openai-vs-llamaindex
- ChatGPTã‚¢ãƒ—ãƒªã®éŸ³å£°ä¼šè©±ãŒç„¡æ–™ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚‚é–‹æ”¾
	- https://x.com/IELTS_expert/status/1728326991676670222?s=20
	- è‹±èªå­¦ç¿’ã‚½ãƒ•ãƒˆã‚„æœ‰æ–™ãƒ¬ãƒƒã‚¹ãƒ³ãŒä¸è¦ã«
- JARVIS-1ã¯æœ¬å½“ã¯ã™ã”ã„ã€
	- https://x.com/ai_database/status/1728257353852797143?s=20
	- ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆï¼ˆåºƒå¤§ãªãƒãƒ¼ãƒãƒ£ãƒ«ä¸–ç•Œã§æ¡æ˜ã‚„å»ºè¨­ã‚’è¡Œã†ã‚²ãƒ¼ãƒ ï¼‰ã‚’ä¸Šæ‰‹ã«ãƒ—ãƒ¬ã‚¤ã™ã‚‹AIã€JARVIS-1ã€ãŒé–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚ éå¸¸ã«è¤‡é›‘ãªå‹•ä½œã‚’å«ã‚€200ç¨®é¡ä»¥ä¸Šã®è¡Œå‹•ãŒå¯èƒ½ã¨ã®ã“ã¨ã€‚
	-  ã“ã®ã‚ˆã†ãªæŠ€è¡“ã‚’å¿œç”¨ã™ã‚‹ã¨ã€ãƒ­ãƒœãƒƒãƒˆãŒç¾å®Ÿä¸–ç•Œã§ã‚‚ã•ã¾ã–ã¾ãªé‡è¦ã‚¿ã‚¹ã‚¯ã‚’é”æˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚â€¦
- æœ€çµ‚çš„ã«ã™ã¹ã¦ã®çµ±è¨ˆã¯ãƒ™ã‚¤ã‚ºã«è¡Œãç€ãã—ã‹ãªã„ã¨æ€ã£ã¦ã„ã¾ã™ï¼ˆçµ±è¨ˆæ•°ç†ç ”ç©¶æ‰€ã€éŒè°·æ°ï¼‰
	- https://www.ism.ac.jp/ism_info_j/labo/project/162.html
- ãƒ«ã‚«ãƒ³å…ˆç”Ÿã«ã‚ˆã‚‹Q*ã«å¯¾ã™ã‚‹è¡¨æ˜
	- https://x.com/ylecun/status/1728126868342145481?s=20
	- ã€ŒQ*ã«é–¢ã™ã‚‹å®Œå…¨ãªãƒŠãƒ³ã‚»ãƒ³ã‚¹ã®æ´ªæ°´ã¯ç„¡è¦–ã—ã¦ã­ã€‚LLMã®ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ä¸»ãªèª²é¡Œã®1ã¤ã¯ã€è‡ªå·±å›å¸°çš„ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã™ã€
- Macã§llama2ã‚’è©¦ã™ãŸã‚ã®swift-chat
	- https://github.com/huggingface/swift-chat
	- Llama 2 7B chat, running 100% private on Mac, powered by CoreML!
	- Pedro Cuencaã•ã‚“ã¯ç¾åœ°æ™‚é–“2023å¹´08æœˆ08æ—¥ã€Apple Silicon Macãªã©Appleãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®Swiftãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨Demoã‚¢ãƒ—ãƒªã‚’å…¬é–‹
	- Swiftã§Transformersãƒ©ã‚¤ã‚¯ãªAPIã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã«é–‹ç™ºã—ãŸSwiftãƒ‘ãƒƒã‚±ãƒ¼ã‚¸â€swift-transformersâ€ã¨ã€Demoã‚¢ãƒ—ãƒªâ€swift-chatâ€ã€åŠ ãˆã¦Transformersãƒ¢ãƒ‡ãƒ«ã‚’CoreMLã¸å¤‰æ›ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼â€transformers-to-coremlâ€ã§ã€
	- CoreMLãŒå½¹ã«ç«‹ã£ãŸã¨ã€ã€
- OECDã€ç”ŸæˆAIã‚„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’è€ƒæ…®ã—ã¤ã¤AIã®å®šç¾©ã‚’æ”¹å®šã€
	- https://www.euractiv.com/section/artificial-intelligence/news/oecd-updates-definition-of-artificial-intelligence-to-inform-eus-ai-act/
	- æ¬§å·AIæ³•ãªã©ã®ä»–ã®è¦åˆ¶ã¨ã®æ•´åˆæ€§ã‚‚è€ƒæ…®ã—ãŸã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ã¨ã£ãŸ
	- ç›®æ¨™ã‚’äººé–“ãŒå®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ã„ã†äº‹å®Ÿã¸ã®è¨€åŠã‚’å‰Šé™¤ã€
	- ã€Œå‡ºåŠ›ã®ç”Ÿæˆæ–¹æ³•ã‚’æ¨æ¸¬ã™ã‚‹ã€ã¨ã„ã†æ–‡è¨€ã‚‚ã€AI ãƒ¢ãƒ‡ãƒ«ãŒç’°å¢ƒã‹ã‚‰å…¥åŠ›ã‚’å—ã‘å–ã‚Šã€1 ã¤ä»¥ä¸Šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é€šã˜ã¦é©åˆ‡ãªå‡ºåŠ›ã‚’æ€ã„ã¤ãã¨ãã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«å°å…¥

## 11/20

ä»Šé€±ã¯ã€OpenAIã®CEOã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã®é›»æ’ƒè§£ä»»ãŒå…¨ã¦ã‚’æŒã£ã¦è¡Œã£ãŸã€‚å…ˆé€±OpenAI dev dayã§é›„å§¿ã‚’ã€ãã—ã¦äººé¡ã®æœªæ¥ã‚’å£é–“è¦‹ãŸã®ã«ã€‚ã€‚ãƒœãƒ¼ãƒ‰ã‹ã‚‰å¾©å¸°ã®è¦è«‹ã‚‚ã‚ã‚‹ã¨ã„ã†ã—ã€ã¾ã ã¾ã ç¾åœ¨é€²è¡Œå½¢ã€‚ã•ã¦ã€RAGã‚‚embeddingã‚’ã¤ã‹ã£ãŸé¡ä¼¼æ¤œç´¢ã‚ˆã‚Šã‚‚æ§‹é€ ã‚’åŠ å‘³ã—ãŸæ¤œç´¢ã¨ã‹ã€å¤šæ§˜æ€§ã‚’ã‚‚ã¤æ¤œç´¢çµæœã®åˆ©ç”¨ã¨ã‹ã€ã ã‚“ã ã‚“ã€æ¨è–¦æŠ€è¡“ãªã©ã§ç¢ºç«‹ã•ã‚ŒãŸãƒã‚¦ãƒã‚¦ãŒæ´»ç”¨ã•ã‚Œå§‹ã‚ãŸã€‚LlamaIndexã®æ–°æ©Ÿèƒ½ã€text-to-SQL+semanticã£ã¦ã®ãŒã„ã„ã­ã€‚LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–¢ä¿‚ã‚‚ã«ãã‚„ã‹ã€å˜ã«è«–ç†ã‚½ãƒ«ãƒãƒ¼ã‚’å¤–éƒ¨ã«ã‚‚ã£ã¦ã¦ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚½ãƒ«ãƒãƒ¼ã«æ¸¡ã™è«–ç†å¼ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã‚Šã‚‚ã€ã‚½ãƒ«ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ãã®ã¾ã¾ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ã£ã¦ã€è§£ãè¡Œç‚ºãã®ã‚‚ã®ã‚’æ¨¡æ“¬ã™ã‚‹ã¨ã„ã†LoGiPTã¨ã‹ã€çµæ™¶æ§‹é€ ã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã—LLaMA-2ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€VAEã‚’ä¸Šå›ã£ãŸã¨ã„ã†äº‹ä¾‹ã¨ã‹ãŒã‚ã‚‹ã€‚ãã‚‚ãã‚‚ã§ã™ã‚ã­ã€æ–°ã—ã„OpenAIã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€200å€‹ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã€ãŠå¬¢æ§˜LLMãã‚‰ã„ã¯ã§ãã‚‹ã¿ãŸã„ã§ã”ã–ã„ã¾ã™ã§ã™ã€‚LLMã¯ãã®ãƒ¡ã‚¿ãªèƒ½åŠ›ã‚‚é‡è¦ãªè¦ç´ ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’ä½œã‚‹ãƒ¡ã‚¿ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã¤ãã£ãŸã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMãŒç†è§£ã‚„ã™ã„ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã‹ã€ã“ã£ã¡æ–¹é¢ã®ãƒ¡ã‚¿ãªä¸–ç•Œã‚‚ã„ã„æ„Ÿã˜ã§ç™ºå±•ã—ã¦ã„ã‚‹ã€‚ï¼ˆã¡ã‚‡ã£ã¨è¦–ç‚¹ã‚’å¤‰ãˆãŸï¼‰ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨LLMã®ãƒ¡ã‚¿èƒ½åŠ›ã‚’åˆ©ç”¨ã™ã‚‹ã®ãŒLLMæ´»ç”¨ã®æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã€‚create-llamaã¨ã‹ã€OpenGPTã¨ã‹ã€LLMA Factoryã¨ã€è‡ªå‹•çš„ã«ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ä»•çµ„ã¿ãŒãŸãã•ã‚“å‡ºã¦ããŸã€‚ ã‚ãšã‹1åˆ†ã§10æ—¥é–“ã®å¤©æ°—ã‚’äºˆæ¸¬å¯èƒ½ãªAIã€ŒGraphCastã€ã€ãŠèŒ¶ã®æ°´å¤§å­¦ã®ç¥å±±å…ˆç”Ÿã®è§£èª¬ãŒã€å¾“æ¥ã®æ‰‹æ³•ãŒä¸å¾—æ„ãªã¨ã“ã‚ã«Graph transformerãŒã´ã£ãŸã‚Šåˆã£ãŸã¨ã„ã†ã¨ã“ã‚ãŒè…¹è½ã¡ã—ã¾ã™ã€‚Microsoftã®ç™ºè¡¨ã—ãŸCopilotã€ã¤ã¾ã‚ŠGPTsã®ï¼­ï¼³ç‰ˆã€‚ã“ã†ã„ã†ä¸–ç•Œè¦³ã«ãªã‚‹ã‚ˆãªã€‚æ—©é€ŸOpenCopilotã¨ã‹ã€WebCoPilotã¨ã‹ã€ã‚ã£ã¨ã„ã†ã¾ã«ã€ä¼¼ãŸã‚ˆã†ãªOSSãŒã€ã€ã€ã€‚YahooçŸ¥æµè¢‹ã€ã¤ã„ã«GPT-4ã‚’ã¤ã‹ã£ãŸè‡ªå‹•å›ç­”ã‚’ãƒ†ã‚¹ãƒˆä¸­ã€‚äººã®è¡†çŸ¥ã¯ChatGPTã«æ•—ã‚ŒãŸã®ã‹ã€‚ã€‚ï¼­ï¼£æ¥­ã®ç´—ã€…æ°ã€NTTæ­¦è”µé‡é€šç ”ã§é–‹å‚¬ã•ã‚ŒãŸR&Dãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§ã€AIåŒ–ã•ã‚Œã‚‹ã€ï¼­ï¼£æ¥­ã‚‚ï¼¡ï¼©ã«ä»£æ›¿ã•ã‚Œã‚‹ï¼Ÿã•ã‚Œãªã„ï¼Ÿã¾ã‚ã€ChatGPTã§ä»•äº‹ãŒãªããªã£ãŸã®ã¯ã€ChatGPTã®CEOã‚‚ä¾‹å¤–ã§ã¯ãªã„ã¨ã„ã†ã®ã¯ãƒ–ãƒ©ãƒƒã‚¯ã‚¸ãƒ§ãƒ¼ã‚¯ã‹ã‚‚ã€‚

- Adding Structure-Aware Retrieval to GenAI Stack
	- https://medium.com/@yu-joshua/adding-structure-aware-retrieval-to-genai-stack-373976de14d6
	- å˜ãªã‚‹embeddingã‚’ã¤ã‹ã£ãŸé¡ä¼¼æ¤œç´¢ã®RAGã§ã¯ãªãã¦ã€æ§‹é€ ã‚’æŠ½å‡ºã—ãŸã†ãˆã§ã®ã€RAGã£ã¦ã®æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ã€neo4j+LangChainã®å®Ÿä¾‹ã§ç¤ºã—ãŸè‰¯ä¾‹
	- This stack is (1) fully local, (2) uses advanced retrieval methods that encode relationships between different chunks of texts
- LlamaIndex ã«ã‚ˆã‚‹OpenAIã®æ–°æ©Ÿèƒ½ã‚’ä½¿ç”¨ãƒ»ç†è§£ã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ by npakaã•ã‚“
	- https://note.com/npaka/n/n728fdb8f76da?sub_rt=share_sb
	- Parallel Function Callingã€Assistant API Agentã€Function Callingã«ã‚ˆã‚‹é«˜åº¦ãªRAGã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAG
	- GPT Builderã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•æ€§ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€GPTã‚’ç”Ÿæˆã™ã‚‹metaãªãƒ„ãƒ¼ãƒ«
	- ã€Œtext-to-SQL ã¨ semantic search ã®ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã€ãªã‚“ã‹ã¯èˆˆå‘³æ·±ã„
- æ—¥æœ¬ã®å¥³æ€§ãŒå…ˆé€²å›½ã®ä¸­ã§é•·å‘½ãªã®ã¯ã€ç¤¾ä¼šé€²å‡ºãŒé€²ã¾ãªã‹ã£ãŸã‹ã‚‰ï¼Ÿ
	- æ—­ãƒªã‚µãƒ¼ãƒ
	- https://arc.asahi-kasei.co.jp/report/arc_report/pdf/rs-824.pdf
	- ã€Œå…ˆé€²å›½ã®ä¸­ã§ã¯å¥³æ€§ã®ç¤¾ä¼šé€²å‡ºãŒé€²ã¾ãªã‹ã£ãŸã“ã¨ãŒã€ ä¸–ç•Œä¸€ã®å¥³æ€§é•·å¯¿ã«çµã³ã¤ã„ãŸã¨æ€ã‚ã‚Œã‚‹ã€‚ã€ 
	- ã€Œå‡ç­‰æ³•ã¯å¥³æ€§ã®å¹³å‡å¯¿å‘½ã‚’çŸ­ç¸®ã•ã›ã‚‹è¦å› ã§ã‚ã‚‹ã€‚ã€
- gpt-3.5-turbo-1106ã‚’ä½¿ã£ãŸã€æ–°ã—ã„OpenAIã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
	- https://x.com/matsu_vr/status/1723688378795958670?s=20
	- ã§ãŠå¬¢æ§˜ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸã€‚200ä¾‹ã®ä¼šè©±ã§ååˆ†ãŠå¬¢æ§˜ã«ãªã£ãŸï¼
- Boosting RAG: Picking the Best Embedding & Reranker models
	- https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
	- RAGã‚’ã‚„ã‚‹ã«ã‚ãŸã£ã¦ã©ã‚Œã‚’ä½¿ãˆã°ã‚ˆã„ã‹ã‚’èª¿ã¹ãŸãƒ–ãƒ­ã‚°ã€‚OpenAI ChatGPTã‚„Google PaLMãªã©ã§ä½œã£ãŸ embeddings ã¨ BAAI ç­‰ãŒæä¾›ã—ã¦ã„ã‚‹ reranker ã§ã€ã©ã®çµ„ã¿åˆã‚ã›ãŒç²¾åº¦ãŒè‰¯ã„ã‹
- OpenAI Dev dayã‚’å—ã‘ãŸã€llamaindexã®ãƒã‚¤ãƒ¬ãƒ™ãƒ«APIã®ã‚¢ãƒ—ãƒ‡ã¾ã¨ã‚
	- https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p
	- å¤§å¤‰ã ãƒ¼
-  Prompt Engineering a Prompt Engineer
	- https://huggingface.co/papers/2311.05661
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’ä½œã‚‹ãƒ¡ã‚¿ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œã‚‹ã¨ã„ã†è©±ã€LLMã£ã¦ãƒ¡ã‚¿èƒ½åŠ›ãŒã‚ã‚‹ã®ã§ã€ã“ã†ã„ã†è©¦ã¿ãŒå¯èƒ½ã€‚CoTè¶Šãˆã¨ã„ã†ã®ã¯æœ¬å½“ã‹ï¼Ÿ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMãŒè¨€ã„æ›ãˆã¦ã€LLMè‡ªèº«ãŒç†è§£ã—ã‚„ã™ãã™ã‚‹æ‰‹æ³•ã€RaRã€
	- https://aiboom.net/archives/51160
	- ä¾‹ãˆã°ã€ŒGPT-4ã§è¨€ã„æ›ãˆã¦GPT-3.5ã§å…¥åŠ›ã™ã‚‹ã€ã‚‚æœ‰åŠ¹ã¨ã®ã“ã¨ã§ã™ã€‚ å®Ÿè¡Œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„æ€§èƒ½ç­‰ã‚’è©³ã—ãç´¹ä»‹ã™ã‚‹è¨˜äº‹ã‚’å…¬é–‹ã—ã¾ã—ãŸ
-  Language Models can be Logical Solvers
	- https://huggingface.co/papers/2311.06158
	- å¾“æ¥SOTAã¯ã€solver-augmented language modelsã‚’ã¤ã‹ã£ã¦ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’å–ã‚Šå‡ºã—ã¦ã€å¤–éƒ¨ã‚½ãƒ«ãƒãƒ¼ã§èª¬ã„ã¦ã„ãŸãŒã€ã€æ–‡æ³•ãŒã‚ã£ã¦ãªã„ã¨ã‹ãã†ã„ã†ä¸‹ã‚‰ãªã„ã‚¨ãƒ©ãƒ¼ã«æ‚©ã¾ã•ã‚Œã¦ããŸ
	- LoGiPTã¯ã€ç›´æ¥è«–ç†çš„ãªå°å‡ºã‚’ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã€æ—¢å­˜ã‚½ãƒ«ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã€‚å•é¡Œã¯è§£æ±ºã•ã‚ŒãŸ
	- https://x.com/IntuitMachine/status/1724104506185580589?s=20
-  JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models
	- https://arxiv.org/abs/2311.05997
	- JARVISã£ã¦ç¢ºã‹ã€ã‚¢ã‚¤ã‚¢ãƒ³ãƒãƒ³ã®ã‚µãƒãƒ¼ãƒˆAIã®åå‰ã§ã¯ï¼Ÿï¼Ÿ
- äººé–“ã®æƒ…å ±å‡¦ç†ã«ã¨ã£ã¦ã€Œã¡ã‚‡ã†ã©ã„ã„å¡©æ¢…ã€ã®é€Ÿåº¦ã‚’è¶…ãˆã¨ã‚‹æ°—ãŒã™ã‚‹ by è°·ãƒãƒ¥ãƒ¼
	- https://x.com/rmaruy/status/1724044250286108818?s=20
	- Buonomanoã€è„³ã¨æ™‚é–“ã€ã«ã‚ˆã‚Œã°ã€è„³ã«ã¯å˜ä¸€ã®ã‚¯ãƒ­ãƒƒã‚¯ã¯ãªã„ï¼ˆå¤šé‡æ™‚è¨ˆåŸç†ï¼‰ã€‚ãŒã€é€²åŒ–ã®éç¨‹ã§ç”Ÿç‰©ãŒç›¸æ‰‹ã«ã—ã¦ããŸæ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚ˆã‚Šå¤§å¹…ã«é€Ÿã„æƒ…å ±å‡¦ç†ã¯ã§ããªã„ã ã‚ã†ã€‚ä¸€æ–¹ã€æƒ…å ±ã®ã€Œé‡ã€ã«é–¢ã—ã¦ã¯ã¾ã å·¥å¤«ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
- DPOã§calm2ã®ç‰©èªç”Ÿæˆèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹è©¦ã¿ã€
	- https://x.com/_oshizo_/status/1724039980463657130?s=20
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§LLMãŒæ–‡å­—ã‚’ç”Ÿæˆã™ã‚‹æ§˜å­ã®ãƒ‡ãƒ¢ã€
	- https://x.com/dylfreed/status/1723927399857901724?s=20
	- llamacppã‚’ã¤ã‹ã£ã¦8GB RAM MacBook Airã§å‹•ãã‚“ã ã¨ã•
- LLMã£ã¦çµå±€ä½•ã‹ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«èª¬æ˜ã™ã‚‹
	- https://x.com/davidad/status/1723990400682148124?s=20
	- ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€å„å±¤é–“ã«è¦ç´ ã”ã¨ã®éç·šå½¢æ€§ã‚’æŒã¤ç·šå½¢å›å¸°ã®ã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒæ§‹é€ ã§ã™ã€‚LLM/GPT ã®çˆ†ç™ºçš„ãªå¢—åŠ ã«ç›´æ¥ã¤ãªãŒã£ãŸã€ŒAttending is All You Needã€ã®æ ¸ã¨ãªã‚‹è²¢çŒ®ã€ãã“ã« *ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯* å›å¸°ã‚’éç·šå½¢å±¤ã«æŠ•ã’è¾¼ã‚€ã“ã¨ã§ã™ã¾ãŸã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã«ã¤ã„ã¦ã¯@geoffreyhinton ã€æ´»æ€§åŒ–æ­£è¦åŒ–ã«ã¤ã„ã¦ã¯@ChrSzegedy ã€ãŠã‚ˆã³å‹¾é…æ­£è¦åŒ–ã«ã¤ã„ã¦ã¯@dpkingmaã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ (Adam)ã€‚
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’å‹•ã‹ã™PCã‚’è‡ªä½œ
	- https://note.com/ai_meg/n/n8855a8dd4bbd?sub_rt=share_pb
	- ãƒã‚¶ãƒ¼ãƒœãƒ¼ãƒ‰ï¼šAsrokã€€B760 PRO RS/DS  
	- CPUï¼ši5-13400F  
	- GPU:PALITã€€GFORCE-RTX4060ti-16G
- RETOOLã®State of AIãƒ¬ãƒãƒ¼ãƒˆ
	- https://retool.com/reports/state-of-ai-2023
	- 66% of companies have at least one AI use case live
	- Accuracy is #1 concern
	- RAG is 2nd most popular use case (1st is code)
	- @llama_index is one of the leading frameworks for enterprises 
- OpenGPTã¯ã©ã‚“ã©ã‚“é€²åŒ–ã™ã‚‹
	- https://github.com/langchain-ai/opengpts
-  The Alignment Handbook
	- https://github.com/huggingface/alignment-handbook
	- Robust recipes to align language models with human and AI preferences
- EditGPT
	- https://chat.openai.com/g/g-zpuYfzV7k-editgpt
	- Grammeryã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æŒã¤GPTsãŒã€ã€
- å²¡é‡åŸã•ã‚“ã®ã€ã€Œæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã€ãŒä»Šå¹´åº¦ã®å¤§å·å‡ºç‰ˆè³ã«é¸å‡º
	- https://hillbig.github.io/diffusion-models/
	- http://www.okawa-foundation.or.jp/activities/publications_prize/list.html
- ã“ã‚Œã¯è¡æ’ƒ!1.5Bã§è¶…é«˜æ€§èƒ½LLM!RWKV-5-World-v2 by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/nfc8dd1abf494?sub_rt=share_pb
	- ã¾ã ç”Ÿãã¦ãŸã®ã‹ã€RWKV
- The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4
	- https://arxiv.org/abs/2311.07361
	- Evaluates GPT-4â€™s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilitie
	- MSã‹ã‚‰ã®è«–æ–‡ã€è£½è–¬ã¨ã‹ã®è©±ãŒå¤šã„ãŒã€ãªã‚“ã‹ã¤ã¾ã‚‰ã‚“
- Open AIä¸»ä»»ç§‘å­¦è€…ã®Ilya Sutskeveræ°ã¯æ˜¨æ—¥ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã«ã¦ã€AGIã«ãŸã©ã‚Šç€ããŸã‚ã«ã¯Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‹Î±ã§ã€Œæ˜ã‚‰ã‹ã«ã€å•é¡Œãªã„ã¨
	- https://www.youtube.com/watch?v=Ft0gTO2K85A
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®Fine-tuningã«ã‚ˆã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ç²å¾—ã®æ¤œè¨
	- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/
	- è‹±èªã§ä¸»ã«å­¦ç¿’ã•ã‚ŒãŸLLaMA2ã«å¯¾ã—ã¦æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸInstruciton Tuningã‚„è¿½åŠ äº‹å‰å­¦ç¿’ãŒã©ã®ç¨‹åº¦å¯èƒ½ã‹ã®æ¤œè¨¼
	- ä¸å¯æ€è­°ãªçµæœãŒå‡ºãŒã¡ãªã®ã§ã€ã„ã‚ã‚“ãªè¨­å®šã§è©¦ã•ãªã„ã¨ã„ã‘ãªã„ã“ã¨ãŒã‚ã‹ã£ãŸ
- LangChainã‹ã‚‰ã€Query Construction Guideã€text-to-SQL+semanticæœ€å¼·ç¯€
	- https://blog.langchain.dev/query-construction/
	- 1. Structure+unstructured data:  Text-to-SQL+semantic (w/ PostgresSQL with the Pgvector 
	- 2. Unstructured w/ metadata: Text-to-metadata filters (w/ new docs + a template for self-query retriever)
	- "Text-to-SQL+semantic" is an interesting recent addition to LangChain that extends "Text-to-SQL" w/ semantic queries on an embedding column.
	- ãã†ã‹ã€ã‚„ã£ã±ã‚Š text-to-SQL+semantiãŒæœ€å¼·ãªã®ã‹
- ã€Chain of Empathyï¼ˆå…±æ„Ÿã®é€£é–ï¼‰ã€
	- Yoon Kyung Lee et al., "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"
	- å¿ƒç†ç™‚æ³•ã®ã‚»ã‚ªãƒªãƒ¼ã‚’åæ˜ ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã€Chain of Empathyï¼šCoEã€ã‚’é–‹ç™ºã—ã€ãã®æ€§èƒ½ã‚’æ¤œè¨¼
-  Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
	- https://openreview.net/forum?id=0r5DE2ZSwJ
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹çµæ™¶æ§‹é€ äºˆæ¸¬
	- çµæ™¶æ§‹é€ ã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã—LLaMA-2ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€VAEã®å¾“æ¥æ‰‹æ³•ã‚ˆã‚Šã‚‚å®‰å®šãªçµæ™¶æ§‹é€ ã‚’ç”Ÿæˆã§ããŸ
	- ã“ã®æ‰‹ã®æ‰‹æ³•ã¯ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ãŠé‡‘ã¨æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã“ã‚ãŒèª²é¡Œ
- create-llama, a command line tool to generate LlamaIndex apps
	- https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191
	- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§llamaindexã‚’ã¤ã‹ãŸãŸã‚¢ãƒ—ãƒªã‚’ç”Ÿæˆã™ã‚‹ä»•çµ„ã¿ã®å…¬é–‹ï¼ï¼ï¼
- GPT4ãªã©ãŒã€å¸¸è­˜ã‚’ã‚‚ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã‚‹è©•ä¾¡
	- https://github.com/allenai/everyday-things
	- The LLMs have poor accuracy (54-59%) on commonsense spatial/functional relationships in ParRoT dataset.
	- This suggests the LMs do not have fully coherent conceptual pictures of everyday objects.
- LLMA Factory
	- https://github.com/hiyouga/LLaMA-Factory
	- Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- WebPilot
	- https://chat.openai.com/g/g-pNWGgUYqS-webpilot
	- è¨˜äº‹ã‚„è«–æ–‡ã€PDF ãªã©ã®æŠ½å‡ºç³»ã®ä¾¿åˆ© GPTs ã‚’ä½œã£ãŸã‘ã‚Œã©ã€ã™ã¹ã¦ WebPilot ã§ååˆ†ã ã£ãŸ(ã‚ã“ã‚ã“ã•ã‚“)
- beã•ã‚“ã€æ¯æ—¥ãƒ™ãƒ«ãƒãƒ³æ–¹ç¨‹å¼ã‚’è§£ã„ã¦æ—¥å¸¸ã‚’éã”ã—ã¦ã„ã‚‹ã¨ã€
	- https://x.com/behemuhemulove/status/1724408454348194303?s=20
- ã€HELP MEã€‘Assistants APIã§ç ´ç”£ã—ãã†ã«ãªã£ãŸè©±
	- https://note.com/nike_cha_n/n/n65a6101d59d7
	- ã¡ã‚ƒã‚“ã¨è¨ˆç®—ã—ãªã„ã¨ã‚ã£ã¨ã„ã†é–“ã«ä¸Šé™ã«é”ã™ã‚‹ã‹ã‚‚ã€
- Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion
	- https://arxiv.org/abs/2311.06318
	- MSã‚ˆã‚Š
	- Microsoft Research presents a method to personalize LLMs for search via entity-based user knowledge stores derived from logs.
- YahooçŸ¥æµè¢‹ã€GPT-4ã‚’ç”¨ã„ãŸã€è‡ªå‹•å›ç­”ã‚’ãƒ†ã‚¹ãƒˆä¸­
	- https://chiebukuro.yahoo.co.jp/topic/ai/answer.html
	- äººçŸ¥ã¯ä¸è¦ã«ãªã£ãŸã®ã‹ã€‚ã€‚
-  Trusted Source Alignment in Large Language Models
	- https://huggingface.co/papers/2311.06697
- GPT paper asistantã®ã‚½ãƒ¼ã‚¹
	- https://github.com/tatsu-lab/gpt_paper_assistant
	- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®æ©‹æœ¬å…ˆç”Ÿè¬¹è£½
- Licheng Wen et al., "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving"
	- https://arxiv.org/abs/2311.05332
	- è¦–è¦šã‚’æ‰‹ã«ã—ãŸLLMãŒè‡ªå‹•é‹è»¢ã«ã©ã‚Œã»ã©å½¹ç«‹ã¤ã®ã‹ã‚’æ¢ã‚‹ãŸã‚ã€GPT-4Vã®èƒ½åŠ›ãŒæ¤œè¨¼ã•ã‚Œã¾ã—ãŸã€‚ 
	- ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€ã€Œå› æœé–¢ä¿‚ã®æ¨è«–ã€ã‚„ã€Œã‚·ãƒ¼ãƒ³ï¼ˆæ™¯è‰²ï¼‰ã®ç†è§£ã€ã«é•·ã‘ã¦ã„ã‚‹ã¨çµè«–ã¥ã‘ã‚‰ã‚Œã¾ã—ãŸã€‚
- ã†ã‚‹ã•ã„ã‚„ã¤ã€æŠ€è¡“ã‚’ç†è§£ã—ãªã„ã¨ã€ãƒ“ã‚¸ãƒã‚¹å±•é–‹ã®ãã£ã‹ã‘ãŒå‡ºã¦ã“ãªã„ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’è”‘è¦–ã—ã¦ã€ãã‚Œã‚’å•†å£²ã«ã—ã¦ã„ã‚‹ã®ãŒå«Œã„ã€‚
	- https://x.com/toukatsujin/status/1724196831109017964?s=20
	- ã€ŒæŠ€è¡“åŠ›ã‚’ç£¨ã‹ãªã„ã¨ç”Ÿãæ®‹ã‚Œãªã„ã¨æ€ã£ã¦ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã»ã¨ã‚“ã©ã€‚ã§ã‚‚æŠ€è¡“ã¯æ—¥ã€…é€²åŒ–ãƒ»å¤‰åŒ–ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’å­¦ã¹ã°ä¸€ç”Ÿå®‰æ³°ã¨ã„ã†ã“ã¨ã¯ãªã„ã€‚ã‚€ã—ã‚ãƒ“ã‚¸ãƒã‚¹ç†è§£åŠ›ã‚’ç£¨ã„ãŸã»ã†ãŒä¸€ç”Ÿå®‰æ³°ãªã®ã«ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¤šãã¯åˆ†ã‹ã£ã¦ã„ãªã„ã€
- Rapidly build an application in Gradio power by a Generative AI Agent
	- https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent?hl=en
	- Gradio ã®ä½œè€…ã®åˆã‚ã¦ã®è«–æ–‡ã¨ã„ã†ã†ã‚ã•ã‚‚
- ChatGPTã¨DeepLã®å­—å¹•ç¿»è¨³ã®æ¯”è¼ƒ
	- https://x.com/gijigae/status/1724345403234193540?s=20
	- ChatGPTã¯ã€â‘ è‹±èªå­—å¹•ã‚’ç¹‹ãç›´ã™ â‘¡æ—¥æœ¬èªã«è¨³ã™ â‘¢è¨³ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªæµã‚Œã«ãªã‚‹ã‚ˆã†ã«åˆ†ã‘ã€å…ƒã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¸æˆ»ã™ ã¨ã„ã£ãŸä¸€é€£ã®ä½œæ¥­ã‚’å…¨éƒ¨ã‚„ã£ã¦ãã‚Œã‚‹ã€‚
- GPTsã¨Asistant APIã®é•ã„
	- https://x.com/gijigae/status/1724428173905989945?s=20
	- GPTsã¨Assistants APIã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸChatGPTãŒä½œã‚Œã‚‹ç‚¹ã§ä¼¼ã¦ã„ã‚‹ã€‚ãŸã ã€ChatGPT Plusã¸ã®åŠ å…¥ã‚„ã‚¹ãƒ†ãƒ¼ãƒˆç®¡ç†ã‚’å«ã‚ã€é•ã„ã‚‚å¤šã„â†“ã€‚å¿™ã—ãã¦ä¸€ã¤ã—ã‹è©¦ã›ãªã„ã¨ã„ã†æ–¹ã«ã¯å¾Œè€…ã‚’ãŠå‹§ã‚ã—ãŸã„ã€‚ç‰¹ã«ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸChatGPTã‚’ç”Ÿå¾’ã«å…¬é–‹ã™ã‚‹éš›ã€ChatGPT Plusã¸ã®åŠ å…¥ãŒä¸è¦ã¨ãªã‚‹ã®ã¯å¤§ãã„ã€‚
- ã€Œè¡¨è±¡ï¼ˆrepresentationï¼‰ã€æ¦‚å¿µã‚’åˆ†æã™ã‚‹RPPFãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
	- ç¥çµŒç§‘å­¦ãªã©ã§å¤šç”¨ã•ã‚Œã‚‹ãŒæ›–æ˜§ã§å•é¡Œå«ã¿ã®ã€Œè¡¨è±¡ï¼ˆrepresentationï¼‰ã€æ¦‚å¿µã‚’ã€20ï½30åã®å“²å­¦è€…ã¨ç¥çµŒç§‘å­¦è€…ã§åˆ†æã™ã‚‹ã€ŒRepresentation: Past, Present and Future (RPPF) projectã€
	- https://www.thetransmitter.org/representation/what-are-we-talking-about-clarifying-the-fuzzy-concept-of-representation-in-neuroscience-and-beyond/
- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»è£œå®Œã«ç‰¹åŒ–ã—ãŸæ—¥æœ¬èªLLMã€ŒELYZA-japanese-CodeLlama-7bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ˆå•†ç”¨åˆ©ç”¨å¯ï¼‰
	- https://note.com/elyza/n/n5bce23d7c9c8
	- https://zenn.dev/elyza/articles/fcbf103e0a05b1
- ã‚ãšã‹1åˆ†ã§10æ—¥é–“ã®å¤©æ°—ã‚’äºˆæ¸¬å¯èƒ½ãªAIã€ŒGraphCastã€ã‚’Google DeepMindãŒç™ºè¡¨ã€ã‚¹ãƒ‘ã‚³ãƒ³ã§æ•°æ™‚é–“ã‹ã‘ãŸäºˆæ¸¬ã‚ˆã‚Šé«˜ç²¾åº¦
	- https://gigazine.net/news/20231115-google-graphcast-global-weather-forecasting/
	- https://github.com/google-deepmind/graphcast
- RAG over Governments Document
	- https://github.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Chatting%20with%20your%20Docs.ipynb
- GGUF ç‰ˆã® 5 bit é‡å­åŒ–ã•ã‚ŒãŸ Llama 2 ã‚’ WasmEdge ã§ã€‚7B ãŒ 24 token / sec ã§å‹•ä½œã—ã¾ã—ãŸâ†“
	- https://www.secondstate.io/articles/fast-llm-inference/
	- Mac ãƒ¦ãƒ¼ã‚¶ã¯è¦‹ãŸã‚‰ã¨ã‚Šã‚ãˆãšè©¦ã—ã¦ã€‚ã‚³ãƒãƒ³ãƒ‰ï¼”è¡Œå©ãã ã‘ãªã®ã§ï¼Rust x Wasm ã§ Llama 2 æ¨è«–ãŒãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ãã¾ã™
- ELYZA-japanese-CodeLlama-7b-instructã®ggufãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç‰ˆ
	- https://huggingface.co/mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¯ Copilot Studio ã‚’ç™ºè¡¨
	- Igniteã®ä¸­ã§æœ€å¾Œã«ç™ºè¡¨ã€GPTsã¿ãŸã„ãªã‚‚ã®ã«ãªã‚‹
	- 
- ãŠèŒ¶å¤§ã€ç¥å±±å…ˆç”Ÿã«ã‚ˆã‚‹ã€Googleã®æ°—è±¡äºˆæ¸¬ã®æ°—è±¡å­¦è€…ã‹ã‚‰ã®è§£é¡Œ
	- https://x.com/kohyama_met/status/1724986380546408878?s=20
	- ã€ŒAIæ°—è±¡äºˆå ±è«–æ–‡ã€ã®æ„Ÿæƒ³ã‚’æŠ•ç¨¿ã—ãŸã‚‰æ€ã„ã®ã»ã‹åéŸ¿ãŒå¤§ãã‹ã£ãŸã®ã§ã€æ°—è±¡å­¦è€…ã‹ã¤æƒ…å ±ç§‘å­¦ç§‘æ•™å“¡ã¨ã—ã¦ã€ã„ãã‚‰ã‹çœŸé¢ç›®ã«è§£èª¬ã—ã¾ã™ã€‚
	- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒå¾“æ¥å‹ãƒ¢ãƒ‡ãƒ«ã®ä¸å¾—æ‰‹ã«ã†ã¾ããƒãƒã£ã¦ã„ã‚‹
- Research Assistantã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå…¬é–‹ã•ã‚Œã‚‹
	- https://github.com/langchain-ai/langchain/tree/master/templates/research-assistant
	- With this template you can easily plug in an arbitrary retriever, allowing you to do research over a knowledge base of your choice.
- æ±å¤§ æ¾å°¾ç ”ã®PRMLï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã¨æ©Ÿæ¢°å­¦ç¿’ï¼‰è¼ªèª­ä¼šã‚¹ãƒ©ã‚¤ãƒ‰é›†
	- https://www.slideshare.net/matsuolab/
	- é»„è‰²ã„æœ¬ã¯ã‚„ã£ã±ã‚Šã€è–å…¸
- OpenCopilot
	- https://github.com/openchatai/OpenCopilot
- tldrawãŒæ´’è½ã«ãªã‚‰ãªã„ãã‚‰ã„å„ªã‚Œã¦ã„ã‚‹
	- https://makereal.tldraw.com/
	- ãƒ©ãƒ•ãªUIã®å›³è§£ã‚„èª¬æ˜ã‚’ã¤ãã‚‹ã ã‘ã§ã€GPT-4Vã§èªè­˜ã—ã¦è‰¯ã„æ„Ÿã˜ã«ä»•æ§˜ã‚’è§£é‡ˆã—ã¦å®Ÿéš›ã«å‹•ããƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œã£ã¦ãã‚Œã‚‹
- ç´—ã€…æ°ã€NTTæ­¦è”µé‡é€šç ”ã§é–‹å‚¬ã•ã‚ŒãŸR&Dãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§ã€AIåŒ–ã•ã‚Œã‚‹
	- https://x.com/03sasa03/status/1725479562094755951?s=20
-  OpenAI announces leadership transition
	- https://openai.com/blog/openai-announces-leadership-transition
	- ãˆã£ï¼
	- ã€Œå–ç· å½¹ä¼šã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ä¸€è²«ã—ã¦ç‡ç›´ã•ã‚’æ¬ ãã€å–ç· å½¹ä¼šã®è²¬ä»»é‚è¡Œã‚’å¦¨ã’ã¦ã„ã‚‹ã€
- OpenAIã‹ã‚‰è¿½ã„å‡ºã•ã‚ŒãŸç›´å¾Œã®ã€Sam Altomanã®ãƒ„ã‚¤ãƒ¼ãƒˆ
	- https://x.com/sama/status/1725742088317534446?s=20
	- i love you all.
- è¥¿æµ¦å…ˆç”Ÿã®è«–æ–‡ã«ã€ç­‘æ³¢å¤§ã®æ›è°·æ°ãŒã‹ã¿ã¤ãã‚‚ã€çµ±è¨ˆã®å°‚é–€åŒ–ã‹ã‚‰è¿”ã‚Šè¨ã¡ã«
	- https://x.com/behemuhemulove/status/1725749314000175387?s=20
	- ä¸»ãªå•é¡Œç‚¹ (1) ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®è©•ä¾¡ãªã— (2) çŸ­æœŸäºˆæƒ³ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’ç¹‹ãåˆã‚ã›ã¦é•·æœŸã®ã‚·ãƒŠãƒªã‚ªã‚’ä½œã£ã¦ã„ã‚‹ æ˜æ—¥ã®å¤©æ°—ã‚’é«˜ç¢ºç‡ã§å½“ã¦ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦ã‚‚ã€ãã®äºˆæƒ³ã‚’ç¹‹ãåˆã‚ã›ã€ã€ã€
	- beæ°ã‚ˆã‚Šã€ï¼ˆ2ï¼‰ã¯ä¾‹ãˆã°1å¹´å¾Œã®äºˆæ¸¬ã™ã‚‹ã¨ã—ã¦1ãƒ¶æœˆãšã¤äºˆæ¸¬ã—ã¦ãã®ã‹ã€å¹´å˜ä½ã§äºˆæ¸¬ã—ã¦ãã‹ä½ã®é•ã„ã—ã‹ãªãã€çµ±è¨ˆå­¦ã‚„MLã§ã¯å…¨ãå•é¡Œãªã„ã¨æ€ã†ã®ã§ã€ã“ã®ç‚¹å©ã„ã¦ã‚‹æ–¹ãŒçµ±è¨ˆå­¦ã®è¦³ç‚¹ã‹ã‚‰ç„¡çŸ¥ã«ã¿ãˆã‚‹
-  create-llama ã«ã‚ˆã‚‹LlamaIndexã‚¢ãƒ—ãƒªã®ä½œæˆ by npakaã•ã‚“
	- https://note.com/npaka/n/neafa42455864?sub_rt=share_h
- ä½“è»¸ãŒç›´ç«‹ã—ãŸæ™‚ç‚¹ãŒäººé¡ãŒè‡ªå·±ã‚’èªè­˜ã—ãŸåˆ†å²ç‚¹ã‹ã‚‚ã—ã‚Œãªã„
	- https://x.com/daijapan/status/1725841037086892358?s=20
	- èªçŸ¥ç§‘å­¦è¬›åº§ã‚ˆã‚Šã€
- Building Research Assistant	
	- https://www.youtube.com/watch?v=DjuXACWYkkU
	- YouTube tutorial on building one from scratch. Covers LCEL, LangSmith, parallelization, retrievers
- Ilya Sutskeverã£ã¦èª°ãï¼Ÿ
	- https://x.com/mr_bay_area/status/1725808417376473167?s=20
	- ã€Œè‡ªç„¶è¨€èªå‡¦ç†æ¥­ç•ŒãŒæ·±å±¤å­¦ç¿’ä¸€è‰²ã«ãªã‚‹æµã‚Œã‚’æ±ºå®šã¥ã‘ãŸäººã€ã§ã™ã­ã€‚ãã‚Œãã‚‰ã„å½¼ãŒä½œã£ãŸseq2seqã¯è¡æ’ƒã ã£ãŸã—
- :smile:ã€:ikanai:
	
## 11/13

ä»Šé€±ã¯ã€OpenAI Dev Day(11/6)ãŒå…¨ã¦ã‚ã‚Šã€LLMå‘¨ã‚Šã®é¢¨æ™¯ãŒä¸€å¤‰ã—ãŸã€‚GPT-4 Turboã‚„Assistant APIã‚„ã€ä¾¡æ ¼ã®æ”¹å®šï¼ˆå®‰ããªã£ãŸï¼‰ã€æœ€å¾Œã«ç‹¬è‡ªã®GPTã‚’ã¤ãã‚Œã‚‹GPT Builderã¨ã€OpenAI ã¾ã‚ã‚Šã®OSSã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç ´å£Šã™ã‚‹ãŒã”ã¨ãã®æ€’æ¶›ã®ãƒªãƒªãƒ¼ã‚¹ã€‚å¯¾å¿œã™ã‚‹OSSå´ã®LangChainã‚„llamaindexã‚‚æ–°æ©Ÿèƒ½ã®å–ã‚Šè¾¼ã¿ã‚„å¯¾æ¡ˆå®Ÿè£…ã§å¿™ã—ã„é€±ã ã£ãŸã€‚Assistant APIã£ã¦ã€**Code Interpreter**ã€**Retrieval**ã€**Function Calling**ã€€ãŒå‘¼ã³å‡ºã›ã€APIã‹ã‚‰ã‚‚ä½œã‚Œã‚‹ã‘ã©ã‚‚ã€playgroundã‹ã‚‰ã‚‚ä½œã£ã¦ç°¡å˜ã«è©¦ã›ã‚‹ã€‚Assistant APIã«å®Ÿè£…ã•ã‚ŒãŸæ©Ÿèƒ½(Assistants/Theads/Run )ã‚’çµ„ã¿åˆã‚ã›ã‚Œã°ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚‚ç°¡å˜ã«ä½œã‚Œã‚‹ã€‚è©³ã—ãã¯Nakajimaã•ã‚“ã®GPTvsGPTãŒè‰¯ã„ä¾‹ã€‚ç„¡é™ã«ç’°å¢ƒå•é¡Œã«ã¤ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒè¨è«–ã™ã‚‹ã¨ã„ã†ãƒ‡ãƒ¢ã¯ã¡ã‚‡ã¨åœ°ç„çµµã€‚æ—©é€Ÿã€LangChainã‚‚ã€LlamaIndexã‚‚ã€Assistant APIã‚’ã¤ãã£ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚‹æ©Ÿèƒ½ã‚’å…¬é–‹ã€ã‚‚ã¨ã‚‚ã¨ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨çµ„ã¿åˆã‚ã›ã¦ã¿ãŸã„ãªç™ºå±•ã‚‚ã€‚OpenAI ã®Retreiveæ©Ÿèƒ½ã¯ã€pdfã‚„docã‚„pptã‚„markdownç­‰å¤šå½©ãªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚“ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦Chatã§ãã‚‹æ©Ÿèƒ½ã€‚ã¾ã•ã«ã€RAGã¤ã¶ã—ãªã‚“ã ã‘ã©ã‚‚ã€llamaindexã®äººJerry Liuã«ã‚ˆã‚‹ã¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®é™ç•Œã‚’è¶…ãˆã‚‹ã¨æ™®é€šã®top-kå¼ã®å˜ç´”ãªRAGãŒå‹•ã„ã¦ã„ã‚‹ã®ã§ã¯ã¨ã„ã†ã“ã¨ã€‚è©¦ã—ã«ãƒŠã‚¦ã‚·ã‚«(Wikipediaã€57kãƒˆãƒ¼ã‚¯ãƒ³)ã‚’GPT-4ã§ã‚„ã£ã¦ã¿ãŸã‚‰ã€ç¢ºã‹ã«æ€§èƒ½ã‚ˆã‹ã£ãŸã€‚RAGã«ã¤ã„ã¦ã¯è‡ªã‚‰ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®æ–¹æ³•ãªã©ã®ï¼‰ç´°ã‹ã„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«èµ°ã‚‹ã‹ã€ãã‚Œã¨ã‚‚å…¥ã‚Šå£ã ã‘ç”¨æ„ã—ã¦ã‚ã¨ã¯ã€åˆ¥ã®OSSç­‰ã«ã¨ã„ã†æˆ¦ç•¥ã®ã©ã¡ã‚‰ã ã‚ã†ï¼ŸGPT-4ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãŒã€$3M(ï¼•å„„å††å¼±)ã®[Submit]ãƒœã‚¿ãƒ³ã¯æŠ¼ã›ãªã„ã€‚ã€‚GPT-4ã‚’åŠç«¯ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚æ€§èƒ½ã¯å‘ä¸Šã—ãªã„ã¨ã„ã†ã®ã‚‚ã™ã”ã„ãªã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆæ”¯æ´ã‚‚ã€llamaindexã‹ã‚‰builder agentã€Langchainã‹ã‚‰ã‚‚ã€OpenGTPãŒç™ºè¡¨ã€‚OpenAIæœ¬å®¶ã‚‚GPTsã§ã€å¥½ã¿ã®GPTã‚’ä½œã£ã¦å…¬é–‹ã¨ã„ã†æ©Ÿèƒ½ãŒå…¬é–‹ã€Plusãƒ¦ãƒ¼ã‚¶ãƒ¼ãªã‚‰ä»–äººã®GPTã‚’ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«ã€ã©ã‚“ã©ã‚“ã€ç‹¬è‡ªã®GPTãŒå…¬é–‹ã•ã‚Œã¦ã€ã¾ã•ã«ç™¾èŠ±ç¹šä¹±ã€ã“ã‚Œã«åˆ©ç”¨æ–™ã‚’é‚„æµã™ã‚‹ä»•çµ„ã¿æ•´ãˆã°ã€ã¾ã•ã«ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ãƒ¼ã‚¹çµŒæ¸ˆåœã«ä¸€ç›´ç·šã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®RAGã¨ã„ã†ã®ã‚‚å‡ºã¦ããŸã€‚PFNã®PLaMo-13B-Instructã®å…¬é–‹ã‚„ã€æ—¥æœ¬èªå‘ã‘ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®æ”¹å®šã‚„ã€shi3zã•ã‚“ã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ—¥æœ¬èªä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´å‚™ãªã©ã€æ—¥æœ¬èªå¯¾å¿œã®æ”¹è‰¯ã‚‚ç€å®Ÿã«é€²ã‚“ã§ã„ã‚‹ã€‚ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚¢ AIã®æ¬¡ã«æ¥ã‚‹ã‚‚ã®ã€ã®ãƒ€ã‚¤ã‚½ãƒ³ã«ã‚ˆã‚‹ã¨ã€LLMã¯ã€ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹AIã®é™ç•Œã‚’è¶…ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ï¼‰ã‚¢ãƒŠãƒ­ã‚°ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«è¿‘ã„ã‚‚ã®ã‚‰ã—ã„ã€‚ãƒ€ã‚¤ã‚½ãƒ³ã®æœ¬ã‚’èª­ã¿ãªãŠã™ã¨ã€AGIã®å¯èƒ½æ€§ã«ã¤ã„ã¦ã‚‚ã€ãƒ‡ã‚¸ã‚¿ãƒ«ã§ã¯åˆ°é”ã§ããªã„ãŒã€ã‚¢ãƒŠãƒ­ã‚°ãªã‚‰ã°å¯èƒ½æ€§ã¯æ’é™¤ã§ããªã„ã¿ãŸã„ãªä¸»å¼µã ã£ãŸã€‚æœ€å¾Œã«ã€ChatGPTã®ç™»å ´ã¯ã€ãƒ‡ã‚¶ã‚¤ãƒŠã‚„ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®è·ã‚’å¥ªã†ã ã‘ã§ãªãã€å˜ä¾¡ã‚‚ä¸‹ã’ãŸã€ç‰¹ã«é«˜åå…¥ã®å±¤ã‚’ã€ã¨ã„ã†FTã®è¨˜äº‹ãŒæ€–ã™ãã‚‹ã€‚

- ALMA-7B-Ja-V2
	- https://huggingface.co/webbigdata/ALMA-7B-Ja-V2
	- ç¿»è¨³ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã®ALMA-jaã®V2æ¥ã¨ã‚‹ï¼!GPTQã‚‚ã‚ã‚‹
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT
	- Microsoftã‹ã‚‰ç™ºè¡¨ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ã‚¹ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€Œãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã™ã‚‹ãƒ¢ãƒ‡ãƒ«Table-GPT
	- å¤šæ§˜ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ã‚¹ã‚¯ã«ã¦GPT-3.5ã‚„ChatGPTã‚ˆã‚Šé«˜æ€§èƒ½ã€é«˜ã„æ±ç”¨æ€§ã‚’ç¤ºã™
	- https://arxiv.org/abs/2307.08674
- OpenAI dev day
	- GPT-4 Turbo ç™ºè¡¨ 
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·128k
	- JSON Mode 
	- ãƒŠãƒ¬ãƒƒã‚¸ã‚«ãƒƒãƒˆã‚ªãƒ• 2023/04
	- DALL E-3 / Text to Speech 
	- Whisper v3 
	- GPT-4 Fine-tuningå¯èƒ½ã«
	- GPT-3.5 Turbo ã¯ã‚‚ã† 16K ãŒãƒ‡ãƒ•ã‚©ãƒ¬ãƒ™ãƒ«ã§ã•ã‚‰ã«å®‰ããªã‚Šã€GPT-4 Turbo ã¯ä¾¡æ ¼ãŒå…¥åŠ› 1/3, å‡ºåŠ› 1/2 ã«ãªã£ãŸ
	- ã€Œå¾“æ¥ã®16å€ã¨ãªã‚‹300ãƒšãƒ¼ã‚¸ã‚’è¶…ãˆã‚‹é•·ã„æ–‡æ›¸ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã€2023å¹´4æœˆã¾ã§ã®æƒ…å ±ã‚’åæ˜ ã€
	- functionsã¨function_callãŒéæ¨å¥¨ã«ãªã£ã¦toolsã¨tool_choiceã«ãªã£ãŸã‚“ã 
- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã€ŒChatGPTã€ã®ã‚«ã‚¹ã‚¿ãƒ ç‰ˆã‚’ä½œã‚Œã‚‹ã€ŒGPTsã€ã€æœ‰æ–™ä¼šå“¡ã«æä¾›ã¸
	- https://www.itmedia.co.jp/news/articles/2311/07/news074.html
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã®æŒ‡ç¤ºã§å¯¾è©±ã—ãªãŒã‚‰ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ChatGPTã‚’æ§‹ç¯‰ã§ãã‚‹ã€‚ã€ŒWebæ¤œç´¢ã‚„ç”»åƒä½œæˆã€ãƒ‡ãƒ¼ã‚¿åˆ†æãªã©ã¨åŒã˜ãã‚‰ã„ç°¡å˜ã€ã¨ã—ã¦ã„ã‚‹
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
	- https://huggingface.co/papers/2311.02303
	- MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, CodeFuse-CodeLLama-34B, achieves an impressive pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\%, zero-shot).
- Assistants API ã®è§£èª¬ã¨å‹•ä½œç¢ºèªï¼ˆGoogle Colabï¼‰
	- https://note.com/schroneko/n/nd04c46242171
- llamaindexã‹ã‚‰ã€OpenAI dev dayã‚’ã†ã‘GPT builderã‚’æ¨¡æ“¬ã™ã‚‹Builder Agentã®ä¾‹ã‚’å…¬è¡¨
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb
	- https://x.com/jerryjliu0/status/1721639447207583882?s=20
	- ä¾‹ï¼šã€Œãƒˆãƒ­ãƒ³ãƒˆã®ã“ã¨ã‚’ã‚ˆãã‚ã‹ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã€â†’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã§ãã‚‹ã€‚ã€‚
- LangChainã‹ã‚‰ã€OpenGPTã®ç™ºè¡¨ã€
	- https://github.com/langchain-ai/opengpts
	- builds upon LangChain, LangServe an
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEyODE3OTA3OCwtNTQwNjAwNzc2LDE3Mz
YyMDgxMDksMjEwMzYwMTYzOSwtMTQ0MDgzMTkwLC01NTc5MDU4
MDAsLTIwNTE2NTEyMjIsNzkzMTQyNjQsNTE5NDcxNzA2LC0xOD
UyNzIxMjM1LC0xNTc2MTY3NTIzLDEzNDc2OTkyNTAsNTM1NDE2
NjIwLDExMzAyOTgwMzIsMTczNTExMzQzNSwtMjkxMTQ1OTk1LC
0xMzcxMzk1NjA0LC0xMjAxNjkyOTY0LDE5NDA0MzgzNjksLTE3
NTkzODE0NTVdfQ==
-->