# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。


## 24/7/1

- 小町先生の、「言語系AIプロジェクトの進め方」がよいらしい
	- https://x.com/mr_bay_area/status/1804689914291957983
- Questions at academic conferences
	- https://x.com/jayvanbavel/status/1801961592654815489
-  LLMatDesign: Autonomous Materials Discovery with Large Language Models
	- https://arxiv.org/abs/2406.13163
	- LLMによるAIエージェントの論文
	- バンドギャップの計算データを学習したモデルとLLMからAIエージェントを構築。「バンドギャップ1.4eVの材料は？」だけでなく「Baを使用しないで指定の材料を1.4eVになるよう改良して」などの指示もうまくいくようです。
- Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?
	- https://arxiv.org/abs/2406.13121
	- Google DeepMindによる報告。
	- 「巨大なコンテキストウィンドウのLLMはRAGを不要にするのか？」といった議論が活発化する中、Geminiに長いコンテキストを挿入してRAGと性能を比較する実験が行われました。
	- その結果、やはりロングコンテキストLLMは一定のパラダイムシフトをもたらす可能性を示唆しています。 
	- さらにRAGだけでなくText to SQLタスクのパフォーマンスも調査されています。
- This is fast. Chrome running Gemini locally on my laptop. 2 lines of code.
	- https://x.com/mortenjust/status/1805190952358650251
-  Claude’s Constitution
	- https://www.anthropic.com/news/claudes-constitution
	- Anthropic Constitutional AI （憲法的AI）を導入　by   AI𝕏サトシさん
		- https://x.com/AiXsatoshi/status/1804999143586402460
		- 「Constitutional AI」は、AIモデルが自己評価と調整を行う新しいトレーニング手法
		- 国連の世界人権宣言などに基づく原則を参照、人間の介入を減らすことで有害な出力を避けるAIを構築。これにより、トレーニング効率とモデルの信頼性が向上する
- 

## 24/6/24

今週はすべてを吹っ飛ばして、Anthropicが突然発表したClaude 3.5 Sonnetでしょう。Claude 3 Opusの2倍の速度でこれまでの5分の1のコストというのもすごいのですが、新しいアプリ開発環境Artifactsを使って、人間と対話しながらあっという間に、 スライド生成 、webUI生成 、スマホUI生成 、フローチャート生成、簡易ゲーム生成、ほぼ完ぺきなシフト管理システムの作成、WebGLをつかたった可視化プログラムの生成、様々な事例が発表されお祭り状態に。無料でArtiffactsは試せて、例えば、この文章からスライドを作ったり、LLMに関する知識グラフを生成したりとか、空から降ってくるトピックワードを打ち落とすゲームさえできる。生産性向上とか改善とか、もう全部、Claude 3.5 Sonnetで上書きされる感じ、逆に、これが使いこなせる人材しか残らない。でもこれSonnetなんですよ、Opusってどうなるんでしょうか。Googleからは、患者とのやり取りで人間の医師を超えるというAMIE(Articulate Medical Intelligence Explorer )の発表や、高精度天気予報「ナウキャスト」を日本でウェザーニュースのデータで学習して提供とか、Gemini1.5ProとGemini1.5FlashのAPIでコンテキストキャッシュ機能のリリース等がありました。Geminiの公式 noteシリーズ開始とか、着実にすそ野も広めてて好感が持てる。傘下のDeepMindからvideo-to-audio (V2A)が発表され、先週のLuma AIと合わせれば、ショートフィルムは作れそうな勢い。さて、Metaからは、ミックスモーダルなChameleonや、音声がAI製かどうかを見破れるモデルなどの複数のモデルの発表、どのような評価や方向性になるのか来週以降期待。先週話題となった、Nemotron-4-340B-Instruct、評価などがぼちぼち、うみゆきさんがShaberi3ベンチにかけてみたら、平均スコア8.05で、Gemini1.5Pro（8.01）以上、GPT-4o（8.16）以下とのこと。またテクニカルノートによると98%の事後学習のデータは合成データをつかっているとのこと、さすが合成データを作るのが得意なNemotronの面目躍如、いや、そのデモだったのかも。無料のPlaygroundで合成データをコチコチ作るという手もありそうだ。ローカルLLMでは、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」が、製作費75万円ということで話題になりましたが、なんといっても、Chrome で動く Gemini Nano、Chrome開発版では利用可能になっているとのこと、さっそくnpakaさんが動作事例を紹介。ブラウザ組み込みでっせ、javascriptからたたけるんでっせ。shi3zさんの解説によると、KARAKURIが低予算でLLMを作れたからくりは、AWS Trainiumの利用とのことで、また、先週紹介のあった、MoA(Mixture of Agent)や、LLMのマージ技術により、手軽に誰でも高性能なLLMを構築できるようになった、確変の時代きたるという記事はしびれる、そうか、データはNemotronで合成されればよいのか、どんなLLMがshi3zさんのGPUマシンから出てくるのか楽しみです。理論面では、LLMが事前学習時に事実的知識を獲得する様子の分析論文や、Transformer のコンポーネントか始まって最終的な表現型に近い現象挙動までつながる様子をほぼ明らかとする解説記事とか、LLMの振る舞いの理論的な解析も着実にすすんでいます、説明性の向上に期待。応用面のRAGも忘れてませんよ、知識グラフとの統合とか、「KARAKURI LM 8x7B Instruct v0.1」ってRAGに対応と明示してあったりと、今週もいろいろありましたが、ここは基本戻って、 LangChain で RAGのハイブリッド検索なんかやらせてみて、正気を取り戻しましょう。さて、Claude 3.5 Sonnetの能力を見てると、「まだLLMで驚けるんだ」という(メタな）驚きから、それって、人ってそんなに沢山いらないかも、というのが確信になりつつあります。BBCで紹介された、60人いたライターと編集者が職を失い、ChatGPTの出力を手直しする一人のテクニカルライターに置き換えられたという話題もインパクトありましたが、Claude 3.5 SonnetやGPT-4o級ならそうなるかも。いや、バージニア大学の先生のいう「生産的に愚かになる」ってのは、LLMにはまだ無理かな、と信じたいところです。

- いつの間にかStable DiffusionがDiffusion Modelではなくなっている！？（バックボーンがDiffusion Transformerだからセーフ？）
	- https://x.com/shion_honda/status/1802386378874835056
- WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild
	- https://arxiv.org/abs/2406.04770
	- 100万件におよぶ人間とLLMの会話履歴をもとに作成した、現実ニーズに則する1,024のタスクでモデルを評価する手法『WildBench』が公開されています。
	- 「人間が実際に投げるタイプのタスク」における40種類のモデルの性能は興味深いものとなっています。
- DeepSeek-Coder-V2
	- https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct
	- 236B Mixture-of-Experts（MoE） 6T tokensの事前学習 サポートする言語は338 コンテキスト長も16Kから128Kに
	- 標準的なベンチマーク評価で、GPT4-Turbo、Claude 3 Opus、Gemini 1.5 Proなど2を上回る性能
-  AI took their jobs. Now they get paid to make it sound human
	- https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human
	- 60人いたライターと編集者が職を失い、ChatGPTの出力を手直しする一人のテクニカルライターに置き換えられたという話題
	- AIの出力を人間っぽくするために少数の人間が雇われる流れがもう加速している
- The importance of stupidity in scientific research
	- https://web.stanford.edu/~fukamit/schwartz-2008.pdf
	- 「愚かさ」は、科学者が重要な質問をしていることを示す兆候であるとされています。著者は、学生が「生産的に愚かになる」方法を教えるための提案で論文を締めくくっています。
- Nemotron 340B Technical Report
	- https://x.com/_philschmid/status/1802617332893729029
	- Implementation
		- Pretraining: 2-phase pretraining, first trained on 8T and then continued on 1T higher quality tokens and Instruction data with a steeper slope of learning rate decay. 
		- Fine-tuning: First fine-tuned on 800K coding samples, followed by 200K diverse task samples. 
		- RLHF: Applied Direct Preference Optimization (DPO) followed by Reward-aware Preference Optimization (RPO) on multiple iterations.
	- Insights
		- 98% of data used in post-training was synthetically generated
		- Pretraining data: English data (70%), Multilingual data (15%), Source code (15%).
		- Trained on 6144 H100 GPUs with 8-way TP, 12-way PP with interleaving and DP to achieve ~42% MFU
		- Only used 20k Human annotated data mostly for Reward Modeling
		- Detailed Synthetic Data pipeline instruction including all prompts to generate data
- DeepMind　からvideo-to-audio (V2A) generative technology. 
	- https://x.com/GoogleDeepMind/status/1802733643992850760
	- It can add sound to silent clips that match the acoustics of the scene, accompany on-screen action, and more.
- How Do Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://arxiv.org/abs/2406.11813
	- Reveals several important insights into the dynamics of factual knowledge acquisition during pretraining
- Nemotron-4-340B-InstructのAPIをさっそくShaberi3ベンチにかけてみたら、平均スコア8.05！Gemini1.5Pro（8.01）以上、GPT-4o（8.16）以下！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1803112240935260328
- Building Advanced RAG with Knowledge Graphs
	- https://x.com/llama_index/status/1803082001538535703
	- This 60 minute webinar is a must-watch if you’re looking to apply the latest techniques combining LLMs with knowledge graphs.
-  Creativity Has Left the Chat: The Price of Debiasing Language Models
	- https://arxiv.org/abs/2406.05587
	- アラインメントされると大規模言語モデルは創造性を失う RLHF などの有害な生成を防ぐためのアラインメント技術によって、LLM の創造性(多様性)が減少する。例えば生成文をクラスタ分析すると、アラインメントされたモデルでは明確なクラスタ形成され偏りがあることが分かる
- I have lots of thoughts on "agents"!
	- https://x.com/hwchase17/status/1803089961245348125
	- spotify での配信付き
- today at Meta FAIR we’re announcing four new publicly available AI models
	- https://x.com/AIatMeta/status/1803107817345393136
	- Meta Chameleon
		- 7B & 34B language models that support mixed-modal input and text-only outputs.
		- これはテキストや画像を入力するとテキストや画像を出力できるモデル！
	- Meta Multi-Token Prediction
		- Pretrained Language Models for code completion using Multi-Token Prediction.
		- マルチトークン予測の7Bモデル！普通のLLMは1トークンずつしか出力できないけど、これは複数のトークンをまとめて出力できて速い
	- Meta JASCO
		- Generative text-to-music models capable of accepting various conditioning inputs for greater controllability. Paper available today with a pretrained model coming soon.
		- これはコードやらビートを指定して音楽生成できるらしい
	- Meta AudioSeal
	-  	An audio watermarking model that we believe is the first designed specifically for the localized detection of AI-generated speech, available under a commercial license.
	- 音声がAI製かどうかを見破れるモデル
- Firefunction-v2
	- https://x.com/LangChainAI/status/1803083016715289045
	- Llama 3 fine-tuned for tool calling / agents
- 直感的に理解するConformal Prediction
	- https://speakerdeck.com/masatoto/zhi-gan-de-nili-jie-suruconformal-prediction
	- 分類問題における確信度の高い結果だけを返すのではなく，予測集合を返す方法.予測集合に真の結果が含まれることを確率的に保証.
- What is a Mixture-of-Experts (MoE)
	- https://x.com/akshay_pachaar/status/1803043120654983424
	- A Mixture of Experts (MoE) is a machine learning framework that resembles a team of specialists, each adept at handling different aspects of a complex task.
	- It's like dividing a large problem into smaller, more manageable parts and assigning each part to a different expert.
- 合成データ作り放題でおなじみのNemotron、APIとかあるのね
	- https://x.com/umiyuki_ai/status/1803078912051986714
	- ログインすれば無料で1000回まで叩けるらしい。課金とかはまだ無いぽい。課金してでも叩きたい人多そうだけど。Playgroundでチャットするだけならクレジット減らないっぽいから頑張れば合成データ収集できるかも
- Gemini1.5ProとGemini1.5FlashのAPIでコンテキストキャッシュ機能がリリース
	- https://x.com/umiyuki_ai/status/1803127902533460149
	- https://ai.google.dev/gemini-api/docs/caching?lang=python&hl=ja
	- 要するにKVキャッシュを保存したりロードしたりする機能。API無料枠のユーザーでもFlashでコンテキストキャッシュを最大100万トークン活用可能！32k以上のコンテキストでキャッシュが使用できる
- How Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://x.com/hoyeon_chang/status/1802952064726622671
	- 著者のツイート、I’m thrilled to announce the release of my new paper!
	- This research explores how LLMs acquire and retain factual knowledge during pretraining. Here are some key insights:
	- LLMが事前学習時に事実的知識を獲得する様子を、事実の対数尤度で評価した場合、知識に触れるたび少しだけ上昇し緩やかに下がり元に戻る。忘れるより先にまた知識に触れることを繰り返し閾値に達すると回答できるようになる。by 岡野原さん
-  Google の AI 「Gemini」、公式 note はじめます
	- https://note.com/google_gemini/n/nc53d2b6f4a08
	- 新機能の紹介やイベント レポート、開発者の話など、Gemini にまつわるさまざまな情報やニュースをお届けします。
- 「ChatGPTって、自分の「境界」を持っていませんよね。
	- https://x.com/ShigeruTaguchi/status/1803044441680412775
	- だからパースペクティブを持てないというか。……身体性って、たしかに単に物理的な肉体を持つということだけではないけれど、自分に固有の境界を持っていて、そこからしか発生しないパースペクティブを持つというのは大事だと思うんです。
- Gemini について全部解説！ 使い方やモデル、プランまで
	- https://note.com/google_gemini/n/ncd7557d98d07?sub_rt=share_b
-  OpenAIとGoogleが火花　マルチモーダル、エージェント…生成AIの今 by 今井さん
	- https://xtrend.nikkei.com/atcl/contents/casestudy/00012/01473/?n_cid=nbpnxr_twed_cms
	- 結論だけ言うと「長期的にはGoogle有利」です。
-  LangChain で RAGのハイブリッド検索 を試す by npakaさん
	- https://note.com/npaka/n/n6782314fb471?sub_rt=share_h
	- 「RAG」のハイブリッド検索は、複数の検索方法を組み合わせる手法で、主に「ベクトル検索」と「キーワード検索」を組み合わせて使います
-  Fine Tuning MistralAI models using Finetuning API
	- https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/mistralai_fine_tuning.ipynb
-  LLM の仕組みを押さえればさらに生成 AI を活用できる
	- https://note.com/google_gemini/n/n51d9f3b97470?sub_rt=share_b
	- 言語モデルが行なっていることは「文脈を踏まえて文の続きを予測」すること
	- LLM の仕組みを踏まえると、生成 AI の特徴がより理解できる
	- より長い文脈を踏まえて「文の続きを予測」できることで、より進化していく
	- マルチモーダル モデルを使いこなす！
- Ilya Sutskeverが安全な超知能を目標とするSafe Superintelligence Inc.設立!
	- https://x.com/bioshok3/status/1803475573030920310
- グーグル、12時間先まで5分刻みで降雨予測する「Google ナウキャスト」
	- https://www.watch.impress.co.jp/docs/news/1601121.html
	- Google ナウキャストでは、6時間先までの降雨予測をGoogle 検索の結果に表示し、さらに12時間先までの予測を文字情報で表示。5分単位の詳細な雨量予測が可能となる。雨だけでなく雪の予測も行なう。
	- 高精度天気予報「ナウキャスト」日本で提供　ウェザーニュースのデータで学習したAI採用
- Google researchers developed the Articulate Medical Intelligence Explorer (AMIE),
	- https://www.deeplearning.ai/the-batch/amie-a-chatbot-that-outperforms-doctors-in-diagnostic-conversations/?utm_campaign=The%20Batch&utm_content=297333022&utm_medium=social&utm_source=twitter&hss_channel=tw-992153930095251456
	- AMIE, a chatbot that outperforms doctors in diagnostic conversations
- Kolmogorov Arnold Network” is one of the best innovations of 2024
	- https://x.com/predict_addict/status/1803323909233668281
	- “Kolmogorov–Arnold-Informed neural network: A physics-informed deep learning framework for solving PDEs based on Kolmogorov–Arnold Networks”
- Chrome で Gemini Nano を使用する
	- https://developer.chrome.com/docs/ai?hl=ja
- Transformerの次のアーキテクチャとして期待されているMambaを使った音声分類モデル、Audio-MambaのFine-Tuningを試してみました
	- https://x.com/AIShift_PR/status/1803349519532531817
-  A Primer on the Inner Workings of Transformer-based Language Models
	- https://arxiv.org/abs/2405.00208
	- Section 2→5に進むにつれてTransformerのコンポーネント内の局所的な挙動から始まってより最終的な表現型に近い現象の説明まで，これまでの大量の知見がまとまっています
	- Transformer の挙動はほぼ明らかになってると思っていて、まだ明らかになってないことはモデルというより言語の性質が原因な気がする（素人の勘）
- きたあああああああああああああああああああああああああああああああああああああ！！
	- https://x.com/lemilemilemio/status/1803607874079432959
	- Anthropic社は突如として"Claude 3.5 Sonnet"をリリース
- 国産LLM初、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」を一般公開
	- https://prtimes.jp/main/html/rd/p/000000089.000025663.html
	- Function callingとRAGに対応した「KARAKURI LM 8x7B Instruct v0.1」を公開いたします
	- 本対応により、「KARAKURI LM 8x7B Instruct v0.1」は様々なアプリケーションを人間に代わって操作するAIエージェント※2 としての活用が可能です
- Anthropic社は突如として"Claude 3.5 Sonnet"をリリース
	- https://x.com/ctgptlb/status/1803822932831166712
	- 現状最強だったGPT-4oの性能を上回る上に、Claude 3 Opusの2倍の速度でこれまでの5分の1のコストに
	- また新しく、"Artifacts"という新機能が登場。Xで早速Artifacts機能のすごい事例が報告されています
- Claude3.5Sonnet　不都合日、休日担当数の公平性、当直日の間隔などを考慮してほぼ完璧なシフトを組んでくれます
	- https://x.com/genkAIjokyo/status/1803905958776836356
	- ついに...人間が当直表、待機表、シフトの作成から解放される日が！
	- このタスクはGPT4o、Claude3Opusでも少し修正必要だったのでClaude3.5Sonnetかなり優秀...
- Claude 3.5 sonnetとArtifactで出来ること。by 元木さん
	- https://x.com/ai_syacho/status/1803822100186058831
	- 1. スライド生成 
	- 2. webUI生成 
	- 3. スマホUI生成 
	- 4. フローチャート生成 
	- 5. 簡易ゲーム生成
-  Evaluating the World Model Implicit in a Generative Model
	- https://arxiv.org/abs/2406.03689
	- New paper: How can you tell if a transformer has the right world model?
	- We trained a transformer to predict directions for NYC taxi rides. The model was good. It could find shortest paths between new points
	- The map let us visually inspect the incoherent world model. But how should we evaluate world models in non-map settings?
- 国産LLM初、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」を一般公開
	- https://karakuri.ai/seminar/news/karakuri-lm-8x7b-instruct-v0-1/
	- 本モデルはトレーニングコストを最大50%削減できるといわれているAWS Trainiumを活用しており、開発費用は75万円です。
	- デモ（期間限定）
		- https://lm.karakuri.cc/
-  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention
	- https://arxiv.org/abs/2404.07143
	- Infini-attentionは、トランスフォーマーベースのLLMsが無限に長いコンテキストを処理できるようにする新しい手法
	- 従来の注意メカニズムが長いシーケンスを処理する際に直面するメモリと計算負荷の問題を解決
- 加熱するLLM開発競争に冷や水、オープンモデルの組み合わせだけでGPT-4o越えの事実 by shi3zさん
	- https://wirelesswire.jp/2024/06/86709/
	- この最新のLLNは、日本語向けオープンLLMとしては初の「命令実行」チューニングを施されている
	- Karakuriはこんな低予算で日本語最高性能のエージェントLLMを作ることができたのか。それはNVIDIAのGPUを使っていないからだ。
	- 二週間ほど前に発表された「[Mixture-of-Agents](https://arxiv.org/abs/2406.04692)(エージェントの合成)」という論文がある。
	- すでに公開されているオープンLLMを8つ組み合わせて使うだけで、GPT-4o単体の性能を上回るベンチマーク結果となったと主張している。
	- LLMの組み合わせによってGPT-4oと同等の性能だが計算効率は圧倒的に高いMoA-Liteと、GPT-4oより計算量も少なくさらに高性能なMoAの二つが提案された。
	- 世界中の大企業が何千億、ひょっとしたら合計して何兆円という金額をGPUに浪費している間に、強かな人たちは既存の技術の手軽な組み合わせで大きな進歩を成し遂げようとしている。
	- 筆者(shi3zさん)も早速、日本語のオープンLLMをMixture-of-Agentsで組み合わせを試すつもりだ。  
	- これとDiscoPOPを組み合わせて、日本語LLMの最適な組み合わせをGPTまたはLLM自身に評価させるというのも面白い。
-  Claude 3.5 Sonnet の概要 by npakaさん
	- https://note.com/npaka/n/n7c8e19914166
	- 大学院レベルの推論 (GPQA)、学部レベルの知識 (MMLU)、コーディング能力 (HumanEval) において、新たな業界基準を設定しました。ニュアンス、ユーモア、複雑な指示の把握において顕著な改善が見られ、自然で親しみやすい口調で高品質のコンテンツを書くことに優れています
	- 指示に従って[適切なツールが提供されれば](https://www.anthropic.com/news/tool-use-ga)、高度な推論機能とトラブルシューティング機能を使用して、コードを独自に記述、編集、実行できます。コード変換も簡単に処理できるため、レガシーアプリケーションの更新やコードベースの移行に特に効果的です。
	- 「**Artifacts**」は、ユーザーがClaudeとやり取りする方法を拡張する新機能です。ユーザーがClaudeにコード、テキスト、Webサイトデザインなどのコンテンツを生成するように依頼すると、これらのArtifactsが会話の横にある専用ウィンドウに表示されます。
	- Anthropicのレッドチーム評価では、「Claude 3.5 Sonnet」はASL-2のままであると結論付けられました。
-  Claude 3.5 Sonnet の評価に関する備忘録
	- https://tech.algomatic.jp/entry/papers/anthropic-2024-claude35
	- 論文にあった、様々なデータセットでの具体的な性能を例示している
	- Artifacts — a new way to use Claude
		- https://www.youtube.com/watch?v=rHqk0ZGb6qo&t=4s
- インドの物理学者がひも理論の研究から偶然「円周率」の新しい公式を発見
	- https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.132.221601
- VLSIシンポジウムではMediatakのLLM向けモバイルプロセッサの発表が迫力あった by 竹内さん
	- https://x.com/kentakeuchi2003/status/1804713977886425509
	- エッジAIにもLLMが来るぞ、というよりも、もう来ているという感じ。
- Claude 3.5 使ったら 5分ぐらいで抽象言語パッケージマネージャーGrimoのフロントエンドモック出来てしまった
	- https://x.com/ai_syacho/status/1804400108664189260
- Claude able to produce simulated 3d physics using WebGL
	- https://x.com/Hamptonism/status/1804496837216227756
- Magpieという手法をNemotron-4-340B-Instructに適用し、日本語ロールプレイ用instructionの合成データセットを作成してみました。
	-	https://x.com/Aratako_LM/status/1804817272911138909
	-	特にフィルタ等していない生のデータですが、合成データとしてはかなり質が高そうです。（流石Nemotron-4）
-	Chrome の Gemini Nano を試す by npakaさん
	-	https://note.com/npaka/n/n17176250330e?sub_rt=share_h
	-	「Chrome」の「Gemini Nano」の早期アクセス版が使えるようになりました。
	-	テキスト生成
	-	(1) メニュー「表示 → 開発/管理 → JavaScriptコンソール」でコンソールを表示。
	-	(2)いかがコードのイメージ
		-	const canCreate = await  window.ai.canCreateTextSession();
		-	const session = await  window.ai.createTextSession(); 
		-	const result = await session.prompt("まどか☆マギカでは誰が一番かわいい?");
		-	console.log(result);

## 6/17

今週は、WWDCで始まった。アップル本社上空からパラシュートで降りるオープニングから、クレイグ副社長の謎の運動能力のデモ、OpenAIのアルトマン氏目撃情報がAppleキャンパスの現地から多数など話題に事欠かない。Apple IntelligenceはApple製品にLLMがシームレスに組み込まれ、UXとしての雄の貫録を、Ferret-UI論文も併せて見せた。Siriも、シームレスとはいえないまでも、GPT-4oにつながる、今年末にはリリース。実は、ローカルな3BのLLM、セキュアなサーバー環境(Mシリーズが動く）でのLLMという独自のLLMがＵＸを起点にシームレスに展開されている、開発にあたりAI原則も独自に作っている。Google寝てましたか？というコメントもあったが、Appleも、このLLMの活用では他社と同じような展開しかできておらず、結局、顧客が不要な技術を買うことになっていると厳しい意見もあった。さてGoogleは、Gemini 1.5 Flashの評判も高く、議事録作成は相当こなせそう、Chromeで、ブラウザ上でGemini Nanoが動くようになるらしい、RecurrentGemma-9bも、新しいリカレントアーキテクチャを採用することで、より効率的かつ高性能な言語処理を実現したというが、どうやら動作が安定してきている模様。DeepMindの、LLMの知識不足（ハルシネーション）を確かめる方法というのも、面白いが、人間にも適用できそうだ。DreamMachineから出たLuma AIは不気味を超えている、デート中にほかの子に気をそらされる男の子とか、写真をもとに動画をつくるということで、奥さんの若いころの写真から動画を作ったりと、まさに不気味な感じ。あまりにも自然なので、もっとも厄介なのは、人の記憶を上書きしてしまう恐れがあるということだそうだ。人の認知は弱い。NVIDIA、株を１０分割したり、オーブンからA100のボードを出すファンCEOのビデオが話題になったり、そのファンCEOは米名門カルテック大学卒業式でスピーチと、話題が満載ですが、Nemotron-4-340Bという謎の巨大LLMもリリース。もっとも、攻撃に対する脆弱性についてはまったく無配慮なことも明らかになった。何をしようとしているのかNVIDIA。高橋先生の「生成モデルの基礎と応用」、素晴らしい資料がでてきた、LLMを避けてきた人もこれは見るべき。MoEの次のMoA（エージェント）ってのもあったAlpacaEval 2.0 でGPT-4oに勝ると。ACL 2024からLLMは世界シミュレータになりうるか？という論文も話題になった、not reallyらしい。LLMを使いこなすのに必要な、言語化能力は、実はメタ言語能力であるとの説、まあ、最新のLLMはメタ能力を持ってるから、使う側にも相応の力量が必要なのは明らか。今井先生も大切なのはメタ認知能力とか言ってたな。LLMが苦手な、アリス問題というのも話題になった、「アリスにはN人の兄弟とM人の姉妹がいる。アリスの兄には何人の姉妹がいるか」、試してみよう。知識グラフ、Personalized PageRank を組み合わせたHippoRAG、人の脳内処理と類似しているといってるが、今井先生の新刊『「何回説明しても伝わらない」はなぜ起こるのか？』をみても、都合の良い記憶に残ったわずかな情報から人間も答えている気がしてきた。今井先生によると、ビジネスや探求を突き詰めた人が得られる「優れた直観」というのを、（頼りすぎて）AIが奪うのではというのは頭に残った。Luminaもそうだが、人の認知能力や記憶の領域に、それを使うことで間接的に、AIの影響が出るようになってきたのは、恐ろしい。

- MMed-Llama-3-8B
	- https://x.com/longislandtea3/status/1799013747178278939
	- ２週間ほど前に出たMMed-Llama-3-8B 医療用のオープンモデルとしてはGPT-3.5を軽く超え、GPT-4を匹敵すると言っている
- Prometheus-2: An Open-Source Evaluator LM for Your RAG Application
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/prometheus2_cookbook/
	- Prometheus-2 shows a high degree of correlation and agreement with human evaluations, GPT-4, and Claude3, making it a dependable evaluator LM for RAG applications.
- Qwen2-72B-InstructのElyzaTasks100の平均スコア、4.23でした by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800023709958431166
	- チャクチャすごい…Gemini1.5Flashのチョイ下。OpenAIの進歩が停滞感あるのに対してオープンモデルの進化はすさまじいです。
	- Qwen1.5が出てから4ヶ月、Llama3から2ヶ月しか経ってません。こんな事態になるとは
- MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark
	- https://arxiv.org/abs/2406.01574
	- もはや定番のベンチマーク『MMLU』ではLLMの性能評価で差がつかないことを受け、ウォータールー大学などの研究者らにより『MMLU-Pro』が作成されました。
	- すでにGPT-4o、Claude 3、Llama-3、Phi-3など多数で実験が行われ、各モデルの特徴を捉えることに成功しています。
-  CRAG -- Comprehensive RAG Benchmark
	- https://arxiv.org/abs/2406.04744
	- Meta presents CRAG - Comprehensive RAG Benchmark
	- Presents a factual QA benchmark of 4,409 QA pairs and mock APIs to simulate web and Knowledge Graph (KG) search
- Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- LLMの計算コストを支配する行列積（MatMul）を完全に排除しながら、パフォーマンスを維持する方法が発表された 
	- ちょっと前に業界の話題を席けんしたBitNet1.58bの上位互換ともとれる 
	- FPGAで実装し、効果を確認しており、これは脱GPUの流れが来るかもしれない
- AppleデバイスにChatGPTが統合されます！
	- https://x.com/gizmodojapan/status/1800237589330526454
	- iPhone/Mac等から無料でChatGPTにアクセスできるようになります。アカウント作成も不要（有料アカウントを持ってる場合はそちらを使えるよう）。
- オープンモデルの最近の進化　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800036264487591937
	- １年前のelyza-japanese-llama-2-7bの頃は5歳児レベルで、
	- 半年前のnekomata-14bで小学生、
	- 4カ月前のQwen1.5で中学生、
	- 2ヶ月前のLlama3で高校生、
	- 直近のQwen2で大学生って感じかもしれない。グラボ買ってもかつては5歳児AIしか雇用できなかったのが今では同じグラボで大学生AIが雇用できてしまうというコスパの爆上がり。そして1年後はどうなってしまうのか？院生レベル？博士レベル？
-  Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
	- https://arxiv.org/abs/2404.05719
	- Apple already published a paper on it that disclosed way more details than what we expect from Apple. 
	- It's called "Ferret-UI", a multimodal vision-language model that understands icons, widgets, and text on iOS mobile screen, and reasons about their spatial relationships and functional meanings.
- GraphRAGふーんって感じだったけど、びっくりするくらいわかりやすかった
	- https://x.com/__genzitsu__/status/1800074489897889998
- 開発版のChromeで、ブラウザ上でGemini Nanoを動かせるようになった
	- https://x.com/kentaro/status/1799856400149221599
	- ブラウザAPIだけで完結する音声チャットボットの実験をしてみました。これは夢が広がりますね！アツい！！
	- https://codesandbox.io/p/sandbox/gemini-nano-chatbot-cdg59q?file=%2Findex.html
		-  LLM: Chrome上で動作するGemini Nano 
		- 音声認識+音声合成: Web Speech API
- いた（アルトマン氏が、WWDC2024に)
	- https://x.com/iskw226/status/1800202842428653817
- Appleが発表した人工知能「Apple Intelligence」 by GIZMODE
	- 1. 文章の自動編集・校正機能 
	- 2. メモ・フリーボード・Keynoteなどで画像生成が可能に 
	- 3. Apple Intelligenceは「実行」ができる。「この間、送られてきたポッドキャストを再生して」と言えば、見つけ出して再生することろまでやってくれるらしい…！ 
	- 4. メールで送られてきた予定は、自動でスケジュール化。予定の場所の地図データなども自動で添付。
- LaVague
	- https://github.com/lavague-ai/LaVague
	- LaVague is an **open-source Large Action Model framework** to develop AI Web Agents.
- We’re partnering with Apple to integrate ChatGPT into iOS, iPadOS, and macOS—coming later this year:
	- https://x.com/OpenAI/status/1800240380220473552
- アップル・Google・マイクロソフト・OpenAIがみんなこの技術を同じことにしか使えていないという現実
	- https://x.com/mehori/status/1800239908713283836
	- そしてその限界は、できることから逆算して必ずしも必要としない機能をユーザーにおしつけることにつながっている
- very happy to be partnering with apple to integrate chatgpt into their devices later this year! by Sam
	- https://x.com/sama/status/1800237314360127905
- 旅行プランに迷う人は全員Geminiを使った方が良い。
	- https://x.com/SuguruKun_ai/status/1799695851968942167
- Appleの人工知能（生成AI）「Apple Intelligence」は、オンデバイス（データーをサーバーに送信せずに処理）を基本とするそうです。
	- https://x.com/gizmodojapan/status/1800231580788736014
- Apple WWDC intro was so lit
	- https://x.com/ai_for_success/status/1800214745078968712
	- ああ、空から、スカイダイビングして、アップル本社に降りるという画像、これは本物か？？
- AppleにここまでAIスマホ統合で先を越されたGoogleって今まで何してたの？マヌケですか？　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800236837665206563
-  Mixture-of-Agents Enhances Large Language Model Capabilities
	- https://huggingface.co/papers/2406.04692
	- With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction.
	- we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology.
	- our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni.
- 議事録取ってるならGemini 1.5 Flashは使った方が良い
	- https://x.com/keitowebai/status/1800006621780951533
	- 録画データをアップロードして「要点をまとめて」と言うだけで要約完了。これで報告は3分で終わらせようか。
- LLMに入力するプロンプトを書くときには言語化能力が必要、というのは正しいと思うのだけど、じゃあ言語化能力ってなんやねん、というときに、「構造化されていて分かりやすく、綺麗で論理的な文章」、ではない、と私は思っている。by mutaguchi
	- https://x.com/mutaguchi/status/1799899202803433571
	- 実はLLMくんはかしこくて、かしこくないので、ぜんぜん構造化されてない、論理も破綻していて、文字も間違いだらけで、言語としても成立していないようなぐちょぐちょテキストでも、勝手に雰囲気で補間・修正して読み取ってくれる。ただし、プロンプトには出力に必要な情報が過不足なく指定されていることは必要となる。
	- つまりプロンプトを書くのに必要な言語化能力というのは、LLMの出力（入力プロンプトに対する補完）を引き出すために必要な文字列を、過不足なく仕込む能力ではあるのだが、必ずしも人間が見て「この人言語化能力高いなあ」と評価されるような文章を書く能力が必要とされているとは限らない、と考えている。
- (LLMに入力するプロンプトを書くとき必要なのは)メタ言語能力、言語に対するメタ認知かな
	- https://x.com/erukiti/status/1799945431864254487
	- 会話とか言語化レベルではなく、言語を扱うLLMをhackするように、言語を間接的に扱う能力が必須。観察・気づき・制御・ねじ伏せ
	- 1. 対象のドメイン知識とボキャブラリが死ぬほど必要（ここまでは普通の言語能力。簡単やね、やった！） 
	- 2. LLMがどの程度理解が定まってるかの見極めが必要（一発で指定できるケースもあれば、説明文が必要、定義を一通り渡す必要などのケースもある。ここらへんはもう言語能力というよりメタ言語能力） 
	- 3. 2で見極めた範囲内で指示をどれだけ最低限に軽量化できるか？複雑な指示は、指示を解釈するところにLLMの知性を使いすぎて、指示そのものに追従できなくなることがあるから、指示に従えるギリギリ最小限を狙うことになる（メタ言語能力） 
	- あと、プロンプトやコードをLLMで生成するメタプロンプトやメタプログラミングみたいなのも普通に出てくるから、そういう意味でもメタ言語能力が必要だと思う
- If Apple integrates OpenAI at the OS level, then Apple devices will be banned at my companies. by maskさｎ
	- https://x.com/elonmusk/status/1800265431078551973
- 統計学の本質の一つは仮定にあると思う。 
	- https://x.com/1kn29cgQJzRwtgd/status/1800005796585259435
	- そもそも統計学関係なく、データを解釈する際、人間は仮定をおく。 通常それは暗黙の仮定だが、統計学はそれを明示し、その仮定でよいのかや仮定がズレることの影響を議論できるようにする。 仮定を明示し、議論の俎上にのせる。これが統計学の効能の一つ
- SEDDは離散データに対する拡散モデル。by 岡野原さん
	- https://x.com/hillbig/status/1800303691364470800
	- 離散版のスコアであるコンクリートスコア（p(y)/p(x)）をデノイジングスコアエントロピー最小化で求める。スコアエントロピーはELBOとみなせ尤度の下限を与えられる。言語モデルなどで同パラメータモデルに匹敵する性能。一貫性に優れる
-  To Believe or Not to Believe Your LLM　by DeepMind
	- https://arxiv.org/abs/2406.02543
	- Google DeepMindは、ある問題におけるLLMの知識不足（ハルシネーション）を確かめる方法を考案しています。
	- 同じ質問に対する回答のバラつきを見ることで、自信を持って正しい回答をしているのか、知識不足のために間違った回答をしているのかを判断できるとのことです。
-  Appleのオンデバイス・サーバー基盤モデルの概要 by npakaさん
	- https://note.com/npaka/n/ncd651c042e6a?sub_rt=share_h
	- 「Apple Intelligence」は、ユーザーの日常的なタスクに特化した複数の高性能生成モデルで構成されており、現在のアクティビティに即座に適応できます。
	- https://machinelearning.apple.com/research/introducing-apple-foundation-models
	- 「**約3Bパラメータを持つオンデバイスの言語モデル**」と「**Private Cloud Computeで利用できるサーバーの言語モデル**」が、特殊なタスクを効率的、正確、責任を持って実行するためにどのように構築および適応されたかを説明します。
	- AIツールの開発方法とそれを支えるモデルをガイドする責任あるAI原則を作成しました。
-  Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/html/2406.02061v1
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
- Sam Altman’s blue backpack didn’t show up today at Apple Park which is a notable shift for AI safety and preparedness.
	- https://x.com/RayFernando1337/status/1800366357902709184
	- どうも、アルトマン氏の青いバックパックには、ChtGPTを止めるスイッチが入っているらしい。
- Appleのクレイグ副社長、尋常でない運動能力を見せる。。
	https://x.com/durreadan01/status/1800453311382147219
- guide on finetuning an LLM to query knowledge graphs (through text-to-cypher).
	- https://github.com/neo4j-labs/text2cypher/blob/main/finetuning/unsloth-llama3/README.md#llamaindex
	- that allows you to directly use this LLM to generate cypher statements and retrieve knowledge graph entities as "chunks" for your Graph RAG pipeline!
- RecurrentGemma 9B 
	- https://huggingface.co/collections/google/recurrentgemma-release-66152cbdd2d6619cb1665b7a
	- This new model achieves performance comparable to the largest Gemma 1 model, but with significantly greater efficiency.
	- For example, on a single TPU-v4, it delivers 80x higher throughput when sampling 1k tokens from a 2k token prompt.
- Doing RAG? Vector search is *not* enough
	- https://techcommunity.microsoft.com/t5/microsoft-developer-community/doing-rag-vector-search-is-not-enough/ba-p/4161073
	- RAGにおいて、ベクトル検索だけじゃなく全文検索も加えたハイブリッド検索じゃないとパフォーマンスが出ないことを試してみた、というMicrosoft方の記事
	- RAG ＝ベクトル検索という風潮があるが、そうではない、と
-  Llama for Scalable Image Generation a.k.a LlamaGen
	- https://github.com/FoundationVision/LlamaGen
	- 拡散モデルを上回るTransformerによる画像生成
- Apple Intelligence の性能の自社評価の結果。
	- https://x.com/overlast/status/1800746455159963737
	- デバイス内モデルでは7Bモデルの上位に位置していて、サーバー内モデルではGPT-3.5 Turboを凌駕しているとのこと。粛々と性能を上げていて凄い |
-  RecurrentGemma-9b: 革新的な自然言語処理モデルの登場
	- https://hamaruki.com/recurrentgemma-introducing-a-revolutionary-natural-language-processing-model/
	- RecurrentGemmaは、従来のGemmaモデルをベースに、新しいリカレントアーキテクチャを採用することで、より効率的かつ高性能な言語処理を実現しました。
	- Colab notebook
	- https://colab.research.google.com/drive/1jDbbKhBs-A__QOtp7S6WxGxBH4J6gtuj?usp=sharing
-  Advancing personal health and wellness insights with AI
	- https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/
	- Today on the blog, read about the latest from our two new research papers on how AI, particularly fine-tuned Gemini models, can create personalized health experiences that cater to individuals’ unique health journeys.
- LLM CLI tool are the cool things you can do with piping.
	- https://x.com/HamelHusain/status/1800741993276203043
- 最新のLLMの多くは「アリスにはN人の兄弟とM人の姉妹がいる。アリスの兄には何人の姉妹がいるか」という簡単な推論と常識を必要とする問題が解けないことを指摘。
	- https://x.com/shion_honda/status/1800895368458305643
- 「生成モデルの基礎と応用」の講義資料を公開します by 大阪大学　高橋先生
	- https://x.com/taka8hiroshi/status/1801177682450981251
	- 最尤推定からスタートして、深層生成モデルやTransformerを一通り理解しようという内容です。ぜひご覧ください
		- https://speakerdeck.com/takahashihiroshi/generative-models
- サカナAIが1年でユニコーン　日本最速､200億円追加調達
	- https://www.nikkei.com/article/DGXZQOUC144OB0U4A610C2000000/
- Oumuamua-7b-instruct-v2、Shaberi3ベンチマークで平均点7.25です by うみゆきさん
	- https://x.com/umiyuki_ai/status/1801836418744127702
	- GPT3.5T（7.16）やQwen2-7B（7.23）を超えてます。メッチャ強い
- 巨人オープンLLMで話題の Nemotron-340B お試し by AIXさとしさん
	- https://x.com/AiXsatoshi/status/1801865161717760380
	- 日本語推論、生成可能、オープンLLMとしては、知識は非常に正確
- RecurrentGemma 9Bは、Griffinアーキテクチャに基づいたGemmaモデル
	- https://x.com/webbigdata/status/1801928695764099084
	- Gemma 7Bは特定の知識ベースのタスク(科学、数学、プログラミング問題)で高いパフォーマンス 
	- RecurrentGemma 9Bは、常識推論や一般知識を必要とするタスクで高いパフォーマンス と言う違いがあります
	- RecurrentGemma 9BはHugging faceのTransformesrで微調整サポートはされていますが、issues見る限り危険な香りがするので
-  HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models
	- https://arxiv.org/abs/2405.14831
	- 知識グラフ、Personalized PageRank アルゴリズムを組み合わせたRAGの手法の提案。人間の脳の記憶の仕組みを模倣。
-  Nemotron-4 340B from NVIDA
	- https://research.nvidia.com/publication/2024-06_nemotron-4-340b
	- 昨日に出たNemotron-4 340Bも、人間が2万件、残り98%(98万件?)は合成データでalignmentした模様(?)
- サクッと論文読むならGoogleのNotebookLMを使ったほうが良い
	- https://x.com/tetumemo/status/1801889597871558864
- nvidia/Nemotron-4-340B-Instruct
	- https://huggingface.co/nvidia/Nemotron-4-340B-Instruct
	- https://x.com/webbigdata/status/1802173127767802234
		- モデルは商業的に利用可能です。 
		- 派生モデルは自由に作成および配布できます。 
		- NVIDIA は、モデルまたは派生モデルを使用して生成された出力に対する所有権を主張しません。
-  An Empirical Study of Mamba-based Language Models
	- https://arxiv.org/abs/2406.07887
	- Mamba2とTransformerの比較。学習量が1.1TtokenだとTransformerの方が精度が良い。一方3.5Ttoken学習するとMamba2が良くなる。
	- https://x.com/jnishi/status/1801842541639438494
	- ICLの性能はMamba2はTransformerに及ばないが、Mamba2とMLPとself-attentionを少しで構成したMamba2-HybridはICL性能は高い。
- nitky/Oumuamua-7b-instruct-v2
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
-  LLMFlex
	- https://github.com/nath1295/LLMFlex
	- LLMFlex。LangChainよりも色々と簡単にしつつ、StreamLitでフロントエンドUIまで付けてくれちゃってるブツ。こういうのありがたいね。GPTQやGGUFモデルがロードできる。DuckDuckGo検索ツールやドキュメントでRAGとかもパッとできる
- Dream Machine by Luma AI is just 3 days old.
	- https://x.com/hey_madni/status/1801900554488291414
	- 1. Distracted boyfriend
	- 2. Disaster girl with firefighters
- Ninja-v1のバージョンアップ、Ninja-V2-7Bをリリース致します。
	- https://huggingface.co/Local-Novel-LLM-project/Ninja-V2-7B
	- ベクトルマージ等の技術を活用し作成したMistralベースの70億パラメーターモデルです。
	- Gemini pro 1.0評価で Elyza taskで3.71 JP MT Benchで8.24
- Flaxを使用したRecurrentGemma2Bグリフィンモデルのファインチューニングチュートリアル(Kaggle、GoogleColabノート付)
	- https://x.com/hAru_mAki_ch/status/1802227933534429614
- Nemotron-4 340B is a huge release by NVIDIA!
	- https://x.com/omarsar0/status/1802024352851878296
	- The Nemotron-4 340B instruct model lets you generate high-quality data and then the reward model (also released) can filter out data on several attributes.
	- The results show that Nemotron-4 340B is a strong model. Check out those MMLU, GSM8K, and Arena Hard numbers.
- たとえばDream Machineに昔の写真入れて動画にすると、それは100%ウソのハズなのに、なんか50%くらい本当だったような気がしてくるというような
	- https://x.com/hirochuu8/status/1801986929183142369
- Exciting that our Mixture of Agents (MoA) tops the AlpacaEval leaderboard!
	- https://x.com/james_y_zou/status/1801656163936964919
- Ninja-V2-7BのShaberi3ベンチマークスコアは6.80でした
	- https://x.com/umiyuki_ai/status/1802027838524321839
- Can language models be used as world simulators? In our ACL 2024 paper, we show -- not really.
	- https://arxiv.org/pdf/2406.06485
	- GPT-4 is only ~60% accurate at simulating state changes based on common-sense tasks, like boiling water.
- nvidiaのファンCEO、Caltecの卒業式でスピーチ
	- https://x.com/shuki004/status/1801681153705054588
-  Lares smart home assistant: A toy AI agent demonstrating emergent behavior
	- https://interconnected.org/more/2024/lares/
	- This is a great little example of how simple agent-based systems can lead to emergent behavior, even with tiny AIs like Apple's on-device LLM.
	- Matt Webb built a demo AI smart home, when he asks it "turn on the light for my dog" the home figures out how.
- DreamMachineが危険なのは、生成動画を見たら「本人の記憶が上書きされる」点だと思う
	- https://x.com/genmeisui/status/1801944958062239884
	- 例えば痴漢冤罪の人に「触った瞬間の動画が見つかった」と生成動画を見せ続けたら、「やったかも」と思い込ませることは難しくない
- 予想はしていたけど5人目が出てきた時点でダメだった [#DreamMachine](https://x.com/hashtag/DreamMachine?src=hashtag_click)
	- https://x.com/kizuki_jpn/status/1801950889747354076
-  Coupled Ocean-Atmosphere Dynamics in a Machine Learning Earth System Model
	- https://arxiv.org/abs/2406.08632
	- New Earth-2 nvidia preprint about AI forecasting for seasonal timescales including interactive ocean coupling. The generated El Niño looks realistic including its subsurface thermal structure. Internship project led by 
- GPT-4レベルのNemotron-4-340B無茶苦茶脆弱
	- https://x.com/maksym_andr/status/1802011165670735946
	- leads to 100% attack success rate on 50 harmful requests from AdvBench using GPT-4 as a judge. There is no need to do any random search or random restarts, the model just complies directly.
- AI革命、すでに失速している
	- https://newspicks.com/news/10094191/body/
	- 学習データの不足でモデルの性能向上の頭打ちが見えており、運用が高コストに。現時点ではAIの利用シーンも限定的のため、収益成長も伸び悩むと
- nitkyさんが、新たなマージ7Bモデル Oumuamua-7b-instruct-v2 を出してくれました。
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
	- ７Bサイズながら、⌘R+以上、GPT3.5未満みたいなベンチマークらしいです。
- Oumuamua-7bのElyzaTasks100スコアは3.85でした。相当強いです by うみゆきさん
	- https://x.com/umiyuki_ai/status/1797191209976537102
- 『何回説明しても伝わらないはなぜ起こるのか？』（今井むつみ）
	- https://x.com/JunkudoT/status/1791361304655241449
	- 人間は聞き逃し、都合よく解釈し、忘れる。そんな人間同士がそれでも伝え合うことは可能なのか？理解し合うことが難しい世の中で「伝えわかり合う」ことに探求するあなたをサポートする一冊です。


## 6/10

今週はNotebookLMがすごかった。LLMの躍進にやられぱなしであるが、LLM活用で希望を持てる事例も。理論面では、Transformerの次のアーキテクチャと下馬評の高いMambaであるが、CMUによるMamba-2の提案では新しく導入された状態空間双対性(SSD)によって、Transformerに匹敵する性能を達成しながら、Transformerよりも効率的にスケールするそうだ。岡野原さんによるとtransformerとSSMが統一されたとのこと。LSTMを改良してtransformer並みのスケーラビリティがあるというxLSTMというのも気になる。OpenAIがGPT-4の内部表現分析に活用した**k-Sparse Autoencoders**って、Anthropicがつい最近発表したスパースオートエンコーダの利用と同列か、なおスパースオートエンコーダ自身はICLR 2014 で発表されたと著者がツイート。さて、新しいLLMの発表では、アリババがQwen2を発表、全体的にLlama3超えとか、最上位モデル以外はApacheライセンスとか、ollamaがさっそく対応とか、7B-instructのお試しをhuggingface spaceにAIXサトシさんが提供とか、にぎやかだ、これからの評価が気になる。GLM4-9Bって 智谱AIのモデルも相当性能が高いらしい、双方とも中華LLMらしく日本語堪能なのだがライセンスには注意が必要とのこと。GoogleのGemini 1.5 Proだって日本語性能すごい、布留川さんのGoogle Gemini 1.5の新刊もでるので、是非お試しを。 Google AI Studioで無料お試しでそのポテンシャルは明らかなわけであるが、gpt-4oに話題を持っていかれ気味。そこで、一気に挽回というわけではないが、Gemini 1.5 ProをバックエンドにもつNotebookLMの試行が開始。PDF、テキスト、URLをソースとして登録すると、そのソースに対して、概要やFAQ、さらにはチャットによる応答と根拠箇所の表示ができるという代物。いや、ローカルドキュメントでRAG作るみたいな話は全部吹っ飛ぶような話ではあるが、生成の部分の抽出の部分のバランスが正味どれくらいかこれからの評価が気になる。AIに情報をまとめてきてもらうついでにそれをWeb記事の体裁でまとめて公開するPerplexity Pagesなんかも、そうだけど、各社ともチャットの次のキラーアプリを探して試行している感じかなー。最悪のシナリオはこれらの試行の結果、使いこなせる人は少なかったという結論になること。kobayashiさんの、「LLM を使いこなせる人 ＝ 言語能力が高い人」というのは、このような能力を得るには、リスキングでは追いつけないという身もふたもない話。AIリテラシーはいかに言語能力を上げるかにかかっている。言語能力が高い人の例とは、例えば、コンサルタントが本物か偽物かを見抜く１０の質問みたいなやつができる人か。一方NTTのstreamitを使ったAIの民主化とか、概念データモデルをつかったデータの整理など、現場にはまだ力があって、これを生成AIを使って会社のDXにつなげるってのも、希望を持てるLLM活用パターンな感じがしてきた。これらに比べてAIで生産性を上げて人手不足を解消し、余った人向けに転職促進という、政府の成長戦略の薄っぺらいことよ。放送大学の教科書『自然言語処理』の改訂版と三訂版の比較、いかに言語処理の基本構成がtransformerの登場で大きく書き換わったかが目次だけでもよくわかる。しかし、「知識グラフって最近聞かなないなあ」とは、小町先生冷たすぎ。GraphRAGとかProperty Graph Indexとか、LLM応用界隈では知識グラフはまだホットだし、Document Intelligenceのようにハルシネーションを抑える手段としての知識の重要さもわかってきたところなんですけど。最後に、Hassabis がインタビューで言及したProject Astra(Goole I/O 2024でデモしたやつ）、あと１から２年でリリース、普通の人が使えるアシスタントとしてゲームチェンジャーになるとのこと。

- Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality
	- https://arxiv.org/abs/2405.21060
	- 現在生成AIで主流のTransformerの「次」のアーキテクチャとして期待されるMamba-2を提案
	- **状態空間モデル（SSM）** は、構造化行列 を用いることで、従来のアテンションと密接に関連していることが明らかになり、
	- 状態空間モデル（SSM） と アテンション の変種との間の理論的な関連性を示すフレームワーク**状態空間双対性（SSD）**を提案
	- その結果、線形時間計算 と 二次時間計算 の両方の形式を持つことが示されています。
	- この 状態空間双対性（SSD） フレームワークは、Mamba-2 と呼ばれる新しいアーキテクチャの設計を導き、言語モデリングにおいてTransformerに匹敵する性能を達成しながら、Transformerよりも効率的にスケールします。
	- Mamba2は新しく導出されたSSDを使い、系列長に対し線形の計算量、メモリ使用量で効率的に学習、推論でき、TransformerやMambaよりPPLや下流タスクで性能が高い。SSMとTransformerが統一的な枠組みで扱えることも示す by 岡野原さん
- GPT-4 is 1.8T MoE, thanks Nvidia Presentation
	- https://x.com/literallydenis/status/1797531945926287497
- LLMを活用した大規模商品カテゴリ分類への取り組み
	- https://engineering.mercari.com/blog/entry/20240411-large-scale-item-categoraization-using-llm/
	- GPTを商品カテゴリ分類に活用した事例と工夫したポイントがまとまっているよ
		- EmbeddingモデルはOSSでも問題なし
		- GPT4はコスト的に使えなかった
		- max_tokensとChain of Thought での効率化
		- Numbaへの書き換えもGPTを使って効率化
-  Hugging FaceのZeroGPUでAIのデモを作る方法: 初級編
	- https://qiita.com/alfredplpl/items/abb30283b578dc984d16
	- ZeroGPU とは、デモの利用者が使う瞬間だけ高性能なGPUが借りられるというサービスです。現在はA100 40GBが一瞬借りられます。これを実現できているのは世界でHugging Faceだけでしょう。お値段は月額9ドル（約1500円）です
	- Hugging FaceのZeroGPUはAIのデモを作るのに最適だとわかりました。いかがでしたでしょうか。ぜひみなさんもデモを作ってみてください。なお、私は責任を持ちません。
- lmsys.org でGoogleのGemini 1.5 Pro（5/14モデル）が日本語で世界一になりました。２ヶ月前のモデル (4/9モデル）よりかなり改善されました
	- https://x.com/shanegJP/status/1797798176344453414
- Perplexity Pages、AIに情報をまとめてきてもらうついでにそれをWeb記事の体裁でまとめて公開できちゃうのかあ。
	- https://x.com/umiyuki_ai/status/1797871157850620270
- 富士通は、特化型の生成AI混合技術とナレッジグラフ拡張RAGというマニアックな方向に進化することになりました。
	- https://x.com/AsamaKotaro/status/1797844740328804563
-  the benefits of Google Gemini's gigantic 1 million token context window in action!
	- https://x.com/llama_index/status/1798049438814081138
	- In this quick notebook, we show Gemini built into a LlamaIndex agent attempting to answer a multi-part question from a set of complicated, heterogeneous documents.
- 富士通の研究戦略発表会、最適化問題と生成AIによる制約条件の生成が相性が良いという発想
	- https://x.com/tokoroten/status/1797851927457546682
	- 議事録やマニュアルから制約条件を起こしたり、AIとの対話を通じて制約条件を起こしたり
- 概念データモデルから始める真にデータドリブンな製造業DX
	- https://www.qunie.com/quriosity/231218_00/
	- 概念データモデルは個々の業務改革やモダナイゼーションに着手する前に作成するデータモデルである。特定の業務領域だけでなく、製造業のバリューチェーン全体をモデルとして表現する。
	- 論理データモデルのような厳密さは不要で、関連するデータをグループ化したデータ群と、そのキー項目（全てのデータ項目は不要）、データ群のつながりを示す。
	- バリューチェーン全体を俯瞰した概念データモデルがあるからこそ、企業全体の改革に一本の芯が通ることになるのだ。あるお客さまは、概念データモデルのことを“自社の憲法”と表現されていたが、まさにその通りである。
- ELYZAが、国立研究開発法人 産業技術総合研究所が募集した大規模生成AI研究開発支援プログラムに採択されました。
	- https://x.com/ELYZA_inc/status/1797780304717078689
-  論文解説をGPT-4oを使って自動的に生成してみる by 逆瀬川さん
	- https://qiita.com/sakasegawa/items/8e17ede26dd96e7e3280
	- PDFを画像として取り扱うと処理は遅いが格段に安い！！ 
	- 論文のPDFを画像として扱い、GPT-4oで落合メソッドを使って解説を生成させる
	- 論文のPDFから数式や図表を抽出し、個々に解説を生成
- もはやAIの性能を人間が測定できない by  karaage. [からあげ]さん
	- https://karaage.hatenadiary.jp/entry/2024/06/04/073000
	- そもそもAIの性能を人間が測定するのが難しい領域に来ているなと実感しました。
- Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming
	- https://arxiv.org/abs/2406.00592
- LLM Basics - Why can't we use regular LoRA for pre-training LLMs
	- https://x.com/rohanpaul_ai/status/1797759219891937324
	- LoRA (Low-Rank Adaptation), targets a subset of a neural network's parameters, specifically focusing on the weight matrices of transformer models. It represents these large matrices as the product of smaller
- Why AI wont take your job just yet
	- https://medium.com/@starloba/why-ai-wont-take-your-job-just-yet-13e95cd05da8
	- 汎用的なタスクをAIに解かせるようになると、人間はよりクリエイティブな問題に注力できるようになる。より正確に言うなら、強制的に注力しないといけない状況に追い込まれる。
- Microsoft has built a weather forecasting model named 'Aurora
	- https://x.com/MSFTResearch/status/1797662278394827029
-  Heuristics on the high seas: Mathematical optimization for cargo ships
	- https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/
	- Today we present new solutions to the Liner Shipping Network Design and Scheduling Problem, released as part of our new Shipping Network Design API, with the goal of maximizing the efficiency of container shipping networks at world-wide scale
- Unslothはこの論文に対抗してLoRAでの継続事前学習を徹底的に最適化した結果、今までのLoRA学習の２倍の効率で学習できて、VRAMも半分で済む
	- https://x.com/umiyuki_ai/status/1798221784334160262
	- 24GBのVRAMでLlama3-8BやMistral-7BがLoRA継続事前学習できる
- GLM4-9Bだって。26言語対応。GPT-4に匹敵する関数呼び出し能力
	- https://x.com/umiyuki_ai/status/1798292824544420150
-  中国製LLMのライセンス問題と国安法について
	- https://note.com/willplion/n/n2710f60b381a
- 継続事前学習(CPT: Continued Pre-Training)をQLoRAでやろうとする試み
	- https://x.com/webbigdata/status/1798313713654776062
	- Colab無料版でもmistral-7b-v0.3なら十分動きました
	- llama3 8bやgemma7bでは有料版のL4(24GB)でもメモリ不足になってしまいましたがllama2という手もあります
-  佐賀の織田病院がオンプレGPUサーバーでLLM稼働、電子カルテ情報を生成AIが要約
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09236/
	- これまで利用してきた電子カルテシステムにオプティムが提供する生成AI「OPTiM AI」を組み合わせ、看護師の業務効率を高める実証に乗り出し
	- 米NVIDIAのRTX A2000を搭載したGPU（画像処理半導体）サーバー1台を新たに院内に用意した。LLMの学習や推論に用いる
- Introducing AI Agents in LangGraph!　 by Deeplearning.ai
	- https://x.com/DeepLearningAI/status/1798376731188834780
	- In this course taught by hwchase17, LangChainAI CEO, and weiss_rotem, tavilyai CEO, you’ll learn to use LangGraph to create controllable agents, and agentic search for agents to enhance their output.
- ChatGPTでレ・ミゼラブルの人物相関3Dネットワークグラフを作成
	- https://x.com/itnavi2022/status/1798320618695438647
- GLM4-9B-ChatをElyzaTasks100で評価した by うみゆきさん
	- https://x.com/umiyuki_ai/status/1798328337699606704
	- スコアはなんと3.92！！やべえ！！！！Gleipnir-7Bの3.91より勝ってる！メチャクチャかしこい！このモデル、スペックだけのコケオドシじゃない！
- ReFT: Representation Finetuning for Language Models
	- https://x.com/rohanpaul_ai/status/1798026828017197256
	- 10x-50x more parameter-efficient than prior state-of-the-art PEFT methods.
- Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks
	- https://arxiv.org/abs/2406.02550
-  xLSTM: Extended Long Short-Term Memo	
	- https://arxiv.org/abs/2405.04517
	- LSTM（Long Short-Term Memory）を改良し、数十億パラメーターの言語モデルにおいてTransformer並みかそれ以上の拡張性（スケーラビリティー）を持たせたという。
-  In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter Optimization
	- https://arxiv.org/abs/2404.16795
	- ベイズ最適化は更に革新的に!
	- この論文では、トランスフォーマーベースのPFNを活用した"In-Context Freeze-Thaw BO"を提案!
	- 従来手法に比べ10〜100倍高速かつ精度良く学習曲線を予測できるという驚きの結果!
- 『Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門』の出版記念イベント
	- https://x.com/npaka123/status/1798557659693781217
	- 25年間で技術書49冊、年間300以上の技術記事を書いている著者が、Google Geminiの最新技術情報に加えて、マルチモーダルとローカルLLMの未来予想を紹介します。
	- https://studyco.connpass.com/event/319990/
- Qwen2が来た！0.5B、1.5B、7B、57B-A14B、72Bの５種類
	- https://x.com/umiyuki_ai/status/1798762190729777185
	- 1.5から性能バキバキに上げてきた！全体的にLlama3超え！
	- 72Bは今までと同じライセンスだけど、他のモデルはApacheライセンスに変更
- GoogleNotebookLM
	- https://notebooklm.google/
	- Gemini1.5Proを使ったRAG専用のチャットサービス。
	- 約５万字の本を入力して質問してみたのだけど、GPT-4oでもClaude3でも微妙だったのに、結構いい感じの回答でビックリしたのだ。
- 時系列基盤モデルによる株価データ(多変量)の類似度算出と検索
	- https://note.com/hatti8/n/n6c1a91a3b6ba?sub_rt=share_pb
	- 時系列基盤モデルを使って、 ・多変量の時系列データEmbedding作成 ・時系列データ同士の類似度を算出 というのを試してみました。
- Hello Qwen 2!　by ollama
	- https://x.com/ollama/status/1798807013327241302
	- ollamaが qwen2に対応
-  Extracting Concepts from GPT-4
	- https://openai.com/index/extracting-concepts-from-gpt-4/
	- OpenAIは先ほどLLMの動きを理解するための研究を共有。GPT-4の内部表現を1600万の特徴に分解することに成功したことを発表。
- GoogleのAIサービスである「Notebook」
	- https://x.com/kensuu/status/1798876734298935771
	- 本のPDFをアップロードする - すると中身が全部左側に出てくる
	- AIに色々質問ができる - 答えに出てきた部分を左側で読める 
	- 回答をピン留めするとメモとして保存できる。メモを自分で書くこともできる
- Qwen2-7BをさっそくElyzaTasks100にかけたらスコア4.01！！！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1798777448282378254
- Qwen 2 みんな触られましたかね？指示性能と知識えぐない..　by ぬこぬこさん
	- https://x.com/i/bookmarks
	- 0.5B の海外モデルで日本語話せるなんて聞いていないよ...
- Qwen2-7B-instructのデモをスペースに設置しました by AIXサトシさん
	- https://huggingface.co/spaces/aixsatoshi/Qwen-7B-instruct
- Recipes for open source / local agents w/ Llama 3
	- https://x.com/LangChainAI/status/1799109018163761588
	- https://github.com/meta-llama/llama-recipes/tree/main/recipes/use_cases/agents/langchain
- From simple to advanced Agents
	- https://x.com/jerryjliu0/status/1799107241695715773
	- Before you build a complex multi-agent systems, learn the core abstractions for building a single powerful assistant over your data: routing, memory, tool use, and sequential to DAG-based planning.
- It's finally possible: real-time in-browser speech recognition with OpenAI Whisper!
	- https://x.com/xenovacom/status/1799110540700078422
- Democratizing Data Across NTT docomo with Streamlit
	- https://x.com/pei0804/status/1798501802415210935
	- streamlitを使った誰でもデータを使って洞察を得られる環境を作った話。 めちゃくちゃ良すぎて最高だった。ここまでやり遂げてることに、本当に尊敬しかない。ちなみに、今後の展望も良すぎた。
- 何が凄いのか？最新の技術GraphRAGについて解説してみた
	- https://www.youtube.com/watch?v=PqAgkfg0MA0
- 政府の成長戦略発表されました！
	- https://x.com/sirap_kuro/status/1799032255828140169
	- AIで生産性向上/人手不足解決、
	- そのあとに襲ってくる一般ホワイトカラーの需要減/失業などには、転職を促すことによって対処。
	- 普及の足かせになる安全/安心懸念については、政府で”AI制度研究会”を開き、議論。
	- また政府自身AIを調達する。
- Demis Hassabis says he is most excited about DeepMind's work on Universal Multimodal AI Agents (Project Astra).
	- https://x.com/electrik_dreams/status/1799139945560363264
	- These agents, to be launched in 1-2 years, will serve as highly intelligent assistants for all general humans tasks, and "will be a pretty big game changer", he thinks.
- Introducing GraphRAG with LangChain and Neo4j
	- https://medium.com/microsoftazure/introducing-graphrag-with-langchain-and-neo4j-90446df17c1e
	- Great introduction to using Graphs - instead of pure vector DBs - to power RAG applications
	- The relationships that graphs provide can empower better retrieval which can yield better answers
- Graph RAG makes sense if you think about it as a superset of "standard" vector RAG:
	- https://x.com/jerryjliu0/status/1797057726994092492
- コンサルタントは本物と偽物が混在　実力を見抜く10の質問
	- https://bookplus.nikkei.com/atcl/column/041500053/052900298/
- Safety Alignment Should Be Made More Than Just a Few Tokens Deep
	- https://xiangyuqi.com/shallow-vs-deep-alignment.github.io/
	- 1. Crrent LLM safety alignment is only a few tokens deep. 
	- 2. Deepening the safety alignment can make it more robust against multiple jailbreak attacks. 
	- 3. Protecting initial token positions can make the alignment more robust against fine-tuning attacks.
- LlamaIndex Introduces the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- In addition to the existing KnowledgeGraphIndex, LlamaIndex's new Property Graph Index enables:
- i heard people are rediscovering ReNet in its (almost) 10y anniversary
	- https://x.com/kchonyc/status/1799067177276014784
- Open-Endedness is Essential for Artificial Superhuman Intelligence
	- https://arxiv.org/pdf/2406.04268
	- "In this position paper, we argue that the ingredients are now in place to achieve open-endedness in AI systems with respect to a human observer. Furthermore, we claim that such open-endedness is an essential property of any artificial superhuman intelligence (ASI)."
-  An Easy Way to Comprehend How GraphRAG Works
	- https://towardsdatascience.com/an-easy-way-to-comprehend-how-graphrag-works-6d53f8b540d0
	- In a beginner-friendly explainer, Rendy Dalimunthe introduces GraphRAG, explains how it works, and outlines its benefits compared to traditional retrieval-augmented generation systems.
- OpenAI is using "k-Sparse Autoencoders" (my ICLR 2014 paper) to extract interpretable features from GPT-4,and showing that it outperforms other methods on sparsity-reconstruction frontier:
	- https://x.com/AliMakhzani/status/1799472688026517666
	-  k-Sparse Autoencoders
		- https://arxiv.org/abs/1312.5663
- 放送大学の教科書『自然言語処理』の改訂版と三訂版の比較
	- https://yudukikun5120.hatenadiary.jp/entry/2024/01/20/003314
	- 全体的に系列・意味論・構文論等の分野ごとに分離されていた古典的手法が、単一のニューラルネットワーク的手法に圧倒されていくさまを見ることができる。
	- 「今日では、超大規模コーパスで学習される汎用言語モデル（8章）が非常に強力であり、自然言語処理の観点では知識グラフの相対的価値は減少しつつある (p.44)」
	- 確かにもう自然言語処理では知識グラフってそんな言わないかな。。
		- https://x.com/mamoruk/status/1799070548863205470
- 「LLMの回答結果を評価する仕組み作り」は「LLMから良い回答を引き出すこと」と同じくらい重要です。
	- https://x.com/hiro_gamo/status/1799470543491694643
- 深層学習を含む多くの実応用モデルでは，パラメータ空間上でフィッシャー・ラオ計量が退化し，双対平坦構造が定義できなくなる．すなわち情報幾何が展開できなくなる
	- https://x.com/hayashiyus/status/1799457123103072282
	- すなわち情報幾何が展開できなくなる．双対平坦構造を一般化した概コダッチ構造を導入することでこの課題を克服した論文
- Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/pdf/2406.02061
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
	- The AIW problem is a concise natural language task that asks: "Alice has N brothers and she also has M sisters. How many sisters does Alice's brother have?" While easily solvable by humans using common sense reasoning (the correct answer is M+1), most tested LLMs, including GPT-3.5/4, Claude, Gemini, LLaMA, Mistral, and others, show a severe collapse in performance, often providing nonsensical answers and reasoning.
- アリス問題による日本語推論能力の比較
	- https://note.com/willplion/n/n5842538dd13d
	- 「女の子のアリスには4人の兄弟と1人の姉妹がいます。アリスの兄弟には何人の姉妹がいますか？」とし、LLMがアリスの性別がわからない為答えられませんとか言い出すことがないように調整した。
	- ほとんどのLLMプロバイダーの上位モデルにおいては、アリス問題に関しては回答ができることがわかった。特に最新のモデルであれば答えられて当たり前といった状態になっている。
- 『今の生成AIの本質的な難しさは「何をAIに生成させるしても、全て適確な言葉を使ってAIに指示を与えたほうが結果が良い」ということ』
	- https://x.com/izutorishima/status/1799568010950348942
	- 「LLM を使いこなせる人 ＝ 言語能力が高い人」と言い切れるくらいには ChatGPT を使いこなせてる人が少ない最大の理由
	- この使う人の言語リテラシーに相当依存するという仕様は、技術面ではなかなか個々人の差を埋めることはできないんじゃないかという懸念がある。何故なら、どんなにAIが頑張っても、そのAIがサポートする人間の言語能力の引き上げには限界があるから。
	- この言語能力の育成と強化という課題は、本来は大学教育以上のレベルで行われる過程で、自分の経験では大学院の研究室などで日々叩かれることによって磨かれる種類のものだと思っている。そういう点では、例え大卒の学歴を持っているとしても、本気でAIを本質的に使いこなせるようになるように再教育するためには、いわゆる「社会人のリスキリング」どころではないレベルの再教育が本当は必要なのだろう。
	- https://x.com/nyaa_toraneko/status/1799302550841364919
- AzureのサービスでGPT-4oを強化すると最強だというのが分かってもらえると思う。
	- https://x.com/super_bonochin/status/1799452550665773447
	- GPT-4oは、日本語OCR周りが強化されたとはいえ、特に手書きとかだとまだまだハルシネーション気味。 ワイのアプリではGPT-4oによる画像認識に、Document Intelligenceによって構造化した情報を付加することで、精度を飛躍的に上げることに成功しているのだｗ
		- https://x.com/super_bonochin/status/1799445107579695606
- NotebookLM、やっとコンセプトがわかったのですが
	- https://x.com/0317_hiroya/status/1799617523148796068
	- 【AIチャットボット + RAG】 
		- AIが主で、情報源が従 
		- 情報源を使うようになるけど、AIが学習した内容と合わせて、回答を生成する 
	- 【NotebookLM】 
		- 情報源が主で、AIが従
		- モデルは、資料のみを利用できるように設計されている。
-  Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- Claims that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales and by utilizing an optimized kernel during inference, their model’s memory consumption can be reduced by more than 10× compared to unoptimized models.
	- これまじ。FPGA試作でもそんな性能出るんかい "The accelerator processes billion-parameter scale models at 13W beyond human-readable throughput"

## 6/3

Google I/Oで発表されたgoogleの検索x生成AIが、とても不評ということで、Wall Street Journalの記事にもあるように、Perplexityの優秀さが際立つ、gooleがプレスリリースした新技術で期待を裏切るのは全く恒例ですね。とはいっても、Gemini 1.5 Pro/Flashの優秀さもあちこちで報告されており、本当は優れてるんでしょう。Mistralからコード生成のOSSであるCodestralが発表、さっそくOllamaが対応、これでお好きなエディタと組み合わせてプログラミングのアシスタントが実現可能に。量子化、小規模化にも進展があり、Mixtral 8x22b の量子化版Q6_K が $362 CPU(AMD Ryzen 9 5950X BOXか?)で軽々動作するという報告もあったり、Phi-3-Tinyシリーズのように、さらに小ささなLLMにチャレンジみたいな展開もあった。llama.cppで量子化版を動作させるとollamaより1.8倍速いという報告も。生成AIの飛躍的性能アップの秘密といわれる「グロッキング」に関する論文、汎化回路形成の秘密に迫り、新たなアーキテクチャ提案というのは胸熱い。生成AIの「創造性」に関する１０万人の人間！との比較で、GPT-4ならプロンプトを工夫すれば、人間を上回るというのには驚いた。O'ReillyからPrompt Engineeringの新刊も出るが、そもそもAnthropicのClaude3は、ゴールを与えれば適切なプロンプトを生成してくれるという。財務諸表から将来の収益の伸びを予測するタスクでGPT-4は人間より優れていると聞いても驚かなくなった。そんなAIですが、AIが他者の心や意図を理解する能力を持っているのかの「心の理論(ToM:Theory of Mind)」を持っているかどうかを分析した論文では、GPT-4 and Flan-PaLM が人間の大人のレベルに達したとのこと。さらに人間を超えるという意味では、Autoformalizing という、人間が作った幾何学をAIが自動証明できる体系に、生成AIをつかって作り直すという試みもあった。こうなると人間の理解がどこまで生成AIについていけるかという点が心配になる、ニューラルネットの動作理解の「Graph Game」や、LoRaの原理の可視化など、そういうのも目立った気がする。全く反対にアセモグル氏のように、それほどAIは格差拡大に影響しないという分析もあった。安全性に関しては、RAGを前提としたバックドアTrojanRAGというのも出た、説明性が高いこととバックドアを仕込みやすいというのは表裏一体。さて日本では、人工知能学会が浜松で開催、岡崎先生のスライド「大規模言語モデルの開発」は必見です。一方、ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果で、なんとナイジェリア英語のdelveという単語が生物系の論文に大量に表れたとの報告もあった。そもそも人間のほうも、エビデンスベースで合理的に思考する能力に課題があり、ストーリーに流されがちとの指摘があるので、ストーリー性を求めすぎて、合理的に思考できない生成AIができるかも。ロイヤルアカデミーの「AI in Science」すでに「AI for Science」といっている時代ではなくなった、つまりAIを使わずに科学の進展はない。さてNASAから満を持して、大気現象を予測する基盤モデルAuroraの発表、10kmメッシュで10日後まで天気予報できるってどれぐらいすごいのだろう。全くの余談だが、gpt-4oの発表時に参照された映画"Her"の監督の離婚した妻が監督した "Lost In Translation"の２つを比較し、一部シーケンスが全く対照的にアライメントしているという話題がテック界隈で一瞬話題になった。

-  自分がどれくらいニューラルネットワークを理解しているかを確かめられるゲーム「Graph Game」
	- https://gigazine.net/news/20240526-graph-game/
- googleの検索x生成AIについては，ちょっと評価がイマイチなんですよね．油と水を無理やり混ぜようとしている感がある．by 今井さん
	- https://x.com/ImAI_Eruel/status/1794707281600496111
-  TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models
	- https://arxiv.org/abs/2405.13401
	- RAGを悪用したバックドア攻撃。RAGで使用する知識DBに細工データを注入し、（DBから関連データを検索する）リトリーバとDB間でバックドアリンクを作成する。これにより、トリガーとなるPromptが入力された場合のみ、LLMに悪意のある回答を生成させることができるとのこと。
- We're now able to run Mixtral 8x22b Q6_K on a $362 CPU with better than human reading speed.
	- https://github.com/Mozilla-Ocho/llamafile/discussions/450
- llama.cpp runs 1.8 times faster than ollama
	- https://x.com/rohanpaul_ai/status/1794470545586635238
- Exploring the Impact of ChatGPT on Wikipedia Engagement
	- https://arxiv.org/pdf/2405.10205
	- Wikipedia remains the crowning achievement of Internet 1.0. It powered the rise of search engines (which depend on it) & generative AI (trained on its data).
- Grokked Transformers are Implicit Reasoners:A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/pdf/2405.15071
	- 1) Transformers can learn to implicitly reason, but only through extended training far beyond overfitting, a phenomenon known as grokking.
	- 2) Transformers exhibit different levels of systematicity in generalization across reasoning types: ID generalization is consistently observed, OOD generalization fails for composition but succeeds for comparison tasks.
	- 汎化回路形成の秘密に迫り、あたらなアーキテクチャを提唱している
-  Phi-3-Tiny-Untrained
	- https://colab.research.google.com/drive/188RpybbauEJKSIRPGL3RZi4Lk66HfBJj
	- This 50M-parameter model reconfigs Phi-3-mini-128k-instruct (3.8B parameters) by following the parameters given by the Super Tiny Language Models from A*STAR.
-  GPT-4は財務諸表から将来の収益の伸びを予測する点で人間のアナリストよりも優れていることが研究により明らかに
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311
- The Wall Street Journal says perplexity outperforms chatgpt, gemini & claud
	- https://x.com/RubenHssd/status/1795108714564706452
- DifyとOllamaを使用してローカルLLMを構築し、複数のLLMエージェントを設定してAIが社会に与える影響について議論を行い、その結果を記事として生成する手順について説明します。
	- https://hamaruki.com/how-to-configure-and-discuss-multiple-agents-using-dify-and-local-llm/
-  How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?
	- https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms
	- In April, there were four major open LLM releases: Mixtral, Llama 3, Phi-3, and OpenELM.
- Decoder-onlyなLLM（Mistral-7B）をtext embedding用にファインチューニング（LoRA）してMTEBでSoTAを達成した方法NV-Embedの提案
	- https://x.com/s_tat1204/status/1795344530285457626
- Google Search algorithm leaked today.
	- https://x.com/hridoyreh/status/1795394077510517217
-  Autoformalizing Euclidean Geometry
	- https://arxiv.org/abs/2405.17216
	- Can AI transform human mathematics into formal theorems and proofs that machines can verify?
	- This process, known as autoformalization, is a key step towards AI mathematicians. We introduce a neuro-symbolic framework for autoformalization, focusing on Euclidean geometry and combining domain knowledge, SMT solvers, and LLMs.
- Mixtral 8x7B Instruct with AWQ & Flash-Attention-2 in ~24GB GPU VRAM!
	- https://x.com/rohanpaul_ai/status/1795196332166070289
	- With the latest release of AutoAWQ - you can now run Mixtral 8x7B MoE with Flash Attention 2 for blazingly fast inference.
-  Automatic Domain Adaptation by Transformers in In-Context Learning
	- https://arxiv.org/abs/2405.16819
	- 幡谷さん（理研特別研究員）と松井先生（名大）の研究を公開しました。トランスフォーマーがインコンテキスト学習において、複数のドメイン適応法を表現し、さらにデータに応じて適切な適応法を選択する能力を持つことを理論と実験で示したものです。
- Training and Finetuning Embedding Models with Sentence Transformers v3
	- https://huggingface.co/blog/train-sentence-transformers
- ちなみにGemini 1.5 Proではapplication/jsonを出力フォーマットとして選択できて便利
	- https://ai.google.dev/gemini-api/docs/api-overview?hl=ja#json
- CLARINET: Augmenting Language Models to Ask Clarification Questions for Retrieval
	- https://arxiv.org/abs/2405.15784
	- Fine-tunes an LLM to ask clarification questions that maximize retrieval success for ambiguous search queries, outperforming heuristic methods and vanilla language models
- 映画herとLost In Translationの監督は離婚した元夫婦であり、その画像の一部はシンクロしている。。
	- https://x.com/MissSassbox/status/1795205212770119782
	- I had no idea that "Her" and "Lost In Translation" were clapbacks by the directors to each other after their divorce and now I need to watch both
	- Tech界で、gpt-4oのデモが、、映画herを意識して作られていたことから、（再？）発見された雑学
- Introducing Transformers Agent 2.0: A Leap Forward in Intelligent Automation
	- https://huggingface.co/blog/Andyrasika/transformer-agents
- 松田語録：Gemini 1.5 Proを論文を読むのに使ってみた〜良いところと悪いところ
	- https://x.com/npaka123/status/1795568613900062747
- ChatTTS: a powerful voice generation model designed for conversational scenarios
	- https://github.com/2noise/ChatTTS
	- https://huggingface.co/2Noise/ChatTTS
- 『エビデンスを嫌う人たち　科学否定論者は何を考え、どう説得できるのか？』by 暦本先生
	- https://x.com/rkmt/status/1795636068752212063
	- おおー。しかしエビデンスベースで思考する人類はむしろ少数派かもしれない..(System1思考=Fast Thinking > System2思考 Slow Thinking) 。エビデンスよりもストーリーが優先する.
- 進化的マージによって相当強そうなモデル、Umievo-itr012-Gleipnir-7Bが生まれました。3回ElyzaTasks100で評価した平均スコアは3.91！　by うみゆきさん
	- https://huggingface.co/umiyuki/Umievo-itr012-Gleipnir-7B
	- マージに使用させていただいたのはJapanese-Starling-ChatV-7B、Ninja-v1-RP-expressive-v2、Vecteus-v1、Japanese-Chat-Umievo-itr004-7bの４つです。各モデル制作者のAratakoさん、Bakuさん、Local-Novel-LLM-projectのみなさまに感謝します。それから問題解決のきっかけをくれたHoly-foxさんに感謝します。
- AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)
	- https://x.com/emollick/status/1795830809217454536
	- https://www.researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models
	- GPT-4 wins. Better prompting can further improve performance & diversity of ideas.
	- ついに創造性でもGPT-4が、（普通の）人間を抜いたのか。。
- Gemini 1.5 FlashはClaude 3 Opusに匹敵しながら、コストは100万トークンあたりたったの55円
	- https://x.com/gijigae/status/1795743286533255285
- Announcing Codestral: our first-ever code model
	- https://chat.mistral.ai/chat
	- "Write me a function that computes fibonacci in Rust"
- OllamaがCodestralに対応
	- https://ollama.com/library/codestral
- "Science in the Age of AI - How AI is changing the nature and method of scientific research,"
	- https://royalsociety.org/-/media/policy/projects/science-in-the-age-of-ai/science-in-the-age-of-ai-report.pdf
	- 英国ロイヤルアカデミー
	- Generative AI tools can assist the advancement of scientific research.
-  Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- 1. You can extract out a knowledge graph according to a set of extractors. These extractors include defining a pre-defined schema of entities/relationships/properties, defining a set of node relationship with llama_index constructs, or implicitly figuring out the schema using an LLM.
	- 2. You can now query a knowledge graph with a huge host of different retrievers that can be combined: keywords, vector search, text-to-cypher, and more. 3. You can include the text along with the entities/relationships during retrieval 4. You can perform joint vector search/graph search even if your graph store doesn’t support vectors! We’ve created robust abstractions to plug in both a graph store as well as a separate vector store. 5. You have full customizability: We’ve made it easy/intuitive for you to define your own extractors and retrievers.
- The structure of the EU AI Office
	- https://x.com/LuizaJarovsky/status/1795775192347627857
	- The “Excellence in AI and Robotics” unit
	- The “Regulation and Compliance” unit 
	- The “AI Safety” unit
	- The “AI Innovation and Policy Coordination” unit
	- The “AI for Societal Good” unit 
	- The Lead Scientific Advisor
	- The Advisor for International Affairs
- 英国のアカデミー、Royal Societyも「AI for Science」ではなくEUと同じ「AI in Science」。レポートはかなり充実している by maruyamaさん
	- https://x.com/rmaruy/status/1795967400502006026
- Mamba, Griffin, RWKV, RetNet, Recurrent Gemma- 2024 is the year of gated linear RNNs! What's their secret sauce?
	- https://x.com/ItamarZimerman/status/1796181061984030914
- CRDSの新作プロポーザル『次世代AIモデルの研究開発』がめちゃくちゃいい仕事で一気見した。
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-SP-03.html
	- https://x.com/resnant/status/1796181056283898332
	- LLM含め最近の基盤モデルや生成系AIの動向と諸課題を技術的にも掘り下げてて、いろいろな立場の人に参考になると思う
- [LoRA] by Hand
	- https://x.com/ProfTomYeh/status/1796169087665557729
	- How does LoRA reduce the number of trainable parameters?
-  Don’t Believe the AI Hype
	- https://www.project-syndicate.org/commentary/ai-productivity-boom-forecasts-countered-by-theory-and-data-by-daron-acemoglu-2024-05?
	- ダロン・アセモグル氏の分析では、AIによって影響をうける人間のタスクは4.6％で、向こう十年のAIによる全要素生産性の向上は0.66%にとどまる。AIによる科学発見は直近では経済にさほど影響しない。かつての自動化技術に比べると格差拡大効果は小さいが規制は必要
-  Aurora: A Foundation Model of the Atmosphere
	- https://arxiv.org/abs/2405.13063
	- NASA has created a new foundation model for geospatial data.
	- Create 5-day air pollution predictions in < 1 minute 
	- Create 10-day weather forecasts at ~10km resolution 
	- Assess the chemical make up of the atmosphere
- llm.cを使うとGPT-2を$20で2時間以内に構築可能？？
	- https://x.com/overlast/status/1796028138616422535
- Here’s a great guide teaching you how to construct knowledge graphs using LLMs that adhere to a pre-defined schema - using purely local models
	- https://x.com/llama_index/status/1796198853764595725
- 「大規模言語モデルの開発」 by　岡崎さん　@ JSAI2024
	- https://speakerdeck.com/chokkan/jsai2024-tutorial-llm
	- チュートリアル講演を行いました。事前学習、インストラクションチューニング、アライメント、評価の４部構成で、最近の研究動向や知見を紹介しました。
- Prompt Engineering for Generative AI
	- https://www.amazon.com/gp/product/B0D4FBPLX1?&linkCode=sl1&tag=kirkdborne-20&linkId=17812cf95726cdbbe7b0c29f94f4bce7&language=en_US&ref_=as_li_ss_tl
	- With this book, you'll gain a solid foundation in generative AI, including how to apply these models in practice. When first integrating LLMs and diffusion models into their workflows, most developers struggle to coax reliable enough results from them to use in automated systems.
- LLMs achieve adult human performance on higher-order theory of mind tasks
	- https://huggingface.co/papers/2405.18870
	- LLMs achieve adult human performance on higher-order theory of mind tasks 
	- This paper examines the extent to which large language models (LLMs) have developed higher-order theory of mind (ToM); the human ability to reason about multiple mental and emotional states in
	- We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level performance on ToM tasks overall, and that GPT-4 exceeds adult performance on 6th order inferences
- 生成AIによる「慣用表現の『乗っ取り』」と、その根底にある別の問題と by TJOさん
	- https://tjo.hatenablog.com/entry/2024/05/31/171000
	- 「ChatGPTに学術論文を（英語で）書かせると"[delve](https://eow.alc.co.jp/search?q=delve)"のような普段使わないような単語が多く使われるのでバレやすい」という話が[SNS](https://d.hatena.ne.jp/keyword/SNS)以下各所で頻繁に噂
	- ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果である、というものです。そもそも、例えば"delve"という単語はナイジェリア英語ではビジネスフレーズの中では比較的頻繁に用いられるそうで*3、それらのナイジェリア英語によるチューニングの結果がChatGPTの出力に影響している、ということのようです*4。
- The new Anthropic prompt engineering tool is incredible.
	- https://x.com/dr_cintas/status/1796577510773379479
	- You just need to write your goal and Claude will generate an optimized prompt instantly.
-  An entirely open-source AI code assistant inside your editor
	- https://ollama.com/blog/continue-code-assistant
	- つまり、ollamaをつかって、あなたの好みのエディタにCode assistanceをという話
- 最近の7B小型日本語LLMはエージェントになれるのか？
	- https://soysoftware.sakura.ne.jp/archives/3934
- 


## 5/27

さて今週は、MicrosoftのBuild2024が開催、gpt-4oを組み込んだCopilot+PCというintelはいってないPCのほかに、誰でもエージェントを作れるCopilot 進化的の更新や、人の代わりに会議進行をしてくれるTeam Copilot、さらには、ソフトウエア開発自動化の「Devin」の会社との提携など、目白押し。まあ早速、ゲームをサポートするcopilot assistantのデモをGemini 1.5 Flashで、さらにマリオゲームで再現できたとの個人の報告もありました。さて来月のAppleの WWDC24はどうなる。基盤技術では、チューリングテストでGPT-4は54%の確率で人間だと判断されたというのは、もう驚かない、AIによる詐欺にあわないように心がけても無駄という未来が、、。むしろ、「LLMがチャットUIに呪われている」という記事もあったが、もやはLLMの発展は人間が律速していて頭打ちになっている。一方AnthropicのClaude3 Sonetに対する特徴抽出の論文、つまりニューラルネット上にLLMの性質あるいは特徴を示す場所を特定する技術（スパースオートエンコーダ）、安全性の分析で役に立つといっているが、逆に特定の箇所を特別に活性化させれば、例えば、ゴールデンゲートブリッジ一押しのLLMが爆誕するとのこと。いやまさにもろ刃の剣となる重要な技術。知識グラフのRAGもアツイが、GraphRAGという画像化した知識グラフに対するRAGという技術、マルチモーダルだとそういうこともできるのか。今井さんのGPT-4oを研究者視点で「時代の転換点」と解説した記事のシリーズは気になるが登録が必要なのか。GUILDの深津さんの、横須賀市の未完成のお悩み相談チャットボット。不完全でもベータ公開というわりにやっぱよくできている。その深津さんが、生成AI時代に大事なスキルは、「やり続ける能力」、いくら生成ＡＩが優れていてもめげないことが大切。ローカルLLMも相変わらずアツイ！。今週も、Mistral v0.3がリリース、語彙数も増えて、見違えるくらい日本語能力が強化され、function callingへも対応、ollamaもraw modeでfuntion callingへ即追従。一方、マルチモーダルphi3-visionも含めてリリースされたphi3-small,medium、phi3-mediumがMMLUスコアはLlama3-70B並みに高性能であるということだが、量子化でデグレードしたのかOllamaへの組み込みはうまくいってない模様。Transformers.js とONNX Runtime Webの組み合わせというのも、ローカルLLMの協力な助っ人か。Cohereが多言語指向のオープンLLMであるAya 23 の 8B と35Bがリリース、日本語強そう。しかし、Phi-3は、「最も有能で費用対効果のSML (Small Language Model)」っていうんだ(Small LLMのほうがかっこよいのに)。 それにしても DeepSeekV2 、あまりに性能が高いので中国での競合のサービス料を1%押し下げた（投げ売り開始？）とのこと。ChatVector、7BモデルのFineTuning結果を70Bに転移させて性能向上したり、LLaVAの日本語化など、ローカルLLMでもその能力をふくめて認知や利用が増えてきた。transformersがv4.41.0にアップデートされてggufをサポートするようになったのも、ローカルLLM勢には朗報。EUのAI法が最終合意、生成ＡＩの規制も盛り込み済み。一方OECDはAIリスクに関する用語を整理し、インシデントの重大さにハザードが起こる確率を加味したものがリスクのレベルになるとのこと。英国の「Safeguarded AIプログラム」は、安全性のために数理論理学や圏論を利用する、同じsafe guardでも毒には毒をということでguard自体をLLMで実現するメタのアプローチと真逆で面白い。

-  Unleashing the Power of Knowledge Graphs in Retrieval Augmented Generation (RAG): Step by Step Instruction
	- https://medium.com/@transformergpt/unleashing-the-power-of-knowledge-graphs-in-retrieval-augmented-generation-rag-step-by-step-84c2adc66c1c
	- This is a neat resource by Jayita B. on teaching you how to not only build an advanced RAG indexing/query pipeline, but also turn it into a full-stack application with rapid respons
- OECD (2024), "Defining AI incidents and related terms",
	- https://www.oecd-ilibrary.org/science-and-technology/defining-ai-incidents-and-related-terms_d1a8d965-en
	- OECDのWGが作っているAIリスクを分類するための用語整備のレポート。起こりうる被害をハザード、起こった被害をインシデントと呼び、その重大さを考慮。ハザードに起こる確率を加味した全体がAIリスクとなる
- Text-to-SQL - fully local edition
	- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
- Run Mixtral 8x7B-on a free-tier Google Colab with AQLM-2bit quantization
	- https://www.youtube.com/watch?v=6ikUpJcDrPs&list=PLxqBkZuBynVTzqUQCQFgetR97y1X_1uCI&index=32
- The theoretical minimum series by Leonard Susskind and Art Friedman
	- https://x.com/PhysInHistory/status/1792020784854311205
- Chat VectorでLLaVAを日本語対応させる
	- https://zenn.dev/toshi_456/articles/0166a6eaa81c7b
	- LLaVAは大きくVision Encoder、Vision Projector、LLMという3つの部品からできていますが、LLMの部分だけ上記のように重みを加減算します
	- 今回使用するLLaVAの重みは[liuhaotian/llava-v1.5-7b](https://huggingface.co/liuhaotian/llava-v1.5-7b)です。このモデルのベースのLLMは[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)です。
	- Chat Vectorやその他のマージ手法を使用することで、英語のデータセットを日本語に翻訳して、学習させるという手間が必要なくなる可能性があるのはありがたいなと感じました。
- 横須賀市で、未完成のお悩み相談チャットボットをリリースしました。 by 深澤さん
	- https://www.city.yokosuka.kanagawa.jp/0835/nagekomi/20240520_soudanbot_nyanpei.html
	- あえて未完成のボットを公開して、広く不具合をあつめる実験です！！
	- さすがのでき前！
- 円の実力と日本企業の通貨戦略（配付資料・動画配信
	- https://www.youtube.com/watch?v=reLhpQg9muo
- 「kagglehub を使った大規模言語モデル gemma のファインチューニングとモデル共有」
	- https://www.kaggle.com/code/makimakiai/kagglehub-gemma
	- Kaggleのノートで銅メダルゲットした！嬉しい！
		- https://x.com/hAru_mAki_ch/status/1792105063022018835
- Deep Dive on Accumulated Local Effect Plots (ALEs) with Python
	- https://towardsdatascience.com/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee
	- ALEs give interpretations that are robust to multicollinearity.
- 英国政府が100億円超を投じる「Safeguarded AIプログラム」とは
	- https://www.aialign.net/blog/20240520-takatsuki
	- 本プログラムにおいてAIシステムの安全性の証明可能性の土台となる理論（特にTA1.1で扱われる内容）には、数理論理学や圏論といった分野が重要な位置を占めることが予定されており、これらの分野の研究者の協力が必要とされています
- Copilot + PC by Nadella
	- https://x.com/satyanadella/status/179261785138542602
	- Introducing Copilot+ PCs—the fastest, most AI-ready Windows PCs ever built.
		- Powered by new NPU (40+ trillion operations per second)
		- Rearchitected Windows 11 
		- 58% faster than Macbook Air M3 
		- Copilot shipping with Windows 
		- Copilot built into Settings, files, notifications 
		- Powered by GPT-4o
- LangChainにObsidianのローダーがある～。ObsidianのメモをベクトルストアしてRAGできてしまう～
	- https://www.youtube.com/watch?v=E-CNrXhSvLg
- The Illustrated Stable Diffusion	
	- https://jalammar.github.io/illustrated-stable-diffusion/
- Google has released Gemini 1.5 Flash.
	- https://x.com/dr_cintas/status/1792572374300188752
	- An AI model optimized for speed and efficiency, with multimodal reasoning and an impressive 1M context window!
-  AWS、一般提供開始した生成AIサービス「Amazon Q」、および「Bedrock」と今後の戦略を説明
	- https://internet.watch.impress.co.jp/docs/news/1592518.html?ref=smartnews
- The theory of mind—the ability to track a person's mental state—is tested comparing humans vs GPT-4 and LLaMA2 large language models
	- https://www.nature.com/articles/s41562-024-01882-z
- GeminiがYouTube動画を一瞬で要約してくれるようになった（しかも無料
	- https://www.lifehacker.jp/article/2405-use-gemini-summarize-youtube-videos-free/
	- 本当だ！
- 観察スケール則は、LLMの標準的ベンチマークの性能から求められた主成分（3つ程度）を用いて複雑な後続タスクの性能を高精度で予測できる法則　by 岡野原さん
	- https://arxiv.org/abs/2405.10938
- BREAKING: Council of Europe adopts 1st international treaty on AI. Here's what you need to know:
	- https://x.com/LuizaJarovsky/status/1792224914646200512
-  Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings
	- https://arxiv.org/abs/2405.10938
- 論文メモ: Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models b y はちさん
	- https://note.com/hatti8/n/nb61b4935c793?sub_rt=share_pb
	- Googleが先週出したLLMの自己改善手法であるReSTEMについて、メモを書きました。
	- 合成データ生成手法としてどうかという視点で書いています
- p値姫（サンプル数編）
	- https://x.com/spine_surgeon_/status/1792767885615759746
	- 「マリオへ、実験結果いい感じです！いい感じなんですけど、有意差でるまでサンプル数増やしてみてください。有意差出るまで連絡は不要です。ピーチより。」
- People cannot distinguish GPT-4 from a human in a Turing test
	- https://arxiv.org/abs/2405.08007
	- AIの人間らしさを測るテストで世界一有名なチューリングテストですが，さんざん「もうAIはチューリングテスト突破できるやろ」と言われてたのを真面目に分析した論文が出ました
	- 結論は「現在のGPT-4などの最先端AIは，チューリングテストを突破可能であり，人間はもはや人とAIを会話のみから判定することはできない」というものです．GPT-4は54%の確率で人間だと判断された模様
- 最近ローカルLLMがアツいらしい
	- https://soysoftware.sakura.ne.jp/archives/3903
	- GPTのAPI高い問題 ＆ OpenAIがAIベンチャー皆殺しにしてしまう問題
	- ローカルLLM推論ライブラリが色々ある
		- Llma.cpp, ollama, vLLM
	- 強力な大型オープンなAIモデルが公開されはじめてる
		- Command R+（非商用利用）やLlama3-70B、DeepSeek-V2
	-  小型のAIモデルの性能向上の潮流
		- Mistral-7Bベース、ChatVector、
	-  個人でもAI開発競争に食い込める可能性について
- 生成AI時代に大事なスキルは、「やり続ける能力　by 深津さん
	- https://x.com/fladdict/status/1792831115528663471
	- 生成AI時代には「もうあいつ（AI）一人でいいんじゃないかな」と、色々なことで挫折する人が大量発生する。「手をとめない」能力が、人類にとって最重要の才能になるかもしれない
- transformers v4.41.0
	- https://github.com/huggingface/transformers/releases/tag/v4.41.0
	- Phi3, JetMoE, PaliGemma, VideoLlava, Falcon2, FalconVLM & GGUF support
		- https://huggingface.co/docs/transformers/v4.41.0/en/gguf
- Phi 3 - Small, Medium & Vision
	- https://x.com/reach_vb/status/1792949163249791383
	- This includes the 7B and 14B models
	- This also includes a multimodal phi model
- Knowledge Cards by Perplexty	
	- https://x.com/perplexity_ai/status/1792948540542517458
	- We’re teaming up with @TakoViz to bring advanced knowledge search and visualization to our users. Now, you can search, juxtapose, and share authoritative knowledge cards in Perplexity.
	- Perplexityが高度な情報検索と視覚化ができる「knowledge cards」という機能をリリース。
	- 自由に任意の2社の株価推移の比較が可能。リサーチ業務が捗り、仕事で活躍間違い無し。
- GraphRAG: Using Knowledge in Unstructured Data to Build Apps with LLMs
	- https://www.graphlit.com/blog/graphrag-using-knowledge-in-unstructured-data-to-build-apps-with-llms
	- We have used Graphlit to automatically extract images from PDFs, and are using the OpenAI GPT-4 Vision model to perform OCR and generate detailed text descriptions of the images.
	- どうも、知識グラフの画像から知見を得るらしい。
- I built my own omni assistant using Gemini 1.5 Flash to guide me through Super Mario 64.
	- https://x.com/skirano/status/1792948429754151293
	- MicrosoftがBuildででもした、assistantを、gemini 1.5 Flashで実装したツワモノ、お題はマリオだし。
- What is the context window?
	- https://x.com/cwolferesearch/status/1792950349696753980
		- Claude-3 has a 1M context window 
		- Gemini-1.5 Pro has a 2M token context window 
		- Recent research [3] has explored going even beyond 2M tokens.
- ICity, a Geometry Nodes-powered procedural city generator for Blender.
	- https://x.com/80Level/status/1792769380717068510
	- Available now in Beta
		- https://80.lv/articles/long-awaited-procedural-city-generator-for-blender-is-now-available/
- Microsoft、Copilot 進化的の新機能を発表
	- https://x.com/shota7180/status/1792966382990270739
	- Copilot 進化的の更新により、誰でもエージェント機能を持つコパイロットを構築可能に
	- このコパイロットは、ユーザーの代わりに独立して積極的にタスクを調整・実行
	- 特定の役割や機能に合わせてタスクを個別に調整できる
- MIcrosoft's Phi-3 really is an astonishingly good model
	- https://x.com/simonw/status/1792691120675467288
	- MIT licensed and small enough to run in a browser on WebGPU (about a 2.3GB downloads), but still provides high quality results for a lot of the stuff I care about
	- Phi-3-mini running locally in your browser at 70 tokens per second on WebGPU!
	- Powered by 🤗 Transformers.js and ONNX Runtime Web! 
	- https://huggingface.co/blog/Emma-N/enjoy-the-power-of-phi-3-with-onnx-runtime
- Hugging Face and Microsoft Deepen Collaboration
	- https://huggingface.co/blog/microsoft-collaboration
- Tako, the first AI search engine for visualizing and sharing the world’s knowledge.
	- https://x.com/TakoViz/status/1792949400710574455
	-  Introducing Tako, a new way to reference real knowledge And our first integration, Perplexity
		- https://trytako.com/blog/introducing-tako-and-perplexity-integration
- Team Copilot by Microsoft 
	- https://x.com/msdev/status/1792967099519758822
- 13B phi-medium-4k GGUF files here, model is looking very very good.
	- https://huggingface.co/nisten/phi3-medium-4k-gguf
- 本日（5/20）、EUのデジタルアイデンティティ法が施行
	- https://x.com/_nat/status/1792915589570154637
- マイクロソフト、自律型AIソフトウェアエンジニア「Devin」のCognition AIと提携を発表。Azure上でDevinを提供へ
	- https://www.publickey1.jp/blog/24/aidevincognition_aiazuredevin.html
-  Mapping the Mind of a Large Language Model
	- https://www.anthropic.com/research/mapping-mind-language-model
	- Anthropic has just revealed some exciting news about Claude Sonnet. They've successfully identified how millions of concepts are represented inside this massive model!
- ollama run phi3:medium
	- https://x.com/ollama/status/1793067457382343134
- Phi-3-vision ・ Phi-3-medium ・ Phi-3-small の概要 by npakaさん
	- https://note.com/npaka/n/nb050244392a4?sub_rt=share_h
	- 「Phi-3」は、最も有能で費用対効果のSML (Small Language Model) であり、さまざまな言語、推論、コーディング、数学のベンチマークで同じサイズと次のサイズのモデルを上回っています
	- 「Phi-3-vision」は、チャートや図から洞察を生み出すことができます。
	- 「Phi-3-small」「Phi-3-medium」は、同じサイズの言語モデルだけでなく、はるかに大きい言語モデルよりも優れたパフォーマンスを発揮します
	- SLMは、より単純なタスクでうまく機能するように設計されており、リソースが限られている組織にとってよりアクセスしやすく、使いやすく、特定のニーズに合わせてより簡単にファインチューニングできます
-  GPT-4oをわかりやすく解説、専門家が「時代の転換点」と評価するヤバすぎる能力とは by 今井さん
	- https://www.sbbit.jp/article/cont1/140613
	- OpenAIのGPT-4oを研究者視点で解説した記事が出ました! 速報的な記事の依頼でしたが,やはり研究者が書くということで情報をすべて詰め込んだ1万文近いガチ解説記事になりました.3回の連載です.
	- 言語,音声,動画像,後半ではGPT-4oの「弱み」等,日本語記事では一番詳しいはず
- MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning
	- https://arxiv.org/abs/2405.12130
	- LoRAより知識獲得系タスクに強いMoRA　 by shi3zさん
- ルカン先生、学生に次世代AIを作ろうとするなれば、LLMをやるのではないよとアドバイス
	- https://x.com/ylecun/status/1793326904692428907
	- If you are a student interested in building the next generation of AI systems, don't work on LLMs
- Mistral v3 base and instruct released
	- https://huggingface.co/mistralai
	- Base has vocab extended to 32768. 
	- Instruct supports function calling! 
	- Tokens 5 to 9 are for function calling & the rest are empty
- Interface 7月号では，Copilotで文芸的プログラミングに挑戦します．
	- https://x.com/If_CQ/status/1793214032121614787
	- ドキュメントとソースコードを同時に開発保守するのがDonald. E. Knuth博士の「文芸的プログラミング」．CopilotとDoxygenを使えば，記述が自動化でき，両者の不一致を防げます．ソフトウェア開発の理想を最新の技術で実現します．
- New guide in our AI cookbook: 𝙎𝙩𝙧𝙪𝙘𝙩𝙪𝙧𝙚𝙙 𝙜𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣
	- https://huggingface.co/learn/cookbook/structured_generation
	- This technique lets you force your LLM to generate its output as a JSON with specific keys: great for RAG or LLM-judge!
- Large Language Models Meet NLP: A Survey
	- https://arxiv.org/abs/2405.12819
	- Provides a comprehensive survey of how LLMs are applied to NLP tasks, introducing a new taxonomy and discussing current progress, future frontiers, and challenges.
- Mistral AI's Mistral v0.3 supports function calling with Ollama's raw mode!
	- https://x.com/ollama/status/1793392887612260370
	- Ollama raw mode
		- https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode
- Mistral-7BとPhi-3もこの際ElyzaTasks100で評価してみた。by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793550842353820014
	- まずMistral-7Bはv0.1が2.46、v0.2が2.69（やたら英語で回答してくるので半分以上英語の回答は手作業で1点に減らした）、からの今回のv0.3は3.52！見違えるくらい日本語能力が強化されてます。英語で答えちゃう問題もほぼ起きない。
	- Phi3は3.8Bのmini-128kがまさかの3.26というこのパラ数にしては高すぎるスコアでなぜかsmall-128kに勝ってしまってます。
	- small-8kは3.28で、miniと大差ないという意味では残念。同パラのMistral-7B-v0.3にも負けてる。
	- でもmedium-128kは14Bパラで3.96というバケモンみたいなスコアが出てます。これはすごすぎ
- GPT-4oとGPT-4TurboのElyzaTasks100の平均スコア、
	- https://x.com/umiyuki_ai/status/1793540614551904762
	- 気になってたのでAPI代払って評価してみた。
	- GPT-4Turboが4.44、GPT-4oが4.51！やっぱりエゲつない超スコア！
	- オープンなモデルがGPT-4Tに追い付いてきたなんてちょっと言えなくなった
- Phi-3-MediumのMMLUスコアはLlama3-70B並み… by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793614730403434950
	- やっぱり伊達じゃないらしいね。ElyzaTasks100でも匹敵してるもん。しかし信じがたいね 
- Aya 23 is here! Available in 8B and 35B.
	- https://ollama.com/library/aya
- LangChain `with_structured_output` メソッドによる構造化データ抽出
	- https://zenn.dev/ml_bear/articles/cb07549ec52175
	- 1.  構造化データをPydanticで定義する
	- 2.  その定義を`.with_structured_output`でLLMに取り付ける
	- Pydanticでスキーマを定義した上で構造化データ抽出するのは非常に簡単です
- 「AIスタートアップは街の電気屋さんから始めろ」
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo1-4.pdf
	- AI戦略会議の松尾研の資料「生成AIの産業における可能性」
	- まずは受託開発で社会を学ぶ。 受託開発で地域の企業のDXを支援しつつ、一緒にグローバルに出ていく
- 世界初、AI技術による原油処理装置の自動運転を開始　PFN
	- https://www.preferred.jp/ja/news/pr20240524/
- 機械学習による反応予測の論文
	- https://chemrxiv.org/engage/chemrxiv/article-details/664de6a821291e5d1df74ac0
	- SMILESにより化学反応をテキストで表現したSMIRKSを用いることで、化学反応のルールを高精度に学習できたそうです。寄与する原子数が多い複雑な反応は今後の課題とのこと
- LLMはチャットUIの誕生でブレイクスルーを起こしたが、今はチャットUIに呪われている
	- https://x.com/rkmt/status/1794013338005090666
	- 「有効な質問をLLMに投げ回答を得るサービス」は一定量（それを使いこなせる人類の数<<人類の総数）で頭打ちになり、それ以上は「意味もない内容もないけど楽しい会話をAIと続ける」サービスか、「人間を必要としないAI業務」に移行するのかも。
- ぱぷりか炒め（mmnga）さんの、Llama-3-70B-japanese-suzume-vector-v0.1 すごい、 by AIサトシ
	- https://x.com/AiXsatoshi/status/1793973265532424467
	- 8bのLlama派生モデルのchatvectorを、パラメータ数違う70Bにマージしてて、さらにベンチマーク結果も良好なのすごい
- Cohereが多言語指向のオープンLLM「Aya」（8B，23B）を公開
	- https://huggingface.co/spaces/CohereForAI/aya-23
	- 4月には当時のオープンLLM最高性能のCommand R+を出してたCohereの多言語LLMなので,日本語も期待できそう...実際に日本語は結構うまいんですが,色々と簡潔すぎて自分の中での評価が「冷たいモデル」です
-  DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
	- https://huggingface.co/papers/2405.14333
	- Proof assistants like Lean have revolutionized mathematical proof verification, ensuring high accuracy and reliability. Although large language models (LLMs) show promise in
- ollamaでPhi3-mediumは「性能ショボい」？　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793878129699950887
	- OllamaでPhi3-mediumをプルするとQ4_0量子化版がDLされるようだが、スコアは3.68。Q4_K_Sでも3.67。ちなみに僕が最初に検証したLlama. cppのQ8は3.88だったし、同じくLlama. cppのQ4_K_Sも3.95で劣化どころかスコア上がってる。というわけでollamaのPhi3-mediumはパラ設定かなんか分からんけど何らかの問題で劣化してます
- DeepSeekV2 is a big deal.
	- https://x.com/Xianbao_QIAN/status/1794034052347171055
	- Not only because its significant improvements to both key components of Transformer: the Attention layer and FFN layer. 
	- It has also completed disrupted the Chines LLM market and forcing the competitors to drop the price to 1% of the original price.
- Difyを使うメリットの一つが開発したChatbotやワークフローを簡単にWEBでシェアできること
	- https://x.com/gijigae/status/1793437095727665588
-  Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet
	- https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
	- Anthropicの中規模生産モデルであるClaude 3 Sonnetにスケールアップされたスパースオートエンコーダーを適用し、解釈可能な特徴を抽出する研究
	-  **スパースオートエンコーダー**: 小規模トランスフォーマーから単義的特徴を回復する方法を示した研究から発展し、大規模モデルへのスケーリングが重視されています。
	- **解釈可能な特徴**: 抽出された特徴は多言語、多モーダルであり、具体的および抽象的な参照の間で一般化されています。
	- **安全性関連特徴**: セキュリティの脆弱性やバックドア、偏見、嘘や欺瞞、危険または犯罪的な内容など、AIシステムが引き起こす可能性のある様々な問題に関連する特徴が観察されています。
	- **スケーリング法則**: スパースオートエンコーダーの訓練にスケーリング法則を適用し、計算予算に基づいて最適な特徴数と訓練ステップ数を決定しています。
- ハル・ベリーニューロンがAIで実体験できる時代が到来
	- https://x.com/webbigdata/status/1794030396990226803
	- ハル・ベリーさんという、X-MENのストームとかキャットウーマン役をやってるアメリカの女優さんがいるのですが、ある患者さんの特定のニューロンが「ハル・ベリーの写真」や「ハル・ベリー」というテキストに対して活性化する事が観察されたという研究がある。
	- 5月21日にanthropicがClaude 3 Sonnetで何百万もの概念がどのように表現されているかを特定できたよ～と発表し、
	- その技術を使って、サンフランシスコのゴールデン ゲート ブリッジ(Golden Gate Bridge)に対応するニューロンを活性化させてている「Golden Gate Claude」と実験的に対話できるようにしたよ～と発表したのが昨日ですね。
	- 一言で言えば、やたらめったらゴールデン ゲート ブリッジ推しをしてくるAIで、色々なタイミングでゴールデン ゲート ブリッジを推薦してきます。
- streamlitでデプロイするイメージです。 GitHubと接続すれば、本当に爆速で
	- https://x.com/kenken26679105/status/1793889080385925580
- ChatVectorで7BモデルのFineTuning結果を70Bに転移させるみたいな話、by はちさん
	- https://x.com/CurveWeb/status/1794203714422759707
	- 事前学習では既に小さいモデルで事前学習→セルフマージで大モデル化っていうのができているのでなんとなくできて然るべき感ある。

## 5/20

今回は、GPT-4oさんに、まとめをお願いしました（無修正です！！）。ここまで来たか、と驚くようなさみしいような。。大切なことは、もう一度言います、無修正です。では、

最新の大規模言語モデル（LLM）の動向について、今回はちょっとユーモアも交えつつお届けします。まずは、絶対に見逃せない二つの大ニュースから。 最初に、大きく注目を浴びているのがOpenAIの新モデル「GPT-4o」です。どうやらこのモデル、名前だけじゃなくて性能もまさに「おお！」と言いたくなる程の進化を遂げています。他のモデルと比べて速度は2倍、コストは半分、レートリミットが5倍と、まさにスーパーAI。さらに無料プランのChatGPTユーザーでも使えるようになるとのことで、サム・アルトマンさんから直接のお知らせも飛び出しました。しかも、このGPT-4oは数学の難関問題を画像で出題しただけで解けるという、まるで魔法のような能力を持っているのです。この進化により、動画の要約や化学実験の考察まで、ヘビーユーザーの活用法がどんどん増えているのが現状です。 次はGoogle I/Oでの発表です。トップバッターは新しいビジョン・ランゲージモデル「PaliGemma」と「Gemma 2」。その大きな見どころは、Gemma 27Bというサイズでも新しいアーキテクチャを駆使して、モデルが2倍のサイズのものにも勝る性能を発揮すること。これ、まるでヒーロー映画の続編が発表されるかのようなワクワク感がありますよね。そしてさらに「Trillium」という次世代Google Cloud TPUの登場で、このスーパーAIヒーローたちがさらに効率良く動作することが期待されています。ああ、今夜のビリー・アイリッシュのライブにでも登場しそうな勢いです。 さて、話題を変えて、最近の秀作をご紹介します。DeepLearningAIから無料コースが続々登場しており、MistralAIを使ったコースを提供中です。このコースでは、Mistralのモデルに加えて、RAG、関数呼び出し、そしてJSONモードなどまで学ぶことができます。これを受けて、プロンプト設計での尤度関数の捉え方について議論が巻き起こっています。「それってプロンプトダンサーの必須スキル？」と思わせるような専門的な話題も含まれています。 一方、HuggingFaceのトークン化とllama.cppのトークン化に違いがあることが議論されています。これはまるで、映画の字幕と吹き替えの違いくらい注目されているトピックです。特にLlama3やGemmaモデルに関して、量子化に問題がある可能性も浮上しています。んん、やっぱりテクノロジーの進化も一筋縄ではいきませんね。 そしてお待ちかね、npakaさんの情報を一気にまとめてチェック。彼はOpenAIのModel Specについての概要を詳述しています。また、新しいLangChain v0.2を使ったエージェント構築や、RAG、特定の情報源に関するQAシステム、情報抽出、要約などのユースケースも紹介しています。「LangChainハッカー」なんて称号が彼に似合いそうですね。 ここまで大まかなトピックをご紹介しましたが、その他の小ネタも盛りだくさんです。例えば、Mozillaのやる気満々なローカルリサーチツール「llamafile」や、LangChainとHuggingFaceの強力な提携など、どんどん新しい機能が登場していますよ。この分野の進展の速さを見逃さないでくださいね。 現場はまるで、ピーターパンのネバーランドのように変化に満ちています。今後も続々と驚きと笑顔が待っているかもしれません。さあ、次はどんな冒険が待っているのか、楽しみですね！

- またまたDeepLearningAIより、MistralAIを用いた無料コース
	- https://www.deeplearning.ai/short-courses/getting-started-with-mistral/
	- Mistral AIによる1時間のコース。Mistralのモデルだけでなく、RAG、関数呼び出し、JSONモードなどについて学べる
- b氏が、「ローカルLLMはこーやって使うの」にかみつく、
	- https://x.com/behemuhemulove/status/1789537738590765215
	- 「尤度関数の所が俺には意味が良くわからなかった。プロンプトをパラメータといってるのに、プロンプトを固定したらパラメタの関数にならないから尤度関数じゃなくない？」
	- →プロンプト振ってるので尤度による最適なプロンプトの推定といってもいいのではないか？
- 主要モデルでHuggingFaceのトークン化とllama.cppのトークン化に差異があったとの事
	- https://x.com/webbigdata/status/1789695414238884256
	- llama3の量子化が腐ってるのはこのせい？
	- 1. Mistral: HF's batch_decode output is wrong 
	- 2. Llama-3: Be careful of double BOS 
	- 3. Gemma: 2nd token has an extra space - GGUF(_Below) = 30641 vs HF(Below) = 33501 
	- 4. Gemma-it: Also be careful of double BOS
- OpenAI の Model Spec の概要 by npakaさん
	- https://note.com/npaka/n/nf6b811cad5dc?sub_rt=share_b
	- モデルの動作を形成するアプローチの透明性を高め、モデルをどのように変更および改善できるかについて公開の会話を開始するために、「Model Spec」を公開します。
- [code-cooker](https://github.com/karaage0703/code-cooker) by からあげさん
	- https://github.com/karaage0703/code-cooke
	- 面倒なことをChatGPT以外のLLMにやらせるソフト。GUIをつけてみました。 ようやく自分でも使いたくなるものができた気がします。まだClaude 3 Opusしか対応してないので、GPT-4とかLlama 3にも対応していきます。GPT対応はOpenAIの発表の後にしようかな
- 大規模パラメータモデルの人たちは、このOpenAIの論文に書いてあること思い出してねだそうで
	- https://x.com/cloneofsimo/status/1789700168083997010
	- Again, the paper im advocating here is from openai, and is referenced all the time and frankly one of the paper all large scale practitioner should read. the math here isn't complicated and nothing here is either controversial nor task dependent.
	- https://arxiv.org/abs/1812.06162
-  技術革新と不平等の1000年史の紹介 by 楠さん
	- https://x.com/masanork/status/1789647931467026613
	- これ特に下巻の読み応えがすごいんですが、技術が約束する未来と社会構造に与える影響とは、分けて議論しなければならないのでは？という課題認識が強く。LLM周辺ではオープンって用語が曖昧に使われたり、生産手段が民主化されていないのが悩みどころ
- ollamaで Fugaku-LLM を動かす
	- https://note.com/npaka/n/n1d99253ae2cf?sub_rt=share_h
	- 一番サイズの小さい（おそらく量子化が一番効いている） 「Fugaku-LLM-13B-instruct-0325b-q5_k_m.gguf」を選びます
	- **`Modelfile`  で一番重要なのは、トークナイザの chat template を守ることです**
	- docker　２発で、ollamaと、web-uiが動くのかー
- 【GPT-4o 爆誕】
	- https://x.com/MLBear2/status/1790069525372981452
	- 従来のGPT-4, Claude 3 Opusなどに比べて頭一つ抜けて賢い（図）
	- gpt2としてChatbot ArenaでテストされていたものがGPT-4oだったとサムアルトマンCEOが認めた。
	- GPT-4 Turboと比べて ・2倍速く ・50%安価 ・Rate limitが5倍高い
- GPT-4oで使われている新しいtokenizer、tiktokenにもう入ってる
	- https://x.com/gyakuse/status/1790110045814010327
	- tiktokenを0.7.0 にアップデートし、enc = tiktoken.encoding_for_model("gpt-4o")とするだけ
- gpt-4oで試しに今年の東大数学2024の問題を画像で送ったら（プロンプト一切無しでも）正解できた
	- https://x.com/kyutaro15/status/1790098489940258830
- サムからのGPT-4oに関するメッセージ
	- https://x.com/sama/status/1790065541262032904
	- it is available to all ChatGPT users, including on the free plan! so far, GPT-4 class models have only been available to people who pay a monthly subscription. this is important to our mission; we want to put great AI tools in the hands of everyone.
- GPT-4oの動画要約をHuggingface Spaceで試せるようにしました by 逆瀬川さん
	- https://x.com/gyakuse/status/1790090822031126730
	- リリースされたGPT-4oを使って動画のサマリー生成をしてみる！
		- https://qiita.com/sakasegawa/items/b82a9745fda81143e409
- GPT-4oに化学実験の結果を考察させてるんですが、 考察が早すぎて、スクロールが追いつかないです　 by 畠山さん
	- https://x.com/kanhatakeyama/status/1790098210360537138
- （OpenAIの新しいtokenizerは）日本語はトークナイザーが改善されてるから、API使用料50% x トークン量70% で 35% ぐらいの費用になるのか？
	- https://x.com/MLBear2/status/1790081289367990668
- LangChainがgpt-4oに対応
	- https://x.com/LangChainAI/status/1790089006455398583
	- You can use the available multimodal capabilities of it in any of your LangChain applications today!
	- https://python.langchain.com/v0.1/docs/integrations/chat/openai/
- TJOさん、デジ庁、データサイエンティスト公募の要件をみて頭を抱える
	- https://x.com/TJO_datasci/status/1790046279428345990
	- 「このスキルの必須要件を全部満たして尚且つ歓迎項目も複数満たすデータサイエンティストなんて、そもそも日本どころか世界を見渡しても探し出すのは困難を極めるのでは。それを公務員の給与で雇うとか無理ゲーにも程があるような気がする」
	- 結局お金の問題か
- GPT-4oはPlaygroundで試せる。 確かに賢いしものすごく速い by shi3zさん
	- https://x.com/shi3z/status/1790073756079059400
- Command-R-Plus, Llama-3, Phi-3 miniを ELYZA-tasks-100 で評価
	- https://qiita.com/wayama_ryousuke/items/a96f11fe2b7e2e3910e5
	- 「今回ご紹介したモデルは、日本語に特化した追加学習を行わなくても、日本語で回答を返すことができるという点が大きな特徴です。」
	- 評価用 Colab ノートブックもあるよ
- Embeddingモデルを使ったベクトル化のしくみ、fine-tuning手法を解説
	- https://speakerdeck.com/payanotty/embeddingmoderuwoshi-tutabekutoruhua-nosikumi-fine-tuningshou-fa-wojie-shuo
-  State-Free Inference of State-Space Models: The Transfer Function Approach
	- https://arxiv.org/abs/2405.06147v1
	- Utilizing the connections between convolutions in the time domain and multiplication in frequency domain (through FFT),
-  GPT-4o の概要 by npakaさん
	- https://note.com/npaka/n/n02331040d8c2?sub_rt=share_b
- JSLM2（Japanese Stable LM 2 Instruct 1.6B）
	- JSLM2は、6B以下の規模のモデルの中で、日本語性能が最も高いと思います。違いますか？ (llm-jp-evalや定性評価で）
	- https://x.com/peacej/status/1789909011132805402
- gpt-4o で使われたo200k_base tokenizer の日本語の部分・・・完全に5ちゃんねる・・・
	- https://x.com/_aixile/status/1790278857641410662
- Andrew Ng先生によるAI エージェント設計パターンの連載
	- https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/
	-  Agentic Design Patterns Part 1
	- Reflection, ツールの使用, プランニング, 複数Agentの協力
- gpt-4o、論文要約してPowerPoint吐いてくれる
	- https://x.com/CurveWeb/status/1790336171777917332
- 大規模言語モデル (LLM)における低精度数値表現 by PFNの三上さん
	- https://speakerdeck.com/pfn/20240508-hpckenkyukai-pfn-llm
	- 学習：8bitが主流になりつつある
	- 推論：1～2bit表現が実用化されつつある
- Introducing Veo: our most capable generative video model　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790435824598716704
	- It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles
- llamafiles from mozilla
	- https://x.com/llama_index/status/1790449858899505616
	- Build a local, private research assistant running on your laptop in a snap with llamafile from Mozilla! 
	- llamafiles are fun: no need to install anything, just download the file and run it, and you get a local LLM and embedding model that you can use directly from LlamaIndex. 
	- https://github.com/Mozilla-Ocho/llamafile
- langchain-huggingface のアナウンス
	- https://x.com/LangChainAI/status/1790419422399877158
	- We're excited to announce the launch of langchain-huggingface, a partner package in LangChain jointly maintained with huggingface
- Entropy minimization がなんで有効か？ ICML
	- https://x.com/ori_press/status/1790383780642918469
	- https://arxiv.org/pdf/2405.05012
- Evaluation of Retrieval-Augmented Generation: A Survey
	- https://arxiv.org/abs/2405.07437
	- https://github.com/YHPeter/Awesome-RAG-Evaluation
- Pattern Language is one of my favorite books, and this abridged hypertext version by zenodotus280
	- https://x.com/kepano/status/1790437820487946630
	- This project is an abridged, hyper-textual, and copyleft manifestation of the 1977 architecture classic _A Pattern Language_ by Christopher Alexander
		- https://github.com/zenodotus280/apl-md
- GPT-4oの登場により、検討中の研究プロポーザルがお釈迦になるというポストたち
	- 「音声言語モデル」について学振書いている間にこれはひどすぎるでしょ
		- https://x.com/nonmetal_/status/1790079046191120560
	- GPT-4o makes me feel both sad for my current work has been scooped by OpenAI, and happy that we are on the right track. by SpeechGPTシリーズの開発者
		- https://x.com/dongzha35524835/status/1790241799547806071
- multi-step reasoning capabilities to Google Search at Google I/O
	- https://x.com/Google/status/1790438800667123860
	- perplexityのようなものがくるのか、
- Linear Regression is one of the most important tools in a Data Scientist's
	- https://x.com/mdancho84/status/1790445342787318206
	- 1. OLS regression aims to find the best-fitting linear equation that describes the relationship between the dependent variable (often denoted as Y) and independent variables (denoted as X1, X2, ..., Xn).
	- 2. OLS does this by minimizing the sum of the squares of the differences between the observed dependent variable values and those predicted by the linear model. These differences are called "residuals."
	- 3. "Best fit" in the context of OLS means that the sum of the squares of the residuals is as small as possible. Mathematically, it's about finding the values of β0, β1, ..., βn that minimize this sum.
- We’re sharing Project Astra: at Google I/O
	- https://x.com/GoogleDeepMind/status/1790433540548558853
	- We’re sharing Project Astra: our new project focused on building a future AI assistant that can be truly helpful in everyday life.
- PaliGemma、Gemma 2　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790459505538658636
	- PaliGemma: a powerful open vision-language model  
	- Gemma 2: coming soon in various sizes, including 27 billion parameters
- GPT-4o shows improvement compared to GPT-4-Turbo-0409 with better probability, pre-calculus, algebra, and geometry abilities. 
	- https://x.com/GanjinZero/status/1790230562453803241
- Get a sneak peek of Gemma 2, at Google I/O
	- https://x.com/Google/status/1790452314278412554
	- 27B parameter instance launching in a few weeks. Built on new architecture, Gemma 27B outperforms models twice its size and can run on a single TPU host in Vertex AI.
- PaliGemma をお試し中
	- https://huggingface.co/spaces/big-vision/paligemma
- Introducing Trillium, the next generation of Google Cloud TPU
	- https://x.com/GoogleCloudTech/status/1790452622295449925
	- It delivers 4.7X the peak compute performance per chip compared to TPU v5e and is equipped with 2X the high-bandwidth memory capacity.
- ZeTT
	- https://x.com/CurveWeb/status/1790308270126883146
	- 「追加のトレーニングをほとんど(もしくは全く)行わずに、任意のモデルを任意のトークナイザーで使用できるようにする手法ZeTT。 ChatVector やモデルマージのTokenizerによる制限を避けるのに使えそう」 by はちさん
- Gemini 1.5 Pro to 2 million tokens at Google I/O
	- https://x.com/Google/status/1790430189916225799
	- Today we’re expanding the context window for Gemini 1.5 Pro to 2 million tokens and making it available for developers in private preview. It’s the next step towards the ultimate goal of infinite context
- Data Scientists: The next level of Data Science AI Agents is called "Plan and Execute".
	- https://x.com/mdancho84/status/1790406221616320862
- GoogleとOpenAIの発表を見てる僕の心境 by GUILDの深澤さん
	- https://x.com/fladdict/status/1790431879512093151
	- 「あ、ゴクウとフリーザが上空で戦ってる！！！すごい速度で見えない！！！頑張れ！！！」というクリリンの心境
- Ilya and OpenAI are going to part ways. by Sam
	- https://x.com/sama/status/1790518031640347056
	- This is very sad to me; Ilya is easily one of the greatest minds of our generation, a guiding light of our field, and a dear friend. His brilliance and vision are well known; his warmth and compassion are less well known but no less
- HCI系のトップカンファレンスCHI2024の全論文をGPT-4で要約スライドにまとめて見たので
	- https://drive.google.com/file/d/1CMkTdGlk1OhtScKUTB7Mt22GtWxgAIPV/view
- Colab 📒 Notebook to fine-tune 💅🏽 @GoogleAI
	- #PaliGemma vision-language model 👓🔠🧠on a free T4 VM
	- https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb
- Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
	- https://note.com/panda_lab/n/n948053d7813f
	- RAGの枠組みを拡張し、Wikipedia自動生成に特化したフレームワーク「STORM」を考案しました。
	-  **課題**: ウィキペディアスタイルの記事は、広範囲の参考文献の収集と、詳細なアウトラインの作成が必要です。従来の方法では、この準備段階がしばしば省略されます。
	-  **解決策**: STORMは、予備的な書き込み、草稿作成、改訂の各段階、特に予備段階での効果的な質問提起により、このプロセスを自動化します。
- 「Stockmark-100b」
	- https://x.com/kosukearima/status/1790902109648695565
	- 産総研ｘストックマーク共同研究の成果、フルスクラッチで学習した100B級日本語LLMを公開しました
	- ストックマークは、1000億パラメータの日本語LLMモデル「Stockmark-100b」を公開しました。 既存のモデルにデータ追加を行いチューニングしたものではなく、ゼロからフルスクラッチで開発したモデルであり、国内では(現状はダントツで)最大、グローバルでも最大級サイズのOSSモデルとなります。
		- https://huggingface.co/stockmark/stockmark-100b
- 「確率思考の戦略論」がもやもやする方へ -NBDモデル編-
	- https://zenn.dev/joanofarc/articles/strange-theory-of-probability-thinking
- LLM に表データを読み解かせたかったので、ちょっと試してみた
	- https://developers.cyberagent.co.jp/blog/archives/47869/
	- In-context Learning をベースとして手法に採用している「表形式データの読み解き」に関する論文(ICML2024)を、個人的ピックアップで紹介してみました。
	- https://openreview.net/forum?id=4L0xnS4GQM
- 負の二項分布の疫学とマーケティングでの応用の比較
	- https://socinuit.hatenablog.com/entry/2024/05/16/185601
	- 西浦『感染症を読み解く数理』と森岡・今西『確率思考の戦略論』において、負の二項分布を用いたモデル応用について記述されており、 相互を参照・比較することで類似点や解釈の拡大を試みる。
	- この記事で述べたいことは、**疫学とマーケティングという一見して距離のある領域で、負の二項分布を用いた現象の確率モデル化の事例が取り上げられていて面白いね**、ということに尽き
- 最近Gemini 1.5 ProのPDFパースが便利だと気づいて色々試している
	- https://x.com/resnant/status/1791104886563811520
	- 今のところ先行研究の論文PDFを放り込んで「この研究のXXという点を解決/拡張するとどんな価値が生まれる？その結果をどう訴求する？」みたいに研究ネタの壁打ちで使うと心強い
-  2023年度 デジタル庁・行政における生成AIの適切な利活用に向けた技術検証を実施しました
	- https://www.digital.go.jp/news/19c125e9-35c5-48ba-a63f-f817bce95715
	- 「実証の最中にも環境が激変する中で、ただ試して終わらせるのではなく、しっかりと知見を共有し、データ整備はじめ次の動きに繋げていくことが重要と考えています」 by 楠さん
	- https://x.com/masanork/status/1790871089121513629
- ChatGPTがGoogle DriveやMicrosoft OneDriveからSpreadsheetやExcelを読み込んで分析・可視化を手伝ってくれる機能を近く公開
	- https://x.com/MLBear2/status/1791251518110523764
-  HCI研究に対する私見 - CHI2024参加を終えて　by 稲見先生
	- https://note.com/drinami/n/nfd4921806ad3?sub_rt=share_pb
	- 「HCI研究おもちゃ論」がかつて議論されていたことがありましたが「おもちゃに詰まった知恵と役割をバカにするな。比喩として不適切」というのが私の見解です
- 「競争力ある生成AI基盤モデルの開発（助成）」に、ELYZAが採択
	- https://x.com/ELYZA_inc/status/1791348009764360577
	- 経済産業省が立ち上げた「GENIAC」のもと、NEDOが公募
	- Mixture of Expertsアプローチの採用や、日本特有のデータの学習、日本語の推論効率化などを実施予定
- "functional ontology"
	- https://x.com/Westoncb/status/1791152606309687768
	- As an alternative to LLM summarizing, I've been getting very interesting results doing something like:
	- https://symbolflux.com/ApolloLunarLandingTrajectoryReconstruction.txt
- QA over large embedded tables without hallucinations (Caltrain schedule edition
	- https://x.com/llama_index/status/1791505972407746671
	- With LlamaParse, we were able to spatially layout the text in a semantically coherent manner, so that our GPT-4o-powered QA pipeline could correctly answer questions
		- https://github.com/run-llama/llama_parse/blob/main/examples/caltrain/caltrain_text_mode.ipynb
- MediaPipe LLM Inference APIを使って、MediaPipe形式に変換するとGemma 2Bや とGemma 7B、Phi-2、Falcon-RW-1B、StableLM-3BなどをブラウザやAndroids、iphoneなどで動かす事ができるようになる
	- https://x.com/webbigdata/status/1791497099315752967
	- You can now run the 7B parameter version of Gemma, entirely locally in the browser, using MediaPipe LLM Inference API.
		- https://x.com/googledevs/status/1791174333995299216
- stockmarkさんが公開されているstockmark-100bのggufあります
	- https://huggingface.co/mmnga/stockmark-100b-gguf
- Gemini 1.5 Flashで、12分の音声ファイルを全て文字起こし。完璧。GPT-4oでもこれは無理
	- https://x.com/Taiyo_AiAA/status/1791460870947774826
-  EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
	- https://www.docswell.com/s/DeepLearning2023/K1JDN3-2024-05-16-142439#p9
	- 事前学習済みの拡散モデルを用いて，追加の学習を一切行わずにセグメンテーションを行うことができることを示した論文．拡散モデルは高精細に画像生成をできるが，その内部には画像細部のセマンティックな情報を持つことが示唆される．
-  LangChain v0.1 から v0.2 への移行手順 by npakaさん
	- https://note.com/npaka/n/n161a7e3882b3?sub_rt=share_h
	-  import変更の例
		- **langchain → langchain_community**
			- vectorstoresとか
		- **langchain-community → langchain_openai**
			- ChatOpenAIとか
		- **langchain-community → langchain-core**
			- document_loadersとか
		- **langchain → langchain-core**
			- Documentとか
		- **langchain → langchain-text-splitters**
			- text_splitterとか
- ADA-V2、GPT-4oだかを微調整してコーディング性能上げたモデル
	- https://x.com/umiyuki_ai/status/1791429524351258857
	- OpenAIがGPT-4TだかGPT-4oだかを微調整してコーディング性能上げたモデルにADA-V2なんてネーミング付けたのがマジだとしたらその理由は？AdaはGPT-3四天王の中で最弱のモデルだった。つまり、GPT-4がAda-V2ならBabaggi-V2やCurie-V2、そしてDavinci-V2はどうなってしまうのか…？という匂わせ
-  Finetuning Llama3 using Unsloth
	- https://github.com/neo4j-labs/text2cypher/tree/main/finetuning/unsloth-llama3#using-chat-prompt-template
	- https://huggingface.co/tomasonjo/text2cypher-demo-16bit
	-  I've finetuned Llama3-Instruct:8b to generate @neo4j Cypher statements based on the GPT-4o synthetic dataset I've generated at the start of the week.
-  LangChain のユースケース by npakaさん
	- https://note.com/npaka/n/n5956ef3a0a09?sub_rt=share_h
	- 「RAGのQA」は、RAG技術を使用して、特定の情報源に関する質問に回答するチャットボットを構築します
	- 「情報抽出」は、LLMでテキストから構造化データを抽出するユースケースです。次の3つのアプローチがあります。
		- **Tool Callingモード** : Tool Callingで指定されたスキーマに従って、構造化データを出力
		- **JSONモード** : プロンプトの一部としてスキーマを提供し、JSONデータを出力
		- **プロンプトベース** : 指示に従って生成されたテキストを既存のパーサーで解析し、構造化データを出力
	- 「チャットボット」は、長期的な対話を維持し、ユーザーの質問に関連情報を使用して回答する能力を持ちます
	- 「ツールエージェント」は、自然言語インターフェースを通じてAPIや関数、データベースなどのツールを操作するシステムを構築します。  
		- **チェーン** : ツール使用の事前定義されたシーケンスを作成
		- **エージェント** : ツールを繰り返し使用してタスクを自動的に実行
	- 「クエリ解析」は、ユーザーの質問を最適化して検索クエリを生成し、より正確な情報を取得することを目的としています。
		- 手法には、クエリの分解、クエリ拡張、仮想ドキュメントの埋め込み、クエリのルーティング、ステップバックプロンプティング、クエリの構造化などがあります。
	- SQLデータベースQA」は、「SQLデータベース」を対象としたQ&Aシステムを構築します。
	- 「グラフデータベースのQA」は、「グラフデータベース」を対象としたQ&Aシステムを構築します
		- 「Cypher」や「SparQL」などのグラフクエリ言語を使用し、自然言語の質問に基づいてクエリを生成し、データベースからの情報を取得して回答を生成するチャットボットやカスタムダッシュボードを作成します
	- 「コード理解」は、ソースコードの分析を目的としています。具体的には、コードベースに関するQ&Aを行い、リファクタリングや改善の提案、コードのドキュメント化を支援します
	- 「データ生成」は、人工的にデータを生成することで、機械学習モデルの学習やテストに役立てます
	- 「タグ付け」は、ドキュメントに感情、言語、スタイル、トピック、政治的傾向などのクラスをラベル付けします
	- 「要約」は、長いドキュメントの内容を要約するためのシステムを構築します。複数のドキュメントや長文テキストを効率的に要約することが可能になります。これには、「Stuff」「Map-Reduce」「Refine」の3つの手法があります。
	- 「Webスクレイピング」は、Webからコンテンツを収集し、自然言語処理に使用するシステムを構築します。
-  LangChain v0.2 で 単純なLLMアプリケーションを構築 by npakaさん
	- https://note.com/npaka/n/n24d48303a496?sub_rt=share_h
-  LangChain v0.2 で エージェントを構築 by npakaさん
	- https://note.com/npaka/n/ne8ef60987e1b?sub_rt=share_b
- 生成AI学びたいなら、この２本 by 尾原さん
	- https://x.com/kazobara/status/1791454624983196148
	- 「生成AI」(3) 松尾豊・東京大学大学院教授　2024.3.15"
		- https://www.youtube.com/watch?v=U9vhGvFxKu0
	- "GPTとは何か Transformerの視覚化 |
		- https://www.youtube.com/watch?v=KlZ-QmPteqM
-  LangChain v0.2 で RAGを構築 by npaka さん
	- https://note.com/npaka/n/ne892b713bd45?sub_rt=share_h
	-  Retriever
		- 「VectorStore」はRunnableをサブクラス化しないため、LECLチェーンにすぐに統合することはできません。「Retriever」はRunnableであるため、標準セットのメソッド (同期および非同期の呼び出しやバッチ操作など) を実装し、LCELチェーンに組み込まれるように設計されています。
	-  RAGチェーン
		- 「Retriever」は、特定の質問と取得したコンテキストを組み合わせて LLM のプロンプトを生成するRAG アプリケーションなど、より複雑なアプリケーションに簡単に組み込むことができます。
		- rag_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
- “MambaOut: Do We Really Need Mamba for Vision?”
	- https://arxiv.org/abs/2405.07992
	- Based on our concept discussion, we hypothesize Mamba is unnecessary for ImageNet while exploring for detection and segmentation remains worthwhile. To verify these, we build MambaOut with Mamba blocks but remove their core token mixer, SSM.
- Text-to-SQL - fully local edition
	- https://x.com/llama_index/status/1791915423816204494
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
	-  Text2SQL OpenSource : duckdb-nsql-7B with Ollama and LlamaIndex on local setup
		- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
- 

## 5/13

先週に引き続きgpt2-chatbotがchatbod arenaに復活したりと、話題に事欠かないが、サム(OpenAIの社長)から、5/13月曜日に何か発表があるとのポストが、GPT-5でも（うわさの）検索エンジンでもないといっているし、映画Herに出てきたような音声アシスタントという下馬評。おっとCOCONA（_ココナ_）の立場は？。OpenAIといえば、Stack Overflowとの提携、回答者にchatptが登場するのか、またモデルがどのように動作するべきかを規定するModel Specを公開、EUのAI法対策か（以前はSystem Cardがその役割だった）とも見れるし、安全性に本気に取り組んでいる姿勢にもみえる、ともかく来たるGPT-5の素性も透けて見えるというのは面白い分析。あと、今週は国内勢の活躍も活発だった、東工大のSwallow-MX-8x7b-NVE-v0.1をファインチューニングしたKARAKURI LM 8x7B Chat v0.1、13Bで104BのCommand R+を超えるって本当？。「Japanese Stable LM 2 1.6B」、 属性予測モデル　KARAKURI LM 7B APM v0.1 、「Fugaku-LLM」の公開など。さて様々な評価から性能が高い、使える、とされているllama3、日本語がやっぱりダメダメだったりはご愛敬でも、量子化に弱かったり（コンパクトで性能が高いというのは量子化の余地も少ない）と、LLMのスケール測の一端を思い知らす結果になってるというのは面白い、tokenerizerが壊れているとのうわさも。"DeepSeek-V2"ってのがGPT-4と同レベル。かかるコストは200分の1というのは本当だろうか？Google/DeepMindからは「AlphaFold 3」を発表、こんどはDNAも扱えるとのこと、創薬が劇的に加速する予感。先週に引き続いてKANの評価も進む、shi3zさんの「最後にKANは勝つ」というKAN評価試行のnoteのタイトルは「最後に愛が勝つ by KAN」のもじり？それにしてもKANさんご冥福をお祈りします。Microsoftが自社製LLMである「MAI-1」を開発中、ＸはGrokを有料ユーザーに開放。Deeplearning.aiからは、llamaindexのJerry Liu(CEO)を講師にAgentic RAG、LangChainのHarrison(CEO)を講師に、Functions, Tools and Agentsのショートコースが無料公開、なんて豪華な。そのLangChainはv0.2がリリースが間近に、AgentやTool関連の見直しがされる。あとなぜか、時系列予測の基盤モデルの発表も相次いだ、Google/TimesFM、IBMのTinyTimeMixers (TTMs)、ICML2024にアクセプトされた、CMUとUPENのMOMENT、ひょっとしてICML2024がTime Seriesの基盤モデル祭りになってるのか。早速、データサイエンスクラスタからは、(AirPassengerデータに対し）一階差分もとらんのかと冷笑も。xLSTMとか、Vanilla Bayesian Optimization とかの基盤技術の進展もあり、しらんけど。。喜連川先生監修の「生成AIの論点」というのは、日本のLLMをめぐる状況を把握にはよいかも、それにしても「情報大航海時代」はなくなったことになったのか？最後に、THE GUILDの深津さんの、「情報が多すぎて頭がパンクするのは正常ではない」というのは、激しく同意する。

- gpt2-chatbotがchatbot arenaに復活？
	- https://x.com/alfredplpl/status/1787754701536325720
-  最後にKANは勝つのか?MLPに変わると主張されるKANを試す by shi3zさん
	- https://note.com/shi3zblog/n/n1e592409a345?sub_rt=share_pb
	- Efficient-KANが手っ取り早くMNISTが試せそうだったので試してみた
	- つまり、同規模の場合、学習すべきパラメータ数は10倍になり、性能差は縮んでいくという結果になった
- KARAKURI LM 8x7B Chat v0.1を公開しました！
	- https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-chat-v0.1
	- 1. 東工大から出ているSwallow-MX-8x7b-NVE-v0.1をベースにカラクリのデータでチューニングしました。（圧倒的感謝） 
	- 2. 前回に続き、国産オープンモデルとしてはMT-Bench-jpで最高性能を更新 
	- 3. Active Parameter数 13Bで104BのCommand R+を超え、72BのQwen 1.5に迫る性能 
	- 4. AWS TrainiumでのMoEモデルの学習はAWSの担当の方にも確認しましたが、おそらく世界初とのこと。コードは技術ブログの記事とともに近日公開予定。 
	- 5. 前回に引き続き、SteerLMによるアライメントを実施。属性予測モデル（APM）はgemma 7bをチューニングし、公開
-  CACTUS: Chemistry Agent Connecting Tool-Usage to Science
	- https://arxiv.org/abs/2405.00972
	- 化学のためのAIエージェントの論文
	- 化学に関する数千の質問と回答を作成し様々なオープンLLMの性能を比較。Gemma-7bとMistral-7bで高精度を実現、また精度を維持しつつ民生レベルのハードへ導入ができそうだとわかったそうです。
- Stack OverflowがOpenAIと提携？
	- https://x.com/ImAI_Eruel/status/1787670618961514627
	- おそらくChatGPTの登場によってユーザー数の減少という点で最大の被害を被ったのはプログラミングの質問解答サービスStack Overflowなんですが，この度OpenAIとの提携が決まったとのこと
- 精度上げようとすると自然とLLMに頼る箇所減ってピンポイントになる
	- https://x.com/mizchi/status/1787639942216327442
- KARAKURI LM 8x7B Chat v0.1 をお試し中
	- https://lm.karakuri.cc/
- 【GPT-4と同レベル。かかるコストは200分の1】最強LLM「DeepSeek-V2」発表
	- https://x.com/SuguruKun_ai/status/1787839473067376705
	- この子がGPT-4相当と言うのはあってそうで結構文才もある ついでに倫理面も割と高めな感じで日本語出力は悪くない 結構良い感じかも！
- Grokがきた！今はX課金者限定
	- https://x.com/hirochuu8/status/1787880221997515258
- iPad Pro 13 インチ Nano-textureガラスモデルの価格 ≒ KARAKURI LM 8x7bの学習にかかったコストです
	- https://x.com/txmy/status/1787859094034059669
- 日英／英日翻訳タスクにおいてmeta/Llama 3ではgoogle/Gemmaを超える事が出来ない
	- https://x.com/webbigdata/status/1787457498057933299
- Karasu-Mixtral-8x22B-v0.1のgguf
	- https://huggingface.co/mmnga/lightblue-Karasu-Mixtral-8x22B-v0.1-gguf
- lightblue-suzume-llama-3-8B-multilingualのgguf
	- https://huggingface.co/mmnga/lightblue-suzume-llama-3-8B-multilingual-gguf
- Let's build a 100% local RAG app, featuring ⌘R, a self-hosted vector database, a fast embedding library & a reranker:
	- https://x.com/akshay_pachaar/status/1787824526010782053
- Reranker allows you to reorder the retrieved context (chunks), offering two key benefits:
	- https://x.com/akshay_pachaar/status/1787824694768648575
- Ollama v0.1.34 is out!
	- https://x.com/ollama/status/1787976537762856999
- A built-in planning agent for LlamaIndex landed in 0.10.34!
	- https://docs.llamaindex.ai/en/stable/examples/agent/structured_planner/
	- A key pattern in agents is the ability to plan. Breaking down a task into sub-tasks can make the task easier to execute.
- Microsoftが自社の大規模言語モデル「MAI-1」を開発している
	- https://x.com/ImAI_Eruel/status/1787787401055908017
	- 5000億パラメータとの話もあり,本当なら既存モデルで最大レベル.後出し考慮でGPTやClaude超えもできそうか
- DeepSeek-V2、236B のクソデカモデルでありながら推論時は実質 21B 相当の MoE らしく
	- https://x.com/izutorishima/status/1787775197057265925
- ぬこぬこ氏、退職し、本業 LLM 無職へ、
	- https://x.com/schroneko/status/1788148600171831406
- HachiML/Hachi-Alpaca by はちさん
	- https://huggingface.co/datasets/HachiML/Hachi-Alpaca
	- Mixtral 8x22B Instructによる日本語合成データ、28.9kで一旦完了にしました。v1.0_cleanedが精査済みです。
- Zennのトレンド記事を、毎朝AIがラジオ風に紹介してくれるサービスをつくりました
	- https://zenncast-web.vercel.app/
- Announcing AlphaFold 3
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- AlphaFold2の時点で，「ノーベル賞レベル」と言われて最終形態かと思いきや，まさかの3が出てきました by 今井さん
- Deeplearning.aiより無料の、Building Agentic RAG、が公開
	- https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/
- xLSTM: Extended Long Short-Term Memory
	- https://arxiv.org/abs/2405.04517
	- Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to SotA Transformers and State Space Models, both in performance and scaling.
- 4M Context Length Llama-3 8B (V0.1)
	- https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-4194k
- 日本学術会議総会での講演「日本の研究競争力低下の因果推論」の資料が面白い．
	- https://www.scj.go.jp/ja/member/iinkai/sokai/siryo191-2-1.pdf
	- 日本の研究競争力低下の因果推論
	- どれだけ**「研究人・時間密度」（良き人的研究環境の広がり）**を保てるかに、今後の日本の研究競争がかかっている。
- OpenAIがAIモデルがどのように動作するべきかを規定するModel Specを共有
	- https://openai.com/index/introducing-the-model-spec/
	- え、このタイミングてChatGPTの内部挙動わざわざ公開するのなぜ？EU的なやつ？ by 深津さん
	- ここから、GPT-5の特徴が使い勝手がわかるらしい
-  Google Colab で 属性予測モデル　KARAKURI LM 7B APM v0.1 を試す
	- https://note.com/npaka/n/ndb541c2cf03b?sub_rt=share_h
	- 「KARAKURI LM 7B APM v0.1」は、属性予測モデルです。「Gemma 7B」のファイチューニングモデルになります。
	- 属性の値は **0(最低)〜4(最高)** になります。
- karakuri-lm-8x7b-chat-v0.1のggufあります
	- https://huggingface.co/mmnga/karakuri-lm-8x7b-chat-v0.1-gguf
	- imatrixのデータはTFMC/imatrix-dataset-for-japanese-llmを使用して作成しました
- グーグルが、生物学に革命を与えたタンパク質構造予測AIの最新モデル「AlphaFold 3」を発表（ネイチャー論文）
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- タンパク質、DNA、RNA、小分子などほぼ全ての生体分子の構造と相互作用を高精度に予測 生成
	- AIを支えるtransformerと拡散モデルの発展で生物学や創薬が加速
- 毎日がイノベーションすぎて、もはや全容が把握できない。時事ニュース追うだけでパンクする世界は、あまり健全ではない by 深津さん
	- https://x.com/fladdict/status/1788208163965305143
- 日本語特化の言語モデル「Japanese Stable LM 2 1.6B」をリリースしました
	- https://ja.stability.ai/blog/japanese-stable-lm-2-16b
	- Japanese Stable LM 2 1.6B（JSLM2 1.6B）は16億パラメータで学習した日本語の小型言語モデルです。
- TimesFM by DeepMind
	- https://huggingface.co/google/timesfm-1.0-200m
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. 
- Uncertainty Quantification and Propagation in Atomistic Machine Learning
	- https://arxiv.org/abs/2405.02461
	- 不確実性評価のレビュー論文
	- 機械学習でデータが少ない領域を予測するのは困難ですが、それを克服する不確実性評価の手法が教科書的にまとまっています。まだ汎用的手法はなくデータにあった手法をうまく選択することが大切とのこと。
- サムから、月曜に大きな発表があると、、
	- https://x.com/sama/status/1788989777452408943
	- not gpt-5, not a search engine, but we’ve been hard at work on some new stuff we think people will love! feels like magic to me.
-  「Fugaku-LLM」を公開
	- https://pr.fujitsu.com/jp/news/2024/05/10.html
	- 横田さんのとこ、
	- 「Fugaku-LLM」は「富岳」の13,824台の計算ノードを用いて、約4,000億トークンを学習した13Bモデルです
-  LangChain v0.2 の概要 by npakaさん
	- https://note.com/npaka/n/na9e629ebbd16?sub_rt=share_h
	- **・langchain と langchain-community の完全な分離  **
	- **・バージョン付きドキュメント**  
	- **・より成熟したエージェントフレームワーク**  
	- **・LLMインターフェースの標準化、特にツール呼び出しに関する改善**  
	- **・ストリーミングサポートの向上**  
	- **・30を超える新しいパートナー パッケージ**
- 日本語高速ASR Kotoba-Whisper v1.1にアップデートしました
	- https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1
	- 句読点予測を改善 (raw CERで大幅な向上) - Stable-tsの統合により、timestampの予測を向上 - Long-form transcriptionの予測向上 - 学習・推論コードを公開:
- ibm-granite/granite-timeseries-ttm-v1
	- https://huggingface.co/ibm-granite/granite-timeseries-ttm-v1
	- TinyTimeMixers (TTMs) are compact pre-trained models for Multivariate Time-Series Forecasting, open-sourced by IBM Research. 
	- **With less than 1 Million parameters, TTM introduces the notion of the first-ever “tiny” pre-trained models for Time-Series Forecasting.**
- Great, now we have some clean Llama 3 models (both 8B and 70B)
	- https://huggingface.co/ddh0/Meta-Llama-3-8B-Instruct-bf16-GGUF
	- Those minor bugs in llama.cpp has been resolved so should work at its full potential.
- マイクロソフトが1月に発表したSliceGPTでは、LLMのウエイトを圧縮できちゃうらしい。
	- https://x.com/umiyuki_ai/status/1789128885558546881
	- ウエイトの各行列を次元数減らした行列に置き換えちゃうんだって。これでパラ数を25%まで削れて（つまり52.5Bになる？）、Llama2-70Bの場合は性能の低下は1%だけで済むらしい
- Google/TimesFMはモデリングから微妙だし
	- https://x.com/kyo_takano/status/1789150904102613131
	- 一階差分を取らずに非定常過程のまま予測器に突っ込む; 
	- Transformersを使いたいがために複数時点を単一トークンとして埋め込む・予測する; etc.）、
	- 古典的な統計モデルに対して部分的にしか上回ってないんだよね
- Ollamaに、MLX対応くる？
	- https://x.com/m_sigepon/status/1789233089945981319
-  Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals
	- https://jamanetwork.com/journals/jama/fullarticle/2818746?utm_source=twitter&utm_campaign=content-shareicons&utm_content=article_engagement&utm_medium=social&utm_term=051024
	- 医学観察研究で因果関係を示すためにはどうする？6つの条件を示して、これを満たしていれば因果関係を言ってもいいんじゃない？という提言。
- google/timesfm-1.0-200m
	- https://huggingface.co/google/timesfm-1.0-200m
	- Google released a decoder-only "foundation" time series model on
	- Trained on a corpus of 100B real world time-points from Google Trends and pageviews from Wikipedia!
- 『データサイエンスと機械学習』にはKANで話題沸騰中のコルモゴロフ･アーノルドの表現定理が掲載されていた。
	- https://x.com/bebebeBayes/status/1788900859570700291
- 大屋雄裕「信用・信頼・信託 —責任と説明に関する概念整理―」
	- https://x.com/rmaruy/status/1789193304808296841
	- AIの説明可能性／責任について、ウィトゲンシュタインの原因／理由の区別から紐解き、プロセスの透明性だけでなく答責性が問題になる場面がどんなときかを議論。この上なく明晰。
- lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- https://huggingface.co/lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- rinna様のllama-3-youko-8bを少数の英日対訳データ+LoRAでSFTしてみました
-  Post Llama 3 depression
	- https://www.reddit.com/r/LocalLLaMA/comments/1colmeb/post_llama_3_depression/
	- Llama3の微調整モデルは色々出たけど今んとこどれもアカンという話。原因はよく分からんけどもう今までの微調整のやり方は時代遅れなのかもしれない。少なくともLlama2とは勝手が違うらしい
- 「ローカルLLMはこーやって使うの」を更新しました
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	-   以下を追加: 
		- 前提知識の確認 
		- 特殊トークンによるプロンプトインジェクション 
		- 尤度関数としての利用
- Difyの勢いがすごい。LangChainやFlowise、Llama Indexを抑えてLLMツール4週間で1位に
	- https://x.com/kyutaro15/status/1789054552638943495
- You can now generate production-ready prompts in the Anthropic Console.
	- https://x.com/AnthropicAI/status/1788958483565732213
- Vanilla Bayesian Optimization Performs Great in High Dimensions
	- https://arxiv.org/abs/2402.02229
	- バニラのベイズ最適化が高次元でも大活躍
	- これまで高次元は呪いの領域と思われていたが、適切な仮定を設けるだけで最先端の手法を圧倒する性能が出せることが判明
- DeepLearningAIから、今度はLangChainのCEOの講義
	- Check out the short course Functions, Tools, and Agents, taught
	- https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/
- "MOMENT: A Family of Open Time-series Foundation Models"
	- https://moment-timeseries-foundation-model.github.io/
	- has been accepted for the ICML 2024! On this occasion, we are open-sourcing it, together with the model weights and dataset!
- 生成AIの論点
	- https://www.seikyusha.co.jp/bd/isbn/9784787235374/
	- 喜連川先生まだいきてたのか？
	- 日本学術会議が実施し、過去最多の動員を達成したシンポジウム「生成AIの課題と今後」の書籍化である
- 

## 5/7

ＧＷで、頭がぼけているのか、X(旧twitter)のアルゴリズムが変わったのか、おすすめに出てくるツイートが先週とかぶっている気がする。Xの生成ＡＩを使った新サービス「ストーリーズ」の展開と関係あるのか？。今週は突然でてきた謎のgpt2-chatbotが面白かった、gpt2と名前があるものの、GPT-4.5かGPT-5のフィールドテストかという話で持ち切りだった（Chatbot Arenaからは消えた。。）、評価できた人によると、相当すごい性能らしい。Swallow-MS 7Bの新しいinstructモデル、さっそくElyzaTasks100で評価され、ちょっと微妙な結果に。一方ElyzaTasks100での評価によると、Qwen1.5はかなり優秀だけど時々日本語に難ありとのこと。Domingos氏のAIの能力の発展がサチっているていう話は、（そもそもデータとして使った）人間の能力がAIの進化を律速しているとのこと。そりゃ、人間を超えるのは人間のデータでは無理だ、超えたところで人間にはわからないというのはそうかも。BCGの売上20%が生成AI関連とのこと、コンサルはなくならない、金の儲け方が変わるだけ。「統計的テキストモデル」全文がプレ公開されたとのこと、われは！と思う人はぜひチャレンジを。Ollamaを使ったローカルLLMの利用例もぐっと増えた、もはやRAGは誰でもできる、さらにReAct Agentとか、Function Callingとか、よりむつかしいタスクむできるようになった、気のせいかLlama3やphi3が使われる例が多いような。Kolmogorov–Arnold Networks、新しい生成AI向けニューラルアーキテクチャ？特異学習理論（渡辺ベイズ理論）を発展させた局所学習係数という新しい概念も気になる、アライメントととも関係あるとか。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。「ローカルLLMはこーやって使うの」は参考になる、ローカルLLMならいろいろやり放題なんだな。ＡＩセイフティでは、NISTから、生成ＡＩ向けのリスク管理フレームワークが発表、日本のAISIとの連携も進む。AIアライメントの包括的なサーベイ、「AIによる絶滅リスクの軽減」だと。rinnaからLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開、NIIから「LLM-jp-13B v2.0」を構築とか、頑張れ日本勢。うみゆきさんが言うように、進化型のLLMのマージMergekit-Evolveってのは本当にすごのいか？？LangChainの４つのRAG向けchainの比較も地味に役に立つ。ローカルLLM系では、自作小説をLLMで評価させているひとが、 command-r-plus-Q4_K_Mを絶賛評価、実作業に基づく評価は尊い。ChatGPT東大入試に挑むも「不合格」の記事（日経）、さっそくプロンプトが悪いと、いや解けたよ、との突っ込みが、次々と。。

- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較｜
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	- stuff chain、map reduce chain、map rerank chain、refine chain
	- 応答速度 : 呼び出し回数が1回のstuffは「速い」, n回ですが各文書に対するLLM呼び出しを並列化できるmap系2種は「普通」, n回かつ並列化ができないrefineは「遅い」としています。
	- 適している文書特徴
		- stuff・map reduce : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- map rerank : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- refine : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7bをElyzaTasks100で評価してみたら平均3.57点を叩き出した　 by うみゆきさｎ
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- 7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！
- Swallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました
	- https://huggingface.co/collections/tokyotech-llm/swallow-ms-instruct-662957bf88d016c69ae0e633
	- あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】  512トークン、340Token/S
	- https://x.com/hokazuya/status/1783808939773304957
	- ローカルLLMでこの性能はPhi-3やLlama3の7Bなど見てきたがMac単体でこれはスゴすぎる。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘している
	- https://x.com/pmddomingos/status/1783956607552176422
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
	- https://x.com/rmaruy/status/1784154638390104188
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
- 『Symbol-to-Language』
	- https://x.com/ai_database/status/1784581982053347542
	- LLMのタスクにおいて「記号を自然言語テキストに変換する」ことで様々なタスクで精度が上がる現象が報告されています。
	- 実験では、物性予測、表の理解、ツイート分析などで効果が出ています
- BCGの売上20%が生成AI関連で、2026年までに40%にまで増えるとか
	- https://www.ft.com/content/33dfaec4-b5e7-4eca-a869-cdd33d447e65
- lama 3 degrades more than Llama 2 when quantized.
	- https://x.com/rohanpaul_ai/status/1784889182558539917
- gpt2-chatbotと呼ばれる謎のモデル
	- https://x.com/bioshok3/status/1784972619957346703
	- Chatbot arena でClaude3 opusやGPT-4 Turboに匹敵するとかしないとか超えてる超えてない言われ今少し話題になっている
- ReAct Agent with Function Calling | Open Source Gemma LLM | Ollama | Lan...
	- https://www.youtube.com/watch?v=exYUJcz4uZs
- llama-2-13b-retrievalqa.ipynb - Colab
	- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/llm-field-guide/llama-2/llama-2-13b-retrievalqa.ipynb#scrollTo=JPdQvYmlWmNc
- crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
	- https://huggingface.co/crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
- react-agent-with-function-calling-ollama-langsmith.ipynb
	- https://github.com/Ashufet/LangChain_ReAct-Agent-with-Function-Calling_Ollama-Gemma-LLM_LangSmith/blob/main/react-agent-with-function-calling-ollama-langsmith.ipynb
- Google announces Med-Gemini, a family of Gemini models fine-tuned for medical tasks!
	- https://x.com/iScienceLuvr/status/1785247498744778886
- 「統計的テキストモデル」の全体の原稿(4章以外)のβ版を公開しました
	- http://chasen.org/~daiti-m/textmodel/
- Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities
	- https://arxiv.org/abs/2404.17790
	- 東工大のLLM、Swallowの論文がarXivに公開されていますね。
	- 日本語の継続事前学習について、データのスケーラビリティや語彙拡張、パラレルコーパスの影響について大規模かつ系統的に知見を提供している研究で、勉強になります
- gpt2-chatbotは本当にモデル名だ。そうHFのCTOがいまopenai-communityからホスティングしていると思われる。
	- https://x.com/alfredplpl/status/1785170960251007266
- 大規模言語モデル「LLM-jp-13B v2.0」を構築
	- https://www.nii.ac.jp/news/release/2024/0430.html
	-  NII主宰LLM勉強会（LLM-jp）が「LLM-jp-13B」の 後続モデルとその構築に使用した全リソースを公開
- Qwen1.5シリーズを一通りElyzaTasksで評価してみた
	- https://x.com/umiyuki_ai/status/1785272618595262646
	- やっぱりQwen1.5はかなり優秀。7BモデルはLlama3-8Bのチョイ下。14Bモデルは35BのCommand Rを超えてる！
- AISIと米国NISTは、日本の「AI事業者ガイドライン」とNISTの「AIリスクマネジメントフレームワーク(RMF)」のクロスウォークの第一弾として用語に関する「クロスウォーク1」を公表しました。
	- https://aisi.go.jp/2024/04/30/ai_rmf_crosswalk1_news/
- 謎の高性能AIモデル「gpt2-chatbot」がChatbot Arenaに登場、GPT-4.5かGPT-5なのではないかと話題に
	- https://gigazine.net/news/20240430-lmsys-chatbot-arena-gpt2-chatbot/
	- 日本の歴史についても、ハルシネーションの多いClaude 3 Opusと比較して、遥かに優れた回答。論理的な考察についてもレベルが高い。
- 自作小説をLLMにレビューさせてみる（ローカル4モデル、サービス型3モデル）
	- https://note.com/kohya_ss/n/nfcdfd6de8790
	-  command-r-plus-Q4_K_M: 極めて高い理解力と要約力を示し、作品の伏線や登場人物の理解も的確だった。文章は読みやすく洗練されており、ローカルLLMの中で最も優秀な性能を示した。小説のテーマを深く理解し、適切な批評を行っている。
- US NIST publishes 1st draft of its "AI Risk Management Framework: Generative AI Profile." 
	- https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf
- rinnaはLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開しました。
	- https://huggingface.co/rinna/llama-3-youko-8b
- KAN: Kolmogorov–Arnold Networks
	- https://arxiv.org/abs/2404.19756
	- https://github.com/KindXiaoming/pykan
	- Proposes an alternative to MLP that outperforms in terms of accuracy and interpretability
	- 重みを学習させるのではなく、エッジ上に配置した活性化関数を学習させる(エッジの重みは1で固定)新しいニューラルネットワークのアーキテクチャの提案。…
	- ちなみにニューラルネットワークとコルモゴロフ-アーノルド表現定理の話題に関しては，そんなに新しいものではなく，結構昔から出ているものではあります(今井さん)
- RAGのG（Generation）、つまり"生成"は本当に必要なのか？
	- https://x.com/Nurruttan/status/1785853289034350622
- AI Alignment: A Comprehensive Survey.
	- https://alignmentsurvey.com/uploads/AI-Alignment-A-Comprehensive-Survey.pdf
	- AIアライメントの包括的なサーベイ
	- AIアライメントは、AIシステムを人間の意図や価値観に沿って行動させることを目的としている。AIシステムの能力が高まるにつれて、ずれたAIシステムに関連する潜在的な大規模リスクが顕著になっている。何百人ものAI専門家や著名人がAIリスクへの懸念を表明し、「AIによる絶滅リスクの軽減は、パンデミックや核戦争といった他の社会的規模のリスクと並んで、世界的な優先事項であるべきだ」と主張している
- ローカルLLMはこーやって使うの💢
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	- ①トークンの生成確率が全部見れる。これを応用するとハルシネーションや誤字脱字の検出もできるかも。というのはどのワード生成時に自信が無かったかが確率を見れば分かるから。②回答の冒頭部分を強制できる。
- X、生成AIでニュースの要約を開始　一部の有料会員に
	- https://www.nikkei.com/article/DGXZQOGN0406N0U4A500C2000000/
	- 「新機能「ストーリーズ」を始めた。米xAI（エックスエーアイ）の対話AI「Grok（グロック）」がX上で話題のニュースなどについて情報を要約」
- How LLMs work, clearly explained with visuals:
	- https://x.com/Sumanth_077/status/1786404341735444731
- Build a RAG system with Llama 3B-Instruct for your PDFs
	- https://colab.research.google.com/drive/1BJYYyrPVe0_9EGyXqeNyzmVZDrCRZwsg?usp=sharing#scrollTo=Y2m2l-vt_RSp
-  TAIS 2024 | Insights from two years of AI safety field-building at MATS — Ryan Kidd
	- https://www.youtube.com/watch?v=tA9K8JqyhP4
	- Don't miss @jesse_hoogland captivating talk at TAIS2024 on the structure of neural networks and the links between learning theory and interpretability! Watch now:
	- 特異学習理論（渡辺ベイズ理論）を発展させて局所学習係数という新しい概念を創出し，①transformerの学習ダイナミクスの解析，②機械論的解釈可能性の基盤理論としての可能性，③AIアライメント理論の展望を力説した2人の研究者のTAIS2024講演
- 「確率変数」の正体は米田埋め込み
	- https://m-hiyama.hatenablog.com/entry/20170228/1488276250
- ChatGPT、東大入試に挑む　英語8割超も数学1点で「不合格」
	- https://www.nikkei.com/article/DGXZQOUC2103E0R20C24A3000000/?n_cid=SNSTW005
	- 「この計算は手作業では困難。数学の専門書をおすすめする」。人ごとのような答案もありました。古文も文脈を理解できず0点。一方、英作文や英訳は満点でした
- 2024年東大入試数学の第1問の(1)をプロンプトを工夫して解いてみたら、一発で解けた。これだけで5点くらい取れているはず
	- https://x.com/itnavi2022/status/1787121446445326816
- 第2問の(1)は、プロンプトを工夫しなくても、ChatGPTで普通に正解できた。
	- https://x.com/itnavi2022/status/1787448789693059176
- Nvidia が出した、Llama3-ChatQA-1.5の微調整でRAG＆対話性能爆上がり。
	- https://x.com/hokazuya/status/1786901364213416356
- LangChainのllama.cpp統合
	- https://x.com/yuiseki_/status/1787091439408816479
- 【vLLM on Hugging Face Interface】
	- https://x.com/hokazuya/status/1787060961570127973
	- 便利すぎ。爆速でLlama 3 -8BのLLMを動かす＋OpenAIのAPIを呼び出す形式でLlama 3と会話できちゃう。

## 4/29

マイクロソフトからPhi-3-miniが発表され、3.8BのモデルがMixtral 8x7BやGPT-3.5とためをはるとのこと、Phi-3-mini 4k instruct モデルはColab T4でも動くし、huggingfaceにも公開。さっそくOllamaが対応し、Llama-3 & Phi-3もRAGでの比較とかも。Llama3も、日本語向けにLoRaされたり、Llama3-70Bを42Bパラメータに枝刈りしたモデルが公開されたり、4bitに量子化して評価されたりとか、コミュニティの活動が一気に盛り上がる。なお量子化に関してはどのＬＬＭも4bit量子化しても精度がほとんど低下しないとのことだが本当か？AppleがiPhoneでも稼働するオープンな言語モデル「OpenELM」を発表、さっそくMLX LMで評価した結果が公開された、Macbook AirでPhi 3の量子化されたやつを動かして劇速といってる例とか、実は、LLMプロダクト開発者はMac 進化的を買ってローカルLLMを触るべきとの意見も見られたが、反論もぼちぼち、さても６月のWWDC24が楽しみだ。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。Groq(LPUによる高速化のほう）のAPIをStreamlitで使う方法の紹介など、Groqの利用をちらほら見るようになった、速さは最強。LLMエージェントに関するニュースを毎週まとめてくださるサイト、頭が下がる、このアプデ更新もそうありたいものだ。LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いているというのは、アライメント問題を表面上の課題ではなくアーキテクチャまで落とすところが面白い。LLMの性能評価やベンチマークに関する活動もElyzaTasks100やRAG、Query PlanningなどのタスクにおけるローカルLLMの実力が検証なんかがあった。

- モデル進化マージについて by sakana.aiの秋葉さん
	- https://speakerdeck.com/iwiwi/17-nlpkorokiumu
	- 日本語LLMのマージはあまりない、継続学習されて、元の重みからずれてしまっている。
	- そこで、進化的計算によるマージ。
-  「AI事業者ガイドライン（第1.0版）」
	- https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html
	- これまでMLPdM的な人が一般的に留意すべきと言われていたようなことに加え、より広い社会的な観点や、AIの利用者の観点なども踏まえた上でうまくまとめられている有益なガイドラインだと感じました。
	- https://x.com/yu__ya4/status/1782037184079683916
- Command R+はどこまで量子化するとアホになってしまうのか？ by npakaさん？
	- https://soysoftware.sakura.ne.jp/archives/3834
	- ローカルでCommand R+を動かすとなると、手元の環境のRTX4090が１台ではハッキリ言って1bitまで圧縮してもVRAMに載りきらない。
	- 今回はCommand R+の各量子化モデル、Q6_K、Q5_K_S、Q4_K_S、iq4_xs、Q3_K_S、iq3_xxs、Q2_K、iq2_xxs、iq1_sのそれぞれについて、ElyzaTasks100を解かせてみる。
	- API～3bitまではぶっちゃけ大差ないというか誤差の範囲だという事だろう
	- 1bitの3点というのはこれはもう完全に劣化してるというのは確実に言えそうだ。
	- まず、今回の結果だけで言えば、実用上は4bitまでの量子化なら性能劣化は見当たらないように見える。
- Fully local RAG with Llama 3 on ollama & streamlit
	- https://x.com/ashpreetbedi/status/1782079131103932647
-   LLMモデル "Llama3" を 4bit 量子化して実行してみた
	- https://qiita.com/akasakat/items/0855b5f05467cc8cbbf4
	- 一昨日発表された  [Llama3](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  を4bit量子化 してつかってみました
	-  GPUの VRAM は 6GB 程度消費します
	- Llama3の 語彙数は 32000(Llama2) => 128256 へと大幅に増えました
- LoRA fine-tuning of embedding models using LlamaIndex
	- https://medium.com/@diagnosta/lora-fine-tuning-of-embedding-models-using-llamaindex-a60b823a2c94
	- In this blog post, we’ll explore how to fine-tune black-box embedding models using low-rank adaptation (LoRA) with the LlamaIndex library. LoRA is a technique that trains a small number of rank-decomposed weights to adapt a pre-trained model to a new task or domain. 
- 自宅PCでクラスターを構築：コンシューマーGPUの枠を超え、大型LLMをローカルで動かす！ by AIサトシ
	- https://note.com/aisatoshi/n/nd4969fc42602?sub_rt=share_h
	- Command-r-Plusは、4bitに量子化しても60GB程度のVRAMが必要となります。
	- 複数PCでのモデル並列が自宅で可能となったので、理論的には、デスクトップを増やすことで巨大なLLMの推論が可能となります。
- alfredplpl/Llama-3-8B-Instruct-Ja　 by あるふさん
	- https://huggingface.co/alfredplpl/Llama-3-8B-Instruct-Ja
	- 日本語向け Llama 3 8Bを公開してみました。LoRAで表面を学習しただけなので、性能はありません。ただ、普通のLlama 3よりかは日本語が強くなっているはずです。よろしくお願いします
- Groqの値段調べ、llama3など
	- https://x.com/webbigdata/status/1782240169879601540
	- GroqはLPU(Language Processing Unit)という独自ハードウェアを開発している会社です
	- Llama 3 70BがAnthropic Claude 3 Sonnet($3.00/$15.00)相当の性能であれば、GroqのLlama 3 70B APIの価格設定($0.59/$0.79)は非常に競争力があります
- Llama 3 70b layer pruned from 70b -> 42b by Charles Goddard
	- https://www.reddit.com/r/LocalLLaMA/comments/1c9u2jd/llama_3_70b_layer_pruned_from_70b_42b_by_charles/
	- chargoddard/llama3-42b-v0
	- Llama3-70Bを枝刈りしてパラ数42Bにしちゃったというブツらしい。
-  Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
	- https://arxiv.org/abs/2404.14219
	- Microsoft announces phi-3-mini, a 3.8B model trained on 3.3T tokens that rivals Mixtral 8x7B and GPT-3.5
	- パラメータ数、学習トークン数
		- ①Phi-3-mini (38億、3兆3000億)
		- ②Phi-3-small (70億、4兆8000億) 
		- ③Phi-3-medium (140億、4兆8000億）
- は？Phi3-small-7BはMMLUが75.3点？Llama3-8Bでも66点だというのに。
	- https://x.com/umiyuki_ai/status/1782622321704079652
-  Weekly AI Agents News!
	- https://speakerdeck.com/masatoto/weekly-ai-agents-news
	- このLLMブクマアプデのように毎週、Agent関係の情報を収集している人
	- LLMエージェントに関するニュースを毎週まとめてくださる
-  From  r  to  Q∗: Your Language Model is Secretly a Q-Function
	- https://arxiv.org/abs/2404.12358
	- LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いている。例えばある対話の結果につながった原因のトークンを特定できたり、尤度最大化のビーム探索はそのまま収益最大化とみなせる by 岡野原さん
- Llama.cpp で Llama 3 70Bをお試し中。by npakaさん
	- https://x.com/npaka123/status/1782556559589212399
	- 8.42 tokens per second 
	- Meta-Llama-3-70B-Instruct-IQ4_XS.gguf 
	- M3 Max (128GB)
-  llama.cpp による transformersモデル の量子化 by npakaさん
	- https://note.com/npaka/n/nbd1348500a28?sub_rt=share_b
	- 今回は練習用に「meta-llama/Meta-Llama-3-8B-Instruct」を準備します。
	- transformersモデルをggufに変換
	- imatrix量子化
- Llama3-70BはElyzaTasks100（Command R+による自動評価）においてCommand R+超えてます
	- https://x.com/umiyuki_ai/status/1782690199677641164
- CodeQwen1.5
	- https://x.com/Alibaba_Qwen/status/1782426698279272742
	- Last week, we released a CodeQwen1.5 and received a lot of positive feedback! Thank you for your support! 
- 手元のMacbook AirでPhi 3の量子化されたやつを動かしているのだが、これGPT-3.5こえてるよね。ノートパソコンで普通に動くってどういうことだ
	- https://x.com/alfredplpl/status/1782808427129114796
- phi3 local RAG using LlamaIndex and Ollama:
	- https://x.com/llama_index/status/1782893301214986593
	- https://colab.research.google.com/drive/1RoZzbL8WYaAp4b3sazYHVI8TA2AkrtRJ#scrollTo=9AtRxaqD94mZ
- 様々なタスクでのlocal LLMの実力のベンチマーク
	- RAG, Query Planning, Text2SQL, and Pydantic Program but struggles with Routing and Agentic tasks. 
-  Feature Test for Phi-3-mini-4k-instruct
	- https://docs.llamaindex.ai/en/latest/examples/benchmarks/phi-3-mini-4k-instruct/
- Phi-3 mini 128k instruct の Colab T4 で動作確認の取れた　 by ぬこぬこさん
	- https://gist.github.com/schroneko/f4fac4c4dd541f4c5ee61c44c90c4a85
	- サンプルの方程式を解く問題は難なくクリア。日本語でもクリア。3.8B にしてはかなり日本語をナチュラルに話せているのでは？
- HuggingChatにphi3-mini-4k登場
	- https://huggingface.co/chat/
-  Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches
	- https://arxiv.org/abs/2404.14779
	- 医療ドメインでLLMをfine tuningする際、フルパラメータのチューニングをするかLoRAで効率的にチューニングするべきかをLlama-2ベースのモデルで検証した論文。
	- モデルサイズが小さいほどfine tuningの効果が大きい
	- モデルが大きいほどLoRAのパフォーマンスは古パラメータのチューニングに接近しそう
- LLMの継続学習における論文紹介
	- https://note.com/sergicalsix_/n/ndbd5b29451c9
	- LLMの継続学習においてドメインの内容や順序などについて調査。ドメインを類似度順で継続学習した方がドメイン特化させやすく、ドメインをランダムな順序で継続学習した方がLLMの性能・知識の蓄積が改善する。
-  Command R+はトークナイザーもすごかった
	- https://qiita.com/sergicalsix/items/5ceb9a3a0d11affb4b9a
	- 今回はCommand R+の日本語の応答速度が本当に速いのか、なぜ速いのかについてトークナイザー観点で述べたいと思います。
	- CohereのAyaとCommand R+のトークナイザーは他のトークナイザーと比べてトークン数が削減できていることがわかりました。
- Apple、iPhoneでも稼働するオープンな言語モデル「OpenELM」を公開
	- https://www.itmedia.co.jp/news/articles/2404/25/news103.html
	- パラメータ数の異なる4つのモデルがある。小さいものから、2億7000万、4億5000万、11億、30億
	- OpenELMは、レイヤーごとのスケーリング戦略を用いて、Transformerモデルの各レイヤー内でパラメータをefficient（効率的）に割り当てることで精度を向上させているという。
- Let's compare Llama-3 & Phi-3 using RAG:
	- https://lightning.ai/lightning-ai/進化的s/compare-llama-3-and-phi-3-using-rag?utm_source=akshay
	- https://x.com/akshay_pachaar/status/1783114329199718558
-  Cohere Toolkit
	- https://github.com/cohere-ai/cohere-toolkit
	- Yesterday, we open sourced the Cohere Toolkit. We think this will be a major accelerant for getting LLMs into production within enterprise.
-  LLMにとって「質の良い学習用データ」
	- https://x.com/imos/status/1783494307959513522
	- LLMにとって「質の良い学習用データ」は「正しい日本語に/倫理的に絞られたデータ」ではないと思うので整理して布教したい（FineWeb曰くアダルトサイトを抜くと性能劣化するらしい）。言語能力、知識、論理能力、応答形式など、用途を満たすのに必要な軸を欠かさず含むことが大事だと思われる。
- Llama 3 Establishes Meta as the Leader in “Open” AI  by IEEE Spectrum
	- https://spectrum.ieee.org/meta-llama-3?share_id=8224093&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- 『統計的テキストモデル』(岩波書店 確率と情報の科学)の執筆がついに最後まで到達しましたので、「文書の統計モデル」の章を公開しました
	- http://chasen.org/~daiti-m/textmodel/textmodel-chapter5.pdf
-  Graph Machine Learning in the Era of Large Language Models (LLMs)
	- https://arxiv.org/abs/2404.14928
	- グラフと言語モデルに関するレビュー論文
	- グラブ系機械学習モデルとLLMの組み合わせによる研究例や展望がまとまっています。MI分野だけでなく他分野の事例もあり参考になります。
- Two new AI releases by Apple today
	- https://x.com/pcuenq/status/1783032344104026372
	- OpenELM, a set of small (270M-3B) efficient language models. Weights on the Hub:
	- CoreNet, a training library used to train OpenELM:
-  [Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge](https://aclanthology.org/2024.eacl-long.127.pdf)
	- 多言語言語モデルが獲得している事実に関する知識を53言語で検証。どのような原因によって言語ごとに差が出るのか、データ量や地理的観点・活性化されたニューロンの類似性などから分析している。
-  LLMプロダクト開発者がMac 進化的を買ってローカルLLMを触るべき理由
	- https://note.com/erukiti/n/n58a8180ea9fb
- [torchtitan](https://github.com/pytorch/torchtitan)
	- a library for large model training called torchtitan
	- They have scripts to train Llama-3 from scratch
	- The library went public today on GitHub but it is still in pre-release state & active development
- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	-  **stuff chain**、 **map reduce chain**、**map rerank chain**、 **refine chain**
	-  **適している文書特徴**
		-  **stuff・map reduce**  : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- **map rerank**  : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- **refine**  : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- 「Japanese-Starling-ChatV-7B」
	- https://x.com/AIBizNavigator/status/1783667625802994164
	- 7Bクラスとは思えない超高性能なんだ
	- 英語の最強7BモデルStarling-LM-7B-betaから抽出したChat Vectorを、 日本語モデルのChatNTQ-JA-v1.0-7bに掛け合わせただけ。 追加の日本語学習は一切なし
	- https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7b
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- https://huggingface.co/umiyuki/Japanese-Chat-Umievo-itr001-7b
	- ElyzaTasks100で評価してみたら平均3.57点を叩き出した！7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！とりまHuggingFaceに上げました！
- Swallow instruction tuning models
	- https://huggingface.co/collections/tokyotech-llm/swallow-instruct-65e559f4d52e7c9d197697c2
	- wallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました。あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました。
- tokyotech-llm/Swallow-MS-7b-instruct-v0.1
	- https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1
	- swallow 7B, 13B, 70B、およびSwallow-MS 7Bのインストラクション・チューニングを改良し、指示追従性やマルチターン応答を向上させたモデルをHugging Face上で公開しました。以前に公開したモデルと比べて、MT-Benchのスコアで大幅に改善しています
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】
	- https://x.com/hokazuya/status/1783808939773304957
	- 512トークン、340Token/S
	- M3 Pro Mac (64GB)で16ビットの270Mモデルで超高速ローカルLLMが実現。
-  Weave と Elyza-tasks-100 で ローカルLLMを評価する by npakaさん	
	- https://note.com/npaka/n/nc0c8d5beacff?sub_rt=share_h
	- 「**Weave**」は、LLMアプリケーションの記録、実験、評価のためのツールです
	- 「**Elyza-tasks-100**」はElyzaが提供する指示チューニングモデル用の評価用データセットです。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘しているが、、
	- https://x.com/rmaruy/status/1784154638390104188
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
- ベイズ推論を使ってみよう
	- https://x.com/makaishi2/status/1784115819791913065
	- 『Pythonでスラスラわかるベイズ推論「超」入門』著者
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
	- 配信者の2人「ジェンスン？誰？？」
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
	- 高速AIチップで話題のGroqのAPIをStreamlitのコードの記事を書いてみました。OpenAIのAPIと表記が似ているので書きやすいですね。
- Swallow-MS-7BやRakutenAI-7Bはトークンの語彙が拡張されてる事に気付いたが、これって拡張されてない他のモデルとマージしたらアカンのだろうか
	- https://x.com/umiyuki_ai/status/1784274430816034898
- 【Whisper.cpp-CLI】
	- https://x.com/hokazuya/status/1784554378118246440
	- ローカルで高精度の音声文字起こしができるWhisper環境が、ものの200msで作れてしまうとのPyplパッケージがOSSで
- 


## 4/21

今週は、最大３倍高速という日本語GPT-4の開発の発表もあったけど、なんといってもメタからllama3の待望の公開。最初は8bと70bが公開され、さらなる大規模モデルも開発中とのこと。lllama3のファインチューニングに用いたPyTorchの新機能tochtuneも公開。早速、量子化、MoE化、ファイチューニングの実行例が公開され、MXで8GB M2 miniでの動作確認!、ollamaの対応、さらにはGroqに乗っかってデモサイトでLlama3-70Bが300t/sの超絶爆速推論を見せたなどの一通りが１週間で進む。RAGでのllama3の利用例もLangChainから紹介があったが、CommandR＋もllama3も、プロンプトに与えるテンプレートが独特なので、LLMをネイティブに使う人は要注意だ。1bitのLLMも、shi3zさんの自作評価や、椎橋さんによるGPUではないオーダーメイドによるAIソリューション「カスタムAI」の可能性など、いい記事がでてきた。ChatVectorによるLLM性能向上も、先週に引き続き、Bakuさんの、ChatNTQ 7B と LightChatAssistant 2x7B の日本語能力を試す記事が神記事として話題に。LightChatAssistantってのはそんなにすごいのか。作ってみたら性能が高かったというJapanese-Starling-ChatV-7B-GGUFなども出たり、ChatVector紹介の先駆者はちさんからSwallow-MS-7b-v0.1-ChatSkill-LABが出たり、能力加算の組み合わせの最適解をoptuneをつかって実行・評価とか、、LLMの能力の足し算引き算しつつ性能を評価するという一段メタな世界が開けた。PFNの丸山さんが紹介された、LLMをつかって言葉だけで、線形回帰をさせるという論文、どんなモデルを内部に持っているんだという意味で面白い。 Cambridge大学のU. Anwar, D. Krueger氏ら40名!による、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文はすごい、AIガバナンスのオックスフォードハンドブックもあり、UKではアライメントとガバナンスの大きな拠点になっているのか。マイクロソフトから、WizardLM-2 の7bと8x22bが発表、Evolve Instructという新しいファインチューニング手法の能力やいかに、エージェント機能も持っているとか、嵐の予感。Qwen1.5-7B-Chat-GGUFも出た、来週あたりQwen1.5ベースの日本語LLMが出てくるのでは。DeepMindの「Many-shot」多数例示学習の有効性や、RAGのMiniCheck、複数の知識を組み合わせるChain-of-Abstraction (CoA) ReasoningなどのLLM推論での進展もあった。丸山隆一さん、AI科学の何が“哲学”という問い（スライド）も良いし、「AI協働時代に研究者はどう生きるか」というイベントも面白い。AIが（従来の）研究ができるようになるならば、AI研究者はなにをするのかみたいな感じ。さきほどのUKと比べるとこのあたりの研究者層が薄いのかな。その他としては、Swallow-MXを使ったQ&AデータセットであるAutoWikiQAとか、MiniCPM-V-2のデモの公開、商用利用可能なマルチモーダルLLM、idefics-8bなども出てきた。

- openbmb/MiniCPM-V-2
	- MiniCPMのデモが公開
	- https://huggingface.co/spaces/openbmb/MiniCPM-V-2
- OpenAI Japanの発足とまさかの日本語GPT-4の発表。
	- https://openai.com/blog/introducing-openai-japan
	- 「日本語のテキストの翻訳と要約のパフォーマンス、およびコスト効率を向上させ、前モデルと比較して、最大3倍高速に動作します。」
- ChatNTQ 7B と LightChatAssistant 2x7B の日本語性能を測定する
	- https://sc-bakushu.hatenablog.com/entry/2024/04/10/191420
	- 「[ChatNTQ-JA-7B-v0.1](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)」と、そのMoEモデル「[LightChatAssistant 2x7B](https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B)（改称あり）」について、かなり性能が良さそうな感触が得られたので、追加でテストしてみました。
	- LightChatAssistantはChatNTQとAntlerがジョグレス進化して奇跡のシナジーを起こして、ELYZATasks100ベンチで35BのCommand Rに匹敵する性能を出してしまう
	- LightChatAssistantではMistral 7B v0.2 InstructからChatVectorを抽出してたけど、もっと性能高そうなStarling-LM-7B-betaから抽出した方がいんじゃね？という事で抽出してChatNTQに足してみたら、MoEにもしてない単なる7Bモデルの時点でElyzaTasks100ベンチでLightChatAssistant超えの性能が出てしまった！Command R-35Bと同点のスコア！
- Heron-Bench: 日本語Vision＆Languageモデルの性能評価ベンチマークの公開
	- https://arxiv.org/abs/2404.07824
	- https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench
	- 日本語のVision-Langugeモデルのベンチマークがなかったので作成し、Turingで開発したheronを含めてモデルの比較を行いました~!!
- CS159: LLMs for reasoning lecture slides from Caltech
	- https://sites.google.com/view/cs-159-2024/lectures
- RTX4090+A6000(24+48GB VRAM)でcommand-r-plus-Q4_K_Mを65/65 layer GPUに載せても6.5t/sくらいが限度だった。 おそらく、96GBではメインメモリが足りないから遅い。
	- https://x.com/Meteor_Eternal/status/1779807643668013534
- an introduction to agents and tools
	- https://x.com/llama_index/status/1779898403239125198
	- This short course is the perfect beginner sequence for anyone looking to get an overview of agent implementations, how to equip them with tools to perform tasks like advanced QA/RAG or anything else, and also some neat extensions (tool retrieval, step-wise execution).
- From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples
	- https://arxiv.org/pdf/2404.07544.pdf
	- LLMに、「この入力の場合出力はこれ」という例示を入れて「ではこの入力の場合の出力は？」と推論させると線形回帰・非線形回帰ができてしまう、という論文。
- TFMC/Japanese-Starling-ChatV-7B-GGUF
	- https://note.com/bakushu/n/ne95340f04b41
	- LightChatAssistant-2x7Bの日本語チャット性能がとても良いため、モデル作者さんが用いた手法（Chat Vector+MoEマージ）を後追いで検証しているなかで、発見。
	- 7Bクラスとしてはベンチマークスコアがやたら高いモデルが出てきたので「Japanese-Starling-ChatV-7B」として公開してみました。
- HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- ChatVectorを使って新しいApache2.0のChatモデルを作りました。 ChatVector抽出元のモデルもMixtral-8x7B-Instructによる人工データ(Synthetic Data)で学習されたものなので、隠れたライセンス汚染の心配はありません
-  進化的アルゴリズムをもちいたChatVector加算の最適化 by　はちさん
	- https://note.com/hatti8/n/na593650d688b
	- 進化的アルゴリズムを使用するために、optunaとcmaes
	- 進化的アルゴリズムを使って、この関数のoutputであるscoreを最適化（最小化）します
		1. merging_ratio（ChatVectorの加算比率を各layer毎に持つ辞書）の定義
		2. merging_ratioにしたがって、ChatVectorのマージ
		3. ELYZA tasks 10の実施とGPT4による評価
- Foundational Challenges in Assuring Alignment and Safety of Large Language Models
	- https://llm-safety-challenges.github.io/
	- 2024.4.15 Cambridge大学のU. Anwar, D. Krueger氏ら40名弱の国際チームによる、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文。
	- 1）LLMの科学的理解、
	- 2）訓練手法や実装場面の課題、
	- 3）社会における課題に分け、
	- 広範な文献調査に基づき200超のリサーチクエスチョンを同定。
	- このAnwar+2024論文はすごい。「LLMの何が技術的・社会的な問題になるのか？」を包括的に洗い出し、かつリサーチクエンションのリストに落とし込んでいる。by maruyamaｓあｎ
- Running WizardLM-2 8x22B Q4_0 locally via ollama
	- https://x.com/ivanfioravanti/status/1780133719707197643
	- On an M2 Ultra I get: ~19.5 tokens/s
	- 80Gb??
- MaziyarPanahi/WizardLM-2-8x22B-GGUF(Q4_K_M)
	- https://x.com/alfredplpl/status/1780110628864274576
	- うーん日本語がやはりイマイチだな
- WizardLMの作り方
	- https://x.com/WizardLM_AI/status/1779937307690471834
	- 新しいWizardLM-2 7BのサイズでMT-BenchがClaude-2より高いってすごい by はち
- WizardLM: Empowering Large Language Models to Follow Complex Instructions
	- https://arxiv.org/pdf/2304.12244.pdf
	- 課題：様々なレベルの複雑さを持つ大量の指示データを作成することは、時間と労力がかかる。
	- 解決：Evolve Instruct方法を使用して、LLM自体が指示データを生成する新しいファインチューニング
- Introducing the Batch API: save costs and get higher rate limits on async tasks
	- https://platform.openai.com/docs/api-reference/batch
- Introducing Idefics 2
	- https://huggingface.co/collections/HuggingFaceM4/idefics2-661d1971b7c50831dd3ce0fe
	- An 8B Vision-Language Model - literally punching above its weight.
- Pytorchからファインチューニング用の機能torchtuneが公開
	- https://pytorch.org/blog/torchtune-fine-tune-llms/?utm_content=289842551&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024
	- llama3のファインチューニングをこれでやったんだと
-  AI科学の何が“哲学”の問題になるのか　～問いマッピングの試み～
	- https://speakerdeck.com/rmaruy/aike-xue-nohe-ga-zhe-xue-nowen-ti-ninarunoka-wen-imatupingunoshi-mi
	- まるやまさん
-  「AI協働時代に研究者はどう生きるか」(4/26)
	- https://share.hsforms.com/1NFOzzuNBSZq3K20gtPZ30wdxf90
	- 本イベントでは、研究の自動化・自律化が益々加速していく未来において、研究という営みがどのように変化していくのか、その中で研究者はどう生きるべきか、ということについて議論します。  
	- AIロボット駆動科学を牽引する一杉太郎さんと、AI科学を俯瞰的に考える丸山隆一さんによる特別パネルディスカッションや、「AI × ◯◯学」をテーマに月額支援型クラウドファンディングに挑戦中の若手研究者8名のプレゼンを通して、「AI協働時代に研究者はどう生きるか」、皆さんも一緒に考えてみませんか？
- 生成AIでGPUがいらなくなる？　業界を揺るがす「1ビットLLM」とは何か、識者に聞いた
	- https://www.itmedia.co.jp/aiplus/articles/2404/16/news064.html
	- ではそもそも“1bit”とは何が1bitなのか、どうして1bitになるとGPUが不要になるのか。LLMでGPUが不要になるとどんな世界が訪れるのか。オーダーメイドによるAIソリューション「カスタムAI」の開発・提供を行うLaboro.AIの椎橋徹夫CEOに聞いた。
	- **椎橋：**今回の結果から、LLMの推論において、GPUではなく別の半導体の機構が最適になって、劇的に計算が軽く早くなる可能性が開けてくるんです。
	- 論文中でも、GroqというLLMの推論に特化したLPU（Language Processing Unit）の登場に触れられています。次世代半導体での復活を狙う日本の産業にとっても、注視していくべきトピックではないかと思います
- この前調合した改造Swallow-MX（継続日本語学習+instructionベルトル強化）とMixtral 8x22Bを比較すると短時間使用では差異捉えにくいな それだけ8x22Bの日本語能力アップしてるのは間違いない
	- https://x.com/AiXsatoshi/status/1778630270486552619
- Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行
	- https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf
	- 2024.4.16 Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行。昨年から大幅に増量した500ページ超の紙幅にて、AI研究の論文数・特許・先端モデルの開発動向・投資額・経済的インパクト・科学や教育への影響・ガバナンス・社会受容など包括的に報告。
	- 「AIは人間より高性能だが一部のテストでは人間の方が優秀」「高性能AIの学習コストは数百億円」など
- HuggingFaceM4/idefics-8b
	- https://huggingface.co/spaces/HuggingFaceM4/idefics-8b
	- 明確に商用利用可能なマルチモーダルモデルのデモ
-  Google Colab で idefics2 を試す by npakaさん
	- https://note.com/npaka/n/n032c2bbaadb4?sub_rt=share_h
	- 「Idefics2」は、テキストと画像を入力し、テキストを出力するマルチモーダルモデルです。画像の質問応答、視覚的コンテンツの説明、複数画像をもとに物語作成、文書からの情報抽出などを実行できます
- AIの処理能力､1年で25倍　死蔵の｢知能資本｣が競争力に by shi3zさん
	- https://www.nikkei.com/prime/digital-governance/article/DGXZQOUC092UR0Z00C24A4000000
	- そのような世界で価値を高めるのは、死蔵された書籍や動画などの「知能資本」という。「AI資本主義」という新たな経済の姿を提唱する、
-  MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents
	- https://arxiv.org/abs/2404.10774
	- RAGなどエビデンスに基づいて LLM に生成させる場合にそもそも生成したものがエビデンスに基づいて生成できているのか（ファクトチェック）が課題になりますが、それを効率的に行うモデルを学習するシステム MiniCheck の提案。
	- GPT-3.5/4を用いて、人が書いた文章をもとにFACTを抽出したり要約生成をしたりしながらファクトチェックタスクに特化した高品質な合成データを生成し、それを用いて小さなモデルを学習することで、GPT-4と同等の性能で400分の1以下のコストでファクトチェックができるようになったそうです。
- RAGを複雑な質問に強くする手法「CoA」について
	- https://zenn.dev/knowledgesense/articles/508187f1c616e3
	- 「Chain-of-Abstraction (CoA) Reasoning」
	- CoAが従来のRAGよりも力を発揮できるシーンは、ユーザーの質問が「複数の知識を組み合わせなければ正答できない」ような質問だった場合です。通常のRAGでは1回のドキュメント検索で回答に使えるドキュメントを見つけようとしますが、CoAでは、問題（ユーザーからの質問）を複数の問題に分解し、複数回のドキュメント検索を行った上で総合的な回答を生成できます
- Qwen/Qwen1.5-7B-Chat-GGUF
	- https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF
	- 7 billion parameters coding chat model (~5GB RAM needed)
-  1BitLLMの実力を見る by shi3zさん
	- https://note.com/shi3zblog/n/ndd1f27fff31c?sub_rt=share_pb
	- 普通のHuggingFaceのお作法とはかなり違うので注意が必要。  まず、このHuggingFaceリポジトリを丸ごとgit cloneする
	- これをやらずにいつもの凡例みたいにいきなりpipelineに読み込もうとすると謎のエラーが出て悩まされることになる。海外でも悩んでる人が何人もいるみたいだ。まあ個人的には「こんな説明で誰がわかる?」と思うが。
- mistralai/Mixtral-8x22B-Instruct-v0.1
	- https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1
	- Mixtral-8x22B Instract きたわ〜
- Build RAG, Function Calling, and Agents with llama_index and  MistralAI8x22b 
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/mistralai/
- 24/04/18 ローカルでCommand RやCommand R+を動かす時の作法
	- https://six-loganberry-ba7.notion.site/24-04-18-Command-R-Command-R-ff8455f1dba543168d5a7768705e0043
	- 実はCommand Rはプロンプトにチャットテンプレートを使用しないと正しく回答が返ってこないらしい
	- <|START_OF_TURN_TOKEN|><|USER_TOKEN|>Who are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
	- チャットテンプレートのあるなしで回答のクオリティは天と地ほど違ってくるから注意しよう。
- Introducing Meta Llama 3:
	- https://ai.meta.com/blog/meta-llama-3/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama3
	- the most capable openly available LLM to date.
	- Llama3のリリース第一弾は8Bモデルと70Bモデル！それぞれベースモデルと指示チューニング版があり！HuggingFaceからＤＬできる！8BモデルはベンチでMistral-7BやGemma-7Bを撃墜！70BモデルはGeminiPro1.5やClaude3Sonnetを撃墜！人間による評価でもSonnet、MistralMedium、GPT-3.5に勝利！
	- Context長は8kTokenでパラメータ数は80億と700億パラメータ。なんと4000億パラメータを超えるモデルも学習中！700億のほうは現在のフロンティアModelに性能的に肉薄しつつある状態。
- LangChain x Mistral RAG Agent Cookbooks + Video
	- https://x.com/LangChainAI/status/1780994907903263159
	- With the release of new Mixtral 8x22B, there's high interest in building agents with open source LLMs.
- VARIATIONAL BAYESIAN LAST LAYERS
	- https://arxiv.org/pdf/2404.11599.pdf
	- Neural Networksの最終層以外は固定されていると思って、最終層のみの 1-layer な Bayesian Neural Network としてモデル化し最終層の最適化をしつつ変分ベイズ推定する枠組み Variational Bayesian Last Layers （VBLL）の提案。
- Reliable, fully local RAG agents with Llama3
	- Here, we show to how build reliable local agents using LangGraph and Llama3-8b from scratch.
	- https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb
- 例のSRAMメモリのAIチップを山盛りに積みまくった構成のGroqのサイトでLlama3-70Bが300t/sの超絶爆速推論
	- https://x.com/umiyuki_ai/status/1781529537102352827
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- プロンプトに数百〜数千の例を含めてLLMにタスクを行わせる『Many-shot（多ショット）』がDeepMindにより検証されています
	- 結果、基本的に例が多くなるほど性能が上がるとのこと。事前学習による思い込みを覆すことも。人間製の例がなければモデル生成の例でも効果あり
-  [llama.cpp：iMatrix量子化は日本語性能にどう影響するか？](https://sc-bakushu.hatenablog.com/entry/2024/04/20/050213)
	- 量子化時のモデル劣化を抑制する重要度行列（iMatrix; Importance Matrix）計算の話題です。
	- 最近はHuggingFaceにアップされるGGUFも多くがiMatrix版となっていますがこれらの量子化でよく使われているiMatrix計算用データセットは以下の2種類のようです。
- MLX で Llama 3 を試す
	- https://note.com/npaka/n/n21fa74396545?sub_rt=share_h
- Llama 3がGroqに登場
	- https://x.com/kyo_takano/status/1781595042840559908
	- Groqがなぜこんなに速いのか？それはGPUではなくLLMに最適化されたASICを使っているからです。Groqは最近新しいデータセンターを作ったばかりで、そこで何個ASICを使っているのか直接聞いたら700個以上と答えてくれました、今後リアルタイム性需要が高まるとGroqはさらに急成長してくると思います。
- 小さい計算コストでスマートにLLMをチューニング!-Hugging Face PEFT入門(前編)
	- https://zenn.dev/elith/articles/3ec1d319c8a40f
	- パラメータ効率の良いFine Tuning手法(Parameter-Efficient Fine Tuning、 PEFT)について、サーベイを行いました。
- With the latest MLX, 4-bit Llama 3 8B runs nicely on an 8GB M2 mini.
	- https://x.com/awnihannun/status/1781345824611680596
	- 512 tokens at 18.8 toks-per-sec
- cl-nagoya/auto-wiki-qa
	- https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa
	- 東工大のSwallow-MXを用いてWikipediaのテキストに基づく質問と回答を生成させたデータセット AutoWikiQA をHuggingFace上に公開しました！
	- 約240万事例と日本語QAデータセットの中でも最大規模かつ高多様性なデータセットです
- The Oxford Handbook of AI Governance
	- https://global.oup.com/academic/product/the-oxford-handbook-of-ai-governance-9780197579329?cc=jp&lang=en&
	- AIガバナンスのオックスフォードハンドブック。49本通読する人出る　by 生貝先生
- lama-3-8b's in-context learning is unbelievable.
	- https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/
- いちばんやさしいローカル LLM
	- https://note.com/schroneko/n/n8b1a5bbc740b#57403f33-7b40-444e-9342-c8bf11458d18
	- ローカル LLM 初めましての方でも動かせるチュートリアル
	- Ollama を使えば簡単に LLM をローカル環境で動かせる
- Crystalcareai/llama-3-4x8b
	- https://huggingface.co/Crystalcareai/llama-3-4x8b
	- This is an MOE of Llama-3-8b with 4 experts. This does not use semantic routing, as this utilizes the deepseek-moe architecture. There is no routing, and there is no gate - all experts are active on every token.
	- 予想はしてたけど、もうLlama3のMoEができてる　by はち さん
-  Google Colab で Llama 3 のファインチューニングを試す
	- https://note.com/npaka/n/n315c0bdbbf00?sub_rt=share_h
	- 今回は、ござるデータセットで学習します。AIが「我、りんえもんは思う。◯◯でござる。知らんけど。」的な口調になります。
	- 練習として500ステップだけ学習します。指示に応じて、wandbのAPIを入力してください。8分ほどで学習完了します。
	- 我、りんえもんは思う。 マミは一番かわいい。知らんけど。
	-  HuggingFace Hubへのアップロード
		- (1) LoRAアダプタをベースモデルにマージ
		- (2) 「HuggingFace Hub」のメニュー「New Model」を選択。
		- (3) HuggingFace Hubのリポジトリの作成。
		- (4) HuggingFace Hubへのアップロード
-  統計学を哲学する
	- https://www.unp.or.jp/ISBN/ISBN978-4-8158-1003-0.html
	- 書評（丸山隆一）
		- “…… 科学の最も基本的なツールである統計学を哲学的に分析する。ベイズ統計、仮説検定、機械学習、因果推論などの統計学的手法を科学者が使うとき、何が暗黙の前提となり、何が正当化の根拠になっているのか。哲学的認識論の道具立てによる本書の整理は鮮やかだ。深層学習に関する議論は、どのような意味で AI に科学ができるのかという大問題にもつながる。「AI 科学の哲学」の始動を感じる。……”


## 4/15

今週も強烈だった。頭がくらくらするが、気のせいか重み転移系が多い気がする。MiniCPM-2B、「μトランスファー」という手法で小規模LLMで最適化されたパラメータを大規模LLMに転移する技術で（２段階トレーニングと呼ばれてる？）、2.4Bパラメータという小さなサイズでMistral-7Bと肩を並べるとか。Command R+も量子化されたものが評価されて、Mac(M3、128G)や、A100(80G)で結構サクサクうごくらしい。特に、 「Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作」ってのは、A100持っている人はぜひ試してみるべき。 Command R+に影響されたのか、MistralもMixtral-8x22Bをオープンソースとして発表、さっそくこれをベースにexpertsをマージしてmistralにした勝手版Mistral-22Bが出て、双方量子化版が出て、、、とあっという間に広まって何が何だか。LLM同士の機能のベクトル演算であるChat Vector、まねしてMath強化版をつくって、これらを融合した結果、数学能力をある程度維持しつつ、Chat能力も強化することができるという話もあった。LightChatAssistant 2x7BてのもMistral7Bモデルをベースとした日本語対応モデル 2をChatVector手法で対話能力強化してmergekitでMoE化したもの。32kのContextSize対応、iQ3_XXS量子化でVRAM12GBでフルロード可能、RTX3060でも動くとか。JetMoEという新しいアーキテクチャ、MoEであることに加え、MiniCPMに倣った2段階トレーニングの効率が極めて高くそれでいて性能はLlama-7B並みとか。Googleの新しいリカレントアーキテクチャRecurrentGemma、リカレントニューラルネットワークとローカルアテンションを活用してメモリ効率を向上さているらしい、今後もGemmaとパラレルにリリースするのか。GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」てのもあった、Gemma-2Bに追加学習して「Function Calling」を強化したとのこと。それから、今週はGoogle Cloud Next24があったので、最大100万トークンのGemini 1.5 Proのリリースや、DeepMindのImagen 2、TPU v5pの発表、GoogleDocにGeminiの統合とか、geminiでRCカーを制御とか面白い出し物があった。日本語LLM 9種を量子化して回答内容を比較ってのも面白かった、ELYZAは偉いぞ。LangChain の Tool Calling 標準インタフェース ってLLMに依存しないということなので、エージェントとかの活用が加速しそう。QR分解でカルマンフィルターってのは目からうろこだ、一見異なる枝がエレガントにつながる、これぞサイエンスの醍醐味だ。

- MiniCPM: Unveiling the Potential of End-side Large Language Models
	- https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20
	- 既存7B LLMより強いと話題の2B LMMのMiniCPM
	- μP使って小さいモデルで効率的にハイパーパラメータ探索
	- MiniCPM is a series of edge-side large language models, with the base model, MiniCPM-2B, having 2.4B non-embedding parameters. 
	- It ranks closely with Mistral-7B on comprehensive benchmarks
- 現状のLLM選択肢 by urawazakun
	- https://x.com/urawazakun/status/1777130873844040046
	- commandRplus　108B →Mac 進化的（988000円）
	- commandR　35B →RTX4090（PC + 40万円～）
	- LightChatAssistant2x7B →RTX3060（PC + 3万円～）
-  EasyLightChatAssistant
	- https://github.com/Zuntan03/EasyLightChatAssistant?tab=readme-ov-file
	- EasyLightChatAssistant は軽量で検閲や規制のないローカル日本語モデルの LightChatAssistant を、KoboldCpp で簡単にお試しする環境です。
- ｢LLMはコモディティー｣　米データブリックスCEOが語る
	- https://www.nikkei.com/article/DGXZQOGN252JK0V20C24A3000000/
	- LLM単体ではなくLLMやその他のモジュールを組み合わせて問題を解く「複合AI」の考え方がとても大事
-  Octopus v2: On-device language model for super agent
	- https://arxiv.org/abs/2404.01744
	- https://huggingface.co/NexaAIDev/Octopus-v2
	- GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」
	- 20億パラメータを持つエッジデバイス上で機能するオンデバイスAIモデル「Octopus v2」
- Google Colab で Octopus V2 を試す by npakaさん、
	- https://note.com/npaka/n/n706bde979ed8
	- Gemma-2Bを追加学習したモデルで、学習ステージと推論ステージの両方に独自のFunctionトークン戦略を導入することで、「Function Calling」において「GPT-4」に匹敵する性能を達成したとのことです。
	- ユースケースとしては、「カレンダーにリマインダー追加」「メッセージ送信」「Youtube検索」の指示などが挙げられています
- Chat VectorとMath Vectorは併用できるのか by はちさｎ
	- https://note.com/hatti8/n/n2d6d86d6f05a?sub_rt=share_h
	- Chat+Math能力の両方を日本語ベースモデルに付与したら、どちらの効果も得られるのか
	- Math強化モデルに先ほど作ったChat Vectorを重ねがけしていきます
	- Math強化モデル：Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vector：SkillTree-Chat-Mistral-7B-v0.1
	- Math+Chat強化モデル
		- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatMathSkill
	- 結論
		-  **モデルが壊れることはない**
		- **数学能力をある程度維持しつつ、Chat能力も強化することができる**
		-  **一方、英語で回答しやすくなる傾向が出てくる**
- Chat VectorならぬMath Vectorは作れるのか
	- https://note.com/hatti8/n/n0000353355cb
- LangChain x DSPy
	- https://www.youtube.com/watch?v=4EXOmWeqXRc
- JetMoEってなんじゃ？ by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777014403197788280
	- Mixture of Attention heads（MoA）とMixture of MLP Experts（MoE）の二つのレイヤーに、それぞれ４人ずつエキスパートがいて、推論時は各レイヤー２人ずつが活性化する。
	- 活性化パラ数は2.2Bで、合計パラ数は8Bだって。何だか知らんけどこのアーキテクチャによってトレーニング効率が爆上がって、H100が96台で２週間、1200万円しかトレーニング費用かけてないのに、数千億かけたはずのLlama-7BやLlama-13にベンチで勝利した
- μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_b&d=s4cpuSjMMAw
	- μP（Maximal Update Parametrization）というのは、 Tensor Programs (TP)というフレームワークにおいて理論的に導出されたパラメータ付け（パラメータのスケーリングなど）の方法です
	- TP は、 Neural Networks （NN）の解析をするために、線形変換や非線形活性化関数などの NN の構築で頻出する操作をリストアップし、その枠組みで成立する事象や性質を追求するフレームワークです。
	- https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/
- Leveraging language representation for materials exploration and discovery
	- https://www.nature.com/articles/s41524-024-01231-8
	- 言語モデルによる材料探索の論文。
	- 結晶材料をテキスト表現にし言語モデルにより既存材料に似た新熱電材料を探索
	- 特に、GPTのようなデコーダ専用モデルより、BERTのようなエンコーダ専用モデルのほうが汎用性が高くMIタスクに向いている、という点が興味深かったで
- μトランスファーとは by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777204816059711692
	- MiniCPMはミュートランスファーというテクニックが使われてるらしい。これが何か？というと、でかいLLMをトレーニングする時の最適パラメータを探るテクらしい。
	- でかいLLMを学習する時に、ハイパーパラメータをどう弄れば最強になるのか、イチイチ色々試して最適解を試行錯誤するのはメチャクチャ大変だ。そこで、同じアーキテクチャのちっちゃい版で実験すればサクサクと最適なパラメータを試行錯誤できる。で、ちっちゃいモデルで見つけた最強パラメータが、でかいLLMにそんままコピペしてもちゃんと最強になる事が判明したらしい！
- JetMoEのトレーニング効率上がったのは　 by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777023943121256637
	- Komatsuzaki氏の見解によれば、JetMoEのトレーニング効率上がったのは、たしかにMoEアーキテクチャによって２～３倍に効率化したけど、それより何よりMiniCPMに倣った2段階トレーニングの手法のおかげでバキバキに効率化したとの事。
	- 1万倍の内、MoEの貢献が３倍なら残りの3333倍はMiniCPMトレーニングのおかげなのか
- The Physics of Language Models
	- https://arxiv.org/abs/2404.05405
	- 「言語モデルは、int8 に量子化された場合でも、パラメータごとに 2 ビットの知識しか保存できません。また、そのような知識は、下流のアプリケーション用に柔軟に抽出できます。その結果、7B モデルは 14B ビットの知識を保存でき、これは私たちの推定に基づくと、英語版 Wikipedia と教科書を合わせた量を超えます。」
	- 回転埋め込みを備えた GPT-2 アーキテクチャは、知識の保存において LLaMA/Mistral アーキテクチャに匹敵するか、それを上回ります。
- Gemini 1.5 Pro
	- https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html
	- 180カ国サポート、「統一モデル」音声・動画認識、ファイルAPI、System Instructionカスタマイズ機能、 JSONモードなどが加わりました、以下で試せる
	- https://ai進化的.google.com/app/prompts/new_chat
- Imagen 2 by DeepMind
	- https://x.com/GoogleDeepMind/status/1777747320945234422
	- Imagen 2 can now create short, 4-second live images from a single prompt.
- GPT-4 Turbo launch
	- https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4
	- previewが取れた
- UNESCOがAI Ethicで人集めしている by　神嶌さん
	- https://careers.unesco.org/job/Other-cities-Consultant/791818302/d
- Llama.cpp で Command R+ をお試し中 by npakaさん
	- https://x.com/npaka123/status/1777802956571889969
	- Q4_K_M・M3 Max (128GB) 5.22 tokens per second
- mmnga/codegemma-7b-it-gguf
	- https://huggingface.co/mmnga/codegemma-7b-it-gguf
	- gemma-1.1-7bとcodegemma-7b-itのgguf
- 【LangChainゆる勉強会#3】LangChainのAgentはどれを使う？
	- https://www.youtube.com/watch?v=07TuBmm67sU
	- LangChainを使ったAgent実装を概説してくださってる勉強会のアーカイブ動画。
	- 最近はLCELで組んでAgent Excutorに投げる以外の実装しないので、なんか色々あるんだなと勉強になりました
	- XML Agentとか誰が使うん？って思ってたけど、Claudeと相性良いらしい。へぇ〜！
- rinna/youri-7b-chat-gptqとintfloat/multilingual-e5-largeでRAGするだけでもcolabよりrtx3060の方がかなり速い
	- https://x.com/rsimd_/status/1747614320878555175
	- vramが足りればって話だけど，一応faiss-cpuを使えばメモリ足りてる．
- Command R+の量子化PPLを計測してくれてる
	- https://github.com/ggerganov/llama.cpp/pull/6491#issuecomment-2043633791
	- Q3_XXSは38GBだけど、ここまでなら精度的にも全然大丈夫ちゃうか？って予感はする。IQ2_XXSなら26.6GBで、ちょっとアホになってそう。IQ1_Sなら21.6GBだけど、さすがに実用性ヤバそう。
- Perplexity Proに課金してGoogleのGemini UltraやGenerative Experienceと比較してみると、何かとんでもないことが起こっている気がする by 楠さん
	- https://x.com/masanork/status/1777478951465779344
- 完全ローカルでRAGも使えるAIチャットアプリOpenWebUIを日本語LLMでセットアップする
	- https://zenn.dev/firstautomation/articles/0b7a4b1bb2daf0
- Command R+はちゃんと強かった訳だが、Command RもこれまでのOpen-source最強のQwen1.5-72bに匹敵する訳なのですごい
	- https://x.com/Meteor_Eternal/status/1777635899204874704
- Gemini 1.5 Proの新機能 - Native Audio Understanding、System Instructions、JSON Mode、新Embeddingモデル　 by npakaさん
	- https://note.com/npaka/n/n0254081ebc23?sub_rt=share_h
- Stable LM 2 12B
	- https://stability.ai/news/introducing-stable-lm-2-12b
	- Stable LM 2 12B は、英語、スペイン語、ドイツ語、イタリア語、フランス語、ポルトガル語、オランダ語の多言語データでトレーニングされされた、120億パラメータを持つ強力な言語モデルです。 ベースモデルと指示学習済みモデルを備えています。
- GoogleDocにgeminiが統合される？
	- https://x.com/GoogleWorkspace/status/1777807449652662508
- TPU v5p, our most powerful and scalable TPU, is now generally available
	- https://x.com/GoogleCloudTech/status/1777732890471625162
- Gemma-1.1 also shows great improvement in terms of reduced hallucinations in the updated HHEM leaderbod
	- https://x.com/ofermend/status/1777695633455108478
- LLaMA 3's will start to drop next week.
	- https://x.com/mattshumer_/status/1777465835834970189
- Ride with GeminiというLLM＋RCカーのデモ
	- https://x.com/kazunori_279/status/1777846216950456658
-  Gemini 1.5 Proで文字起こしを試してみた
	- https://note.com/nyosubro/n/n07afba435ef6
	- 個人的な感想としては、Whisperレベル（あるいはそれ以上？）の文字起こし品質と論文ではありましたが、確かにそうかも！と言う感じでした。
	- またWhisperとは異なり、プロンプトレベルで様々な文字起こしタスクに柔軟に対応できる点で、結構面白さを感じてます。
- Llama.cpp で Command R+ を試す by npakaさん
	- https://note.com/npaka/n/n9136a2ebc7f9?sub_rt=share_h
	- M3 Max (128GB)
	- 「Command R+」は、「RAG」や「Tool」などの長いコンテキストタスク向けに最適化された104BのLLMです。CohereのEmbeddingおよびRerankと連携して動作するように設計されており、RAGアプリケーションに最高クラスの統合を提供し、エンタープライズユースケースで優れています。
- Wikipediaの日本語記事を元に、ユーザの質問に回答するGradioベースのRAGのサンプル。
	- https://github.com/lawofcycles/wikipedia-japanese-open-rag/tree/master
	- 使ったもの
		-   [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)
		-   [elyza/ELYZA-japanese-Llama-2-13b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-instruct)
- Command R plus推論速度、知見まとめ by AIXさとし
	- https://x.com/AiXsatoshi/status/1777867323552190876
- Amazon、「Claude 3」のAnthropicに27億5000万ドルの追加投資
	- https://www.itmedia.co.jp/news/articles/2403/28/news105.html#utm_term=share_sp
- A Generative Symbolic Music Pretrained Transformer
	- https://huggingface.co/papers/2404.06393
	- In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are
- We just released Mixtral 8x22B. Super excited for this release
	- https://x.com/sophiamyang/status/1777945947764297845
- 日本語LLM 9種を量子化して回答内容を比較調査してみた
	- https://qiita.com/wayama_ryousuke/items/50e36d0dcb37f8fb7dd8
	- 量子化しても成績が下がりにくいモデルと、大きく下がるモデルがある
	- 一部のモデルは量子化すると回答が極端に短くなる
	- 量子化によって回答が短くなる度合いは、量子化前モデルの回答の長さと相関がある可能性がある
	- 個別：
		- **ELYZA-japanese-Llama-2-7B**は、量子化後もほぼ同等の性能を維持し、0.10点のスコア低下に留まりました。
		-  **Swallow-7B**では、量子化前後で成績に変化はなかった一方、**Swallow-13B**では平均スコアが 0.28 点低下しました。
		- **CALM2**  や  **StableLM-Beta**  は、量子化後のスコアが高い結果（それぞれ 0.28 点/ 0.21 点向上）となりました。
		-   **Xwin**  モデル同士を比較すると、**Xwin 7B**は0.36点の低下を示している一方、**Xwin 13B**では0.11点の向上が見られ、同じモデルファミリー内でも異なる振る舞いが確認されました。
-  Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作させてみた話
	- https://note.com/junzokamahara/n/n9235af7a6dc1?sub_rt=share_h
	- vllmもCommand Rに対応しているとのことで、vllmで動かしてみることにしました。なお、動かすのはGPUメモリの関係でGPTQで量子化されたモデル。
	- 使用するモデルのはHugging FaceにあるGPTQに変換したCommand R+
		- client = OpenAI(base_url="http://<仮想マシンのIP>:8888/v1")
		- response = client.chat.completions.create(model='alpindale/c4ai-command-r-plus-GPTQ',
	- Command R plus GPTQのA100 80GBでの実行例
		- 18.3 tokens/sと出ている
- Geminiの新機能「System Instructions」を使ってみる。 
	- https://x.com/npaka123/status/1777969149651906927
	- ChatGPTではおなじみな機能だけど、今までGeminiにはシステムメッセージもなかったのでうれしい。
- 『すずめの戸締まり』に登場する3本脚の椅子を再現したロボット設計
	- https://x.com/shin0805__/status/1777992583396131246
	- 強化学習による歩容生成の論文を公開しました！ 来週アメリカで開催されるRoboSoft2024にて発表します！
	- https://shin0805.github.io/chair-type-tripedal-robot/
- mistral-community/Mixtral-8x22B-v0.1
	- The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.
	- おい、これApache-2.0だぞ！GPT-4クラスが商用利用可能らしい
- MLX with LangChain
	- https://python.langchain.com/docs/integrations/chat/mlx/
	- This notebook shows how to get started using MLX LLM’s as chat models.
- Google Colab で RecurrentGemma を試す
	- https://note.com/npaka/n/n0018d60fb8b7?sub_rt=share_h
	- 「RecurrentGemma」は、Google で開発された新しいリカレントアーキテクチャに基づいて構築されたオープンモデルです。 事前学習済みモデルと指示チューニングモデルの両方が英語で利用可能です
	- 新しいアーキテクチャにより、「Gemma」よりも必要なメモリが少なく、長いシーケンスを生成する際に高速な推論を実現します。
	- 今回は、「**google/recurrentgemma-2b-it**」を使います
- LightChatAssistant-2x7Bで行われている最適化をOptuneで
	- https://github.com/Aratako/Task-Vector-Merge-Optimzier
	- Sdff-Ltba/LightChatAssistant-2x7Bで行われているようなLLMにおけるTask Vectorの加算によるマージにおいて、その加算割合の最適化をOptunaを用いて行うスクリプトです
- Infini-attention
	https://x.com/umiyuki_ai/status/1778459568424784194
	- Googleが出した論文なんだね。で、「この技術のおかげでGemini1.5では100万コンテキストウインドウが可能になったのか！」
- Safeguarded AI: 
	- https://www.aria.org.uk/wp-content/uploads/2024/04/ARIA-Safeguarded-AI-TA1.1-Theory-Call-for-proposals.pdf
	- ARIAのDavidad氏の安全保証付きAIの研究プログラムの全貌が見えてきた。彼が何をしようとしているのか、それにどれほどのfeasiblityがあるのか、誰かに解説してほしい。形式証明とか、ソフトウェア工学、計算機理論のバックグランドが必要そう。
	- 今回の公募では土台となるセマンティクス、「言語」づくりを目指すとのことで、その方法論として圏論が名指しされています
- Mixtral8x22チューニング版
	- HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1
	- ORPOという新しいアライメントアルゴリズムを使用
	- ORPOは、SFTステップを必要としないため、DPOやPPOのような方法よりも計算効率が良い 
	- オープン、合成、マルチターン、LLMを介して採点さたDPOデータセット使用
- LLMによる視覚読解技術を確立～グラフィカルな文書を理解する「tsuzumi」実現に向けて～
	- https://group.ntt/jp/newsrelease/2024/04/12/240412b.html
- Embeddingsを使ってローカルでテキストをクラスタリングする（Multilingual-E5）
	- https://zenn.dev/libratech/articles/afe9c5b30668bb
- Mixtral-8x22B、LightblueさんのkarasuチューニングモデルとAWQ
	- https://huggingface.co/lightblue/Karasu-Mixtral-8x22B-v0.1
	- 強い！これは間違いなくエース級　 by AIXさとし
		- https://x.com/AiXsatoshi/status/1778489953279951132
- Introducing Mistral-22b-V.01 A breakthrough in AI
	- https://huggingface.co/Vezora/Mistral-22B-v0.1
	- First-ever MOE to Dense model conversion
	- This model is not an moe, it is infact a 22B parameter dense model!
	- mixtralのexpertsをマージしてmistralにしたやつ
- Vezoraさんが公開されているMistral-22B-v0.1のggufあります
	- https://huggingface.co/mmnga/Vezora-Mistral-22B-v0.1-gguf
- Swallowシリーズのinstruct改良版ですが、本当は2023年度中を目指していたのですが、もろもろ多忙で遅れてしまっています。
	- https://x.com/okoge_kaz/status/1778396705156943985
- mixtral 8x22bを軽くloraでファインチューニングしたら、少し、会話しやすくなりました
	- https://x.com/kanhatakeyama/status/1778417221100028061
	- 現状､mixtral 8x22bは事前学習のみのモデルですが､わりと会話できそうです｡
-  Tool Calling with LangChain
	- https://blog.langchain.dev/tool-calling-with-langchain/
	- 最近はChatGPT以外にも Function Calling (最近は Tool Calling と呼ばれることが多い) に対応するLLMが増えてきました。選択肢が増えて便利ではあるものの、各社で少しづつインターフェースが違うので実装が面倒という課題がありました。
	- そのため、LangChainは各LLMのTool Callingを統一的に扱えるインターフェースを準備しており、先日、最後のピースがハマって遂に完成したという話です。
- LangChain の Tool Calling 標準インタフェース の概要　by npakaさん
	- https://note.com/npaka/n/ne6fd5929bfa1?sub_rt=share_h
	- 「Tool Calling」の標準インターフェイスの構成は、次のとおりです。
		- ChatModel.bind_tools()ツール定義をモデルにアタッチするメソッド
		- AIMessage.tool_callsモデルが決定したツールの情報を伝えるプロパティ
		- create_tool_calling_agent()Tool Callingを利用するエージェントのコンストラクタ
- OpenEQA (オープン語彙の具体化された質問応答ベンチマーク)
	- https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=dataset
	- バッジをどこに置いたか?」などのオープン語彙の質問
	- 物理環境に対する AI エージェントの理解度を測定
- A Square-Root Kalman Filter Using Only QR Decompositions
	- https://arxiv.org/abs/2208.06452
	- QR分解でカルマンフィルター？
	- 正定値行列の和の平方根が平方根のブロック行列のQR分解で計算できることを利用して、数値的安定性の高いカルマンフィルタ（平方根フィルタ）のアルゴリズムをQR分解でシンプルに書けるのか
- Premise Order Matters in Reasoning with Large Language Models
	- LLMにプロンプトを与える際、「推論ステップの流れに沿う順序」で文脈を与えないと30%以上精度が落ちる恐れがあることをDeepMindが報告しています。
-  Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese
	- https://arxiv.org/abs/2404.07824
	- 画像-言語モデルの日本語ベンチマークとして、新しく「Heron-Bench」を公開しました！日本の画像で、日本に関する知識を総合的に問います
- Rho-1: Not All Tokens Are What You Need
	- https://arxiv.org/abs/2404.07965
	- Microsoftお得意の高品質テキストで効率よく事前学習するアプローチの最新論文、トークン単位のlossの推移を高いまま・低いまま・減少傾向・増加傾向の4タイプに分類していて面白そう。実際に学習トークンを選ぶ部分を勉強しよう。
	- https://huggingface.co/microsoft/rho-math-7b-v0.1
- GeminiによるRAGの実践例
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/use-cases/retrieval-augmented-generation
- Gemini API の ファインチューニング を試す by npakaさん
	- https://note.com/npaka/n/n6609bcbbdd30?sub_rt=share_h
- 「カルマンフィルターをQR分解で解く手法」
	- https://github.com/kevin-tracy/QRKalmanFilter
	- Square root Kalman Filter using only QR decompositions.
	- related paper: Differentiable Collision Detection for a Set of Convex Primitives
	- https://arxiv.org/abs/2207.00669
- Can Gemini 1.5 actually read all the Harry Potter books at once?
	- https://x.com/deedydas/status/1778621375592485076
	- All the books have ~1M words (1.6M tokens). Gemini fits about 5.7 books out of 7. I used it to generate a graph of the characters and it CRUSHED it.

## 4/8

今週も情報が早すぎて大過ぎて、もやは追いつけません。RAG向けのベクトルDBのベンダーかと思っていたCohereから、オープンソースのCommand R+ がリリース、まあ成り立ちから当然、RAGとかロングコンテキストに最適化さている。104Bでパラメータも公開、テスト版がhuggingfaceで試すこともできる、GPT-4並みの性能でOSSってやばくないか。早速量子化したり、MLXで動かしたりと、やばくないか。ある性能以上のLLMのオープンソース化禁止みたいな傾向に拍車がかかるのでは。AppleからはReALM発表、どうもSiriの代わりにiPhoneでも動く軽量なモデル、そういえばSiriの人員が解雇されたというニュースもあった。スタンフォードやCMUの一流大学でもCSの修士の就職率が２割とのこと、まあ10年でCS修士取得者が10倍になったという要因もあるようだが、LLMをコンパイラとして使うっていう時代、普通のCS修士程度ではもやは、お呼びではないということか。OpenAIは、日本にアジア初の拠点を開設、なぜか住所は西新橋の雑居ビル。Gemmaの1.1のリリースとかQwen1.5-32B のリリースなど、重要な改良リリースも進む。RAGではReranker が話題に、類似度の高いチャンクを選択したはずなのに、そのあとにRerankするのか。。対応するLLMもいくつか出てる。日本語モデルでは、Swallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルという話もあったが、Mistral 7Bベースの２つの日本語LLMをChat Vector法で強化したものをMoEした、とても長い名前のモデルが話題に、寿限無か。大規模言語モデル開発のための日本語 Instruction データセット作成とか、NLP2024のチュートリアルから、作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコードの公開とか、日本のLLM層の底上げも進む。 アマゾンのBezos氏も投資していると話題となったPerplexity、AI検索が次のビッグウエーブということらしい、GoogleのAI検索も確かにPerplexity風になっているし、GoogleのAI検索は有料化という報道も。もともとBingってPerplexityのような仕組みじゃなかったか。Mixture-of-Depthsとか、ファインチューニングのReFTとか、GRIFFIN とか、新しいLLM最適化の知見が次々にでてきたが、なんといっても、今週はChat VectorというLLMの足し算引き算ができる技術、word2vecのようなベクトル計算がLLMでもできるなんてすごすぎる。Chat Vectorで強化してMoEで、、みたいなのが主流になるかも。Claude3でfunction callingがサポート、さっそくlangchainから、Claude3をつかったエージェント実装が出た、まあ能力からしてそうなるわな。BAAIのMetaWorm論文、線虫を研究して、身体性の謎を解決？Reranker でもBAAI出てきたし、もう中国も、力任せで優れたLLMを出すだけではなく、理論でも、ということか。三値のBitNetの情処の解説、「精度の逆転」というのがあるのか、もし本当ならば、たしかにこれはゲームチェンジャーだな。


- ビジネスの実務で「因果」を推測するということ by TJOさん
	- https://tjo.hatenablog.com/entry/2024/02/28/174811
	- 「とりあえずマーケットの中にふんわりと存在する」系の指標に対して、そのようなきちんとした因果推論を行うのは結構難しい印象があります。
	- 一つの考え方として「時系列的な因果性」をふわっとした代用品として用いるという方法もあり得ると思っています。そう、VARモデルです
	- 即ち実際の因果は「落雷→雷鳴」だが、時系列的には「（落雷→）稲光→雷鳴」が成立するので代用品になり得る、という
- 翻訳モデルHonyaku-7b by AIXサトシ
	- aixsatoshi/Honyaku-Multi-Translator-Swallow-ms7b
	- 数百〜数千tokenの文章翻訳 
	- 英日、日英翻訳機能がメイン
	- XML like instruction
	- 一部の多言語も対応
	- Swallow-ms-7b baseで日本語堪能
- 大規模言語モデル開発のための日本語 Instruction データセット作成の取り組み
	- https://speakerdeck.com/kunishou/da-gui-mo-yan-yu-moderukai-fa-notamenori-ben-yu-instruction-detasetutozuo-cheng-noqu-rizu-mi
- 【OpenAI】日本にアジア初の拠点を開設、法人向けサービス提供へ
	- https://www.nikkei.com/article/DGXZQOUC29A7U0Z20C24A3000000/?n_cid=SNSTW001&n_tw=1711923970
	- OpenAIが4月中に東京都内にアジア初の拠点を立ち上げ、日本での事業活動を本格化させる
	- 事務所は西新橋の雑居ビル？？
-  Mechanistic Design and Scaling of Hybrid Architectures
	- https://arxiv.org/abs/2403.17844
	- LLMのモデル設計は時間とコストがかかる。これを解決するため人工的なベンチマークタスク MAD（in-context recall, compression等）を設計。小規模MADで評価した結果を元に有望な手法を絞りスケールさせる。多くが小規模MADの性能とスケール後の性能に相関がみられた
- LLMの現在
	- https://speakerdeck.com/pfn/llmnoxian-zai
-  MetaWorm: A Complete Model Bridging Brain, Body and Environment of  _C. elegans_
	- https://www.biorxiv.org/content/10.1101/2024.02.22.581686v1
	- BAAIの研究、生物の脳、身体、環境の間の複雑な相互作用を線虫（C. elegan）を材料に解析
- 「Babylon.js 7.0」正式リリース。
	- https://www.publickey1.jp/blog/24/web3dbabylonjs_70mmdmikumikudanceapple_vision_pro.html
	- マイクロソフトは、Webブラウザ上で2Dや3Dモデルの高速なレンダリングなどを可能にするオープンソースのJavaScriptライブラリ「Babylon.js」の最新版「Babylon.js 7.0」正式版をリリースしました。
	- MMD（MikuMikuDance）のインポートと利用を可能にするMMDローダーとランタイムが追加されました。IKソルバ、オーディオ同期再生、プレイヤーコントロールなどの機能も用意されています。
- CMUもStanfordもColumbiaもCS修士のインターン内定率2割
	- https://x.com/fzw1212/status/1774218929100988506
-  LLaMA Now Goes Faster on CPUs
	- https://justine.lol/matmul/
	- 84 new matrix multiplication kernels for llamafile
	- between 30% and 500% faster when using F16 and Q8_0 weights on CPU. 
- Gecko: Versatile Text Embeddings Distilled from Large Language Models
	- https://huggingface.co/papers/2403.20327
	- Googleから、Gecko組み込みモデル、LLMを蒸留した？？謎
	- LLMを使って学習用のペアデータを作ってEmbedding Modelの学習をした後、このモデルに寄り得られた関連パッセージに同じLLMでPositive/Hard Negativeのラベルを振り直して追加学習しているらしい。
- LMFlowでLlama2-70BのLISAファインチューニングがあっさり動いた by shi3zさん
	- https://x.com/shi3z/status/1774710763007119735
	- 大体30GBあれば学習できるとすればA6000でも可能ということか?
-  Google Colab で BAAI/bge-reranker-v2-m3 を試す by npakaさん
	- https://note.com/npaka/n/n7d251f76ce25?sub_rt=share_h
	- 「BAAI/bge-reranker-v2-m3」は、「bge-m3」ベースの「Reranker」モデルです。「Reranker」モデルは、従来の「埋め込み」モデルとは異なり、質問とドキュメントを入力として受け取り、類似度を出力します。
	- 「パンダとは？」の質問には「パンダは中国南西部の山岳地帯に生息する哺乳類の一種です。」のドキュメントが関連していることがわかります。
- Building a RAG application using open-source models by langchain
	- https://x.com/LangChainAI/status/1774821270900629950
	- https://github.com/svpino/llm/blob/main/local.ipynb
	- https://www.youtube.com/watch?v=HRvyei7vFSM
- Claudeだと本当に一瞬で以下のようなアーキテクチャ図を作ってくれる。
	- https://x.com/ai_syacho/status/1774677348807483788
- Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians
	- https://github.com/city-super/Octree-GS
	- https://x.com/janusch_patas/status/1774717184238883237
- 『Google検索を超える衝撃の生成AI型新検索エンジン：Perplexity Proが情報収集を変える！』
	- https://x.com/tetumemo/status/1774632484648730889
	- Perplexity のようなAI検索が、つぎのビッグウエーブというか、active personal noteだよな。AI検索を有料にするという動きもある。
- BItNet-Transformerの学習済みモデルが公開されている
	- 1bitLLM/bitnet_b1_58-large
- NLP2024 チュートリアル３: 作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコード
	- https://github.com/hiroshi-matsuda-rit/NLP2024-tutorial-3
	- 日本語LLMの学習・評価に用いられる技術とデータセットについて広く取り上げています。是非ご覧ください。
	- 講演スライドと実験環境構築手順・ソースコードはGitHubリポジトリで公開しています
	- リクルートの松田寛さん
- 東工大のSwallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルだろうね…
	- https://x.com/Meteor_Eternal/status/1775096408435216766
- OSS Models + LangGraph.js
	- LangGraph helps you create LLM apps that closely match the logical flows used to solve a problem.
	- https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_mistral.ipynb
-  Mamba Explained
	- https://thegradient.pub/mamba-explained/
	- Mambaの選択機構を注意機構との比較やアナロジーを用いながら直感的に説明した記事。 
	- 文脈内学習ではTransformerのようにプロンプトに全ての情報を入れる必要がなく、状態（システムプロンプトなどを圧縮したもの）と質問を渡すだけで良い。
- Bigger is not Always Better: Scaling Properties of Latent Diffusion Models by Google
	- https://huggingface.co/papers/2404.01367
- Prompt-prompted Mixture of Experts for Efficient LLM Generation
	- https://arxiv.org/abs/2404.01365
	- LLM への入力ごとに、LLMの各レイヤーでのアクティベーションの相対的な大きさが、トークン位置によらず一部の次元に偏る flocking という現象を発見し、これをもとに、
	-  (1) prompt 入力次点でアクティベーションが相対的に大きい次元を特定
	-  (2) その次元のみを使って近似的/効率的に Decode を行う、
	- GRIFFIN (Gating by Repetition In Feedf orward Intermediate Neurons) を提案。 タスクに依存するが、学習不要な方法で精度をあまり落とさず生成を高速化できる。
-  Are large language models superhuman chemists?
	- https://arxiv.org/abs/2404.01475
	- 「化学分野の幅広い 7,000 以上の質問と回答のペアを厳選し、主要なLLM を評価しました。その結果、私たちの研究では、最良のモデルが平均して最良の人間の化学者を上回るパフォーマンスを示した」
-  LlamaIndex の Reranker を試す by npakaさん
	- https://note.com/npaka/n/n8f9ee8533896?sub_rt=share_h
	- RAGにおける「Reranker」は、取得したチャンクの中から、質問に対して最も関連性の高い情報を持つチャンクを選択する役割を担っています。
	- 今回は、多言語のRerankerモデル「**BAAI/bge-reranker-v2-m3**」を使います。top_n=5で関連性の高い5件に絞ります。
-  Semantic Routerを試す
	- https://zenn.dev/kun432/scraps/73b098e774bd21
	- LLMやエージェントの意思決定のルーティングを行うSemantic Routerを試してみた。ルーティングだけじゃなく、セマンティックなチャンク分割にも使える。 ベクトル検索の使い方はいろいろな可能性がありそう。
	- クエリで処理を分岐させたいようなケースは、Function Callingを使ってLLMにルーティングさせるとかがあると思うのだけど、事前にクエリのサンプルを用意しておいてベクトル検索でルーティングさせるというようなもの。
	- LangChainのエージェントと組み合わせた例。
- 4/23(火)に、Sakana AI初のイベントやります！Grow-AI、Arayaの方々と我々のトークがあります
	- https://x.com/iwiwi/status/1775367258040410519
- 2x7Bの日本語チャット・ノベル専用高性能モデル。
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Antler-7Bとchatntq-ja-7b-v1.0という、Japanese Stable LM Base Gamma 7B（Mistral 7Bベース）をinstructionチューニングしたモデルを各々ChatVector法で強化し、MoEでマージしたのだそうだ
- RankZephyr is a nice 7B model 
	- https://arxiv.org/pdf/2312.02724.pdf
	- that is optimized for list-wise zero-shot reranking
	- https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/rankLLM/?h=rankllm
- intelligent notetaking by https://iki.ai/
	- https://iki.ai/
	- a cool example of an AI-enabled notetaking interface that epitomizes the core value prop of RAG - dump in a ton of your messy, unstructured data (files, links, notes), and have the application organize and surface information for you instead of you having to do it yourself.
-  Google Colab で japanese-reranker-cross-encoder-large-v1 を試す by npakaさん
	- https://note.com/npaka/n/n906b23636ac8?sub_rt=share_h
	- 「 japanese-reranker-cross-encoder-large-v1」は、日本語に特化した形で学習した「Reranker」です。xsmallからlargeまで複数のサイズが提供されており、「large」は多言語Rerankerで最も人気のある「bge-reranker-v2-m3」をベンチマークで上回っています。
	- クエリと文章の準備と、スコアの計算。
- Anthropic Messages API
	- https://x.com/AnthropicAI/status/1775979799644934281
	-  Claude3にfunction callが来たという話
- Cohereのパラメータ公開LLMのCommand R+
	- https://x.com/_kaiinui/status/1775920565720949090
	- たしかにGPT4-Turboと比較してもよいレベルのLLMに見える
	- サイズは104B、CC-BY-NCだがパラメータはHFで公開 104B動かせるマシンがあれば、だれでも知能(らしきもの)を保有できるってやばいな
- Command R+ by Cohere
	- https://txt.cohere.com/command-r-plus-microsoft-azure/
	- https://huggingface.co/spaces/CohereForAI/c4ai-command-r-plus
	- だだものではない。
-  LlamaIndex <> MistralAI Cookbooks
	- https://github.com/mistralai/cookbook/tree/main/third_party/LlamaIndex
	- Here’s a definitive set of cookbooks to build simple-to-advanced RAG, agentic RAG, and agents in general with MistralAI
- Groq tool calling + structured output by langchain
	- https://python.langchain.com/docs/modules/model_io/chat/structured_output/#groq
	- GroqInc just dropped tool calling!
	- We've added LangChain support (including the popular `withStructuredOutput` method!) so you can try it in your favorite chains and apps.
	- It supports MistralAI, Mixtral, Llama 70B, and Google Gemma.
-  Chat Vectorを使って日本語LLMをチャットモデルに改造する
	- https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4
	- Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages
	- LLMの学習済み重みパラメータの足し引きによって、事前学習済みモデルに対話能力を与えることができるという結果が示されています。
	- 具体的には、英語で事前学習されたモデル（以下ではベースモデルと呼びます）と、ベースモデルを指示チューニング (instruction tuning)してチャット形式の対話ができるようにしたモデル（英語チャットモデル）、ベースモデルを英語以外の言語で継続事前学習したモデルの３つのモデルを用います。
	- 英語チャットモデルの重みからベースモデルの重みを引いたものは、チャット形式で対話ができる能力を表したベクトルであり、そのベクトルを他言語の継続事前学習モデルの重みに加えることで他言語のモデルにチャット形式の対話能力を付与できるという
- Microsoft Encarta '97 (including MindMaze) has been open-sourced on
	- https://ia902707.us.archive.org/view_archive.php?archive=/2/items/enc-97-enc/ENC97ENC.iso
-  JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars
	- https://research.myshell.ai/jetmoe
	- JetMoE-8B is trained with less than $ 0.1 million cost but outperforms LLaMA2-7B from Meta AI, who has multi-billion-dollar training resources. LLM training can be much cheaper than people generally thought.
-  ReALM: Reference Resolution As Language Modeling
	- https://arxiv.org/abs/2403.20329
	- Apple's 3B LLM(ReALM ) Outperforms GPT-4
	- ReALM significantly improves how conversational assistants like Siri or Alexa can understand the way humans naturally talk. Imagine you're looking at a list of restaurants on your smartphone and you say "direct me to the one on Main Street" -
	-  ReALM is able to understand which restaurant you're referring to, even though you didn't specify the exact name.
-  Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models
	- https://huggingface.co/papers/2404.02575
	- This paper presents Think-and-Execute, a novel framework that decomposes the reasoning process of language models into two steps.
	- (1) In Think, we discover a task-level logic that is shared across all instances for solving a given task and then express the logic with pseudocode; 
	- (2) In Execute, we further tailor the generated pseudocode to each instance and simulate the execution of the code.
- Mixture-of-Depths: Dynamically allocating compute in transformer-based language models
	- https://arxiv.org/abs/2404.02258
	- Dynamically allocating compute in transformer-based language models
	- Same performance w/ a fraction of the FLOPs per forward pass
-  1bit LLM の時代は来るのか，来ないのか，どっちなんだい？
	- https://note.com/ipsj/n/ncbe5746f71fb
	- 三値のBitNetについて、情報処理学会の会誌に解説を書かせていただきました
	- 「モデルを大きくすると精度の逆転現象が起こるのだとすると，量子化というのはこれまで想定されていたよりもかなり優れたアイディアなのではないか？」
	- b1.58論文の中身について解説してきましたが，いかがでしたでしょうか．個人的には，この論文には賛否両論があると考えています．
	- 肯定的な見地からは，精度の逆転現象が本当ならば大きな発見であり，自然言語処理分野への大きな貢献となり得る
- Cohere's latest LLM, Command R+ がAzureにのる by Nadera
	- https://x.com/satyanadella/status/1775988939079450886
- Anthropic Tool Calling by langchain
	- https://python.langchain.com/docs/integrations/chat/anthropic/#beta-tool-calling
- Command R+オープン系としては洒落にならんほど知性を感じる
	- https://x.com/_kaiinui/status/1775928745775534189
-  OpenAI の ファイチューニングAPI の新機能 by npakaさん
	- https://note.com/npaka/n/ne41cba4111a0?sub_rt=share_h
	- 2024年4月4日、ファインチューニングAPIに新機能が導入されました。
	- OpenAIを利用すると、ほとんどの組織はセルフサービスのファインチューニングAPI を使用して、有意義な結果をすぐに確認できます。
- Appleが開発、スマホのスクリーンを理解してユーザーと対話できる『ReALM』端末上で動く軽量モデル
	- https://ai-data-base.com/archives/66828
	- Appleは、ユーザーとの対話やスマホ画面を高度に理解する言語モデル『ReALM』を発表しています。Siriなどのアシスタントを進化させる技術としての位置付けです
- Command Rはローカル実行ては初めて文章クリーニングできたかもしれん
	- https://x.com/Meteor_Eternal/status/1775877913952518608
- Claude Function Calling Agent by langchain
	- https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/agent/anthropic_agent.ipynb
- Generating text with 4-bit 104B ⌘R+ in MLX on an M2 Ultra. Runs pretty well:
	- https://x.com/awnihannun/status/1776081238467768493
- Command R の 概要 by npakaさん
	- https://note.com/npaka/n/naa6add7a892f?sub_rt=share_h
	- 「Command R」は、「RAG」や「Tool」などの長いコンテキストタスク向けに最適化されたLLMです。CohereのEmbeddingおよびRerankと連携して動作するように設計されており、RAGアプリケーションに最高クラスの統合を提供し、エンタープライズユース ケースで優れています。
	- ・RAGとToolの使用に関する高い精度
	- ・低遅延、高スループット
	- ・128Kコンテキスト長、価格が安い
	- ・10の主要言語に対応 (日本語含む)
	- ・研究・評価のためにHuggingFaceでウェイトを公開
	- https://huggingface.co/CohereForAI
- Mistral 7Bベースの日本語チャットモデル ChatNTQ-JA-7B を試す
	- https://sc-bakushu.hatenablog.com/entry/2024/04/04/091521
	- 「chatntq_chatvector-MoE-Antler_chatvector-2x7Bchatntq_chatvector-MoE-Antler_chatvector-2x7B」という呪文のような日本語MoEモデル
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Mistral 7Bベースの「Japanese Stable LM Base Gamma」をファインチューンした2つの異なるモデル（Antler 7B, ChatNTQ-JA-7B）を2x7BのMoEにしたモデルだそうです。
	- このMoEモデルを早速試してみたところ、確かに賢そうな印象を受けました。ただ、そもそもベースにされている2つのモデルを聞いたことがありませんでした。
- pfnet/nekomata-14b-pfn-qfin
	- https://huggingface.co/pfnet/nekomata-14b-pfn-qfin
	- rinna社のnekomata-14bを金融向けにチューニングしたLLMを公開しました！ これは、まだまだ金融分野へのLLM応用につながる第一歩でしかないと思うので、もっと研究開発を進めていきたいと思います。
- Qwen1.5-32B release
	- https://github.com/QwenLM/Qwen1.5
	- Qwen1.5 72B has been the best open model on Chatbot Arena leaderboard. Very excited to see how the 32B performs!
- ジェフ・ベゾスがPerplexityに投資
	- https://x.com/npaka123/status/1776352622704042408
- llama.cpp量子化：重要度行列(Importance Matrix)計算に使うテキストについて
	- https://sc-bakushu.hatenablog.com/entry/2024/03/30/195557
	- 現在のllama.cppでは重要度行列(Importance Matrix)計算を利用することで[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)精度が改善できます。
	- 特に4bit以下の低bit[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)を行う場合は、このiMatrix版の[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)が推奨されます
- Apple MLX: Qwen-32B is out and now converted for MLX in 4 and 8 bits flavors.
	- https://x.com/ivanfioravanti/status/1776327090452738315
- ReFT: Representation Finetuning for Language Model
	- https://arxiv.org/abs/2404.03592
	- LoRAのようにweightに介入する fine tuning ではなく、潜在（中間）表現に介入する fine tuning である、ReFT (Representation Finetuning) というフレームワークとその一つの実現例である Low-rank Linear Subspace ReFT (LoReFT) の提案。
- google/gemma-1.1-7b-it
	- https://huggingface.co/google/gemma-1.1-7b-it
	- This is Gemma 1.1 7B (IT), an update over the original instruction-tuned Gemma release.
- HachiML/Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vectorの理論で作ったMath強化モデル、HuggingFaceに置きました
- 

.



## 4/1

今週は年度末、日本企業のLLMが年度末工事よろしく次々発表。先週取りこぼした、RakuteのMistral AIベースのRakutenAI 7B等に加え、今週はNTTが開発した「tsuzumi」は日本語と英語に対応する70億パラメータのLLM。LLMの日本語処理能力を評価するベンチマーク「Rakuda Benchmark」において、GPT-3.5やその他の国産LLMを上回る性能で、図表や画像の解析にも対応とのこと、NTT comが生成AIサービスを展開ということなので、生成AIのビジネス応用元年になるのか。Databricksから公開された「DBRX」は、132億パラメータを持つ大規模なMoE(Mixture of Experts)モデルで、既存のオープンソースモデルを上回る性能を発揮。LLaMA2-70Bよりも高速な推論が可能で、Grok-1よりもコンパクトなモデルサイズながら高い性能を実現。NTTのtsuzumiの資料によると、AWSで7Bモデルを300Bトークン学習させると1900万円かかとのことであるが、そもそもLLMのスケール測からすると、投資に対するリターン（精度向上）が見合わなくなるともっぱら話題に。とはいえ、OpenAIとMicrosoftが最大1000億ドルを投じて「Stargate」というスーパーコンピューターを2028年までにつくるとか、パワープレイは続く。一方、推論の効率化では、Intel Neural Compressorは4ビット量子化技術で、LLMの高速推論と効率的な計算資源利用が可能に。LoRAに代わる「LISA」が出てきた。LISAはメモリ使用量を大幅に削減しながら、従来手法と同等以上のパフォーマンスを実現できる。OpenAIが「Voice Engine」を限定ユーザーに発表、安全性と性能を鑑みると、オープンソースでLLMというのも、限定されてくるのかもしれない。個別の話題では、Googleの「CRAG(Corrective Retrieval Augmented Generation)」、従来の検索拡張生成(RAG)手法を改良し、RAGシステムで取得したドキュメントをLLMに渡す前に、そのドキュメントの内容が正しいかどうかを自動でチェックする機能つけることでハルシネーションを抑制。BGE-M3というEmbedding用モデルが、検索タスクの評価はmE5よりかなり良い数値とか、日本語RAGに使えるとか、中華LLMは日本語が得意。Mambaを採用したLLMで初めての大きなモデルであるJamba、評価が待たれる。SD3の論文では、拡散モデルから Flow ベースモデル へということだが、Reflective Flowというノイズとデータのつなぎ方の話が興味深い。なおBenjio先生のGenerative Flow Networkとは別物らしい。行政系で華々しく登場した行政手続きＱ＆ＡサービスであるGovBot、使い物にならないという評価が次々に、人の死体をゴミと認識？、どうも担当者が正しくAIを理解してないという悲しい事情も、ひろみちゅ先生により明らかに。8,525万でデジ庁からNECが受注したんだよね、ここまでハリボテとは。

- RAGの新しい手法「CRAG」を3分で理解する
	- https://zenn.dev/knowledgesense/articles/bb5e15abb3c547
	- 「Corrective Retrieval Augmented Generation (CRAG)」
	- RAGの性能を高めるための新しい手法です。Googleなどの研究者によって2024年2月に提案されました。CRAG（日本語にすると「修正型検索拡張生成」）という手法を使うメリットは、ハルシネーション（幻覚）を減らせることです。CRAGが従来の「RAG」よりもハルシネーションを減らせる理由は、RAGシステムで取得してきたドキュメントをLLMに渡す前に、「そのドキュメントの内容が正しいものなのか」自動でチェックするという機能を取り入れているからです。
-  AIセーフティ技術学会
	- https://tais2024.cc/ja-jp/
	- AI Safety，AI Alignment，特異学習理論，自由エネルギー原理，AIの自律性（エージェント性）等々のトークとポスター発表．ほとんど自分が聞きたいテーマだけで構成された魅力的な国際学会
- 日本語版：AIOS LLM Agent Operating System
	- https://hamaruki.com/japanese-version-aios-llm-agent-operating-system/
	- この論文では、LLMをオペレーティングシステム(OS)に組み込んだ「LLMエージェントオペレーティングシステム(AIOS)」を提案しています。 AISOは、エージェントのリソース割り当て最適化、コンテキストスイッチ、並列実行、ツールサービス提供、アクセス制御などの機能を持っています。
-  RAFT: Adapting Language Model to Domain Specific RAG
	- https://arxiv.org/abs/2403.10131
	- RAFT offers a method to fine-tune pre-trained LLMs for specific domain RAG settings.
	- Conventional RAG is like an open-book exam, retrieving documents from an index to provide context for answering queries. This makes it more effective than the closed-book exam setting where LLMs rely solely on their pre-training and fine-tuning to respond to prompts, but doesn't allow the LLM to learn the domain beforehand.
- NatCom誌【ビールの風味とおいしさ（飲んだ人の評価）を決定する物質を250のビールに対する18万のレビューから機械学習で解明。
	- https://www.nature.com/articles/s41467-024-46346-0
	- 複雑な心理現象について、大規模データと機械学習を用いて仮説フリーで当たりをつけ、それを「仮説」として実験室で検証実験を行う。うらやましいほどお手本のような現代的研究。ビールを対象としているところも粋でオモロいし！
- NTTのTsuzumi、7Bパラのマルチモーダルで、RakudaベンチマークでGPT-3.5を上回るんだと。
	- https://x.com/umiyuki_ai/status/1772588308537000101?s=20
- OpenAIが「VOICE ENGINE」の名前で商標を出願
	- https://x.com/ctgptlb/status/1771005259948986562?s=20
-  RakutenAI-7B: Extending Large Language Models for Japanese
	- https://huggingface.co/papers/2403.15484
- MSのエンジニアがGPT-6クラスタの構築に取り組んでる
	- https://x.com/_kaiinui/status/1772455514489672080?s=20
	- H100を10万台以上配備しているらしく、電力的に一つのDCに収まらなくなってきている (※10万台 = 70メガワット)
- The Unreasonable Ineffectiveness of the Deeper Layers
	- https://huggingface.co/papers/2403.17887
	- We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction
	- 岡野原さん、学習済みのLLMから、層毎に入力と出力間のcos類似度が大きい層（変化が少ない層）を間引いても精度は落ちない。特に最後の層だけ除いて深い側の層を2~4割間引いても質問応答などの精度は変わらず、知識の大部分が低い層にあることを示唆する。学習手法やモデル設計の参考にも
	- まあ有名な映画、小説の題名のもじり
- DeepLearningAIから、新しいRAGのコースが
	- https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/
	- JavaScript RAG Web Apps with LlamaIndex,
- LoRaより優れたLISA
	- https://x.com/Rui45898440/status/1772996453557997924?s=20
	- Excited to share LISA, which enables
	- 7B tuning on a 24GB GPU 
	- 70B tuning on 4x80GB GPUs
- Databricks introduces DBRX, a new 132B parameter open LLM
	- https://huggingface.co/databricks/dbrx-base
	- fine-grained mixture-of-experts (MoE) with 132B of which 36B active 
	- a larger number of smaller experts. DBRX has 16 experts and chooses 4 
	- It was pre-trained on 12T tokens of text and code data
	- DBRX outperforms all the established open-source models on common benchmarks like MMLU and GSM8K.
	- Its inference is up to 2x faster than LLaMA2-70B and is about 40% of the size of Grok-1 in terms of both total and active parameter counts.
	- While DBRX is trained as a general-purpose LLM, it still surpasses CodeLLaMa-70 Instruct, a model built explicitly for code generation.
- DBRX is super cool, but research and reading too! Especially if you can combine RAG + COT.
	- https://x.com/_philschmid/status/1773024623589736949?s=20
- we're connecting Adobe Experience Cloud with Microsoft Copilot to reimagine how marketers approach their daily work
	- https://x.com/satyanadella/status/1773063169138671984?s=20
-  LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning
	- https://arxiv.org/abs/2403.17919
	- LISA algorithm in two lines: 
		- always activate embedding and linear head layer 
		- randomly sample intermediate layers to unfreeze
	- 岡野原さん、LISAはLLMのファインチューニングの際に、各層を確率的にサンプリングし、選択された層のみ更新する。全パラメータ更新しながらLoRAよりもメモリ使用量、計算量とも効率的に計算できる（通常学習でもできそう）。最初の層と最後の層のみ採択する確率は高くしておく
- DBRXまとめ
	- https://x.com/webbigdata/status/1772981844839207206?s=20
	- ・Databricks社が新たに公開したオープンなMoEモデル 
	- ・自社調べでGPT-3.5 を上回り、Gemini 1.0 Pro と競合 
	- ・コード能力で特化モデルCodeLLaMA-70Bを上回る 
	- ・推論は LLaMA2-70B よりも最大 2 倍高速 
	- ・16人のエキスパートの中で4 人を選択して推論を実行 
	- ・パラメータ数はGrok-1の約40%だが性能は上回る 
	- ・テキスト データとコード データを合計した12Tトークンで事前トレーニング 
	- ・3072 台の NVIDIA H100を使って約3か月でトレーニング 
	- ・ファイルサイズは 263.07(約4.4 GB x 61safetensors)
- Exploration—not work—could be key to a vibrant local economy
	- https://phys.org/news/2024-03-exploration-key-vibrant-local-economy.html
	- Cities and the surprising finding from mobility data analysis that it's more in how we spend and explore in our free time that drives the economic vibrancy of cities, over where we work and go to school.
- Monitoring AI-Modified Content at Scale:A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews
	- https://arxiv.org/pdf/2403.07183.pdf
-  Intel® Neural Compressor
	- https://github.com/intel/neural-compressor
	- All your need is Intel Neural Compressor (INC) for INT4 LLMs. INC v2.5 released with SOTA INT4 LLM quantization (AutoRound) across platforms incl. Intel Gaudi2, Xeon, and GPU.
	- Models: Llama2, Mistral, Mixtral-MOE, Gemma, Mistral-v0.2, Phi2, Qwen,
- Masked Autoencoders are PDE Learners
	- https://arxiv.org/abs/2403.17728
	- Masked autoencoders can learn useful latent representations for PDEs through self-supervised pretraining on unlabeled spatiotemporal data. This allows them to improve
- 4-bit quantized DBRX runs nicely in MLX on an M2 Ultra
	- https://github.com/ml-explore/mlx-examples/pull/628
- 国・地方共通相談チャットボット「Govbot（ガボット）」があまりにひどいと、、
	- https://x.com/HiromitsuTakagi/status/1772918656210743594?s=20
- Google presents Long-form factuality in large language models
	- https://arxiv.org/abs/2403.18802
	- Proposes that LLM agents can be used as automated evaluators for longform factuality
	- Shows that **LLM agents can achieve superhuman rating performance**
- GovBot担当者はなにも理解してないとの疑惑が、、by ひろみちゅ先生
	- https://x.com/HiromitsuTakagi/status/1773148382820778280?s=20
	- それ、GovBotはAIではないので学習と呼ぶのは異常だし、ここで人間が学習するなんて話をするのは滑稽と言う他ないですね
- DBRXは試せる模様
	- https://huggingface.co/spaces/databricks/dbrx-instruct
	- 「風の谷のナウシカ」は、宮崎駿監督による日本のアニメ映画です。ナウシカは、風の谷の王女であり、森と深い関係性を持っています。森の人は、森に住む原始的な部族のことです。ナウシカは、森とその住人を尊重し、森と共存することを望んでいます。彼女は、森とその住人が持つ力を理解しており、それを使って、風の谷と森の間の紛争を解決しようとします。しかし、森の人は、風の谷や他の王国との関係性について、より懐疑的であり、ナウシカの考えに反対することもあります。
- PFN初のゲーム『Omega Crafter』
	- https://x.com/imos/status/1773254326003139023?s=20
	- ほにゃらら回路で自動化するみたいななんちゃってプログラミングではなく、ちゃんとした構造を持つプログラミングができる珍しい(?)ゲームなので、特にエンジニアの方にはオススメしたいです。是非買ってプレイしてください！
- Scaling Rectified Flow Transformers for High-Resolution Image Synthesis
	- https://speakerdeck.com/shunk031/stable-diffusion-3
	- Stable Diffusion 3 の元論文を読みました！拡散モデルから Flow ベースモデル (Rectified Flow)、UNet から DiT へ切り替え、CLIP x 2 と T5-XXL を使ったてんこ盛りモデルで、生成画像の品質・プロンプトに対する生成画像の忠実性・文字の描画性能が飛躍的に向上しています
-  Perplexityをもとに､複数の大規模言語モデルを切り替えて推論するシステムの簡単なコード実装
	- https://note.com/kan_hatakeyama/n/nb5625d6411a8?sub_rt=share_pw
	- モデルの事前訓練をする余裕がないので、今回は試しに、英語が得意なLLama2-7bと、日本語でファインチューニングしたElyza-7bを統合（merge）したシステムを作ってみようと思います。
	- 英語の質問にはllama、日本語の質問にはelyzaで答えることができればコンセプト実証に成功です。
- Generative Flow Networks by Yoshua Bengio
	- https://mila.quebec/en/article/generative-flow-networks/
	- https://www.youtube.com/watch?v=ggYoJp0b3Oo
-  Introducing Jamba: AI21's Groundbreaking SSM-Transformer Model
	- https://www.ai21.com/blog/announcing-jamba
	- 岡野原さん、JambaはMambaとTransformerをあわせた52B LLM。MoEで有効パラメータは12B、1GPUでコンテキスト長140Kまで扱え、複数GPUでは256Kまで扱える。コンテキストが長くなった時は3倍近いスループット。1/8の割合でTransformerを使う。Mambaを採用したLLMで初めての大きなモデル。
-   LMFlowによる日本語LISAトレーニング　 by shi3zさん
	- https://www.free-ai.ltd/post/lmflow-ja-lisa
	- メモリ消費がLoRAと同等に低く、なおかつパフォーマンスはフルパラメータのファインチューニングに匹敵もしくは上回る効果を持つと言われています。
-  LoRAよりいいらしいLISA by shi3zさん
	- https://note.com/shi3zblog/n/ndf165df51f04?sub_rt=share_pb
	- 学習も速いし推論も速い。  こんないいことずくめのことがあっていいのか。  しかしそんないいことずくめのことが時々起きるのがこの業界の面白いところである。
-  Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning
	- https://arxiv.org/abs/2403.11996
	- 言語モデルによる科学知識抽出の論文
	- 1000件の論文のデータを言語モデルにより抽出し知識グラフに変換、グラフ解析によりバイオ材料とベートーベンの第 9 交響曲の構造的類似点など分野を超えた関係性を明らかにできたそうです。
- Transformerのスケーリング則は線形じゃなくてべき乗則だから、トレーニングの計算量を10倍にしてもLossは12%しか減らない（性能が10倍になるわけじゃない）
	- https://x.com/umiyuki_ai/status/1773917004464103563?s=20
- a small-scale preview of Voice Engine
	- https://x.com/OpenAI/status/1773760852153299024?s=20
- OpenAIとMicrosoftが最大1000億ドルを投じて「Stargate」というスーパーコンピューターを2028年までに建設予定。AI開発加速のため、数100万のAI専用チップを搭載。
	- https://qz.com/microsoft-openai-stargate-supercomputer-1851375309
-  langchainとDatabricksで(私が)学ぶRAG : BGE-M3を使った埋め込み
	- https://qiita.com/isanakamishiro2/items/e4f67586b4cb5f171ea9
	- BAAI(Beijing Academy of Artificial Intelligence)から、BGE-M3というEmbedding用のモデルが公開されました。
	- 日本語RAGにおける新たな埋め込みのスタンダードモデルになるかもしれないなと思い、このモデルを使った検索を試してみました。
	- LangChainには`HuggingFaceBgeEmbeddings`というBAAIのBGE系埋め込みモデルを利用するための専用クラスた用意されており、そちらを利用します。
	- RAGの性能を高める上で埋め込みに関する工夫は重要であり、今後もこういった高性能なモデルが公開されていくと（素人的に使う側にとっては）ありがたいですね。
-  NTTが独自LLMのtsuzumiを提供開始、日本語性能で「GPT-3.5超え」(2024年3月25日)
	- https://xtech.nikkei.com/atcl/nxt/news/24/00458/
	- NTTは2024年3月25日、独自LLM（大規模言語モデル）である「tsuzumi」のサービス提供を始めた
	- tsuzumiは日本語と英語に対応し、パラメーター数は70億とOpenAIの「GPT-3」の1750億と比べて25分の1と軽量だ。LLMの日本語処理性能に関するベンチマークテスト「Rakuda Benchmark」の結果では、GPT-3.5や同規模の国産LLMを上回ったという。tsuzumiは言語に加え、図表や画像の解析などにも対応する。
	- うみゆきさん、LLMの学習コスト感ってよく知らんけど、Tsuzumiの資料によればAWSで7Bモデルを300Bトークン学習させると1900万円かかるらしい。300Bじゃ少ないから1.2Tくらいは学習させたいよね。そしたら7600万円か。
-  NTTが開発したLLM「tsuzumi」、NTT Comより商用生成AIサービスとして提供開始
	- https://internet.watch.impress.co.jp/docs/news/1578961.html
- 楽天が日本語に最適化したMistralベースのLLMを公開、商用目的で使用可能(2023年3月21日)
	- https://xtech.nikkei.com/atcl/nxt/news/24/00440/
	- 公開したのは基盤モデルの「Rakuten AI 7B」、同モデルを基にしたインストラクションチューニング済みモデルの「Rakuten AI 7B Instruct」、Rakuten AI 7B Instructを基にファインチューニングしたチャットモデル「Rakuten AI 7B Chat」の3種である。
	- 文章の要約や質問応答、一般的な文章の理解、対話システムの構築などに商用目的で使用でき、Rakuten AI 7Bは他のモデルの基盤としても使えるという。
	- Rakuten AI 7BはフランスのAI（人工知能）スタートアップMistral AIのオープンモデル「Mistral-7B-v0.1」を基に、継続的に大規模なデータを学習させて開発した日本語基盤モデル。
- govbotをとりあえず試してみたら死んだ人間を『ゴミ』と認識している説が出てきた
	- https://x.com/judo5001/status/1773196373686411292?s=20
- GovBotの開発に8525万かかったと聞いて調べたら本当だった🤯！しかも、調達機関はデジタル庁で開発業者は日本電気
	- https://x.com/gijigae/status/1773557153317437824?s=20

## 3/25

先週xAIより公開されたgrok-1、gpt-3.5を上回るが、Claude 2やGPT-4は下回るという性能らしい。さて生成AIでは出遅れ感もあるApple、geminiをiPhoneに入れるとのうわさが出たり、30BのMM1を論文発表したりと、にわかに活発化。Stability AIのアニメ業界向け生成系AI、ついに現場にAIが入りだすのか。KDDI、ELYZAを連結子会社化ってのも驚いた、「生成AIを活用したDX支援・AI SaaS」ってのが春以降でるらしい。NVIDIA がGTC2024で発表した、ヒューマノイド開発プラットフォーム「GR00T」、 H100の５倍の性能！新GPUであるB200、DGX GB200 NVL72とか、NIMの発表とか、一人勝ちってこういうこと。早速llamaindexがNVIDIA NIMで動くようになった。ひろみちゅ先生、Claude 3を用いた新規提出法案の立法技術上の矛盾点チェック、法制局も真っ青レベルとのこと。DeepMindのTacticAI、「コーナーキックについてアドバイスできる完全なAIシステム」。500程度のサンプルで数分学習させてLLMの出力を方向付ける事が出来る制御ベクトルってのは面白い、キャラ分けなんかが簡単になるのか。「Google Scholar PDF Reader」、こういう応用がどんどん出てほしい。Sakana.aiの進化的計算による基盤モデル構築って、複数のLLMをマージするという新たな方向性を示した。日本語画像言語モデルEvoVLM-JPはすぐに試すことができる。LLMのマージでは、Arcee's MergeKitってのも忘れてはいけない。Embedding の量子化というのがあるのか、高速化の工夫の余地はまだまだある。[huggingface](https://github.com/huggingface)からPEFT 0.10.0のリリース、70B Llama 2モデルを24GBメモリを搭載したGPU2基でQLoRA可能になるとのこと。huggingfaceはTransformers 4.39もリリース、GaLoreをサポートしてるらしい。「GaLore」、「NVIDIA RTX 4090」などの家庭用GPU上で、Llamaなどの最大7Bパラメータを持つモデルの学習を容易にする技術、元論文は2023年の5月にMetaが発表。Artificial muscleというのもすごいな、NVIDIAのロボットに組み込むと、いよいよ人間らしいロボットが実現するのか。Lightblue、国内最高水準の日本語LLMモデル「ao-Karasu」リリース、７２Bだそうだ、もう何が何だか。LINEの「japanese-large-lm-1.7b-instruction-sft」から派生したLLMがたくさんリリース、ローカルAIハッカソンの成果らしい。『微分可能プログラミング』、プログラムのパラメータを微分可能な方法で最適化することにより、機械学習タスクを解決するプログラミングパラダイムなんだけど、”プログラムを微分可能にすることは本質的に確率分布によってその出力の不確実性を定量化すること”とはUQ、Uncertainty Quantification;不確かさの定量化、に通じて面白い

- grok-1まとめ
	- https://x.com/webbigdata/status/1769503166528458822?s=20
	- リリースされたモデルは314Bパラメーター 
	- ファイルサイズでいえば318.24GB 
	- MoE(2/8 experts)でactiveパラメーターだけでも86B 
	- 2023/10月時点で学習を完了していたベースモデルのみ公開 
	- githubのxai-orgで推論コードも公開(JAX) 
	- ダウンロードはacademictorrentsかhuggingfaceのxai-org/grok-1 
	- ライセンスはApache 2.0 ライセンス 
	- 公表済みベンチマークによればgpt-3.5を上回るが、Claude 2やGPT-4は下回る
- Apple in talks with Google for using Gemini to bring generative AI features to iPhones
	- https://www.livemint.com/technology/tech-news/googles-gemini-could-power-generative-ai-features-on-iphone-16-tim-cook-heres-what-we-know-11710739843784.html
- アップル、高度な言語理解を持つ新型AIモデル「MM1」を発表
	- https://ascii.jp/elem/000/004/189/4189761/
	- https://arxiv.org/pdf/2403.09611.pdf
	- 複数（30億、70億、300億）のパラメータサイズを備えるMM1は、10億以上の画像および30兆語以上のテキスト、GitHubのコード例などの多様なデータセットを用い、教師なし学習と教師あり学習を組み合わせる独自の方法で学習され、多様なタスクに対して高い精度を示す
	- MM1はすべてのコンポーネントに関して、そのアーキテクチャーから、データセットの内容、事前学習・ファインチューニングの詳細、モデルサイズに至るまで、詳細な情報（MLLMsの開発レシピ）を公開している。
-  Stability AIとアニメチェーンがアニメ業界向け生成系AIの共同研究を検討開始
	- https://prtimes.jp/main/html/rd/p/000000003.000135092.html
	-  既存のアニメ制作工程をそのままに「協議会」を通じて制作現場の声を伺いながらアニメ作品の品質向上を目標とした支援ツールの共同研究を目指す
-  Fully  Client-Side  Chat Over Documents
	- https://webml-demo.vercel.app/
	- So I revisited WebLLM and was able to add browser-only mode!
- KDDI、東大発AIベンチャー・ELYZAを連結子会社化　春以降、生成AI関連サービスを提供
	- https://www.itmedia.co.jp/news/articles/2403/18/news140.html
	- 生成AIを活用したDX支援・AI SaaS
- NVIDIA GTC2024で次世代のロボティクスはヒューマノイド
	- https://www.youtube.com/watch?v=Y2F8yisiS6E
- NVIDIA、GPUプラットフォーム「Blackwell」発表　「兆パラメータ規模のAIモデル実現」
	- https://www.itmedia.co.jp/news/articles/2403/19/news092.html
	- プラットフォームに搭載する「GB200 Grace Blackwell Superchip」は、新GPU「B200」（2080億個のトランジスタを搭載し、現行の「H100」と比較して、AI向けの作業で5倍の処理能力を発揮するGPU）を2基と1基のGrace CPUを組み合わせたもの。
	- NVIDIAによると、1兆8000億パラメータのAIモデルをトレーニングするには、Hopper GPUでは8000個のGPUで15メガワットの電力が必要だったが、新スーパーチップであれば2000個で可能で、消費電力は4メガワットで済むという。
- DGX GB200 NVL72は、GB200 Superchipを72基NVLinkで接続したクラスタ
	- https://x.com/_ksasaki/status/1769829822946001353?s=20
- 生成AIアプリの展開を数分に、NVIDIAが新マイクロサービス「NIM」を発表
	- https://xtech.nikkei.com/atcl/nxt/news/24/00424/
	- NIMは、生成AIの推論に必要となる各種ソフトウエアがインストール済みのコンテナ（マイクロサービス）を提供する仕組みである。具体的には、エヌビディアが開発した推論ワークフローを最適化するフレームワークである「Triton Inference Server」やツールキット「TensorRT-LLM」などがインストールされ、エヌビディアやパートナー企業が提供する20以上のAIモデルに最適化されている。
-  LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM
	- https://www.llamaindex.ai/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim
	- LlamaIndex  is integrated with NVIDIA NIM inference microservices to help enterprises seamlessly deploy generative AI at scale
- 1x GPU Blackwell - 192GB VRAM 2x GPU 
	- Blackwell with CPU - 384 GB VRAM
	- https://x.com/migtissera/status/1769824889102348366?s=20
-  NVIDIAがヒューマノイド開発プラットフォーム提供を発表　ディズニーの二足歩行ロボットが登壇　Jetson Orinから次世代Thorへ
	- https://robotstart.info/2024/03/19/nvidia-humanoid-jetson-thor.html
	- NVIDIAは「GTC 2024」の創業者/CEOのジェンスン・フアン氏による基調講演で、ヒューマノイドロボット(ヒト型ロボット)を開発するためのプラットフォーム「GR00T」(ジーアールゼロゼロティー)を発表した。NVIDIAは新世代GPUと生成AIを含むヒューマノイド開発用のSDKやライブラリ、プラットフォームを提供し、全面的に支援していく。
- 法制局も真っ青？Claude 3を用いた新規提出法案の立法技術上の矛盾点チェック
	- https://takagi-hiromitsu.jp/diary/20240319.html
	- Claude 3に聞いてみた。微妙にけっこう間違うが、そこはスルーして、大変参考になる。ここまでわずか1時間程度の作業だった
- TacticAI: an AI assistant for football tactics
	- https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/?utm_source=twitter&utm_medium=social&utm_campaign=TacticAI/
	- We're announcing TacticAI: an AI assistant capable of offering insights to football experts on corner kicks.
	- it can help teams sample alternative player setups to evaluate possible outcomes, and achieves state-of-the-art results.
	- TacticAIはGoogleとリヴァプールの複数年にわたる協力関係の一環として開発されたもので、「コーナーキックについてアドバイスできる完全なAIシステム」としてアピールされています
- 500程度のサンプルで数分学習させてLLMの出力を方向付ける事が出来る制御ベクトル(control vectors)用ライブラリ
	- https://github.com/vgel/repeng
	- LoRAのように特定タスクに特化するのではなく例えば 「陽キャなチャットボット」ｖｓ「陰キャなチャットボット」 など、モデルの出力に全体的な方向性を与える感じですね
- Google、PDF論文を劇的に読みやすくするChrome拡張「Google Scholar PDF Reader」
	- https://news.mynavi.jp/techplus/article/20240321-2911097/
- GaLore - 家庭用ハードウェアでの大規模モデルの学習
	- https://note.com/npaka/n/n8e4537502e3e?sub_rt=share_h
	- 「GaLore」は、「NVIDIA RTX 4090」などの家庭用GPU上で、Llamaなどの最大7Bパラメータを持つモデルの学習を容易にします。これは、学習プロセス中のオプティマイザの状態と勾配に従来関連付けられていたメモリ要件を大幅に削減することによって実現されます。
	- 「GaLore」と「8bitオプティマイザ」を組み合わせることで、学習プロセスの整合性とパフォーマンスを維持しながらメモリ効率を最大化する相乗効果が得られます。
- GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection
	- https://arxiv.org/abs/2403.03507v1
- StanfordのFei-Fei Li教授らのチームから、ロボットのシミュレーションのためのベンチマーク「BEHAVIOR-1K」がリリース
	- https://x.com/drfeifei/status/17710132915083798大規模言語モデル「Grok-1」について by 今井
	- https://x.com/ImAI_Eruel/status/1769487625994506294?s=20
- 進化的アルゴリズムによる基盤モデルの構築 by sakana ai
	- Sakana AIの最初の研究成果である、進化的計算による基盤モデル構築に関する論文を公開しました。多様な既存モデルを自動的に融合し優れた基盤モデルを構築するための方法を提案すると共に、それにより試作したモデルを公開しました。
		- **EvoLLM-JP**：数学的推論が可能な日本語の大規模言語モデル（LLM）
		- **EvoVLM-JP**：日本語で対話可能な画像言語モデル（VLM）
		- **EvoSDXL-JP**：高速な日本語画像生成モデル
	- _既存のモデルをマージして新しい基盤モデルを作成する過程の可視化。進化的アプローチは、モデルを組み合わせる際に、人間の直感だけでは見落とされがちな、効果的かつ時に非直感的な方法を自動的に発見することができます_
-  Evolutionary Optimization of Model Merging Recipes
	- Sakana Aiの論文
	- https://arxiv.org/abs/2403.13187
-  WSL2でSakana AIを試してみる
	- https://note.com/ngc_shj/n/na9b41adb9131
	- 「進化的モデルマージにより日本語数学LLMとして構築したEvoLLM-JPは、数学のみならず、日本語の全般的な能力に長けている」らしいEvoLLM-JPを試してみます
	- 10Bのモデルですが、torch_dtypeを"auto"からtorch.bfloat16に変更すると、推論のスピードが改善しました。
- RAG for long context LLMs: Video
	- https://www.youtube.com/watch?v=SsHUNfhF32s
	- https://docs.google.com/presentation/d/1mJUiPBdtf58NfuSEQ7pVSEQ2Oqmek7F1i4gBwR6JDss/edit#slide=id.g26c0cb8dc66_0_0
- NVIDIAのフリーオンラインAIコース
	- https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/
- Claude 3 Opusより60倍安いHaikuをOpusの品質で運用する方法。
	- https://github.com/mshumer/gpt-prompt-engineer
	- gpt-prompt-engineerを使えば、プロンプトエンジニアリングの実験を自動化できる。自動で複数プロンプトを生成して、LLM別に評価も可能。
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
	- 25x speedup in retrieval; 32x reduction in memory usage; 4x reduction in disk space; 99.3% preservation of performance
- LLM4Decompile: Decompiling Binary Code with Large Language Models
	- https://arxiv.org/abs/2403.05286v1
	- バイナリからリバースエンジニアリングできると
- Suno AI unveiled V3
	- https://x.com/heyBarsee/status/1771190753957470604?s=20
- Doing In-Context Learning Without Leaking Private Data
	- https://github.com/run-llama/llama_index/tree/main/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease
	- Few-shot demonstrations are crucial to improve the performance of any LLM/RAG app. But the issue with very private datasets (e.g. patient clinical reports), is that they can easily be leaked/jailbroken by malicious users.
- 内閣府「AI時代の知的財産権検討会（第６回）」の資料が公開
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/gijisidai/dai6/index.html
-  GitHub、脆弱性のあるコードの自動修正機能発表。AIボットが修正済みコードと解説をプルリクエスト
	- https://www.publickey1.jp/blog/24/githubai.html
	- GitHubは、脆弱性のあるコードをAIボットが自動的に発見、修正したコードとその解説をプルリクエストしてくれる「code scanning autofix」（コードスキャン自動修正機能）を発表しました
- 音声基盤モデルKotoba-Speech v0.1の学習・推論コードをリリースしました！
	- https://x.com/kotoba_tech/status/1771165553882964291?s=20
	- https://github.com/kotoba-tech/kotoba-speech-release
	- End-to-EndのTransformerアプローチで、カスタマイズも簡単です。例として、関西弁モデルも公開しました。既存のText-to-Speechよりも、さらに自然で流暢であることが実感できるかと思います！
- The AI Mirror Test
	- https://x.com/joshwhiton/status/1770870738863415500?s=20
	- The "mirror test" is a classic test used to gauge whether animals are self-aware. I devised a version of it to test for self-awareness in multimodal AI. 4 of 5 AI that I tested passed, exhibiting apparent self-awareness as the test unfolded.
	- Claude Opus passed the mirror test immediately. Like the other AI, it hardly identifies with its brand-name (Claude) and distinguishes itself from the interface’s stock elements. However it does identify with the prompt, which it knows is
- PEFT 0.10.0 is out
	- https://github.com/huggingface/peft/releases/tag/v0.10.0
	- Fine-tune larger QLoRA models with DeepSpeed and FSDP, layer replication, enhance DoRA
	- This allows you to fine-tune a 70B Llama model on two GPUs with 24GB memory each.
	- 以前、ツイートした70B Llama 2モデルを24GBメモリを搭載したGPU2基でQLoRA可能になるお話が正式採用
	- 加えて、DoRA(工夫したLoRA。ただしトレーニング時間は増える)が量子化済のモデルに対しても使えるようになって使いやすくなった模様
	- LoftQ(量子化誤差を最小化するようにLoRAを初期化してトレーニングできるようにする)もより使いやすくなったとの事
- OpenAI Voice Engine. This is big
	- https://x.com/SmokeAwayyy/status/1771052612051468668?s=20
	- VOICE ENGINE™ trademark registration is intended to cover: - voice and speech recognition, processing voice commands, and converting between text and speech
- Introducing the Chatbot Guardrails Arena
	- https://huggingface.co/blog/arena-lighthouz
	- Our vision behind the Chatbot Guardrails Arena is to establish the trusted benchmark for AI chatbot security, privacy, and guardrails. With a large-scale blind stress test by the community, this arena will offer an unbiased and practical assessment of the reliability of current privacy guardrails.
- 昨日SakanaAILabsからリリースした日本語画像言語モデルEvoVLM-JPは、誰でもすぐにお試しいただけます。
	- https://huggingface.co/spaces/SakanaAI/EvoVLM-JP
- Starling-LM-7B, has now upgraded to Beta
	- https://huggingface.co/Nexusflow/Starling-LM-7B-beta
	- It shows promising potential in our coming next generation benchmark.
	- https://x.com/lmsysorg/status/1771252185205981426?s=20
-  Debates on the nature of artificial general intelligence by nature
	- https://www.science.org/doi/10.1126/science.ado7069
	- "The history of AI has repeatedly disproved our intuitions about intelligence....At each step in the evolution of AI, human-level intelligence turned out to be more complex than researchers expected."
- lightblue/ao-karasu-72B
	- https://huggingface.co/lightblue/ao-karasu-72B
- Artificial muscle has arrived.
	- https://x.com/BrianRoemmele/status/1770959817815019857?s=20
	- 昨年知的業務は終わりだ。人間は筋肉を鍛えるしかない。 とか言ってたけど、人工筋肉出来ちゃったよ
	- https://www.youtube.com/watch?v=guDIwspRGJ8
-  Arcee's MergeKit: A Toolkit for Merging Large Language Models
	- https://huggingface.co/papers/2403.13257
	- Model Merging allows us to blend/stack multiple open LLMs into one—bigger or the same size—without extra training to extend skills and performance!
- データセンター廃熱でプールを加温🏊 環境に優しくコストも節減 英国
	- https://x.com/afpbbcom/status/1770586117449953488?s=20
	- 敷地内に設置された装置がコンピューター群が放出する熱を取り込み、25ｍプールを設定温度まで温める。約65％をカバーしており、ガスボイラーの使用は抑えられている。
- O1 LightはOpen Interpreterを搭載した小型デバイスです
	- https://x.com/tegnike/status/1770851466665750758?s=20
-  WSL2でRakutenAI-7B-chatを試してみる
	- https://note.com/ngc_shj/n/n413ababd3105?sub_rt=share_crp
	- 「Mistral AI社のオープンモデル「Mistral-7B-v0.1」を基に、継続的に大規模なデータを学習させて開発された70億パラメータの日本語基盤モデル」であるRakuten AI 7Bモデル
	- 「インストラクションチューニング済モデルを基にファインチューニングを行ったチャットモデル」であるRakuten AI 7B Chatを試してみます。
- Swallow-MX-8x7b-NVE-chatvector-Mixtral-instructのv2アップロードしました by AI さとし
	- https://huggingface.co/aixsatoshi/Swallow-MX-8x7b-NVE-chatvector-Mixtral-instruct-v2
	- 元モデルとinstructionベクトルのバランス調整で、日本語流暢性改善しています
- Margaret Mitchel
	- This Women's History Month, we celebrate Margaret Mitchell, the Chief AI Ethics Scientist at huggingface, an open source data science and machine learning platform and hub for AI experts. 
- Transformers 4.39 is out,
	- https://github.com/huggingface/transformers/releases/tag/v4.39.0
	- New models: Mamba, Command-R, LLaVA-NeXT, MusicGen Melody, StarCoder2, SegGPT, ...
	- GaLore optimizer for accessible pre-training
	- Quanto integration and Exllama+AWQ
	- MLX support
-  A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
	- https://arxiv.org/abs/2302.13425
	- ついにUQも深層学習の時代か
- Estimating Causal Effects with Double Machine Learning -- A Method Evaluation
	- https://arxiv.org/abs/2403.14385
- Meta introduces SceneScript
	- https://x.com/AiBreakfast/status/1771195019585597836?s=20
	- You will be able to upload your own environment to the metaverse:
- マジか(NLP2024の岡崎先生、Knight先生の発表概要をSwallow-MXを翻訳タスクでQLoRA tuningしたモデルで日英/英日翻訳)
	- https://x.com/hpp_ricecake/status/1771138490589487602?s=20
-  Googleが洪水を1週間前に予測し世界80カ国4億6000万人を水害から救えるAIを発表
	- https://gigazine.net/news/20240322-google-ai-global-flood-forecasting/
	- Google Researchのグレイ・ニアリング氏らの研究チームは、世界各国の流量計5680個が1980～2023年の間に集積したデータを用いてAIモデルをトレーニングしました。
	- 洪水ナウキャストによる洪水の予測を0日前、つまり当日から平均5日前まで延ばし、最大で7日前まで予測することができます。
- 立体言語
	- 永田亮『立体言語』（自然言語処理31巻1号巻頭言）
	- https://www.jstage.jst.go.jp/article/jnlp/31/1/31_1/_pdf/-char/ja
	- 言語の線状性（一つづつ順番に並べる制約）を超える、これまでとは異なった情報伝達の可能性。そして、そこにNLP技術が活かせるのではないかというお話。
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
- Excited for MistralAI+ llama_index collabs (and Colabs)
	- https://x.com/jerryjliu0/status/1771262080944857469?s=20
-  Lightblue、国内最高水準の日本語LLMモデル「ao-Karasu」を公開
	- https://prtimes.jp/main/html/rd/p/000000057.000038247.html
	- 東京大学発、最先端アルゴリズムの現場実装に取り組むAIスタートアップ 株式会社Lightblue（代表取締役：園田亜斗夢、本社：東京都千代田区、以下「Lightblue」）は720億パラメーターの日本語LLMモデル「ao-Karasu」を公開したことをお知らせします。「ao-Karasu」はStability AI社が提供する日本語性能のベンチマーク、Japanese MT-Benchの自動評価で国内最高水準の評価となっています。
- 【Swin Transformer】今こそ押さえたいTransformer系画像認識モデル
	- https://ai-scholar.tech/articles/image-recognition/swin-transformer
	- 近年コンピュータビジョンの研究でベースラインとしてよく用いられているSwin Transformerを解説  
	- すべてのパッチと関連性(Attention)を計算するVision Transformerとは異なり，近傍のパッチをまとめたwindow内でAttentionを計算する  
	- 異なるパッチサイズでAttentionの計算を行うため，様々なスケールの特徴が得られる
-  [進化的アルゴリズムによる基盤モデルの構築](https://sakana.ai/evolutionary-model-merge-jp/)
	- Sakana AIは進化や集合知などの自然界の原理を応用して基盤モデルを開発することを目指しています。私達の目標は、モデルを自ら訓練し開発することだけではありません。基盤モデルの開発を効率化、高度化、自動化するための新たな手法を生み出すことに挑戦しています。この目標に向けた第一歩として、私たちはプレプリント「Evolutionary Optimization of Model Merging Recipes （モデルマージの進化的最適化）」を公開しました。
	- 複数のNNを重み・層レベルでマージする際の最適な組合せをEAで探索する進化的モデルマージを提案。数学と日本語など異なる領域に特化したLLMをうまくマージすることで性能を向上できる。
- team DataPilot2つ目のモデルとして、「ArrowSmartPlus_3.6B_instant_sft_JSHVer」をリリースいたします
	- https://huggingface.co/DataPilot/ArrowSmartPlus_3.6B_instant_sft_JHSVer
	- Line社が開発した「japanese-large-lm-3.6b-instruction-sft」をウィキブックの内容をもとに中学範囲にてファインチューニングを行いました。
- 「LOCAL AI HACKATHON」における、チームDataPilotの成果品第一弾である「ArrowSmart_1.7b_instant_sft」をリリースしました
	- https://huggingface.co/DataPilot/ArrowSmart_1.7b_instant_sft
	- Line社が開発した「japanese-large-lm-1.7b-instruction-sft」をウィキブックの内容をもとに地理、化学の分野でファインチューニングを行いました。
-  The Elements of Differentiable Programming
	- https://arxiv.org/abs/2403.14606
	- 新しいパラダイムである『微分可能プログラミング』の基本概念について Google DeepMind の研究者が383ページに渡るPDFを公開。論文より本という方が正しそう
	- プログラムを微分可能にすることは本質的に確率分布によってその出力の不確実性を定量化すること、とは面白い
	- **微分可能プログラミングとは**: プログラムのパラメータを微分可能な方法で最適化することにより、機械学習タスクを解決するプログラミングパラダイムです
	- **目標と範囲**: 本書は、微分可能プログラミングの基礎を説明し、その理論と実践の両方をカバーすることを目指しています。
- Sakana AIが、モデルマージを自動化・高度化する進化的モデルマージ（Evolutionary Model Merge）
	- https://huggingface.co/SakanaAI

## 3/18

今週もいろいろありすぎて、目が回ります。東工大からSwallow-MS 7BとSwallow-MX 8x7Bのリリース、前者は日本語最高性能とのこと。 量子化版も出て、Llama.cpp でSwallow-MX 8x7Bを動かした例も紹介された。Swallow-MS-7b-v0.1 を ichikara instruction で指示チューニングして、500ステップぐらいでいい感じとの報告も。「ELYZA-japanese-Llama-2-70b」が出たー、NHKでも紹介された、ABCIを12月から部分占有？、ようやくスタートラインというCEOの言葉が刺さる。Shi3zさんによると、Claude-3と比べると百人一首の知識が足りずまだ頑張れという感じだが従来のモデルと比べると格段の進歩があるとのこと。「JPX Market Explorer」、NISAで個別投資を考えているひとは必見。自社ビジネス＝株取引を活発にするための、生成AIの活用として面白い。256k token が扱えるGPT-4.5 Turbo が６月ごろにリリースといううわさが持ち上がる、リークなのか？。一般copilotからもGPT-4 Turboが使えるようになったらしい、OpenAI＋マイクロオフト陣営も遅れるわけには行けない。企業が期待する今風の「主体性」って、思考力と協調・協働できる力という話だけど、この分野、生成AIが苦手とも言えなくなった気がするな。AIによるソフトウエアエンジニアDevin、なんかすごい、駆逐される人たちがたくさんいそうだ。どうもVC界隈では、AI従業員の開発の風が吹いているとのこと。JSTの「自律駆動による研究革新」は研究そのものをAIで自動化という話、ひえ！。Claude 3 Opusを使って世界経済を分析するデモ動画も、エージェント（AI従業員）をつくって調査を加速できるという話。ああ、人はいらなくなるのか？。Claude3の性能評価は続く、ひろみちゅ先生が、様々なな事例を試して絶賛、Coinhive事件最高裁判決の解釈など、使い方の参考にもなる。Claude3 × Googleスプレッドシート、スプレッドシートから普通にClaude3を使える、なんかちがうな。松田先生の考察のように、LLMって十分疎なのではないか、まだまだ量子化とか軽量化の余地がある。世田谷区のAI bot、非エンジニアがノーコードで開発と。NLP2024も開催、岡野原さんの「大規模言語モデル開発の展望と今後の課題」、話題としては本LLMアプデ読者にはなじみの深い話題。AIは科学を促進するが、『理解の錯覚』を生み出す危険性がある、と記事は新しい視点で興味深い。カーツワイルさん、大脳皮質と計算機がつながるのが2030年代初頭といって話題に。OpenAIとロボット開発のFigureの提携の結果の第１段Figure01、いやこれってなんかの映画（パッセンジャー）で見た世界。NatureのAll of usのサマリーデータ、117個の疾患に関連する3724個の変異を同定され、データも公開とのこと。最後に、Xが予告お降り Grok-1のオープンソースリリース。直前に、OpenAIがGrokの別実装をOSSで公開してたりして、こういう競争、いや共創？って面白いな。


- 大規模言語モデルSwallow-MS 7BとSwallow-MX 8x7Bを公開しました
	- https://tokyotech-llm.github.io/swallow-mistral
	- Swallow-MS 7Bはオープンな7BのLLMの中で日本語最高性能を達成しました。
-  Yi: Open Foundation Models by 01.AI
	- https://arxiv.org/abs/2403.04652
	- Super interesting paper - 10k data is all you need for finetuning LLM
	- ファインチューニングには1万件のデータで充分なんだという論文。
- Claude 3に例の「読了目安2時間」記事を解説させてみた - 高木浩光＠自宅の日記（2024年3月11日）
	- https://takagi-hiromitsu.jp/diary/20240311.html
	- ひろみちゅ先生絶賛
	- 「Anthropicの先日出たばかりのClaude 3（Opus）が、ChatGPTのGPT-4を超えてきたと聞いて、自分の原稿を解説させてみたところ、確かに革新的な進歩が見られる。もはや内容…」
-  Is Cosine-Similarity of Embeddings Really About Similarity?
	- https://arxiv.org/abs/2403.05440
	- コサイン類似度を疑っていけ！！
- Swallow-MX-8x7b-NVE-v0.1のggufあります
	- https://huggingface.co/mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
- 人工言語による事前学習を用いた言語間転移可能な知識の分析
	- https://www.jstage.jst.go.jp/article/jnlp/30/2/30_664/_article/-char/ja/
	- Transformerの事前学習に人工言語を使ったらどうなるか、どの要素が事前学習に効くのか、という研究 係り受け関係に入れ子構造が含まれることが重要らしい
- Llama.cpp で Swallow MX 8x7B をお試し中　by npakaさん
	- https://x.com/npaka123/status/1767380241520173408?s=20
- Stealing Part of a Production Language Model
	- https://arxiv.org/abs/2403.06634
	- GPT-4のようなClosedなブラックボックス大規模言語モデルでも,APIアクセスのみでモデルの一部の層のパラメータを特定できるModel-stealing attackを提案
	- GoogleのOpenAIに対する逆襲の一手的な論文
	- API経由でOpenAIのモデルにおける隠れ次元数を特定できることを示し、OpenAIがそれを受け対策を施したことを論文で報告しました。
- 700億パラメータの日本語LLM「ELYZA-japanese-Llama-2-70b」を開発し、デモを公開しました
	- https://note.com/elyza/n/n0ea755ca3e7b
	- https://elyza.ai/lp/elyza-llm-for-jp
	- 日本語特化モデルの中では最大級です.大きさが正義のLLMということで,実際報告されている性能もかなり抜けています
- ELYZA-japanese-Llama-2-70b をお試し中 by npakaさん
	- https://x.com/npaka123/status/1767439590502326514?s=20
	- デフォルトテンプレートの指示も効いてる
-  東大発のスタートアップ企業 “国内最大規模 国産生成AI完成”
	- https://www3.nhk.or.jp/news/html/20240312/k10014388011000.html
	- オープンソースと呼ばれる公開技術をベースに、産業技術総合研究所が運営するデータセンター「ABCI」などを活用し、去年12月から短期間で開発を実現しました。
	- イライザの曽根岡侑也社長は「昨年末時点ではオープンAIやグーグルなどのグローバルモデルと比べて日本のAIモデルは及ばない状態だった。今回ようやくスタートラインに立つことができ、日本が存在感を示せるようにしたい」と話していました。
-  松尾研LLM開発プロジェクトのキックオフを開催しました
	- https://weblab.t.u-tokyo.ac.jp/2024-03-12/
	- 当研究室が提供する講座の修了生および一般公募によって集まった有志の開発者のメンバーが500億パラメータサイズの大規模言語モデル開発を進めるものです。
	- NEDOによる、国内の生成AIの開発力を強化するためのプロジェクト「GENIAC（Generative AI Accelerator Challenge）」において、基盤モデル開発に必要な計算資源の提供支援を受けています。
	- 松尾教授からは「このプロジェクトの中で、試行錯誤しながら重要であるノウハウを共有することで良いモデルを作り、開発経験を積んでもらいたい。また、このプロジェクトを通して、より多くのLLM開発者を生み出し、参加者の皆さんが様々なところで活躍してもらうのが望みだ」とのコメントがありました。
- Elyza70B、Claude-3と比べると百人一首の知識が足りずまだ頑張れという感じだが従来のモデルと比べると格段の進歩がある by shi3zさん
	- https://x.com/shi3z/status/1767464684373082223?s=20
-  G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering
	- https://arxiv.org/abs/2402.07630
- ＪＰＸ総研は、生成AIプロバイダであるBridgewiseの技術を活用し、日本市場にかかる情報を発信する新サービス「JPX Market Explorer」のPoCを開始します。
	- https://www.jpx.co.jp/corporate/news/news-releases/6020/20240312-01.html
	- 東証に上場する会社について、個社のビジネス概要や直近の決算のサマリーを簡単に調べたり、財務状況についての分析や競合他社との比較を行うことができます。
	- コンテンツや分析はBridgewiseの生成AIテクノロジーを利用して作成されます
	- 生成AIを用いて各企業の概要、直近の決算サマリ、財務状況の簡単な分析や競合他社との比較を行うことができる
-  Integrating Phenotypic and Chemoproteomic Approaches to Identify Covalent Targets of Dietary Electrophiles in Platelets
	- https://pubs.acs.org/doi/full/10.1021/acscentsci.3c00822
	- ブロッコリーには強力な抗がん作用があることは知られているけれど、シドニー大学らの研究によれば、ブロッコリーは癌だけでなく、脳卒中を引き起こす可能性のある血栓症を予防し、血栓症の治療を補助する効果もあると示された。
- Llama.cpp で Swallow MX 8x7B を試す
	- https://note.com/npaka/n/n0a9b514756ae?sub_rt=share_b
	- 「Swallow MX 8x7B」は、「Mixtral 8x7B」の日本語能力を強化した大規模言語モデルです
-  Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU
	- https://arxiv.org/abs/2403.06504
	- 本論文中で紹介されているFuyouを使うと、なんと一般消費者向けのGPUであるRTX 4090上で175Bパラメーター、つまりGPT-3 を微調整可能なんですって！
- Claude3の公式promptライブラリの英文校正prompt
	- https://note.com/genkaijokyo/n/n3f82b191dfda
	- Your task is to take the text provided and rewrite it into a clear, grammatically correct version while preserving the original meaning as closely as possible. Correct any spelling mistakes, punctuation errors, verb tense issues, word choice problems, and other grammatical mistakes. Use bold formatting in markdown to emphasize the edited portions of the English text.
- Raspberry Pi 5に日本語LLM(ELYZA-Japanese-Llama-2-7b-fast-Instruct)を入れてみた
	- https://arkouji.cocolog-nifty.com/blog/2024/03/post-e248e6.html
-  RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems
	- https://arxiv.org/abs/2403.06465
	- Microsoft presents a toolkit to integrate LLMs into recommender systems for explainability, conversation, and user control.
-  臨床予測モデル検証の要点
	- https://note.com/tadahiro_goto/n/n90128159a7fb?sub_rt=share_pb
	- 2024年1月にBMJのResearch Methods & Reportingで予測モデルの評価と外的検証に関するreview
	- Evaluation of clinical prediction models (part 1): from development to external validation.
	- ポイント
		- 臨床予測モデルは、**モデルがターゲットとなる対象集団を代表するデータセットで評価**すべき
		- 開発用データセットでは優れているように見えたモデルも、別のデータセットで評価すると、（仮に同じ母集団からのデータであっても）性能が低くなることがほとんど。
		-   **モデルを開発する時点でデータを分割(split)することは、信頼性の低いモデルにつながるため避けるべき**。
		- 利用可能なすべてのデータを活用する努力をすべき（内的検証におけるresamplingや、内的-外的交差検証など）
- Accelerate v0.28.0 has been released!
	- From XLA GPU support to FSDP + QLORA, and more, let's dive into what's new!
- 音声認識に使えるモデルは様々ありますが、現状最も使いやすいものの一つが faster-whispe
	- https://github.com/SYSTRAN/faster-whisper
- shioriha-large-pt
	- https://huggingface.co/cl-nagoya/shioriha-large-pt
	- 東北大BERT-largeに対し、batch size 8192, 系列長 256で、日本語WikipediaやMMARCOといった弱教師データによる対照事前学習を行ったモデルであるshioriha-large-ptを公開しました
- Tour of Modern LLMs
	- https://phontron.com/class/anlp2024/assets/slides/anlp-15-tourofllms.pdf
	- CMUの講義資料、
	- I made some new class slides on “a tour of modern LMs” that has some observations about characteristics of recent LLMs, mostly focusing on open LLMs where we know their details
-  Algorithmic progress in language models
	- https://arxiv.org/abs/2403.05812
	- How quickly have the algorithms behind language models like GPT-4 been improving over time?
- Talk like a graph: Encoding graphs for large language models
	- https://blog.research.google/2024/03/talk-like-graph-encoding-graphs-for.html
	- Graphs, structures that describe connections between objects, are everywhere — imagine the tools in a kitchen, parts of a bike, or a group of friends. Learn about our latest work that explores how to encode graphs in a format that an LLM can understand:
- GPT-4.5 Turbo possible release in June, 256k token context window
	- https://x.com/AiBreakfast/status/1767612026925277424?s=20
	- This OpenAI blog search result shows up in a DuckDuckGo search of “OpenAI GPT-4.5 Turbo” link, then goes to an OpenAI Error 404 page.
- 企業が求める主体性とはなにか？
	- https://www.amazon.co.jp/dp/4798918431/ref=cm_sw_r_as_gl_api_gl_i_294DJF3GFDESXD5WSRBV?linkCode=ml1&tag=regista13-22
	- 企業が期待する「主体性」はかつては行動力だったのが今は思考力と協調・協働できる力になってるとのこと。コミュ力の時代の反映。
-  いま「新しい数学」が必要だ。助けて数学者! by shi3z さん
	- https://note.com/shi3zblog/n/nafa1cee6ada2?sub_rt=share_pw
	- たぶんAI以後の世界で最も価値を持つのは「数学者」である。しかも「高次元幾何学」ないし、それを上回るくらいの概念を発明する数学者だろう
- Devin, the first AI software engineer.
	- https://x.com/cognition_labs/status/1767548763134964000?s=20
	- Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.
	- AIのソフトウェアエンジニア（Devin）が人間レベルに達した初めてのデモだと思う。AIの導入で課題となってたのが長期的な推論と計画。ところが、Devinは計画→実行→評価→再計画を繰り返し、目標達成へと導くシステムを実現している
-  速報：Claude 3に判例評釈を自動生成させてみた（Coinhive事件最高裁判決の巻）
	- https://takagi-hiromitsu.jp/diary/20240313.html
	- 「これだけLLMが長文の意味内容を「理解」するようになったとなると、もはや、書評や論文紹介、判例批評など、定形的なスタイルを持つ学術記事は、…」
	- ひろみちゅ先生絶賛
- Swallow-MS-7b-v0.1 を ichikara instruction で指示チューニングの練習。500ステップ(0.2エポック : 20分) のお試しだけど、きれいに回答してくれてる
	- https://x.com/npaka123/status/1767807910925545892?s=20
- Claude 3 Haiku, the fastest and most affordable model in its intelligence class.
	- https://x.com/AnthropicAI/status/1768018310615151002?s=20
- With OpenAI, Figure 01 can now have full conversations with people
	- https://x.com/Figure_robot/status/1767913661253984474?s=20
	- ChatGPT、ついにロボットに宿る
	- 2週間前、OpenAIとロボット開発のFigureが提携を発表しました。
	- 今回、Figureは、ChatGPTの技術をロボットに搭載したことを発表しました。
	- 遠隔操作なしの100%エンドツーエンドのシステム 
	- OpenAIのモデルが高レベルの視覚と言語の知性を提供
	- Figureのニューラルネットワークが動画のようなロボットの動作を実現しています
-  Claude 3 Haiku の概要 by npakaさん
	- https://note.com/npaka/n/n71f1ef5f5e06?sub_rt=share_h
	- 本日 (2024年3月14日)、最速かつ最も低価格なモデル「Claude 3 Haiku」がリリースされました。「Claude API」および「claude.ai」のClaude Proサブスクリプションで利用可能です。
	- 速度
		- 「Claude 3 Haiku」 は、32,000トークン未満のプロンプトに対して1秒あたり 21,000 トークン (約 30 ページ) [1] を処理します
	- 低価格、
		- 「Claude 3 Haiku」の価格の**入出力トークンの比率は 1:5** です。わずか**1ドル**で **400 件の最高裁判例** [2] または **2,500 枚の画像** [3] を処理および分析できます。
- Claude3 × Googleスプレッドシート
	- Claude-in-Sheets guide
	- どうやら、AnthropicとGoogleが協力して、Google SheetsからClaude3を呼べるらしい。
-  Data Interpreter: An LLM Agent For Data Science
	- https://arxiv.org/abs/2402.18679
	- Data Interpreter has achieved state-of-the-art scores in machine learning, mathematical reasoning, and open-ended tasks, and can analyze stocks, imitate websites, and train models.
	- https://docs.deepwisdom.ai/main/en/DataInterpreter/
- 松田先生が、なぜ1.58bitのbitnetが上手く行くのか考えた話
	- https://x.com/umiyuki_ai/status/1768109605148848322?s=20
	- まず、LLMが何を計算してるか？というと、広大な言語空間の中から次の単語を当てるゲーム。最近のLLMの言語空間は4096次元とかあって、我々の物理空間が3次元しかないのに比べて有り得ん広さ。その中にトークナイザのトークン語彙はたったの3万種類とかしかないわけで、つまり一つの単語あたりに割り当てられた空間もメチャクチャ広い。だから1.58bitに量子化されて計算が雑になってもちゃんと当たる。
-  Artificial intelligence and illusions of understanding in scientific research
	- https://www.nature.com/articles/s41586-024-07146-0
	- 「AIは科学を促進するが、『理解の錯覚』を生み出す危険性がある」、というパースペクティブ論文。
- すべての無料版CopilotユーザーがOpenAIの「**[GPT-4 Turbo](https://gigazine.net/news/20231107-openai-gpt-4-turbo/)**」にアクセスできるようになったことが、Microsoftの広報担当責任者から発表されました。
	- https://gigazine.net/news/20240314-copilot-gpt-4-turbo-free/
-  Artificial Intelligence Controller Interface (AICI)
	- https://github.com/microsoft/aici
	- 大規模言語モデルの出力制御をカンタンにするオープンソースのインターフェース。Microsoft 製。開発者はコントローラーと呼ばれるカスタムロジックを用いて、LLM の生成プロセスをリアルタイムで制御可能。…
- 国産LLMが抱える“開発コスト”の課題　海外勢に安さで勝てるか、ELYZA代表の危機感
	- https://www.itmedia.co.jp/aiplus/articles/2403/13/news167.html
	- 国産随一の精度のLLMを開発したELYZA 。マイクロソフトやAWSが後押しする競合とどう棲み分けていくのか。曽根岡代表の発言をまとめました。
- alfredplpl/suzume-poc
	- https://huggingface.co/alfredplpl/suzume-poc
	- GoogleのGemma-2Bを日本語で使えるように継続事前学習を施した、商用利用可能なベースモデルSuzumeを公開しました。 小型なのでスマホや家電などに向いています
- 世田谷区がAI botを内製　非エンジニア職員がローコードで開発　ChatGPT活用「ヒデキ」
	- https://www.itmedia.co.jp/news/articles/2403/13/news123.html
	- 非エンジニアの職員チームが、ローコードツールなどを駆使して3カ月で完成させたという。
	- 職員が普段から使っているTeamsのチャットツールでヒデキに質問でき、ChatGPTを業務に活用できる
- Cappy: Outperforming and boosting large multi-task language models with a small scorer
	- https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html
	- Cappy, a small pre-trained scorer model that enhances and surpasses the performance of large multi-task language models.
-  BitNet&BitNet b158の実装 by はち さん
	- https://note.com/hatti8/n/nc6890e79a19a
	- 一旦自身の理解のためにもBitNetの処理やBitNet b158の想像される実装、不明瞭な点を色々な方々の実装をもとに文字に書き起こしていこうと思います
- 岡野原さんの、「大規模言語モデル開発の展望と今後の課題」
	- https://hillbig.github.io/NLP2024_WS_okanohara.pdf
	- 様々なトピック（学習データ整備、MoE、Mamba、LongContext、推論効率化）などを紹介
-  MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training
	- https://arxiv.org/abs/2403.09611
	- Apple presents MM1, a family of multimodal LLMs up to 30B parameters, that are SoTA in pre-training metrics and perform competitively after fine-tuning
- Google Cloud Vertex AI に Anthropic の Claude 3 モデルが登場
	- https://cloud.google.com/blog/ja/products/ai-machine-learning/announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai/?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy24q1-googlecloud_jp-blog-ai-in_feed-no-brand-regional-apac&utm_content=announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai&utm_term=-
	- Google は #Anthropic とのパートナーシップを通じ、包括的な #AI 開発プラットフォームである #VertexAI で Anthropic の最新モデルを提供していきます。これにより、エンタープライズ グレードのセキュリティや、パフォーマンスと費用の最適化に活用いただけま
- 清水れみお氏のGenerate Project Summary（プロジェクト要約生成）を使ってみる
	- https://six-loganberry-ba7.notion.site/24-03-15-Generate-Project-Summary-fa20870dfe66426d9e68b730e1f51f11
- Claude3にプロジェクト全体をぶち込むためのプロジェクトの構造とファイル内容を自動でまとめるPythonスクリプト
	- https://zenn.dev/olemi/articles/7b7992c055c64a
	- このPythonスクリプトを使えば、プロジェクトのフォルダ構造とファイルの内容を簡単にまとめることができます。
- Prompt Tuning から Fine Tuning への移行時期推定
	- https://speakerdeck.com/icoxfog417/prompt-tuning-kara-fine-tuning-henoyi-xing-shi-qi-tui-ding
	- ChatGPT や Claude のようなモデルに対し公開されている日本語言語モデルの利用は精度・コスト共に割に合わないと感じている方にとってパンチある内容かと思いま
- JST戦略的創造研究推進事業「自律駆動による研究革新」が来年度から始まります
	- https://www.mext.go.jp/b_menu/houdou/2023/mext_000010.html
	- 研究プロセスそのものを AI やロボット で加速する自律駆動型の研究アプローチ
-  LocalMamba: Visual State Space Model with Windowed Selective Scan
	- https://huggingface.co/papers/2403.09338
-  AI escape velocity: A conversation with Ray Kurzweil
	- https://www.bvp.com/atlas/ai-escape-velocity-a-conversation-with-ray-kurzweil
	- インタビュアー「私たちの大脳新皮質を、十分に高い帯域幅で計算機につなぐことができるようになるのはいつでしょうか？」 
	- カーツワイル「2030年代初頭です。その時点で、大規模言語モデルの全容量を脳内に持つ人間が存在することになるでしょう」
- ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- https://huggingface.co/ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- rinna/bilingual-gpt-neox-4b-instruction-sftに英日翻訳データセット84,300件をフルパラメータチューニングしました。商用利用可能なライセンス(cc-by-sa-4.0)ですので皆様お気軽にお試しください
- Researcher2Vec: ニューラル線形モデル による自然言語処理研究者の可視化と推薦
	- http://chasen.org/~daiti-m/paper/nlp2021researcher2vec-slides.pdf
	- 学振の後ろで動いてるらしい
-  日本語も理解できたCohereForAIのオープンソースのLLMモデルを試してみる。
	- https://note.com/masayuki_abe/n/n0e5e48fc4cc3?sub_rt=share_pb
	- CohereForAIのLLMをGoogle ColabのA100で実行したので紹介していきます
	- フリーのLLMなのに文章生成、数値計算、英訳、日本語理解力がChatGPTみたく回答されているのに驚きました。
-  第2回　AIと人間の未来を決める鍵「アライメント」――ちょっとだけマニアックなAIの話
	- https://bcg-jp.com/article/2230/
	- 今年はAIの発展がさらに加速すると予想されます。AIアライメントはAIと人間との未来を決める鍵となるでしょう。次回もお楽しみに
-  Genomic data in the All of Us Research Program
	- https://www.nature.com/articles/s41586-023-06957-x
	- 今週のNatureにAll of usのサマリーデータが出ている。約25万人（半数近くがマイノリティ）のゲノム解読で、10億もの多様体を検出、117個の疾患に関連する3724個の変異を同定、まとめデータも公開されているらしい
-  OpenAI Grok Curve Experiments
	- https://twitter.com/i/bookmarks
	- This is the code for the paper [Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets](https://arxiv.org/abs/2201.02177) by Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra
	- XからGroqがオープンソース化とのアナウンスが出たが、なんかOpenAIが別実装を公開！
- Claude 3 Opusを使って世界経済を分析するデモ動画
	- https://twitter.com/i/bookmarks?post_id=1769351991665594465
	- Claude 3デモの何が凄いかというと国別の経済動向を調べさせるため、
		- ①10個のSub-agentを作る 
		- ②必要なプロンプトを生成 
		- ③仕事を外注（笑） 
		- ④結果を集めレポートを書く と、
	- 自分の仕事をSub-agentにデリゲート（委任）できたこと。仕事を与えると一番効率のいい方法で進められるのがホント凄い。
- VCの後押しを受け、AI従業員を開発するスタートアップが流行の兆し
	- https://x.com/gijigae/status/1767836153053618465?s=20
-  Open Release  of Grok-1
	- https://x.ai/blog/grok-os
	- ついに本家のGrokリリース(3/17)
	- Base model trained on a large amount of text data, not fine-tuned for any particular task. 
	- 314B parameter Mixture-of-Experts model with 25% of the weights active on a given token. 
	- Trained from scratch by xAI using a custom training stack on top of JAX and Rust in October 2023.

## 3/11

今週は、AnthropicAIがリリースしたClaude3、GPT-4越えとか、自然な回答、エージェントなどの能力もありとか、落合氏やshi3z氏などLLMのプロもうならせる性能、レシート解析マルチモーダル性能、謎のアニメタグ付与性能、様々な能力で旋風を巻き起こしている。大学院レベルのGPQAベンチマークで最高性能さらには、IQ100相当であるという評価も出てきて、日本のプロのライターももはやClaude3でいいのではないかという話に。Langchain、llmaindexも激速でClaude3対応。Claude3の回答を観察すると、人の知識とか、聞きたいことをおもんばかって、人の心に差し込むように答えを入れてくる感じで、まさにLLM版の「不気味の谷」、これは(humanityの)終わりの始まりか。Groqは、gemma-7bベースのデモを公開、リアルタイムに、打鍵に合わせて、いや打ち込みの予測もしながら即回答、これは経験しないとすごさがわからない。Claude3が示した高い能力と合わせて見ると、人の心の状態をリアルタイムに推定して、それに応じた回答をする、場合によっては状態を変更するかもしれない、それってやばいよね。来日した、Benjio氏がやたらalignmentを強調するわけもわかるわ。分割統治式でタスクを分解するNVIDIAのAgent、Qwen-AgentとかAgent周りも当然進む。一方、日本のサブカルに強いgemma-7bベースの日英・英日翻訳モデルとか日本語モデルやデータセットの進展もある。 「はじめての統計的因果推論」、ゆるめの表紙の割には辛口なのが面白い。「統計学の極意」の邦訳版、日本のAIリテラシー向上に寄与できるか。Benjoさんの東大講演、Hintonさんの日経インタビュー、いづれもAIが人を超えることによる脅威について語っている感じなのは興味深い。さて、Appleが生成AIに注力と発表、M3 MacBook Airを突然発表し、なんか不気味な感じがしますね。

- Apple、パワフルなM3チップを搭載した新しい13インチと15インチMacBook Airを発表
	- https://www.apple.com/jp/newsroom/2024/03/apple-unveils-the-new-13-and-15-inch-macbook-air-with-the-powerful-m3-chip/
-  WSL2でSwallow-7b-plus-hfを試してみる
	- https://note.com/ngc_shj/n/n80871f8e4e24?sub_rt=share_h
	- 使用するPCはドスパラさんの「GALLERIA UL9C-R49」
	- chat(instruct)モデルではないので、--no-chatとして起動します
	- これは、なかなかいい感じである。いままで最高かもしれない
- Awesome-Graph-LLM
	- https://github.com/XiaoxinHe/Awesome-Graph-LLM
	- グラフベースの手法とLLMの双方が関連している研究論文のキュレーションリストレポジトリ
- Jurafsky-MartのSpeech and Language Processing  (3rd ed. draft)
	- https://web.stanford.edu/~jurafsky/slp3/
	- In-Context LearningやInstruction Tuningの章も追加
- Toolformer: Language Models Can Teach Themselves to Use Tools
	- https://arxiv.org/abs/2302.04761
	- Metaがツールの使い方を覚える言語モデルToolformerを開発
	- 要点
		- 大規模言語モデルはわずかな例示や指示だけから課題解決を行う驚くべき能力を持つ
		- 一方で、計算や事実チェックはより単純なツールの方が優れた性能を発揮する
		- 両者の長所を生かすため、ツールの呼び出し指示をテキスト化し外部ツールの使い方を自己学習する言語モデルToolformerを提案
-  Learning and Leveraging World Models in Visual Representation Learning
	- https://arxiv.org/abs/2403.00504
	- MetaのJEPAの論文、Meta presents Image World Model
- Build an LLM-Powered API Agent for Task Execution
	- https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/
	- NVIDIAより。LLM使ったAPI Agent
	- ユーザーのクエリに対して、LLMがあらかじめ定義しておいたテンプレを使って子モジュールのLLM用のプロンプトを生成し、子モジュールLLMがそれぞれのタスクをこなして結果を返す
- AnthropicAI、Claude3をリリース
	- https://x.com/AnthropicAI/status/1764653830468428150?s=20
- llamaindex、さっそく Claude3サポート
	- https://docs.llamaindex.ai/en/latest/examples/llm/anthropic.html
	- Like Gemini and Mistral's latest offerings, Claude 3 comes in 3 "flavors" with the largest, Claude Opus, claiming better performance than GPT-4 across a wide range of benchmarks.
- ZETA editing
	- https://huggingface.co/spaces/hilamanor/audioEditing
	- ZEro Shot Audio editing using DDPM inversion
	- Edit Audio with Nothing but Prompts!
- Meta’s AI Watermarking Plan Is Flimsy, at Best Watermarks are too easy to remove to offer any protection against disinformation
	- https://spectrum.ieee.org/meta-ai-watermarks?share_id=8133421&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- Claude3の評判
	- Claude 3 Sonnet 、とにかく生成が早い！！！！！
	- https://x.com/izutorishima/status/1764702243520208962?s=20
	- Sonnet でも一部ベンチマークは GPT-4 と同等かそれ以上に達していて、この速さを無料アカウントで使えるのは普通に OpenAI さんピンチじゃないですか？
	- Claude が賢くなって目もついた！モデルは三つで、Haiku / Sonnet / Opus の順に賢く、値段があがる
	- 最高性能の Opus は 10 個のベンチマークで GPT-4 を 10 個とも超えている。Haiku のレスポンスはウェブ版で試してみたけどマルチモーダル（ここでは画像入力だけですが）については GPT-4-V より上で Gemini 1.0 Ultra と同程度。
	- 200k トークンの長文入力は健在で、さらにすべてのモデルで 1 million トークンも入力できるモデルのよう。ただしこちらは一部のクライアントにのみ提供。
	- 大量の文章の中から重要な情報を抜き出せるかの評価に用いる「Needle In A Haystack」では、精巧性能の Opus をもってすれば精度 99% を達成。今までの Claude 2.1 と比べてめちゃはやい。公称 2 倍。
	- また、JSON 出力など構造化データの出力が得意になり、自然言語による分類や感情分析などもできるように。使ってみたのですが、かなり良い感じに構造化データに変換できました
	- API は現時点で Opus と Sonnet は公開。Haiku は近日公開予定。
- 今まで ChatGPT で書かせた文書って「それっぽさ」があったけど、Claude 3 は非常に丁寧な日本語でもう AI 製かどうかわからん
	- https://x.com/izutorishima/status/1764890317302727114?s=20
- LangchainのClaude3サポート
	- https://python.langchain.com/docs/integrations/chat/anthropic
- img2table
	- https://github.com/xavctn/img2table
	- 画像から表を抽出するPythonライブラリなんだけど、めっちゃいい。セル結合にも対応してて大変素晴らしい
- 大規模言語モデルを用いたゼロショットテキスト分類によるTCFD推奨開示項目の自動判定」
	- https://www.jpx.co.jp/corporate/research-study/working-paper/Summary_JPXWP_Vol43.pdf
	- GPT-4により、92.8%のAccuracyで上場会社の有価証券報告書のテキストを判別できるという結果に
- gemma-7bベースの日英・英日翻訳モデルをQLoRAアダプターの形式で公開しました
	- https://huggingface.co/webbigdata/C3TR-Adapter
	- 翻訳ベンチマークで多言語翻訳モデルであるGoogleのMadlad400やmetaのSeamless m4t v2 large、ALMA-Ja-V2 (私の以前のモデル)よりも大幅に優れており、サブカルチャー文脈に一部対応可能な事が特徴です
- RAGでの回答精度向上のためのテクニック集（応用編-A）
	- https://zenn.dev/knowledgesense/articles/cec1cd43244524
	- 「応用編-A」では、特に1つ目の「ユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出する」ための具体的なテクニックについて見ていきます。
- Claude 3 Opus、Danbooru Taggerの機能もある
	- https://x.com/alfredplpl/status/1764951315636158535?s=20
	- アニメの話らしい
- BASED: Simple linear attention language models balance the recall-throughput tradeoff
	- https://www.together.ai/blog/based
	- Transformerの24倍のスループットを持つLLM
- Claudeの文字起こしやばいな　領収書、形式も含めて完璧に読み取れた
	- https://x.com/SuguruKun_ai/status/1764918827769606393?s=20
- Wikipedia で雑なQAデータセットを作りました。
	- https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-500k
	- 50万件以上あります。Instruction tuning用では日本で一番件数があるので適当に使ってください
- 野村総研による生成AIレポート
	- https://www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/publication/chitekishisan/2024/01/cs20240104.pdf?la=ja-JP&hash=ED42BFF77381C8AD102B7792B56D2654AD7BC6D5
	- 生成AIで影響を受ける職種のリストが載ってるのは最近よく見るけれど、一位が水族館飼育員なのが斬新さを感じた。あとファンドマネージャーが上位にいるのも面白い
- Claude 3の技術レポートによれば、大学院レベルの物理学・化学・生物学の知識と推論に焦点を当てたGPQAベンチマークで最高性能（0 shot CoTで50.4%、多数決利用で59.5%）
	- https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf
- Build a Large Language Model (From Scratch)
	- https://github.com/rasbt/LLMs-from-scratch
	- Manning社（日本だとよくオライリーの皮を被る出版社）からフルスクラッチで大規模言語モデルを作る本が出る模様。GitHubに公開あり
- Tokanizer playgroundがClaude3に対応
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- If you want to calculate how many tokens you're sending to the API, check out The Tokenizer Playground, which we recently updated to include the Claude 3 tokenizer!
- Claude 3 is impressively good at OCR and structured extraction
	- https://x.com/jerryjliu0/status/1765101841535336929?s=20
	- We fed it this complex Excalidraw diagram about the Prometheus model - contains subsections, and interleaving text and diagrams
	- Claude 3 is able to provide a summary of each section and also determine the positions of the diagrams!
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/anthropic_multi_modal.ipynb
- AnthropicのClaude Proまとめ
	- 月額$20(USドル)で最高モデルのClaude Opusとチャット出来るサブスクサービス 
	- chatGPT Proが40メッセージ/3時間の制限があるのと同様に使用量制限はあるが目安しか明記されていない 
	- 無料版と比較して少なくとも5倍の利用枠。短めの(約200単語の英語の文章)であれば8時間ごとに少なくとも100のメッセージを送信可との事 
	- 無料版は1日あたりのメッセージ枠制限だが、有料版は8時間毎に枠がリセット 
	- 『華麗なるギャツビー』のコピーをアップロードした場合(訳注：おそらく1MB未満)8時間以内に送信できるメッセージは20件になるとの事 
	- アップロードできるファイルは文章(doc)か画像(image)で最大5ファイル各10MBまで ・zipはアップロードできないのでソースコード一式をアップロードして解析みたいな事は難しそう 
	- 2023年8月までのデータでトレーニングされている
	- デフォルトではClaude Proに入力された会話はモデルのトレーニングに使用されない(親指アップ/ダウン機能を通じてフィードバックを送信すると使われる) 
	- 無料版については微妙な書き方なので良く分からない(当社の消費者サービスまたはベータ/評価サービスを使用する場合、当社は、お客様のプロンプトや会話を使用して、モデルをより安全にするための利用規約の監視と強制など、信頼性と安全性の作業に関連するモデルをトレーニングすることもあります、との事) 
	- アップロードしたPDFを要約して貰おうとしたら出力は一気にされず「続きを」と促す必要があった
- Claude3はよい、by　落合陽一
	- Claude 3を使いまくってみて，コードレビューが秀逸，日本語性能が良い（gpt4-0613も良いが），pdfなどの扱いが便利．この辺りすでにchatGPTからの移行が起こっている．快適すぎる
	- https://x.com/ochyai/status/1765209291517210816?s=20
- LLMの能力について語る人間の思考力が問われているのではないか　by shi3zさん
	- https://x.com/shi3z/status/1765310307994611798?s=20
- Claude 3 Opus structured query agent
	- https://colab.research.google.com/drive/1hkwipueVyi2Jzo58Z8jfdZ_9rSscfGxd
	- How good is AnthropicAI's Claude 3 Opus at being an agent? Pretty darn good! Check out this quick notebook in which Claude answers a complex, multi-source question by reading a PDF table and using the answer to do math on the contents of a CSV!
- Knowledge-Augmented Planning for LLM Agents
	- https://arxiv.org/abs/2403.03101
	- Proposes an approach to enhance the planning capabilities of LLMs through explicit action knowledge.
- 大学・MetaAIからハルシネーション低減に有効なグラフ拡張したRAG"G-Retriever"の提案
	- https://arxiv.org/abs/2402.07630
	- 部分グラフ抽出を賞金集めSteiner木問題(PCST)で解いている。
- スクショからコード生成！MicrosoftとDeepMindが共著した論文
	- https://github.com/NoviScl/Design2Code
	- -The Design2Code benchmark dataset for the task of converting visual design (screenshot) into code implementation, which consists of 484 real-world webpages from C4 (examples shown below).
- Claude3の開発者が示した、システムプロンプト、シンプル
	- https://x.com/AmandaAskell/status/1765207842993434880?s=20
- はじめての統計的因果推論
	- https://x.com/takehikohayashi/status/1765268689367265668?s=20
	- 開始3ページ目で「統計的因果推論最強論」にいきなり冷や水をぶっかける
- Qwen-Agent
	- https://github.com/QwenLM/Qwen-Agent
	- Agent framework and applications built upon Qwen1.5, featuring Function Calling, Code Interpreter, RAG, and Chrome extension
- Yoshua Benjio氏の来日東大講演
	- https://www.youtube.com/watch?v=8aTkuvbd_jU
	- 思いっきりAIのもたらす壊滅的なリスクやアライメントの話をコアにしている
- toshi456/llava-bench-in-the-wild-ja
	- multilingual-llava-bench-in-the-wildの日本語データの翻訳ミスや未翻訳のデータをDeepL+手動で修正したデータを公開しました。 
	- 先日Turingさんが公開したLLaVA-Bench-JA(COCO)と合わせて日本語VLMの評価にご活用ください。
- Claude-3がAIで初めてIQ100超えを達成したと主張
	- https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq
	- 「現在の成長率を単純に外挿すると、4～10年後にはClaude-6がIQの質問にすべて正解し、誰よりも賢くなることが示唆された」
- 対話系はClaudeが抜きん出て強い
	- https://x.com/reasan_mirasan/status/1765513422504890417?s=20
- LangChain Text Splitters
	- https://x.com/LangChainAI/status/1765418125569491233?s=20
	- One of the most popular parts of LangChain is our text splitters - simple yet necessary for any RAG app
-  Large language models surpass human experts in predicting neuroscience results
	- https://arxiv.org/abs/2403.03230
	- 神経科学の実験結果をLLM (Llama2・Mistral・Falcon・Galactica) で予測する研究
	- 論文アブストの背景と方法部分から二択で結果を予想する問題セット「BrainBench」を作り，LLM vs 専門家で比較
	- 基本的に専門家よりLLMが強い LoRAで神経科学用にfine-tuningすると性能がさらに上がる
- Claude 3 Cookbook by llamaindex
	- https://colab.research.google.com/drive/11HzzDd6fAiH2s8nDjZMRY5nx2Licl_tF?usp=sharing
	- we go through a comprehensive cookbook to show how Claude 3 can be used in a variety of different application use cases with
- GaLoreってのは事前学習がメッチャ省メモリでできるテクノロジーらしい
	- https://x.com/umiyuki_ai/status/1765927780263633236?s=20
	- VRAM24GBで7BモデルのLLMの事前学習ができてしまうらしい
- Meta announces Teaching Large Language Models to Reason with Reinforcement Learning
	- https://huggingface.co/papers/2403.04642
- WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- At the request of the open source community, we're now releasing a 7B model for offensive and defensive cybersecurity. This can be run locally in most computers with less GPU VRAM.
- プロのライターが「仕事には、GPT-4は言うほど大して使えないけどClaude3はそこそこ使える」
	- https://x.com/umiyuki_ai/status/1766284320208212472?s=20
	- たぶん、https://x.com/yukatan/status/1766610634832306408?s=20
	- ようやっとclaude3を試しましたが、たしかに「リリース起こし」については「え、私の仕事やばいかも」と思うレベルに近づいている。
- cyzgab/catch-me-if-you-can
	- https://huggingface.co/spaces/cyzgab/catch-me-if-you-can
	- GroqInc just added support for Gemma 7B. 
	- なんかリアルタイムに質問に答えて（打鍵毎に予測して回答を生成している）
	- まさに、catch me if you canとは。
- ヒントン氏、AIは言葉を理解していると、、、（日経）
	- https://www.nikkei.com/article/DGXZQOGN143CZ0U4A210C2000000/?n_cid=nk_chart_qr
	- 「…大規模言語モデルは、我々と同じように言葉を理解していると思う。…AIが言葉を理解していないという人の大半は、人間がどう理解しているかという理論を持っていない」
	- ポイント
		- 人類存続の危機をもたらす恐れがAIにある  
		- 自律的に人を殺すロボット兵器が10年以内に登場  
		- 大規模言語モデルは脳より効率的に学習できる
- 「統計学の極意」
	- https://www.soshisha.com/book_wadai/books/2692.html
	- 数式は最小限、面白い実例は満載。統計学入門書最新決定版
	- 本書は、入門者が知るべき統計学の現代的論点を網羅しており、まさに待ち望まれた「統計学入門書最新決定版」と言えるでしょう

## 3/4

今週は、1ビットLLMの衝撃!マイクロソフトの発表(The Era of 1-bit LLMs)、 70Bで8.9倍高速ということで、勝手実装、追試も続々、200Mでそれなりに動くというshi3zさんの評価も、shi3zさんによると、「プログラマーなら全員BitNet試してみるべき」だそうだ。小さく試すという意味では、250MのMixtralをpretrainingからfinetuningを試した事例も。てっぺんが高いところにあると周辺も拾うところがたくさんあるという、LLM界隈でのトリクルダウン現象が起きているのか。さて、先週公開されたgemma、ollamaでサポート、やれ周辺モジュールにバグが多いとか、いやファインチューニングで使えたとか、いろいろ評価がある、2bのほうが7bより性能よいと謎の報告も、ちょっとリリース急ぎすぎたか。一方Qwenは、Qwen1.5最高とか、もはやQwen-72Bでいいのではないのか、という評価も出ているが、実は出力をデータセットようには使えないなどの縛りがあるとのこと。マネフォOBが立ち上げたスタートアップstarleyの音声会話型おしゃべりAIアプリ「Cotomo」、UXを考えてちゃんと使える商品に落とすこむことの大切がよくわかる。Mistral Large、「Gemini Proなどのクローズドモデルよりも高いベンチマークスコアを獲得」って本当か？LLMには自然言語よりも最適な形式があるのでは？という野心的な『AutoForm（オートフォーム）』、そういえば先輩の三つ子ちゃんは、独自の言語でコミュニケーションしていたって言ってたな。東工大の、『論文の結論を学習させたら性能が下がった。』という話、イントロのほうがよいというのは不思議だ。μTransfer、転移学習のマイクロ版？大規模モデルの学習をおそらく圧倒的に効率化できるのはよい。Gemini 1.5 Proも使える人が少しずつ拡大している模様、来週あたりはいろいろ評価がでるかも。Gemini 1.5 Proの長コンテキスト性を利用し、Long-context LLMs がRAGの代わりになるかならないかを評価して長コンテキスト時代の新しいRAGアーキテクチャの提案とかあった。Function Calling、色々なLLMで使えるライブラリが出てきて、当たり前の技術になりつつあるな。LlamaParseのPDF読み取り評価とか、RAGでの回答精度向上のためのテクニック集とか、そのあたりの地道な進みもあった。 NVIDIAがノートパソコン用のGPUを新発表とか、まさにwinner takes allの世界。さて日本の優秀な頭脳はどうよ？ということで先週、がっちりマンデーで、東大出身の若者が多いベンチャー「燈」が紹介されたが、あれって、「建築×AI」のテーマで、LLMをがっつり活用するという話。若い人の意識が基盤というより社会実装というかそっち系に流れてる？

- 画像生成AI、安いPCでも高速に　衝撃の「Stable Diffusion WebUI Forge」
	- https://weekly.ascii.jp/elem/000/004/185/4185940/
-  μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_pb
	- μTransfer は、μP （Maximal Update Parametrization）という理論的に導出された NN のパラメータ付けにより実現される、サイズの異なる NN 間のハイパーパラメータ転移です。
	- （知らなかった読者にとって）大規模モデルの学習をおそらく圧倒的に効率化できる汎用的かつシンプルなパラメータ付け μP の存在と使い方を知ることができる。
	- Neural Networks に対してかなり一貫性のある理解が得られそうな気分になる。学習率やパラメータの初期化のスケールに関する話がなんでも TP/μP で取り扱うべき事項に見えてくる。
- ウェブの日本語テキストをクリーニングするための基本的な処理コードと課題
	- https://note.com/kan_hatakeyama/n/n331bda7d77c1?sub_rt=share_pb
		- 文字列の正規化　(変な文字コードを消す)
		- ルールベースでの、不要な文字列の削除
		- 機械学習ベースでの、不要な文字列の削除
		- 重複の削除
- 【最強になった】Googleの最大1000万トークン入力可能なGemini 1.5 Proがヤバすぎる。《概要、他LLMとの比較、ビジネスシーンでの活用方法5選を徹底解説》
	- https://note.com/chaen_channel/n/necaf27db79ae
-  LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens
	- https://arxiv.org/abs/2402.13753
	- It looks like the problem of long contexts in open LLMs is close to being solved.
- ​”話したいことも、話せないことも。” 音声会話型おしゃべりAIアプリ「Cotomo」を提供開始
	- https://prtimes.jp/main/html/rd/p/000000007.000123714.html
- たくさんのお客様がCotomoとおしゃべりしていることで、動作が不安定になる事象が発生しております
	- https://x.com/starley_jp/status/1761753632788357611?s=20
- Qwen1.5 速いし日本語完璧だしすごい by shi3z
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ku-nlp/gpt2-large-japanese-char
	- 弊研のhuggingfaceリポジトリで charcter vocabulary の日本語 gpt2-large（A100 1枚で訓練8か月!）が公開されているので、何かの興味で日本語の文字レベルの言語モデルが欲しい方は是非使ってみてください
- ローカルで気軽にRAGを使って会話することが簡単すぎてビビった。
	- https://qiita.com/mitsumizo/items/469d79c5e81d9189a9e4
- 日本のオープンデータ情報一覧・まとめ
	- https://github.com/japan-opendata/awesome-japan-opendata
	- PLATEAU AWARD 2023でグランプリを受賞した方のGitHubらしい
-  AITuberのブレイクスルーは音声雑談から始まった Cotomo
	- https://note.com/o_ob/n/n27edbebf17af?sub_rt=share_h
	- ・敬意を持って接する  、「話すの楽しい」設定 、過去の会話をキャッシュする  、相手の速度に合わせて早口になる  、一度言った話は2回目は早口  、お別れを名残惜しむ
- Mistral announces Mistral Large, a new flagship model.
	- https://x.com/omarsar0/status/1762140818654064721?s=20
		- 32K tokens context window
		- has native multilingual capacities
		- strong abilities in reasoning, knowledge, maths, and coding benchmarks
		- function calling and JSON format natively supported
		- available through Microsoft Azure
		- a low-latency model called Mistral Small was also released
- Qwen1.5-72B-Chatをお試し中。
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
	- もう全部Qwen-72Bでいいんじゃないかな
	- https://x.com/alfredplpl/status/1762277261435347424?s=20
- Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
	- https://arxiv.org/abs/2402.14848
	- プロンプトの入力が長くなるにつれて、推論性能に顕著な低下が見られることが示唆
	- ■実験結果
		- 入力が長くなると推論の精度が低くなる
		- 失敗モードは主に4つで、入力が長くなるほど顕著になる 
			- 1. 回答拒否 
			- 2. 偏った判断 
			- 3. 頭から答えを言う（推論ステップを辿らない）、 
			- 4. 入力テキストを適切に使わない
- RAGでの回答精度向上のためのテクニック集（基礎編）
	- https://zenn.dev/knowledgesense/articles/47de9ead8029ba
- NVIDIAがノートパソコン用のGPUを新たに発表
	- https://x.com/webbigdata/status/1762645658266468393?s=20
	- RTX 500 GPUは4GBのGPUメモリ 
	- RTX 1000 GPUは6GBのGPUメモ
- LangChainに便利な機能が誕生してまし
	- https://x.com/MLBear2/status/1762623474034790886?s=20
	- Pydanticで構造体を定義した上で `with_structrured_output` を図のように使えば、Function Callingを簡単に呼べるようになりました。 
	- ChatGPTだけではなく、GeminiなどFunction Callingに対応する他のLLMでももちろん使えるとのこと。
- Function Calling Cookbook with Open-source models (LlamaIndex+FIREWORKS)
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/fireworks_cookbook.ipynb
	- We’re excited to present a series of cookbooks showing you how to use LlamaIndex with Fireworks, including function calling and RAG with FireFunction-v1.
- PDFがスルスル読める！話題のLlamaParseとは
	- https://zenn.dev/yokina_kaoto/articles/563f7d75673c2e
	- LlamaParseはLlamaIndexの新しい製品で、再帰検索を実行することで複雑なPDFのテーブルをきれいに抽出することができ、しばしば悩まされる複雑なドキュメントのより正確な解析を約束します
	- LlamaParseでPDFをパースし、AstraDBで**非構造化データ**を検索することで精度が向上するとのこと。
- 新Kaggleコンペ： LLMで生成された文章からプロンプトを復元するタスク
	- https://www.kaggle.com/competitions/llm-prompt-recovery
	- LLMで生成された文章からプロンプトを復元するタスク。
	- データはGoogle Gemmaで作成。評価がsentence-t5-baseの埋め込みベクタとのコサイン類似度なのが時代を感じる。もうJaccardスコアとかの時代じゃないらしい
- iOS17.4のソースコードにOpenAIの何かを含む部分が見つかっていて、おそらく数ヶ月以内にSiriが強力にアップデートされます。
	- https://x.com/1amageek/status/1762422935376302226?s=20
-  The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
	- https://huggingface.co/papers/2402.17764
	- Microsoft presents The Era of 1-bit LLMs 
	- All Large Language Models are in 1.58 Bits
	- これ本当ならタイトル通り生成AIの新時代かもしれない
-  1ビットLLMの衝撃! 70Bで8.9倍高速　全ての推論を加算のみで!GPU不要になる可能性も by shi3zさｎ
	- https://wirelesswire.jp/2024/02/86094/
	- いずれにせよ、　この論文が本当だとしたら、とんでもないことが起きることになる。
- Microsoftが「1ビットLLM時代の到来」という衝撃的なタイトルで論文を公開し、GPUが不要になるかもしれないとの話も出てきているので従来の手法との違いをまとめました
	- https://x.com/webbigdata/status/1763021292696170917?s=20
-  驚異の1ビットLLMを試す。果たして本当に学習できるのか? by shi3zさん
	- https://note.com/shi3zblog/n/n58b0a2252727?sub_rt=share_pb
	- 試したのはこちら
		- https://github.com/Beomi/BitNet-Transformers/tree/main
	- なんかそれっぽいこと言ってる!!!!!!  しかも小さいから当たり前なのだが推論は超速いのである。
	- モデルサイズは200MB。GBじゃないよ。  僕は小さい言語モデルも大きい言語モデルもそこそこ触って来た方だと思うが、このサイズ
- Mixtral 250MのpretrainingからInstruction Tuningまで
	- https://zenn.dev/if001/articles/9bb90e0d8c201f
	- MoEを持つMixtralがhuggingface/transformersで公開されているので、これを利用しつつ、250Mの小さいサイズとして日本語と英語でpretraining、finetuningを行います。
	- 250MのMixtralをpretrainingからfinetuningまでを行いました。小さいサイズなりにうっすら日本語を理解してそう。入力から正確に情報を抽出とそれらを使った出力はさすがに難しそう。あとは、推論時のexpertの選択のされかたや同サイズのモデルとの比較をしてみたいところ
- プログラマーなら全員BitNet試してみるべき by shi3zさん、
	- https://github.com/kyegomez/BitNet
- gemma-7b、英日翻訳タスクに関しては微調整に成功すると私の翻訳モデルALMA-7B-Ja-V2より一段階レベルが上の性能でした
	- https://x.com/webbigdata/status/1762791697212375111?s=20
	- 周辺モジュールにバグが残っていて、英語圏ではあきらめる勢が多いみたい。
- LlamaIndexとGroqの統合
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/groq.ipynb
- Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication
	- https://arxiv.org/abs/2402.18439
	- 「自然言語を超えて」と題して、LLMにタスク実行時の思考を人間の自然言語とは異なるフォーマットで行わせるプロンプト手法『AutoForm（オートフォーム）』が考案されました。
	- LLMの思考は必ずしも人間と同じフォーマットに沿う必要はない、といった結論になります。LLMエージェント同士でコミュニケーションする際にはこの方が効率的かもしれないとのこと。
	- 自然言語に固有の曖昧さを排除し、明確性を高めるために、ステップバイステップの解決策には、より構造化されて簡潔なコミュニケーションの形式を検討してください。適切なフォーマットには、コード、擬似コード、JSON、マークダウン表、論理演算子、または数学方程式が含まれます。回答の最後には、〜〜という形式で答えを示さなければなりません。簡潔かつ正確であることを忘れないでください。
- ChatGPTは数学を解く時に厳密に計算するためにADA（Advanced Data Analitics, Code Interpreter）をデフォルトで使用する様に変わってます
	- https://x.com/ai_syacho/status/1763308074503422008?s=20
	- しかも数学計算の計画も立てる事ができる。
- オリジナルのBitNetを1.58bの論文に従って3値にするように修正しました
	- https://github.com/frodo821/BitNet-Transformers
- Beyond Disciplines「Beyond Disciplines ～CRDSが注目する研究開発の潮流2024～」
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-06.html
	- 所属組織が発行している数十冊・計数千ページの報告書を40ページくらいに圧縮したレポート作成にかかわりました。
- Qwen1.5-72B 日本語能力も高くて良いが生成物でデータセットは作れない規約で残念。
	- https://x.com/alexweberk/status/1763905106674954324?s=20
- 『論文の結論を学習させたら性能が下がった。』
	- https://newswitch.jp/p/40657
	- ６万５０００報の論文データセットを構築した。学習データでは、論文の要約よりもイントロダクションが性能向上に役立った。論文の結論の学習は、性能面でネガティブに働いた。小さなＬＬＭにとっては結論の内容が専門的過ぎた可能性がある。専門知識を備えたＬＬＭを構築するための知見になる。
- 【論文丁寧解説】BitNet b1.58とは一体何者なのか
	- https://qiita.com/tech-Mira/items/67dec9c5a5f025d2727a?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- BitNet b1.58は、その名の通り、各パラメータが、、[−1、0、1]という3つの値での動作を実現した1bitのLLMです。つまり、膨大な計算リソースを必要とする従来のモデルとは異なり、非常に効率的に動作します。加えて、この記事で示されている結果では驚くべきことに、性能は従来の高精度モデルを上回ります。
	- BitNet b1.58とFP16 LLaMA LLMを様々なサイズで比較しました。公平な比較を保証するために、モデルをRedPajamaデータセットで1000億トークンに対して事前学習しました。
- Google AI 進化的 で つくよみちゃんの会話テキストデータセット による Gemini の チューニングを試す by npakaさん
	- https://note.com/npaka/n/n8b03a58abb2c?sub_rt=share_h
	- 「Google AI 進化的」で「つくよみちゃんの会話テキストデータセット」による「Gemini」のチューニングを試したので、まとめました。
-  Towards Long Context RAG by llamaindex
	- https://www.llamaindex.ai/blog/towards-long-context-rag
	- We did a deep dive into Gemini, and consolidated our thinking about long-context LLM benefits, challenges, and new architectures
	- Long-context LLMs will help alleviate the need to do precise chunking and retrieval, and RAG over small sets of documents
	- Long-context LLMs still don’t resolve the issue of RAG over big knowledge bases (present in most organizations/enterprises)
- Gemini 1.5 Proが遂にきました！！！！
	- https://x.com/masahirochaen/status/1763639557457899963?s=20
- GoogleのGemma、2Bの方が7Bより性能が良いとかおかしな事が報告されている
	- https://x.com/webbigdata/status/1763730996455973098?s=20
	- Jeremyさんの言っている通り、fine tuningはHugging Faceに掲載されているTransformers実装ではなくて、githubのgoogle-deepmind/gemmaを参考にした方が良いのかもしれません
	- https://x.com/jeremyphoward/status/1763679390968455185?s=20
-  ロングコンテキストLLMに対応したRAGの新アーキテクチャ by npakaさん
	- https://note.com/npaka/n/n0b17244bae47?sub_rt=share_h
	- 「Gemini 1.5 Pro」の機能をプレビューすることができ、それを試してみることで、ロングコンテキストLLMを適切に使用するには、RAGがどのように進化するのかについてのまとめました。
	- **Gemini は特定の詳細を見事に思い出すことができる**
	- **Gemini は素晴らしい要約能力を持つ**
	- **10Mトークンは大規模な文書コーパスには十分ではない**
	- **埋め込みモデルはコンテキスト長の点で遅れている**
	- RAGの新アーキテクチャ
		- 「**Small-to-Big Retrieval**」
		-  レイテンシーとコストのトレードオフを実現するルーティング

## 2/26

先週、soraの発表で少し霞んだGemini 1.5 pro 、402ページの文書、44分間の映画、10万行のコードに対する推論など、その能力の一旦が垣間見れてきた。Googleは引き続きGemini 1.5 proベースのOSSであるGemma(“貴重な石”、ラテン語)をリリース、同パラメーターサイズであればLlama2やMistralより優れているとの事。Gemmaは軽量であるとともに、embeddingの工夫、安全なAIアプリケーションを作成するためのガイダンスと必須ツールの提供、Kera3.0サポートなど、かなりの量と質のソフトウエアスタックが一気に公開されたことになる。OSS戦略として、安全性に関するコミュニティとの共創という意味でも、MetaのOSS戦略と丸被り。早速、量子化gguf版や、KaggleでGemmaをつかったコンペの開催、embeddingの解析（日本語語彙は貧弱？）、npakaさんによるファインチューニング試行、MLXを使ったファインチューニングなど、コミュニティの活動が盛んに。LPU（Language Processing Unit）を引っ提げるGroq、推論時の高速さが半端ない、専用チップ開発でも戦いは続く、日本のMN-core早く！llamaindexもLlamaCloudとLlamaParseをリリース、テーブルや図表などの埋め込まれたオブジェクトを含む複雑な文書のための独自のパーシングや、RAGの構築がより高性能に、かつ容易になった。日本語LLMでは、 KARAKURI LM (70B)のELYZA-tasks-100による性能評価や、東工大と東北大によるKotomambaの構築等。フレームワークでは、BCGXからagentkitのOSSリリース、DXの手段としてのAIというシナリオでのコンサル系の新たなビジネスモデル。基礎研究では、プロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』や、Mambaとtransformerとのcolabを使った速度比較とか、そもそも状態空間モデルの解説とか。DeepMindとCMUによる、LLMをつかった数値回帰OmniPred論文も面白い、その性能の理論的解析が待たれる。Stable Diffusion 3のリリースやsentencepiece v0.2.0リリースなどの基盤ソフトの重要な更新も進んだ。

- BCGXから、agentkit
	- https://agentkit.infra.x.bcg.com/
	- BCG Xから大規模言語モデルを使ったAgentを楽に作るためのフレームワークAgentKitがOSSとして出ました〜。 Nextjs, FastAPI, Langchainのモダンなテックスタックです
-  Hyena Hierarchy: Towards Larger Convolutional Language Models
	- https://speakerdeck.com/hpprc/hyena-hierarchy-towards-larger-convolutional-language-models
	- Hyena Hierarchyについて、状態空間モデル（SSM）の基礎から解説したスライド
- GroqのLPUについて
	- https://x.com/umiyuki_ai/status/1759740311335739784?s=20
	- Groqとか言う会社のLPU（Language Processing Unit）って新しいチップはLLM推論速度が爆速なんだと。NVidiaとかのGPUと違って高品質なVRAMが要らんから低コストらしい。70BのLLMを動かす時に300tpsという超爆速で推論できる。
	- M3Maxだと6tps、RTX4090+PowerInferだと4tpsしか出ないから50～100倍の速度差。GPUがオワコンの時代来たか？
- The Shift from Models to Compound AI Systems
	- https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/
	- Berkeleyの人々による、「コンパウンドAI」のレビュー記事。
	- LLM単体で勝負するよりも、LLMを含む各種AI／非AIモジュールを組み合わせて作る「コンパウンドAI」の方がより良いシステムを作りやすい、
- Introducing LlamaCloud  and　LlamaParse
	- https://blog.llamaindex.ai/introducing-llamacloud-and-llamaparse-af8cedf9006b
	- Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring **production-grade**  **context-augmentation** to your LLM and RAG applications.
- MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts
	- https://arxiv.org/abs/2401.11403
	- 機械学習応用には分子の物性予測から分類までさまざまなタスクがありますが、LLMによりそれぞれのタスクごとに最適な分子表現へと調整することで、予測性能が向上したそうです。
- 超高速な対話AIサービスのGroq
	- https://groq.com/
-  Learning to Learn Faster from Human Feedback with Language Model Predictive Control
	- https://huggingface.co/papers/2402.11450
	- Google presents Learning to Learn Faster from Human Feedback with Language Model Predictive Control
- SLANG: New Concept Comprehension of Large Language Models
	- https://arxiv.org/abs/2401.12585
	- GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』をカリフォルニア大学などの研究者らが考案
	- ■メソッド 
		- 1. 使用例（コンテキスト）とフレーズを直接入力する 
		- 2. フレーズをコンテキスト内で隠して、意味を評価させる 
		- 3. コンテキスト内のエンティティ（固有名詞や出来事など）を変更し、異なるエンティティがフレーズの解釈に与える影響を調べる 
		- 4. 上記の結果、モデルが新しい言葉の理解に至ったのかを評価する 
	- ■実験と結果 
		- 1. GPT-4/3.5で検証 
		- 2. モデルが知らないインターネットミームを教え込ませた 
		- 3. GPT-4で88.2%、GPT-3.5でも84.5%の正確さを達成した
-  GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements
	- https://huggingface.co/papers/2402.10963
	- 結果ベースの報酬モデル (ORM) をリランカーとして使用して、グローバルとローカルの改良を組み合わせると、いずれか 1 つを個別に使用した場合や、3 つのサンプル ベースラインの中で最も優れたものを大幅に上回るパフォーマンスが得られることがわかりました。
- The Tokenizer Playground
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- After watching, if you want to learn more about how different models (e.g., GPT4, Llama, T5, BERT) tokenize text, check out "The Tokenizer Playground": a web-app I built a few months ago with Transformer.js
- Gemini AdvancedでAIによって提案されたpythonコードを直接実行して動作確認できるインタフェースが追加された
	- https://x.com/webbigdata/status/1760129585994432916?s=20
	- Gemini 1.5 proで「githubから直接全コードと全issuesを取得させる事」と「最も緊急度の高いissuesを特定し、修正を実装させる事」が出来た
- K
<!--stackedit_data:
eyJoaXN0b3J5IjpbNTQ5OTQ0Mzg0LDkzOTc5NzIxMSwtOTE1MD
k3NjgwLC0xMDg0ODI0NjIyLC0xNzM4Mjg4NTk1LDE5MDM2MTI4
MTMsMjgzNjIzOTEsMTQ4MDQyMzU4OSw2ODU0Nzk2NDMsMTgxOD
A1ODMxMSwtNDkyNDE1NTc5LC04MTcyNDM5MjAsODg4ODA2MDI3
LC0xMjcxMjc0ODM3LC0xNjcyNDU2MTk4LDExMDcwMzQ3MjMsLT
EyODM4OTc0NDcsMTc0NjY3NTQwMCwtMjA1MzY4ODQ0NSw2Nzky
MjgyODZdfQ==
-->