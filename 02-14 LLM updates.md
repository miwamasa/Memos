# ã²ãŸã™ã‚‰LLMé–¢é€£æƒ…å ±ã‚’è¿½ã†ã€
ã“ã‚Œã¯ã€å€‹äººã®twitter bookmarkã‚’æ¯é€±ãŠã•ã‚‰ã„ã—ã¦ã„ã‚‹ã€‚

## 1/1

- Build Hybrid Search from Scratch
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/qdrant_hybrid.ipynb
	- 1. Generate a sparse vector (using SPLADE) from both a query and document
	- 2. Define a fusion function that will combine results retrieved from sparse/dense queries. Here thereâ€™s an alpha parameter that controls weighting towards sparse vs. dense retrieval
	- 3. Of course, the dense vector is generated by your favorite embedding model (OpenAI, BGE, Sentence Transformers).
- Ferret: An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.
	- https://github.com/apple/ml-ferretFO
	- Apple releases Ferret
- OpenAssistant Conversations -- Democratizing Large Language Model Alignment
	- https://huggingface.co/OpenAssistant
	- https://projects.laion.ai/Open-Assistant/blog/
-  WSL2ã§PowerInferã‚’è©¦ã—ã¦ã¿ã‚‹
	- https://note.com/ngc_shj/n/nba94b08a2b58?sub_rt=share_h
	- ä½¿ç”¨ã™ã‚‹PCã¯ã€GALLERIA UL9C-R49(RTX 4090 laptop 16GB)ã€ãƒ¡ãƒ¢ãƒªã¯64GBã€OSã¯Windows 11+WSL2ã§ã™ã€‚
	-  LLaMA(ReLU)-2-70B, LLaMA(ReLU)-2-7B
	- 70Bï¼48GBã§ï¼å‹•ã„ãŸã‚ˆ
- ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- https://huggingface.co/ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- This repository contains the bitsandbytes 4-bit quantized version of mistralai/Mixtral-8x7B-Instruct-v0.1
-  LLaMA.cpp+(cu)BLASã®CPU/GPUã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ¤œè¨¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç·¨ï¼‰
	- https://blog.shikoan.com/llama-cpp-local/
	- CPUæ¨è«–ã®æ™‚ã¯5ï½8tpsã ã£ãŸé€Ÿåº¦ãŒã€GPUæ¨è«–ã§ã¯60tpsã«çˆ†é€ŸåŒ–ã—ãŸã‚‰ã—ã„ã€‚ï¼ˆã‚°ãƒ©ãƒœã¯RTX A6000ï¼‰â†“
- è¦šé†’ã—ãŸguidanceã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã‹ã‚‰ãƒã‚¤ã‚ºã®ç„¡ã„ç”Ÿæˆã—ã¦ã‚‚ã‚‰ã„ã€ï¼”æŠã‚¯ã‚¤ã‚ºã¨ã‹jsonç”Ÿæˆã•ã›ã‚‹
		- Llama.cppãŒCPUæ¨è«–ã ã‘ã§ãªãã€GPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦GPUæ¨è«–ã™ã‚‹äº‹ã‚‚å¯èƒ½ã«ãªã£ãŸã€‚ã—ã‹ã‚‚ã€ã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼æ•°ã‚’èª¿æ•´ã§ãã‚‹ã‹ã‚‰ã€ã‚°ãƒ©ãƒœã®VRAMã«å¿œã˜ã¦åŠåˆ†ã ã‘ã¯GPUã€åŠåˆ†ã¯CPUæ¨è«–ãªã‚“ã¦äº‹ã‚‚å¯èƒ½ã ã€‚
		- Nekomataã®å…¬é–‹ã«ã‚ˆã£ã¦ã¤ã„ã«æˆ‘ã€…ã¯æ—¥æœ¬èªã§ãã‚Œãªã‚Šã«è³¢ãã¦è»½é‡ãªãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’æ‰‹ã«å…¥ã‚ŒãŸã®ã ï¼
		- 

## 12/25

æ±å·¥å¤§ã‹ã‚‰LLama2ã®æ—¥æœ¬èªã‚’ã²ãŸã™ã‚‰å¼·åŒ–ã—ãŸswallow(7B, 13B, 70B) ãŒé¢¯çˆ½ã¨ç™»å ´ã€llama2ãƒ™ãƒ¼ã‚¹ã§æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã‚’ã¡ã‚ƒã‚“ã¨æ•´å‚™ã—ãªãŠã—ã¦ã€ã“ã“ã¾ã§ã§ãã‚‹ã¨ã„ã†è©±ã€‚ç”£ç·ç ”ã®ABCIã®Aãƒãƒ¼ãƒ‰ã‚’ï¼–ï¼æ—¥å æœ‰ã—ã¦ã¤ãã£ãŸã¨ã„ã†ã€‚ä¸€æ–¹rinnaã¯Qwenãƒ™ãƒ¼ã‚¹ã§ç¶™ç¶šå­¦ç¿’ã‚’ã•ã›ãŸNekomataã‚’å…¬é–‹ã€AWSã®æ”¯æ´ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ´»ç”¨ã—ã€660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ç´„7æ—¥ã§è¡Œã£ãŸã€‚ã“ã“ã«ãã¦ã€å›½ç”£LLMã‚‚ã„ã‚ã„ã‚æˆæœãŒã§ã¦ããŸãŒã€LLMã®æ¨ªæ–­è©•ä¾¡ã«ã‚ˆã‚‹ã¨ã€30Bä»¥ä¸Šã§ã¯ã€ä¸­å›½å‹¢ãŒå¸­å·»ã€‚7Bã‚¯ãƒ©ã‚¹ã ã¨ã€ELYZA-japanese-Llama-2 ã‚„ CALM2 ãªã©ã®æ—¥æœ¬ç™ºãƒ¢ãƒ‡ãƒ«ã‚‚ãªã‚“ã¨ã‹æ€§èƒ½ã‚’å‡ºã›ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€ã‚‚ã£ã¨ã‚‚ä¸­å›½LLï¼­ã¯ãªãœã‹æ—¥æœ¬èªå‡¦ç†ã«å¾—æ„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ãªã‹ãªã‹ã®å¼·æ•µã‹ã‚‚ã€‚openchatã®è©•ä¾¡ãŒé«˜ã„ã€‚ollama(ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å®Ÿè¡Œãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼‰ãŒè¿…é€Ÿã«æ§˜ã€…ãªOSSã®LLMã«å¯¾å¿œã—ã¦ã„ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã«æ—‹é¢¨ã‚’èµ·ã“ã—ã¦ã„ã‚‹ã€‚LangChainã¨ollamaã‚’çµ„ã¿åˆã‚ã›ãŸresarch-assistantäº‹ä¾‹ã¯æ–°ä¸–ä»£ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚¢ãƒ—ãƒªæ§‹ç¯‰ã®è‰¯ä¾‹ã€‚OpeanAIã¯ã€AGIãŒã§ããŸæœªæ¥ï¼ˆç¾åœ¨ã‹ã‚‚ã—ã‚Œãªã„ï¼‰ã«å‚™ãˆãŸã€Preparedness Frameworkãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ç™ºè¡¨ã€‚ä¼æ¥­ã‚¬ãƒãƒŠãƒ³ã‚¹ã¨ã—ã¦ã€AGIç›¸å½“ã®AIã®é–‹ç™ºã®é€æ˜æ€§ã‚’é«˜ã‚ã‚‹ã¨ã„ã†ã€‚ OpenAIã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®7ã¤ã®åŸå‰‡ã€Practices for Governing Agentic AIã€ãªã‚“ã‹ã‚‚å®‰å…¨æ€§ã«é–¢ã‚ã‚‹é‡è¦ãªæŒ‡é‡ã«ãªã‚Šã†ã‚‹ã€‚llamaindexã®Contorable RAG Agentã¨ã„ã†Agentã®ä½ãƒ¬ãƒ™ãƒ«ã®åˆ¶å¾¡ï¼¡ï¼°ï¼©ã¨ã®æä¾›ã¨ã„ã†ã®ã‚‚ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¬ãƒãƒŠãƒ³ã‚¹ã®ä¸€ã¤ã®å›ç­”ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã€‚æ—¥æœ¬èªembeddingså¤‰æ›ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ã‚‚ã€AIã‚¯ã‚¤ã‚ºç‹ãã‚‰ã„ã¯è§£ã‘ã‚‹ã‚‰ã—ã„ã€ã‚„ã£ã¦ã¿ã‚ˆã†ã€‚æ·±å±¤å­¦ç¿’ã«ã‚ˆã‚‹æ–°ã—ã„æ§‹é€ ã‚¯ãƒ©ã‚¹ã®æŠ—ç”Ÿç‰©è³ªã®ç™ºè¦‹ã¨ã„ã†ã®ã‚‚ã™ã”ã„ãªã€ç§‘å­¦ã®é ˜åŸŸã§ã‚‚AI/LLMã¯å¸¸é€£ã•ã‚“ã«ãªã‚Šã¤ã¤ã‚ã‚‹ã€‚ãªãŠã€Natureæœ€æ–°å·ã¯ã€ŒAIã«ã‚ˆã‚‹ï¼ˆæ°—è±¡ï¼‰äºˆæ¸¬ã€ãŒè¡¨ç´™ã«ãªã£ã¦ã„ã‚‹ã€DeepMindã®ã‚¢ãƒ¬ã§ã‚ã‚‹ã€‚intel-extension-for-transformersã‚‚é‡å­åŒ–å¯¾å¿œã¨ã‹ç€å®Ÿã«é€²åŒ–ã€Llama.cppã‚ˆã‚Šæ—©ã„ã¨ã„ã†å ±å‘Šã‚‚ã€‚Appleã®ï¼­ï¼¬ï¼¸ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚‚æ§˜ã€…ãªOSSã®LLMå¯¾å¿œãŒå…¬é–‹ã•ã‚Œç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€‚Appleè‡ªèº«ã‚‚ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’SSDãªã©ã®å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã™ã‚‹ã“ã¨ã§é«˜é€ŸåŒ–ã™ã‚‹è«–æ–‡ã‚’ç™ºè¡¨ã€iphoneã§å‹•ãã‚ˆã†ã«ãªã‚‹ï¼Ÿã“ã‚Œã£ã¦ã€æŠ•æ©Ÿçš„ï¼¬ï¼¬ï¼­å®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã¿ãŸã„ã«ãªã‚‹ã®ã‹ï¼ŸPowerInferã¿ãŸã„ãªãƒ¡ãƒ¢ãƒªç¯€ç´„ã§æ°‘é–“GPUã§ã‚‚é«˜é€ŸåŒ–(A100ã®85%ã¨ã‹)ã¿ãŸã„ãªã®ã‚‚ã‚ã‚‹ã€‚

-  Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models
	- https://arxiv.org/abs/2312.06585
	- Rest^EMã¯ã€LLMã‚’äººæ‰‹ã§ä½œã£ãŸæ­£è§£ãƒ‡ãƒ¼ã‚¿ã§æ•™å¸«ã‚ã‚Šå¾®èª¿æ•´ã™ã‚‹ã®ã§ãªãã€1) å„å•é¡Œã®å€™è£œè§£ã‚’ç”Ÿæˆ 2)å€™è£œã®å ±é…¬ã‚’è¨ˆç®— 3)å ±é…¬ã§é‡ã¿ä»˜ã‘ã—å†å­¦ç¿’ ã‚’ç¹°ã‚Šè¿”ã™ã€‚æœŸå¾…å€¤æœ€å¤§åŒ–æ³•ã®ä¸€ç¨®ã¨ã¿ãªã›ã‚‹ã€‚æ•°å­¦ã‚„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãªã©è‡ªå‹•è©•ä¾¡ã§ãã‚‹å ´åˆã«æœ‰åŠ¹ã€‚äººæ‰‹ã®ä½œæˆãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Šæœ‰åŠ¹
- Local RAG on Window
	- the latest state-of-the-art models into your RAG workflow on Windows Subsystem for Linux (WSL). Thereâ€™s 5 cookbooks
	- https://github.com/marklysze/LlamaIndex-RAG-WSL-CUDA
-  Build a Large Language Model (From Scratch)
	- https://www.manning.com/books/build-a-large-language-model-from-scratch
	- Maningã®æœ¬ã‚‰ã—ã„
	- In short, in this book, I'll guide you step by step through creating your own LLM, explaining each stage with clear text, diagrams, and examples. This includes Implementing the data preparation, sampling, and tokenization pipeline:
-  ã‚¢ãƒ‹ãƒ¡ã«ã‚ˆãã‚ã‚‹çƒä½“ã«å…­è§’å½¢ãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸãƒãƒªã‚¢ã«ã¤ã„ã¦
	- https://note.com/uynet/n/n6692895dec4f?sub_rt=share_h
	- ã‚¢ãƒ‹ãƒ¡ã«ã‚ˆãã‚ã‚‹çƒä½“ã«å…­è§’å½¢ãŒè²¼ã‚Šä»˜ã‘ã‚‰ã‚ŒãŸãƒãƒªã‚¢ã«ã¤ã„ã¦
	- ã‚ªã‚¤ãƒ©ãƒ¼ã®å¤šé¢ä½“å®šç†ã‚ˆã‚Šã€å…­è§’å½¢ã®ã¿ã§å¤šé¢ä½“ã‚’æ§‹æˆã™ã‚‹ã“ã¨ã¯ä¸å¯èƒ½ã€‚
-  The LangChain Ecosystem Is Expanding At A Tremendous Pace
	- https://cobusgreyling.medium.com/the-langchain-ecosystem-is-expanding-at-a-tremendous-pace-135756e162e9
	- ã¾ãŸæ§‹æˆãŒå¤‰ã‚ã‚‹ã®ã‹ã¨ã„ã†ã‹ã€LangChain-coreã«ã¯ã€åŸºæœ¬éƒ¨åˆ†ã¨LCELã€agent,RAG,chainsã¯LangChainã«ã€ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£æä¾›éƒ¨åˆ†ã¯LangChain-comunityã¸ã€‚
-  å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®æ•™é¤Šã«æŒ‘ã‚€: å¤§è¦æ¨¡ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®æ–°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒMMMUã€
	- https://ai-scholar.tech/articles/large-language-models/mmmu
	- https://arxiv.org/abs/2311.16502
	- æ±ç”¨äººå·¥çŸ¥èƒ½ï¼ˆAGIï¼‰ã®ãƒ¬ãƒ™ãƒ«3ã¨ã—ã¦å®šç¾©ã•ã‚Œã‚‹ã€Œã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAGIã€ã®é€²æ­©ã‚’è©•ä¾¡ã™ã‚‹æ–¹æ³•ã®é‡è¦æ€§ã‚’æèµ·ã€‚  
	- å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ç†è§£ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ŒMMMUã€ã‚’ææ¡ˆã—ã€AIãƒ¢ãƒ‡ãƒ«ã®å°‚é–€çŸ¥è­˜ã¨æ¨è«–èƒ½åŠ›ã‚’è©•ä¾¡ã€‚  
	- ç¾åœ¨ã®AIãƒ¢ãƒ‡ãƒ«ï¼ˆGPT-4Vã‚’å«ã‚€ï¼‰ã¯MMMUã§ä½ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ãŠã‚Šã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆAGIã®é”æˆã«å‘ã‘ã¦æ›´ãªã‚‹æ”¹å–„ãŒå¿…è¦ã§ã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã€‚
- Attention towards chemistry agnostic and explainable battery lifetime prediction
	- https://chemrxiv.org/engage/chemrxiv/article-details/6576e76dfd283d7904bec035
	- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹é›»æ± å¯¿å‘½äºˆæ¸¬ã®è«–æ–‡ã€‚
	-  å¾“æ¥ã®åŠ£åŒ–äºˆæ¸¬ã¯å€‹åˆ¥ãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´ã•ã‚Œä»–ã®é›»æ± ã¸ã®é©ç”¨ãŒå›°é›£ã§ã—ãŸãŒ BASFã•ã‚“ãŒç‹¬è‡ªã«æ§‹ç¯‰ã—ãŸç´„2ä¸‡ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã“ã¨ã§æ±åŒ–æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ãŒã§ããŸãã†ã§ã™ã€‚
- llama_indexã‚ˆã‚Šã€step-wise agent APIã€aka. Low level agent API
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner.ipynb
	- https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html
	- allows you to step through and control agents in a much more granular fashion. End result: build reliable agentic software systems over your data
- ãªã‚“ã‹LoRaè«–æ–‡ãŒã‚ã‚‹ã‚‰ã—ã„
	- https://x.com/cwolferesearch/status/1736795049579491751?s=20
	- LoRA models the update derived for a modelâ€™s weights during finetuning with a low rank decomposition, implemented in practice as a pair of linear projections. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix into each layer of the model.
	- QLoRA is (arguably) the most popular LoRA variant and uses model quantization techniques to reduce memory usage during finetuning while maintaining (roughly) equal levels of performance.
- "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent"
	- https://arxiv.org/abs/2312.10003
	- Googleã®ç ”ç©¶è€…ã‚‰ã¯ã€è‡ªå·±å­¦ç¿’ã¨è‡ªå·±æ”¹å–„ã‚’è¡Œã†LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®é–‹ç™ºæ‰‹æ³•ã‚’è€ƒæ¡ˆã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®çµæœã€å¤–éƒ¨çŸ¥è­˜ã‚’åŠ¹ç‡çš„ã«å–ã‚Šå…¥ã‚Œã¦å¤šæ®µéšæ¨è«–ã‚’è¡Œã†ã“ã¨ã§ã€è‡ªã‚‰ç¶™ç¶šçš„ã«æ€§èƒ½ã‚’å‘ä¸Šã•ã›ã¦ã„ã‘ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã£ãŸã¨ã®ã“ã¨ã§ã™ã€‚
	- æ–¹æ³•
		- â‘  è‡ªå·±æ”¹å–„ã™ã‚‹æ‰‹æ³•ã‚’å–ã‚Šå…¥ã‚ŒãŸ 
		- â‘¡ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ–°ã—ã„æƒ…å ±ã§æˆé•·ã™ã‚‹ç‰¹æ®Šãªå­¦ç¿’æ–¹æ³•ã‚’å°å…¥ 
		- â‘¢ å¤šæ®µéšæ¨è«–ã®èƒ½åŠ›ã‚’é«˜ã‚ã‚‹æ–¹æ³•ã‚’æ¡ç”¨
	- çµæœ
		- â‘  è‡ªå·±è’¸ç•™ã¨æˆé•·ãƒãƒƒãƒå¼·åŒ–å­¦ç¿’ã«ã‚ˆã£ã¦ã€æ™‚ãŒçµŒã¤ã»ã©ã«æ€§èƒ½ã‚’æ”¹å–„ 
		- â‘¡ å¤šæ§˜ãªæ¡ä»¶ä¸‹ã§ä¸€è²«ã—ã¦è‰¯ã„çµæœã‚’ç¤ºã—ãŸ
- LLMã‚’ä½¿ã£ã¦è‡ªåˆ†ã®ä½ã¿ãŸã„è¡—ã‚’è¦‹ã¤ã‘ã¦ã¿ãŸ
	- https://zenn.dev/ubie_dev/articles/5973d99ff0696e
	- æ‰‹æ®µï¼š
		- 30å€‹å¼±ã®éƒ½å¸‚ã®ç‰¹å¾´ã‚’3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã‚‹
		- 30å€‹å¼±ã®ç‰¹å¾´ãŒä¼¼ã¦ã„ã‚‹éƒ½å¸‚ã‚°ãƒ«ãƒ¼ãƒ—ã‚’5ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã‚‹ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æçµæœã®ãƒ©ãƒ™ãƒ«ä»˜ã‘
		- ã‚°ãƒ«ãƒ¼ãƒ—é¸æŠå¾Œã€å¸Œæœ›ã®éƒ½å¸‚ã®æ¡ä»¶ã‚’LLMã«ä¼ãˆã¦ã€ãŠå‹§ã‚ã®éƒ½å¸‚ã‚’å›ç­”ã—ã¦ã‚‚ã‚‰ã†ã€‚
		- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã«ã¯ã€Cursorã‚’åˆ©ç”¨
	- ç¾æ™‚ç‚¹ã«ãŠã„ã¦ã¯ã€LLMãŒå¾—æ„ãªã‚¿ã‚¹ã‚¯ã‚’äººãŒåˆ¤æ–­ã—ã¦ã€é©åˆ‡ã«LLMã‚’æ´»ç”¨ã™ã‚‹ã»ã†ãŒã€è‰²ã€…ã¯ã‹ã©ã‚‹ãªã€ã¨ã„ã†æ„Ÿè¦šã‚’ã‚‚ã¡ã¾ã—ãŸ
- Open AIãŒAIã«ã‚ˆã‚‹å£Šæ»…çš„ãƒªã‚¹ã‚¯ã‚’è¿½è·¡ã€è©•ä¾¡ã€äºˆæ¸¬ã€ä¿è­·ã™ã‚‹ãŸã‚ã®ã€ŒPreparedness Framework(Beta)ã€ç™ºè¡¨ã€‚
	- https://openai.com/safety/preparedness
	- ãƒ¢ãƒ‡ãƒ«ã®ãƒªã‚¹ã‚¯ã—ãã„å€¤ã‚’å®šç¾©ã—ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€CBRN (åŒ–å­¦çš„ã€ç”Ÿç‰©å­¦çš„ã€æ”¾å°„æ€§ç‰©è³ªã€æ ¸è„…å¨)ã€èª¬å¾—ã€ãƒ¢ãƒ‡ãƒ«ã®è‡ªå¾‹æ€§ã«4ã¤ã®å®‰å…¨ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æŒ‡å®šã€‚ 
	- ä»–ã€Œunknownunknownsã€ã«ã‚‚æ³¨åŠ›
	- ç·©å’Œå¾Œã®ã‚¹ã‚³ã‚¢ãŒã€Œmediumã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’å°å…¥å¯èƒ½ã€‚ 
	- ç·©å’Œå¾Œã®ã‚¹ã‚³ã‚¢ãŒã€Œhighã€ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã¯é–‹ç™ºå¯èƒ½ã€‚ ã€ŒCriticalã€ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã‚‚ã—ãã¯ãã†äºˆæƒ³ã•ã‚Œã‚‹å ´åˆCapabilityå‘ä¸Šé–‹ç™ºä¸­æ­¢ã€‚å®‰å…¨æ€§ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã§ã‹ã¤å®‰å…¨ã§ã‚ã‚‹ã“ã¨ã‚’åˆç†çš„ã«ä¿è¨¼ã§ãã‚‹å ´åˆã«ã®ã¿ã€èƒ½åŠ›å‘ä¸Šé–‹ç™ºã‚’ç¶™ç¶šã™ã‚‹ã€‚
	- æŠ€è¡“çš„ä½œæ¥­(Preparedness Team)ã¨é‹ç”¨æ§‹é€ ã‚’ç›£ç£ã™ã‚‹å°‚é–€ãƒãƒ¼ãƒ (å®‰å…¨æ€§è«®å•å§”å“¡ä¼š(SAG)è¨­ç«‹ã€‚å‰è€…ã¯ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡é‚è¡Œã€‚ 
	- SAGã¯çµŒå–¶é™£ã¨å–ç· å½¹ä¼šã«å®‰å…¨æ€§ã‚’å ±å‘Šã™ã‚‹ãŸã‚ã®éƒ¨é–€æ¨ªæ–­çš„ã§ååˆ†ã«å¤šæ§˜ãªè¦–ç‚¹ã‚„çŸ¥è­˜ã‚’æŒã¤å°‚é–€å®¶ã‚°ãƒ«ãƒ¼ãƒ—ã€‚ 
	- çµŒå–¶é™£ãŒæ„æ€æ±ºå®šè€…ã§ã€å–ç· å½¹ä¼šã¯æ±ºå®šã‚’è¦†ã™æ¨©åˆ©ã‚’æŒã¤
-  ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã®7ã¤ã®åŸå‰‡ï¼š OpenAIã€Practices for Governing Agentic AIã€ã‚’èª­ã¿è§£ã
	- https://note.com/mahlab/n/nf6bc6078460d
	- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ã€äººé–“ã«ã‚ˆã‚‹éƒ¨åˆ†çš„ãªç®¡ç†ä¸‹ã§ã‚ã£ã¦ã‚‚ã€è¤‡é›‘ãªç›®æ¨™ã‚’è‡ªå¾‹çš„ã«é‚è¡Œã§ãã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã®ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚
	- ã“ã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ã¯ã€ç”»åƒç”Ÿæˆã‚„è³ªå•å¿œç­”ã®ã‚ˆã†ãªé™å®šã•ã‚ŒãŸç”¨é€”ã§å‹•ä½œã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ ã¨ã¯ç•°ãªã‚Šã€ã‚ˆã‚Šå¹…åºƒã„è¡Œå‹•ã‚’é¸æŠã™ã‚‹èƒ½åŠ›ãŒã‚ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¤‡é›‘ãªç›®æ¨™ã‚’é”æˆã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
	- ã—ã‹ã—ã“ã®ç¨®ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã“ã®ã‚ˆã†ã«å¤§ããªç¤¾ä¼šçš„ä¾¿ç›Šã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ãŒã‚ã‚‹åé¢ã€ã‚·ã‚¹ãƒ†ãƒ ã®éšœå®³ã‚„æ‚ªç”¨ã«ã‚ˆã‚‹é‡å¤§ãªå•é¡Œç™ºç”Ÿã®ãƒªã‚¹ã‚¯ã‚‚ç§˜ã‚ã¦ã„ã¾ã™ã€‚
	- ãã“ã§ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã§ã¯ã€ã“ã®ãƒªã‚¹ã‚¯ã‚’ç·©å’Œã—ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã®æ©æµã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®ã€ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã«é–¢ä¸ã™ã‚‹é–¢ä¿‚è€…ãŒå¾“ã†ã¹ãåŸºæœ¬åŸå‰‡ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
	- å…·ä½“çš„ã«ã¯ã€ä»¥ä¸‹ã®7ã¤ã®åŸå‰‡ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
		1. ã‚¿ã‚¹ã‚¯é©åˆæ€§ã®è©•ä¾¡ã™ã‚‹
		2. è¡Œå‹•ç¯„å›²ã®åˆ¶é™ã™ã‚‹
		3. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œã®è¨­å®šã™ã‚‹
		4. é€æ˜æ€§ã®ç¢ºä¿ã™ã‚‹
		5. è‡ªå‹•ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã†
		6. å›ºæœ‰ã®è­˜åˆ¥å­ã‚’ä»˜ä¸ã™ã‚‹
		7. äººé–“ã«ã‚ˆã‚‹åˆ¶å¾¡æ¨©ã®ä¿æŒã™ã‚‹
	- ã“ã‚Œã‚‰ã¯ã‚ãã¾ã§ã‚‚è©¦è¡Œçš„ãªææ¡ˆã§ã‚ã‚Šã€å„åŸå‰‡ã®è©³ç´°ã¨èª²é¡Œã¯ã“ã‚Œã‹ã‚‰ã®è­°è«–ãŒå¾…ãŸã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ãŒã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹AIã‚·ã‚¹ãƒ†ãƒ ã®è²¬ä»»ã‚ã‚‹åˆ©ç”¨ã®æ¨é€²ã«è³‡ã™ã‚‹ã§ã‚ã‚ã†åŸºç›¤ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
	- æœ€çµ‚çš„ã«ã¯æ³•åˆ¶åº¦ã‚’å«ã‚ãŸç¤¾ä¼šã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã§ã€ã“ã®å–ã‚Šçµ„ã¿ã‚’æ”¯ãˆã¦ã„ãå¿…è¦ãŒã‚ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚
- LLM prompting ã§çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ä½œæˆãƒ»å¯è¦–åŒ–
	- https://github.com/rahulnyk/knowledge_graph
	- Mistral OpenOrca (https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca) ç­‰ã® LLM prompting ã§çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰ã¨ã‚¨ãƒƒã‚¸ã®æƒ…å ±ã‚’ç”Ÿæˆï¼ãã®å¾Œï¼Œnetworkx ã§ã‚°ãƒ©ãƒ•ã‚’å¯è¦–åŒ–ã™ã‚‹
- GCPã”æœ¬ä½“ã«ã‚ˆã‚‹ã€Geminiã¨LangChainã®ã‚³ãƒ©ãƒœnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/orchestration/langchain
	- This includes SEVEN different notebooks for using LangChain to orchestrate a Gemini-powered LLM app
		-   [Getting Started with LangChain ğŸ¦œï¸ğŸ”— + Vertex AI PaLM API](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/intro_langchain_palm_api.ipynb)
		-  [How to use the LangChain ğŸ¦œï¸ğŸ”— BigQuery Data Loader](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/langchain_bigquery_data_loader.ipynb)
- openchat/openchat-3.5-1210
	- https://huggingface.co/openchat/openchat-3.5-1210
	- https://x.com/shi3z/status/1736911369360859173?s=20
	- ã“ã‚Œã™ã”ã„ã€‚ ã»ã‚“ã¨ã«GPT-3.5-Turboä¸¦ã®æ€§èƒ½ã£ã½ãè¦‹ãˆã¦7B ãã—ã¦ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ Apacheãƒ©ã‚¤ã‚»ãƒ³ã‚¹ by shi3zã•ã‚“
	- 2023å¹´11æœˆã«ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸ**[OpenChat-3.5-7B](https://huggingface.co/openchat/openchat_3.5)**ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼æ•°ãŒ70å„„ã—ã‹ãªã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãš2023å¹´3æœˆæ™‚ç‚¹ã®ChatGPTã‚’è¶…ãˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚’å‡ºã™ã»ã©æ€§èƒ½ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«
- åè‘—ã ã£ãŸé»„è‰²ã„æœ¬ï¼ˆçµ±è¨ˆå­¦ã¸ã®ç¢ºç‡è«–ï¼Œãã®å…ˆã¸ï¼‰ã®ç¶šç·¨ã®èµ¤ã„æœ¬ï¼ˆçµ±è¨ˆå­¦ã¸ã®æ¼¸è¿‘è«–ï¼Œãã®å…ˆã¯ï¼‰
	- https://x.com/hshimodaira/status/1737005536896508268?s=20
- æ±å·¥å¤§ã‹ã‚‰Swallowç™»å ´ã€æ—¥æœ¬èªã‚³ãƒ¼ãƒ‘ã‚¹ã®æ•´å‚™ã®å……å®Ÿã¶ã‚Šã«ã¤ã„ã¦
	- https://tokyotech-llm.github.io/swallow-llama
	- Llama 2ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’å¼·åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (7B, 13B, 70B) ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé‡ã¿ï¼‰ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã®ã§ã€LLAMA 2 Community Licenseã«å¾“ã†é™ã‚Šã€ç ”ç©¶ã‚„å•†æ¥­åˆ©ç”¨ãªã©è‡ªç”±ã«åˆ©ç”¨ã§ãã¾ã™
	- Common Crawlï¼ˆç”¨èª8ï¼‰ã‹ã‚‰é…å¸ƒã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆ2020å¹´ã‹ã‚‰2023å¹´ã«ã‹ã‘ã¦åé›†ã•ã‚ŒãŸ21ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆåˆ†ã€ç´„634å„„ãƒšãƒ¼ã‚¸ï¼‰ã‹ã‚‰æ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‹¬è‡ªã«æŠ½å‡ºãƒ»ç²¾éŒ¬ã—ã€ç´„3,121å„„æ–‡å­—ï¼ˆç´„1.73å„„ãƒšãƒ¼ã‚¸ï¼‰ã‹ã‚‰ãªã‚‹æ—¥æœ¬èªã‚¦ã‚§ãƒ–ã‚³ãƒ¼ãƒ‘ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚ã“ã®è¦æ¨¡ã¯ã€CC-100 (ç´„258å„„æ–‡å­—ï¼‰ã€mC4ï¼ˆç´„2,397å„„æ–‡å­—ï¼‰ã€OSCAR 23.10ï¼ˆç´„740å„„æ–‡å­—ï¼‰ã‚’æŠœãã€æ—¥æœ¬èªã®è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚³ãƒ¼ãƒ‘ã‚¹ã®ä¸­ã§ã€å•†ç”¨åˆ©ç”¨ãŒå¯èƒ½ãªã‚‚ã®ã¨ã—ã¦ã¯æœ€å¤§ã¨ãªã‚Šã¾ã™
- "Perspectives on the State and Future of Deep Learning -- 2023"
	- https://arxiv.org/abs/2312.09323
	- Appleã‚„ã‚«ãƒ¼ãƒã‚®ãƒ¼ãƒ¡ãƒ­ãƒ³å¤§å­¦ãªã©è¤‡æ•°æ©Ÿé–¢ã®ç ”ç©¶è€…ã‚‰7åï¼‹ChatGPTãŒé›†ã„ã€ã€ŒAIã®ç¾åœ¨ã€ã«ã¤ã„ã¦è­°è«–ã‚’äº¤ã‚ã—ãŸå†…å®¹ãŒã¾ã¨ã‚ã¦å ±å‘Š
	- â– ã¾ã å–ã‚Šçµ„ã‚ã¦ã„ãªã„é‡è¦èª²é¡Œ 
		- â‘  æ°—å€™å¤‰å‹•ãªã©ã®è‡ªç„¶ç§‘å­¦ã«AIã‚’å¿œç”¨ã™ã‚‹ 
		- â‘¡ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIã§å¤šæ§˜ãªæ¥­ç•Œã«å½±éŸ¿ã‚’åŠã¼ã™ 
	- â– ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®ç†è§£ 
		- â‘  ç‰©ç†å­¦ã®è¤‡é›‘ãªæ¦‚å¿µã‚’çŸ¥ã‚‹ã®ã¨åŒã˜ãã‚‰ã„é›£ã—ã„ ï¼ˆã—ã‹ã—ä¸å¯èƒ½ã§ã¯ãªã„ï¼‰ 
		- â‘¡ å†…éƒ¨å‹•ä½œã‚’è¦–è¦šåŒ–ã™ã¹ã 
	- â– ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®è§£é‡ˆå¯èƒ½æ€§ 
		- â‘  å®Œå…¨ãªè§£é‡ˆã¯é›£ã—ã„ã¨ã®è¦‹æ–¹ã‚‚ã‚ã‚‹ 
		- â‘¡ ã‚ã‚‹å´é¢ã‹ã‚‰ã®è§£é‡ˆã¯å¯èƒ½ã ãŒçœŸå®Ÿã¨ã¯ç•°ãªã‚‹ 
	- â– ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®ä¾¡å€¤ 
		- â‘  ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯é‡è¦ã ãŒç¾åœ¨ã¯ã‚«ã‚ªã‚¹ã§ã‚ã‚‹ 
		- â‘¡ ç”£æ¥­ç•Œã§ã¯è¨­å®šã¨æŒ™å‹•ã‚’ç´°ã‹ãè€ƒæ…®ã—ã¦ã„ã‚‹ 
	- â– ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã®å°†æ¥æ€§ 
		- â‘  ä¸‡èƒ½ã§ã¯ãªã„ãŸã‚ã€å­¦ç¿’æ–¹æ³•ã‚’æ”¹å–„ã™ã¹ã 
		- â‘¡ äº‹å‰çŸ¥è­˜ã‚’çµ±åˆã™ã‚‹ãªã©ã®å¯¾ç­–ãŒå¿…è¦ 
	- â– ç ”ç©¶ã¯ä»Šå¾Œã©ã†ãªã‚‹ 
		- â‘  ã‚¨ãƒ©ãƒ¼æ•°ã‚ˆã‚Šã‚‚ã‚¨ãƒ©ãƒ¼ã®ç¨®é¡ãŒé‡è¦–ã•ã‚Œã¦ã„ã 
		- â‘¡ å®Ÿç”¨æ€§ã«ã‚·ãƒ•ãƒˆã—ã¦ã„ã
- Googleã‹ã‚‰ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®èª¬æ˜ãŒã§ã‚‹	
	- https://ai.google.dev/docs/prompt_best_practices?hl=ja
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­è¨ˆã«æ­£ã—ã„æ–¹æ³•ã‚„é–“é•ã£ãŸæ–¹æ³•ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã‚‹ä¸€èˆ¬çš„ãªæˆ¦ç•¥ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ä¸€èˆ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆæˆ¦ç•¥ã«ã¤ã„ã¦ç´¹ä»‹ã—ã¾ã™ã€‚
-  Controllable Agents for RAG
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner_rag_controllable.ipynb
	- llamaindexã‚ˆã‚Šã€Building Human-in-the-Loop, Advanced RAG
	- add step-wise feedback for complex query executions over a RAG pipeline
- æ±å·¥å¤§ã¨ç”£ç·ç ”ã€è‹±èªã®è¨€èªç†è§£ã‚„å¯¾è©±ã§é«˜ã„èƒ½åŠ›ã‚’æŒã¤å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒSwallowã€ã‚’å…¬é–‹ 
	- https://note.com/aicu/n/n3eb8c1f2df02?sub_rt=share_pb
	- Swallowã®ç ”ç©¶é–‹ç™ºã¯ã€ç”£ç·ç ”ãŒæ§‹ç¯‰ãƒ»é‹ç”¨ã™ã‚‹AIæ©‹æ¸¡ã—ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆABCI: AI Bridging Cloud Infrastructureï¼‰ã®ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã€å›½ç«‹ç ”ç©¶é–‹ç™ºæ³•äººæ–°ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ»ç”£æ¥­æŠ€è¡“ç·åˆé–‹ç™ºæ©Ÿæ§‹ï¼ˆNEDOï¼‰ã®ã€Œæ¬¡ä¸–ä»£äººå·¥çŸ¥èƒ½ãƒ»ãƒ­ãƒœãƒƒãƒˆã®ä¸­æ ¸ã¨ãªã‚‹ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ãƒˆæŠ€è¡“é–‹ç™ºã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ (JPNP18002) ã®ã€Œç†Ÿç·´è€…è¦³ç‚¹ã«åŸºã¥ãã€è¨­è¨ˆãƒªã‚¹ã‚¯è©•ä¾¡æ¥­å‹™ã«ãŠã‘ã‚‹åˆ¤æ–­æ”¯æ´ã‚’è¡Œã†äººå·¥çŸ¥èƒ½é©ç”¨æŠ€è¡“ã®é–‹ç™ºã€ã€ãã®ä»–ã®æ”¯æ´ã«ã‚ˆã£ã¦å®Ÿæ–½ã•ã‚Œã¾ã—ãŸ
	- ç”£ç·ç ”ABCIã®ä¸€å®šéƒ¨åˆ†ï¼ˆAãƒãƒ¼ãƒ‰ã¨å‘¼ã°ã‚Œã‚‹é«˜æ€§èƒ½ãªè¨ˆç®—ãƒãƒ¼ãƒ‰ï¼‰ã‚’æœ€å¤§60æ—¥é–“å æœ‰åˆ©ç”¨ã™ã‚‹æ©Ÿä¼šã‚’æä¾›ã™ã‚‹ã€Œå¤§è¦æ¨¡åŸºç›¤ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰æ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã«ã‚ˆã‚‹ã‚‚ã®ã§ã™
	- swallowã£ã¦ã¤ã°ã‚ï¼Ÿï¼ˆæ±å·¥å¤§ã®ãƒãƒ¼ã‚¯ï¼‰
-  AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse Catalysts Design
	- https://arxiv.org/abs/2312.02308v1
	- å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹è§¦åª’ææ–™ã®é€†è¨­è¨ˆã®è«–æ–‡ã€‚ 
	- -OHã¨ã®çµåˆã¯å¼·ã„ãŒH2Oã¨ã®çµåˆã¯å¼±ã„ã€ã®ã‚ˆã†ãªè¤‡æ•°ã®å¸ç€å‰¤ã®æœ€é©åŒ–ã‚’å¤šç›®çš„å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚Šè¡Œã„ã€16ä¸‡åŒ–åˆç‰©ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã§ããŸãã†ã§ã™ã€‚ 
	- ææ–™é–‹ç™ºã¯ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ãŒåŸºæœ¬ãªã®ã§ã€ã“ã†ã„ã†æœ€é©åŒ–ã¯éœ€è¦ãŒã‚ã‚Šãã†
- ã€ã‚¹ã‚­ãƒ«å®šç¾©å§”å“¡ä¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ï½ã‚¹ã‚­ãƒ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã€ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°ã¨ç”Ÿæˆ AIã€œã€ï¼ˆ2023å¹´10æœˆ20æ—¥ï¼‰
	- https://www.youtube.com/watch?v=nQumYtpN0zY
	- DSå”ä¼š ã‚¹ã‚­ãƒ«å®šç¾©å§”å“¡ä¼š ã‹ã‚‰ç”ŸæˆAIæ™‚ä»£ã«å³ã—ã€ã‚¹ã‚­ãƒ«ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ ver.5ã¨ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ ver.4ã‚’ç™ºè¡¨ã—ãŸéš›ã®è§£èª¬å‹•ç”»ãŒYouTubeã«ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸã‚ˆã†ã§ã™ã€‚ã„ããªã‚Šãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’è¦‹ã¦ã‚‚ãã†ç°¡å˜ã«èƒŒæ™¯ã¯ç†è§£ã§ããªã„ã®ã§ã‚ªã‚¹ã‚¹ãƒ¡ã€‚ç›¸å½“ã«æ¿ƒåšã§ã™ã€‚
-  ELYZA-tasks-100 ã§LLM14å€‹ã®æ—¥æœ¬èªæ€§èƒ½ã‚’æ¨ªæ–­è©•ä¾¡ã—ã¦ã¿ãŸ
	- https://qiita.com/wayama_ryousuke/items/105a164e5c80c150caf1
	- æ—¥æœ¬èªLLMã£ã¦è‰²ã€…ã‚ã‚‹ã‘ã©ãƒ™ãƒ³ãƒã ã‘ã˜ã‚ƒã‚ˆãã‚ã‹ã‚‰ã‚“ãªã€ã¨ã„ã†ã“ã¨ã§æ¤œè¨¼ã—ã¦ã¿ãŸçµæœã‚’è¨˜äº‹ã«ã—ã¦ã¿ã¾ã—ãŸ 
	- openchatã€Swallowç­‰ç™ºè¡¨ã•ã‚ŒãŸã°ã‹ã‚Šã®LLMã«ã¤ã„ã¦ã‚‚æ¤œè¨¼ã—ã¦ã¿ã¦ã¾ã™
	- å¹³å‡ã‚¹ã‚³ã‚¢ãŒæœ€ã‚‚é«˜ã‹ã£ãŸã®ã¯ `Xwin-LM-70B-V0.1` ã§ã€æ¬¡ã„ã§ `deepseek-llm-67b-chat`ã€`Yi-34B-Chat` ã¨ç¶šã„ã¦ã„ã¾ã™ã€‚  
	- ä¸Šä½3ã¤ã¯ã™ã¹ã¦ä¸­å›½å‹¢ã§ã€ãƒ‘ãƒ©ãƒ¡ã‚¿æ•°ã‚‚30Bä»¥ä¸Šã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã™
	- ãƒ‘ãƒ©ãƒ¡ã‚¿æ•°ãŒæ¯”è¼ƒçš„å°‘ãªã„ 7B ãƒ¬ãƒ³ã‚¸ã§ã¯ã€ELYZA-japanese-Llama-2 ã‚„ CALM2 ãªã©ã®æ—¥æœ¬ç™ºãƒ¢ãƒ‡ãƒ«ãŒé«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¦ã„ã¾ã™ã€‚
	- ä¸€æ–¹ã€ãƒ‘ãƒ©ãƒ¡ã‚¿æ•° 30B ä»¥ä¸Šã®å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ï¼ˆãã‚‚ãã‚‚æ—¥æœ¬ç™ºã®ãƒ¢ãƒ‡ãƒ«ãŒå°‘ãªã„ã“ã¨ã‚‚ã‚ã‚Šï¼‰æµ·å¤–ãƒ¢ãƒ‡ãƒ«ãŒé«˜ã„æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚
-  GPTsã‚ˆã‚Šç²¾åº¦ã®é«˜ã„RAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰
	- https://speakerdeck.com/mkazutaka/gptsyorijing-du-nogao-iragsisutemunogou-zhu
	- https://github.com/mkazutaka/20231219-llmapp-meetup
-  LLM in a flash: Efficient Large Language Model Inference with Limited Memory
	- https://arxiv.org/abs/2312.11514
	- Appleã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’SSDãªã©ã®å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«ä¿å­˜ã—ã€æ¥ç¶šã—ãŸPCãªã©ã§èª­ã¿è¾¼ã¿ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã‚’é–‹ç™ºã—ã¾ã—ãŸ
	- CPUã§4-5å€ã€GPUã§20-25å€ã®æ¨è«–é€Ÿåº¦å‘ä¸ŠãŒå®Ÿç¾ã—ã€ã•ã‚‰ã«PCãƒ‡ãƒã‚¤ã‚¹ã®è¨˜æ†¶å®¹é‡ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®åŠåˆ†ã§ã‚‚ã€LLMã‚’é«˜åŠ¹ç‡ã«å®Ÿè¡Œã§ããŸã¨ã®ã“ã¨ã§ã™ã€‚
	- æ‰‹æ³•ï¼š
		- â‘  ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤–éƒ¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ¡ãƒ¢ãƒªã«æ ¼ç´ 
		- â‘¡ è¦æ±‚ã«å¿œã˜ã¦PCã®DRAMï¼ˆãƒ¡ãƒ¢ãƒªï¼‰ã«è»¢é€ 
		- â‘¢ ãƒ‡ãƒ¼ã‚¿è»¢é€é‡ã‚’æ¸›ã‚‰ã—æ¨è«–é€Ÿåº¦ã‚’å‘ä¸Š
	- çµæœï¼š
		- â‘  CPUã§4-5å€ã€GPUã§20-25å€ã®æ¨è«–é€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ 
		- â‘¡ PCãƒ‡ãƒã‚¤ã‚¹ãƒ¡ãƒ¢ãƒªï¼ˆDRAMï¼‰ãŒãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã®åŠåˆ†ã§ã‚‚ã€LLMã‚’é«˜åŠ¹ç‡ã«å®Ÿè¡Œ
- ã€ŒAGI Breakthroughã€
	- https://x.com/bioshok3/status/1737258881452294277?s=20
	- ã€ŒAGI Breakthroughã€ã¨åä»˜ã‘ã‚‰ã‚ŒãŸOpenAIå–ç· å½¹ä¼šã¸ã®å…¬é–‹æ›¸ç°¡ãŒVerses AIã‹ã‚‰æ€¥é½å‡ºã•ã‚Œã¦ã„ã‚‹ã€‚
	- AGIã«ç¹‹ãŒã‚Šã†ã‚‹èƒ½å‹•çš„æ¨è«–ã«ã¤ã„ã¦ã®ç”»æœŸçš„ãªé€²æ­©ã‚’æœ€è¿‘é”æˆã€‚Open AIæ†²ç« ã«åŸºã¥ãã€AGIã®å®‰å…¨ãªé…å‚™ã®ãŸã‚æŠ€è¡“å”åŠ›ã‚’è¦è«‹ã—ã¦ã„ã‚‹ã€‚ä»Šå¾Œã©ã†ãªã‚‹ã‹æ³¨è¦–å¿…è¦ã€‚
- llamaindexã‚ˆã‚Štext2sqlã‚’ã¤ã‹ã£ãŸã€research assistant templte
	- https://github.com/langchain-ai/langchain/tree/master/templates/sql-research-assistant
	- ollamaã‚’åˆ©ç”¨ã—ãŸãƒ­ãƒ¼ã‚«ãƒ«LLMç‰ˆã‚‚ãµãã¾ã‚Œã¦ã„ã‚‹ï¼
	- ãªã‚‹ã»ã©ã€ã“ã‚ŒãŒLangCainã¨LLMã‚’ã¤ã‹ã£ãŸãƒ­ãƒ¼ã‚«ãƒ«Webã‚¢ãƒ—ãƒªæ§‹ç¯‰ã®æ–°ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã‹
- PowerInfer - a high-speed inference engine for deploying LLMs locally
	- https://github.com/SJTU-IPADS/PowerInfer
	- Just came across this super interesting project on speeding up inference. It's not MoE but it's a simple approach that exploits the high locality in LLM inference to design a GPU-CPU hybrid inference engine.
	- It's now possible to use PowerInfer with Llama 2 and Faclon 40B. Mistral-7B support is coming soon!
	- æ¯”è¼ƒå‹•ç”»ã€https://x.com/omarsar0/status/1737168751668187229?s=20
- swallow-70B-instructã®GGUFãŒã§ãã¦ã„ã‚‹ã€‚ã€‚TheBloke/Swallow-70B-instruct-GGUF
	- https://huggingface.co/TheBloke/Swallow-70B-instruct-GGUF
- swallow-13B-instuctã®spaceã‚’ã¤ãã‚Šã¾ã—ãŸ
	- https://huggingface.co/spaces/hayas/Swallow-13B-instruct
	- ã€Œæ±äº¬å·¥æ¥­å¤§å­¦ã®å¤§å²¡å±±ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ã¯è¡Œæ”¿çš„ã«ã¯ã©ã“ã®åŒºã«å±ã™ã‚‹ï¼Ÿã€ã¨ã€å•ã†ã¨ç‹‚ã£ãŸï¼
-  A mathematical perspective on Transformers
	- https://arxiv.org/abs/2312.10794
	- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¯ã€è‡ªå·±æ³¨æ„ã¨å±¤æ­£è¦åŒ–ã¨ã„ã†2ã¤ã®ä¸»è¦ãªæ©Ÿæ§‹ã‚’å«ã‚€ç›¸äº’ä½œç”¨ã™ã‚‹ç²’å­ç³»ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã•ã‚Œã‚‹ã€‚ç²’å­ç³»ã¯ç¢ºç‡æ¸¬åº¦ã®æµã‚Œã‚’å®Ÿè£…
-  Discovery of a structural class of antibiotics with explainable deep learning
	- https://www.nature.com/articles/s41586-023-06887-8
	- æ¯’æ€§ã®ãªã„ã€ãƒ¡ãƒã‚·ãƒªãƒ³è€æ€§é»„è‰²ãƒ–ãƒ‰ã‚¦çƒèŒã«å¯¾ã—ã¦æœ‰åŠ¹ãªè¤‡æ•°ã®åŒ–åˆç‰©ã‚’å«ã‚€æ–°ã—ã„æ§‹é€ ã‚¯ãƒ©ã‚¹ã®æŠ—ç”Ÿç‰©è³ª (æœ€å¾Œã®ç™ºè¦‹ã«ã¯ 38 å¹´ã‹ã‹ã£ãŸ)
- "A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise"
	- https://arxiv.org/abs/2312.12436
	- GPT-4Vã«å¯¾ã—ã¦Geminiã®ç”»åƒèªè­˜èƒ½åŠ›ã¯ã©ã‚Œã»ã©æ€§èƒ½ãŒé«˜ã„ã®ã‹ã€ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§æ¯”è¼ƒã—ãŸå®Ÿé¨“çµæœãŒå ±å‘Šã•ã‚Œã¾ã—ãŸã€‚
	- GPT-4Vã¯è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«é•·ã‘ã¦ãŠã‚Šã€Geminiã¯ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã®çµ±åˆã«é•·ã‘ã¦ã„ã‚‹å‚¾å‘ãŒã‚ã‚‹ã¨ã®ã“ã¨ã§ã™ã€‚
	- æ¯”è¼ƒï¼š
		- â‘  Geminiã¯å¤šãã®å ´åˆã€GPT-4Vã¨åŒç­‰ã‹ãã‚Œä»¥ä¸Šã®æ­£ç¢ºã•ã‚’ç¤ºã™ 
		- â‘¡ Geminiã¯GPT-4Vã‚ˆã‚Šã‚‚çŸ¥è­˜ãŒå¹…åºƒã„ã‚ˆã†ã«è¦‹ãˆã‚‹
-  Fairness and Machine Learning by Arvind Narayanan
	- https://mitpress.mit.edu/9780262048613/fairness-and-machine-learning/
	- An introduction to the intellectual foundations and practical utility of the recent work on fairness and machine learning
	- ãƒ‰ãƒ©ãƒ•ãƒˆãŒã‚ã‚Šã€ã™ã§ã«ãŸãã•ã‚“ã®å¤§å­¦ã®æˆæ¥­ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚https://fairmlbook.org/
- ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ã¿ã§ã€AIç‹ã‚¯ã‚¤ã‚ºç¬¬ä¸€å›ã‚³ãƒ³ãƒšã«è‡¨ã‚€ - Q&Aã‚¿ã‚¹ã‚¯ã§ã®è¤‡æ•°ã®æ—¥æœ¬èªembeddingsã®è©•ä¾¡
	- https://secon.dev/entry/2023/12/21/080000-vector-search-ai-ou-comp/
	- AIç‹ ã€œã‚¯ã‚¤ã‚ºAIæ—¥æœ¬ä¸€æ±ºå®šæˆ¦ã€œ ç¬¬ä¸€å›ã‚³ãƒ³ãƒšã¨ã¯ã€è³ªå•ã«å¯¾ã—ã¦ç´„20å€‹ã®å€™è£œã‹ã‚‰ã€å›ç­”ã¨ãªã‚‹ä¸€ã¤ã‚’é¸æŠã™ã‚‹ã‚³ãƒ³ãƒšã ã€‚trainç”¨ã«ç´„13,000ä»¶ã€valç”¨ã«ç´„2,000ä»¶ãƒ‡ãƒ¼ã‚¿ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã€‚
	- è³ªå•ã«å¯¾ã—ã¦ã®å›ç­”ãŒå«ã¾ã‚Œãã†ãªæ–‡ã‚’æ¤œç´¢ã™ã‚‹æ—¥æœ¬èªembeddingså¤‰æ›ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯ã€multilingual-e5-large ã®æ€§èƒ½ãŒé«˜ã‹ã£ãŸ
- Autonomous chemical research with large language models
	- https://www.nature.com/articles/s41586-023-06792-0
	- Coscientist"â€”a GPT-4 based autonomous LLM system that demonstrates appreciable reasoning capabilities, ... solving of multiple problems and generation of code for experimental design"
	- è‘—è€…ã‚‰ã¯ GPT-4 ã‚’ä½¿ç”¨ã—ã¦ã€è‡ªå¾‹çš„ã«ç ”ç©¶ã€è¨ˆç”»ã€ãŠã‚ˆã³åŒ–å­¦å®Ÿé¨“ã‚’å®Ÿæ–½ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚ã“ã‚Œã«ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã‚“ã§å®Ÿé¨“æ©Ÿå™¨ã®ä½¿ã„æ–¹ã‚’å­¦ã¶ã“ã¨ã‚‚å«ã¾ã‚Œã¾ã™ (ã»ã¨ã‚“ã©ã®æ“ä½œã¯ã‚³ãƒ¼ãƒ‰ã§æ“ä½œã•ã‚Œã¾ã—ãŸãŒã€1 ã¤ã®ã‚¿ã‚¹ã‚¯ã¯äººé–“ãŒå®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸ)ã€‚
- Ollama v0.1.17 now has support for Phi-2
	- https://ollama.ai/library/phi
	- It's a small model at 2.7 billion parameters. Good for its reasoning and language understanding abilities. Given its small size, it'll run effectively on a wider set of hardware.
- TheBloke/Swallow-13B-GGUF
	- https://huggingface.co/TheBloke/Swallow-13B-GGUF
	- ã¾ãŸã¾ãŸ Swallow-13Bã®GGUFãŒå‡ºã¦ã„ã‚‹
-  rinnaã€Qwenã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹
	- https://rinna.co.jp/news/2023/12/20231221.html
	- rinnaã¯Qwen-7Bã¨14Bã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ Nekomata 14B Instructionã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ä¸€éƒ¨ã®70Bã¨åŒãƒ¬ãƒ™ãƒ«ã¾ã§åˆ°é”ã—ã¦ã„ã¾ã™ã€‚
	- Nekomata 7Bã¨14Bã¯ã€70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Qwen-7Bã¨140å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Qwen-14Bã«å¯¾ã—ã¦ã€æ—¥æœ¬èªã¨è‹±èªã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ãã‚Œãã‚Œ300å„„ã¨660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã§ç¶™ç¶šäº‹å‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã™
	- AWS Trainiumã‚’æ­è¼‰ã—ãŸ16ãƒãƒ¼ãƒ‰ã®Amazon EC2 trn1.32xlargeã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç”¨ã„ã¦ã€660å„„ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã¯ç´„7æ—¥ã§å®Œäº†ã—ã¾ã—ãŸ
	- ãƒ¢ãƒ‡ãƒ«åã®ç”±æ¥ã¯ã€å¦–æ€ªã®ã€ŒçŒ«åˆï¼ˆã­ã“ã¾ãŸï¼‰ã€
- Running Mixtral 8x7 locally with LlamaIndex
	- https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab
	- Running MistralAI's Mixtral 8x7b on your laptop is now a one-liner! Check out this post in which we show you how to use OLLAMA with LlamaIndex to create a completely local, open-source retrieval-augmented generation app complete with an API:
-  Google Colab ã§ StreamDiffusion ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n4cb9a2d9fd72?sub_rt=share_h
	- ã€ŒStreamDiffusionã€ã¯ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”»åƒç”Ÿæˆã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã™ã€‚å¾“æ¥ã®ç”»åƒç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨æ¯”ã¹ã¦é£›èºçš„ãªé€Ÿåº¦å‘ä¸Šã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
- Apple ãŒæä¾›ã—ã¦ã„ã‚‹MLXãŒå¾ã€…ã«å……å®Ÿã—ã¦æ¥ãŸã€‚çµæ§‹å‡„ã„ã“ã¨ã«ãªã‚‹ã‹ã‚‚ã€‚
	- https://huggingface.co/mlx-community
	- a bunch of pre-converted MLX models! 
	- Llama, Phi-2, Mistral, Mixtral (and instruct and code variations where available)!
- rinnaã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹nekomata-14b-instructionã®gguf
	- mmnga/rinna-nekomata-14b-instruction-gguf
	- qwenãƒ™ãƒ¼ã‚¹ã§vocab15ä¸‡ã‚ã‚Šã¾ã™
-  Gemini Pro Visionãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦Google Cloudã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸå‹•ç”»ã‚’è§£æã—ã¦ã¿ãŸ
	- https://qiita.com/tatsuki-tsuchiyama/items/5701475d46ee31efbb54
- ã€ŒNekomataã€ã‚·ãƒªãƒ¼ã‚ºã®GGUF 4bité‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆã¯ã€é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚
	- https://huggingface.co/collections/rinna/nekomata-6582b5134ee85531becbb9a9
-  regex to do sentence splitting that generalizes beyond English to non-Latin languages (CJK, etc.) 
	- https://x.com/jerryjliu0/status/1738232451200356445?s=20
- æœ€æ–°ã® SCIENCEã®ç‰¹é›†ã¯AI Powered Forecasting ã€VOLUME 382|ã€ISSUE 6677ã€22 DEC 2023
	- https://www.science.org/toc/science/382/6677?utm_campaign=SciMag&utm_source=Twitter&utm_medium=ownedSocial
	- Trained on four decades of historical data, GraphCast is an artificial intelligence model that predicts global weather with greater speed and accuracy compared with traditional approaches solving physical equations. It supports severe event predictions, such as cyclone tracking.
-  Ferret: Refer and Ground Anything Anywhere at Any Granularity
	- https://github.com/apple/ml-ferret?tab=readme-ov-file
	- Appleã‹ã‚‰ã€ã‚ã‚‰ã‚†ã‚‹å½¢å¼ã®å‚ç…§ï¼ˆç®±ã¨ã‹ã€ãªã‚“ã¨ã‹ã®æ¨ªã¨ã‹ï¼‰ã‚’å—ã‘å…¥ã‚Œã€å¿œç­”ã¨ã—ã¦ã‚ã‚‰ã‚†ã‚‹ã‚‚ã®ã‚’æ¥åœ°ã™ã‚‹ï¼ˆãã‚Œã¯çŒ«ã®ã—ã£ã½ã¨ã‹ï¼‰ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã® MLLM
	- ç‰©ä½“èªè­˜ã®ä¸€ç¨®ãªã®ã‹ã€
- "Retrieval-Augmented Generation for Large Language Models: A Survey"
	- https://arxiv.org/abs/2312.10997
	- LLMã®RAGï¼ˆå¤–éƒ¨çŸ¥è­˜æ¤œç´¢ã«ã‚ˆã‚‹å¼·åŒ–ï¼‰ã«ã¤ã„ã¦ã®èª¿æŸ»çµæœ
	- åŸºæœ¬ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨å„æ§‹æˆè¦ç´ ï¼ˆãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ï¼ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼æ‹¡å¼µï¼‰ã®è©³ç´°ã€è©•ä¾¡ã€ãã—ã¦ä»Šå¾Œã®ç™ºå±•ã«ã¤ã„ã¦è¨€åŠã•ã‚Œã¦ãŠã‚Šç¶²ç¾…çš„ã§ã™ã€‚
	- â– RAGã®è©•ä¾¡
		- â‘  æ­£ç¢ºæ€§ã€æƒ…å ±æ›´æ–°é€Ÿåº¦ã€é€æ˜æ€§ãªã©ãŒä¸»è¦ãªæŒ‡æ¨™
		- â‘¡ RAGASã‚„ARESãªã©ã®è‡ªå‹•è©•ä¾¡æ‰‹æ³•ãŒã‚ã‚‹
	- â– ä»Šå¾Œã®ç™ºå±•
		- â‘  ã•ã‚‰ãªã‚‹æœ€é©åŒ–ãŒå¿…è¦
		- â‘¡ å¿œç”¨ç¯„å›²ã®æ‹¡å¤§ãŒæœŸå¾…ã•ã‚Œã‚‹
		- â‘¢ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã¨ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ãŒç™ºå±•ã™ã¹ã
- Geminiã§ã®tokenã‚«ã‚¦ãƒ³ãƒˆãŒæ—¥æœ¬èªã§ChatGPTã®1/2ã§ã‚ã‚‹ã“ã¨ãŒåˆ¤æ˜
	- https://x.com/Mega_Gorilla_/status/1738821637297115598?s=20
	- Gemini ãŠå‰ã€932 Charactersã§500Tokenã£ã¦ã€ã€ ãŠå‰ã®Tokenã©ã†ãªã£ã¦ã‚‹ã‚“ã ï¼Ÿï¼ OpenAIãªã‚‰ã€åŒã˜æ–‡å­—åˆ—ã§ã€1000ãƒˆãƒ¼ã‚¯ãƒ³è¶Šãˆã ãã€‚
- Youri7Bã‚’ãƒ­ãƒ¼ã‚«ãƒ«LLMã§APIã‚µãƒ¼ãƒãƒ¼åŒ–ã—ã¦ã‚ªãƒªã‚¸ãƒŠãƒ«ç¾å°‘å¥³ã¨ãŠè©±ã—ã¦ã¿ãŸ
	- https://zenn.dev/yasuna/articles/b954b2cd77e27f
	- ãƒ­ãƒ¼ã‚«ãƒ«PCã«LLMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦APIã‚µãƒ¼ãƒã¨ã—ã¦å‹•ã‹ã™
	- ãƒ–ãƒ©ã‚¦ã‚¶ã§ç°¡å˜ã«3Dã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ä¼šè©±ã§ãã‚‹ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã¤ãªã’ã‚‹
	- ã‚ªãƒªã‚¸ãƒŠãƒ«3Dã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ä½œã‚‹
	- ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã‚’ã™ã‚‹
- intel-extension-for-transformers
	- https://github.com/intel/intel-extension-for-transformers
	- ã„ã‚ã„ã‚å¯¾å¿œã§ãã‚‹LLMã‚„é‡å­åŒ–å¯¾å¿œãŒå¢—ãˆã¦ã„ã‚‹æ¨¡æ§˜
- ãƒ¬ã‚¾ãƒŠãƒƒã‚¯ãŒé‡å­åŒ–å­¦è¨ˆç®—ã«æ¯”ã¹ã¦æ•°åƒå€é€Ÿãç‰©æ€§ã‚’äºˆæ¸¬å¯èƒ½ãªã‚¢ãƒ—ãƒªã‚’é–‹ç™º
	- https://monoist.itmedia.co.jp/mn/articles/2312/22/news064.html#utm_term=share_sp
	- ãƒ¬ã‚¾ãƒŠãƒƒã‚¯ã¯2023å¹´12æœˆ21æ—¥ã€ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’ç”¨ã„ãŸAIï¼ˆäººå·¥çŸ¥èƒ½ï¼‰ã¨è†¨å¤§ãªè“„ç©ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã‚‹ã‚±ãƒ¢ã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã‚¢ãƒ—ãƒªã‚’ç‹¬è‡ªé–‹ç™ºã—ã€é‹ç”¨ã‚’é–‹å§‹ã—ãŸã¨ç™ºè¡¨ã—ãŸã€‚
- Building LLM-Powered Web Apps with Client-Side Technology
	- https://ollama.ai/blog/building-llm-powered-web-apps
	- https://www.youtube.com/watch?v=-1sdWLr3TbI
	- Iâ€™d try a different approach and try to build a web app using exclusively local models and technologies, preferably those that run in the browser!
	- ollamaã‚’ã¤ã‹ã£ã¦Langchainã‚’ã¤ã‹ã£ãŸã€Webãƒ™ãƒ¼ã‚¹ã®ãƒ­ãƒ¼ã‚«ãƒ«ãªRAGã®æ§‹ç¯‰ä¾‹
- PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU
	- https://arxiv.org/abs/2312.12456
	- æ¶ˆè²»è€…å‘ã‘GPUã§ã‚‚é«˜æ€§èƒ½GPUã«è¿‘ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§LLMã‚’å‹•ã‹ã™æ‰‹æ³•ã€ŒPowerInferã€
	- â– ã€ŒPowerInferã€ã®ãƒã‚¤ãƒ³ãƒˆ 
		- â‘  LLMã«ãŠã‘ã‚‹ãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã™ 
		- â‘¡ æ¨è«–ã®å‡¦ç†é€Ÿåº¦å‘ä¸Šã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã—ã¦ã„ã‚‹ 
		- â‘¢ GPUã¨CPUã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼ 
	- â– å®Ÿé¨“ 
		- â‘  æ¶ˆè²»è€…å‘ã‘ç’°å¢ƒã‚’ç”¨æ„ ï¼ˆIntel i9, NVIDIA RTX 4090ãªã©ï¼‰ 
		- â‘¡ LLaMA-70Bã»ã‹åˆè¨ˆ3ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ 
		- â‘¢ å®Ÿéš›ã®ã‚µãƒ¼ãƒ“ã‚¹ã«è¿‘ã„ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã‚’è¡Œã£ãŸ 
	- â– çµæœ 
		- â‘  æ¶ˆè²»è€…å‘ã‘ã§ã‚‚é«˜æ€§èƒ½ï¼ˆA100ï¼‰ã®82%ã«ä¸Šã‚‹ç”Ÿæˆé€Ÿåº¦ã‚’é”æˆ 
		- â‘¡ é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§8.00å€ã€éé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§11.69å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã‚’å®Ÿç¾ 
		- â‘¢ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®æ´»æ€§åŒ–ã«å¿œã˜ã¦é©åˆ‡ãªå‰²ã‚Šå½“ã¦ã‚’å®Ÿè¡Œ

## 12/18

ä»Šé€±ã‚‚ã™ã•ã¾ã˜ã„æƒ…å ±é‡ã€‚ãƒ«ã‚«ãƒ³å…ˆç”Ÿã‚‚ã“ã®æƒ…å ±é‡ã«ã¯è¿½ã„ä»˜ã‘ãªã„ã¨ã®ã“ã¨ï¼ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å‹•ç”»ï¼‰ã€‚Geminiã®APIãŒä½¿ãˆã‚‹ã‚ˆã†ãªã‚Šã€æ§˜ã€…ãªã‚µãƒ³ãƒ—ãƒ«ã‚„ã€LangChainã€llamaindexã¨ã®çµ±åˆãŒã©ã‚“ã©ã‚“è¡Œã‚ã‚ŒãŸã€‚ãƒ•ãƒªãƒ¼ç‰ˆãªã‚‰ã°ã€60QPM (queries per minute)ã¾ã§ã¯ä½¿ãˆã‚‹ã€‚ã‚¯ãƒªã‚¹ãƒã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œã‚ã†ã¯ã„ã„ã­ã€å¹´è³€çŠ¶ã‹ãªã€‚Mistralã€MOEã®ã™ã°ã‚‰ã—ã•ã‚„ã€MOEã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºï¼ˆãƒãƒ¼ã‚¸ã¨ã‹ã€æ—¥æœ¬èªã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å…¥ã‚Œè¾¼ã‚€ã¨ã‹ã®è©¦ã¿ï¼‰ã®è©¦ã¿ãŒå§‹ã¾ã‚‹ã€‚NeurPS2023ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è³ªãŒé‡è¦ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ãŒã€DeepMindã‹ã‚‰ã¯ã€LLMãŒè³ªã®è‰¯ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã—ã¦å­¦ç¿’ã™ã‚‹ã€Œè‡ªå·±å­¦ç¿’ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚RAGã§ã‚‚è³ªå•ã‚’äº‹å‰ã«LLMã§ã€è§£ãã‚„ã™ã„ã‚ˆã†ã«ã€å¤‰å½¢ã™ã‚‹ã£ã¦ã®ã¯ã„ã„ã­ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®Phi-2ã€2.7Bãƒ‘ãƒ©ã®LLMã§ãã“ãã“æ€§èƒ½ãŒã§ã‚‹ã‚‰ã—ã„ã€‚DeepMindã®FunSearchã€æ–°ã—ã„ç§‘å­¦ã®ç™ºè¦‹ãŒLLMã§å®Ÿç¾ã§ãã‚‹ä¸–ç•ŒãŒã¤ã„ã«ã‚„ã£ã¦ããŸã€‚å­£ç¯€æŸ„ã‚¢ãƒ™ãƒ³ãƒˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç³»ã®è¨˜äº‹ãŒã‚ˆã„ã€å¤å…¸ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã«ã‚ˆã‚‹åˆ†æã¨ã‹ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã‹ã€‚LLMã«ã‚ˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç ”ç©¶ã‚‚ã€open-ended ãªçŠ¶æ³ã§ç ”ç©¶ã‚’ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒæ˜ç¢ºã«ãªã‚Šã€ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆã§ã®è©•ä¾¡äº‹ä¾‹ã¨ã‹ã©ã‚“ã©ã‚“é€²ã‚“ã§ã‚†ãã€‚

- "TaskWeaver: A Code-First Agent Framework
	- https://arxiv.org/abs/2311.17541
	- Microsoftã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªç„¶è¨€èªã§ã€Œã“ã†ã—ã¦ã€ã¨è¨€ã†ã ã‘ã§LLMãŒè¦æ±‚ã‚’ç†è§£ã—ã€å®Ÿè¡Œã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã€TaskWeaverï¼ˆã‚¿ã‚¹ã‚¯ã‚¦ã‚£ãƒ¼ãƒãƒ¼ï¼‰ã€ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚ 
	- å®Ÿé¨“ã®çµæœã€æ ªä¾¡äºˆæ¸¬ã‚„ç•°å¸¸æ¤œå‡ºãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’é€šã—ã¦æœ‰åŠ¹æ€§ãŒç¢ºèªã•ã‚Œã¦ã„ã‚‹ãã†ã§ã™ã€‚
	- â‘  è‡ªç„¶è¨€èªã§ã®è¦æ±‚ã‚’ã‚³ãƒ¼ãƒ‰ã«å¤‰æ›ã™ã‚‹ 
	- â‘¡ è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹æœ‰ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ 
	- â‘¢ æœ€é©ãªãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§é¸æŠã—ã€ã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ã™ã‚‹
- LLMã‚’ã‚»ãƒ©ãƒ”ã‚¹ãƒˆã¨ã—ã¦å®Ÿè¡Œã—ã€ã€ŒèªçŸ¥ã®æ­ªã¿ã€ã‚’è©•ä¾¡ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Diagnosis of Thought (DoT)ã€ã«åŸºã¥ãMyGPT
	- https://chat.openai.com/g/g-o9r1c3nkf-serapisuto-diagnosis-of-thought-dot
- æ—¥æœ¬èª LLM ã®ç²¾åº¦ãŒã„ã¾ã„ã¡ãªã®ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å•é¡ŒãŒã‚ã‚Šãã†ã¨ã„ã†æŒ‡æ‘˜
	- https://github.com/AUGMXNT/shisa/wiki/A-Review-of-Public-Japanese-Training-Sets#analysis
- gtp-fastã®æœ¬å®¶github
	- Simple and efficient pytorch-native transformer text generation.
	- https://github.com/pytorch-labs/gpt-fast
- "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey"
	- https://arxiv.org/abs/2312.00678
	- LLMã®åŠ¹ç‡ã‚’é«˜ã‚ã‚‹ãŸã‚ã®ãƒã‚¦ãƒã‚¦ã«é–¢ã™ã‚‹ç¶²ç¾…çš„ãªèª¿æŸ» by Microsoft
	- ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼ãƒ‡ãƒ¼ã‚¿ï¼ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼æ¨è«–ã€ã¨ã„ã£ãŸ5ã¤ã®è¦³ç‚¹ã‹ã‚‰å ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚
- MistralAI Embeddings
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/mistralai.ipynb
	- llamaindexã‚ˆã‚ŠMistralAI ã®Embeddingsã‚’åˆ©ç”¨ã™ã‚‹notebook
	- ãªã‚“ã‹ã€MistralAIè‡ªä½“ã‚‚ã¤ã‹ã‚‹ã‚‰ã—ã„
		- The new Mistral 8x7B model is an open-source model that made waves in the AI community today, outperforming gpt-3.5 and llama2 70B. Check out `mistral-tiny`, `mistral-small`, and `mistral-medium` variants.
		- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/mistralai.ipynb
- MistralãŒã©ã†ãˆã‚‰ã„ã®ã‹ï¼Ÿ by ã‚¸ãƒ ãƒ•ã‚¡ãƒ³æ°
	- https://twitter.com/DrJimFan/status/1734269362100437315
	- MoE is the right path forward
	- An LLM is a snapshot of a civilization
	- ã‚¸ãƒ ãƒ•ã‚¡ãƒ³æ°æ›°ãã€Mistralã®Mixtralãƒ¢ãƒ‡ãƒ«å…¬é–‹ã®ãƒ¯ã‚±åˆ†ã‹ã‚‰ã‚“ãƒ ãƒ¼ãƒ–ã¯å®Ÿã¯é«˜åº¦ãªæˆ¦ç•¥ã ã£ãŸã€‚ã¾ãšä½•ã®èª¬æ˜ã‚‚ãªããƒ¢ãƒ‡ãƒ«ã‚’torrentã«æŠ•ä¸‹ã€‚ãã‚“ã§vLLMãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ãƒ—ãƒ«ãƒªã‚¯æŠ•ã’ã¦ã€èª°ã§ã‚‚Mixtralã§éŠã¹ã‚‹ã‚ˆã†ã«ç’°å¢ƒã‚’ä½œã£ã¦ã‚ã’ã‚‹ã€‚æœ€å¾Œã«ã‚ã‚‰ãŸã‚ã¦ãƒ–ãƒ­ã‚°è¨˜äº‹ã§ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç™ºè¡¨ï¼ç™ºè¡¨ã¨åŒæ™‚ã«ã™ãéŠã¹ã¦ä¸–é–“ãŒç››ã‚Šä¸ŠãŒã£ã¦æ³¨ç›®åº¦ã‚’ç¨¼ã’ã‚‹ã¨ã„ã†æµã‚Œ by ã†ã¿ã‚†ãã•ã‚“
- "From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"
	- https://arxiv.org/abs/2312.06571
	- æ±äº¬å¤§å­¦ã¨æ ªå¼ä¼šç¤¾ã‚ªãƒ«ã‚¿ãƒŠãƒ†ã‚£ãƒ´ãƒ»ãƒã‚·ãƒ³ã®ç ”ç©¶è€…ã‚‰ã¯ã€ŒLLMã¨ç‰©ç†çš„ãªä¸–ç•ŒãŒã¤ãªãŒã‚‹ã¨ä½•ãŒèµ·ã“ã‚‹ã®ã‹ï¼Ÿã€ã¨æƒ³åƒã—ã€å®Ÿéš›ã«GPT-4ã¨ãƒ’ãƒ¥ãƒ¼ãƒãƒã‚¤ãƒ‰ãƒ­ãƒœãƒƒãƒˆã‚’é€£æºã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®æ¦‚è¦
		- â‘  ãƒ­ãƒœãƒƒãƒˆã€ŒAlter3ã€ã«å¯¾ã—ã¦ã€æ§˜ã€…ãªè‡ªç„¶è¨€èªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æŒ‡ç¤º 
		- â‘¡ GPT-4ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ­ãƒœãƒƒãƒˆå‹•ä½œã®ã‚³ãƒ¼ãƒ‰ã«å¤‰æ› 
		- â‘¢ ãƒ­ãƒœãƒƒãƒˆãŒäººé–“ã®ã‚ˆã†ãªå‹•ãã‚„æ„Ÿæƒ…è¡¨ç¾ã‚’å®Ÿè¡Œ 
	- å®Ÿé¨“ã®çµæœ 
		- â‘  ã€ŒAlter3ã€ã¯9ç¨®é¡ã®ç•°ãªã‚‹å‹•ä½œã®å®Ÿè¡Œã‚’æˆåŠŸ 
		- â‘¡ ç¬¬ä¸‰è€…ã«ã‚ˆã‚‹å‹•ä½œã®è©•ä¾¡ã¯é«˜ã‹ã£ãŸ 
		- â‘¢ äººé–“çš„ãªå‹•ä½œã¨æ„Ÿæƒ…è¡¨ç¾ã‚’å®Ÿç¾
-  Mixtral 8x7B ã®æ¦‚è¦  by npakaã•ã‚“
	- https://note.com/npaka/n/n6043bc8b01bc?sub_rt=share_h
	- æ¨è«–ã¯6å€é€Ÿãã€ã»ã¨ã‚“ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€ŒLlama2 70Bã€ã‚’ä¸Šå›ã£ã¦ã„ã¾
	- **Mistral-tiny** : Mistral 7B Instruct v0.2ã€‚è‹±èªã§ã®ã¿æ©Ÿèƒ½ã€‚MT-Benchã§ã¯7.6ã‚’ç²å¾—ã€‚  
	- **Mistral-small** : Mixtral 8x7Bã€‚è‹±èª/ãƒ•ãƒ©ãƒ³ã‚¹èª/ã‚¤ã‚¿ãƒªã‚¢èª/ãƒ‰ã‚¤ãƒ„èª/ã‚¹ãƒšã‚¤ãƒ³èªã¨ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¿ãƒ¼ã€‚MT-Benchã§8.3ã‚’ç²å¾—ã€‚  
	- **Mistral-medium** : Mistral AIã®æœ€é«˜å“è³ªã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ãƒ¢ãƒ‡ãƒ«ã€‚è‹±èª/ãƒ•ãƒ©ãƒ³ã‚¹èª/ã‚¤ã‚¿ãƒªã‚¢èª/ãƒ‰ã‚¤ãƒ„èª/ã‚¹ãƒšã‚¤ãƒ³èªã¨ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¿ãƒ¼ã€‚MT-Benchã§8.6ã‚’ç²å¾—ã€‚
- ãƒŸã‚¹ãƒˆãƒ©ãƒ«ã®MoEç‰ˆã§ã‚ã‚‹mixtralã§ã™ãŒé©šã„ãŸäº‹ã«æ—¢ã«llama.cppã®é‡å­åŒ–ç‰ˆãŒå‡ºã¦ã„ã‚‹ã®ã§gpuãŒãªã„ç’°å¢ƒã‚„Macã§ã‚‚å‹•ã‹ã›ã‚‹
	- https://x.com/webbigdata/status/1734425932029628876?s=20
- "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"
	- https://arxiv.org/abs/2312.06585
	- LMã«è‡ªã‚‰é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã•ã›ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã™ã‚‹ã€Œè‡ªå·±å­¦ç¿’ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ by DeepMind
	- æ–¹æ³•
		- â‘  è‡ªã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ‹¡å¼µã™ã‚‹ 
		- â‘¡ ç”Ÿæˆã—ãŸãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã™ã‚‹
		- â‘¢ æ•°å­¦ã‚’ä¸­å¿ƒã¨ã—ãŸæ§˜ã€…ãªå•é¡Œè§£æ±ºã«ä½¿ãˆã‚‹
	- å®Ÿé¨“çµæœ 
		- â‘  æ•°å­¦ã«ãŠã„ã¦ã€æ­£ç­”ç‡ã®å‘ä¸Šã‚’é”æˆ 
		- â‘¡ ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®å•é¡Œã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®é©å¿œèƒ½åŠ›ãŒå‘
-  Query Transform Cookbook
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/query_transformations/query_transform_cookbook.ipynb
	- RAGã«ãŠã„ã¦ã€æ¤œç´¢çµæœã‚’contextã«ç©ã‚“ã§LLMã«å›ç­”ã•ã›ã‚‹ã®ã§ã¯ãªãã¦ã€è³ªå•ã‚’LLMã§å¤‰æ›ã—ã¦ã‚†ãã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- Query Understanding Layer
- Mistral-7B-Instruct-v0.2 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://x.com/npaka123/status/1734348586689908878?s=20
	- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- Mixtral-8x7B-Instruct-v0.1 ã‚’è©¦ã™ã€‚load_in_4bitã€‚ by npakaã•ã‚“ã€
	- https://x.com/npaka123/status/1734408371154100457?s=20
	- https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
	- èµ·å‹•ã¾ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å«ã‚ã¦20åˆ†ã§æ¨è«–é€Ÿåº¦ã¯200ãƒˆãƒ¼ã‚¯ãƒ³ã§21ç§’
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒPhi-2ã¨ã‹ã„ã†2.7Bãƒ‘ãƒ©ã®LLMã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://x.com/umiyuki_ai/status/1734763437274890746?s=20
	- MicrosoftãŒIgniteã§è©±ã—ã¦ã„ãŸã‚ãšã‹27å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«Phi-2
	- ãƒ‘ãƒ©æ•°å°ã•ã„ãã›ã«ã‚ã‚Šå¾—ã‚“é«˜æ€§èƒ½ã‚’ç™ºæ®ã—ã¦ã‚‹ã‚‰ã—ã„ã€‚
	- å­¦ç¿’é‡ã¯1.4Tãƒˆãƒ¼ã‚¯ãƒ³ã§ã€96å€‹ã®A100ã§14æ—¥ã‹ã‘ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã€‚
	- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ãƒ‘ãƒ©æ•°3.2Bã®Gemini Nanoã«å®Œå‹ï¼ˆã¦ã‹Gemini Nanoã®ãƒ‘ãƒ©æ•°åˆã‚ã¦çŸ¥ã£ãŸã‚ï¼‰
	- ãã—ã¦ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ç‹¬è‡ªãƒ™ãƒ³ãƒã«ãŠã„ã¦ã€ã¾ã•ã‹ã®Llama2-70Bç›¸æ‰‹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§åœ§å‹ã€æ•°å­¦ã§åƒ…å·®ã«è¿«ã‚‹ã€‚Llama2-13Bç›¸æ‰‹ã«ã¯å®Œå‹ã—ã¦ã—ã¾ã†ã€‚
- The Emergent Abilities of LLMs Could Be A Mirage!
	- The best paper award in NeurIPs 2023 went to a paper claiming that the emergent abilities of LLMs could be a mirage!
- llamaindexã«ã¦mistralaiã®ã‚µãƒãƒ¼ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¬é–‹
	- https://docs.llamaindex.ai/en/stable/examples/llm/mistralai.html
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘Mixtral-8x7bã‚’llama.cppã§è©¦ã™
	- https://note.com/bakushu/n/n5b270b288cba?sub_rt=share_b
	- llama.cppã§ã€ŒMixtral-8x7bã€ã®GGUFé‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã—ã¾ã—ãŸï¼ˆç¾æ™‚ç‚¹ã§ã¾ã mergeã•ã‚Œã¦ã„ãªã„ã®ã§branchã‚’åˆ©ç”¨ï¼‰
	- ã€Œ**Mixtral-8x7b**ã€ã¯MistralãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸMoEï¼ˆMixture of Expertsï¼‰æ§‹é€ ã®LLMã§ã€ŒMistral 7Bã€ãƒ™ãƒ¼ã‚¹ã®8å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’æŸã­ã¦ã„ã¾ã™ã€‚
	-   ä»Šå›ã¯Google Colabã§ã€Œ[**Mixtral-8x7B-Instruct-v0.1-Q4_K_M-GGUF**](https://mixtral-8x7b-instruct-v0.1-gguf/)ï¼ˆ4bité‡å­åŒ–ç‰ˆï¼‰ã€ã®æ¨è«–ã‚’è©¦ã—ã¾ã—ãŸã€‚
	- 4bité‡å­åŒ–ã§ã‚‚26GBã»ã©ã‚ã‚Šã¾ã™ã€‚Colab Proã®CPUã‚ªãƒ³ãƒªãƒ¼+ãƒã‚¤ãƒ¡ãƒ¢ãƒªã§å®Ÿè¡Œã—ã¦ã¿ã¾ã—ãŸã€‚GPUã®ã¿ã§æ¨è«–ã™ã‚‹ãªã‚‰A100ãŒå¿…è¦ã§ã™ã€‚
	- Colabã®CPUã ã¨ã•ã™ãŒã«é…ã„ã‚‚ã®ã®ã€æœ€è¿‘ã®PCã®CPUãªã‚‰ãµã¤ã†ã«å‹•ã‹ã›ãã†ã€‚Llama 34B/70Bã®é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã«æ¯”ã¹ã‚‹ã¨å…¨ç„¶é€Ÿã„ã§ã™
- LangChainã‚’ä½¿ã‚ãªã„
	- https://tech-blog.abeja.asia/entry/advent-2023-day13
	- æŠ€è¡“çš„è² å‚µã«ãªã‚Šã†ã‚‹ã¨ã‹ã€Agentã£ã¦function callã§ä»£æ›¿å¯èƒ½ã¨ã‹ãã†ã„ã†è©±
- LlamaIndex + Gemini
	- https://blog.llamaindex.ai/llamaindex-gemini-8d7c3b9ea97e
	- llamaindexã€ã„ããªã‚ŠGeminiãƒ•ãƒ«ã‚µãƒãƒ¼ãƒˆ
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/gemini.ipynb
	-  Multi-modal Modelä¸­ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€ã€ã€
-  Google Generative Language Semantic Retriever
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/managed/GoogleDemo.ipynb
	- Googleâ€™s new semantic retrieval endpoint offers specialized embeddings and LLMs for high-quality retrieval + synthesis with guardrails. Use it out of the box, OR combine it with LlamaIndex components to build advanced RAG.
	- The Gemini API contains semantic search with custom embedding models for better retrieval, as well as toggles incl. safety during generation.
	- GoogleãŒsemantic Retrieverã£ã¦ã®ã‚’ã ã—ã¦ãŸã®ã‹ï¼Ÿ
- LangChainã‚‚Geminiå¯¾å¿œ
	- https://python.langchain.com/docs/integrations/chat/google_generative_ai
	- Access Google AIâ€™s `gemini` and `gemini-vision` models, as well as other generative models through `ChatGoogleGenerativeAI` class in the [langchain-google-genai](https://pypi.org/project/langchain-google-genai/) integration package.
- Gemini Pro APIã®ä¾¡æ ¼è¡¨ã€
	- https://ai.google.dev/pricing?hl=ja
	- å…¥åŠ›ãŒ$0.00025/1k charactersãªã®ã§gpt-3.5-turbo-1106ã®1/4ã®ä¾¡æ ¼ï¼ˆã¤ã¾ã‚Š11æœˆä»¥å‰ã®gpt-3.5-turboã®1/12ï¼‰ã§ä½¿ãˆã‚‹ã‚‰ã—ã„ã€‚
	- ãƒ•ãƒªãƒ¼ç‰ˆãªã‚‰ã°ã€60QPM (queries per minute)ã¾ã§ã¯ä½¿ãˆã‚‹ï¼ï¼ï¼ï¼
- phi-2ã‚’è©¦ã™
	- https://x.com/npaka123/status/1735077608071876882?s=20
	- Llama2-70Bç›¸æ‰‹ã«ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§åœ§å‹ã—ãŸ2.7Bãƒ¢ãƒ‡ãƒ«ã€‚
	- https://huggingface.co/microsoft/phi-2
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªä½œã—ã‚ˆã†ï¼(Transformers+DeepSpeed+torch.compile+flash_attn2
	- https://zenn.dev/selllous/articles/transformers_pretrain_to_ft
	- è‹±èªãŒãƒ¡ã‚¤ãƒ³ã®LLM Mistral-7Bãƒ¢ãƒ‡ãƒ«ã‚’300M(0.3B)ã¸ãƒ€ã‚¦ãƒ³ã‚µã‚¤ã‚ºã—ã¦ã€pretraining + instruction tuningã‚’Colabä¸Šã®GPU T4(!!!)ã§6æ™‚é–“(0.02epoch)ã§æ—¥æœ¬èªå­¦ç¿’ã•ã›ã‚‹ã¨ã„ã†æ„æ¬²çš„ãªè¨˜äº‹
-  FunSearch: Making new discoveries in mathematical sciences using Large Language Models
	- https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/?utm_source=twitter&utm_medium=social
	- DeepMindã®ç ”ç©¶ãƒãƒ¼ãƒ ãŒã€AIã‚’ç”¨ã„ã¦æ•°å­¦ã®æœªè§£æ±ºå•é¡Œã«æŒ‘ã¿ã€ç§‘å­¦ç•Œã«ãŠã‘ã‚‹å‰ä¾‹ã®ãªã„æˆæœã‚’å‡ºã—ãŸã¨ç™ºè¡¨ã—ã¾ã—ãŸã€‚ ã€ŒFunSearchã€ã¨åä»˜ã‘ã‚‰ã‚ŒãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã€å•é¡Œè§£æ±ºç­–ã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å½¢ã§ç”Ÿæˆã€‚ã€Œã‚­ãƒ£ãƒƒãƒ—ã‚»ãƒƒãƒˆå•é¡Œã€ã¨ã€Œãƒ“ãƒ³ãƒ‘ãƒƒã‚­ãƒ³ã‚°å•é¡Œã€ã¨ã„ã†æ•°å­¦ã®å•é¡Œã«ãŠã„ã¦ã€æ–°ãŸãªè§£æ³•ã‚’ç™ºè¦‹ã—ãŸã¨ã®ã“ã¨ã§ã™ã€‚
	- Introducing FunSearch in @Nature: a method using large language models to search for new solutions in mathematics & computer science
	- DeepMindãŒLLMã‚’ã€Œäº‹å‰ã«ã‚¿ã‚¹ã‚¯è©•ä¾¡ã§ãã‚‹å•é¡Œã€ã«éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ„ã¿åˆã‚ã›ãŸFunSearch(searching in the function space)ææ¡ˆã€‚
	-  LLMãŒã‚³ãƒ¼ãƒ‰ç”Ÿæˆ->è©•ä¾¡->æ´—ç·´ã®ãƒ«ãƒ¼ãƒ—ã€‚ 
	- ** ç§‘å­¦,æ•°å­¦ã®æœªè§£æ±ºå•é¡Œã«å¯¾ã—ã¦ã€åˆã‚ã¦LLMã‚’ç”¨ã„ãŸæ–°ãŸãªç™ºè¦‹ **ã€‚ 
	- ãã®ä¾‹ã¨ã—ã¦cap set problem,bin-packing problemã€‚
-  Benchmarking RAG on tables
	- https://blog.langchain.dev/benchmarking-rag-on-tables/
	- llmaindexã‚ˆã‚Šã€ãƒ†ãƒ¼ãƒ–ãƒ«ã®ï¼²ï¼¡ï¼§ã«ã¤ã„ã¦ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€long contextã¯æ€§èƒ½ã¯ã§ãªã„
-  MOEè¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ä¸€äººã‚’æ—¥æœ¬èªå¾—æ„ãªãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆãŸã‚‰ã©ã†ãªã‚‹ã®ã‹ï¼Ÿ
	- https://note.com/aisatoshi/n/n6c06d5183517?sub_rt=share_pb
	- Mistral7Bã‚’8ã¤æŸã­ãŸã€Mixtral 8x7Bã¨ã„ã†MOEãƒ¢ãƒ‡ãƒ«
	- ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’ä½•äººã‹ã€æ—¥æœ¬èªãŒå¾—æ„ãªMistral7Bäº’æ›ãƒ¢ãƒ‡ãƒ«ã«å·®ã—æ›¿ãˆãŸã‚‰ã©ã†ã ã‚ã†ï¼Ÿ
	- æ³¨æ„æ©Ÿæ§‹ã ã‘ã€MLPå±¤ã ã‘ã€ã‚³ãƒ”ãƒ¼ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°ã‚’å¤‰æ›´ãªã©å®Ÿé¨“ã—ã¾ã—ãŸãŒã€åŸºæœ¬ãƒ¢ãƒ‡ãƒ«ãŒå£Šã‚Œã¾ã—ãŸ
- è‡ªæ°‘å…šãŒAIè¦åˆ¶ã‚’æè¨€
	- https://x.com/umiyuki_ai/status/1735277687097414124?s=20
- GCPã‚ˆã‚ŠGemeniã®æ§˜ã€…ãªåˆ©ç”¨æ–¹æ³•ã¨notebook
	- https://github.com/GoogleCloudPlatform/generative-ai
- Geminiã‚’ã¤ã‹ã£ã¦ã€ã‚¯ãƒªã‚¹ãƒã‚¹ã‚«ãƒ¼ãƒ‰ã‚’ä½œã‚‹ä¾‹ by google
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Prepare_Christmas_cards_with_Gemini_and_Sheets.ipynb
-  OpenAI thinks superhuman AI is coming â€” and wants to build tools to control it
	- https://openai.com/blog/superalignment-fast-grants
	- Open AIè¶…äººçš„ãªAIã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã«å‘ã‘ãŸç ”ç©¶ã«1000ä¸‡ãƒ‰ãƒ«ã®åŠ©æˆé‡‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–‹å§‹ã€‚ 
	- æ”¯æ´ã«Google CEOå…¼ä¼šé•·ã®ã‚¨ãƒªãƒƒã‚¯ãƒ»ã‚·ãƒ¥ãƒŸãƒƒãƒˆæ°ã€‚ 
	- ã‚¤ãƒªãƒ¤ã‚µãƒ„ã‚±ãƒãƒ¼æ°ä»Šã‚‚ã¾ã Super Alignmentãƒãƒ¼ãƒ ç‡ã„ã¦ã‚‹ã¨ã®ã“ã¨ï¼
-  A Guide on 12 Tuning Strategies for Production-Ready RAG Applications
	- https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439
	- LLMã®RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®12æˆ¦ç•¥ã‚’æ›¸ã„ãŸãƒ–ãƒ­ã‚°è¨˜äº‹ã€‚å…·ä½“çš„ã«ã¯ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã€åŸ‹è¾¼ã¿ã€ãƒãƒ£ãƒ³ã‚¯åŒ–ã€ã‚¤ãƒ³ãƒ‡ã‚¯ã‚·ãƒ³ã‚°ã€ã‚¯ã‚¨ãƒªå¤‰æ›ã€ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ç­‰ã€å®Ÿè·µçš„ãªæˆ¦ç•¥ã€‚
- Bishopå…ˆç”Ÿã®ã€ŒDeep Learning: Foundations and Conceptsã€
	- https://www.bishopbook.com/
	- Vision Language Modelã®ã¨ã“ã‚è¦‹ãŸã‚‰CM3LeonãŒè¼‰ã£ã¦ã¦é©šã„ãŸ
- Benchmarking Large Language Models As AI Research Agents
	- https://arxiv.org/abs/2310.03302
	- ã“ã®è«–æ–‡ãŒç´ æ™´ã‚‰ã—ã„ã®ã¯ã€open-ended ãªçŠ¶æ³ã§ç ”ç©¶ã‚’ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã„ã†ã‚³ãƒ³ã‚»ãƒ—ãƒˆã‚’æ˜ç¢ºã«æç¤ºã—ãŸç‚¹ã 
- calm2-7b-chatã‚’RAG QAã§ä½¿ã†ãŸã‚ã®èª¿æŸ»
	- https://x.com/_oshizo_/status/1735282188546089332?s=20
	- contextå…¨ä½“ã®é•·ã•ï¼ˆæ¨ªè»¸ï¼‰ã¨ã€æ­£è§£ã«ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä½ç½®ï¼ˆç¸¦è»¸ï¼‰ã‚’å¤‰ãˆãªãŒã‚‰ã€å‡ºåŠ›ã«æ­£è§£ã®æ–‡å­—åˆ—ã‚’å«ã‚“ã å‰²åˆã‚’é›†è¨ˆã€‚ 
	- æ­£è§£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒcontextã®æœ«å°¾ä»˜è¿‘ã«ã‚ã‚Œã°å…¨ä½“ã®é•·ã•ã¯ã‚ã¾ã‚Šå½±éŸ¿ã—ãªã„ãŒã€æœ«å°¾ã‹ã‚‰1ké›¢ã‚Œã‚‹ã”ã¨ã«æ­£ç­”ç‡ãŒ0.6æ›ã‘ã«ãªã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸
- LLMãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è©•ä¾¡ãƒ»ãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ã¤ã„ã¦ã¾ã¨ã‚ã¦ã¿ãŸ
	- https://zenn.dev/pomcho555/articles/8e42f0a4ce39eb
	- RAGASã‚’ä½¿ã£ãŸè‡ªå‹•ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
	- RAGASã‚’ä½¿ã£ãŸè‡ªå‹•è©•ä¾¡
- Web3æ™‚ä»£ã®ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ï¼Ÿ â€“ Geoã‚’è§¦ã£ã¦ã¿ãŸ
	- https://zenn.dev/s_egami/articles/4ec2e0de59ff4d
- "Pixel Aligned Language Models"
	- https://arxiv.org/abs/2312.09237
	- Googleã®ç ”ç©¶è€…ã‚‰ã¯ã€ç”»åƒã‚’ãƒ”ã‚¯ã‚»ãƒ«ãƒ¬ãƒ™ãƒ«ã§è¨€èªåŒ–ã™ã‚‹èƒ½åŠ›ã‚’ã‚‚ã¤LLMã€PALMã€é–‹ç™ºã—ã¾ã—ãŸ
	- å®Ÿé¨“ã®çµæœã€ã€ŒäººãŒç†è§£ã—ã‚„ã™ã„ã€å†…å®¹ã§æ­£ç¢ºã‹ã¤è©³ç´°ã«ç”»åƒã‚’èª¬æ˜ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ç¢ºèªã•ã‚Œã¾ã—ãŸ
-  æ—¥æœ¬ã®å¤å…¸å’Œæ­Œã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã§åˆ†æã™ã‚‹
	- https://note.com/yhkondo/n/nd321604729cd?sub_rt=share_pw
	- OpenAIã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä½¿ã£ã¦ã€ã€å¤ä»Šé›†ã€ã€ä¸‡è‘‰é›†ã€ã€å’Œæ¼¢æœ—è© é›†ã€ç­‰ã‚’åˆ†æã—ã€ã„ã‚ã‚†ã‚‹ã€ŒèŠ±é³¥é¢¨æœˆã€ã¨ã„ã†æ¦‚å¿µãŒã©ã“ã‹ã‚‰ç”Ÿã¾ã‚Œã¦ããŸã‹ã‚’æ¢æ±‚ã—ãŸã‚‚ã®ã§ã™ã€‚AIã®æŒã¤åŠ›ã‚’æ„Ÿã˜ã¦ã„ãŸã ã‘ã‚‹ã¨ç¢ºä¿¡ã—ã¦ã„ã¾ã™
-  Google Colab ã§ Gemini Pro ã‚’ã‚‚ã£ã¨è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n1c368639cada?sub_rt=share_h
	- 1.  2. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®è¡¨ç¤º
	- 2.  3. è³ªå•å¿œç­”
	- 3.  4. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
	- 4.  5. ãƒãƒ£ãƒƒãƒˆ
	- 5.  6. ç”»åƒã‹ã‚‰ã®è³ªå•å¿œç­”
	- 6.  7. ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®è³ªå•å¿œç­”
	- 7.  8. åŸ‹ã‚è¾¼ã¿ã®ç”Ÿæˆ
-  Voyager: An Open-Ended Embodied Agent with Large Language Models
	- https://arxiv.org/abs/2305.16291
	- LLMã‚’ã®ã›ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆã‚’ã•ã›ãŸç ”ç©¶ï¼Œé€²æ—ã®è§£é™¤å…·åˆã‚„ãƒãƒƒãƒ—ã®æ¢ç´¢ç¯„å›²ã®åºƒã•ã‚’ã¿ã¦ã„ã¦ï¼Œæ»…èŒ¶è‹¦èŒ¶é¢ç™½ã„ãªï½—ã€€ãƒ—ãƒ¬ã‚¤é¢¨æ™¯ã‚’ã¿ã¦ã¿ãŸã„
- mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- https://huggingface.co/mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- Mixtral-8x7B-Instruct-v0.1 ã®Expertsã®ã†ã¡2ã¤æ¯ã«mergeã—ã¦4x7bã«ã—ãŸå®Ÿé¨“ãƒ¢ãƒ‡ãƒ«ä½œã‚Šã¾ã—ãŸ
	- Modelã‚µã‚¤ã‚ºã¯24Bã«ãªã‚Šã¾ã™
- NeurIPS Large Language Model Efficiency Challenge:  1 LLM + 1GPU + 1Day
	- https://llm-efficiency-challenge.github.io/index
	- OSS LLMãƒ¢ãƒ‡ãƒ«ã‚’å…ƒã«é™ã‚‰ã‚ŒãŸè³‡æºãƒ»æ™‚é–“ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã™ã‚‹ã¨ã„ã†ã‚³ãƒ³ãƒš
	- é‡è¦ãªã®ã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
	- è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ä¸Šè³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹æˆã—è¨“ç·´ã™ã‚‹ã®ãŒéµ
- 
	


## 12/11

ä»Šé€±ã¯ãªã‚“ã¨ã„ã£ã¦ã‚‚ã€Googleã®Geminiã€‚GPT-4è¶Šãˆã¨ã‹ã€ã™ãã«Bard(è‹±èªç‰ˆï¼‰ã§Gemini Proã‚’è©¦ã›ã‚‹ã¨ã‹ã€ç ”ç©¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã—ã¦ä½¿ã†ãƒ‡ãƒ¢ã¨ã‹ã€ãã‚Œã‹ã‚‰ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’ãƒ•ãƒ«ã«ç”Ÿã‹ã—ãŸå­ä¾›å‘ã‘ã®ãŠéŠã³ãƒ‡ãƒ¢ã¨ã‹ãªã‹ãªã‹è¡æ’ƒçš„ã§ã‚ã£ãŸãŒã€ãªã‚“ã¨ãŠéŠã³ãƒ‡ãƒ¢ãŒç´™èŠå±…ï¼ˆéƒ¨åˆ†ã‚’ã¤ãªã’ã¦ãã‚Œã‚‰ã—ãè¦‹ãˆã‚‹ã‚ˆã†ã«ã—ãŸã€éƒ¨åˆ†éƒ¨åˆ†ã¯æœ¬ç‰©ã‚‰ã—ã„ãŒï¼‰ã¨ã®å ±é“ãŒã‚ã‚Šã€äº‹å‰ã®ã€Œï¼‘æœˆã«é…å»¶ã€ã¨ã®å ±é“ã¨åˆã‚ã›ã‚‹ã¨ç· ã‚åˆ‡ã‚Šã«é–“ã«åˆã‚ãªã‹ã£ãŸã‚“ã ã‚ã†ã‘ã©ã€å‰å›ã®BardãŠæŠ«éœ²ç›®ã§ã®å¤±æ…‹ã¨ã„ã„ã€è„‡ãŒç”˜ã„ã€‚ãªãŠGeminiã®å‘½åã®ç”±æ¥ã€ä¸Šä½ï¼–åã®ä¸»è¦è²¢çŒ®è€…ã®First Nameã‹ã‚‰ã¨ã£ãŸã‚‰ã—ã„ã€‚Mambaã¨ã„ã†ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒã®ä»£æ›¿æŠ€è¡“ã€æ€§èƒ½ã‚ˆã•ãã†ã§æœŸå¾…ã€‚ DeepMindã®ã€GNoMEã€ã¯ã€Œäººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®ææ–™ã‚’ç™ºè¦‹ã—ã€ç§‘å­¦ã®ç™ºå±•ã‚’LLMãŒæ˜ã‚‰ã‹ã«åŠ é€Ÿã™ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚ãã‚Œã£ã¦å±é™ºãªææ–™ã‚‚ã€‚ã€‚ã€‚Metaã¯å®‰å…¨ãªAIã®ãŸã‚ã®Purple LLamaã‚’ç™ºè¡¨ã€Securityã‚„å®‰å…¨ã‚¬ãƒ¼ãƒ‰ã‚’æä¾›ã€‚æ”»æ’ƒï¼ˆred)ã¨é˜²å¾¡(blue)ãŒå”åŠ›ã™ã‚‹ã‹ã‚‰Prupleãªã‚“ã ã£ã¦ã€‚å®‰å…¨ã‚¬ãƒ¼ãƒ‰(Llama Guard)ã¯LLMã§å®Ÿè£…ã•ã‚Œã€ã¤ã¾ã‚ŠLLMã«ã¯LLMã£ã¦ã“ã¨ã€‚Metaã¯IBMç­‰ã¨ã®ä¼æ¥­é€£åˆã§å®‰å…¨ãªOSSã¨ã—ã¦ã®ç”Ÿæˆå‹AIé–‹ç™ºã‚’ä¿ƒé€²ã€OSSã®LLMãŒã¾ã™ã¾ã™ç†±ããªã‚‹ï¼Ÿã€‚Appleã‹ã‚‰æ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯mlxç™ºè¡¨ã€M3ã£ã¦ã™ã”ã„ã‚“ã ã€LLMã§ã¯ä»Šä¸€æ­©ãƒ—ãƒ¬ã‚¼ãƒ³ã‚¹ã®ç„¡ã„Appleã€CNBCã®æ½œå…¥ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§ã‚‚ã€LLMç«¶äº‰ã«é€²å‡ºã™ã‚‹ã‹ã¨èã‹ã‚Œã¦ã€è²¬ä»»è€…ã¯ãƒ¢ã‚´ãƒ¢ã‚´ã¯ãã‚‰ã‹ã—ã¦ãŸãªã€ã‚ã‚„ã—ã•æº€è¼‰ã€‚NVIDIAã®H100ã€MSã¨Metaã¯ãã‚Œãã‚Œ150k(15ä¸‡å€‹ï¼‰ã‚’æŒã£ã¦ã„ã¦ãƒ€ãƒ³ãƒˆãƒ„ã€ã©ã†ã‚‚H100ãŒ15ä¸‡å€‹ã‚ã‚Œã°ï¼—æ—¥ã§GPT-4ãŒä½œã‚Œã‚‹æ€§èƒ½ã‚‰ã—ã„ã€‚ä¸€æ–¹AMDã‚‚ç”ŸæˆAIã§NVIDIA H100ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã®GPUã€ŒInstinct MI300ã€ã‚’ç™ºè¡¨ã€‚GPUã‚‚ç†±ã„ã€ã‚ã‚Œã‚‰ã®ç‰§é‡å…ˆç”Ÿã®MN-coreã®ç™»å ´ã‚’æœŸå¾…ã—ã¾ã™ã‹ã€‚ã¤ã„ã«æ¬§å·AIæ³•ãŒæˆç«‹ã€AIã®å®šç¾©ãŒï¼¯ï¼¥ï¼£ï¼¤ã®ãã‚Œã«æ•´åˆã—ãŸã¨ã‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹è¦åˆ¶ã®æ˜ç¢ºåŒ–ãŒãƒã‚¤ãƒ³ãƒˆã€‚ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã«ã©ã†å‚™ãˆã‚‹ã‹ãŒè‚ã€‚ãã®AIæ³•ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¸ã®è¦åˆ¶éƒ¨åˆ†ã«ç•°è­°ã‚’å”±ãˆã¦ã„ãŸä»MistralãŒã€æº€ã‚’æŒã—ã¦ï¼Ÿæ–°ã—ã„ mixtral-8x7b-32kseqlenã‚’ç™ºè¡¨ã€MoE(Mixture of Expert)ã¨ã„ã†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒè‚ã‚‰ã—ã„ã€æ¬§å·AIè¦åˆ¶ã«é–¢é€£ã—ã¦mixtral-8x7b-32kseqlenã‚’å¿µé ­ã«ã€ãŸã£ãŸ87Gã®weightã§AGIãŒæ¥ã‚‹ãªã‚‰AIè¦åˆ¶å¿…è¦ã ã‚ˆã­ã¿ãŸã„ãªæ„è¦‹ã‚‚è¦‹ã‹ã‘ãŸã€‚ã“ã®ã»ã‹ã«ã‚‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMå‘ã‘ã®Ollama ã¨ã‹ã€è¨€èªãƒ‡ãƒ¼ã‚¿ãªã—ã§å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLVMï¼‰ã‚’æ§‹ç¯‰ã¨ã‹ã€ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã®æ—¥æœ¬ãŒDXã§ããªã„ãƒ¬ãƒãƒ¼ãƒˆ(èª¤æ¤ã‚’ç™ºè¦‹ï¼)ã¨ã‹ã€2bité‡å­åŒ–æŠ€è¡“QuIP#ã¨ã‹ã€æ§˜ã€…ã‚ã£ãŸãŒè¿½ãˆã¦ãªã„ã€‚ã€‚ãã‚‚ãã‚‚ã€ï¼‘é€±é–“åˆ†ã®ãƒ–ã‚¯ãƒæ•´ç†ã™ã‚‹ã ã‘ã§ï¼’æ™‚é–“ã‹ã‹ã‚‹ã‚“ã ã‘ã©ã€‚ã€‚ã€‚GPT-4ã«ã‚„ã‚‰ã›ã‚‹ã‹ã€‚ã€‚

- ä»Šæœˆã®NatureèªŒã¯é¢ç™½ã‹ã£ãŸ
	- https://x.com/ykfrs1217/status/1731287315459490165?s=20
	- â‘  å¤§éƒ½å¸‚ã»ã©ã€ç•°ãªã‚‹ç¤¾ä¼šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ã²ã¨ãŸã¡ã¯æ··ã˜ã‚ã‚‰ãªã„ï¼ˆ[https://doi.org/10.1038/s41586-023-06757-3â€¦](https://t.co/tEkbdQOPG3)ï¼‰ 
	- â‘¡ åŒã˜ç”ºï¼ˆâ‰ƒå­¦å†…ï¼‰ã®ç ”ç©¶è€…ã ã‘ã§è¡Œã‚ã‚ŒãŸç ”ç©¶ã®æ–¹ãŒã€ç•°ãªã‚‹åœ°åŸŸé–“ã®å…±åŒç ”ç©¶ã‚ˆã‚Šã‚‚é©æ–°çš„ãªæˆæœãŒã§ã‚„ã™ã„ï¼ˆ[https://doi.org/10.1038/s41586-023-06767-1â€¦](https://t.co/jrBRV4Gxtk)ï¼‰
-  Phantom oscillations in principal component analysis
	- https://www.pnas.org/doi/10.1073/pnas.2311420120?utm_source=TOC&utm_medium=ealert&TOC_v120_i48=&ref=d4140497
	- æ™‚é–“çš„ãƒ»ç©ºé–“çš„ã«ã‚¹ãƒ ãƒ¼ã‚ºãªãƒ‡ãƒ¼ã‚¿ (ã»ã¨ã‚“ã©ã®ç”Ÿç†ãƒ‡ãƒ¼ã‚¿â€¦) ç­‰ã‚’ä¸»æˆåˆ†åˆ†æ PCA ã™ã‚‹ã¨ã€å½ã®ã‚ªã‚·ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒå‡ºç¾ã™ã‚‹
-  Refactoring Programs Using Large Language Models with Few-Shot Examples
	- https://arxiv.org/abs/2311.11690
	- ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«LLMã‚’ä½¿ã†
- "On Bringing Robots Home" Nur Muhammad Mahi Shafiullah et al., New York University
	- https://arxiv.org/abs/2311.16098
	- å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã®æ™®åŠã«å‘ã‘ã¦ã€ä¸€èˆ¬ã®ãƒ­ãƒœãƒƒãƒˆã‚’å„å®¶åº­ã«é©ç”¨ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€DobbÂ·Eã€ãŒé–‹ç™ºã•ã‚Œã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹
	- ä¸€èˆ¬ã®ãƒ­ãƒœãƒƒãƒˆã‚’å®¶åº­ç”¨ãƒ­ãƒœãƒƒãƒˆã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®ä¸€é€£ã®æµã‚Œã‚’ã‚«ãƒãƒ¼ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒã€DobbÂ·Eã€
	- â‘  åˆè¨ˆ109ã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿéš›ã®å®¶åº­ã§å®Ÿæ–½ã—ã€ãƒ­ãƒœãƒƒãƒˆã®æˆåŠŸç‡ãŒ81ï¼…ã«é”ã—ãŸ 
	- â‘¡ èª¿ç†å®¶é›»ã‚’é–‰ã‚ã‚‹ï¼ã‚¯ãƒƒã‚·ãƒ§ãƒ³ã‚’ã²ã£ãã‚Šè¿”ã™ã‚¿ã‚¹ã‚¯ã¯100ï¼…ã€6è»¸ã§ç‰©ã‚’ç§»å‹•ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯56% 
	- â‘¢ ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã«ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ãŸç…§æ˜ã‚„å½±ã®æ¡ä»¶ä¸‹ã§ã¯ãƒ­ãƒœãƒƒãƒˆã¯å®‰å®šã—ã¦ç¨¼åƒã™ã‚‹
- Introducing Llama Datasets 
	- https://blog.llamaindex.ai/introducing-llama-datasets-aadb9994ad9e
	- llamaindexã‚ˆã‚Šã€RAGå‘ã‘ã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å…¬é–‹
	- history of alexanetã¨ã‹ã€origin of covid19ãªã©ã®pdfã‚’å«ã‚€ã€å¤šåˆ†æ­£è§£å€¤ã¯ï¼Ÿ
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
	- https://arxiv.org/abs/2311.16079
	- llama2ã‚’åŒ»ç™‚ã«ç‰¹åŒ–ã—ã¦ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸLLM
	- Compared to closed-source LLMs, MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2.
	- webuiã§è©¦ã›ã‚‹ï¼
	- https://github.com/epfLLM/meditron/blob/main/deployment/README.md#serving-with-web-gui
- RAGç”¨é€”ã«ä½¿ãˆã‚‹ã€Wikipedia æ—¥æœ¬èªã® embeddings ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ã® faiss index ã‚’ä½œã£ãŸ
	- https://secon.dev/entry/2023/12/04/080000-wikipedia-ja-embeddings/
	- Wikipediaæ—¥æœ¬èª550ä¸‡æ–‡ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ãã‚‹embeddingsã¨æ¤œç´¢ç”¨faiss indexä½œã‚Šã¾ã—ãŸã€‚20è¡Œãã‚‰ã„ã‚³ãƒ¼ãƒ‰æ›¸ãã ã‘ã§ç°¡å˜ã«åˆ©ç”¨ã§ãã¾ã™ï¼RAGã—ã¦ã‚‚ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã¨é¢ç™½ã¿ãŒå°‘ãªã„ã®ã§ã™ãŒã€Wikipediaçªã£è¾¼ã‚€ã¨é¢ç™½ã•ãŒå¢—ãˆã¦ãã‚‹ã®ã§ã€èˆˆå‘³ã‚ã‚‹æ–¹ã¯ãŠè©¦ã—ãã ã•ã„ï¼
	- huggingface spaceã§è©¦ã›ã‚‹
	- https://huggingface.co/spaces/hotchpotch/wikipedia-japanese-rag-qa
	- ã€ŒãƒŠã‚¦ã‚·ã‚«ã¨æ£®ã®äººã¨ã®é–¢ä¿‚ã¯ï¼Ÿã€ã«ã¯å…¨ãç­”ãˆã‚‰ã‚Œãªã„ã€‚
	- FAISS+ELYZAã ã¨ã€ã€ŒãƒŠã‚¦ã‚·ã‚«ã¨æ£®ã®äººã¯ä»²è‰¯ã—ã ã£ãŸã€‚ã€ã¨ç­”ãˆã¦ãã‚ŒãŸã®ã«ã€‚ã€‚
- Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift
	- https://arxiv.org/abs/2311.15961
	- å…±å¤‰é‡ã‚·ãƒ•ãƒˆã®ãƒã‚¿ã§"All you need"çš„ãªæµè¡Œã‚Šã®ã‚¿ã‚¤ãƒˆãƒ«ã®è«–æ–‡ãªã‚“ã ã‘ã©ï¼Œå†…å®¹ã¯ã—ã£ã‹ã‚Šæ•°ç†ã‚„ã£ã¦ã‚‹ã£ã½ã„ï¼ãŒã£ã¤ã‚ŠShimodaira (2000)ã‚‚å‚ç…§ã•ã‚Œã¦ã¾ã—ãŸï¼å…±è‘—è€…ã«æ•°ç†çµ±è¨ˆã®å¤§å¾¡æ‰€ã®Jianqing Fanå…ˆç”Ÿã¨ã‹ï¼Œæ©Ÿæ¢°å­¦ç¿’ã®ç†è«–ç³»ã®Chi Jinå…ˆç”Ÿãªã©
- Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation
	- https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2
	- Check out this fantastic blog covering the basics of RAG, the theory behind it, and how to use it in practice
- Mamba: Linear-Time Sequence Modeling with Selective State Spaces
	- https://arxiv.org/abs/2312.00752
	- ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚„æ³¨æ„æ©Ÿæ§‹ã«é ¼ã‚‰ãªã„ã€ç·šå½¢æ™‚é–“ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã®ãŸã‚ã®æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
	- 2å€ã‚µã‚¤ã‚ºã®Transformersã«åŒ¹æ•µã—ãŸã‚Šã€5å€ã®é«˜é€Ÿæ¨è«–ãŒå‡ºæ¥ãŸã‚Šã¨ã€Transformerã‚’ä»£æ›¿ã—ã†ã‚‹å¯èƒ½æ€§
	- 2.8BãŒå‡ºã¦ã‚‹ã‚‰ã—ã„ã€
	- https://huggingface.co/state-spaces/mamba-2.8b
-  Instruction-tuning Aligns LLMs to the Human Brain
	- https://arxiv.org/abs/2312.00575
	- Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain.
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã®å¿œç”¨å‹•å‘ã®è«–æ–‡èª¿æŸ»
	- https://speakerdeck.com/masatoto/marutimodarullmnoying-yong-dong-xiang
- ç”Ÿæˆæ–‡æ³•ç ”ç©¶è€…ã®ä¸­ã§ã€Œè¨€èªã®æœ¬è³ªã€ï¼ˆä»Šäº•å…ˆç”Ÿï¼‰ã®è©•åˆ¤ãŒè‰¯ããªã‹ã£ãŸ
	- https://x.com/kkling51/status/1731543891348996466?s=20
	- (i) ã‚¢ãƒ–ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æ¨è«–ã¯é©åˆ‡ãªæ¨è«–ã§ã¯ãªã„ã‹ã‚‰ãã‚Œã«é ¼ã‚‹ã¹ãã§ã¯ãªã„ 
	- (ii) è¨€èªã¨ã¯ä½•ã‹ã¨ã„ã†å®šç¾©ãŒãªã„ãŸã‚ï¼Œæœ¬è³ªãŒä½•ãªã®ã‹åˆ†ã‹ã‚‰ãªã„ï¼
	- ãƒ—ãƒ©ãƒˆãƒ³ã®å•é¡Œã‚‚æœªè§£æ±ºã®ãƒãƒ
- Amil Merchant et al., "Scaling deep learning for materials discovery", nature
	- https://www.nature.com/articles/s41586-023-06735-9
	- DeepMindã®ã€GNoMEã€ãŒã€Œäººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®ææ–™ã‚’ç™ºè¦‹ã—ã€ã†ã¡736ã¯æ—¢ã«äººé–“ãŒå®Ÿé¨“å®¤ã§å†ç¾ã—ãŸã¨ã®å ±å‘Š
	- å¤§è¦æ¨¡ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨å…ˆé€²çš„ãªæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹æ‰‹æ³•ã«ã‚ˆã‚‹ã€ãƒãƒ†ãƒªã‚¢ãƒ«ã‚ºã‚¤ãƒ³ãƒ•ã‚©ãƒãƒ†ã‚£ã‚¯ã‚¹ã®ç™ºå±•äº‹ä¾‹ã§ã™
	- æ–¹æ³•
		- â‘  GNNã‚’ç”¨ã„ã¦ç´ æã®ç‰¹æ€§ã‚’æ§‹é€ ã‚„çµ„æˆã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«åŒ–
		-  â‘¡ ææ–™ç™ºè¦‹ã®åŠ¹ç‡ãŒå¤§å¹…ã«å‘ä¸Šã—ã€äººé–“ã®ç›´æ„Ÿã‚’è¶…ãˆãŸ220ä¸‡ã®æ§‹é€ ãŒç™ºè¦‹ã•ã‚ŒãŸ 
		- â‘¢ çµæ™¶æ§‹é€ å†…ã®åŸå­ã‚’ç½®æ›ã™ã‚‹æ‰‹æ³•ã‚„ãƒ©ãƒ³ãƒ€ãƒ ãªæ¢ç´¢ã‚’å«ã‚€ã€å¤šæ§˜ãªå€™è£œç”Ÿæˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¢ºç«‹
	- çµæœ
		- â‘  220ä¸‡ã®æ–°ãŸãªå®‰å®šæ§‹é€ ã‚’ç‰¹å®šã—ã€ãã‚Œã‚‰ã®å¤šãã¯æ—¢å­˜ã®åŒ–å­¦çš„ç›´æ„Ÿã‚’è¶…ãˆã¦ã„ãŸ 
		- â‘¡ ç™ºè¦‹ã•ã‚ŒãŸå®‰å®šæ§‹é€ ã®ã†ã¡736ã¯ã€ç‹¬ç«‹ã—ãŸå®Ÿé¨“ã§å®Ÿç¾ã•ã‚Œã¦ã„ã‚‹ ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸Šã§ã®æ¤œè¨¼ã§ã¯ãªãã€å®Ÿé¨“å®¤ã§ç‰©ç†çš„ã«ææ–™ã‚’ä½œæˆã—ã€å®Ÿè¨¼ã§ããŸï¼‰
- NVIDIAã®H100ã‚’ã©ã“ã«å‡ºè·ã—ãŸã‹ã®å›³ã€‚MS,MetaãŒåœ§å€’çš„ã«å¤šã„ã€GPT4ã‚’7æ—¥ã§è¨“ç·´ã§ãã‚‹è¦æ¨¡ï¼Ÿ
	- https://x.com/Lauramaywendel/status/1731698695853244849?s=20
	- GPT4 was presumably trained for around 90 days using 25k A100 GPUs. Microsoft and Meta having reportedly bought 150k H100 GPUs each this year, can now train a GPT4 class model in only 7 days from scratch
- Google Geminiã®æä¾›ã‚’ï¼‘æœˆã¾ã§å»¶æœŸ
	- https://x.com/rowancheung/status/1731531903193219260?s=20
	- ã„ãã¤ã‹ã®åˆ†é‡ã§ã¯GPT-4ã‚’ä¸Šå›ã‚‹ã‚‚ã€è‹±èªä»¥å¤–ã§ã®æ€§èƒ½ãŒå‡ºãªã„ã€‚
	- ã“ã‚Œã£ã¦ã€å¾Œã‹ã‚‰ç¶šãã‚¤ãƒ™ãƒ³ãƒˆã®äºˆå…†ã‹ã—ã‚‰ã‚“ã€
- ã‚ã‚‹ç‰©ç†å­¦ã®æœ¬ã§ã€ã‚®ãƒªã‚·ãƒ£èªã®èª¬æ˜è¡¨ã§ã‚¼ãƒ¼ã‚¿ã®ã¨ã“ã‚ãŒã€ã€
	- https://x.com/yori_Alphard/status/1731663363737026586?s=20
	- "Zã‚¬ãƒ³ãƒ€ãƒ "ã«ãªã£ã¦ã„ã‚‹ã€‚ã€‚
- GIVT: Generative Infinite-Vocabulary Transformers
	- https://huggingface.co/papers/2312.02116
	- æœ¬å½“ã«ãƒˆãƒ¼ã‚¯ãƒ³ãŒé›¢æ•£ã§ãªãã¦ã€ç„¡é™ãªã®ã ã‚ã†ã‹ï¼Ÿ
- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ä¸è¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã ã‘ã§ã©ã†ã«ã‹ãªã‚‹ï¼Ÿ
	- https://x.com/IntuitMachine/status/1732089266883141856?s=20
	- A recent research paper provides compelling evidence that the extensive fine-tuning used to "align" large language models into helpful assistants may be largely unnecessary.
	- Allenã‚¤ãƒ³ã‚¹ãƒ†ã‚£ãƒ†ãƒ¥ãƒ¼ãƒˆã®ä»•æ¥­ã‹ã€https://allenai.org/
- llamaindexã§ã‚‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãŒç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€Webinerãªã©
	- https://x.com/llama_index/status/1732081850246627547?s=20
	- https://lu.ma/350wf7v7
- å®‰å…¨ã§è²¬ä»»ã‚ã‚‹AIã®é–‹ç™ºå‘ã‘ã¦ã€Metaã¨IBMãŒææº
	- https://ai.meta.com/blog/ai-alliance/
	- IBM ã¨ãƒ¡ã‚¿ã¯ã€*ã‚ªãƒ¼ãƒ—ãƒ³*ã§ä¿¡é ¼æ€§ã®é«˜ã„ AI ã‚’æ¨é€²ã™ã‚‹ãŸã‚ã« AI Alliance ã‚’ç«‹ã¡ä¸Šã’ã¦ã„ã¾ã™ã€‚ ç”£æ¥­ç•Œã€æ”¿åºœæ©Ÿé–¢ã€å­¦ç•Œã‹ã‚‰ã® 50 ã‚’è¶…ãˆã‚‹è¨­ç«‹ãƒ¡ãƒ³ãƒãƒ¼ã®ãƒªã‚¹ãƒˆã«ã¯ã€AMDã€Anyscaleã€CERNã€Hugging Faceã€Linux Foundationã€NASA ãŒå«ã¾ã‚Œã¾ã™ã€‚
	- æ—¥çµŒã«ã‹ã‹ã‚‹ã¨ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€ã€Œãƒ¡ã‚¿ã¨IBMã€ç”ŸæˆAIã€Œã‚ªãƒ¼ãƒ—ãƒ³å‹ã€ã¸ã€€50ç¤¾ãƒ»å›£ä½“ã¨é€£æºã€
- Prompting vs RAGs vs Fine-tuning:
	- https://x.com/akshay_pachaar/status/1732014719794585684?s=20
	- ã‚ˆãã‚ã‚‹ï¼”è±¡é™ã®çµµã€
	- So finetuning is more about changing structure (behaviour) than knowledge, while it's other way round for RAGs.
	- You use RAGs when you want to generate outputs grounded to a custom knowledge base while the vocabulary & writing style of the LLM remains same.
	- If you don't need either of them, prompt engineering is the way to go.
	- And if your application need both custom knowledge & change in the behaviour of model a hybrid (RAGs + Finetuning) is preferred.
- OpenAIã®Safety System Teamsã‹ã‚‰
	- https://openai.com/safety/safety-systems
	- å”åŠ›ã®ãŠé¡˜ã„
- PyTorchãŒå‡ºã—ãŸã€gpt-fastã¯ã™ã”ã„ã‚‰ã—ã„
	- https://x.com/AlphaSignalAI/status/1732116360162050099?s=20
	- Pytorch just released GPT-Fast, an implementation of transformer text generation with everything you need in <1000 lines of code.
	- https://github.com/pytorch-labs/gpt-fast
- Windows11ã«copilotãŒé™è‡¨ï¼Ÿ
	- https://www.microsoft.com/en-us/windows/copilot-ai-features?r=1
- JWT(Json Web Token)
	- https://x.com/alexxubyte/status/1732077250626179578?s=20
- Jellyfish: A Large Language Model for Data Preprocessing
	- https://arxiv.org/abs/2312.01678
	- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‚’å¾—æ„ã¨ã™ã‚‹LLMã€Jellyfishï¼ˆã‚¯ãƒ©ã‚²ï¼‰ã€ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚ æœªçŸ¥ã®ã‚¿ã‚¹ã‚¯ã«ã‚‚å¯¾å¿œã§ãã€æ¯”è¼ƒçš„è»½é‡ã§ã‚ã‚Š1GPUã§ã‚‚å‹•ä½œã™ã‚‹ã¨ã®ã“ã¨ã§ã™ã€‚ 
	- å¤§é˜ªå¤§å­¦ã€NECã€åå¤å±‹å¤§å­¦ã®ç ”ç©¶è€…ã‚‰ã«ã‚ˆã‚‹ç™ºè¡¨ã§ã™
	- â‘  ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ãŒé€²åŒ– ï¼ˆGPT-4ã¨åŒç­‰ã®æ€§èƒ½ã§ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’è¡Œã†ï¼‰ 
	- â‘¡ ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆã§ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ 
	- â‘¢ å¤šæ§˜ãªå‰å‡¦ç†ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œ 
	- â‘£ ã‚µã‚¤ã‚ºãŒå°ã•ã„ãŸã‚ã€1GPUã§ã‚‚å‹•ä½œã™ã‚‹
- GooglãŒGemini(ã‚¸ã‚§ãƒãƒŠã‚¤ã¨èª­ã‚€ï¼‰ã‚’ç™ºè¡¨
	- https://blog.google/technology/ai/google-gemini-ai/
	- 1. Geminiã¯3ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«(Ultra, Pro, Nano)ãŒå­˜åœ¨ã€‚UltraãŒæœ€ã‚‚è³¢ãã€Nanoã¯ãƒ¢ãƒã‚¤ãƒ«ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã€‚
	- 2. Ultraã¯æ•°ã€…ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT-4è¶…ãˆã®æ€§èƒ½ã‚’ç™ºæ® (ï¾„ï¾ï¾”ï½§)
	- 3. Geminiã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã«å¼·ã„ã€‚å‹•ç”»ãƒ‡ãƒ¢ã®ã‚ˆã†ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã‚‚å¯èƒ½ã€‚ 
	- 4. æœ¬æ—¥ã‚ˆã‚ŠBardã¯Gemini Proã®Fine-tuningãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åˆ©ç”¨ã—ã¦å…¬é–‹ã™ã‚‹ã€‚ãã®ä»–ã«ã‚‚Googleè£½å“ã¸ã®å°å…¥ã‚’é€²ã‚ã‚‹ã€‚ 
	- 5. Gemini APIã¯12æœˆ13æ—¥ã‹ã‚‰Google AI Studioã‚’é€šã˜ã¦æä¾›ã•ã‚Œã‚‹ã€‚
	- https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
- Google AlphaCode 2 ã‚’ç™ºè¡¨
	- AlphaCode 2 Technical Report
	- https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf
	- Geminiã‚’ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ç”¨ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸAlphaCode2ã¯ã€ç«¶æŠ€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°äººå£ã®ä¸Šä½15%ã®æ€§èƒ½
- Metaã®Streamingã®ç¿»è¨³æ€§èƒ½ã¯ã™ã”ã„ã‚‰ã—ã„ã€	
	- https://x.com/hokazuya/status/1732374854027132940?s=20
	- ç¿»è¨³ã“ã‚“ã«ã‚ƒããƒ¬ãƒ™ãƒ«
- Bardã®ç”Ÿæˆè¨˜äº‹ã¯ChatGPTã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ï¼Ÿ
	- https://x.com/kajikent/status/1732237182126129578?s=20
	- ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®é ˜åŸŸã§æœ‰åãªNeil Patelæ°ãŒç´„250ãšã¤ã®ChatGPTç”Ÿæˆã®è¨˜äº‹ã¨Google Bardç”Ÿæˆã®è¨˜äº‹ã§èª­è€…ã«ã©ã¡ã‚‰ãŒå¥½ãã‹èã„ãŸã¨ã“ã‚ã€BardãŒåœ§å‹ã™ã‚‹çµæœã«
- äººé–“ãƒ¬ãƒ™ãƒ«ã®AI(AGI)ã«åˆ°é”ã™ã™ã‚‹ã«ã¯ã€å¸¸ã«10å¹´ä»¥ä¸Šå¿…è¦
	- https://x.com/ylecun/status/1732391273611370931?s=20
	- 3ï½5å¹´ã¯å¸¸ã«å¿…è¦ï¼ˆæ°¸é ã«é”æˆã§ããªã„ï¼‰ã¨ã®è¨˜äº‹ã«Lecanå…ˆç”Ÿã®åå¿œ
- Appleè£½å“Mã‚·ãƒªãƒ¼ã‚ºã«æœ€é©åŒ–ã•ã‚ŒãŸæ·±å±¤å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯mlx
	- https://x.com/goto_yuta_/status/1732287555599741103?s=20
	-  Macã«æ­è¼‰ã•ã‚Œã¦ã‚‹GPU(MPS)ãŒã‚ˆã‚Šæœ‰åŠ¹æ´»ç”¨ã•ã‚Œã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã®é«˜é€Ÿæ¨è«–ãŒå¯èƒ½ã«ãªã£ãŸã‚‰å¬‰ã—ã„ãªã€‚
	- CNBCã®ã€Apple Labã¸ã®æ½œå…¥ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
	- https://www.youtube.com/watch?v=UdhWvg5mycY
- Geminiã®Technical reportã‚’æ—¥æœ¬èªã§è§£èª¬ã—ã¦ã„ã‚‹äººãŒç™»å ´
	- https://x.com/bioshok3/status/1732421662619140551?s=20
	- Gemini Ultraã¯ã€MMLU ã§äººé–“ã®å°‚é–€å®¶ã®æ€§èƒ½ã‚’é”æˆã—ãŸæœ€åˆã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã‚¹ã‚³ã‚¢ã¯90%ä»¥ä¸Šã€‚ã‚„ã°ã™ãã‚‹ã€‚äººé–“ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è‘—è€…ã«ã‚ˆã£ã¦89.8%ã¨è©•ä¾¡ã•ã‚Œã€Gemini Ul traã¯ã“ã®é–¾å€¤ã‚’è¶…ãˆãŸæœ€åˆã®ãƒ¢ãƒ‡ãƒ«!æ™‚ä»£ãŒå¤‰ã‚ã£ãŸã€‚
	- æ•™å¸«ãŒã‚¹ã‚­ãƒ¼ãƒ¤ãƒ¼ãŒå‚é“ã‚’ä¸‹ã‚Šã‚‹ã¨ã„ã†ç‰©ç†å•é¡Œã‚’æãã€ç”Ÿå¾’ãŒãã®è§£æ±ºç­–ã‚’ç·´ã‚‹ã€‚Geminiã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–æ©Ÿèƒ½ã‚’ç”¨ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¯ ä¹±é›‘ãªæ‰‹æ›¸ãã‚’ç†è§£ã—ã€ç”Ÿå¾’ãŒå•é¡Œã®è§£æ±ºã‚’é–“é•ãˆãŸæ¨è«–ã®ç‰¹å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç‰¹å®šã—ã€å•é¡Œã®æ­£ã—ã„è§£æ±ºã‚’é€šã— ã¦ä½œæ¥­ã‚’ä¸ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
	- Google ãŒGeminiã®ãƒ‡ãƒ¢å‹•ç”»ã‚’å‡ºã—ã¦ã„ã‚‹ã‘ã©ã€ã“ã‚Œã»ã‚“ã¨ã«ã“ã®æ¨è«–é€Ÿåº¦ãªã‚‰å‡„ã™ãã‚‹ã¨è¨€ã†ã‹ã‚‚ã†æ ªä¾¡æ•°å€ãã‚‰ã„ã«ãªã‚‹ã‚“ã˜ã‚ƒãªã„ã®ï¼Ÿã£ã¦ãƒ¬ãƒ™ãƒ«ã ã‘ã©ï¼Ÿï¼Ÿ
	- ãƒ‡ãƒ¢ã«ã¤ã„ã¦ã¯ã€Œã“ã®ãƒ‡ãƒ¢ã®ç›®çš„ã®ãŸã‚ã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã¯çŸ­ç¸®ã•ã‚Œã€ã‚¸ã‚§ãƒŸãƒ‹ã®å‡ºåŠ›ã¯ç°¡æ½”ã«ã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã€ã¨æ›¸ã‹ã‚Œã¦ã‚‹
	- å¤šè¨€èªæ€§èƒ½ã¯GPT-4ã‚ˆã‚Šè‰¯ã„
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ã¯32768ã€‚98%ã®ç²¾åº¦ã§æ­£ã—ã„å€¤ã‚’å–å¾—å¯èƒ½ï¼98%?ã¾ã˜ã‹ã‚ˆã€‚
- Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®è¨€èªè¨­å®šã‚’è‹±èªã«ã™ã‚‹ã¨ã€Bardã®ãƒãƒƒã‚¯ãŒGemimi ProãŒä½¿ãˆã‚‹
	- https://x.com/npaka123/status/1732504570218283340?s=20
- Bard(Gemini Pro)ãŒéœãŒé–¢ãƒ‘ãƒ¯ãƒã‚’è§£æã—ã¦èª¬æ˜ã—ã¦ãã‚Œã‚‹ã¨ã€ã€	by ã‚†ãªå…ˆç”Ÿ
	- https://x.com/JapanTank/status/1732689643928445164?s=20
- Geminiè«–æ–‡ã®æœ€å¾Œã®ã€"Core Contributors"ã®æœ€åˆã®ï¼–äººã®é ­æ–‡å­—ã‚’ã¨ã‚‹ã¨ã€"GEMINI"ã«ãªã‚‹
	- https://x.com/nearcyan/status/1732532560029172142?s=20
- Metaã‚ˆã‚Šã€å®‰å…¨ãªAIã®ãŸã‚ã®ã€Purple Llamaï¼ˆãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¿ãŸã„ãªã‚‚ã®ï¼‰ã‚’ç™ºè¡¨
	- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=image
	- CyberSec Evalã¨ã‹ã€Llama GuardãŒæœ€åˆã«å‡ºã‚‹
	- ãªã‚“ã§purpleã‹ã¨ã„ã†ã¨æ”»æ’ƒå´ï¼ˆèµ¤ï¼‰ã¨ã€é˜²å¾¡å´ï¼ˆé’ï¼‰ãŒå”åŠ›ã—ã¦æ§‹ç¯‰ã—ãŸã‹ã‚‰
	- attack (red team) and defensive (blue team) postures.
	- Colabã§è©¦ã›ã‚‹ã‚‰ã—ã„
	- https://colab.research.google.com/drive/16s0tlCSEDtczjPzdIK3jq0Le5LlnSYGf?usp=sharing
- Evaluating and Mitigating Discrimination in Language Model Decisions
	- https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions
	- Anthropicã‚ˆã‚Šã€ï¼ˆLLMã®å‡ºåŠ›ã«ãŠã‘ã‚‹ï¼‰å·®åˆ¥ã‚’æ¤œçŸ¥ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹
-  AMDã€ç”ŸæˆAIã§NVIDIA H100ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã®GPUã€ŒInstinct MI300ã€
	- https://pc.watch.impress.co.jp/docs/news/1552583.html
	- TDP 750Wã®MI300Xã¯ã€TDP 700Wã®NVIDIA H100ã¨æ¯”è¼ƒã—ã€FP64,32ã§ç´„2.4å€ã€AIã§åˆ©ç”¨ã®TF32ã€FP16ã€BF16ã€FP8ã€INT8ãªã©ã§ã¯1.3å€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆå®Ÿç¾ã€‚
- èµ¤çŸ³å…ˆç”Ÿã®ãƒ™ã‚¤ã‚ºæ¨è«–æœ¬ãŒã‚ã‹ã‚Šã‚„ã™ã„ã¨è©•åˆ¤ã«
	- https://x.com/kenken26679105/status/1732977179485757744?s=20
	- å°‘ãªã„ãƒ‡ãƒ¼ã‚¿é‡ã§ã‚‚ã€ã“ã‚“ãªé¢¨ã«ã€è‰²ã‚“ãªå®Ÿå‹™ã®å ´é¢ã«ã™ãã«æ´»ç”¨ã§ãã¡ã‚ƒã†
	- Pythonã§ã‚¹ãƒ©ã‚¹ãƒ©ã‚ã‹ã‚‹ ãƒ™ã‚¤ã‚ºæ¨è«–ã€Œè¶…ã€å…¥é–€ (KSæƒ…å ±ç§‘å­¦å°‚é–€æ›¸)
- ãƒãƒ§ãƒ ã‚¹ã‚­ãƒ¼ã®ã€Œç”Ÿæˆæ–‡æ³•ã€ã¯æ­»ã‚“ã ã¨ã„ã†è«–æ–‡
	- Modern language models refute Chomskyâ€™s approach to language
	- https://lingbuzz.net/lingbuzz/007180/v1.pdf
	- æœ€è¿‘ã®ç”ŸæˆAIã¦ã†ã‹å¤§è¨€èªãƒ¢ãƒ‡ãƒ«LLMã®é©šãã¹ãæˆåŠŸã‹ã‚‰è¦‹ã¦ã€ãƒãƒ§ãƒ ã‚¹ã‚­ãƒ¼æµã®ç”Ÿå¾—çš„çµ±èªæ³•è¦å‰‡ãŒã‚ã‚‹ã¨ã„ã†èª¬ã¯ç¶­æŒã—ã¥ã‚‰ã„
- llamaindexã‚ˆã‚Šã€çŸ¥è­˜ã‚°ãƒ©ãƒ•(KG)ã‚’ä½¿ã†ã€ï¼—ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ã«ã¾ã¨ã‚ã¦ãã‚ŒãŸ
	- https://x.com/llama_index/status/1733190430760845673?s=20
	-  A Simpler Way to Query Neo4j Knowledge Graphs
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/neo4j_query_engine/llama_packs_neo4j.ipynb
- æ¬§å·AIæ³•ã®æœ€çµ‚ãƒˆãƒªãƒ­ãƒ¼ã‚°ãŒçµ‚äº†ã€å¦¥çµã¸
	- https://x.com/WIRED/status/1733268732309332398?s=20
	- https://www.reuters.com/technology/eu-clinches-deal-landmark-ai-act-2023-12-09/?taid=65745dd360152800018aaf1c&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter
	- https://twitter.com/SabrinaKuespert/status/1733311752941515135/photo/1
	- https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?xtor=AD-78-[Social_share_buttons]-[twitter]-[en]-[news]-[pressroom]-[artificial-intelligence-act-possible-deal]-
	- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§è¦åˆ¶ã•ã‚Œã‚‹ã®ã¯ã€è¨ˆç®—é‡ãŒ10^25FLOPsã‚’è¶…ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã€‚
	- è©²å½“ã™ã‚‹ã®ã¯ä»Šã‚“ã¨ã“GPT-4ã¨Geminiã‚ãŸã‚Šã€‚
	- ãã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã«å¿œã˜ã¦åˆ†é¡ã•ã‚Œã‚‹ã€‚
	- ã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã¯ãƒ¢ãƒ‡ãƒ«ãŒã©ã‚“ã ã‘å¼·åŠ›ã‹ã€ã©ã‚“ã ã‘ã®äººãŒä½¿ã†ã‹ã§æ±ºã¾ã‚‹ã€‚
	- è¦åˆ¶ã®å†…å®¹ã¯
		- â‘ ãƒªã‚¹ã‚¯ã®è»½æ¸›ã‚’è¡Œã†ã€€
		- â‘¡ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã€æ•µå¯¾çš„ãƒ†ã‚¹ãƒˆã‚’å®Ÿæ–½ã™ã‚‹ã€€
		- â‘¢ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®ç›£è¦–ã‚’ã™ã‚‹ã€€
		- â‘£ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã•ã›ã‚‹ã€€
		- â‘¤ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œã‚‰ã›ã‚‹
-  Generative AI for Everyoneã‹ã‚‰ã€å¤ã®NLPã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¿ƒã«åˆºã•ã£ãŸã“ã¨8é¸
	- https://note.com/csstudyabroad/n/n5aba3a708f3a
- "Purple Llama CyberSecEval: A benchmark for evaluating the cybersecurity risks of large language models"
	- LLama Purpleé–¢é€£ã® CyberSecEvalã®è«–æ–‡
	- https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/
	- Metaã®ç ”ç©¶è€…ã‚‰ã¯ã€LLMãŒç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã«ãŠã‘ã‚‹ä¸å®‰å®šæ€§ã‚„ä¹±ç”¨ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚
	-  å®Ÿé¨“ã®çµæœã€ç¾åœ¨ã¯ã€èƒ½åŠ›ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã»ã©ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã™ã‚‹å‚¾å‘ãŒå¼·ã„ã¨ã„ã†é€†èª¬çš„ãªçµæœã‚‚å‡ºã¦ãã¾ã—ãŸã€‚
	- â‘  å…¨ä½“çš„ã«LLMã¯ã€30%ã®ã‚±ãƒ¼ã‚¹ã§ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ãŸ 
	- â‘¡ 53%ã®ã‚±ãƒ¼ã‚¹ã§ã€ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒã®æ‰‹ä¼ã„ã‚’ã™ã‚‹ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã—ã¦LLMãŒå¿œã˜ãŸ
	-  â‘¢ ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ›ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã»ã©ã€ä¸å®‰å…¨ãªã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã™ã‚‹å‚¾å‘ãŒå¼·ã‹ã£ãŸ
- "Sequential Modeling Enables Scalable Learning for Large Vision Models"
	- https://arxiv.org/abs/2312.00785
	- ã€Œè¦–è¦šã¯æœ¬æ¥ã€è¨€èªã«ä¾å­˜ã—ãªã„ã€ã¨è€ƒãˆãŸUCãƒãƒ¼ã‚¯ãƒ¬ãƒ¼ã¨ã‚¸ãƒ§ãƒ³ã‚¹ãƒ›ãƒ—ã‚­ãƒ³ã‚¹å¤§å­¦ã®ç ”ç©¶è€…ã‚‰ã¯ã€è¨€èªãƒ‡ãƒ¼ã‚¿ãªã—ã§å¤§è¦æ¨¡ãƒ“ã‚¸ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆLVMï¼‰ã‚’æ§‹ç¯‰ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- â– ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®è©³ç´° 
		- â‘  ç”»åƒã‚„å‹•ç”»ã‚’è¡¨ç¾ã™ã‚‹ã€Œãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«æ–‡ã€ã‚’å®šç¾© ï¼ˆãƒ”ã‚¯ã‚»ãƒ«ä»¥å¤–ã®ãƒ¡ã‚¿æƒ…å ±ã¯ãªã„ï¼‰ 
		- â‘¡ è¦–è¦šãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ– 
		- â‘¢ è‡ªå·±å›å¸°å‹ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
	- â– å®Ÿé¨“ã®çµæœã‚ã‹ã£ãŸã“ã¨ 
		- â‘  ãƒ¢ãƒ‡ãƒ«ã¯å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã—å­¦ç¿’ã™ã‚‹èƒ½åŠ›ãŒé«˜ã„
		-  â‘¡ æ§˜ã€…ãªãƒ“ã‚¸ãƒ§ãƒ³ã‚¿ã‚¹ã‚¯ã§æœ‰åŠ¹ 
		- â‘¢ ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ã€ä¸‹æµã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã™ã‚‹
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- Scenarios of adopting LLMs, techniques for utilizing LLMs on graphs, applications, #opensource code repositories, benchmark datasets
- ã€Œ2030 æ—¥æœ¬ãƒ‡ã‚¸ã‚¿ãƒ« æ”¹é©ã€ by ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼
	- https://www.digitaljapan2030.com/_files/ugd/c01657_fcaed21f58bb4c429cb460ce788b82c4.pdf
	- ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå…¨140ãƒšãƒ¼ã‚¸ï¼‰
	- æ—¥æœ¬ã®ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–ãŒãªãœé…ã‚ŒãŸã®ã‹ã€ãã‚Œã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªæ‰“ã¡æ‰‹ãŒå–ã‚Œã‚‹ã®ã‹ã€ã¨ã„ã†ã“ã¨ãŒåˆ†ã‹ã‚Šã‚„ã™ãæ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚ 
	- æ—¥æœ¬ã®ç·åŠ´åƒæ™‚é–“ã®56%ãŒè‡ªå‹•åŒ–å¯èƒ½
	- ã¨ã„ã£ã¦ã‚‚åˆæœŸç‰ˆã«ã¯èª¤æ¤ãŒã€(Ã—æ”¿åºœã®æ”¯æŒâ†’ã€‡æ”¿åºœã®æŒ‡ç¤ºï¼‰P16
- ollama + stablelm-zephyr è©¦ã™ã€‚ M1ã§ã‚‚ã¯ã‚„ã„ã€‚
	- https://ollama.ai/library/stablelm-zephyr
- Ollama : ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®¹æ˜“ã«llamaã‚’åˆ©ç”¨å¯èƒ½ã«ã‚‹ã™ã‚‹AIãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
	- https://note.com/astropomeai/n/nbcdfd3b38490?sub_rt=share_b
	- https://github.com/jmorganca/ollama
	- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’é€šã˜ã¦å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã¨ã‚„ã‚Šå–ã‚Šå¯èƒ½ãªAIãƒãƒ£ãƒƒãƒˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
	- Llamaã‚„Code Llamaãªã©ã€ã•ã¾ã–ã¾ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆ
	- ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚„ã‚µã‚¤ã‚ºãŒç•°ãªã‚Šã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã«å¿œã˜ãŸAIãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œã‚’æŸ”è»Ÿã«å¯¾å¿œ
	- DockerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨å¯èƒ½ã§ã€Nvidia GPUã®GPUã‚¢ã‚¯ã‚»ãƒ©ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚µãƒãƒ¼ãƒˆï¼ˆCPUä¸Šã§ã‚‚å®Ÿè¡Œå¯èƒ½ï¼‰
	- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã«ä¾å­˜ã—ã€ä¾‹ãˆã°Llama 2ã®7Bãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯æœ€ä½15GBã®RAMã¨4ã¤ã®CPUã‚³ã‚¢ãŒå¿…è¦
	- MacOSã¨Linuxç”¨ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã€Windowsç‰ˆãŒé–‹ç™ºä¸­
-  Ollama Llama Pack Example
	- https://docs.llamaindex.ai/en/latest/examples/llama_hub/llama_pack_ollama.html#
	- llamaindexã‚ˆã‚Šã€ã•ã£ããOllamaå¯¾å¿œã®RAGã®ä¾‹
	- https://llamahub.ai/l/llama_packs-ollama_query_engine
- ollama web-ui is amazing
	- https://github.com/ollama-webui/ollama-webui
- ClimateXã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹
	- https://huggingface.co/datasets/rlacombe/ClimateX
- Mistralã‚ˆã‚Šã€æ–°ã—ã„ mixtral-8x7b-32kseqlenã‚’ç™ºè¡¨
	- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
	- ã€Œæˆ‘ã€…ã¯Mistral MoE (7Bx32experts) ã‚’ 2 ã‹æœˆé–“ä½¿ç”¨ã—ã¦ãŠã‚Šã€ãã‚Œã¯24GBã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ã€
- What is Mixture-of-Experts (MoE)?
	- mixtral-8x7b-32kseqlenã®è£ã«ã‚ã‚‹moeæŠ€è¡“ã¨ã¯
	- https://x.com/sophiamyang/status/1733505991600148892?s=20
	- MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block.
- ãŸã£ãŸ87Gã®weightã§AGIãŒæ¥ã‚‹ã‹ã‚‰ã€AIè¦åˆ¶å¿…è¦ã ã­ã¨ã„ã†
	- https://x.com/abacaj/status/1733561182504587652?s=20
	- mixtral-8x7b-32kseqlenã®ã“ã¨ã‚‰ã—ã„
- MoEã®Mixtral-7bx8ã®GPTQãã¨ã‚‹ï¼
	- https://huggingface.co/TheBloke/mixtral-7B-8expert-GPTQ
- Geminiã®ãŠéŠã³ãƒ‡ãƒ¢ã¯ã€ç´™èŠå±…ã 
	- https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/
- QuIP#: QuIP with Lattice Codebooks
	- https://cornell-relaxml.github.io/quip-sharp/
	- QuIP#ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’2ãƒ“ãƒƒãƒˆé‡å­åŒ–ã—ã€æœ¬æ¥ãªã‚‰ã°140GBã®ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ãªLlama 2 70Bã‚’24GBã®GPUã§å®Ÿè¡Œå¯èƒ½ã«ã™ã‚‹ã¨ã®äº‹ã§ã™
- Bard(/w Gemini Pro)ã¯ã„ã¾ã ã«æ•°ç‹¬ãŒè§£ã‘ãªã„ã€ChatGPTã¯ã¨ã‘ã‚‹ã‘ã©
	- https://x.com/kajikent/status/1733663171578335233?s=20
- OpenAIã€GPT-4ãŒæ€ ã‘è€…ã«ãªã£ã¦ããŸã¨ã„ã†è‹¦æƒ…ã«ã€Œä¿®æ­£ã‚’æ¤œè¨ä¸­ã€ã¨ãƒã‚¹ãƒˆ
	- https://www.itmedia.co.jp/news/articles/2312/10/news059.html
	- ChatGPTã§ã®GPT-4ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã—ã¦ã„ã‚‹ï¼ˆlazierï¼‰ã¨ã„ã†ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãŒã“ã“æ•°ã‚«æœˆå¢—ãˆã¦ã„ã‚‹ã“ã¨ã‚’èªã‚ã€ã€Œä¿®æ­£ã‚’æ¤œè¨ä¸­ã€ã ã¨Xï¼ˆæ—§Twitterï¼‰ã®å…¬å¼ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒã‚¹ãƒˆã—ãŸã€‚
- Mistral MoEã®åˆæœŸè©•ä¾¡
	- https://x.com/bindureddy/status/1733523486885449834?s=20
	- ã¾ã‚ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ãªã„ç´ ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚‚GPT3.5ç›¸å½“ã®æ€§èƒ½ã¨ã„ã†ã®ã¯æœŸå¾…ã§ãã‚‹
	- solid 70B model that is very similar to GPT 3.5, Gemini Pro
	- MMLU on the base models is at 0.717 compared to Gemin Pro's 0.718
	- Expect to see several fine and instruct tunes over the next few weeks. These fine tunes will match GPT-4 quality for several real-world use cases.
-  Google Colab ã§ DiscoLM Mixtral 8x7b alpha ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n3b55c941d864?sub_rt=share_h
	- ã€Œ**Mixtral 8x7b**ã€ã¯ã€ã€ŒMistral AIã€ãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸå²ä¸Šåˆã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ MoEãƒ¢ãƒ‡ãƒ«ã§ã™
	- ã€Œ**DiscoLM Mixtral 8x7b alpha**ã€ã¯ã€ã€ŒMixtral 8x7bã€ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ä½œæˆã—ãŸå®Ÿé¨“çš„ãªãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚å…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚’HuggingFaceå½¢å¼ã«å¤‰æ›ã—ã€ã€ŒSynthiaã€ã€ŒMethaMathQAã€ã€ŒCapybaraã€ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã„ã¾ã™ã€‚
	- ã€Œ**MoE**ã€ (Mixture of Experts) ã¨ã¯ã€LLMã®åŠ¹ç‡ã¨ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã‚’ã‚ˆã‚Šå°ã•ãç®¡ç†ã—ã‚„ã™ã„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã«åˆ†å‰²ã—ã€ãã‚Œãã‚Œã‚’ç‰¹åŒ–ã—ãŸãƒŸãƒ‹ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯å°‚é–€å®¶ãŒå‡¦ç†ã™ã‚‹ã“ã¨ã§æ©Ÿèƒ½ã—ã¾ã™ã€‚
	- 

## 12/4

å…ˆé€±ã¾ã§ã®OpenAIã®ãŠå®¶é¨’å‹•ã‚‚è½ã¡ç€ãã€ä»Šé€±ã¯é€šå¸¸é‹è»¢ã€‚æ—¥å¸¸èƒ½åŠ›ã‚’è©¦ã™ãƒ†ã‚¹ãƒˆã€GAIAã€ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è‰¯ä¾‹ã«ã‚‚ãªã£ã¦ã„ã‚‹ã—ã€ç¾çŠ¶ã®LLMã®é™ç•Œã‚’å›³ã‚‹ã®ã«ã¡ã‚‡ã†ã©ã‚ˆã„ã€‚A*ã®å¯è¦–åŒ–ã€ã“ã†ã„ã†ã®ã‚’å¾…ã£ã¦ãŸã€‚ç•°ãªã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®ç¹‹ãŒã‚Šã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã‚’ä¿ƒã™ã‚·ã‚¹ãƒ†ãƒ ã€Latent Labã€ã¨ã„ã†ã®ã¯ã€ãƒ•ãƒªãƒ¼ã‚¢ãƒ‰ãƒ¬ã‚¹ã®åŸ·å‹™ç’°å¢ƒã®ç ”ç©¶æ´»å‹•ã®æ´»æ€§åŒ–ã«ãƒ’ãƒ³ãƒˆãŒã‚ã‚‹ã‹ã‚‚ã€‚é¸æŠãƒã‚¤ã‚¢ã‚¹å•é¡ŒãŒãªãœã‹ç€ç›®ã•ã‚Œã‚‹ã€‚æ¸…æ°´ã•ã‚“ã€ã¤ã„ã«ã€A100 80GBx8ã®ãƒã‚·ãƒ³ãŒå®Œæˆã€æ—¥æœ¬èªã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ãã‚ãˆã¦ãã‚Œã¦ã€æ—¥æœ¬ç™ºã®ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹LLMé–‹ç™ºã«å¤§ã„ãªã‚‹æœŸå¾…ã€‚IntelÂ® ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒæ‹¡å¼µã€é‡å­åŒ–ã®æ–°ãŸãªã‚‹æ®µéšï¼ŸGoogleã‹ã‚‰debateã‚’åŸºã«ã—ãŸå®‰å…¨ãªLLMåˆ©ç”¨ã«ã¤ã„ã¦ã®ç†è«–è«–æ–‡å…¬é–‹ã€‚ã‚«ãƒ¼ãƒãƒãƒ³æ•™æˆã¨ãƒ«ã‚«ãƒ³å…ˆç”Ÿã®å¯¾è©±ã‚‚å¿…è´ã€system1ã¨system2ã¨æ·±å±¤å­¦ç¿’ã®é–¢ä¿‚ã¯ã€ã‚ã‚‹ã‚ˆãªã€‚BERTopicã‚„ã€AlphaFoldã€googleã®ç¿»è¨³ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚‚ç€å®Ÿã«æ”¹è‰¯ãŒé€²ã‚“ã§å®Ÿç”¨ãƒ•ã‚§ãƒ¼ã‚ºã«ã¾ãŸä¸€æ­©é€²ã‚“ã ã€‚Google Colabã«ã¤ã„ã«transformerãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§å«ã¾ã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€ã¤ã¾ã‚Šãã†ã„ã†ã“ã¨ã ã€‚å¼·åŒ–å­¦ç¿’ç³»ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã€ã‚¹ãƒ‘ãƒ¼ã‚¹ãªå¯¾è±¡ã«ã¯ä¸é©åˆ‡ãªã®ã‹ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€†æ¨è«–ã—ãŸã‚Šã€ã‚µãƒ­ã‚²ãƒ¼ãƒˆï¼ˆä»£ç†ï¼‰ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹é€†å•é¡Œã®ç ”ç©¶ã‚‚æ³¨ç›®ã€‚llamapackã£ã¦ã®ãŒã§ãã¦ã„ã‚‹ã®ã‹ã€è©¦ã—ã¦ã¿ã‚ˆã†ã€‚Agentã‚’ã‚ˆãä½¿ã£ã¦ã‚‹ã‘ã©ã‚‚ã£ã¨ç¨®é¡ãŒã‚ã‚‹ã€èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã£ã¦ã®ã¯ã¡ã‚ƒã‚“ã¨ç†è§£ã—ãŸã„ã€‚ã€Œå’Œæ­Œé›†ã®æ­Œé¢¨ã®è¨€èªçš„å·®ç•°ã®è¨˜è¿°ãƒ¼å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åˆ†æãƒ¼ã€ã¨ã„ã†ã®ã¯ç¶šç·¨ã‚’æœ›ã‚€ã€‚LLMã‚’Pytorchã ã‘ã§ã©ã‚Œã ã‘é«˜é€ŸåŒ–ã§ãã‚‹ã‹ã¨ã‹ã€GPT-fastã¨ã‹ã€å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã¨ã‹ã€ãã†ã„ã†ã®ãŒã‚‚ã£ã¨å‡ºã¦ãã‚‹ã¯ãšã€‚OSSã®LLMã«ã¤ã„ã¦ã®è«–æ–‡ã€ŒChatGPTã®1å‘¨å¹´ã‚’è¨˜å¿µã—ã¦ã€ã‚‚ã„ã„ã­ã€OSSã®LLMãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„å¿œç”¨åˆ†é‡ã«ãŠã„ã¦ã€ã‚¯ãƒ­ãƒ¼ã‚ºãªLLMã«åŒ¹æ•µã™ã‚‹ã€ã‚ã‚‹ã„ã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã¨ãªã€‚ã‚¢ãƒ¡ãƒªã‚«ã®åŒ»å­¦è©¦é¨“ã€ŒUS (4-option)ã€ã§90.2ï¼…ã¨ã„ã†é«˜ã„æ­£è§£ç‡ã‚’ã ã—ãŸGPT-4è©•ä¾¡è«–æ–‡ã€ä¸‹æ‰‹ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚ã¨ã„ã†è©±ã‹ã€‚


-  An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
- GAIA: a benchmark for General AI Assistants
	- https://arxiv.org/abs/2311.12983
- Q*ã§ã¯ãªã„ã§ã™ãŒã€A*æ¢ç´¢ã®æ§˜å­ã‚’å¯è¦–åŒ–ã—ãŸ
	- https://x.com/GregKamradt/status/1728480680127148480?s=20
- Kevin Dunnell et al., "Latent Lab: Large Language Models for Knowledge Exploration"
	- https://arxiv.org/abs/2311.13051
	- LLMãƒ™ãƒ¼ã‚¹ã§ã€ç•°ãªã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé–“ã®ç¹‹ãŒã‚Šã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã‚’ä¿ƒã™ã‚·ã‚¹ãƒ†ãƒ ã€Latent Labã€
	- â‘ å¯¾è©±ã¨è¦–è¦šåŒ–ã‚’é€šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢ 
	- â‘¡ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚’è‡ªå‹•åŒ–
	-  â‘¢ æ–°ã—ã„ç ”ç©¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¢ã‚¤ãƒ‡ã‚¢åˆæˆã‚‚å¯èƒ½
-  Google Colab ã§ LCM LoRA ã‚’è©¦ã™ã€€ by npakaã•ã‚“
	- https://note.com/npaka/n/n940ee84ca5b6?sub_rt=share_h
	- ã€ŒLCMã€ (Latent Consistency Model) ã¯ã€å…ƒãƒ¢ãƒ‡ãƒ«ã‚’åˆ¥ãƒ¢ãƒ‡ãƒ«ã«è’¸ç•™ã™ã‚‹ã“ã¨ã§ã€ç”»åƒç”Ÿæˆã«å¿…è¦ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ¸›ã‚‰ã™æ‰‹æ³•ã§ã™ã€‚25ï½50ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‹ã£ã¦ã„ãŸå‡¦ç†ã‚’4ï½8ã‚¹ãƒ†ãƒƒãƒ—ã§å¯èƒ½ã«ã—ã¾ã™ã€‚
- Multi-modal Foundation Model for Material Design
	- https://openreview.net/forum?id=EiT2bLsfM9
	- åˆ†å­ã‚’è¡¨ç¾ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶ã€‚SELFIESã€DFTç‰©æ€§ã€ã‚¹ãƒšã‚¯ãƒˆãƒ«ã«ã¤ã„ã¦ãã‚Œãã‚Œencoder-decoderã‚’å­¦ç¿’ã—ã€å„ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®æ½œåœ¨ç©ºé–“ã‚’å…±é€šã®æ½œåœ¨ç©ºé–“ã«encode, decodeã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã€‚
	-  æ¬ æãŒå¤šãã¦ã‚‚å­¦ç¿’å¯èƒ½ã‹ã¤ã€å¾Œã‹ã‚‰ç•°ãªã‚‹ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã‚’è¿½åŠ ã—ã‚„ã™ã„
- é¸æŠãƒã‚¤ã‚¢ã‚¹ã®å¼ã€tweedle
	- https://x.com/docmilanfar/status/1728680465928958055?s=20
- llamaindexã‚ˆã‚Šã€RAGè©•ä¾¡ãƒ„ãƒ¼ãƒ«ragsã®v2ãƒªãƒªãƒ¼ã‚¹
	- https://github.com/run-llama/rags
-  Simplifying Transformer Blocks 
	- https://arxiv.org/abs/2311.01906
	- many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:
- llamaindexã‹ã‚‰ã€RAGã®æ–°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€fuzzy citationã‚’ç™ºè¡¨
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/fuzzy_citation/fuzzy_citation_example.ipynb
	- https://llamahub.ai/l/llama_packs-fuzzy_citation
	- éƒ¨åˆ†çš„ãªæ¤œç´¢çµæœã‹ã‚‰ï¼‘ã¤ã®å›ç­”ã‚’åˆæˆï¼Ÿï¼Ÿ
- ï¼²ï¼¡ï¼§ 101 for enterpirze
	- https://gradient.ai/blog/rag-101-for-enterprise
	- çµµãŒç´ æ•µ
-  AIã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã€Œç¶™ä¹‹åŠ©ã€çˆ†èª•!ã¨ã‚Šã‚ãˆãšRAID0ã§12TBã®ãƒ‡ã‚£ã‚¹ã‚¯ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
	- https://note.com/shi3zblog/n/n77e8ad3ed779?sub_rt=share_pb
	- ã¤ã„ã«A100 80GBx8ã®ãƒã‚·ãƒ³ãŒç¨¼åƒã—ãŸã€‚ã“ã“ã¾ã§é•·ã‹ã£ãŸã€‚
	- ã“ã“ã¾ã§æƒã£ãŸã‚‰æ—¥æœ¬æœ€å¤§è¦æ¨¡ã®LLMã‚’å€‹äººã§ä½œã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚
-  A population-level digital histologic biomarker for enhanced prognosis of invasive breast cancer
	- https://www.nature.com/articles/s41591-023-02643-7
	- An important AI report for breast cancer leading to the potential of sparing chemotherapy for many. 
	- The 1st comprehensive analysis of both cancerous and non-cancerous tissue in hundreds of thousands of patient tissues-
- BERTopicã®æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³
	- https://github.com/MaartenGr/BERTopic
	- Merge pre-trained models, apply zero-shot topic modeling, seed domain-specific words, and much more in this HUGE update!
- IntelÂ® Extension for Transformers
	- https://github.com/intel/intel-extension-for-transformers
	- An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere
	- Intel Extension for Transformers supports INT4 model quantized by GPTQ on Intel platforms (Xeon & PC) !
	- https://github.com/intel/intel-extension-for-transformers/tree/1.2.1#int4-inference
-  ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã¨ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã®é–¢ä¿‚
	- https://qiita.com/kaityo256/items/aa5b24904577de40016e
	- é–¢æ•°ï¿½(ï¿½)ã«ãŸã„ã—ã¦ã€ï¿½<0ãªã‚‰ã‚¼ãƒ­ã«ã€ï¿½â‰¥0ãªã‚‰eâˆ’ï¿½ï¿½ã‚’ã‹ã‘ã¦ã€ã€Œã‚ˆã‚ŠåæŸã—ã‚„ã™ãã€ã—ãŸä¸Šã§ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã—ãŸã‚‚ã®ãŒãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã§ã‚ã‚‹ã€‚ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ãŒã€è»¸ã®ä¸­é€”åŠç«¯ãªã¨ã“ã‚ã‚’ã€Œç¸¦ã«ã€ç©åˆ†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ç†ç”±ã‚‚ã€ãƒ•ãƒ¼ãƒªã‚¨é€†å¤‰æ›ã¨ï¿½ã‹ã‚‰ï¿½ã¸ã®å¤‰æ•°å¤‰æ›ã‹ã‚‰ç†è§£ã§ãã‚‹ã§ã‚ã‚ã†ã€‚
	- é–¢æ•°ï¿½(ï¿½)ã«ãŸã„ã—ã¦ã€ï¿½<0ãªã‚‰ã‚¼ãƒ­ã«ã€ï¿½â‰¥0ãªã‚‰eâˆ’ï¿½ï¿½ã‚’ã‹ã‘ã¦ã€ã€Œã‚ˆã‚ŠåæŸã—ã‚„ã™ãã€ã—ãŸä¸Šã§ãƒ•ãƒ¼ãƒªã‚¨å¤‰æ›ã—ãŸã‚‚ã®ãŒãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ã§ã‚ã‚‹ã€‚ãƒ©ãƒ—ãƒ©ã‚¹å¤‰æ›ãŒã€è»¸ã®ä¸­é€”åŠç«¯ãªã¨ã“ã‚ã‚’ã€Œç¸¦ã«ã€ç©åˆ†ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ç†ç”±ã‚‚ã€ãƒ•ãƒ¼ãƒªã‚¨é€†å¤‰æ›ã¨ï¿½ã‹ã‚‰ï¿½ã¸ã®å¤‰æ•°å¤‰æ›ã‹ã‚‰ç†è§£ã§ãã‚‹ã§ã‚ã‚ã†ã€‚
- Google Colabã€Huggingfacesã®å”åŠ›ã§ã€transformerã‚’æœ€åˆã‹ã‚‰ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://x.com/GoogleColab/status/1729217098977845590?s=20
- A Llama-2-based model finetuned for function calling:
	- https://huggingface.co/Trelis/Llama-2-7b-chat-hf-function-calling-v2
- æ—¥æœ¬èªWikipediaã®ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ10ä¸‡å€‹ã‚’ä½œã‚Šã¾ã—ãŸ	
	- https://note.com/shi3zblog/n/na10eed9270f8?sub_rt=share_pb
	- GPT-3.5-Turboã‚’ä½¿ã£ã¦ã€ç´„ä¸€ãƒ¶æœˆã‹ã‘ã¦æ—¥æœ¬èªã®Wikipediaã®é …ç›®ã‚’ã‚‚ã¨ã«å…ˆç”Ÿã¨ç”Ÿå¾’ãŒä¼šè©±ã™ã‚‹ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸ
	- GPT-4ã§ã‚‚ã‚„ã£ã¦ã¿ã‚ˆã†ã‹ãªã¨æ€ã£ã¦ã„ã¾ã™ãŒã€GPT-3.5ã§ã‚‚ä¸€ãƒ¶æœˆã§ã‹ãªã‚Šã®å‡ºè²»ãŒã‚ã‚Šã€GPT-4ã§åŒã˜åˆ†é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã¨ãªã‚‹ã¨æ•°åä¸‡å††ã‹ã‚‰æ•°ç™¾ä¸‡å††ã‹ã‹ã‚Šãã†ã§ã™
- llamaindexã‹ã‚‰RAGã«æœ‰åŠ¹ãªllamapackã‚’ï¼—ç¨®é¡å…¬é–‹
	- https://x.com/llama_index/status/1729303619760259463?s=20
- Compositional Generative Inverse Design
	- https://openreview.net/forum?id=5ueXRkKMMg&referrer=%5Bthe%20profile%20of%20Yilun%20Du%5D(%2Fprofile%3Fid%3D~Yilun_Du1
	- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§è¿‘ä¼¼ã—ãŸä»£ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã¨ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸé€†å•é¡Œè§£æ³•ã¯ã€ã—ã°ã—ã°å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒå¤–ã«ã„ã£ãŸã‚Šå±€æ‰€è§£ã«é™¥ã‚‹ã“ã¨ãŒã‚ã‚‹ã€‚ãã‚Œã‚’é˜²ããŸã‚ã«ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å„ã‚¹ãƒ†ãƒƒãƒ—ã§è§£ã‚’èª˜å°ã—ã€ä¸é©åˆ‡ãªè§£ã‚’é˜²ãCinDMã‚’ææ¡ˆ
- mlc-llm on WSLã§ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›ã‚’è¡Œã†
	- ã€ŒWebGPUã‚’ç”¨ã„ãŸãƒ­ãƒ¼ã‚«ãƒ«LLMãƒ¢ãƒ‡ãƒ«ã®ãƒ–ãƒ©ã‚¦ã‚¶æ¨è«–ã€
	- https://zenn.dev/saldra/articles/356f470e730d1c
- ï¼®ï¼´ï¼´ã‚³ãƒ ã®ï¼¡ï¼©å­¦ç¿’æ•™æ
	- https://gochikika.ntt.com/index.html
	- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã‹ã‚‰ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚„è©•ä¾¡ã¾ã§Pythonã‚³ãƒ¼ãƒ‰ã¨åˆã‚ã›ã¦ä¸€é€šã‚Šå­¦ã¹ã‚‹
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®ï¼¬ï¼¬ï¼­ã§ã‚‚å‡ºåŠ›ã®æˆå‹ãŒå¤§äº‹
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb
- John X. Morris et al., "Language Model Inversion"
	- https://arxiv.org/abs/2311.13647
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã¯æ¬¡ã®å˜èªã®ç¢ºç‡ã‚’å‡ºã™ãŒã€ãã®ã€Œç¢ºç‡ã€ã‚’åˆ©ç”¨ã—ã¦å…ƒã®æ–‡ç« ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰ã‚’ä½•ã¨ã‹ã—ã¦è¦‹ã¤ã‘å‡ºã™æ‰‹æ³•ã‚’é–‹ç™ºã€‚
- OpenAIã®cookbookã«llamaindexã‚’ã¤ã‹ãŸRAGãŒæ²è¼‰
	- https://blog.llamaindex.ai/openai-cookbook-evaluating-rag-systems-fe393c61fb93
- Minimizing Factual Inconsistency and Hallucination in Large Language Models
	- https://arxiv.org/abs/2311.13878
	- LLMã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘åˆ¶ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€å¤šæ®µéšã§æƒ…å ±ã‚’å–å¾—ã•ã›ã‚‹ã“ã¨ã§ã€ä¿¡é ¼æ€§ã®é«˜ã„å¿œç­”ã‚’å–å¾—å¯èƒ½ã§ã™ã€‚
- Relational Deep Learning
	- https://drive.google.com/file/d/1Uk1y6c8z265G0wiRPpGT1cd5lts5lnKq/view
	- Relational Deep Learning is brings the power of Graph Representation Learning to a Relational Database.
- NeurIPA2023ã®è«–æ–‡æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
	- https://www.ai-driven-life.com/neurips-papers
- å¼·åŒ–å­¦ç¿’ã¯ãƒ™ãƒ«ãƒãƒ³æœ€é©æ€§åŸç†ã‹ã‚‰æ¥ã‚‹å‹•çš„è¨ˆç”»æ³•ã«æ”¯ãˆã‚‰ã‚Œã¦ã¾ã™ã€‚ã—ã‹ã—ã€æƒ…å ±ãŒrandomSamplingã•ã‚Œã‚‹ä¸­ã§å®Ÿã¯å„æ™‚åˆ»éš£åˆã†ãƒ‡ãƒ¼ã‚¿ã®åˆ—ãŒã»ã¨ã‚“ã©æƒ…å ±ï¼ˆå ±é…¬ï¼‰ã‚’æŒãŸãªã„ã¨ãªã‚‹ã¨ã€é–“ã«æ¨å®šå™¨ãŒæŒŸã¾ã£ã¦ã‚‹ã®ã‚‚ã‚ã£ã¦ã‚¹ãƒ‘ãƒ¼ã‚¹ã©ã“ã‚ã‹æœ€å¾Œã«ã—ã‹å ±é…¬ãŒå¾—ã‚‰ã‚Œãªã„å•é¡Œã¸ã®å¦¥å½“æ€§ã¯æ€ªã—ã„ã‹ã‚‚ã§ã™ã­ã€‚
	- https://x.com/ML_deep/status/1729249503683969037?s=20
- DeepMind has formalized a theoretical result related to AI safety in Lean. 
	- https://github.com/google-deepmind/debate
	- "Monadic syntax is excellent for expressing stochastic algorithms, and working over finitely supported distributions avoids the need for integrability side conditions during proofs."
	- But Iâ€™m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think â€œnot killing lots of peopleâ€ is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and thatâ€™s where this type of method might shine.
	- https://x.com/davidad/status/1729461156618637502?s=20
- Azure OpenAI Serviceã®æ—¥æœ¬èªè¨˜äº‹ã¾ã¨ã‚
	- https://zenn.dev/microsoft/articles/azure-openai-japanese-blogs
- ã‚«ãƒ¼ãƒãƒãƒ³æ•™æˆã¨ãƒ«ã‚«ãƒ³å…ˆç”Ÿã®å¯¾è©±
	- https://www.youtube.com/watch?v=oy9FhisFTmI
	- Video of Daniel Kahneman and Yann LeCun discussing Dual Process Theory (i.e., System 1 and 2) in relation to Deep Learning.
-  ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search
	- https://arxiv.org/abs/2310.13227
	- uses algorithms like A* to improve LLM answers, improving sota on both planning and reasoning tasks
- Qualcomm Snapdragon 8gen 3 already supported 10b language model running locally on your smartphone.
	- https://x.com/Francis_YAO_/status/1727861621110779941?s=20
	- LLM is the new smartphone OS!
- Domingoså…ˆç”ŸãŒãªã‚“ã‹è¨€ã£ã¦ã„ã‚‹
	- https://x.com/pmddomingos/status/1729303707387658284?s=20
	- Why AI isn't going to taking over (from "The Master Algorithm").
- MistralChameli_7B_v01
	- https://huggingface.co/TokenBender/MistralChameli_7B_v01
	- First version of DPO-ed roleplay/smart version of Mistral. Now to conduct some experiments with reward model and see if this is any good.
- ãƒ™ã‚¤ã‚¸ã‚¢ãƒ³ãƒ¢ãƒ‡ãƒ«ã¸ã®çµŒé¨“ãƒ™ã‚¤ã‚ºä¿®æ­£
	- https://www.jstage.jst.go.jp/article/keidaironshu/68/4/68_161/_article/-char/ja/
	- Robbins (1956) ãŒ Tweedie (1947) ã«è¨€åŠã—ã¦ã‚‹ã“ã¨ã«åŸºã¥ãï¼ŒEfron ãŒ Tweedie's formula ã¨åä»˜ã‘ã¦åºƒã¾ã£ã¦ã„ã‚‹ãŒï¼ŒKoenker & Gu (2016) ã§ã¯ Dyson (1926) ã§æ—¢ã«å¾—ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚
-  A glimpse of the next generation of AlphaFold
	- https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/
	- AlphaFoldã¯æœ€è¿‘å¤§ããªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãŒã‚ã‚Šã€ç²¾åº¦ãŒå¤§å¹…ã«å‘ä¸Šã—ã€ã‚¿ãƒ³ãƒ‘ã‚¯ã ã‘ã§ãªãPDBã«ã‚ã‚‹ã»ã¼ã™ã¹ã¦ã®åˆ†å­ã«ã¤ã„ã¦äºˆæ¸¬å¯èƒ½ã§ã™ã€‚å‰µè–¬ã‚„æ–°å‹CRISPRæ¢ç´¢ã«ã‚‚(ä¸€å®šç¨‹åº¦ã¯)ä½¿ãˆã¾ã™ã€‚
- EMNLP2023 ã®æ¡æŠè«–æ–‡ãƒªã‚¹ãƒˆãŒè¦‹ãˆã‚‹ã‚ˆã†ã«ãªã£ã¦ãŸï¼æ¥é€±ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã§é–‹å‚¬ã•ã‚Œã‚‹è‡ªç„¶è¨€èªå‡¦ç†ã®å›½éš›ä¼šè­°ã§ã™ï¼ã‚¿ã‚¤ãƒˆãƒ«ã«"Language Model"ã¯ã„ã£ã¦ã‚‹è«–æ–‡ãŒ219æœ¬ã£ã¦ï¼Œã©ã‚“ã ã‘è¨€èªãƒ¢ãƒ‡ãƒ«å¥½ããªã‚“ã ã‚ˆ
	- https://2023.emnlp.org/program/accepted_main_conference/
-  OpenAI ã¨ LangChain ã®èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ by npakaã•ã‚“
	- https://note.com/npaka/n/n650532ce289a?sub_rt=share_h
	- ã€Œ**èªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**ã€(cognitive architecture) ã¨ã¯ã€LLMã©ã®ã‚ˆã†ã«æƒ…å ±ã‚’å‡¦ç†ã—ã€å¿œç­”ã‚’ç”Ÿæˆã™ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®æ çµ„ã¿ã§ã™ã€‚ã€ŒFlo Crivelloã€ï¼ˆè‡ªå¾‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®Lindyã®å‰µè¨­è€…ï¼‰ãŒä½¿ç”¨ã—ãŸã“ã®ç”¨èªã‚’åˆã‚ã¦èãã€ç´ æ™´ã‚‰ã—ã„ç”¨èªã ã¨æ€ã„ã¾ã—ãŸã€‚
	- ã€ŒLangChainã€ã§ã¯ã€ã€ŒLLMã€ãŒçœŸã«å¤‰é©çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ã«é›»åŠ›ã‚’ä¾›çµ¦ã™ã‚‹ä¸–ç•Œã‚’ä¿¡ã˜ã¦ã„ã¾ã™ã€‚ã—ã‹ã—ã€ãã“ã«ãŸã©ã‚Šç€ããƒ«ãƒ¼ãƒˆã¯ã€**ä¼æ¥­ãŒã€ŒèªçŸ¥ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ã‚’åˆ¶å¾¡ã§ãã‚‹ãƒ«ãƒ¼ãƒˆ**ã§ã‚ã‚‹ã¨ä¿¡ã˜ã¦ã„ã¾ã™ã€‚
	- **(1) Code**  LLMã‚’åˆ©ç”¨ã—ãªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚  
	- **(2) LLM Call** ã‚¢ãƒ—ãƒªã®å‡ºåŠ›ã®ã¿ã‚’æ±ºå®šã™ã‚‹å˜ä¸€ã®LLMã‚³ãƒ¼ãƒ«ã€‚ 
	- **(3) Chain**  ã‚¢ãƒ—ãƒªã®å‡ºåŠ›ã®ã¿ã‚’æ±ºå®šã™ã‚‹è¤‡æ•°ã®LLMã‚³ãƒ¼ãƒ«ã€‚  
	- **(4) Router**  LLMã‚’ãƒ«ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã€ä½¿ç”¨ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ (Toolã€Retrievalã€Prompt) ã‚’é¸æŠã€‚ 
	- **(5) State Machine**  LLMã‚’ä½¿ç”¨ã—ã¦ã‚ã‚‹ç¨®ã®ãƒ«ãƒ¼ãƒ—ã§ã‚¹ãƒ†ãƒƒãƒ—é–“ã‚’ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãŒã€ã‚³ãƒ¼ãƒ‰ãŒè¨±å¯ã•ã‚ŒãŸé·ç§»å…ˆã«ã®ã¿é·ç§»  
	- **(6) Agent**  åˆ©ç”¨å¯èƒ½ãªã‚¹ãƒ†ãƒƒãƒ—ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æ±ºå®šã‚‚LLMãŒè¡Œã†ã€‚
- Textã‹ã‚‰SQLã‚’ç”Ÿæˆã™ã‚‹Querypls
	- https://github.com/samadpls/Querypls/
- ã‚ã‚Œã‚‰ãŒã€ @jerryjliu0ãŒdeeplearningaiã‚³ãƒ¼ã‚¹ã«ç™»å ´
	- https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/
	- We also have LlamaPacks for every technique mentioned in this course to help you jumpstart your advanced LLM app:
- Deconstructing RAG
	- https://blog.langchain.dev/deconstructing-rag/
	- Given the importance of RAG and the fast pace of development, we've grouped popular RAG concepts into a few categories and created guides for each one.
- Running Starling-7B LLM model on local CPU with @Ollama_ai and getting great results for invoice data extraction, even better than Zephyr, Mistral or Llama2.
	- https://github.com/katanaml/llm-ollama-invoice-cpu
- å††åŸå¡”ã‚’è¿‘ä¼¼ã™ã‚‹ï¼Ÿ
	- https://colab.research.google.com/drive/1oXxBIYJvvUYsVZP6WYAUCb3QK09zTJtO?usp=sharing
	- å††åŸå¡”ã•ã‚“ã®æ–‡ç« ã§å­¦ã¶ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
- ã€Œé•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’LLM(GPT, Claude)ã«é£Ÿã‚ã›ãŸéš›ã«ã€ã¡ã‚ƒã‚“ã¨Retrivalã•ã‚Œã‚‹ã‹ï¼Ÿã€ã‚’æ¤œè¨¼ã—ã¦ã„ã‚‹Githubã€‚
	- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
	-  ç·ã˜ã¦Calude-2ã«æ¯”ã¹ã¦GPT-4 Turboã®ã»ã†ãŒæ­£ç¢ºã«å¼•ç”¨ã—ã¦ã„ã‚‹ã‚ˆã†ã§é¢ç™½ã„ã€‚
- Qwen/Qwen-7B-Chat-Int4ã‚’Google Colobã§å‹•ã‹ã™
	- https://ayousanz.hatenadiary.jp/entry/2023/11/30/182017
	- ãªã‚“ã‹æ—¥æœ¬ã®æ–‡åŒ–ã¯ã¡ã‚ƒã‚“ã¨å­¦ã‚“ã§ã„ãªã„ã¿ãŸã„ã§ã™ã­
-  Accelerating Generative AI with PyTorch II: GPT, Fast
	- https://pytorch.org/blog/accelerating-generative-ai-2/?utm_content=273712248
	- GPT-fastã¨ã„ã†ã®ãŒã™ã”ã‚‰ã„ã—ã„ã€ï¼“å€ï¼Ÿ
- LiLM å°è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« TinyLlama 1.1B ã®æ—¥æœ¬èªè¿½åŠ äº‹å‰å­¦ç¿’(incremental pretrain) ã‚’è©¦ã—ãŸãƒ¡ãƒ¢
	- https://zenn.dev/syoyo/articles/52f1d0d62fcad5
	- ç”Ÿæˆã•ã‚Œã‚‹æ—¥æœ¬èªã¯ã¾ã‚ã¾ã‚ã§ã‚ã‚‹ãŒ, æ§‹æ–‡ã‚„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãŠã‹ã—ã„...
	- ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã—ã¦ã‚‚é–“é•ãˆãŸã‚Š...
	- ã¾ã‚ã§ã‚‚ 1B è¦æ¨¡ãªã‚‰å¦¥å½“ãªã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
- ä»Šå·ã®ã€æ—¥æœ¬èªã®ç ”ç©¶ã€ã§ã€Œå’Œæ­Œé›†ã®æ­Œé¢¨ã®è¨€èªçš„å·®ç•°ã®è¨˜è¿°ãƒ¼å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹åˆ†æãƒ¼ã€ã¨é¡Œã—ã¦ã€OpenAIã®text-embeddingã‚’ä½¿ã£ã¦ã€ã€ä¸‡è‘‰é›†ã€ã¨ã€å¤ä»Šé›†ã€ã®æ„å‘³æ§‹é€ ã®å·®ã‚’è§£æã—ã¦ã¿ã¾ã—ãŸã€‚
	- https://www.musashinoshoin.co.jp/shoseki/view/2976/
- Energy and entropy: Path from game theory to statistical mechanics
	- https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.043055
	- ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’ä½ãã™ã‚‹ã®ãŒç›®æ¨™ã®ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã¨ï¼Œã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’ä¸Šã’ã‚‹ã®ãŒç›®æ¨™ã®ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã®äº¤æ¸‰ã‚²ãƒ¼ãƒ ã«ãŠã‘ã‚‹æœ€é©ãªæˆ¦ç•¥ã‚’é€šã—ã¦ç†±å¹³è¡¡åŒ–ã‚’è­°è«–ã™ã‚‹ã‚‰ã—ã„
- gpt-fast
	- https://github.com/pytorch-labs/gpt-fast
	- LLMã‚’Pytorchã ã‘ã§ã©ã‚Œã ã‘é«˜é€ŸåŒ–ã§ãã‚‹ã‹ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ãŸãƒªãƒã‚¸ãƒˆãƒª Llama-7BãŒ10å€é€Ÿããªã£ã¦ã„ã‚‹ 
	- Pytorchã§ä½¿ãˆã‚‹é«˜é€ŸåŒ–æŠ€è¡“ã‚’ã„ã‚ã„ã‚ç››ã‚Šè¾¼ã‚“ã§ã‚‹ã½ã£ãã¦ã€ä¸­èº«è¦‹ã‚‹ã®ã‚‚å‹‰å¼·ã«ãªã‚Šãã†
- æ—¥æœ¬èªLLMã§LLaVAã®å­¦ç¿’ã‚’è¡Œã£ã¦ã¿ãŸ
	- https://qiita.com/toshi_456/items/248005a842725f9406e3
- googleã‹ã‚‰æ–°ã—ã„ç¿»è¨³ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ç™ºè¡¨
	- Unsupervised speech-to-speech translation from monolingual data
	- https://blog.research.google/2023/12/unsupervised-speech-to-speech.html
-  æ¥­ç•Œåˆ¥ç”ŸæˆAIæ´»ç”¨ã®ã™ã‚ã‚
	- https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/about-deloitte-japan/ai-dossier-2023.html?id=jp:2pm:3tw:4daii-genaidossier:5:6abt:20231201::
	- ãƒ‡ãƒ­ã‚¤ãƒˆãƒˆãƒ¼ãƒãƒ„
-  Microsoft Copilot is now generally available
	- https://blogs.bing.com/search/december-2023/Microsoft-Copilot-is-now-generally-available?ocid=aid_soc_usoc_edu_cons_bing_eng_tw_12.1
- Cè¨€èªã§WASMã‚¤ãƒ³ã‚¿ãƒ—ãƒªã‚¿ã‚’å®Ÿè£…ã—ãŸè©±
	- https://zenn.dev/ri5255/articles/845ef3dab5ab47
	- ã“ã®è‡ªä½œWASMãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ç›®çš„ã¯ã€ã§ãã‚‹ã ã‘ä»•æ§˜ã«å¾“ã£ãŸå®Ÿè£…ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€ä»•æ§˜ã®ç†è§£ã‚’åŠ©ã‘ã‚‹ã“ã¨ã§ã‚ã‚‹ã€‚æ—©ã•ã‚„åŠ¹ç‡æ€§ã‚ˆã‚Šã‚‚åˆ†ã‹ã‚Šã‚„ã™ã•ã‚’å„ªå…ˆã—ã¦ã„ã‚‹ãŸã‚ã€å®Ÿç”¨ã«ã¯å‘ã‹ãªã„ã€‚ä»•æ§˜æ›¸ã‚’èª­ã‚“ã§ã€å®Ÿè£…ã«å›°ã£ãŸéš›ã«å‚ç…§ã—ã¦ã»ã—ã„ã€‚
-  ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«æ•°ç†ãƒ¢ãƒ‡ãƒ«ã§ç«‹ã¡å‘ã‹ã† / Japan.R 2023
	- https://speakerdeck.com/dropout009/japan-dot-r-2023
- Harsha Nori et al., "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
	- https://arxiv.org/abs/2311.16452
	- ã“ã‚Œã¾ã§GPT-4ãªã©ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã¯ã€åŒ»å­¦ãªã©ã®å°‚é–€åˆ†é‡ã§ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã«ã¯æ•µã‚ãªã„ã¨è€ƒãˆã‚‰ã‚Œã¦ãã¾ã—ãŸã€‚ ã—ã‹ã—ã€ã€Œå®Ÿéš›ã¯ã©ã†ãªã®ã‹ï¼Ÿã€ã¨è€ƒãˆãŸç ”ç©¶è€…ã‚‰ã¯ã€ç‰¹åˆ¥ãªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã®GPT-4ãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å·¥å¤«ã®ã¿ã§ã©ã“ã¾ã§æ€§èƒ½ã‚’ç¤ºã™ã®ã‹ã‚’æ¤œè¨¼ã—ã¾ã—ãŸã€‚
	- â‘  ã‚¢ãƒ¡ãƒªã‚«ã®åŒ»å­¦è©¦é¨“ã€ŒUS (4-option)ã€ã§90.2ï¼…ã¨ã„ã†é«˜ã„æ­£è§£ç‡ã‚’å‡ºã—ãŸ
	-  â‘¡ ç†ç”±ä»˜ã‘ãŒå¿…è¦ãªã‚¿ã‚¤ãƒ—ã®å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆPubMedQAã§82.0ï¼…ã®æ­£è§£ç‡ã‚’é”æˆ
-  æ—¥å¸¸èƒ½åŠ›ã‚’è©¦ã™ãƒ†ã‚¹ãƒˆã€GAIAã€æ­£ç­”ç‡ã€äººé–“92%ã«å¯¾ã—ã¦GPT-4ã¯15%ã€€ä¸€èˆ¬çš„ãªãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹AIé–‹ç™ºã®æŒ‡é‡ã«
	- https://aiboom.net/archives/59440
- Langchain102
	- https://www.youtube.com/watch?v=haad3i9VROs
	- Mistral 7b User Showcase + LangServe & LangSmith
- METAã®AIç ”ç©¶è€…ãŒä½•ã‚‰ã‹ã®å¤§ããªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ãŒã‚ã£ãŸã¨ç¤ºå”†ã€‚ è¿‘æ—¥ä¸­ã«å…±æœ‰äºˆå®šã¨ã®ã“ã¨
	- https://x.com/ArmenAgha/status/1731076069170835720?s=20
-  ã€ŒChatGPTã®1å‘¨å¹´ã‚’è¨˜å¿µã—ã¦ã€ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMãŒChatGPTã«ã©ã“ã¾ã§è¿½ã„ã¤ã„ã¦ã„ã‚‹ã‹ä½“ç³»çš„èª¿æŸ»å ±å‘Š
	- https://aiboom.net/archives/59713
	- https://arxiv.org/abs/2311.16989
	- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã¨ã—ã¦ã¯Llama-2ï¼ˆãŠã‚ˆã³MentalLlamaï¼‰ã€Palmã€Vicunaã€Falconã€Wizardã€Lemurãªã©ã®ãƒ¢ãƒ‡ãƒ«ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãã‚Œã‚‰ã®é€²æ­©ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§ã®å„ªã‚ŒãŸæ€§èƒ½ã«ã¤ã„ã¦è©³ã—ãåˆ†æã•ã‚Œã¦ã„ã¾ã™ã€‚èª¿æŸ»çµæœã‹ã‚‰ã¯ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„å¿œç”¨åˆ†é‡ã«ãŠã„ã¦ã€ã‚¯ãƒ­ãƒ¼ã‚ºãªLLMã«åŒ¹æ•µã™ã‚‹ã€ã‚ã‚‹ã„ã¯ãã‚Œã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¤ºã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã¾ã—
- MRS2023(materials research society)ã§LLMãŒå¤šã„ 2023 MRS Fall Meeting & Exhibit
	- https://x.com/yoko_materialDX/status/1731267042810962256?s=20
	- MIã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒå¸¸æ™‚4ã¤ã‚ã‚Šå›ã‚‹ã®ãŒå¤§å¤‰
	- æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¨è‡ªå‹•åˆæˆã®ç™ºè¡¨ãŒå¤§é‡
	- çµæ™¶æ§‹é€ äºˆæ¸¬ã®ç™ºè¡¨ãŒæ€ã£ãŸã‚ˆã‚Šå¤šã‹ã£ãŸ
	- LLMã®ç™ºè¡¨ã¯ææ–™ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãŒä¸­å¿ƒ
	- æ—¥æœ¬ä¼æ¥­ã‹ã‚‰ã®MIç™ºè¡¨ãŒå¤šã‹ã£ãŸ 
	- ä¸–ç•Œæƒ…å‹¢ã‚†ãˆï¼Ÿï¼‰ä¸­å›½æœ¬åœŸã®æ–¹ãŒã»ã¼ã„ãªã‹ã£ãŸ

## 11/27

ã‚¢ãƒ«ãƒˆãƒãƒ³æ°è§£ä»»åŠ‡ã¯ã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã®å—ã‘å…¥ã‚Œã‚’è¡¨æ˜ã™ã‚‹ã‚‚ã€OpenAIã®ä¸»è¦ãƒ¡ãƒ³ãƒãŒã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã«è¿½å¾“ã™ã‚‹ã¨è¡¨æ˜ã—ãŸã®ã§ãƒœãƒ¼ãƒ‰ãŒå¾©å¸°ã‚’æ‡‡é¡˜ã€çµå±€OpenAIã®CEOã¨ã—ã¦æˆ»ã‚‹ã“ã¨ã§å¹•å¼•ãã€‚è§£ä»»åŠ‡ã®èƒŒå¾Œã«ã¯ã€OpenAIã§AGIï¼ˆã‚¹ãƒ¼ãƒ‘ãƒ¼AI)ã‚’é”æˆã™ã‚‹è¦‹è¾¼ã¿ãŒç«‹ã£ãŸã€ãã‚ŒãŒQ*ã¨ã„ã†LLMã§ã€å¾“æ¥ã®LLMãŒè‹¦æ‰‹ã ã£ãŸæ•°ã®æ¨è«–ãŒå¯èƒ½ã«ãªã£ãŸã€Q*ã®å–ã‚Šæ‰±ã„ã‚’å·¡ã‚Šè§£ä»»é¨’å‹•ãŒèµ·ããŸã€ã¨ã„ã†ã†ã‚ã•ã§æŒã¡åˆ‡ã‚Šã«ã€‚Q*-learningãŒãã‚Œã§ã¯ï¼Ÿã¿ãŸãªã“ã¨ã«ãªã£ã¦æ§˜ã€…ãªã¨ã“ã‚ã§ç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€‚ãã‚Œä»¥å¤–ã§ã¯ã€intelãŒæº€ã‚’æŒã—ã¦neural-chat-7b-v3-1ã‚’å…¬é–‹ã€Mistral 7Bãƒ™ãƒ¼ã‚¹ãªã‚“ã ã‘ã©ã€æ§˜ã€…ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šç›¸å½“æ€§èƒ½ãŒè‰¯ã„ã¿ãŸã„ã€ã—ã‹ã—Falcon 180Bè¶Šãˆã¨ã„ã†ã“ã¨ã¯ãªã„ã¨æ€ã†ãã€‚AnthropicAIãŒ200kã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ãˆã‚‹Claude2.1ã‚’ç™ºè¡¨ã€ãƒ‡ãƒ¢ç‰ˆãŒåˆ©ç”¨å¯èƒ½ã§ã€ã•ã£ããçµæ§‹é•·æ–‡ã®æ—¥æœ¬èªã®PDFã‚’ãã®ã¾ã¾æŠ•å…¥ã§ãã‚‹ã¨ã‹ã€ã‚¨ãƒãƒ³ã‚²ãƒªã‚ªãƒ³ä¸–ç•Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‹•ã‹ã—ã¦ã¿ãŸã¨ã‹è©±é¡Œã«ã€‚ã€Œï¼“Dä¸–ç•Œã®ä¸­ã§èº«ä½“æ€§ã‚’ã‚‚ã£ãŸæ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã®è«–æ–‡ã€ã„ã‚„ ã€Œæœªæ¥ã®äºŒã¤ã®é¡”ã€ï¼ˆãƒ›ãƒ¼ã‚¬ãƒ³ï¼‰ã®AIï¼ˆä»®æƒ³ï¼“Dç©ºé–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§èº«ä½“æ€§ã‚’å­¦ç¿’ã•ã›ã‚‹ï¼‰ã‚’å½·å½¿ã•ã›ã‚‹ä¸–ç•ŒãŒç¾å®Ÿã«ãªã£ãŸã‚ˆã†ãªæ°—ãŒã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã™ã‚‹Q&Aã«ãŠã„ã¦ã€SQLæ–‡ã‚’ç”Ÿæˆã•ã‚Œã‚‹æ–¹æ³•ã¨ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†…å®¹ã‚’ã„ã£ãŸã‚“çŸ¥è­˜ã‚°ãƒ©ãƒ•ã«ã—ã¦Q&Aã™ã‚‹æ–¹æ³•ã‚’æ¯”è¼ƒã—ã€å¾Œè€…ã®ã»ã†ãŒé«˜æ€§èƒ½ã¨ã®å ±å‘Šã‚‚ã€‚ã¾ã‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã„ã†ã‹ãã†ã„ã†ã®ã‚’ä¸ãˆãŸã»ã†ãŒã„ã„ã«æ±ºã¾ã£ã¦ã„ã‚‹ã®ã ãŒã€‚RAGã«ãŠã„ã¦ã‚‚ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã®ãŒæœ‰åŠ¹ã‚‰ã—ã„ã€ãã®ã‚ãŸã‚Šã«ã¾ã äººã®å·¥å¤«ã®ä½™åœ°ãŒæ®‹ã£ã¦ã„ã‚‹ã€‚Llemmaã¯ã€LLMã§æ•°å­¦ã®å•é¡Œã‚’è§£ãã®ã«ã€å®šç†è¨¼æ˜å™¨ã‚’ä½¿ã†ã“ã¨ã‚’å‰æã«ã—ãŸPythonã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã§å®Ÿç¾ã€LLMã‚’æ´»ç”¨ã—ã¦å•é¡Œã‚’è§£ããƒ¡ã‚¿ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆç›´æ¥è§£ãã®ã§ã¯ãªãã¦ã€è§£ãæ‰‹é †ãƒ»æ–¹æ¡ˆã‚’ç”Ÿæˆã™ã‚‹ï¼‰ã®ï¼‘ã¤ã€‚LLMãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„è¨€èªã€SUQLã€ã‚‚ã„ã„æ„Ÿã˜ã§éæ§‹é€ ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ãˆã‚‹ã‚‰ã—ã„ãŒã€ä¾‹é¡ŒãŒãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã®ä¼šè©±ã¨ã¯ç¬¬ï¼’ä¸–ä»£AIã«ãŠã‘ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ å•é¡Œã½ãã¦ã„ã„ã­ï¼AIãŒäººé–“ãŒæ€ã„ã¤ã‹ãªã„ã‚ˆã†ãªã€Œç•°è³ªãªã€ä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ç§‘å­¦ãŒé€²åŒ–ã™ã‚‹ã€ã‹ã‚‚ã€‚ChatGPTã‚’ã¤ã‹ã£ã¦ã€éƒ¨å±‹ã‚’ç‰‡ä»˜ã‘ã¦ã„ã‚‹äººãŒã„ãŸã€ã“ã‚Œã¯ã™ã”ã„å¿œç”¨ã ï¼OECDã®AIã®å®šç¾©ã‚‚ç”ŸæˆAIã‚„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’é‘‘ã¿ï¼”å¹´ã¶ã‚Šã«æ”¹å®šã€äººã®æŒ‡ç¤ºã«å¾“ã‚ãšã¨ã‚‚ã€å…¥åŠ›ã«å¯¾ã—ã¦è‡ªã‚‰ã®ã¨ã‚‹ã¹ãå‹•ä½œã‚’æ¨æ¸¬ã™ã‚‹ãƒ¡ã‚¿èƒ½åŠ›ã«ã¤ã„ã‚‚æš—ç¤ºã€ã‚‚ã¯ã‚„AIã«å¯¾ã™ã‚‹ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢çš„ãªå“è³ªä¿è¨¼ã¯ä¸å¯èƒ½ãªäº‹æ…‹ã¸ã€‚

-  Banach-Tarski Embeddings and Transformers
	- https://arxiv.org/abs/2311.09387
	- å†å¸°çš„ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç·šå‹ç©ºé–“ã§ã®è¡¨ç¾ï¼ˆãƒãƒŠãƒƒãƒã‚¿ãƒ«ã‚¹ã‚­åŸ‹ã‚è¾¼ã¿ï¼‰ã‚’è€ƒãˆã‚‹ã¨ãã®è¡¨ç¾ä¸Šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼ˆå¾©å·ï¼‰ãŒTransformerã¨ã—ã¦è‡ªç„¶ã«å®Ÿè£…ã§ãã‚‹ã‚‰ã—ã„
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ãŸæ„å‘³åˆ†æã«ã‚ˆã‚‹è¾æ›¸è¨˜è¿°ã¸ã®å¿œç”¨
	- https://speakerdeck.com/yhkondo/da-gui-mo-yan-yu-moderuwoyong-itayi-wei-fen-xi-niyoruci-shu-ji-shu-henoying-yong
	- åŸ‹ã‚è¾¼ã¿ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼‰ã®è¾æ›¸ä½œæˆã¸ã®å¿œç”¨ã¨ã‹ã€æ•è‰å­ã‚’é¡Œæã«åŸ‹ã‚è¾¼ã¿ã‚’ã¤ã‹ãŸï½”é¡ä¼¼æ¤œç´¢ã—ã¦ã¿ã‚‹ä¾‹ãŒã€è‹±èªã«ã‚ˆã‚‹æ¤œç´¢ã€çµµæ–‡å­—ã«ã‚ˆã‚‹æ¤œç´¢ã€ã‚¯ãƒªã‚¨ãƒ¼ãƒ†ã‚£ãƒ–ãªæ¤œç´¢ãªã©äº‹ä¾‹ãŒã‚ã£ã¦é¢ç™½ã„
- Shicheng Liu et al., "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models"
	- https://arxiv.org/abs/2311.09818
	- LLMãƒ™ãƒ¼ã‚¹ã®æ–°ã—ã„è¨€èªã€SUQLã€ãŒé–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚SQLã‚’æ‹¡å¼µã—ã¦ã€Œéæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ã‚¨ãƒªã€ã‚’å‡¦ç†ã™ã‚‹ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚’å°å…¥
	- ã€SUQLï¼ˆStructured and Unstructured Query Languageï¼‰ã€
	- â‘  æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã¨éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã‚’æ‰±ã† 
	- â‘¡ SQLã«ã€éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹ãŸã‚ã®æ–°ã—ã„ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ã‚’è¿½åŠ  
	- â‘¢ ä¼šè©±å‹æ¤œç´¢ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’å‡¦ç† 
	- â‘£ ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹é€ åŒ–ãŠã‚ˆã³éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æŠ½å‡ºã™ã‚‹
	- å¾“æ¥ã®ç·šå½¢åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚„å¤šæ®µéšæ¤œç´¢ãŠã‚ˆã³æ¨è«–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æ¯”ã¹ã¦ã€SUQLã¯å›åç²¾åº¦ãŒå¤§å¹…ã«é«˜ã„
	- å®Ÿéš›ã®ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³ã«é–¢ã™ã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ã‚½ãƒ¼ã‚¹ã•ã‚ŒãŸè³ªå•ã¨ä¼šè©±ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å®Ÿç”¨æ€§ãŒç¢ºèªã•ã‚ŒãŸ
-  Meta disbanded its Responsible AI team
	- https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence
	- metaãŒè²¬ä»»ã‚ã‚‹AIã®ãƒãƒ¼ãƒ ã‚’è§£æ•£ã•ã›ãŸ
- çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…¥é–€
	- https://www.no-spare.com/store/products/seminar-20231129
	- æœ¬è¬›åº§ã§ã¯ã€é‡‘èæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¸ã®å¿œç”¨ã‚’é¡Œæã«ã€å‹•çš„ç·šå½¢ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¢ãƒ‡ãƒ«ãƒ»æœ€æ–°ã®ç ”ç©¶ã‚’è§£èª¬ã—ã¾ã™ã€‚
-  Hypotheses devised by AI could find â€˜blind spotsâ€™ in research
	- https://www.nature.com/articles/d41586-023-03596-0
	- AIãŒä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹éš›ã«ç›´é¢ã™ã‚‹èª²é¡Œã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã€ç‰©ç†çš„ãªæ³•å‰‡ã®ç†è§£ã€ä»®èª¬ã®ä¸€èˆ¬æ€§ã¨è§£é‡ˆæ€§ãªã©ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚
	- AIãŒä»®èª¬ã‚’ç”Ÿæˆã™ã‚‹å¯èƒ½æ€§ã¨ã—ã¦ã€äººé–“ãŒæ€ã„ã¤ã‹ãªã„ã‚ˆã†ãªã€Œç•°è³ªãªã€ä»®èª¬ã‚„ã€å®Ÿé¨“ã‚’è‡ªå‹•åŒ–ã™ã‚‹ã€Œãƒ­ãƒœãƒƒãƒˆç§‘å­¦è€…ã€ãªã©ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™
-  Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild
	- https://arxiv.org/abs/2311.06237
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’ã—ã°ãå€’ã—ã¦ã€ç•°å¸¸ãªæŒ¯ã‚‹èˆã„ã‚’ã•ã›ã‚ˆã†ã¨ã—ã¦ã„ã‚‹äººé”ï¼ˆé‡è‰¯ã®LLMãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ ï¼‰ã¸ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è«–æ–‡ã€‚æ”»æ’ƒæ–¹æ³•ã‚„ãã‚‚ãã‚‚ä½•ã®ãŸã‚ã«ã‚„ã£ã¦ã„ã‚‹ã®ã‹ï¼Ÿç­‰ã®èª¿æŸ»ã€‚
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã€ã‚²ã‚¹ãƒˆã‚«ãƒ¼ãƒ‰ã‚’ä½¿ã£ã¦ã€OpanAIã‚’è¨ªå•
	- https://x.com/sama/status/1726345564059832609?s=20
	- first and last time i ever wear one of these
-  ChipNeMo: Domain-Adapted LLMs for Chip Design
	- https://arxiv.org/abs/2311.00176
	- ChipNeMoã¯ãƒãƒƒãƒ—è¨­è¨ˆæ”¯æ´å‘ã‘ã«ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã—ãŸLLMã€‚é–‹ç™ºæ”¯æ´Chatbotã€EDAã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆã€ãƒã‚°è¦ç´„ã¨åˆ†æã‚’è¡Œã†ã€‚æ—¢å­˜LLMã«ã€å°‚ç”¨ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¿½åŠ ã—ãŸå¾Œã€ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œäº‹å‰äº‹å‰å­¦ç¿’ï¼ˆDAPT 230å„„ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€æŒ‡ç¤ºå­¦ç¿’ï¼ˆ1000ä¾‹ï¼‰ã‚’ã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œæ¤œç´¢è£œå¼·ã‚’è¡Œã†
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ãƒŠãƒ‡ãƒ©æ°ã€ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ãŸã¡ãŒãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã«Joinã™ã‚‹ã¨ã€ã€
	- https://x.com/satyanadella/status/1726509045803336122?s=20
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã«ã‚ˆã‚‹ç”ŸæˆAIã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
	- https://github.com/microsoft/generative-ai-for-beginners
	- The free 12 lesson course is available on Github and will teach you everything you need to know to start building Generative AI applications.
-  Learning to Filter Context for Retrieval-Augmented Generation
	- https://arxiv.org/abs/2311.08377
	- RAGã«ãŠã„ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’å­¦ç¿’ã™ã‚‹
	- èªå½™ãŠã‚ˆã³æƒ…å ±ç†è«–çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’é€šã˜ã¦æœ‰ç”¨ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç‰¹å®šã—ã€ãƒ†ã‚¹ãƒˆä¸­ã«ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã™ã‚‹ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒå«ã¾ã‚Œã¾ã™ã€‚
	- FILCO ã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã« String Inclusion (STRINC)ã€Lexical Overlapã€Conditional Cross-Mutual Information (CXMI) ãªã©ã®æŠ€è¡“ã‚’ä½¿ç”¨
- æ—¥æœ¬èªå¯¾å¿œ LLM(13B è¦æ¨¡)ã®, è¡Œé–“ã‚’èª­ã‚€ã‚ˆã†ãªã‹ã—ã“ã•ãŒã‚ã‚‹ã‹è©¦ã—ãŸãƒ¡ãƒ¢(ç¾çŠ¶ Qwen 14B ãŒãƒ™ã‚¹ãƒˆ)
	- https://zenn.dev/syoyo/articles/59a5ccbbb5660e
	- 7B ä»¥ä¸‹(10B æœªæº€)ã‚‚è©¦ã—ã¾ã—ãŸãŒ, è¡Œé–“ã‚’èª­ã‚€ã»ã©ã®ã‹ã—ã“ã•ã¯ãªã, 13B è¦æ¨¡ã§é£›èºçš„ã«ã‹ã—ã“ã•ãŒä¸ŠãŒã‚‹æ„Ÿã˜ã ã£ãŸã®ã§, 13 B è¦æ¨¡ã®ã‚’é¸ã‚“ã§ã„ã¾ã™.
	- qwen.cpp(llama.cpp variant)ã§ f16 é‡å­åŒ–ç‰ˆã‚’å‹•ã‹ã—ã¾ã—ãŸ.
	- q4 ã‚ãŸã‚Šã«é‡å­åŒ–ã ã¨ã„ãã‚‰ã‹ã‹ã—ã“ã•è½ã¡ã¾ã—ãŸ(ãã‚Œã§ã‚‚ã»ã‹ã®æ—¥æœ¬èª LLM ã‚ˆã‚Šã‚ˆã„çµæœã‚’ãˆã‚‰ã‚Œã‚‹)  ã¾ãŸ, Qwen7B ã‚‚ã‚ã¾ã‚Šã‹ã—ã“ãã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ.
	- Qwen 14B(Chat) ã¡ã‚ƒã‚“ãŒè¡Œé–“ã‚’èª­ã‚€ã»ã©ã®ã‹ã—ã“ã•ã‚’è¦‹ã›ã¾ã—ãŸ!
- OpenAIãŒNPO+ã§ã‚ã‚‹ã‚ˆã†ãªã“ã¨ãŒã€ä»Šå›ã®ã‚¢ãƒ«ãƒˆãƒãƒ³æ°è§£ä»»ã«ã¤ãªãŒã£ãŸã¨ã®çµµæŸ„
	- https://x.com/GOROman/status/1726701627468546511?s=20
-  Azure OpenAI Service å…¥é–€ by npakaã•ï½
	- https://note.com/npaka/n/n46e6ad252ce1?sub_rt=share_h
	- ã€ŒAzure OpenAI Serviceã€ã§ã€Œgpt-3.5-turboã€ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹é †ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚
-  Orca 2: Teaching Small Language Models How to Reason
	- https://huggingface.co/papers/2311.11045
	- å°ã•ã„ã“ã¨ã¯ã„ã„ã“ã¨ã 
-  Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data
	- https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1
	- llamaindexã®JerryãŒæ”¾ã¤ã€streamlitã‚’ã¤ã‹ã£ãŸã€RAGã‚¢ãƒ—ãƒªç”Ÿæˆãƒ„ãƒ¼ãƒ«RAGs
	- â€œChatGPT over your dataâ€ without needing to code.
- Large-scale pancreatic cancer detection via non-contrast CT and deep learning
	- https://www.nature.com/articles/s41591-023-02640-w
	- ï½¢å˜ç´”CTã®è†µè‡“ãŒã‚“æ¤œå‡ºAIï½£
	- å˜ç´”CTã§ã®è†µè‡“ãŒã‚“æ¤œã¯ä¸å¯èƒ½ã¨è€ƒãˆã‚‰ã‚Œã¦ããŸ 
	- ãã®AIã‚’é–‹ç™º 
	- ç¾å®Ÿä¸–ç•Œã®ãƒãƒ«ãƒã‚·ãƒŠãƒªã‚ªæ¤œè¨¼ã®ç—…å¤‰æ¤œå‡ºã§ã€92.9%ã®æ„Ÿåº¦ã¨ 99.9% ã®ç‰¹ç•°åº¦ã‚’é”æˆ 
	- è†µè‡“ãŒã‚“ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®æ–°ã—ã„ãƒ„ãƒ¼ãƒ«ã®å¯èƒ½æ€§
-  RAGè©•ä¾¡ãƒ„ãƒ¼ãƒ«ã® "RAGAS" ã‚’ä½¿ã£ã¦ã€RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹
	- https://qiita.com/s3kzk/items/44b8780c656b4f747403
	- ä»Šå›è§¦ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯åˆ†å‰²æ™‚ã®è¨­å®šä»¥å¤–ã«ã‚‚ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ±ºå®šã€EmbeddingãŠã‚ˆã³å¿œç­”ã®ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹LLMã®é¸å®šã€ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢/æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸å®šãªã©ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦ç´ ã¯æ•°å¤šãå­˜åœ¨ã—ã¾ã™ã€‚
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°OpenAIã«å¾©å¸°ã™ã‚‹ã¨
	- https://x.com/OpenAI/status/1727206187077370115?s=20
-  2é€±é–“ä½¿ã„å€’ã—ã¦ã‚ã‹ã£ãŸï½¢GPT-4-Turboã®è¡æ’ƒï½£ã€‚OpenAIã®ï½¢ãŠå®¶é¨’å‹•ï½£ã§è¦‹é€ƒã—ã¦ã‚‹å ´åˆã˜ã‚ƒãªã„
	- https://www.businessinsider.jp/post-278766
- AnthropicAIã‚ˆã‚ŠClaude2.1ã®ç™ºè¡¨
	- https://x.com/AnthropicAI/status/1727001773888659753?s=20
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã¯ãªã‚“ã¨ 200k ã¨ 2 å€ã«æ‹¡å¤§ã€‚ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®ä½æ¸›ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®å¯¾å¿œã€ä¾¡æ ¼ã®å¼•ãä¸‹ã’ã€å¤–éƒ¨APIã¨ã®é€£æºæ©Ÿèƒ½(ãƒ™ãƒ¼ã‚¿ç‰ˆ) ãªã©
	- https://claude.ai/ã€€ã§ãŠè©¦ã—å¯èƒ½
- ChatGPTã§éƒ¨å±‹ã®ç‰‡ã¥ã‘ã‚’ã—ã¦ã„ã‚‹äººãŒã„ã„ã‚‹
	- https://x.com/fjtn_c/status/1727216371711586402?s=20
	- ï¼ˆéƒ¨å±‹ã®å†™çœŸé€ã£ã¦ç‰‡ä»˜ã‘ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£ã—ã¦ã‚‚ã‚‰ã£ã¦ã€ãã‚Œã‚’å®Ÿè¡Œã—ã¦å†™çœŸæ’®ã£ã¦ã¾ãŸé€²æ—ã‚’é€ã‚‹â†’åŒã˜ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—ï¼‰
- æ„›æ–°è¦šç¾…ã®å­«ï¼ˆå¤§äº•ç”ºã®çœ¼ç§‘åŒ»ï¼‰ã®é©šæ„•ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰
	- https://x.com/aishinkakura_i/status/1727477535234248712?s=20
	- å­¦ä¼šã§ã‚¢ãƒ¡ãƒªã‚«ã‚’è¨ªã‚ŒãŸéš›ã€ã‚¤ãƒŸã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€Œæ¸…æœã®å­å­«ã‹ã€ã£ã¦å°‹å•ã‚’å—ã‘ã€ã—ã°ã‚‰ãè¶³ã‚’æ­¢ã‚ã‚‰ã‚Œâ€¦
- metaã‹ã‚‰ã€Getting started  with Llama
	- https://ai.meta.com/llama/get-started/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama2&utm_content=image
-  å˜è¡Œæœ¬ãŒå…¥ã‚‹Claude 200kã§åƒ•ã¨ã€Œã‚¨ãƒ´ã‚¡ãƒ³ã‚²ãƒªã‚ªãƒ³ã€
	- https://note.com/shoty/n/n03bff29f683f
	- æ—¥æœ¬èªã ã¨150ãƒšãƒ¼ã‚¸ã„ã‹ãªã„ãã‚‰ã„ãŒèª¿ç†ã§ãã‚‹ã®ã§ã¯ãªã„ã‹ã¨æ€ã†ã€‚ã¤ã¾ã‚Š**å˜è¡Œæœ¬ä¸€å†ŠãŒå…¥ã£ã¦ã—ã¾ã†**
	- ã‚¨ãƒãƒ³ã‚²ãƒªã‚ªãƒ³ã®ç‰©èªã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã§ãã‚‹ã‹ã¨ã„ã†æŒ‘æˆ¦ã‚‰ã—ã„
- ã€DSã«KaggleãŒå¿…ãšã—ã‚‚å¿…è¦ã§ã¯ãªã„è©±ã€‘
	- https://x.com/Nurruttan/status/1727495591905858016?s=20
	- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã¨è¨€ã£ã¦ã‚‚ã€ ã€Œâ‘ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆå‹ã€ ã€Œâ‘£ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‹ã€ ã®ã‚­ãƒ£ãƒªã‚¢ãƒ—ãƒ©ãƒ³ã§ã¯Kaggleå®Ÿç¸¾ã®é‡è¦æ€§ã¯ä½ã„
	-  ä¸€æ–¹ã§ã€ ã€Œâ‘¡ã‚µãƒ¼ãƒ“ã‚¹ã‚°ãƒ­ãƒ¼ã‚¹å‹ã€ ã€Œâ‘¢è£½å“é–‹ç™ºå‹ã€ ã€Œâ‘¤AIé–‹ç™ºå‹ã€ ã¯é‡è¦åº¦ã¯é«˜ã„ã€‚
- Google Bardã§Youtubeã¨ãƒãƒ£ãƒƒãƒˆã§ãã‚‹ã‚ˆã†ã«
	- https://bard.google.com/chat
-  ã€ŒPaper Interpreterã€ã‚’ä½¿ã£ã¦è«–æ–‡ã‚’èª­ã‚‚ã†ï¼
	- https://note.com/daichi_konno/n/nb1f1ac368a30
	- æ±å¤§ã®ã€ç´ºé‡å¤§åœ°å…ˆç”Ÿä½œæˆ
	- **ã€Œè«–æ–‡ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€å†…å®¹ã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã‚Œã‚‹AIã€**
- ã‚¢ãƒ«ãƒˆãƒãƒ³æ°é›»æ’ƒè§£ä»»åŠ‡ã®è£ã«ã€OpenAIãŒã€AGIã‚’é–‹ç™ºã™ã‚‹ã‚ã©ãŒã¤ã„ãŸã‹ã‚‰ã¨ã„ã†
	- Q*-learningã¨ã„ã†æ‰‹æ³•ã«ã‚ˆã‚Šã€æ•°å€¤è¨ˆç®—ãªã©LLMãŒè‹¦æ‰‹ã¨ã—ã¦ã„ãŸèª²é¡Œã‚‚è§£ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
	- https://x.com/hbouammar/status/1727683545852768295?s=20
	- A*ã£ã¦ã®ã¯æ¢ç´¢ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã ã‘ã©ã€ãã‚Œã®Q-learningç‰ˆã¨ã„ã†è©±
- Intelè¬¹è£½ã®ã€LLMãŒã€ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã§ä¸Šä½ã®æ€§èƒ½ã‚’ã¯ã˜ãå‡ºã™
	- https://x.com/Yampeleg/status/1727679553714217421?s=20
	- https://huggingface.co/Intel/neural-chat-7b-v3-1
	- A 7B model from Intel almost as capable as Falcon 180B:ã“ã‚Œã¯æœ¬å½“ã‹ï¼ï¼ï¼
	- Base model: Mistral 7B. 
	- Fine Tuned on: SlimOrca 
	- DPO: LLaMA-13B vs ChatGPT Gens (Prefer ChatGPT)
- An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
	- ï¼“Dä¸–ç•Œã®ä¸­ã§èº«ä½“æ€§ã‚’ã‚‚ã£ãŸæ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
	- 3Dä¸–ç•Œã«å¯¾ã—ã¦ã€ã„ã‚ã°è¨˜å·æ¥åœ°ã™ã‚‹ã‚ˆã†ãªè¨“ç·´ã‚’ã™ã‚‹ã“ã¨ã§èº«ä½“æ€§(embodiment)ã‚’å–å¾—ã€è‡ªç„¶è¨€èªå‡¦ç†ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹ãªã©ã®å¤šæ§˜ãªãƒ‰ãƒ¡ã‚¤ãƒ³ã§æ±ç”¨çš„ãªã‚¿ã‚¹ã‚¯ã‚’è§£æ±ºã§ãã‚‹æ±ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ§‹ç¯‰ã§ããŸã¨ã„ã†
	- æ‰‹æ®µã¨ã—ã¦ã¯ã€3Dä¸–ç•Œã®ç†è§£ã¨ç›¸äº’ä½œç”¨ã‚’å¿…è¦ã¨ã™ã‚‹ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ¬ãƒ™ãƒ«ã¨ã‚·ãƒ¼ãƒ³ãƒ¬ãƒ™ãƒ«ã®å¤šãƒ¢ãƒ¼ãƒ€ãƒ«ãªã‚¿ã‚¹ã‚¯ã‚’å«ã‚€ã€è¦æ¨¡ã¨è¤‡é›‘ã•ã«å„ªã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ…é‡ã«ä½œæˆ
-  å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’LoRAã§å¼·åŒ–ã™ã‚‹éš›ã«å½¹ç«‹ã¤æƒ…å ±ã‚’ç ”ç©¶è€…ãŒå…¬é–‹
	- https://gigazine.net/news/20231123-llm-lora/
	- LoRAã¯ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã«è¿½åŠ ã®æƒ…å ±ã‚’å­¦ç¿’ã•ã›ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã§ãã‚‹ä»•çµ„
	- **â—†LoRAã®åŠ¹æœã«ã¯ä¸€è²«æ€§ãŒã‚ã‚‹**
	- **â—†QLoRAã‚’ä½¿ãˆã°è¿½åŠ å­¦ç¿’æ™‚ã®VRAMä½¿ç”¨é‡ã‚’å¤§å¹…ã«ç¯€ç´„å¯èƒ½**
	- **â—†æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯Adamã§ã‚‚SGDã§ã‚‚å¤§å·®ãªã„**
	- **â—†LoRAã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã™ã¨æ€§èƒ½ãŒä½ä¸‹ã™ã‚‹**
	- **â—†LoRAã«ã‚ˆã‚‹è¿½åŠ å­¦ç¿’ã¯å˜ä¸€ã®GPUã§å®Ÿè¡Œå¯èƒ½**
- Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall
	- Claude2.1ã®é•·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆèƒ½åŠ›ã«å¯¾ã™ã‚‹ã€ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
	- https://x.com/GregKamradt/status/1727018183608193393?s=20
	- 200K ãƒˆãƒ¼ã‚¯ãƒ³ (ç´„ 470 ãƒšãƒ¼ã‚¸) ã§ã€Claude 2.1 ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€éƒ¨ã®æ·±ã•ã§äº‹å®Ÿã‚’æ€ã„å‡ºã™ã“ã¨ãŒã§ãã¾ã—ãŸã€‚ 
	- æ–‡æ›¸ã®ä¸€ç•ªä¸Šã¨ä¸€ç•ªä¸‹ã«ã‚ã‚‹äº‹å®Ÿã¯ã»ã¼ 100% ã®ç²¾åº¦ã§å†ç¾ã•ã‚Œã¾ã—ãŸ 
	- æ–‡æ›¸ã®ä¸Šéƒ¨ã«ã‚ã‚‹äº‹å®Ÿã¯ä¸‹éƒ¨ã‚ˆã‚Šã‚‚ä½ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ãƒªã‚³ãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸ (GPT-4 ã¨åŒæ§˜) 
	- ~90,000 ãƒˆãƒ¼ã‚¯ãƒ³ä»¥é™ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸‹éƒ¨ã«ã‚ã‚‹ãƒªã‚³ãƒ¼ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã¾ã™ã¾ã™æ‚ªåŒ–ã—å§‹ã‚ã¾ã—ãŸ 
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒçŸ­ã„å ´åˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä¿è¨¼ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ
- Why do tree-based models still outperform deep learning on typical tabular data?
	- https://hal.science/hal-03723551
	- Why do tree-based models still outperform deep learning on tabular data?â€ confirms tree-based models outperform deep learning and explain some of the reasons why.
	- When it comes to #tabulardata and #timeseries (by far the most important majority of data for almost any real company), deep learning is not one needs. 
- Pythonã«ã‚ˆã‚‹ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•å…¥é–€: åŸºç¤ç†è«–ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã®å®Ÿè£…ã¾ã§
	- https://www.amazon.co.jp/dp/4621308882?_encoding=UTF8&psc=1&ref_=cm_sw_r_tw_ud_dp_RW79QAZKZRQ7K9N885XB
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã«ãŠã„ã¦ã‚‚,å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦ç‰©æ€§å€¤ã‚„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¨å®šã—ã¤ã¤,ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç²¾åº¦ã‚’é«˜ã‚ã‚‰ã‚Œã‚‹ã‚ˆã†ãª,ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã¨èåˆã—ãŸæ‰‹æ³•ã®é–‹ç™ºãŒé€²ã‚“ã§ã„ã‚‹.ãã“ã§æœ¬æ›¸ã§ã‚‚,ãƒ‡ãƒ¼ã‚¿åŒåŒ–ã®åŸºç¤ã‹ã‚‰ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ¢ãƒ‡ãƒ«ã¸ã®å®Ÿè£…æ–¹æ³•ã¾ã§ã‚ã‚ã›ã¦ç´¹ä»‹ã™ã‚‹.
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã§ã¯ã€ç§©åºå¤‰æ•°ã®æ‹¡æ•£æ–¹ç¨‹å¼ã¨åå¿œæ–¹ç¨‹å¼ã‚’åŒæ™‚ã«è§£ãã“ã¨ã§ã€çµ„ç¹”å½¢æˆéç¨‹ã‚’è¨ˆç®—ã—ã¾ã™ã€‚æ‹¡æ•£æ–¹ç¨‹å¼ã¯ã€ç§©åºå¤‰æ•°ãŒæ‹¡æ•£ã™ã‚‹éš›ã®æŒ™å‹•ã‚’è¨˜è¿°ã™ã‚‹æ–¹ç¨‹å¼ã§ã™ã€‚åå¿œæ–¹ç¨‹å¼ã¯ã€ç›¸ã®å¤‰åŒ–ã‚’è¨˜è¿°ã™ã‚‹æ–¹ç¨‹å¼ã§ã™ã€‚
	- ãƒ•ã‚§ãƒ¼ã‚ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ³•ã¯ã€é‡‘å±ã®å‡å›ºã€å¤šçµæ™¶ç²’æˆé•·ã€æ‹¡æ•£ç›¸å¤‰æ…‹ãªã©ã€ã•ã¾ã–ã¾ãªææ–™çµ„ç¹”å½¢æˆéç¨‹ã®è¨ˆç®—ã«ç”¨ã„ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€å¿œåŠ›å ´ã‚„é›»ç£å ´ã«ãŠã‘ã‚‹çµ„ç¹”å½¢æˆã‚„ãƒŠãƒã‚¹ã‚±ãƒ¼ãƒ«ã«ãŠã‘ã‚‹ãƒ¢ãƒ‡ãƒ«åŒ–ãªã©ã€ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ»ãƒãƒ«ãƒãƒ•ã‚£ã‚¸ãƒƒã‚¯ã‚¹ã‚’å¯¾è±¡ã¨ã—ãŸç¨®ã€…ã®å·¥å­¦åˆ†é‡ã«ã‚‚å¿œç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
- ã€Œãƒã‚¹ã‚¿ãƒ¼ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã®è‘—è€…ã€Domingosæ°ã€Q*-learningã®åŠ¹æœã‚’ã¿ã¦ã€äººé¡ã®çµ‚ç„‰ã‚’å«ã¶
	- https://x.com/pmddomingos/status/1727562239060656339?s=20
	- Q* can solve simple math problems that symbolic AI could solve 50 years ago. Panic! AGI is here! Humanity is over!
- A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases
	- https://arxiv.org/abs/2311.07509
	- impact of KGs for question answering on SQL databases: 54% accuracy vs. 16% with instructions directly on SQL databases.
	- SQL DBã‚’å‚ç…§ã—ã¦è³ªå•å¿œç­”ã‚’è¡Œã†ã‚·ã‚¹ãƒ†ãƒ ã§ã¯ã€LLMã«ç›´æ¥SQLã‚’å‚ç…§ã•ã›ã‚‹ã¨16%ã®æ­£è§£ç‡ã—ã‹å‡ºãªã‹ã£ãŸãŒLLMã‚’ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãã‚Œã‚’å‚ç…§ã•ã›ã‚‹ã¨54%ã«æ”¹å–„ã—ãŸã¨ã„ã†ç ”ç©¶ã€‚
	- æœ¬è³ªçš„ã«æŒã£ã¦ã„ã‚‹æƒ…å ±ãŒåŒã˜ã§ã‚‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ã‚ˆã£ã¦RAGã®ç²¾åº¦ãŒå¤‰ã‚ã‚‹ã“ã¨ã®ä¸€ä¾‹ã¨ã‚‚ã¿ãªã›ã‚‹
- ã†ã¿ã‚†ãæ°ã€Claude2.1ã®æ€§èƒ½ã«èˆŒã‚’å·»ã
	- https://x.com/umiyuki_ai/status/1727875985167790529?s=20
	- Claudeç„¡æ–™ç‰ˆè©¦ã—ã¦ã¿ãŸã‘ã©ã€çµæ§‹é•·æ–‡ã®æ—¥æœ¬èªpdfå…¥åŠ›ã—ã¦è¦ç´„ã—ã¦ã£ã¦ãŠé¡˜ã„ã—ãŸã‚‰ã€ã¡ã‚ƒã‚“ã¨å†…å®¹èª­ã‚“ã§è¦ç´„ç®‡æ¡æ›¸ãå‡ºã—ã¦ãã‚ŒãŸï¼ˆç›®æ¬¡ä¸¸å†™ã—ã§ã¯ãªã„ï¼‰ã€€ï¼“ç« ã®å†…å®¹èª¬æ˜ã—ã¦ã£ã¦è¨€ã£ãŸã‚‰ã¡ã‚ƒã‚“ã¨èª¬æ˜ã—ã¦ãã‚ŒãŸã€‚ã¤ã¾ã‚Šã¡ã‚ƒã‚“ã¨æœ€å¾Œã¾ã§èª­ã‚“ã§ç­”ãˆã¦ã‚‹ã€‚ã‹ãªã‚Šçš„ç¢ºãªå¿œç­”ã‚’è¿”ã—ã¦ãã‚Œã‚‹ã€‚ãã‚Œã§ã‚¿ãƒ€ã€‚ã“ã‚Œç›¸å½“ã‚¹ã‚´ã‚¤ã­
- Yuhan Sun et al., "To be or not to be? an exploration of continuously controllable prompt engineering"
	- https://arxiv.org/abs/2311.09773
	- ã“ã‚Œã¾ã§ã€ŒLLMã®å‹•ãã‚’è¦³å¯Ÿã—ã¦"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª¿ç¯€"ã™ã‚‹ã€æ‰‹æ³•ãŒè¿½ç©¶ã•ã‚Œã¦ãã¾ã—ãŸãŒã€é™ç•ŒãŒã‚ã‚‹ãŸã‚ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹"LLMã®å‹•ãã‚’ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã«èª¿æ•´"ã™ã‚‹ã€æ‰‹æ³•ã€ControlPEã€
	- è‡ªå‹•é‹è»¢ã‚·ã‚¹ãƒ†ãƒ ãªã©ã‚’æ‰‹æ›ã‘ã‚‹ã‚»ãƒ³ã‚¹ã‚¿ã‚¤ãƒ ç¤¾ã«ã‚ˆã‚‹
	- ControlPEã¯ç«¶åˆæŠ€è¡“ã¨æ¯”è¼ƒã—ã¦ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å½±éŸ¿ã‚’ã“ã¾ã‹ãèª¿æ•´ã§ãã‚‹æ‰‹æ³•
	- â‘  LoRAã‚’åˆ©ç”¨ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ â‘¡ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å½±éŸ¿ã‚’é€£ç¶šçš„ã«å¾®èª¿æ•´ â‘¢ å¾“æ¥ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’è£œå®Œã™ã‚‹
- Q*ã®ã‚‚ã¨ã‚‚ã¨ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’å‡ºã—ãŸè«–æ–‡è‘—è€…ãŒè‡ªè«–æ–‡ã‚’å®£ä¼
	- https://x.com/McaleerStephen/status/1727524295377596645?s=20
	-  A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks
	- https://arxiv.org/abs/2102.04518
- Q*ã«ã¤ã„ã¦è‘—åãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆErnest Okumuraã•ã‚“ã®ã‚³ãƒ¡ãƒ³ãƒˆ
	- https://x.com/pacocat/status/1728052432016470281?s=20
	- Q*ãŒQ-learningã‹ã‚‰æ¥ã¦ã„ã‚‹ã‹ã¯çŸ¥ã‚‰ãªã„ã‘ã‚Œã©ã‚‚ã€åˆ¶ä½œè€…ã«ã¨ã£ã¦å¥½ã¾ã—ã„å‡ºåŠ›ã‚’å¾—ã‚‹ãŸã‚ã«æ–¹ç­–ç©ºé–“ã‚’æ¢ç´¢ã™ã‚‹æŠ€è¡“ã¯ä»Šå¾Œã•ã‚‰ã«æ±‚ã‚ã‚‰ã‚Œã¦ã„ãã¨æ€ã†ã—ã€RLHFã¿ãŸã„ãªåˆ†ã‹ã‚Šã‚„ã™ã„ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’è¶…ãˆã¦AGIã¿ãŸã„ãªæ–‡è„ˆã§ã‚‚é‡å¿ƒçš„ãªè©¦ã¿ã¯å¢—ãˆã¦ãã‚‹ã‚“ã˜ã‚ƒãªã„ã§ã—ã‚‡ã†ã‹ã€‚
- Sparse Transformersï¼šå…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã«ã‚ˆã‚‹è¨ˆç®—é‡å¢—åŠ å•é¡Œã¸ã®é©æ–°çš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
	- https://ai-scholar.tech/articles/transformer/sparseTransformer
	- Attentionã®ãƒ¬ã‚¤ãƒ¤ãƒ¼æ¯ã®ç‰¹å¾´ã‚’å†ç¾ã™ã‚‹ã“ã¨ã§ï¼Œè¨ˆç®—é‡ã®å‰Šæ¸›ã‚’é”æˆ  
	- Sliding Window Attenionã€Dilated Sliding Window Attentionã€Global Attentionã¨ã„ã†3ã¤ã®Attentionã‚’ä½¿ã£ã¦Transformernã®è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãŸ  
	- è¨ˆç®—é‡ã‚’å‰Šæ¸›ã—ãŸã ã‘ã§ã¯ãªãã¦ï¼Œå½“æ™‚ã®SOTAã‚’é”æˆã—ã¦ã„ã‚‹ï¼
-  Llemma: An Open Language Model For Mathematics
	- https://arxiv.org/abs/2310.10631
	- ã©ã†ã‚‚ã€LLMã‚’ã¤ã‹ã£ã¦ã€å®šç†è¨¼æ˜å™¨ã‚’ã¤ã‹ã†pythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã‚‰ã—ã„ã€‚å®Ÿéš›ã«èª¬ãã®ã¯pythonã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ï¼‹å®šç†è¨¼æ˜å™¨ã®çµ„ã¿åˆã‚ã›ã€‚
	- The AlgebraicStack dataset of 11B tokensãŒæä¾›ã•ã‚Œã‚‹
	- Llema can solve mathematical problems using a Python interpreter and a formal theorem prover.
- LlamaIndex vs. OpenAI Assistants API
	-  RAG Evaluation Series: Validating the RAG Performance of OpenAI vs LlamaIndex
	- https://www.tonic.ai/blog/rag-evaluation-series-validating-rag-performance-openai-vs-llamaindex
- ChatGPTã‚¢ãƒ—ãƒªã®éŸ³å£°ä¼šè©±ãŒç„¡æ–™ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚‚é–‹æ”¾
	- https://x.com/IELTS_expert/status/1728326991676670222?s=20
	- è‹±èªå­¦ç¿’ã‚½ãƒ•ãƒˆã‚„æœ‰æ–™ãƒ¬ãƒƒã‚¹ãƒ³ãŒä¸è¦ã«
- JARVIS-1ã¯æœ¬å½“ã¯ã™ã”ã„ã€
	- https://x.com/ai_database/status/1728257353852797143?s=20
	- ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆï¼ˆåºƒå¤§ãªãƒãƒ¼ãƒãƒ£ãƒ«ä¸–ç•Œã§æ¡æ˜ã‚„å»ºè¨­ã‚’è¡Œã†ã‚²ãƒ¼ãƒ ï¼‰ã‚’ä¸Šæ‰‹ã«ãƒ—ãƒ¬ã‚¤ã™ã‚‹AIã€JARVIS-1ã€ãŒé–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚ éå¸¸ã«è¤‡é›‘ãªå‹•ä½œã‚’å«ã‚€200ç¨®é¡ä»¥ä¸Šã®è¡Œå‹•ãŒå¯èƒ½ã¨ã®ã“ã¨ã€‚
	-  ã“ã®ã‚ˆã†ãªæŠ€è¡“ã‚’å¿œç”¨ã™ã‚‹ã¨ã€ãƒ­ãƒœãƒƒãƒˆãŒç¾å®Ÿä¸–ç•Œã§ã‚‚ã•ã¾ã–ã¾ãªé‡è¦ã‚¿ã‚¹ã‚¯ã‚’é”æˆã§ãã‚‹ã‚ˆã†ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚â€¦
- æœ€çµ‚çš„ã«ã™ã¹ã¦ã®çµ±è¨ˆã¯ãƒ™ã‚¤ã‚ºã«è¡Œãç€ãã—ã‹ãªã„ã¨æ€ã£ã¦ã„ã¾ã™ï¼ˆçµ±è¨ˆæ•°ç†ç ”ç©¶æ‰€ã€éŒè°·æ°ï¼‰
	- https://www.ism.ac.jp/ism_info_j/labo/project/162.html
- ãƒ«ã‚«ãƒ³å…ˆç”Ÿã«ã‚ˆã‚‹Q*ã«å¯¾ã™ã‚‹è¡¨æ˜
	- https://x.com/ylecun/status/1728126868342145481?s=20
	- ã€ŒQ*ã«é–¢ã™ã‚‹å®Œå…¨ãªãƒŠãƒ³ã‚»ãƒ³ã‚¹ã®æ´ªæ°´ã¯ç„¡è¦–ã—ã¦ã­ã€‚LLMã®ä¿¡é ¼æ€§ã‚’å‘ä¸Šã•ã›ã‚‹ä¸»ãªèª²é¡Œã®1ã¤ã¯ã€è‡ªå·±å›å¸°çš„ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã‚’ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«ç½®ãæ›ãˆã‚‹ã“ã¨ã§ã™ã€
- Macã§llama2ã‚’è©¦ã™ãŸã‚ã®swift-chat
	- https://github.com/huggingface/swift-chat
	- Llama 2 7B chat, running 100% private on Mac, powered by CoreML!
	- Pedro Cuencaã•ã‚“ã¯ç¾åœ°æ™‚é–“2023å¹´08æœˆ08æ—¥ã€Apple Silicon Macãªã©Appleãƒ‡ãƒã‚¤ã‚¹ä¸Šã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LLM)ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®Swiftãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨Demoã‚¢ãƒ—ãƒªã‚’å…¬é–‹
	- Swiftã§Transformersãƒ©ã‚¤ã‚¯ãªAPIã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã«é–‹ç™ºã—ãŸSwiftãƒ‘ãƒƒã‚±ãƒ¼ã‚¸â€swift-transformersâ€ã¨ã€Demoã‚¢ãƒ—ãƒªâ€swift-chatâ€ã€åŠ ãˆã¦Transformersãƒ¢ãƒ‡ãƒ«ã‚’CoreMLã¸å¤‰æ›ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼â€transformers-to-coremlâ€ã§ã€
	- CoreMLãŒå½¹ã«ç«‹ã£ãŸã¨ã€ã€
- OECDã€ç”ŸæˆAIã‚„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’è€ƒæ…®ã—ã¤ã¤AIã®å®šç¾©ã‚’æ”¹å®šã€
	- https://www.euractiv.com/section/artificial-intelligence/news/oecd-updates-definition-of-artificial-intelligence-to-inform-eus-ai-act/
	- æ¬§å·AIæ³•ãªã©ã®ä»–ã®è¦åˆ¶ã¨ã®æ•´åˆæ€§ã‚‚è€ƒæ…®ã—ãŸã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ã¨ã£ãŸ
	- ç›®æ¨™ã‚’äººé–“ãŒå®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ã„ã†äº‹å®Ÿã¸ã®è¨€åŠã‚’å‰Šé™¤ã€
	- ã€Œå‡ºåŠ›ã®ç”Ÿæˆæ–¹æ³•ã‚’æ¨æ¸¬ã™ã‚‹ã€ã¨ã„ã†æ–‡è¨€ã‚‚ã€AI ãƒ¢ãƒ‡ãƒ«ãŒç’°å¢ƒã‹ã‚‰å…¥åŠ›ã‚’å—ã‘å–ã‚Šã€1 ã¤ä»¥ä¸Šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’é€šã˜ã¦é©åˆ‡ãªå‡ºåŠ›ã‚’æ€ã„ã¤ãã¨ãã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«å°å…¥

## 11/20

ä»Šé€±ã¯ã€OpenAIã®CEOã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã®é›»æ’ƒè§£ä»»ãŒå…¨ã¦ã‚’æŒã£ã¦è¡Œã£ãŸã€‚å…ˆé€±OpenAI dev dayã§é›„å§¿ã‚’ã€ãã—ã¦äººé¡ã®æœªæ¥ã‚’å£é–“è¦‹ãŸã®ã«ã€‚ã€‚ãƒœãƒ¼ãƒ‰ã‹ã‚‰å¾©å¸°ã®è¦è«‹ã‚‚ã‚ã‚‹ã¨ã„ã†ã—ã€ã¾ã ã¾ã ç¾åœ¨é€²è¡Œå½¢ã€‚ã•ã¦ã€RAGã‚‚embeddingã‚’ã¤ã‹ã£ãŸé¡ä¼¼æ¤œç´¢ã‚ˆã‚Šã‚‚æ§‹é€ ã‚’åŠ å‘³ã—ãŸæ¤œç´¢ã¨ã‹ã€å¤šæ§˜æ€§ã‚’ã‚‚ã¤æ¤œç´¢çµæœã®åˆ©ç”¨ã¨ã‹ã€ã ã‚“ã ã‚“ã€æ¨è–¦æŠ€è¡“ãªã©ã§ç¢ºç«‹ã•ã‚ŒãŸãƒã‚¦ãƒã‚¦ãŒæ´»ç”¨ã•ã‚Œå§‹ã‚ãŸã€‚LlamaIndexã®æ–°æ©Ÿèƒ½ã€text-to-SQL+semanticã£ã¦ã®ãŒã„ã„ã­ã€‚LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–¢ä¿‚ã‚‚ã«ãã‚„ã‹ã€å˜ã«è«–ç†ã‚½ãƒ«ãƒãƒ¼ã‚’å¤–éƒ¨ã«ã‚‚ã£ã¦ã¦ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚½ãƒ«ãƒãƒ¼ã«æ¸¡ã™è«–ç†å¼ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã‚Šã‚‚ã€ã‚½ãƒ«ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ãã®ã¾ã¾ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ã£ã¦ã€è§£ãè¡Œç‚ºãã®ã‚‚ã®ã‚’æ¨¡æ“¬ã™ã‚‹ã¨ã„ã†LoGiPTã¨ã‹ã€çµæ™¶æ§‹é€ ã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã—LLaMA-2ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã€VAEã‚’ä¸Šå›ã£ãŸã¨ã„ã†äº‹ä¾‹ã¨ã‹ãŒã‚ã‚‹ã€‚ãã‚‚ãã‚‚ã§ã™ã‚ã­ã€æ–°ã—ã„OpenAIã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€200å€‹ç¨‹åº¦ã®ãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã€ãŠå¬¢æ§˜LLMãã‚‰ã„ã¯ã§ãã‚‹ã¿ãŸã„ã§ã”ã–ã„ã¾ã™ã§ã™ã€‚LLMã¯ãã®ãƒ¡ã‚¿ãªèƒ½åŠ›ã‚‚é‡è¦ãªè¦ç´ ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’ä½œã‚‹ãƒ¡ã‚¿ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã¤ãã£ãŸã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMãŒç†è§£ã‚„ã™ã„ã‚ˆã†ã«æ›¸ãæ›ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã‹ã€ã“ã£ã¡æ–¹é¢ã®ãƒ¡ã‚¿ãªä¸–ç•Œã‚‚ã„ã„æ„Ÿã˜ã§ç™ºå±•ã—ã¦ã„ã‚‹ã€‚ï¼ˆã¡ã‚‡ã£ã¨è¦–ç‚¹ã‚’å¤‰ãˆãŸï¼‰ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨LLMã®ãƒ¡ã‚¿èƒ½åŠ›ã‚’åˆ©ç”¨ã™ã‚‹ã®ãŒLLMæ´»ç”¨ã®æ¬¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã€‚create-llamaã¨ã‹ã€OpenGPTã¨ã‹ã€LLMA Factoryã¨ã€è‡ªå‹•çš„ã«ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ä»•çµ„ã¿ãŒãŸãã•ã‚“å‡ºã¦ããŸã€‚ ã‚ãšã‹1åˆ†ã§10æ—¥é–“ã®å¤©æ°—ã‚’äºˆæ¸¬å¯èƒ½ãªAIã€ŒGraphCastã€ã€ãŠèŒ¶ã®æ°´å¤§å­¦ã®ç¥å±±å…ˆç”Ÿã®è§£èª¬ãŒã€å¾“æ¥ã®æ‰‹æ³•ãŒä¸å¾—æ„ãªã¨ã“ã‚ã«Graph transformerãŒã´ã£ãŸã‚Šåˆã£ãŸã¨ã„ã†ã¨ã“ã‚ãŒè…¹è½ã¡ã—ã¾ã™ã€‚Microsoftã®ç™ºè¡¨ã—ãŸCopilotã€ã¤ã¾ã‚ŠGPTsã®ï¼­ï¼³ç‰ˆã€‚ã“ã†ã„ã†ä¸–ç•Œè¦³ã«ãªã‚‹ã‚ˆãªã€‚æ—©é€ŸOpenCopilotã¨ã‹ã€WebCoPilotã¨ã‹ã€ã‚ã£ã¨ã„ã†ã¾ã«ã€ä¼¼ãŸã‚ˆã†ãªOSSãŒã€ã€ã€ã€‚YahooçŸ¥æµè¢‹ã€ã¤ã„ã«GPT-4ã‚’ã¤ã‹ã£ãŸè‡ªå‹•å›ç­”ã‚’ãƒ†ã‚¹ãƒˆä¸­ã€‚äººã®è¡†çŸ¥ã¯ChatGPTã«æ•—ã‚ŒãŸã®ã‹ã€‚ã€‚ï¼­ï¼£æ¥­ã®ç´—ã€…æ°ã€NTTæ­¦è”µé‡é€šç ”ã§é–‹å‚¬ã•ã‚ŒãŸR&Dãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§ã€AIåŒ–ã•ã‚Œã‚‹ã€ï¼­ï¼£æ¥­ã‚‚ï¼¡ï¼©ã«ä»£æ›¿ã•ã‚Œã‚‹ï¼Ÿã•ã‚Œãªã„ï¼Ÿã¾ã‚ã€ChatGPTã§ä»•äº‹ãŒãªããªã£ãŸã®ã¯ã€ChatGPTã®CEOã‚‚ä¾‹å¤–ã§ã¯ãªã„ã¨ã„ã†ã®ã¯ãƒ–ãƒ©ãƒƒã‚¯ã‚¸ãƒ§ãƒ¼ã‚¯ã‹ã‚‚ã€‚

- Adding Structure-Aware Retrieval to GenAI Stack
	- https://medium.com/@yu-joshua/adding-structure-aware-retrieval-to-genai-stack-373976de14d6
	- å˜ãªã‚‹embeddingã‚’ã¤ã‹ã£ãŸé¡ä¼¼æ¤œç´¢ã®RAGã§ã¯ãªãã¦ã€æ§‹é€ ã‚’æŠ½å‡ºã—ãŸã†ãˆã§ã®ã€RAGã£ã¦ã®æœ‰åŠ¹ã§ã‚ã‚‹ã“ã¨ã‚’ã€neo4j+LangChainã®å®Ÿä¾‹ã§ç¤ºã—ãŸè‰¯ä¾‹
	- This stack is (1) fully local, (2) uses advanced retrieval methods that encode relationships between different chunks of texts
- LlamaIndex ã«ã‚ˆã‚‹OpenAIã®æ–°æ©Ÿèƒ½ã‚’ä½¿ç”¨ãƒ»ç†è§£ã™ã‚‹ãŸã‚ã®ã‚¬ã‚¤ãƒ‰ by npakaã•ã‚“
	- https://note.com/npaka/n/n728fdb8f76da?sub_rt=share_sb
	- Parallel Function Callingã€Assistant API Agentã€Function Callingã«ã‚ˆã‚‹é«˜åº¦ãªRAGã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAG
	- GPT Builderã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•æ€§ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€GPTã‚’ç”Ÿæˆã™ã‚‹metaãªãƒ„ãƒ¼ãƒ«
	- ã€Œtext-to-SQL ã¨ semantic search ã®ã‚¸ãƒ§ã‚¤ãƒ³ãƒˆã€ãªã‚“ã‹ã¯èˆˆå‘³æ·±ã„
- æ—¥æœ¬ã®å¥³æ€§ãŒå…ˆé€²å›½ã®ä¸­ã§é•·å‘½ãªã®ã¯ã€ç¤¾ä¼šé€²å‡ºãŒé€²ã¾ãªã‹ã£ãŸã‹ã‚‰ï¼Ÿ
	- æ—­ãƒªã‚µãƒ¼ãƒ
	- https://arc.asahi-kasei.co.jp/report/arc_report/pdf/rs-824.pdf
	- ã€Œå…ˆé€²å›½ã®ä¸­ã§ã¯å¥³æ€§ã®ç¤¾ä¼šé€²å‡ºãŒé€²ã¾ãªã‹ã£ãŸã“ã¨ãŒã€ ä¸–ç•Œä¸€ã®å¥³æ€§é•·å¯¿ã«çµã³ã¤ã„ãŸã¨æ€ã‚ã‚Œã‚‹ã€‚ã€ 
	- ã€Œå‡ç­‰æ³•ã¯å¥³æ€§ã®å¹³å‡å¯¿å‘½ã‚’çŸ­ç¸®ã•ã›ã‚‹è¦å› ã§ã‚ã‚‹ã€‚ã€
- gpt-3.5-turbo-1106ã‚’ä½¿ã£ãŸã€æ–°ã—ã„OpenAIã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
	- https://x.com/matsu_vr/status/1723688378795958670?s=20
	- ã§ãŠå¬¢æ§˜ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã¿ã¾ã—ãŸã€‚200ä¾‹ã®ä¼šè©±ã§ååˆ†ãŠå¬¢æ§˜ã«ãªã£ãŸï¼
- Boosting RAG: Picking the Best Embedding & Reranker models
	- https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
	- RAGã‚’ã‚„ã‚‹ã«ã‚ãŸã£ã¦ã©ã‚Œã‚’ä½¿ãˆã°ã‚ˆã„ã‹ã‚’èª¿ã¹ãŸãƒ–ãƒ­ã‚°ã€‚OpenAI ChatGPTã‚„Google PaLMãªã©ã§ä½œã£ãŸ embeddings ã¨ BAAI ç­‰ãŒæä¾›ã—ã¦ã„ã‚‹ reranker ã§ã€ã©ã®çµ„ã¿åˆã‚ã›ãŒç²¾åº¦ãŒè‰¯ã„ã‹
- OpenAI Dev dayã‚’å—ã‘ãŸã€llamaindexã®ãƒã‚¤ãƒ¬ãƒ™ãƒ«APIã®ã‚¢ãƒ—ãƒ‡ã¾ã¨ã‚
	- https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p
	- å¤§å¤‰ã ãƒ¼
-  Prompt Engineering a Prompt Engineer
	- https://huggingface.co/papers/2311.05661
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’ä½œã‚‹ãƒ¡ã‚¿ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œã‚‹ã¨ã„ã†è©±ã€LLMã£ã¦ãƒ¡ã‚¿èƒ½åŠ›ãŒã‚ã‚‹ã®ã§ã€ã“ã†ã„ã†è©¦ã¿ãŒå¯èƒ½ã€‚CoTè¶Šãˆã¨ã„ã†ã®ã¯æœ¬å½“ã‹ï¼Ÿ
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LLMãŒè¨€ã„æ›ãˆã¦ã€LLMè‡ªèº«ãŒç†è§£ã—ã‚„ã™ãã™ã‚‹æ‰‹æ³•ã€RaRã€
	- https://aiboom.net/archives/51160
	- ä¾‹ãˆã°ã€ŒGPT-4ã§è¨€ã„æ›ãˆã¦GPT-3.5ã§å…¥åŠ›ã™ã‚‹ã€ã‚‚æœ‰åŠ¹ã¨ã®ã“ã¨ã§ã™ã€‚ å®Ÿè¡Œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚„æ€§èƒ½ç­‰ã‚’è©³ã—ãç´¹ä»‹ã™ã‚‹è¨˜äº‹ã‚’å…¬é–‹ã—ã¾ã—ãŸ
-  Language Models can be Logical Solvers
	- https://huggingface.co/papers/2311.06158
	- å¾“æ¥SOTAã¯ã€solver-augmented language modelsã‚’ã¤ã‹ã£ã¦ã€è‡ªç„¶è¨€èªã‹ã‚‰ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãªãƒ­ã‚¸ãƒƒã‚¯ã‚’å–ã‚Šå‡ºã—ã¦ã€å¤–éƒ¨ã‚½ãƒ«ãƒãƒ¼ã§èª¬ã„ã¦ã„ãŸãŒã€ã€æ–‡æ³•ãŒã‚ã£ã¦ãªã„ã¨ã‹ãã†ã„ã†ä¸‹ã‚‰ãªã„ã‚¨ãƒ©ãƒ¼ã«æ‚©ã¾ã•ã‚Œã¦ããŸ
	- LoGiPTã¯ã€ç›´æ¥è«–ç†çš„ãªå°å‡ºã‚’ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã€æ—¢å­˜ã‚½ãƒ«ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã€‚å•é¡Œã¯è§£æ±ºã•ã‚ŒãŸ
	- https://x.com/IntuitMachine/status/1724104506185580589?s=20
-  JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models
	- https://arxiv.org/abs/2311.05997
	- JARVISã£ã¦ç¢ºã‹ã€ã‚¢ã‚¤ã‚¢ãƒ³ãƒãƒ³ã®ã‚µãƒãƒ¼ãƒˆAIã®åå‰ã§ã¯ï¼Ÿï¼Ÿ
- äººé–“ã®æƒ…å ±å‡¦ç†ã«ã¨ã£ã¦ã€Œã¡ã‚‡ã†ã©ã„ã„å¡©æ¢…ã€ã®é€Ÿåº¦ã‚’è¶…ãˆã¨ã‚‹æ°—ãŒã™ã‚‹ by è°·ãƒãƒ¥ãƒ¼
	- https://x.com/rmaruy/status/1724044250286108818?s=20
	- Buonomanoã€è„³ã¨æ™‚é–“ã€ã«ã‚ˆã‚Œã°ã€è„³ã«ã¯å˜ä¸€ã®ã‚¯ãƒ­ãƒƒã‚¯ã¯ãªã„ï¼ˆå¤šé‡æ™‚è¨ˆåŸç†ï¼‰ã€‚ãŒã€é€²åŒ–ã®éç¨‹ã§ç”Ÿç‰©ãŒç›¸æ‰‹ã«ã—ã¦ããŸæ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã‚ˆã‚Šå¤§å¹…ã«é€Ÿã„æƒ…å ±å‡¦ç†ã¯ã§ããªã„ã ã‚ã†ã€‚ä¸€æ–¹ã€æƒ…å ±ã®ã€Œé‡ã€ã«é–¢ã—ã¦ã¯ã¾ã å·¥å¤«ã§ãã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã€‚
- DPOã§calm2ã®ç‰©èªç”Ÿæˆèƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹è©¦ã¿ã€
	- https://x.com/_oshizo_/status/1724039980463657130?s=20
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§LLMãŒæ–‡å­—ã‚’ç”Ÿæˆã™ã‚‹æ§˜å­ã®ãƒ‡ãƒ¢ã€
	- https://x.com/dylfreed/status/1723927399857901724?s=20
	- llamacppã‚’ã¤ã‹ã£ã¦8GB RAM MacBook Airã§å‹•ãã‚“ã ã¨ã•
- LLMã£ã¦çµå±€ä½•ã‹ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã«èª¬æ˜ã™ã‚‹
	- https://x.com/davidad/status/1723990400682148124?s=20
	- ãƒ‡ã‚£ãƒ¼ãƒ— ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ« ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€å„å±¤é–“ã«è¦ç´ ã”ã¨ã®éç·šå½¢æ€§ã‚’æŒã¤ç·šå½¢å›å¸°ã®ã‚µãƒ³ãƒ‰ã‚¤ãƒƒãƒæ§‹é€ ã§ã™ã€‚LLM/GPT ã®çˆ†ç™ºçš„ãªå¢—åŠ ã«ç›´æ¥ã¤ãªãŒã£ãŸã€ŒAttending is All You Needã€ã®æ ¸ã¨ãªã‚‹è²¢çŒ®ã€ãã“ã« *ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯* å›å¸°ã‚’éç·šå½¢å±¤ã«æŠ•ã’è¾¼ã‚€ã“ã¨ã§ã™ã¾ãŸã€ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆã«ã¤ã„ã¦ã¯@geoffreyhinton ã€æ´»æ€§åŒ–æ­£è¦åŒ–ã«ã¤ã„ã¦ã¯@ChrSzegedy ã€ãŠã‚ˆã³å‹¾é…æ­£è¦åŒ–ã«ã¤ã„ã¦ã¯@dpkingmaã«ã‚ˆã‚‹ã‚‚ã®ã§ã™ (Adam)ã€‚
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’å‹•ã‹ã™PCã‚’è‡ªä½œ
	- https://note.com/ai_meg/n/n8855a8dd4bbd?sub_rt=share_pb
	- ãƒã‚¶ãƒ¼ãƒœãƒ¼ãƒ‰ï¼šAsrokã€€B760 PRO RS/DS  
	- CPUï¼ši5-13400F  
	- GPU:PALITã€€GFORCE-RTX4060ti-16G
- RETOOLã®State of AIãƒ¬ãƒãƒ¼ãƒˆ
	- https://retool.com/reports/state-of-ai-2023
	- 66% of companies have at least one AI use case live
	- Accuracy is #1 concern
	- RAG is 2nd most popular use case (1st is code)
	- @llama_index is one of the leading frameworks for enterprises 
- OpenGPTã¯ã©ã‚“ã©ã‚“é€²åŒ–ã™ã‚‹
	- https://github.com/langchain-ai/opengpts
-  The Alignment Handbook
	- https://github.com/huggingface/alignment-handbook
	- Robust recipes to align language models with human and AI preferences
- EditGPT
	- https://chat.openai.com/g/g-zpuYfzV7k-editgpt
	- Grammeryã®ã‚ˆã†ãªæ©Ÿèƒ½ã‚’æŒã¤GPTsãŒã€ã€
- å²¡é‡åŸã•ã‚“ã®ã€ã€Œæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã€ãŒä»Šå¹´åº¦ã®å¤§å·å‡ºç‰ˆè³ã«é¸å‡º
	- https://hillbig.github.io/diffusion-models/
	- http://www.okawa-foundation.or.jp/activities/publications_prize/list.html
- ã“ã‚Œã¯è¡æ’ƒ!1.5Bã§è¶…é«˜æ€§èƒ½LLM!RWKV-5-World-v2 by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/nfc8dd1abf494?sub_rt=share_pb
	- ã¾ã ç”Ÿãã¦ãŸã®ã‹ã€RWKV
- The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4
	- https://arxiv.org/abs/2311.07361
	- Evaluates GPT-4â€™s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilitie
	- MSã‹ã‚‰ã®è«–æ–‡ã€è£½è–¬ã¨ã‹ã®è©±ãŒå¤šã„ãŒã€ãªã‚“ã‹ã¤ã¾ã‚‰ã‚“
- Open AIä¸»ä»»ç§‘å­¦è€…ã®Ilya Sutskeveræ°ã¯æ˜¨æ—¥ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã«ã¦ã€AGIã«ãŸã©ã‚Šç€ããŸã‚ã«ã¯Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼‹Î±ã§ã€Œæ˜ã‚‰ã‹ã«ã€å•é¡Œãªã„ã¨
	- https://www.youtube.com/watch?v=Ft0gTO2K85A
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®Fine-tuningã«ã‚ˆã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ç²å¾—ã®æ¤œè¨
	- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/
	- è‹±èªã§ä¸»ã«å­¦ç¿’ã•ã‚ŒãŸLLaMA2ã«å¯¾ã—ã¦æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸInstruciton Tuningã‚„è¿½åŠ äº‹å‰å­¦ç¿’ãŒã©ã®ç¨‹åº¦å¯èƒ½ã‹ã®æ¤œè¨¼
	- ä¸å¯æ€è­°ãªçµæœãŒå‡ºãŒã¡ãªã®ã§ã€ã„ã‚ã‚“ãªè¨­å®šã§è©¦ã•ãªã„ã¨ã„ã‘ãªã„ã“ã¨ãŒã‚ã‹ã£ãŸ
- LangChainã‹ã‚‰ã€Query Construction Guideã€text-to-SQL+semanticæœ€å¼·ç¯€
	- https://blog.langchain.dev/query-construction/
	- 1. Structure+unstructured data:  Text-to-SQL+semantic (w/ PostgresSQL with the Pgvector 
	- 2. Unstructured w/ metadata: Text-to-metadata filters (w/ new docs + a template for self-query retriever)
	- "Text-to-SQL+semantic" is an interesting recent addition to LangChain that extends "Text-to-SQL" w/ semantic queries on an embedding column.
	- ãã†ã‹ã€ã‚„ã£ã±ã‚Š text-to-SQL+semantiãŒæœ€å¼·ãªã®ã‹
- ã€Chain of Empathyï¼ˆå…±æ„Ÿã®é€£é–ï¼‰ã€
	- Yoon Kyung Lee et al., "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"
	- å¿ƒç†ç™‚æ³•ã®ã‚»ã‚ªãƒªãƒ¼ã‚’åæ˜ ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ‰‹æ³•ã€Chain of Empathyï¼šCoEã€ã‚’é–‹ç™ºã—ã€ãã®æ€§èƒ½ã‚’æ¤œè¨¼
-  Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
	- https://openreview.net/forum?id=0r5DE2ZSwJ
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹çµæ™¶æ§‹é€ äºˆæ¸¬
	- çµæ™¶æ§‹é€ ã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã—LLaMA-2ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€VAEã®å¾“æ¥æ‰‹æ³•ã‚ˆã‚Šã‚‚å®‰å®šãªçµæ™¶æ§‹é€ ã‚’ç”Ÿæˆã§ããŸ
	- ã“ã®æ‰‹ã®æ‰‹æ³•ã¯ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«ãŠé‡‘ã¨æ™‚é–“ãŒã‹ã‹ã‚‹ã¨ã“ã‚ãŒèª²é¡Œ
- create-llama, a command line tool to generate LlamaIndex apps
	- https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191
	- ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã§llamaindexã‚’ã¤ã‹ãŸãŸã‚¢ãƒ—ãƒªã‚’ç”Ÿæˆã™ã‚‹ä»•çµ„ã¿ã®å…¬é–‹ï¼ï¼ï¼
- GPT4ãªã©ãŒã€å¸¸è­˜ã‚’ã‚‚ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã‚‹è©•ä¾¡
	- https://github.com/allenai/everyday-things
	- The LLMs have poor accuracy (54-59%) on commonsense spatial/functional relationships in ParRoT dataset.
	- This suggests the LMs do not have fully coherent conceptual pictures of everyday objects.
- LLMA Factory
	- https://github.com/hiyouga/LLaMA-Factory
	- Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- WebPilot
	- https://chat.openai.com/g/g-pNWGgUYqS-webpilot
	- è¨˜äº‹ã‚„è«–æ–‡ã€PDF ãªã©ã®æŠ½å‡ºç³»ã®ä¾¿åˆ© GPTs ã‚’ä½œã£ãŸã‘ã‚Œã©ã€ã™ã¹ã¦ WebPilot ã§ååˆ†ã ã£ãŸ(ã‚ã“ã‚ã“ã•ã‚“)
- beã•ã‚“ã€æ¯æ—¥ãƒ™ãƒ«ãƒãƒ³æ–¹ç¨‹å¼ã‚’è§£ã„ã¦æ—¥å¸¸ã‚’éã”ã—ã¦ã„ã‚‹ã¨ã€
	- https://x.com/behemuhemulove/status/1724408454348194303?s=20
- ã€HELP MEã€‘Assistants APIã§ç ´ç”£ã—ãã†ã«ãªã£ãŸè©±
	- https://note.com/nike_cha_n/n/n65a6101d59d7
	- ã¡ã‚ƒã‚“ã¨è¨ˆç®—ã—ãªã„ã¨ã‚ã£ã¨ã„ã†é–“ã«ä¸Šé™ã«é”ã™ã‚‹ã‹ã‚‚ã€
- Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion
	- https://arxiv.org/abs/2311.06318
	- MSã‚ˆã‚Š
	- Microsoft Research presents a method to personalize LLMs for search via entity-based user knowledge stores derived from logs.
- YahooçŸ¥æµè¢‹ã€GPT-4ã‚’ç”¨ã„ãŸã€è‡ªå‹•å›ç­”ã‚’ãƒ†ã‚¹ãƒˆä¸­
	- https://chiebukuro.yahoo.co.jp/topic/ai/answer.html
	- äººçŸ¥ã¯ä¸è¦ã«ãªã£ãŸã®ã‹ã€‚ã€‚
-  Trusted Source Alignment in Large Language Models
	- https://huggingface.co/papers/2311.06697
- GPT paper asistantã®ã‚½ãƒ¼ã‚¹
	- https://github.com/tatsu-lab/gpt_paper_assistant
	- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®æ©‹æœ¬å…ˆç”Ÿè¬¹è£½
- Licheng Wen et al., "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving"
	- https://arxiv.org/abs/2311.05332
	- è¦–è¦šã‚’æ‰‹ã«ã—ãŸLLMãŒè‡ªå‹•é‹è»¢ã«ã©ã‚Œã»ã©å½¹ç«‹ã¤ã®ã‹ã‚’æ¢ã‚‹ãŸã‚ã€GPT-4Vã®èƒ½åŠ›ãŒæ¤œè¨¼ã•ã‚Œã¾ã—ãŸã€‚ 
	- ã•ã¾ã–ã¾ãªã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã—ãŸã¨ã“ã‚ã€ã€Œå› æœé–¢ä¿‚ã®æ¨è«–ã€ã‚„ã€Œã‚·ãƒ¼ãƒ³ï¼ˆæ™¯è‰²ï¼‰ã®ç†è§£ã€ã«é•·ã‘ã¦ã„ã‚‹ã¨çµè«–ã¥ã‘ã‚‰ã‚Œã¾ã—ãŸã€‚
- ã†ã‚‹ã•ã„ã‚„ã¤ã€æŠ€è¡“ã‚’ç†è§£ã—ãªã„ã¨ã€ãƒ“ã‚¸ãƒã‚¹å±•é–‹ã®ãã£ã‹ã‘ãŒå‡ºã¦ã“ãªã„ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚’è”‘è¦–ã—ã¦ã€ãã‚Œã‚’å•†å£²ã«ã—ã¦ã„ã‚‹ã®ãŒå«Œã„ã€‚
	- https://x.com/toukatsujin/status/1724196831109017964?s=20
	- ã€ŒæŠ€è¡“åŠ›ã‚’ç£¨ã‹ãªã„ã¨ç”Ÿãæ®‹ã‚Œãªã„ã¨æ€ã£ã¦ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã»ã¨ã‚“ã©ã€‚ã§ã‚‚æŠ€è¡“ã¯æ—¥ã€…é€²åŒ–ãƒ»å¤‰åŒ–ã—ã¦ãŠã‚Šã€ã“ã‚Œã‚’å­¦ã¹ã°ä¸€ç”Ÿå®‰æ³°ã¨ã„ã†ã“ã¨ã¯ãªã„ã€‚ã‚€ã—ã‚ãƒ“ã‚¸ãƒã‚¹ç†è§£åŠ›ã‚’ç£¨ã„ãŸã»ã†ãŒä¸€ç”Ÿå®‰æ³°ãªã®ã«ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®å¤šãã¯åˆ†ã‹ã£ã¦ã„ãªã„ã€
- Rapidly build an application in Gradio power by a Generative AI Agent
	- https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent?hl=en
	- Gradio ã®ä½œè€…ã®åˆã‚ã¦ã®è«–æ–‡ã¨ã„ã†ã†ã‚ã•ã‚‚
- ChatGPTã¨DeepLã®å­—å¹•ç¿»è¨³ã®æ¯”è¼ƒ
	- https://x.com/gijigae/status/1724345403234193540?s=20
	- ChatGPTã¯ã€â‘ è‹±èªå­—å¹•ã‚’ç¹‹ãç›´ã™ â‘¡æ—¥æœ¬èªã«è¨³ã™ â‘¢è¨³ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªæµã‚Œã«ãªã‚‹ã‚ˆã†ã«åˆ†ã‘ã€å…ƒã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¸æˆ»ã™ ã¨ã„ã£ãŸä¸€é€£ã®ä½œæ¥­ã‚’å…¨éƒ¨ã‚„ã£ã¦ãã‚Œã‚‹ã€‚
- GPTsã¨Asistant APIã®é•ã„
	- https://x.com/gijigae/status/1724428173905989945?s=20
	- GPTsã¨Assistants APIã¯ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸChatGPTãŒä½œã‚Œã‚‹ç‚¹ã§ä¼¼ã¦ã„ã‚‹ã€‚ãŸã ã€ChatGPT Plusã¸ã®åŠ å…¥ã‚„ã‚¹ãƒ†ãƒ¼ãƒˆç®¡ç†ã‚’å«ã‚ã€é•ã„ã‚‚å¤šã„â†“ã€‚å¿™ã—ãã¦ä¸€ã¤ã—ã‹è©¦ã›ãªã„ã¨ã„ã†æ–¹ã«ã¯å¾Œè€…ã‚’ãŠå‹§ã‚ã—ãŸã„ã€‚ç‰¹ã«ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã—ãŸChatGPTã‚’ç”Ÿå¾’ã«å…¬é–‹ã™ã‚‹éš›ã€ChatGPT Plusã¸ã®åŠ å…¥ãŒä¸è¦ã¨ãªã‚‹ã®ã¯å¤§ãã„ã€‚
- ã€Œè¡¨è±¡ï¼ˆrepresentationï¼‰ã€æ¦‚å¿µã‚’åˆ†æã™ã‚‹RPPFãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
	- ç¥çµŒç§‘å­¦ãªã©ã§å¤šç”¨ã•ã‚Œã‚‹ãŒæ›–æ˜§ã§å•é¡Œå«ã¿ã®ã€Œè¡¨è±¡ï¼ˆrepresentationï¼‰ã€æ¦‚å¿µã‚’ã€20ï½30åã®å“²å­¦è€…ã¨ç¥çµŒç§‘å­¦è€…ã§åˆ†æã™ã‚‹ã€ŒRepresentation: Past, Present and Future (RPPF) projectã€
	- https://www.thetransmitter.org/representation/what-are-we-talking-about-clarifying-the-fuzzy-concept-of-representation-in-neuroscience-and-beyond/
- ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ»è£œå®Œã«ç‰¹åŒ–ã—ãŸæ—¥æœ¬èªLLMã€ŒELYZA-japanese-CodeLlama-7bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ˆå•†ç”¨åˆ©ç”¨å¯ï¼‰
	- https://note.com/elyza/n/n5bce23d7c9c8
	- https://zenn.dev/elyza/articles/fcbf103e0a05b1
- ã‚ãšã‹1åˆ†ã§10æ—¥é–“ã®å¤©æ°—ã‚’äºˆæ¸¬å¯èƒ½ãªAIã€ŒGraphCastã€ã‚’Google DeepMindãŒç™ºè¡¨ã€ã‚¹ãƒ‘ã‚³ãƒ³ã§æ•°æ™‚é–“ã‹ã‘ãŸäºˆæ¸¬ã‚ˆã‚Šé«˜ç²¾åº¦
	- https://gigazine.net/news/20231115-google-graphcast-global-weather-forecasting/
	- https://github.com/google-deepmind/graphcast
- RAG over Governments Document
	- https://github.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Chatting%20with%20your%20Docs.ipynb
- GGUF ç‰ˆã® 5 bit é‡å­åŒ–ã•ã‚ŒãŸ Llama 2 ã‚’ WasmEdge ã§ã€‚7B ãŒ 24 token / sec ã§å‹•ä½œã—ã¾ã—ãŸâ†“
	- https://www.secondstate.io/articles/fast-llm-inference/
	- Mac ãƒ¦ãƒ¼ã‚¶ã¯è¦‹ãŸã‚‰ã¨ã‚Šã‚ãˆãšè©¦ã—ã¦ã€‚ã‚³ãƒãƒ³ãƒ‰ï¼”è¡Œå©ãã ã‘ãªã®ã§ï¼Rust x Wasm ã§ Llama 2 æ¨è«–ãŒãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ãã¾ã™
- ELYZA-japanese-CodeLlama-7b-instructã®ggufãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç‰ˆ
	- https://huggingface.co/mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¯ Copilot Studio ã‚’ç™ºè¡¨
	- Igniteã®ä¸­ã§æœ€å¾Œã«ç™ºè¡¨ã€GPTsã¿ãŸã„ãªã‚‚ã®ã«ãªã‚‹
	- 
- ãŠèŒ¶å¤§ã€ç¥å±±å…ˆç”Ÿã«ã‚ˆã‚‹ã€Googleã®æ°—è±¡äºˆæ¸¬ã®æ°—è±¡å­¦è€…ã‹ã‚‰ã®è§£é¡Œ
	- https://x.com/kohyama_met/status/1724986380546408878?s=20
	- ã€ŒAIæ°—è±¡äºˆå ±è«–æ–‡ã€ã®æ„Ÿæƒ³ã‚’æŠ•ç¨¿ã—ãŸã‚‰æ€ã„ã®ã»ã‹åéŸ¿ãŒå¤§ãã‹ã£ãŸã®ã§ã€æ°—è±¡å­¦è€…ã‹ã¤æƒ…å ±ç§‘å­¦ç§‘æ•™å“¡ã¨ã—ã¦ã€ã„ãã‚‰ã‹çœŸé¢ç›®ã«è§£èª¬ã—ã¾ã™ã€‚
	- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãŒå¾“æ¥å‹ãƒ¢ãƒ‡ãƒ«ã®ä¸å¾—æ‰‹ã«ã†ã¾ããƒãƒã£ã¦ã„ã‚‹
- Research Assistantã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå…¬é–‹ã•ã‚Œã‚‹
	- https://github.com/langchain-ai/langchain/tree/master/templates/research-assistant
	- With this template you can easily plug in an arbitrary retriever, allowing you to do research over a knowledge base of your choice.
- æ±å¤§ æ¾å°¾ç ”ã®PRMLï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã¨æ©Ÿæ¢°å­¦ç¿’ï¼‰è¼ªèª­ä¼šã‚¹ãƒ©ã‚¤ãƒ‰é›†
	- https://www.slideshare.net/matsuolab/
	- é»„è‰²ã„æœ¬ã¯ã‚„ã£ã±ã‚Šã€è–å…¸
- OpenCopilot
	- https://github.com/openchatai/OpenCopilot
- tldrawãŒæ´’è½ã«ãªã‚‰ãªã„ãã‚‰ã„å„ªã‚Œã¦ã„ã‚‹
	- https://makereal.tldraw.com/
	- ãƒ©ãƒ•ãªUIã®å›³è§£ã‚„èª¬æ˜ã‚’ã¤ãã‚‹ã ã‘ã§ã€GPT-4Vã§èªè­˜ã—ã¦è‰¯ã„æ„Ÿã˜ã«ä»•æ§˜ã‚’è§£é‡ˆã—ã¦å®Ÿéš›ã«å‹•ããƒ¢ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œã£ã¦ãã‚Œã‚‹
- ç´—ã€…æ°ã€NTTæ­¦è”µé‡é€šç ”ã§é–‹å‚¬ã•ã‚ŒãŸR&Dãƒ•ã‚©ãƒ¼ãƒ©ãƒ ã§ã€AIåŒ–ã•ã‚Œã‚‹
	- https://x.com/03sasa03/status/1725479562094755951?s=20
-  OpenAI announces leadership transition
	- https://openai.com/blog/openai-announces-leadership-transition
	- ãˆã£ï¼
	- ã€Œå–ç· å½¹ä¼šã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã„ã¦ä¸€è²«ã—ã¦ç‡ç›´ã•ã‚’æ¬ ãã€å–ç· å½¹ä¼šã®è²¬ä»»é‚è¡Œã‚’å¦¨ã’ã¦ã„ã‚‹ã€
- OpenAIã‹ã‚‰è¿½ã„å‡ºã•ã‚ŒãŸç›´å¾Œã®ã€Sam Altomanã®ãƒ„ã‚¤ãƒ¼ãƒˆ
	- https://x.com/sama/status/1725742088317534446?s=20
	- i love you all.
- è¥¿æµ¦å…ˆç”Ÿã®è«–æ–‡ã«ã€ç­‘æ³¢å¤§ã®æ›è°·æ°ãŒã‹ã¿ã¤ãã‚‚ã€çµ±è¨ˆã®å°‚é–€åŒ–ã‹ã‚‰è¿”ã‚Šè¨ã¡ã«
	- https://x.com/behemuhemulove/status/1725749314000175387?s=20
	- ä¸»ãªå•é¡Œç‚¹ (1) ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®è©•ä¾¡ãªã— (2) çŸ­æœŸäºˆæƒ³ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’ç¹‹ãåˆã‚ã›ã¦é•·æœŸã®ã‚·ãƒŠãƒªã‚ªã‚’ä½œã£ã¦ã„ã‚‹ æ˜æ—¥ã®å¤©æ°—ã‚’é«˜ç¢ºç‡ã§å½“ã¦ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½œã£ã¦ã‚‚ã€ãã®äºˆæƒ³ã‚’ç¹‹ãåˆã‚ã›ã€ã€ã€
	- beæ°ã‚ˆã‚Šã€ï¼ˆ2ï¼‰ã¯ä¾‹ãˆã°1å¹´å¾Œã®äºˆæ¸¬ã™ã‚‹ã¨ã—ã¦1ãƒ¶æœˆãšã¤äºˆæ¸¬ã—ã¦ãã®ã‹ã€å¹´å˜ä½ã§äºˆæ¸¬ã—ã¦ãã‹ä½ã®é•ã„ã—ã‹ãªãã€çµ±è¨ˆå­¦ã‚„MLã§ã¯å…¨ãå•é¡Œãªã„ã¨æ€ã†ã®ã§ã€ã“ã®ç‚¹å©ã„ã¦ã‚‹æ–¹ãŒçµ±è¨ˆå­¦ã®è¦³ç‚¹ã‹ã‚‰ç„¡çŸ¥ã«ã¿ãˆã‚‹
-  create-llama ã«ã‚ˆã‚‹LlamaIndexã‚¢ãƒ—ãƒªã®ä½œæˆ by npakaã•ã‚“
	- https://note.com/npaka/n/neafa42455864?sub_rt=share_h
- ä½“è»¸ãŒç›´ç«‹ã—ãŸæ™‚ç‚¹ãŒäººé¡ãŒè‡ªå·±ã‚’èªè­˜ã—ãŸåˆ†å²ç‚¹ã‹ã‚‚ã—ã‚Œãªã„
	- https://x.com/daijapan/status/1725841037086892358?s=20
	- èªçŸ¥ç§‘å­¦è¬›åº§ã‚ˆã‚Šã€
- Building Research Assistant	
	- https://www.youtube.com/watch?v=DjuXACWYkkU
	- YouTube tutorial on building one from scratch. Covers LCEL, LangSmith, parallelization, retrievers
- Ilya Sutskeverã£ã¦èª°ãï¼Ÿ
	- https://x.com/mr_bay_area/status/1725808417376473167?s=20
	- ã€Œè‡ªç„¶è¨€èªå‡¦ç†æ¥­ç•ŒãŒæ·±å±¤å­¦ç¿’ä¸€è‰²ã«ãªã‚‹æµã‚Œã‚’æ±ºå®šã¥ã‘ãŸäººã€ã§ã™ã­ã€‚ãã‚Œãã‚‰ã„å½¼ãŒä½œã£ãŸseq2seqã¯è¡æ’ƒã ã£ãŸã—
- :smile:ã€:ikanai:
	
## 11/13

ä»Šé€±ã¯ã€OpenAI Dev Day(11/6)ãŒå…¨ã¦ã‚ã‚Šã€LLMå‘¨ã‚Šã®é¢¨æ™¯ãŒä¸€å¤‰ã—ãŸã€‚GPT-4 Turboã‚„Assistant APIã‚„ã€ä¾¡æ ¼ã®æ”¹å®šï¼ˆå®‰ããªã£ãŸï¼‰ã€æœ€å¾Œã«ç‹¬è‡ªã®GPTã‚’ã¤ãã‚Œã‚‹GPT Builderã¨ã€OpenAI ã¾ã‚ã‚Šã®OSSã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã‚’ç ´å£Šã™ã‚‹ãŒã”ã¨ãã®æ€’æ¶›ã®ãƒªãƒªãƒ¼ã‚¹ã€‚å¯¾å¿œã™ã‚‹OSSå´ã®LangChainã‚„llamaindexã‚‚æ–°æ©Ÿèƒ½ã®å–ã‚Šè¾¼ã¿ã‚„å¯¾æ¡ˆå®Ÿè£…ã§å¿™ã—ã„é€±ã ã£ãŸã€‚Assistant APIã£ã¦ã€**Code Interpreter**ã€**Retrieval**ã€**Function Calling**ã€€ãŒå‘¼ã³å‡ºã›ã€APIã‹ã‚‰ã‚‚ä½œã‚Œã‚‹ã‘ã©ã‚‚ã€playgroundã‹ã‚‰ã‚‚ä½œã£ã¦ç°¡å˜ã«è©¦ã›ã‚‹ã€‚Assistant APIã«å®Ÿè£…ã•ã‚ŒãŸæ©Ÿèƒ½(Assistants/Theads/Run )ã‚’çµ„ã¿åˆã‚ã›ã‚Œã°ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚‚ç°¡å˜ã«ä½œã‚Œã‚‹ã€‚è©³ã—ãã¯Nakajimaã•ã‚“ã®GPTvsGPTãŒè‰¯ã„ä¾‹ã€‚ç„¡é™ã«ç’°å¢ƒå•é¡Œã«ã¤ã„ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŒå£«ãŒè¨è«–ã™ã‚‹ã¨ã„ã†ãƒ‡ãƒ¢ã¯ã¡ã‚‡ã¨åœ°ç„çµµã€‚æ—©é€Ÿã€LangChainã‚‚ã€LlamaIndexã‚‚ã€Assistant APIã‚’ã¤ãã£ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚‹æ©Ÿèƒ½ã‚’å…¬é–‹ã€ã‚‚ã¨ã‚‚ã¨ã‚ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨çµ„ã¿åˆã‚ã›ã¦ã¿ãŸã„ãªç™ºå±•ã‚‚ã€‚OpenAI ã®Retreiveæ©Ÿèƒ½ã¯ã€pdfã‚„docã‚„pptã‚„markdownç­‰å¤šå½©ãªãƒ‡ãƒ¼ã‚¿ã‚’èª­ã‚“ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦Chatã§ãã‚‹æ©Ÿèƒ½ã€‚ã¾ã•ã«ã€RAGã¤ã¶ã—ãªã‚“ã ã‘ã©ã‚‚ã€llamaindexã®äººJerry Liuã«ã‚ˆã‚‹ã¨ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã®é™ç•Œã‚’è¶…ãˆã‚‹ã¨æ™®é€šã®top-kå¼ã®å˜ç´”ãªRAGãŒå‹•ã„ã¦ã„ã‚‹ã®ã§ã¯ã¨ã„ã†ã“ã¨ã€‚è©¦ã—ã«ãƒŠã‚¦ã‚·ã‚«(Wikipediaã€57kãƒˆãƒ¼ã‚¯ãƒ³)ã‚’GPT-4ã§ã‚„ã£ã¦ã¿ãŸã‚‰ã€ç¢ºã‹ã«æ€§èƒ½ã‚ˆã‹ã£ãŸã€‚RAGã«ã¤ã„ã¦ã¯è‡ªã‚‰ï¼ˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®æ–¹æ³•ãªã©ã®ï¼‰ç´°ã‹ã„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«èµ°ã‚‹ã‹ã€ãã‚Œã¨ã‚‚å…¥ã‚Šå£ã ã‘ç”¨æ„ã—ã¦ã‚ã¨ã¯ã€åˆ¥ã®OSSç­‰ã«ã¨ã„ã†æˆ¦ç•¥ã®ã©ã¡ã‚‰ã ã‚ã†ï¼ŸGPT-4ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãŒã€$3M(ï¼•å„„å††å¼±)ã®[Submit]ãƒœã‚¿ãƒ³ã¯æŠ¼ã›ãªã„ã€‚ã€‚GPT-4ã‚’åŠç«¯ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚æ€§èƒ½ã¯å‘ä¸Šã—ãªã„ã¨ã„ã†ã®ã‚‚ã™ã”ã„ãªã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œæˆæ”¯æ´ã‚‚ã€llamaindexã‹ã‚‰builder agentã€Langchainã‹ã‚‰ã‚‚ã€OpenGTPãŒç™ºè¡¨ã€‚OpenAIæœ¬å®¶ã‚‚GPTsã§ã€å¥½ã¿ã®GPTã‚’ä½œã£ã¦å…¬é–‹ã¨ã„ã†æ©Ÿèƒ½ãŒå…¬é–‹ã€Plusãƒ¦ãƒ¼ã‚¶ãƒ¼ãªã‚‰ä»–äººã®GPTã‚’ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«ã€ã©ã‚“ã©ã‚“ã€ç‹¬è‡ªã®GPTãŒå…¬é–‹ã•ã‚Œã¦ã€ã¾ã•ã«ç™¾èŠ±ç¹šä¹±ã€ã“ã‚Œã«åˆ©ç”¨æ–™ã‚’é‚„æµã™ã‚‹ä»•çµ„ã¿æ•´ãˆã°ã€ã¾ã•ã«ãƒãƒ¼ã‚±ãƒƒãƒˆãƒ—ãƒ¬ãƒ¼ã‚¹çµŒæ¸ˆåœã«ä¸€ç›´ç·šã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®RAGã¨ã„ã†ã®ã‚‚å‡ºã¦ããŸã€‚PFNã®PLaMo-13B-Instructã®å…¬é–‹ã‚„ã€æ—¥æœ¬èªå‘ã‘ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®æ”¹å®šã‚„ã€shi3zã•ã‚“ã«ã‚ˆã‚‹ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ—¥æœ¬èªä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´å‚™ãªã©ã€æ—¥æœ¬èªå¯¾å¿œã®æ”¹è‰¯ã‚‚ç€å®Ÿã«é€²ã‚“ã§ã„ã‚‹ã€‚ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚¢ AIã®æ¬¡ã«æ¥ã‚‹ã‚‚ã®ã€ã®ãƒ€ã‚¤ã‚½ãƒ³ã«ã‚ˆã‚‹ã¨ã€LLMã¯ã€ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹AIã®é™ç•Œã‚’è¶…ãˆã‚‹ã“ã¨ãŒã§ãã‚‹ï¼‰ã‚¢ãƒŠãƒ­ã‚°ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã«è¿‘ã„ã‚‚ã®ã‚‰ã—ã„ã€‚ãƒ€ã‚¤ã‚½ãƒ³ã®æœ¬ã‚’èª­ã¿ãªãŠã™ã¨ã€AGIã®å¯èƒ½æ€§ã«ã¤ã„ã¦ã‚‚ã€ãƒ‡ã‚¸ã‚¿ãƒ«ã§ã¯åˆ°é”ã§ããªã„ãŒã€ã‚¢ãƒŠãƒ­ã‚°ãªã‚‰ã°å¯èƒ½æ€§ã¯æ’é™¤ã§ããªã„ã¿ãŸã„ãªä¸»å¼µã ã£ãŸã€‚æœ€å¾Œã«ã€ChatGPTã®ç™»å ´ã¯ã€ãƒ‡ã‚¶ã‚¤ãƒŠã‚„ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã®è·ã‚’å¥ªã†ã ã‘ã§ãªãã€å˜ä¾¡ã‚‚ä¸‹ã’ãŸã€ç‰¹ã«é«˜åå…¥ã®å±¤ã‚’ã€ã¨ã„ã†FTã®è¨˜äº‹ãŒæ€–ã™ãã‚‹ã€‚

- ALMA-7B-Ja-V2
	- https://huggingface.co/webbigdata/ALMA-7B-Ja-V2
	- ç¿»è¨³ã‚¿ã‚¹ã‚¯ç‰¹åŒ–ã®ALMA-jaã®V2æ¥ã¨ã‚‹ï¼!GPTQã‚‚ã‚ã‚‹
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT
	- Microsoftã‹ã‚‰ç™ºè¡¨ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ã‚¹ã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ã€Œãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã™ã‚‹ãƒ¢ãƒ‡ãƒ«Table-GPT
	- å¤šæ§˜ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚¿ã‚¹ã‚¯ã«ã¦GPT-3.5ã‚„ChatGPTã‚ˆã‚Šé«˜æ€§èƒ½ã€é«˜ã„æ±ç”¨æ€§ã‚’ç¤ºã™
	- https://arxiv.org/abs/2307.08674
- OpenAI dev day
	- GPT-4 Turbo ç™ºè¡¨ 
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·128k
	- JSON Mode 
	- ãƒŠãƒ¬ãƒƒã‚¸ã‚«ãƒƒãƒˆã‚ªãƒ• 2023/04
	- DALL E-3 / Text to Speech 
	- Whisper v3 
	- GPT-4 Fine-tuningå¯èƒ½ã«
	- GPT-3.5 Turbo ã¯ã‚‚ã† 16K ãŒãƒ‡ãƒ•ã‚©ãƒ¬ãƒ™ãƒ«ã§ã•ã‚‰ã«å®‰ããªã‚Šã€GPT-4 Turbo ã¯ä¾¡æ ¼ãŒå…¥åŠ› 1/3, å‡ºåŠ› 1/2 ã«ãªã£ãŸ
	- ã€Œå¾“æ¥ã®16å€ã¨ãªã‚‹300ãƒšãƒ¼ã‚¸ã‚’è¶…ãˆã‚‹é•·ã„æ–‡æ›¸ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã€2023å¹´4æœˆã¾ã§ã®æƒ…å ±ã‚’åæ˜ ã€
	- functionsã¨function_callãŒéæ¨å¥¨ã«ãªã£ã¦toolsã¨tool_choiceã«ãªã£ãŸã‚“ã 
- ãƒãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã€ŒChatGPTã€ã®ã‚«ã‚¹ã‚¿ãƒ ç‰ˆã‚’ä½œã‚Œã‚‹ã€ŒGPTsã€ã€æœ‰æ–™ä¼šå“¡ã«æä¾›ã¸
	- https://www.itmedia.co.jp/news/articles/2311/07/news074.html
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰ã®æŒ‡ç¤ºã§å¯¾è©±ã—ãªãŒã‚‰ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ChatGPTã‚’æ§‹ç¯‰ã§ãã‚‹ã€‚ã€ŒWebæ¤œç´¢ã‚„ç”»åƒä½œæˆã€ãƒ‡ãƒ¼ã‚¿åˆ†æãªã©ã¨åŒã˜ãã‚‰ã„ç°¡å˜ã€ã¨ã—ã¦ã„ã‚‹
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
	- https://huggingface.co/papers/2311.02303
	- MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, CodeFuse-CodeLLama-34B, achieves an impressive pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\%, zero-shot).
- Assistants API ã®è§£èª¬ã¨å‹•ä½œç¢ºèªï¼ˆGoogle Colabï¼‰
	- https://note.com/schroneko/n/nd04c46242171
- llamaindexã‹ã‚‰ã€OpenAI dev dayã‚’ã†ã‘GPT builderã‚’æ¨¡æ“¬ã™ã‚‹Builder Agentã®ä¾‹ã‚’å…¬è¡¨
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb
	- https://x.com/jerryjliu0/status/1721639447207583882?s=20
	- ä¾‹ï¼šã€Œãƒˆãƒ­ãƒ³ãƒˆã®ã“ã¨ã‚’ã‚ˆãã‚ã‹ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã€â†’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã§ãã‚‹ã€‚ã€‚
- LangChainã‹ã‚‰ã€OpenGPTã®ç™ºè¡¨ã€
	- https://github.com/langchain-ai/opengpts
	- builds upon LangChain, LangServe and LangSmith This gives you more control over the LLM you us
- OpenGTPã¯ã€ LangSmithã«é€£æºã™ã‚‹ã ã‘ã§åˆ©ç”¨ãƒ­ã‚°ãŒå–ã‚Œã‚‹ã®ã§ã€ã‚ã¨ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®Toolsã‚’å……å®Ÿã•ã›ã‚Œã°ã€ãã‚Œãªã‚Šã®ã‚‚ã®ãŒæä¾›ã§ãã‚‹
	- https://x.com/mah_lab/status/1721684588874055764?s=20
- Levels of AGI: Operationalizing Progress on the Path to AGI
	- https://arxiv.org/pdf/2311.02462.pdf
	- DeepMindã‹ã‚‰ã€AGIã«ã„ãŸã‚‹Level0ã‹ã‚‰Level5ã¾ã§ã®æ®µéšã‚’ç¤ºã™ã€ãƒ¬ãƒ™ãƒ«åˆ†ã‘ã®Ontologyã‚’ææ¡ˆã¨ã„ã£ã¦ã„ã‚‹
	-  AGI by considering generality (either Narrow or General) in tandem with five levels of performance (Emerging, Competent, Expert, Virtuoso, and Superhuman).
-  OpenAI Python API Library v1.0 å…¥é–€ã€€by npakaã•ã‚“
	- https://note.com/npaka/n/n27b94df96179?sub_rt=share_sb
	- ã€ŒOpenAI Python API Libraryã€ã®ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ãŒä¸€æ–°ã•ã‚ŒãŸã€ã‚‰ã—ã„
- GPT-4ã®fine-tuningã§æœ‰åŠ¹ãªgainã‚’å¾—ã‚‹ã“ã¨ãŒ3.5-turboã‚ˆã‚Šé›£ã—ã„
	- ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚’é¸ã¶å½¢ã§Custom Models programã‚’æä¾›ã™ã‚‹æˆ¦ç•¥ã¸è»¢æ›ã‹ã€
	- GPT-4ãŒã™ã”ã™ãã‚‹ã®ã§ã€ä¸­é€”åŠç«¯ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯ã‹ãˆã£ã¦æ€§èƒ½ã‚’åŠ£åŒ–ã•ã›ã‚‹ã€‚ã€‚ã€‚ã€‚
	- https://openai.com/blog/new-models-and-developer-products-announced-at-devday
- Assistants APIã‚’åˆ©ç”¨ã™ã‚Œã°ã€TOEICã‚„TOEFLã€è‹±æ¤œã€IELTSã«ç‰¹åŒ–ã—ãŸå®¶åº­æ•™å¸«ã‚‚ä¸€ç¬ã§ä½œã‚Œã‚‹
	- https://x.com/gijigae/status/1721737796724183504?s=20
	- ã„ã¾ã¾ã§ã€OpenAI Plus(3kå††/æœˆ)ã§å®Ÿç¾ã—ã¦ã„ãŸã‚‚ã®ãŒã€Assistans APIã§ã€æœˆ1,500å††ç¨‹åº¦ã®åŠé¡ã«ãªã‚‹ã¨ã„ã†ãŠè©±ã€ãªã‚‹ã»ã©
- OpenAI APIã®RetrievalãŸå¤šç¨®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ
	- OpenAI API ã®ä»Šå›ã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã«å«ã¾ã‚Œã¦ã„ãŸ Knowledge Retrieval (ãƒ•ã‚¡ã‚¤ãƒ«å†…æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹æ©Ÿèƒ½) ã¯ PDF ã¯ã‚‚ã¡ã‚ã‚“ Word ã‚„ãƒ‘ãƒ¯ãƒã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚‚å¯¾å¿œã—ã¦ã‚‹ã‚ˆã†ã ã€‚ RAG é–¢é€£ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ãƒ›ãƒ³ãƒˆè¦ã‚‰ãªã„å­ã«ãªã£ã¡ã‚ƒã£ãŸã­
- OpenAI Assistantsã§è©¦ã—ã«è‹±èªè«–æ–‡ã‚’è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆä½œæˆä¾‹
	- ä»Šå›æ–°ãŸã«APIãŒç™ºè¡¨ã•ã‚ŒãŸRetrievalæ©Ÿèƒ½ã‚’ä½¿ã£ã¦PDFãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜ã‚’ã—ã¦ã¿ã¦ã¾ã™ã€‚
	- https://x.com/alexweberk/status/1721705504228192373?s=20
	- DPOã®è«–æ–‡26ãƒšãƒ¼ã‚¸åˆ†ãã‚‰ã„ã®è¦ç´„ã§$0.80ãã‚‰ã„
-  GPT-3.5-Turbo / GPT-4-Turbo 1106ã®JSONãƒ¢ãƒ¼ãƒ‰ã®ä½¿ã„æ–¹ by [shi3z](https://note.com/shi3zblog)ã•ã‚“
	- https://note.com/shi3zblog/n/nd72e0269dc3f?sub_rt=share_pb
- OpenAI DevDay ã§ç™ºè¡¨ã•ã‚ŒãŸæ–°ãƒ¢ãƒ‡ãƒ«ã¨æ–°é–‹ç™ºãƒ„ãƒ¼ãƒ« ã¾ã¨ã‚ by  [npaka](https://note.com/npaka)ã•ã‚“
	- https://note.com/npaka/n/n9cd206d96f85?sub_rt=share_sb
	- ã€ŒFunction Callingã€ã«ã€å˜ä¸€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰è¤‡æ•°ã®Function (ã€Œè»Šã®çª“ã‚’é–‹ã‘ã¦ã‚¨ã‚¢ã‚³ãƒ³ã‚’ã‚ªãƒ•ã«ã™ã‚‹ã€ãªã©) ã‚’å‘¼ã³å‡ºã™æ©Ÿèƒ½ãªã©ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚ç²¾åº¦ã‚‚å‘ä¸Šã—ã¦ã„ã¾ã™
	- 16Kã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹æ–°ã—ã„ã€ŒGPT-3.5 Turboã€ã‚‚ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã™ã€‚æŒ‡ç¤ºè¿½å¾“ã€ JSONãƒ¢ãƒ¼ãƒ‰ã€ä¸¦åˆ— Function Callingã‚’ã‚µãƒãƒ¼ãƒˆ
	- ã€ŒAssistant APIã€ã¯ã€ç‰¹å®šã®æŒ‡ç¤ºã‚’æŒã¡ã€è¿½åŠ ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã€ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹å°‚ç”¨ã®AIã§ã™ã€‚
	- ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ã€å¿…è¦ã«å¿œã˜ã¦ã€**Code Interpreter**ã€**Retrieval**ã€**Function Calling**ã‚’å‘¼ã³å‡ºã›ã‚‹
- Google Colab ã§ OpenAI API ã® Retrieval ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/ndcacbefb2ef7
	- APIã‹ã‚‰Assistantã‚’ä½œã‚‹æ–¹æ³•ã€çµæœã¯playgroundã§ã‚‚ç¢ºèªã§ãã‚‹ã¨ã„ã†ã‹ã€playgroundã§assistantä½œæˆã®åˆ¥ã®ã‚„ã‚Šæ–¹
- Putting numbers into a better perspective and classifying them according to their level of complexity
	- https://thinkzone.wlonk.com/Numbers/NumberSets.htm?platform=hootsuite
- GLaMM: Pixel Grounding Large Multimodal Model
	- https://huggingface.co/papers/2311.03356
-  GPT-4Vã®APIã‚’ã‚µã‚¯ãƒƒã¨ä½¿ã£ã¦ã¿ã‚‹ï¼
	- https://note.com/peisuke/n/nef0616b8d7fc?sub_rt=share_sb
	- æ—©ç¨²ç”°å¤§å­¦ã®è¬›ç¾©ã®ãƒšãƒ¼ã‚¸ã‚’ä½¿ã‚ã›ã¦ã‚‚ã‚‰ã„ã¾ã™ã€‚åˆ¶ç´„æ¡ä»¶ä»˜ãæœ€é©åŒ–ã®å•é¡Œã‚’è§£ã‹ã™â†’è§£ã‘ã‚‹ã€‚
	- "ç”»åƒã®æ•°å¼ã®å¿œç”¨ä¾‹ã‚’ä¸€ã¤æŒ™ã’ã€ä½•ã‚‰ã‹ã®é©å½“ãªæ•°å€¤ã‚’è¨­å®šã—ã€ãã‚Œã‚’è§£ããŸã‚ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä½œæˆã—ã¦ãã ã•ã„"
- Google Colab ã§ OpenAI API ã® Text-to-Speech ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/nba4af88eb3cf?sub_rt=share_sb
	- 6ã¤ã®å†…è”µãƒœã‚¤ã‚¹ãŒä»˜å±ã—ã¦ãŠã‚Šã€æ¬¡ã®ç›®çš„ã§ä½¿ç”¨ã§ãã¾ã™ã€‚
		- æ›¸ã‹ã‚ŒãŸãƒ–ãƒ­ã‚°æŠ•ç¨¿ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
		- è¤‡æ•°è¨€èªã®éŸ³å£°ã‚’ç”Ÿæˆ
		- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå‡ºåŠ›
- Bayesian Optimization of Function Networks with Partial Evaluations
	- https://arxiv.org/abs/2311.02146
- Assistance APIã«ã¤ã„ã¦
	- ã“ã‚Œã¾ã§ãªã‚‰è‡ªåŠ› or LangChain ã§ã‚„ã£ã¦ããŸã“ã¨ãŒã€ãã‚Œãªã‚Šã« Assistants/Theads/Run ãªã©ã§ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¡ã¾ã£ãŸãœ
	- OpenAIã® [#AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ](https://twitter.com/hashtag/AI%E3%82%A2%E3%82%B7%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%88?src=hashtag_click) ã¯é¢ç™½ã„ã‘ã©ã€ã¾ãŸãŠé‡‘ãŒé£›ã‚“ã§ã„ã
- Assistances APIã‚’ã¤ã‹ã£ã¦ã€GPTvsGPTã‚’ä½œã‚‹ä¾‹
	- https://x.com/yoheinakajima/status/1721769833212281231?s=20
	- https://github.com/yoheinakajima/GPTvsGPT
	- ä¾‹ã¨ã—ã¦ã€åœ°çƒæ¸©æš–åŒ–ãƒ†ãƒ¼ãƒã«å¯¾ã™ã‚‹ã€æµ·è³Švsäººé­šã®è«–äº‰ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼
- Langchainã‹ã‚‰ã€OpenAIã® assistance APIã®ã‚µãƒãƒ¼ãƒˆã‚’ç™ºè¡¨
	- https://github.com/langchain-ai/langchain/blob/master/cookbook/openai_v1_cookbook.ipynb
	- Spin up OpenAI assistants and run them as any other LangChain agent!
	- LangChainã®Agentã¨åŒã˜ã‚ˆã†ã«ã€OpenAIã®agentã‚’ä½¿ãˆã‚‹ã€ã‚‰ã—ã„
	- OpenAIAssistantRunnable.create_assistan
- Contrastive Error Attribution for Finetuned Language Models
	- https://arxiv.org/abs/2212.10722v2
	- æ–‡æ›¸ç”Ÿæˆã«ãŠã„ã¦ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¼•ãèµ·ã“ã™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã®ãƒ‡ãƒ¼ã‚¿ã‚’é«˜ç²¾åº¦ã§ç‰¹å®šã™ã‚‹æ‰‹æ³•ã®ææ¡ˆã€‚
- Tokyo Digital TwinãŒã€
	- https://info.tokyo-digitaltwin.metro.tokyo.lg.jp/
	- èª¿å¸ƒå¸‚ã®3æ¬¡å…ƒ [#ç‚¹ç¾¤](https://twitter.com/hashtag/%E7%82%B9%E7%BE%A4?src=hashtag_click) ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ! ã•ã‚‰ã«ç‹¬è‡ªã®æ‰‹æ³•ã«ã¦å»ºç‰©ãƒ»æ¤ç‰©ãƒ»åœ°è¡¨é¢ã®è‡ªå‹•åˆ†é¡ã‚’è¡Œã„ã¾ã—ãŸ
- GPT-4ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯ã€ï¼•å„„å††ã‹ã‹ã‚‹ï¼Ÿï¼Ÿï¼Ÿ
	- It costs $2-3 million to train a custom GPT-4 model with your own dataset.
	- https://x.com/tdinh_me/status/1721835213121265840?s=20
	- ã„ã‚„ã€ã“ã®ã€ŒSubmitã€ãƒœã‚¿ãƒ³ã¯æŠ¼ã›ãªã„ã€‚ã€‚ã€‚
- GPT4 Turbo ã¯Pyllms ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT4ã‚’å‡Œé§•
	- https://github.com/kagisearch/pyllms
	- https://aider.chat/docs/benchmarks-1106.html
- CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding
	- https://huggingface.co/papers/2311.03354
- QGIS 3.34ã§3DTilesãŒè¡¨ç¤ºã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§ã€3Déƒ½å¸‚ãƒ¢ãƒ‡ãƒ«PLATEAUã®3DTilesã‚’QGISã§è¡¨ç¤ºã—ã¦ã¿ã¾ã—ãŸ
	- https://x.com/shi__works/status/1721808786393121197?s=20
	- https://north-road.com/2023/11/07/qgis-3d-tiles-thanks-to-cesium-ecosystem-grant/
- OpenAI Assistants API(Playground)ã‚’ä½¿ã£ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ã—ã¦ãã‚Œã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’ä½œã‚‹
	- https://zenn.dev/karaage0703/articles/66949a39643557
	- ä»Šã¾ã§ã§ã‚‚ã€Custom Instructionsã¨Advanced Data Analysisï¼ˆCode Interpreterï¼‰ã§ã§ãã¦ã„ãŸã“ã¨ã‚’ã€æ‰‹è»½ã«åˆ‡ã‚Šæ›¿ãˆã‚‰ã‚Œã¦ä¾¿åˆ©ã«ãªã£ãŸã€‚APIçµŒç”±ã§ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ã„ã†ã“ã¨ãªã®ã§ã€æœ¬è³ªçš„ãªå¤‰åŒ–ã¨ã„ã†ã‚ˆã‚Šã¯é †å½“ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
- è‡ªåˆ†ã®ç™–ã«ã‚ã£ãŸãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’LLMã§ä½œã‚ã†ï¼ã€Calm2ã€‘
	- https://zenn.dev/saldra/articles/090c120b49e38c
	- LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ãŠã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯é‡è¦ãªã‚‚ã®ã¨ãªã‚Šã¤ã¤ã‚ã‚‹
	- ä»¥å‰ã¾ã§ã¯äººåŠ›ã§ä½œã‚‹å¿…è¦ãŒã‚ã£ãŸãŒã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒåŠ¹ã7Bãƒ¢ãƒ‡ãƒ«ï¼ˆCalm2-chatï¼‰ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€LLMã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã“ã¨ãŒã§ãã‚‹
	- ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¤ã¤ã€å‹•çš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£ã—ã¦ã„ãæ‰‹æ³•ãŒç›¸å½“ã‚ˆã‹ã£ãŸ
- HuggingFace Diffusers v0.22.0ã®æ–°æ©Ÿèƒ½ by npakaã•ã‚“
	- https://note.com/npaka/n/n5aebfc60408a?sub_rt=share_sb
- OpenAI Assistants APIã«æ‹™è‘—ã€Œã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã®çŸ¥çš„ç”Ÿç”£è¡“ã€ã‚’å…¥ã‚Œã¦è³ªå•ã€‚ã“ã‚Œã“ãã€Œæ›¸ç±ã‚’èª­ã‚€æ–¹æ³•ã®åŠ¹ç‡åŒ–ã€ã ãªæ„Ÿ
	- https://x.com/nishio/status/1721857526990586203?s=20
- OpenAIã® AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ ã«å­çŒ«ã®çµµã‚’æã„ã¦ã‚‚ã‚‰ã„ã¾ã—ãŸ
	- https://x.com/itnavi2022/status/1721945299713941944?s=20
- æ—¥æœ¬èªå¯¾å¿œ13Bãƒ¢ãƒ‡ãƒ«ã®PLaMo-13Bã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ
	- å¯¾è©±æ€§èƒ½ã‚’å‘ä¸Šã•ã›ãŸæŒ‡ç¤ºå­¦ç¿’ï¼ˆinstruction tuningï¼‰æ¸ˆã¿å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«PLaMo-13B-Instructã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- https://tech.preferred.jp/ja/blog/llm-plamo-instruct/
- llamaindexã‚‚OpenAIã®Assistanceã«å¯¾å¿œ
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb
	- OpenAIã®Retrievalã¨llamaindexã®Retrievalã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒå¯èƒ½ï¼ï¼ï¼
- OpenAIã®Retrieval APIã¯ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ãŒé•·ã„å ´åˆã€ç°¡æ˜“ãªtokp-k RAGã«åˆ‡ã‚Šæ›¿ãˆã¦ã„ã‚‹æ¨¡æ§˜
	- The OpenAI retrieval API seems to be doing basic top-k RAG on limited context if there's context overflows.
	- https://x.com/jerryjliu0/status/1721987237771133219?s=20
- GPT-4 Turbo vs GPT-4 tests
	- GPT-4 Turbo has record accuracy (87% vs 52% of GPT-4 on PyLLMs benchmark), it is almost 5x faster with 48 vs 10 tokens/sec). 
	- And it is also 30% cheaper in practice (would be more, but it is 2x wordier in output compared to GPT-4)
	- https://x.com/vladquant/status/1721674365211738269?s=20
-  Google Colab ã§ OpenAI API ã® Function Calling ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/nc3713dba5df6?sub_rt=share_sb
	- ç¾¤é¦¬çœŒã®æ°—æ¸©ã‚’æ•™ãˆã¦ãã ã•ã„
-  Re-evaluating Retrosynthesis Algorithms with Syntheseus
	- https://arxiv.org/abs/2310.19796v1
	- é€†åˆæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è«–æ–‡ã€‚
	- ç‹™ã„ã®ææ–™ã‹ã‚‰åŸæ–™ã‚’äºˆæ¸¬ã™ã‚‹é€†åˆæˆäºˆæ¸¬ã§ã¯å„è«–æ–‡ã§è©•ä¾¡æ–¹æ³•ãŒç•°ãªã£ã¦ã„ã¾ã—ãŸãŒã€Microsoftã•ã‚“ã‚‰ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ§‹ç¯‰ã€ã“ã‚Œã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«ã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒå¾“æ¥ã¨å¤‰ã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã£ãŸãã†ã§ã™ã€‚
-  Google Colab ã§ OpenAI API ã® Code Interpreter ã‚’è©¦ã™ by npakaã•ï½
	- https://note.com/npaka/n/nb90306341d41?sub_rt=share_sb
- GPT-3.5 Turbo ã®ä¾¡æ ¼ãŒ Fireworks ã‚„ Anyscale ãªã©ã® OSS LLM ãƒ‡ãƒ—ãƒ­ã‚¤ã‚µãƒ¼ãƒ“ã‚¹ã® 70B ã®ãƒ‡ãƒ—ãƒ­ã‚¤ä¾¡æ ¼ã¨å…¨ç„¶ç«¶äº‰ã§ãã‚‹ãƒ¬ãƒ™ãƒ«
	- ã©ã†ã‚‚ä»Šå›ã® OpenAI ã®ä¾¡æ ¼æ”¹å®šã§ã€GPT-3.5 Turbo ã®ä¾¡æ ¼ãŒ Fireworks ã‚„ Anyscale ãªã©ã® OSS LLM ãƒ‡ãƒ—ãƒ­ã‚¤ã‚µãƒ¼ãƒ“ã‚¹ã® 70B ã®ãƒ‡ãƒ—ãƒ­ã‚¤ä¾¡æ ¼ã¨å…¨ç„¶ç«¶äº‰ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã¾ã§æ›ã‹ã£ã¦ã„ã‚‹ã‚‰ã—ãã€OSS LLM ãŒæ™®åŠã—ãªã„ã®ã¯çµå±€ OpenAI ã® API ãŒã‚¯ã‚½å®‰ã™ãã‚‹ã‹ã‚‰ã§ã¯ï¼Ÿã¨ã„ã†æŒ‡æ‘˜
- OpenAI API ã® Assistant API ã®ã—ãã¿
	- https://note.com/npaka/n/n9fa7204e4af4?sub_rt=share_sb
- mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration
	- https://huggingface.co/papers/2311.04257
- llamaindexã‚ˆã‚Šã€parallel function callingã«ã‚ˆã‚‹åŠ¹ç‡åŒ–ã®ä¾‹
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb
- OpenAI API ã§æä¾›ã•ã‚Œã¦ã„ã‚‹ ãƒ¢ãƒ‡ãƒ« ã¾ã¨ã‚ by npakaã•ï½
	- https://note.com/npaka/n/n5d0a76b149f1?sub_rt=share_sb
- ã€ç”ŸæˆAIã®ãƒ‘ãƒ©ãƒ‰ãƒƒã‚¯ã‚¹ã€
	- https://aiboom.net/archives/58414
	-  LLMãªã©ã®ç”ŸæˆAIã®èƒŒå¾Œã«ã‚ã‚‹æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã¯äººé–“ã¨ã¯å…¨ãç•°ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã“ã¨ã‚’ç¤ºã™ä»®èª¬
	- AIãŒäººé–“ã®ã‚ˆã†ãªå‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ãªãŒã‚‰ã€ãã‚Œã‚’ç†è§£ã™ã‚‹èƒ½åŠ›ã¯å¿…ãšã—ã‚‚ä¼´ã‚ãªã„ã¨ã„ã†ä»®èª¬ã§ã™ï¼ˆä»®èª¬ã‚’ç«‹ã¦ã‚‹ã«è‡³ã£ãŸèƒŒæ™¯ã¯ã€å‰ç« ã‚’å‚ç…§ï¼‰ã€‚
- Streamlit+GPT4-Vision+TTSã§å‹•ç”»ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è‡ªå‹•ç”Ÿæˆãƒ„ãƒ¼ãƒ«ã‚’ã¤ãã£ãŸ
	- https://zenn.dev/olemi/articles/752d205987cb87
	-  å‹•ç”»ã‹ã‚‰ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’æŠ½å‡ºã—ã€Base64å½¢å¼ã«å¤‰æ›ã™ã‚‹
	- GPT4-Visionã«å‹•ç”»ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã•ã›ã‚‹
	- ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€TTS APIã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
	- Streamlitã§ã€ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹
-  Google Colab ã§ PLaMo-13B-Instruct ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n97a1ac080f76?sub_rt=share_sb
- æ—¥æœ¬èªã«å¯¾å¿œã—ãŸ Embedding Model ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ã®ç²¾åº¦æ¯”è¼ƒï½œTatsuya Shirakawa
	- https://github.com/nouu-me/document_vector_search_benchmark
	- æ—¥æœ¬èªText Embeddingã§ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ç²¾åº¦ã‚’ã„ã‚ã‚“ãªãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã—ã¦ã¿ã¾ã—ãŸã€‚e5è‰¯ã„ã§ã™ã­
-  Extracting List of  `Album`  (with Parallel Function Calling)
	- https://docs.llamaindex.ai/en/latest/examples/output_parsing/openai_pydantic_program.html#extracting-list-of-album-with-parallel-function-calling
- è¤‡æ•°ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«è¨è«–ã•ã›ã‚‹ä¾‹
	- https://x.com/npaka123/status/1722761636937900541?s=20
- Zhenjie Yang et al., "A Survey of Large Language Models for Autonomous Driving"
	- LLMãŒå¾—æ„ã¨ã™ã‚‹ã€Œè¨ˆç”»ã€èªè­˜ã€è³ªå•å¿œç­”ã€ç”Ÿæˆã€ã®èƒ½åŠ›ãŒè‡ªå‹•é‹è»¢ã‚·ã‚¹ãƒ†ãƒ ã«åŠ¹æœçš„ã«ä½¿ãˆã‚‹ã¨ä¸»å¼µ
	- https://arxiv.org/abs/2311.01043
- Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach
	- https://arxiv.org/abs/2209.06995
	- è‰¯è³ªãªãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—å°‘é‡ã§é«˜ã„æ€§èƒ½ã‚’ç²å¾—ã™ã‚‹è©¦ã¿ã€‚
	- LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸ãˆç–‘ä¼¼ãƒ©ãƒ™ãƒ«ã‚’äºˆæ¸¬ã€åˆ†å¸ƒãŒä¸€æ§˜ã§ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„=å­¦ç¿’åŠ¹æœãŒé«˜ã„ã¨ã¿ãªã™ã€‚
	- ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ä¸Šã®è·é›¢ã‹ã‚‰å‘¨è¾ºã‚‚ä¸ç¢ºå®Ÿæ€§ãŒé«˜ã„ã€ã‹ã¤æ¡ç”¨ãƒ‡ãƒ¼ã‚¿é–“ã®è·é›¢ã‚’ç©ºã‘ã‚‹ã€‚
	- 128ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ•ãƒ«å­¦ç¿’ã® 90% è¶…ã®ç²¾åº¦ã€‚
- A.R.I.A. (Aria) - Your AI Research Assistant
	- https://github.com/lifan0127/ai-research-assistant
-  OpenAI ã® Assistant Playuground ã® Function Calling ã‚’è©¦ã™
	- https://note.com/npaka/n/n6bf08e93840d?sub_rt=share_sb
- GPTs ä½œæˆç¬¬äºŒå¼¾ã¨ã—ã¦ arXiv Reader ã‚’ä½œã‚Šã¾ã—ãŸã€‚è«–æ–‡ã¯ PDF å…¥åŠ›ã‹ URL æ‰‹æ¸¡ã—ã‹é¸ã¹ã¾ã™ã€‚
	- https://chat.openai.com/g/g-qrOeOjLX6-arxiv-reader
- Tokenizerã®åˆ†å‰²ã‚’å¯è¦–åŒ–ã—ãªãŒã‚‰ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ•°ãˆã¦ãã‚Œã‚‹ãƒšãƒ¼ã‚¸ãŒOpenAIã®ã‚µã‚¤ãƒˆã«ã‚ã‚‹
	- https://platform.openai.com/tokenizer
- GPTsã§ã€Kaggleã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ç¬¬6ç‰ˆã‚’èª­ã¿è¾¼ã¾ã›ã¦ã¿ã¦ã€è³ªå•ã—ã¦ã¿ã¾ã—ãŸã€‚
	- https://chat.openai.com/g/g-Z3a4iOzGR-kagglenotiyutoriarudi-6ban
- å¼Šç¤¾ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã‚’GPTsã§ä½œæˆã—ã¦ã¿ã¾ã—ãŸã€‚
	- https://chat.openai.com/g/g-uINwYG4Ja-trippy-kasutamasapoto
- LangChainã®# OpenAI Assistantã€jsç‰ˆ
	- https://js.langchain.com/docs/modules/agents/agent_types/openai_assistant
-  Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models
	- https://arxiv.org/abs/2305.17446
	- äº‹å‰å­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ã®è»¢ç§»å­¦ç¿’ãŒãƒ¢ãƒ‡ãƒ«å†…ã®å‰¯ç©ºé–“ã§è¡Œã‚ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ãŸç ”ç©¶ã€‚
	- é‡ã¿ã‚’Flatten ã—ã‚¨ãƒãƒƒã‚¯ã”ã¨ã‚¹ã‚¿ãƒƒã‚¯ã—ã¦ SVD ã«ã‹ã‘ã€ Fine Tuning ä¸­ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼å¤‰å‹•ã‚’èª¬æ˜ã™ã‚‹è»¸ã‚’ç™ºè¦‹ã€‚
	- ã“ã®è»¸ä¸Šã§å¤–ã‚Œå€¤ã«ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ç„¡åŠ¹åŒ–ã—è‘—ã—ã„æ€§èƒ½åŠ£åŒ–ã‚’ç¢ºèª
- å±±å†…å¿—æœ—ã€å°ã•ãªå€«ç†å­¦å…¥é–€ã€
	- ã€Œäººé–“ã¯æ¬²æœ›ã‚’è‡ªåˆ†ã§ç”Ÿç”£ã§ããšã€ä»–ã®äººã‹ã‚‰ã“ã£ãã‚Šç›—ã‚“ã§ãã¾ã™ã€‚ã‚‚ã—ã‹ã™ã‚‹ã¨ã€äººé–“ã¯æ¬²æœ›ãŒæ¬ å¦‚ã—ã¦ã„ã¦ã€ãã‚Œã‚’éš ã™ãŸã‚ã«æ¬²æœ›ã¾ã¿ã‚Œã®å§¿ã‚’å–ã‚ŠãŸãŒã‚Šã¾ã™ã€‚ã‚„ã‚ŠãŸã„ã“ã¨ãŒè¦‹ã¤ã‹ã‚‰ãªã„äººã®æ–¹ãŒåœ§å€’çš„ã«å¤šã„ã®ã§ã™ã€‚ã€
- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§ã®AIç ”ç©¶è€…Fei-Fei Liã•ã‚“ã®æ–°åˆŠâ€The Worlds I Seeâ€ã¯ã€æƒ³åƒã‚’è¶…ãˆã‚‹é¢ç™½ã•ã€‚å¼·ã•ã¨ã—ã¦ã®å¥½å¥‡å¿ƒã€‚
	- https://www.amazon.com/dp/1250897939?ref_=cm_sw_r_cp_ud_dp_QG23D73KJFT6GCP6GNVP
	- After 3+ years, today is the day that my book â€œThe Worlds I Seeâ€ gets to see the world itself. It is a science memoir of the intertwining histories of me becoming an #AI scientist, and the making of the modern AI itself. 
- æ—¥æœ¬èªè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆãŒæ›´æ–°
	- æ—¥æœ¬èªè¨€èªãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆã§ã‚ã‚‹ Stability-AI/lm-evaluation-harness ãŒã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚ŒãŸãŸã‚ã€Youri 7B ã‚·ãƒªãƒ¼ã‚ºã®ã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã—ç›´ã—ã¾ã—ãŸã€‚ GPTQã«ã‚ˆã‚‹ 4bit é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚³ã‚¢ã‚‚ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚
	- https://rinnakk.github.io/research/benchmarks/lm/
- ç”ŸæˆAIã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã«ã¤ã„ã¦
	- ç”ŸæˆAIã¾ã‚ã‚ŠãŒã™ã”ã„æ¥½ã—ã„ã®ã¯ã€æŠ€è¡“ãã®ã‚‚ã®ã¯ã‚‚ã¡ã‚ã‚“ã€ç†è«–ã«è©³ã—ã„äººã€ã„ã¡æ—©ãå®Ÿè£…ã«è½ã¨ã™ã®ãŒå¾—æ„ãªäººã€ãã‚Œã„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã«è½ã¨ã™ã®ãŒå¾—æ„ãªäººã€é¢ç™½ã„ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã«ä»•ç«‹ã¦ã‚‹äººã®å”åŠ›é–¢ä¿‚ãŒãƒãƒƒãƒãƒªå™›ã¿åˆã£ã¦ã‚‹ã¿ãŸã„ãªã¨ã“ã‚ãŒã™ã
	- https://x.com/uezochan/status/1722604877644497292?s=20
- GPT3.5ã‚’ç”¨ã„ã¦ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³æ—¥æœ¬èªä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(16K)ã‚’ä½œã‚Šã¾ã—ãŸ
	- https://note.com/shi3zblog/n/nfc07c53d61a8?sub_rt=share_b
	- Wikipediaæ—¥æœ¬ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(izumi-lab/wikipedia-ja-20230720)ã¨GPT-3.5-Turboã§ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚Šã¾ã—ãŸã€‚
-  Google Colab ã§ Japanese Wikipedia Conversation ã«ã‚ˆã‚‹ Llama 2 ã®LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™
	- https://note.com/npaka/n/n723766f96cbc?sub_rt=share_sb
	- **<s> [INST]** æ—¥æœ¬ã®é¦–éƒ½ã¯ï¼Ÿ **[/INST]** æ±äº¬ã§ã™ã€‚**</s><s> [INST]** ãã®å ´æ‰€ã®è¦³å…‰åæ‰€ã‚’æ•™ãˆã¦ã€‚ **[/INST]** æ±äº¬ãƒ‰ãƒ¼ãƒ ã‚·ãƒ†ã‚£ã€ã‚µãƒ³ã‚·ãƒ£ã‚¤ãƒ³60ï¼ˆå…­ä¸‡åˆ†ä¸€ï¼‰ãŒã‚ã‚Šã¾ã™ã€‚ **</s>**
- llamaindexã‹ã‚‰RAGã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb
	- OpenAIã®RAGãŒã€llamaindexã®5è¡Œã®ã‚³ãƒ¼ãƒ‰ã«åŠ£ã£ã¦ã„ã‚‹ã¨ã€ã€ã€
- LLM OS
	- https://x.com/karpathy/status/1723140519554105733?s=20
	- Specs:
		- LLM: OpenAI GPT-4 Turbo 256 core (batch size) processor @ 20Hz (tok/s)
		- RAM: 128Ktok
		- Filesystem: Ada002
- ChatGPTã¯ã€ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã‚„ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã®é›‡ç”¨ã‚’å¥ªã†ã¨ã¨ã‚‚ã«ã€å˜ä¾¡ã‚‚ä¸‹ã’ã¦ã„ã‚‹
	- ç±³å›½ã®æœ€æ–°ç ”ç©¶ã¯ã€ChatGPTã®ç«‹ã¡ä¸Šã’ã‹ã‚‰æ•°ã‚«æœˆã§ã€ä¸»è¦ãªã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã‚„ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼ã®ä»•äº‹ã®æ•°ãŒå¤§å¹…ã«æ¸›å°‘ã—ã€åå…¥ã‚‚æ€¥æ¿€ã«æ¸›ã£ãŸã¨å ±ã˜ã¦ã„ã‚‹
	- https://www.ft.com/content/b2928076-5c52-43e9-8872-08fda2aa2fcf
	- ã€Œ6æ¡ç¨¼ãäººã¯30000ãƒ‰ãƒ«ã—ã‹ç¨¼ãŒãªã„äººã®3å€ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’å—ã‘ã‚‹ã€
- Pattern Language for Generative AI book!
	- https://x.com/IntuitMachine/status/1722931733866143754?s=20
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã¯çµŒé¨“ã—ãŸè¨€èªã‚’ä¸€èˆ¬åŒ–ã™ã‚‹èƒ½åŠ›ãŒã‚ã‚‹ã‹ï¼ˆï¼‘ï¼æœˆï¼’ï¼•æ—¥ Nature ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ²è¼‰è«–æ–‡ï¼‰ - Lab BRAINS
	- https://lab-brains.as-1.co.jp/enjoy-learn/2023/11/55788/
- Jochen Wulf and Juerg Meierhofer, "Towards a Taxonomy of Large Language Model based Business Model Transformations"
	- https://arxiv.org/abs/2311.05288
	- LLMã‚’åˆ©ç”¨ã—ãŸãƒ“ã‚¸ãƒã‚¹ãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦å®Ÿéš›ã®ã‚±ãƒ¼ã‚¹ã‚’ã‚‚ã¨ã«èª¿æŸ»å ±å‘ŠãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚
		- ã€Œæ–°ã—ã„é¡§å®¢ãƒ¡ãƒªãƒƒãƒˆã®å‰µé€ ã€ã€ã€Œæ–°ã—ã„è²©å£²ãƒãƒ£ãƒãƒ«ã®é–‹æ‹“ã€ã€
		- ã€Œãƒ“ã‚¸ãƒã‚¹ãƒ—ãƒ­ã‚»ã‚¹è‡ªå‹•åŒ–ã®åŠ é€Ÿã€ã€ã€Œæƒ…å ±ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨ã®æ”¹å–„ã€
-  LlamaIndex ã® ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«RAG ã®ã—ãã¿ by npakaã•ã‚“
	- https://note.com/npaka/n/n53e8aabed0f2?sub_rt=share_sb
	- ã€ŒGPT-4V APIã€ã®å°å…¥ã«ã‚ˆã‚Šã€ã€ŒRAGã€ã®æ¦‚å¿µã‚’ãƒ†ã‚­ã‚¹ãƒˆ/ç”»åƒã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«æ‹¡å¼µã—ã€ã•ã‚‰ã«å¤§é‡ã®(ç”»åƒã‚’å«ã‚€) ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ¼ãƒ‘ã‚¹ã‹ã‚‰ä¾¡å€¤ã‚’å¼•ãå‡ºã™
	- SimpleDirectoryReaderã®ç”»åƒæ‹¡å¼µ
	- **MultiModalVectorIndex**ã®å°å…¥
- RAGã«ãŠã‘ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ç²¾åº¦å‘ä¸Šã«ã¤ã„ã¦(æ¦‚è¦ç·¨)
	- https://zenn.dev/sompojapan_dx/articles/eb755a18e893ce
	- æå®³ä¿é™ºã‚¸ãƒ£ãƒ‘ãƒ³æ ªå¼ä¼šç¤¾ DXæ¨é€²éƒ¨
	- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ‰‹ã‚’åŠ ãˆã‚‹
		- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å½¢/chunking**ã€**è¦ç´„ç”Ÿæˆ**ã€**è³ªå•æ–‡ã®æ‹¡å¼µ**ã€**Knowledge Graphã®æ´»ç”¨**
	- æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã«æ‰‹ã‚’åŠ ãˆã‚‹
		- **æ¤œç´¢ãƒ¢ãƒ‡ãƒ«ã®fine-tune**ã€**Re-rankingãƒ¢ãƒ‡ãƒ«ã®æ´»ç”¨**
-  PromptNER: Prompt Locating and Typing for Named Entity Recognition
	- https://arxiv.org/abs/2305.17104v1
- ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚¢ã€ã®ã‚¸ãƒ§ãƒ¼ã‚¸ãƒ»ãƒ€ã‚¤ã‚½ãƒ³ãŒLLMã«ã¤ã„ã¦èªã‚‹
	- https://www.hayakawabooks.com/n/n6b8cf31a9472
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã„ã‚ã‚†ã‚‹è¨€èªã®åœ°å›³ã¨ã‚‚è¨€ãˆã‚‹ã‚‚ã®ã§ã‚ã‚Šã€ã„ã‚ã„ã‚ãªAIã¯ã€ãã®åœ°å›³ã‚’è¾¿ã£ã¦æœ‰ç”¨ãªç›®çš„åœ°ã¾ã§ãƒ‡ã‚¸ã‚¿ãƒ«æ–¹å¼ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã—ã¦ã„ã‚‹ã ã‘ã§ã™ã€‚
	- ã“ã†ã—ãŸåœ°å›³ã¯ã¾ã å¸‚è²©ã®ç”»åƒå‡¦ç†ç”¨ãƒãƒƒãƒ—GPUã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸã ã‘ã®ã‚‚ã®ã§ã™ãŒã€ã„ãšã‚Œã“ã†ã—ãŸï¼ˆè¨€èªã°ã‹ã‚Šã‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚„ã‚ã‚Šã¨ã‚ã‚‰ã‚†ã‚‹äº‹è±¡ã‚’é‡ã¿ã¥ã‘ã™ã‚‹ï¼‰å·¨å¤§ãªãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ã‚¢ãƒŠãƒ­ã‚°ãƒãƒƒãƒ—ãŒåˆ©ç”¨ã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã€å¾ã€…ã«æµ¸é€ã—ã¦ã„ãç¾è¡Œã®ã‚·ã‚¹ãƒ†ãƒ ã«ä»£ã‚ã£ã¦ã„ãã¨æ€ã„ã¾ã™ã€‚
- ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚¢ã€ã‚¸ãƒ§ãƒ¼ã‚¸ãƒ»ãƒ€ã‚¤ã‚½ãƒ³ã‚ˆã‚Š
	- é€£ç¶šä½“ä»®è¨­ã¯ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚‚ã€ã‚¢ãƒŠãƒ­ã‚°ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚‚ã©ã¡ã‚‰ã‚‚ç„¡é™ã®åŠ›ã‚’æŒã¤ãŒã€ãã‚Œãã‚ŒãŒã©ã‚Œã ã‘é€²åŒ–ã—ã¦ã‚‚ç™ºæ®ã™ã‚‹åŠ›ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¤ºå”†ã—ã¦ã„ã‚‹(P292)
	- ã‚¢ãƒŠãƒ­ã‚°ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã§ã¯è¤‡é›‘æ€§ã¯ã‚³ãƒ¼ãƒ‰ã§ãªãã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å®¿ã‚‹ã€‚
	- ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ç¡¬ç›´åŒ–ã—ã¦ãƒã‚¤ã‚ºã‚’ã«å¯¾ã™ã‚‹è€æ€§ã‚’å¤±ã£ã¦ã—ã¾ã£ãŸã€ã‚¢ãƒŠãƒ­ã‚°ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§ã‚ã‚‹
	- ã‚¢ãƒŠãƒ­ã‚°ãƒ»ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ãƒã‚¤ã‚ºã‚’å—ã‘å…¥ã‚Œã‚‹ã°ã‹ã‚Šã‹ã€ï¼œç•¥ï¼æ©Ÿèƒ½ã™ã‚‹ãŸã‚ã«ä¸€å®šã®èƒŒæ™¯ãƒã‚¤ã‚ºã‚’å¿…è¦ã¨ã•ãˆã—ã¦ã„ã‚‹ã€‚(P295)
- äººå·¥çŸ¥èƒ½ã®ä¸‰ã¤ã®æ³•å‰‡ã‹ã‚‰ã¿ã‚‹AIã®æ¬¡ã«ãã‚‹ã‚‚ã®ï¼ˆãƒ€ã‚¤ã‚½ãƒ³ï¼‰(P299)
	- ã€Œã‚¢ã‚·ãƒ¥ãƒ“ãƒ¼ã®å¿…è¦å¤šæ§˜æ€§ã®æ³•å‰‡ã€ã€å®ŸåŠ¹çš„ãªåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã¯å¯¾è±¡ã¨åŒã˜ç¨‹åº¦è¤‡é›‘ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„
	- ã€Œè¤‡é›‘ãªã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´ã‚’è¦å®šã™ã‚‹ã®ã¯ã€ãã‚Œè‡ªèº«ã®æœ€ã‚‚å˜ç´”ãªå‹•ä½œã®è¨˜è¿°ã ã€ï¼ˆãƒã‚¤ãƒãƒ³ï¼‰ã€
	- ã€Œç†è§£å¯èƒ½ãªå˜ç´”ãªã‚·ã‚¹ãƒ†ãƒ ã¯ã€çŸ¥çš„ãªæŒ¯ã‚‹èˆã„ã‚’ã™ã‚‹ã«ã¯è¤‡é›‘ã•ãŒè¶³ã‚‰ãšã€çŸ¥çš„ãªæŒ¯ã‚‹èˆã„ãŒã§ãã‚‹ãã‚‰ã„è¤‡é›‘ãªã©ã‚“ãªã‚·ã‚¹ãƒ†ãƒ ã§ã‚‚ã€ç†è§£ã™ã‚‹ã«ã¯è¤‡é›‘ã™ãã‚‹ã€
	- â†’è‡ªã‚‰æ€è€ƒã™ã‚‹äººå·¥çŸ¥èƒ½ã¯ã€äººé–“ã®çŸ¥æ€§ã‚’ç†è§£ã™ã‚‹ã¾ã§ã¯ã€ãƒã‚·ãƒ³ãŒè¶…äººçš„ãªçŸ¥èƒ½ã‚’æŒã¤ã“ã¨ã‚’å¿ƒé…ã™ã‚‹å¿…è¦ã¯ãªã„ã¨ã‚‚ã„ãˆã‚‹ãŒã€ç†è§£ã‚’ã›ãšã«ä½•ã‹ã‚’ä½œã£ã¦ã„ã‘ãªã„ã¨ã„ã†é“ç†ã‚‚ãªã„ã€‚

## 11/6

ä»Šé€±ã¯ã€Rinnaã®Youri 7Bã®ç™ºè¡¨(10/31)ã€Japanese Stable LM Beta 70Bã®ç™ºè¡¨(11/2)ã€åŒæ—¥CyberAgentLM2-7Bï¼ˆCALM2 -7Bï¼‰ã®å…¬é–‹(11/2)ç­‰ã€æ—¥æœ¬èªLLMã®ç™ºè¡¨ãƒ»å…¬é–‹ãŒç›¸æ¬¡ãã€‚ã‚ã£ã¨ã„ã†é–“ã«4bit é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã•ã‚Œã¦æ‰‹å…ƒã§è©¦ã›ã‚‹ã‚ˆã†ã«ã€‚ã€‚ã€‚70Bã‚‚ã³ã£ãã‚Šã™ã‚‹ãŒã€ç‰¹ã«Calm2ã¯3ä¸‡2000ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆæ—¥æœ¬èªã§ç´„5ä¸‡å­—ï¼‰ã«å¯¾å¿œã—ã¦ã„ã¦ã€RAGä¸è¦ã‹ã‚‚ã€‚Colabã§ã‚‚A100ãªã‚‰ã°å‹•ã‹ã›ã‚‹ã‚‰ã—ã„ã€‚ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã®LLMé–‹ç™ºå§‹å‹•ã‚„ã€NTTã®æ—¥æœ¬èªå¯¾å¿œè¨€èªãƒ¢ãƒ‡ãƒ«ã®tsuzumiã®ç™ºè¡¨ã€ç‰§é‡å…ˆç”ŸãŒã€MM-coreå°‚ä»»ï¼Ÿã«ãªã‚‹ã¨ã®è©±é¡Œã‚‚ã‚ã‚Šã€æ—¥æœ¬ã§ã‚‚LLMã®ã‚¤ãƒ³ãƒ•ãƒ©ãŒä»Šå¾Œãã‚ã£ã¦ãã‚‹ã®ã¯æ¥½ã—ã¿ã€‚æ—¥æœ¬èªäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’SimCSEã£ã¦ã€LLMæœ¬(å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«å…¥é–€)ã§ç´¹ä»‹ã•ã‚Œã¦ã„ãŸã‚„ã¤ã€‚èª¬æ˜å¯èƒ½AIã«ã‚ˆã‚‹ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½é›»æ± é–‹ç™ºã£ã¦ã€AIã«èª¬æ˜ã•ã›ã¦äººé–“ãŒæ¬¡ã‚’è€ƒãˆã‚‹ã¨ã„ã†ã€AIã¨äººã¨ã®å”èª¿ã®æ–°ã—ã„æœªæ¥ã®å½¢ã€‚LLMè©•ä¾¡ã®ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡ã€å¾Œã§èª­ã‚‚ã†ã€‚ TinyLLaMaã€ã©ã“ã¾ã§å°ã•ãã§ãã‚‹ã‹ã€ã“ã†ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã„ã„ãªã‚ã€æœ¬å½“ã«1.1Bã§ã©ã“ã¾ã§ã„ã‘ã‚‹ï¼ŸLLMã‚’åˆ©ç”¨ã—ãŸFAQæ¤œç´¢ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã®å·¥å¤«ã¨ã‹ã€LangChainã®ã‚¢ãƒ—ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å…¬é–‹ã¨ã‹ã€å®Ÿç”¨é¢ã«è¿‘ã„é–‹ç™ºã‚‚é€²å±•ã‚ã‚Šã€‚npakaã•ã‚“ã®ã€LangChainã€LLamaIndexã®ç´¹ä»‹è¨˜äº‹ã€ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§æœ€æ–°ã®æƒ…å ±ãªã®ã§ãŠå¾—ã€‚ã¡ã‚‡ã†ã©æ—¥çµŒæ–°èã§ç´¹ä»‹ã•ã‚ŒãŸã€å²©æ³¢æ–°æ›¸ã®ã€è¨€èªå“²å­¦ãŒã¯ã˜ã¾ã‚‹ã€ã€ãƒ•ãƒ¬ãƒ¼ã‚²ã€ãƒ©ãƒƒã‚»ãƒ«ã€ãƒ´ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã€ã‚‚ã—å½¼ã‚‰ãŒä»Šç”Ÿãã¦ã„ãŸã‚‰LLMã‚’ã©ã†ç ”ç©¶ã—ãŸã®ã‹ã€‚Xã®Grok-1ã¯æ¬¡é€±ã«ç¶šãã ãªã€‚

- FP8-LM: Training FP8 Large Language Model
	- https://arxiv.org/abs/2310.18313
	- Microsoftã®ç ”ç©¶ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹è«–æ–‡ã€‚
	-  FP8è‡ªå‹•æ··åˆç²¾åº¦ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€æ€§èƒ½ä½ä¸‹ã‚’æŠ‘ãˆã¤ã¤ ãƒ»BF16ã‚ˆã‚Šã‚‚64%é€Ÿã ãƒ»ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’42%å‰Šæ¸›ã— GPT-175Bã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§ããŸ
- ControlLLM: Augment Language Models with Tools by Searching on Graphs
	- https://huggingface.co/papers/2310.17796
	- (1) a task decomposer that breaks down a complex task into clear subtasks with well-defined inputs and outputs; 
	- (2) a Thoughts-on-Graph (ToG) paradigm that searches the optimal solution path on a pre-built tool graph, which specifies the parameter and dependency relations among different tools; and
	-  (3) an execution engine with a rich toolbox that interprets the solution path and runs the tools efficiently on different computational devices.
- ãƒãƒ¼ãƒãƒ¼ãƒ‰å¤§å­¦ã¨BCGã®ç ”ç©¶ã«ã‚ˆã‚‹ã¨GPT-4ã®æ´»ç”¨ã§ä»•äº‹ã®ç²¾åº¦ã¯40%å‘ä¸Šã—ã€ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚‚25%æ—©ããªã£ãŸã¨ã®ã“ã¨ã€‚ã“ã®çµæœã‚’è¦‹ã¦ã‚‚AIã®ä½¿ã„æ–¹ã¯ç›Šã€…ã€çŸ¥çš„å·®åˆ¥åŒ–ã®é‡è¦ãªè¦ç´ ã¨ãªã‚‹ã€‚çŸ¥çš„ã•ã¯ã‚‚ã¯ã‚„AIã¨åˆ‡ã‚Šé›¢ã—ãŒå›°é›£ãªçŠ¶æ…‹ã€‚ã“ã†ã—ãŸå¤‰åŒ–ã«ã¤ã„ã¦ã„ããŸã‚ã«ã‚‚æœ€æ–°ã®AIã‚’ä½¿ã„ã“ãªã›ã‚‹åŠªåŠ›ã‚’ã—ã¦ã»ã—ã„ã€‚
	- https://x.com/gijigae/status/1718851299524096284?s=20
- ChatGPT ã®ã‚¢ãƒ—ãƒªç‰ˆã« Retrieval Augmented Generation (RAG)æ©Ÿèƒ½ãŒè¿½åŠ ï¼Ÿ
	- https://x.com/yi_ding/status/1719028284548382901?s=20
- ã‚·ãƒªã‚³ãƒ³ãƒãƒ¬ãƒ¼éŠ€è¡Œã®ç ´ç¶»ã‚’ã€ã‚·ãƒ³ãƒ—ãƒ«ã«è§£æã™ã‚‹notebookãŒå…¬é–‹ã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦Professor Ashwin Raoã«ã‚ˆã‚‹
	- https://colab.research.google.com/drive/15uxrAeCCL327kWH9N0X-ogKwf2zErjP5
- Microsoft ã†ã£ã‹ã‚Šgpt-3.5ãŒ20bç›¸å½“ã ã¨æ¼ã‚‰ã™ã€
	- CodeFusion: A Pre-trained Diffusion Model for Code Generation
	- https://arxiv.org/abs/2310.17680
	- Microsoft paper claims ChatGPT 3.5 has ~20 billion parameters
- Blokeãƒ‹ã‚­ãŒStability AI Japan ã®ãƒ¢ãƒ‡ãƒ«ã‚’4bité‡å­åŒ–
	- https://huggingface.co/TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ
- rinnaã¯Llama 2ã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒYouri 7Bã€ã‚·ãƒªãƒ¼ã‚ºã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ 
	- https://rinna.co.jp/news/2023/10/20231031.html
	- â‘ Youri 7Bï¼šæ—¥è‹±40Bãƒˆãƒ¼ã‚¯ãƒ³ã§ç¶™ç¶šäº‹å‰å­¦ç¿’ 
	- â‘¡Youri 7B Instructionï¼šé«˜ã„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ 
	- â‘¢Youri 7B Chatï¼šè¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®å¯¾è©±ã«å¼·ã„ 
	- GPTQ 4bit é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã‚‚å…¬é–‹ã—ã¦ã„ã¾ã™ã€‚
-  Google Colab ã§ Youri-7B ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/nccadcbcfe37e?sub_rt=share_sb
	- è¤‡æ•°ã‚¿ãƒ¼ãƒ³ã®å¯¾è©±ãƒ¢ãƒ‡ãƒ« (GPTQç‰ˆ)ã§ã‚ã‚‹ã€Œrinna/youri-7b-chat-gptqã€ã‚’ä½¿ã„ã¾ã™
- å¤šæ§˜ãªæ—¥æœ¬èªäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’SimCSEã§æ–‡åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã«fine-tuning
	- https://arxiv.org/abs/2310.19349
	- ã‹ãªã‚Šã„ã„æ„Ÿã˜ã®æ–‡åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒã§ããŸã¨æ€ã†ã®ã§ã€ãœã²ãŠä½¿ã„ãã ã•ã„...ï¼ï¼
	- https://github.com/hppRC/simple-simcse-ja
- Youri 7B Instructionã®GPTQãƒ¢ãƒ‡ãƒ«ã¤ã‹ãˆã°ã€GPUãƒ¡ãƒ¢ãƒª8GBã§ã‚‚ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMç¿»è¨³ãŒã§ããã†ãªæ°—é…
	- https://x.com/kis/status/1719284609761108462?s=20
- ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã€ å›½ç”£å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®é–‹ç™ºã‚’æœ¬æ ¼é–‹å§‹
	- https://www.softbank.jp/corp/news/press/sbkk/2023/20231031_01/
	- 2024å¹´å†…ã«3,500å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®å›½ç”£LLMã®æ§‹ç¯‰ã‚’ç›®æŒ‡ã—ã¾ã™
-  Evaluating Large Language Models: A Comprehensive Survey
	- https://arxiv.org/abs/2310.19736
	- A comprehensive survey (100+ pages) on evaluating LLMs. 
	- â– ã€ŒçŸ¥è­˜ã¨èƒ½åŠ›ã€ã®è©•ä¾¡ 
		- â‘  ã‚¿ã‚¹ã‚¯ä¸­å¿ƒã®è©•ä¾¡ã‹ã‚‰èƒ½åŠ›ä¸­å¿ƒã®è©•ä¾¡ã¸ã¨ç§»è¡Œã—ã¦ã„ã‚‹ 
		- â‘¡ è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯ã¾ã™ã¾ã™æ‹¡å¼µã•ã‚Œã¦ã„ã‚‹
		- â‘¢ ãƒ€ã‚¦ãƒ³ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚¿ã‚¹ã‚¯é–“ã®åŒºåˆ¥ãŒã‚ã„ã¾ã„ 
		- â‘£ ãƒ¢ãƒ‡ãƒ«ã®èƒ½åŠ›ã‚’ç·åˆçš„ã«è©•ä¾¡ã™ã‚‹æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ 
	- â– ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆï¼ˆã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼‰ã®è©•ä¾¡ 
		- â‘  äººé–“ã®ä¾¡å€¤è¦³ã¨ã®ä¸€è‡´ã‚’è©•ä¾¡ã™ã‚‹ç ”ç©¶ãŒå¢—ãˆã¦ã„ã‚‹ 
		- â‘¡ å€«ç†çš„ãªé¢ã‚‚å«ã‚ãŸãƒ¢ãƒ‡ãƒ«ã®é€²æ­©ã¨å¿œç”¨ãŒç›®æŒ‡ã•ã‚Œã¦ã„ã‚‹ 
	- â– å®‰å…¨æ€§ã®è©•ä¾¡ 
		- â‘  LLMã®ç™ºå±•ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯ã«å³æ ¼ãªè©•ä¾¡ãŒå¿…è¦ 
		- â‘¡ ä¾‹ãˆã°ãƒã‚¤ã‚¢ã‚¹ã®å¢—å¹…ã€èª¤æƒ…å ±ã®æ‹¡æ•£ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã®ä¾µå®³ãªã© 
		- â‘¢ ãƒªã‚¹ã‚¯è©•ä¾¡ã¨ã€å¯¾å‡¦ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã‚‹ 
	- â– ç‰¹åŒ–å‹LLMã®è©•ä¾¡ 
		- â‘  ç‰¹å®šãƒ‰ãƒ¡ã‚¤ãƒ³ã‚„ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸLLMã‚‚å­˜åœ¨ 
		- â‘¡ ç‰¹åŒ–å‹ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã«ã¯å°‚é–€çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒå¿…è¦ 
		- â‘¢ é«˜åº¦ãªçŸ¥è­˜ã‚„å°‚é–€çš„ãªæ¨è«–èƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã•ã‚Œã¦ã„ã‚‹
- LanChainã‹ã‚‰ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã«ã‚¢ãƒ—ãƒªãƒ†ãƒ³ãƒ—ãƒ¬ãŒå…¬é–‹
	- https://blog.langchain.dev/langserve-hub/
	- LangChain Templates offers a collection of easily deployable reference architectures that anyone can use.
	- https://github.com/langchain-ai/langchain/tree/master/templates
- LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery
	- https://huggingface.co/papers/2310.18356
	- LoRAShear meticulously studies and proposes a dynamic fine-tuning schemes with dynamic data adaptors to effectively narrow down the performance gap to the full models.
- ggufç‰ˆã€japanese-stablelm-instruct-gamma-7bã€€å®Ÿç”¨ API ã‚µãƒ¼ãƒãƒ»ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä¾‹
	- https://note.com/ai_meg/n/n0c449a877c6f?sub_rt=share_pb
	- ä¼šè©±ãƒ­ã‚°ã€requestãƒœãƒ‡ã‚£-ç°¡ç•¥åŒ–ã®ãŸã‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã€‚llm()ã¸ã®ç”Ÿæˆæ™‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ ãªã©ã€‚
- Youri 7Bã‚’FastChatã§ChatGPTäº’æ›APIã‚µãƒ¼ãƒã¨ã—ã¦å‹•ã‹ã—ã¦éŠã¶
	- https://qiita.com/takaaki_inada/items/fcb63da369b5bfd8a3cf?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- youri-7b-chatã‚’fastchatã§ChatGPTäº’æ›APIã§ãƒ›ã‚¹ãƒˆã—ã¦ChatVRMã§ã‚µã‚¯ãƒƒã¨éŠã¼ã†ã€‚prompt engineeringãŒåŠ¹ãã®ã§system promptè¨­å®šç”»é¢ã§èªå°¾ã‚„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼è¨­å®šã§ãã¾ã™
- Google Colab ã§ Japanese Stable LM Beta 7B ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n49387d8a8af4?sub_rt=share_sb
	- èªå½™æ‹¡å¼µæ¸ˆã¿æŒ‡ç¤ºãƒ¢ãƒ‡ãƒ«ã€Œstabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b ã€ã‚’ä½¿ã„ã¾ã™
- Generative AI for everyone	by Andrew Ngå…ˆç”Ÿ
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- Google Colabã«ã€API keyã‚’ç™»éŒ²ã§ãã‚‹æ–°æ©Ÿèƒ½ãŒå…¬é–‹
	- https://x.com/GoogleColab/status/1719798406195867814?s=20
- èª¬æ˜å¯èƒ½AIã«ã‚ˆã‚‹ãƒšãƒ­ãƒ–ã‚¹ã‚«ã‚¤ãƒˆå¤ªé™½é›»æ± é–‹ç™º
	-  Discovering Process Dynamics for Scalable Perovskite Solar Cell Manufacturing with Explainable AI
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202307160
	- æˆè†œéç¨‹ã®å‹•ç”»ã‚„ã‚¹ãƒšã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰NNã«ã‚ˆã‚Šå¤‰æ›åŠ¹ç‡ã‚’äºˆæ¸¬ã€ãã‚Œã«åŸºã¥ãè§£é‡ˆã™ã‚‹æ‰‹æ³•ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ­ã‚»ã‚¹ã¨ç‰¹æ€§ã®æ–°ã—ã„æ´å¯Ÿã«ã¤ãªãŒã£ãŸãã†ã§ã™ã€‚
- Efficient LLM inference on CPUs! 
	- https://huggingface.co/papers/2311.00502
	- NeurIPS'23ã®è«–æ–‡
	- Compatible with GGML yet better performance up to 1.5x over llama.cpp!
	- https://github.com/intel/intel-extension-for-transformers
- The Computational Lens: from Quantum Physics to Neuroscience
	- è¨ˆç®—æ©Ÿçš„ãªè¦–ç‚¹ã‚’ç”¨ã„ã¦ã€é‡å­ç‰©ç†å­¦ã‹ã‚‰ç¥çµŒç§‘å­¦ã«è‡³ã‚‹ã¾ã§ã®åˆ†é‡ã‚’ç ”ç©¶ã—ãŸãƒãƒ¼ãƒãƒ¼ãƒ‰å¤§å­¦ã®åšå£«è«–æ–‡
	- https://arxiv.org/abs/2310.20539
- Japanese TinyLLaMa 1.1 B, llama.cpp ã§ wasm ã§ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚‚å‹•ã
	- https://github.com/lighttransport/japanese-normalizer-cpp
	- https://x.com/syoyo/status/1719646103891845438?s=20
-  LLMã‚’åˆ©ç”¨ã—ãŸFAQæ¤œç´¢ã®è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã€œãã®ï¼’ã€œ
	- https://www.ai-shift.co.jp/techblog/3761
	- ã€Œ1.  FAQã®å›ç­”å†…å®¹ã‹ã‚‰è³ªå•å†…å®¹ã‚’æŠ½å‡ºã€ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ç”Ÿæˆæ™‚ã®promptã®å·¥å¤«ã«ã¤ã„ã¦å–ã‚Šçµ„ã‚“ã 
- calm2ã§è­°äº‹éŒ²ã‚’ã¾ã¨ã‚ã¦ã¿ã¾ã—ãŸã€‚AIæ™‚ä»£ã®çŸ¥çš„è²¡ç”£æ¨©æ¤œè¨ä¼šï¼ˆç¬¬ï¼‘å›ï¼‰
	- https://x.com/alfredplpl/status/1720005676829970472?s=20
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/kaisai/index.html
	- ä¸»å¼µ1: AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚å«ã¾ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚ 
	- ä¸»å¼µ2: AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯ã€äººé–“ã«ã‚ˆã£ã¦å‰µä½œã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨åŒç­‰ã«ä¿è­·ã•ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚ 
	- ä¸»å¼µ3: è‘—ä½œæ¨©ã‚’ä¾µå®³ã™ã‚‹è¡Œç‚ºã«ã¯ã€AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚å«ã¾ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚ 
	- ä¸»å¼µ4: åç›Šé‚„å…ƒæ³•ã«ã¤ã„ã¦ã¯ã€AIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚é©ç”¨ç¯„å›²ã«å«ã¾ã‚Œã‚‹ã¹ãã§ã‚ã‚‹ã€‚
-  Google Colab ã§ CALM2 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n443e3ea8d0b8?sub_rt=share_sb
	- ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã€Œcyberagent/calm2-7b-chatã€ã‚’ä½¿ã„ã¾ã™ã€‚
- CALM2-7B-chatã®Spaceã‚’ä½œã‚Šã¾ã—ãŸ
	- https://huggingface.co/spaces/hayas/CALM2-7B-chat
- llamaã¨llama2ã®é•ã„ by NTT è¥¿ç”°ã•ã‚“
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
- æ—¥æœ¬èªDeBERTaV2ãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼
	- å½¢æ…‹ç´ è§£æå™¨ã®äº‹å‰ã®å˜èªåˆ†å‰²ãªã—ã§ä½¿ãˆã‚‹base, smallãƒ¢ãƒ‡ãƒ«ã«ãªã£ã¦ã„ã¾ã™
	- https://huggingface.co/izumi-lab/deberta-v2-base-japanese
- ãªã‚“ã¨ã€japanese-stablelm-instruct-beta-70B-GGUF
	- TheBloke/japanese-stablelm-instruct-beta-70B-GGUF
	- ggufã®ãã›ã«40Gã‚‚ã‚ã‚‹ã‚ˆã€ã¾ã£ãŸã
- OpenChat3.5
	- https://huggingface.co/openchat/openchat_3.5
	- gpt-3.5ã«è¿«ã‚‹ï¼Ÿï¼Ÿ
- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã®KOSMOS-2ã‚’å–ã‚Šè¾¼ã‚“ã transformerã®æ›´æ–°ï¼ by huggingface
	- KOSMOSã®ã§ã‚‚ã¯ã“ã¡ã‚‰
		- https://huggingface.co/spaces/ydshieh/Kosmos-2
- Text generation web UIã‚’ã¤ã‹ã£ã¦ã€cyberagent_calm2-7b-chat
	- https://x.com/StelsRay/status/1720137767857029444?s=20
	- ãƒ¢ãƒ‡ãƒ«ã®Loadæ™‚ã«use_fastãŒONã˜ã‚ƒãªã„ã¨å‹•ã‹ãªã„ç‚¹ãŒç½ ã ã£ãŸï¼
-  LangChain ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ - Pythonç‰ˆã€€ by npakaã•ã‚“
	- https://note.com/npaka/n/n0fd7bd3ed27b?sub_rt=share_sb
	- 11/4ç‰ˆãªã®ã§ã€æ•´ç†ã•ã‚Œã¦ã„ã‚‹ã—ã€ã€Œ**LCEL**ã€(LangChain Expression Language)ãªã‚“ã‹ã‚ˆãåˆ†ã‹ã£ãŸ
- Idempotent Generative Network
	- https://assafshocher.github.io/IGN/
	- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„æ–°ã—ã„ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãŒGoogleã¨UC Berkeleyã‹ã‚‰å‡ºãŸã‚ˆã†ã ã€‚ãƒã‚¤ã‚ºé™¤å»ã¨ã„ã†ã‚ˆã‚Šã‹åˆ†å¸ƒã‚’1stepã§å¤‰æ›ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ã“ã¨ã‚’ä»®å®šã™ã‚‹ã‚‰ã—ã„
- CALM2ã®GPTQç‰ˆãŒæ­£å¸¸å‹•ä½œã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚VRAMãŒå°‘ãªã„æ–¹ã¯æ˜¯éãŠä½¿ã„ãã ã•ã„ã€‚
	- https://huggingface.co/mmnga/cyberagent-calm2-7b-chat-GPTQ-calib-ja-1k
-  CALM2ã§é•·ã„æ–‡ç« ã‚’ã¾ã‚‹ã”ã¨å–ã‚Šæ‰±ã†
	- https://note.com/alfredplpl/n/n5ed2ea2b78ec?sub_rt=share_sb
- ã€è²¬ä»»ã‚ã‚‹AI: ã€ŒAIå€«ç†ã€æˆ¦ç•¥ãƒãƒ³ãƒ‰ãƒ–ãƒƒã‚¯ã€
	- https://x.com/abenben/status/1720750416361877680?s=20
- ã€Calm2-7bã€‘ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€æ–°LLMãŒå„ªç§€ã™ããŸã®ã§ã€ChatGPTã¨æ¯”è¼ƒãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ã¿ãŸ
	- https://weel.co.jp/media/cyberagentlm2-7b
-  Othello is Solved
	- https://arxiv.org/abs/2310.19387
	- PFNã‹ã‚‰ã€å¼±å•é¡Œã¨ã—ã¦è§£ã‘ãŸã¨ã„ã†è©±ã€åŒæ–¹æœ€å–„æ‰‹ã®çµæœã¯å¼•ãåˆ†ã‘
-  LlamaIndex v0.8 ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¬ã‚¤ãƒ‰ - Pythonç‰ˆ
	- https://note.com/npaka/n/nd449d5190431?sub_rt=share_b
	- ã€ŒLlamaIndexã€ã¯ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®çŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹å°‚é–€çŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹è³ªå•å¿œç­”ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ç°¡å˜ã«ä½œæˆã§ãã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚
- ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã®é¦–ç›¸ã¯ã€C++ã§æ•°ç‹¬ã‚½ãƒ«ãƒãƒ¼ã‚’å…¬é–‹ã—ã¦ã„ã‚‹	
	- https://t.co/rWig2ugILa
- CALM2-7Bã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã™ã‚‹(11/5è¿½è¨˜)
	- https://note.com/shi3zblog/n/n8b9ff5ea62bf?sub_rt=share_sb
- ä»Šã®é«˜æ ¡ã§ã¯ã€æƒ…å ±â… ã€ã¨ã„ã†ç§‘ç›®ãŒã§ãã¦ã€ITãƒ‘ã‚¹ãƒãƒ¼ãƒˆç›¸å½“ã®ã“ã¨ã‚’å­¦ã‚“ã§ã„ã‚‹â†’â€é«˜å’ç›¸å½“â€ã®ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã£ã¦ã„ã‚‹ã¨ã„ã†è©±
	- https://togetter.com/li/2253207
- ï¼¢ï¼¸ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ãƒ¼ã€€å®Ÿè·µè¡Œå‹•çµŒæ¸ˆå­¦2.0 äººã‚’å‹•ã‹ã™å¿ƒã®ãƒ„ãƒœ
	- https://www.amazon.co.jp/dp/4296115758?ref_=cm_sw_r_cp_ud_dp_BM2H3QZ9AHNCYW8F2ZY7
	- ä¼æ¥­çµŒå–¶ã®ç¾å ´ã§ã©ã®ã‚ˆã†ã«è¡Œå‹•å¤‰å®¹ã‚’ä¿ƒã›ã°ã‚ˆã„ã®ã‹ã¨ã„ã†çŸ¥è¦‹ãŒä½“ç³»çš„ã«æ•´ç†ã•ã‚Œã¦ãŠã‚Šã€æ³•å‰‡ã‚„ç†è«–ã‚’å¯„ã›é›†ã‚ãŸã“ã‚Œã¾ã§ã®äº‹ä¾‹é›†çš„ãªè¡Œå‹•çµŒæ¸ˆå­¦æœ¬ã¨ã¯ä¸€ç·šã‚’ç”»ã™è‰¯æ›¸ã§ã—ãŸã€‚
- Xã‹ã‚‰ã€Grokç™ºè¡¨, Elonâ€™s new LLM.
	- https://x.com/xai/status/1721027348970238035?s=20
	- 330å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿Grok-0ï¼ˆLLaMA 2 (70B) ã®æ©Ÿèƒ½ã«è¿‘ã¥ãã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒªã‚½ãƒ¼ã‚¹ã®åŠåˆ†ã—ã‹ä½¿ç”¨ã—ãªã„ï¼‰ã‚’å…ƒã«Grok-1ã‚’é–‹ç™ºã€‚
	- Grok-1 ã¯ GPT3.5ã‚„ Inflection-1ã‚’æ¨™æº–çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§è¶…ãˆã‚‹ã€‚
- CALM2-7Bã®æ€§èƒ½ã‚’ä»–ã®æ—¥æœ¬èªLLMã¨æ¯”è¼ƒã—ã¦ã¿ãŸ
	- https://note.com/it_navi/n/n35e5fac2b3d3?sub_rt=share_pb
	- CALM2-7B-Chatã¯ã€ä¸€åº¦ã«**3ä¸‡2000ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆæ—¥æœ¬èªã§ç´„5ä¸‡å­—ï¼‰**ã®é•·æ–‡ã®å…¥å‡ºåŠ›ã«å¯¾å¿œ
	- **CALM2-7B-Chat**ã®å›ç­”ã‚’**ELYZA-japanese-Llama-2-7b-instruct**åŠã³**Youri-7B-chat**ã®å›ç­”ã¨æ¯”è¼ƒ
	- è«–ç†çš„æ€è€ƒåŠ›ã«ã¤ã„ã¦ã¯ã€**3ç¨®é¡ã®æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®å›ç­”ã¯äº”åæ­©ç™¾æ­©**ã§å¤§å·®ã‚ã‚Šã¾ã›ã‚“ã€‚ChatGPTï¼ˆGPT-3.5ï¼‰ã®æ€§èƒ½ã¨ã¯ã€ã¾ã ç›¸å½“å·®ãŒã‚ã‚‹ã‚ˆã†ã§ã™
- ã€è¨€èªå“²å­¦ãŒã¯ã˜ã¾ã‚‹ã€é‡çŸ¢èŒ‚æ¨¹è‘—
	- https://www.iwanami.co.jp/book/b633363.html
	- æ—¥çµŒã®æ›¸è©•(11/4æœåˆŠ)æ²è¼‰
	- è¨€è‘‰ã¨ã¯ä½•ã‹ã€‚ã“ã®å•ã„ã«ãƒ•ãƒ¬ãƒ¼ã‚²ã€ãƒ©ãƒƒã‚»ãƒ«ã€ã‚¦ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã¯ã©ã†æŒ‘ã‚“ã ã®ã‹ã€‚ã¨ã³ãã‚ŠãŸã®ã—ã„è¨€èªå“²å­¦ã®èª¬ãèªã‚Š
	- å˜èªå˜ç‹¬ã§æ„å‘³ã‚’æŒã¤ã®ã‹ã€æ–‡ç« ã®ä¸­ã®é–¢ä¿‚æ€§ã¨ã—ã¦æ„å‘³ã‚’æŒã¤ã®ã‹ã€LLMã¯ä½•ã‚’è¦‹ã¦ã„ã‚‹ï¼Ÿ
- ç‰§é‡å…ˆç”Ÿã€PFNé–‹ç™ºã®MN-coreé–‹ç™ºã«æ³¨åŠ›
	- https://jun-makino.sakura.ne.jp/articles/future_sc/note161.html
	- ç¥æˆ¸å¤§ã¨PFNã®ã‚¯ãƒ­ã‚¹ã‚¢ãƒã‚¤ãƒ³ãƒˆãƒ¡ãƒ³ãƒˆã ãã†ã ã€
	- ã€Œä»Šå¾Œã¯ç¤¾å“¡ã¨ã—ã¦ç›´æ¥MN-Core ã® é–‹ç™ºã«é–¢ã‚ã‚‹ã€ã€ã€Œæ™®åŠã¨ã„ã£ãŸã“ã¨ã‚’å«ã‚ã¦Mn-Core ã® é–‹ç™ºãŒæœ¬æ ¼åŒ–ã—ã¦ã„ã‚‹ã€

## 10/30

æ–°ã—ã„LLMãŒã©ã‚“ã©ã‚“ç™ºè¡¨ã•ã‚Œã‚‹ã€‚ã€ŒJapanese Stable LM 3B-4E1Tã€ã€ŒJapanese Stable LM Gamma 7Bã€ã€7Bã®LLMã®è¦‡è€…ã¯ã€Mistral 7Bã¨ã„ã†è©±é¡Œã‚‚ã‚ã£ãŸãŒã€ReActã‚’ã“ãªã›ã‚‹7bã¯ã€Zephyr-7b-betaã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€æ—¥æœ¬èªã¯ã©ã†ã‹ï¼ŸOSSã®LLMã§æ§‹é€ çš„ãªå‡ºåŠ›(Pydantic)ã‚’å‡ºã™ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæœ‰åŠ¹ã‚‰ã—ã„ã€‚text-to-SQLã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒæœ‰åŠ¹ã¨ã®ã“ã¨ã€‚å¿ƒã®ç†è«–(TOM)ã‚‚ã€å¿ƒç†å­¦ã®VoEç†è«–ã®å¿œç”¨ã¨ã‹ãŒã‚ã£ãŸã€‚LLM ã® ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ã„ã‚ã„ã‚ç´¹ä»‹ã•ã‚Œã‚‹ãŒã€è‡ªå‹•è©•ä¾¡ã®çµæœãŒãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§å¯è¦–åŒ–ã•ã‚Œã‚‹MT-BenchãŒè‰¯ã„ã‹ã‚‚ã€‚æ—¢å­˜ã®æ¦‚å¿µã‚’çµ„ã¿åˆã‚ã›ã‚‹systematic compositionalityã®èƒ½åŠ›ã‚’ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãŒæŒã¤ã“ã¨ãŒã§ãã‚‹ã£ã¦ã®ã¯ã€ã“ã‚Œã¯ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ç†è«–ã«ã‚ˆã‚‹èªçŸ¥ã®ä»•çµ„ã¿ã®è§£æ˜ãŒä¸€æ­©ç¾å®Ÿã«è¿‘ã¥ã„ãŸã®ã‹ã€‚Prompt ã«ã‚ˆã‚‹LLMã¸ã®æŒ‡ç¤ºã‚’è¶…ãˆã‚‹ã¨ã„ã†ã€LLM programã¯ã¯ã€åˆ†å‰²çµ±æ²»ã¨ã„ã†ã‹ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¨ã„ã†ã‹ãã†ã„ã†æ„Ÿã˜ã€‚Microsoftã®Agent Frameworkã£ã¦å‰ã‹ã‚‰ã‚ã£ãŸã‚ˆã†ãªæ°—ã‚‚ã™ã‚‹ãŒã€ãªãœæ³¨ç›®ï¼ŸHintonå…ˆç”Ÿã¨Lecumå…ˆç”Ÿã®è­°è«–ãŒLLMã®æ¬¡ã‚’è¦‹æ®ãˆãŸè­°è«–ã§é¢ç™½ã„ã€‚é™ç•Œã¯ã€ã²ã‚‡ã‚“ãªã“ã¨ã‹ã‚‰è¶…ãˆã‚‰ã‚Œã¦ã‚†ãã¨ã„ã†æ­´å²ã‚‚ã‚ã‚‹ã‚ˆãªã€‚FastChatã§æ§˜ã€…ãªLLMã‚’è©¦ã›ã¦è©•ä¾¡ã®å¹…ãŒåºƒãŒã‚‹ã€M-Benchã‚‚FastChatåˆ©ç”¨ã‚’æƒ³å®šã—ã¦ã„ã‚‹ã®ã‹ã€‚

- 7bã®ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒcolabã§å‹•ãï¼ŸVRAM 32Gç¨‹åº¦ã§è¡Œã‘ã‚‹ã¨
	- https://x.com/Sakkusakumura/status/1716158933319246289?s=20
- Character-LLM: A Trainable Agent for Role-Playing
	- https://aiboom.net/archives/57223
	- ç‰¹å®šã®äººç‰©ã€ä¾‹ãˆã°ãƒ™ãƒ¼ãƒˆãƒ¼ãƒ´ã‚§ãƒ³ã‚„ã‚¯ãƒ¬ã‚ªãƒ‘ãƒˆãƒ©ãªã©ã®è¡Œå‹•ã‚„æ„Ÿæƒ…ã‚’æ¨¡å€£ã•ã›ã‚‹ã‚ˆã†è¨“ç·´ã™ã‚‹æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Character-LLMï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼LLMï¼‰ã€
	- è¨“ç·´ã•ã‚ŒãŸLLMã¯ã€ç‰¹å®šã®äººç‰©ã¨ã—ã¦ã®è¡Œå‹•ã‚„æ„Ÿæƒ…ã‚’åŠ¹æœçš„ã«æ¨¡å€£ã§ãã‚‹ã“ã¨ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚
-  Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts
	- https://cxh0519.github.io/projects/Progressive3D/?ref=aiartweekly
	- Progressive3D brings region specific object manipulation through text with a DALL-E 3 like level of prompt understanding to the table.
	- ï¼“Dãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã€æ§˜ã€…ãªåŠ å·¥ã‚’è¨€èªã§è¡Œã†
- Courtland Leer et al., "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models"
	- https://arxiv.org/abs/2310.06983
	- ã€Œå¿ƒã®ç†è«–ï¼ˆTheory of Mindï¼‰ã€ã‚’ãƒ¡ã‚¿èªçŸ¥èƒ½åŠ›ã‚’ã¤ã‹ã£ã¦å‘ä¸Šã§ãã‚‹ã€‚
	- å¿ƒç†å­¦ã«ãŠã‘ã‚‹ã€ŒViolation of Expectationï¼ˆæœŸå¾…é•åï¼‰ï¼šVoEã€ç†è«–ã‚’é©ç”¨
- llamaindexãŒã¤ã‹ã†ã€ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤ºãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹I/FãŒå…¬é–‹
	-  Accessing/Customizing Prompts within Higher-Level Modules
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompt_mixin.ipynb
- LangChainã‹ã‚‰ã€ã‚¢ãƒ‰ãƒãƒ³ã‚¹ãªRAGã§ã‚‚ã‚ã‚‹ã€"Query Transformation"
	- https://blog.langchain.dev/query-transformations/
	- è³ªå•ã®ã»ã†ã‚’å¤‰æ›ã™ã‚‹ã¨ãªï¼Ÿ
- llamaindexã§ã€HuggingFaceã®LLMã‚’æ´»ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒæ‹¡å¼µã•ã‚ŒãŸ(ä¼šè©±ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã€ãªã©ï¼‰
	- you can now plug any `conversational`, `text_generation`, `feature_extraction` endpoints 
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/huggingface.ipynb
- Finetuning LLaMa + Text-to-SQL
	- https://github.com/run-llama/modal_finetune_sql
	- how to fine-tune Llama2 for better text-to-SQL + easily plug into your LLM app, ordered from easy to hard:
	- text-to-SQLã§æœ€ã‚‚æ€§èƒ½ãŒè‰¯ã„ã®ã¯ã€GPT-4/3.5ã§ã‚‚ã€llamaã§ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚Œã°ã©ã†ã«ã‹ãªã‚‹ã€‚ã“ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ã®æ§˜ã€…ã‚’ç´¹ä»‹ã€
- State of Open Source AI Book - 2023 Edition
	- https://book.premai.io/state-of-open-source-ai/
	- å½“ç„¶æœ¬è‡ªèº«ã‚‚OpenSoruce
	- https://github.com/premAI-io/state-of-open-source-ai
-  ComfyUI-LCMã«ã‚ˆã‚‹Vid2Vidã®é«˜é€Ÿå¤‰æ›ã‚’è©¦ã™(Latent Consistency Models)
	- https://note.com/bakushu/n/nec4cee4f4f37
	- Latent Consistency Modelsï¼ˆLCMï¼‰ã¯ã€æœ€å°é™ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°ã§è¿…é€Ÿã«æ¨è«–ã§ãã‚‹æ–°ãŸãªç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«
	- Google Colabã®æ¨™æº–GPUï¼ˆVRAM 16GBï¼‰ã§è©¦ã—ãŸã¨ã“ã‚ã€512x512ã‚µã‚¤ã‚ºã®120ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»å¤‰æ›ã§1åˆ†å¼±ã€‚1024x1024ã‚µã‚¤ã‚ºã®120ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‹•ç”»å¤‰æ›ã ã¨12-13åˆ†ã»ã©ã§ã—ãŸã€‚
-  AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation
	- https://arxiv.org/abs/2308.08155
	- https://microsoft.github.io/autogen/
	- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆè¬¹è£½ã®Agentãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€å‰ã‹ã‚‰ã‚ã£ãŸã‚ˆã†ãªæ°—ã‚‚ã™ã‚‹ãŒã€‚
- Top AI Shops Fail Transparency Test
	- https://spectrum.ieee.org/ai-ethics#toggle-gdpr
	- Stanford transparency index rates Meta, OpenAI, and others on 100 indicators
	- The highest total score goes to Metaâ€™s Llama 2, with 54 out of 100.
-  llm-jpã‚’Colabã§è©¦ã™
	- https://note.com/alexweberk/n/n6b26b324904c?sub_rt=share_pw
	- ã€Œjaster ã‚’å«ã‚€ã‚‚ã®ã¯å›ç­”ãŒãã£ã‘ãªã„ã€ã‚‰ã—ã„ã®ã§ã€ãã‚Œã‚’é™¤ã„ãŸãƒ†ã‚¹ãƒˆ
	- æµçŸ³æ—¥æœ¬èªç‰¹åŒ–ã®ãƒ¢ãƒ‡ãƒ«ã ã‘ã‚ã£ã¦æ—¥æœ¬èªã¯è‡ªç„¶ãªå½¢ã§ç”Ÿæˆã§ãã¾ã—ãŸã€‚æ—¥æœ¬ã«é–¢ã™ã‚‹åŸºæœ¬çš„ãªçŸ¥è­˜ã‚‚å‚™ãˆã¦ã„ã‚‹ã®ã¯å¬‰ã—ã„
-  LLM ã® ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ã¾ã¨ã‚ by npakaã•ã‚“
	- https://note.com/npaka/n/ndec10f78fe2f
	- äººé–“ã‚’è©•ä¾¡è€…ã¨ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ GPT-4ã‚’è©•ä¾¡è€…ã¨ã—ãŸãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€QAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã‚ˆã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€åŸ‹ã‚è¾¼ã¿ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€ ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
	- ç¾çŠ¶ã§è‡ªå‹•è©•ä¾¡å¯èƒ½ãªæœ€è‰¯ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯GPT-4ã‚’è©•ä¾¡è€…ã¨ã™ã‚‹æ–¹æ³•ã€‚ãŸã ã—ã‚³ã‚¹ãƒˆãªã©èª²é¡ŒãŒã‚ã‚‹
- MiniGPT-V
	- https://note.com/ai_meg/n/n748acc8e824b
	- MiniGPT-4ã®APIã‚’å®Ÿè£…ã™ã‚‹ã€‚ã€€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚’è‡ªç”±ã«æ“ä½œã™ã‚‹ã€‚
-  Google Colab ã§ Japanese Stable LM Gamma 7B ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n4f2d6e6c11f7?sub_rt=share_b
- æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒJapanese Stable LM 3B-4E1Tã€ã€ŒJapanese Stable LM Gamma 7Bã€
	- https://ja.stability.ai/blog/japanese-stable-lm-3b-4e1tjapanese-stable-lm-gamma-7b
	- ç´„30å„„ã¨70å„„ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€æ—¥æœ¬èªã‚¿ã‚¹ã‚¯ã®æ€§èƒ½è©•ä¾¡ã§ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹
	- 3Bã¨7Bã®ã‚µã‚¤ã‚ºã§ãã‚Œãã‚Œåœ§å€’çš„æ€§èƒ½ã‚’èª‡ã‚‹è‹±èªLLMã€ŒStable LM 3B-4E1Tã€ã€ŒMistral-7B-v0.1ã€ã«ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã‚µã‚¯ãƒƒã¨ã‚ã¡ã‚ƒãƒ„ãƒ¨æ—¥æœ¬èªLLM
-  Japanese research is no longer world class â€” hereâ€™s why
	- https://www.nature.com/articles/d41586-023-03290-1?error=cookies_not_supported&code=dd59d16e-8d54-49a4-95a3-8fcded36917f&utm_medium=Social&utm_campaign=nature&utm_source=Twitter#Echobox=1698226936
	- natureè¨˜äº‹ã‚ˆã‚Š
	- **è³‡é‡‘ä¸è¶³ã¨æ™‚é–“ä¸è¶³**ã€**è‹¥æ‰‹ç ”ç©¶è€…ã®ä¸æº€ã¨æ¸›å°‘**ã€€ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ã‚‹ã€‚
-  Branch-Solve-Merge Improves Large Language Model Evaluation and Generation
	- https://arxiv.org/abs/2310.15123
	- Promptã‚’è¶…ãˆãŸï¼ŸLLMè‡ªèº«ã‚’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ä¸€éƒ¨ã«åŸ‹ã‚è¾¼ã‚“ã§ä½¿ã†ã‚ˆã†ãªã€LLM programã¨å‘¼ã°ã‚Œã‚‹ã‚ˆã†ãªæ‰‹æ³•
- Large Language Model Programs
	- https://arxiv.org/pdf/2305.05364.pdf
	- LLMã‚’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«åŸ‹ã‚è¾¼ã‚€ã“ã¨ã‚’LLM Programã¨ã¨å‘¼ã¶ã‚‰ã—ã„ã€åˆ†å‰²çµ±æ²»ãªã‚“ã‹ãã†ãªã‚“ã ã‘ã©ã€ãƒ¡ã‚¿ãªLLMã¿ãŸã„ãªæ„Ÿã˜
-  LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions
	- https://arxiv.org/abs/2310.14029v1
	- çµæ™¶æ§‹é€ ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã—ã¦è¨€èªãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã€ãã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã‚’ä½¿ã£ã¦ç‰©æ€§äºˆæ¸¬ã‚’è¡Œã†ã¨å¾“æ¥ã®SOTAã§ã‚ã‚‹GNNãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šé«˜ç²¾åº¦ãªäºˆæ¸¬
-  LangChain ã® Step-back Prompting ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n55f276ad2988?sub_rt=share_sb
	- (1) ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…ƒã®è³ªå•ã«åŸºã¥ã„ã¦ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒãƒƒã‚¯è³ªå•ã‚’ç”Ÿæˆ  
	- (2) å…ƒã®è³ªå•ã¨ã‚¹ãƒ†ãƒƒãƒ—ãƒãƒƒã‚¯è³ªå•ã®ä¸¡æ–¹ã‚’æƒ…å ±åé›†  
	- (3) å–å¾—ã—ãŸä¸¡æ–¹ã®æƒ…å ±ã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆ
- mmnga/japanese-stablelm-instruct-gamma-7b-gguf
	- stabilityAIã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹japanese-stablelm-instruct-gamma-7bã®gguf
	- Mistral-7bã®æ—¥æœ¬èªç‰ˆã§ã€AIã®ã¹ã‚Šã™ã¨ã•ã‚“ã‹ã‚‰æä¾›ã•ã‚ŒãŸé«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã‚‹
- ãƒ•ã‚£ãƒ¼ãƒ«ã‚ºè³å—è³è€…ã®ãƒ†ãƒ¬ãƒ³ã‚¹ãƒ»ã‚¿ã‚ªã•ã‚“ãŒã€è¨¼æ˜æ”¯æ´ç³»Leanã‚’ä½¿ã†ã“ã¨ã§è‡ªåˆ†ã®è«–æ–‡ã®ä¸­ã®ãƒã‚°ï¼ˆãƒŸã‚¹ï¼‰ã«æ°—ã¥ã„ãŸã¨ã„ã†è©±
	- https://mathstodon.xyz/@tao/111287749336059662
	- å®šç†è¨¼æ˜ç³»ãŒå®Ÿæ•°å­¦è€…ã®ãŸã‚ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã€‚ã€‚ã€‚
-  KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval
	- https://huggingface.co/papers/2310.15511
	-  (e.g., 'a list of ice cream shops in San Diego')
-  LLMã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ã¾ã¨ã‚
	- https://qiita.com/fuyu_quant/items/157086987bd1b4e52e80
-  Zephyr: Direct Distillation of LM Alignment
	- https://arxiv.org/abs/2310.16944
	- ãªã‚“ã‹ã™ã”ã„æ€§èƒ½ã‚‰ã—ã„ã€‚
-  Human-like systematic generalization through a meta-learning neural network
	- https://www.nature.com/articles/s41586-023-06668-3
	- æ—¢å­˜ã®æ¦‚å¿µã‚’çµ„ã¿åˆã‚ã›ã‚‹systematic compositionalityã®èƒ½åŠ›ã‚’ã€ãƒ¡ã‚¿å­¦ç¿’ã‚’æ–½ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã§å®Ÿç¾ã€‚35å¹´å‰ã®Fodorï¼†Pylyshynã®ã€Œãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã¯compositionalityã‚’æŒã¦ãªã„ã€ã¨ã®ä¸»å¼µã¸ã®å¿œç­”ã¨ã—ã¦æ›¸ã„ã¦ã„ã‚‹
-  MT-Bench ã®ä½¿ã„æ–¹ by npakaã•ã‚“
	- https://note.com/npaka/n/na28f31e96599?sub_rt=share_b
	- ã€Œ[**MT-Bench**](https://chat.lmsys.org/?leaderboard)ã€ã¯ã€80ã®é«˜å“è³ªã§ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã®è³ªå•ã‚’å«ã‚€ã€æ…é‡ã«ã‚­ãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸLLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã™ã€‚
	- ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§ã§ã‚‹ã®ãŒã‚ˆã„ã€‚
-  7Bã®LLMã®è¦‡è€…ã¯ã€Mistral 7B ï¼Ÿï¼Ÿ
	- https://www.promptingguide.ai/models/mistral-7b
- Getting started  with Llama by Meta
	- Metaè¬¹è£½ã®Llmaã‚¬ã‚¤ãƒ‰
	- https://ai.meta.com/llama/get-started/
	- Yann LeCunå…ˆç”Ÿã®ãŠã™ã™ã‚ã§ã‚‚ã‚ã‚‹ã€‚
- bakLLaVA vision AI can read xrays with only 6Gb of RAM
	- https://github.com/SkunkworksAI/BakLLaVA
	- OSSã®LLMã§ãŒã‚“ç”»åƒæ¤œè¨ºãŒã§ãã‚‹ï¼Ÿ
- Zephyr-7b-betaã£ã¦ç„¡æ•µã‹ã‚‚
	- https://colab.research.google.com/drive/1UoPcoiA5EOBghxWKWduQhChliMHxla7U?usp=sharing
	- found itâ€™s the only 7B LLM that can handle ReAct agent tasks over data
	- ã¤ã¾ã‚Šã€dataã«å¯¾ã—ã¦ã€ReActã™ã‚‹Agentã‚’å®Ÿè£…ã§ãã‚‹å”¯ä¸€ã®7B LLMã¨ã„ã†ã“ã¨ã‚‰ã—ã„
	- Jelly Liuã•ã‚“(llamaindexä½œè€…)ã‚‚æ¿€è³
	- https://x.com/jerryjliu0/status/1718054817640390840?s=20
-  Evaluating RAG pipelines with Ragas + LangSmith
	- https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/
	- RAGã®æ€§èƒ½è©•ä¾¡ã‚’Ragasã¨LangSmithã§è¡Œã†æ–¹æ³•ã‚’ç´¹ä»‹ã—ãŸè¨˜äº‹
	- Ragasã¯LLMã«ã‚ˆã‚‹RAGã®è‡ªå‹•è©•ä¾¡ã‚’æ”¯æ´ã™ã‚‹OSSã€è©¦ã—ãŸã‘ã©ãŠé‡‘ã‹ã‹ã‚‹ã‚“ã ã‚ˆãªã€‚
- llama2 7bã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€å‡ºåŠ›ã‚’ç‰¹å®šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã™ã‚‹ã“ã¨ãŒã§ãã‚‹
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/gradient/gradient_structured.ipynb
	- structured Pydantic objectsã‚’å‡ºåŠ›ã™ã‚‹
- å¸äººã®çµ±åˆå ±å‘Šæ›¸2023ã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ç‰¹è¨±æƒ…å ±åˆ†æã€‚ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å¤‰åŒ–ã«ã¤ã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹å…¨ä½“ä¿¯ç°ã¨ç‰¹è¨±ä¾¡å€¤è©•ä¾¡ã®2ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¯è¦–åŒ–
	- https://ssl4.eir-parts.net/doc/3401/ir_material_for_fiscal_ym1/141477/00.pdf
- Hintonå…ˆç”Ÿã®ã€æ–°ã—ã„LLMã®é–‹ç™ºï¼ˆãŸã¶ã‚“OpenAI)ã«å¯¾ã™ã‚‹å±æƒ§ã«å¯¾ã—ã¦ã€Lecumå…ˆç”Ÿã¯ã€ã©ã†ã›ä»Šã®Auto-Regressive LLMã®å»¶é•·ç·šä¸Šã®é–‹ç™ºãªã®ã§ã€é™ç•Œã¯è‡ªæ˜ã„ã€‚çœŸã«å¿…è¦ãªAIã¯ã€ã€ã¨åè«–ã€‚
	- https://x.com/ylecun/status/1718263303485501784?s=20
	- Objective-Driven AI architecturesãŒå¿…è¦ã¨ã®ã“ã¨
- Advanced Prompt Engineering for RAG by llamaindex
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompts_rag.ipynb
	- åŸºæœ¬çš„ãªRAGã‹ã‚‰ã€few-shotè¿½åŠ ã—ãŸã‚Šã€contextå¤‰æ›ã—ãŸã‚Šã¨ã„ã†è©±é¡Œ
- Stability AI ã® Japanese MT-Bench ã‚’è©¦ã—ãŸ
	- https://x.com/npaka123/status/1718403656725483961?s=20
- Demystifying Advanced RAG Pipelines
	- https://github.com/pchunduri6/rag-demystified
-  Chatting With Your Data Ultimate Guide
	- https://medium.com/aimonks/chatting-with-your-data-ultimate-guide-a4e909591436
-  MT-Bench ã«ã‚ˆã‚‹æ—¥æœ¬èªLLMã®è©•ä¾¡ by npakaã•ã‚“
	- https://note.com/npaka/n/n0530f6f9123f?sub_rt=share_sb
	- ã€ŒStability AIã€ãŒæä¾›ã™ã‚‹**ã€ŒJapanese MT-Benchã€ã®è³ªå•ãƒ•ã‚¡ã‚¤ãƒ«**ã¨**å‚ç…§å›ç­”ãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ä½¿ã†
	- è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€FastChatãŒå¯¾å¿œã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

## 10/23

ä»Šé€±ã¯ã€NIIã‹ã‚‰llm-jp-13b-v1.0ãŒå…¬é–‹ã•ã‚ŒãŸã®ãŒè©±é¡Œã§ã—ãŸã€ã•ã£ããcolabã§ä½¿ã£ãŸä¾‹ãŒå…¬é–‹ã•ã‚ŒãŸã‚Šã€4bité‡å­åŒ–ç‰ˆãŒhuggingfaceã§å…¬é–‹ã•ã‚ŒãŸã‚Šã¨ã€ç››ã‚Šä¸ŠãŒã£ã¦ã¾ã™ã€‚é–¢ä¿‚è€…ã®åŠªåŠ›ã¨ABCIã®æ´»èºã«é ­ãŒä¸‹ãŒã‚Šã¾ã™ã€‚LLMæ´»ç”¨ã‚¢ãƒ—ãƒªã®æ€§èƒ½ã‚’è€ƒãˆã‚‹ã¨ãã«ã€RAGã§ã‚‚ãã†ãªã‚“ã ã‘ã©ã€LLMã¨embeddingã®çµ„ã¿åˆã‚ã›ã‚’ã¡ã‚ƒã‚“ã¨è©•ä¾¡ã™ã‚‹ã£ã¦ã®ãŒæœ€åˆã«ã‚ã‚‹ã¹ããªã®ã‹ã‚‚ã€‚ä½¿ã£ãŸã“ã¨ãªã„ã‘ã©ã‚‚Replicateã¯ãã“ã‚“ã¨ã“ã‚ã†ã¾ãã¤ã„ãŸã‚µãƒ¼ãƒ“ã‚¹å±•é–‹ã¨ã„ãˆã‚‹ã€‚LLMã‚’ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã§æ´»ç”¨ã§ãã‚‹ã¨ã„ã†è«–æ–‡ãŒè©±é¡Œã«ã€‚OpenAIã€é™ã‚ŠãªãAGIã«è¿‘ã„ã¨ã†ã‚ã•ã®Arrakisã®é–‹ç™ºæ–­å¿µï¼Ÿæ˜ ç”»Duneï¼’(Arrakisã¨ã„ã†æ˜ŸãŒéƒ¨éšŠï¼‰ã®å…¬é–‹ã‚‚æ˜¥ã«ãšã‚Œè¾¼ã‚“ã ã‹ã‚‰ã€ä¼¼ãŸã‚ˆã†ãªé‹å‘½ã‚’ãŸã©ã‚‹ã®ã‹ï¼Ÿãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã®ãƒ¬ãƒãƒ¼ãƒˆã€ç”ŸæˆAIã«ã‚ˆã‚Šã€AIã®ä½œæ–‡åŠ›ãŒäººé–“ã®ä¸Šä½25%ã‚’è¶…ãˆã‚‹æ™‚æœŸã®äºˆæ¸¬ãŒ25å¹´å‰å€’ã—ã¨ã„ã†ã®ã¯é©šã„ãŸã€ã¤ã¾ã‚Šæˆ‘ã€…ã¯25å¹´å…ˆã®æŠ€è¡“ã‚’ä»Šè¦‹ã¦ã„ã‚‹ã“ã¨ã«ãªã‚‹ã€ãã‚Šã‚ƒï¼ˆå¤šãã®äººã«ã¯LLMã®å‡„ã•ãŒï¼‰åˆ†ã‚‰ã‚“ã‚ãªã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§ã®ã€Œç§‘å­¦è«–æ–‡ã®æŸ»èª­ã€ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãŒæœ‰ç”¨ã§ã‚ã‚‹ã¨ã„ã†è«–æ–‡ã€ã“ã‚Œã¯æœ—å ±ã ï¼ˆèª°å¾—ï¼Ÿï¼‰ã€‚ã€Œkaggle LLMã‚³ãƒ³ãƒšã€€ä¸Šä½è§£æ³•ã®ã¾ã¨ã‚ã€ã¯ã“ã‚Œã¯LLMãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚·ãƒ§ãƒŠãƒ¼ã«ã¯å¿…èª­ã ã€‚ã¡ã‚ƒã‚“ã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«ä¸ãˆã‚‹ã“ã¨ãŒé‡è¦ã€‚ã‚ãŸã‚Šã¾ãˆã ã‘ã©ã€ãã‚Œã‚’è¡Œã†ã®ã¯é›£ã—ã€‚ã€Œä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã€ã«å¯¾ã™ã‚‹OpenAIå…±åŒè¨­ç«‹è€…ã®Ilya Sutskeveræ°ã®å¯¾è«‡ã€å¤§è¦æ¨¡æ·±å±¤å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯è¨€è‘‰ã‚’ç”Ÿæˆã™ã‚‹ä½•ç­‰ã‹ã®è¡¨ç¾ï¼ˆã¤ã¾ã‚Šä¸–ç•Œãƒ¢ãƒ‡ãƒ«ï¼‰ã‚’å­¦ç¿’ã—ã€ã“ã‚Œã‹ã‚‰æ¼ã‚Œå‡ºã‚‹ã‚‚ã®ãŒãƒ†ã‚­ã‚¹ãƒˆã§ã‚ã‚‹ã¨è¨€ã£ã¦ã„ã‚‹ï¼ˆãƒŠã‚¦ã‚·ã‚«ã®ã€Œå¢“æ‰€ã®ä¸»ã€ã¿ãŸã„ãªã‚‚ã®ã‹ï¼‰ã€‚LLMã®å› æœæ¨è«–èƒ½åŠ›ã®ãƒ™ãƒ³ãƒãƒ¼ãƒãƒ¼ã‚¯ã€fine-tuningã™ã‚‹ã¨æ€§èƒ½ã¯ã‚ãŒã‚‹ãŒã€å°‘ã—è¡¨ç¾ã‚’å¤‰ãˆã‚‹ã¨æ€§èƒ½ãŒçˆ†ä¸‹ãŒã‚Šã£ã¦ï¼ã€ãã‚ŒãŒLLMãªã®ã‚ˆï¼æœ€æ–°ã®è¨€èªç†è«–ã§ã‚ã‚‹ã€Œã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚²ãƒ¼ãƒ ã€ã§äººé–“ã®è¨€èªèƒ½åŠ›ãŒèº«ã«ã¤ã„ãŸã¨ã™ã‚‹ã¨ã€LLMãŒç¤ºã™ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆèƒ½åŠ›ã¯ä½•ï¼Ÿï¼ŸIlya Sutskeveræ°ã®å¯¾è«‡ã®è©±ã¨çœŸã£å‘ã‹ã‚‰å¯¾ç«‹ã™ã‚‹æ„Ÿã˜ã€‚ã€Œè¨€èªã‚²ãƒ¼ãƒ ã€ã¨ã„ãˆã°ãƒ´ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã€ã‚¦ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ç ”ç©¶ã‚’å°‚é–€ã¨ã™ã‚‹å¤§è°·å…ˆç”Ÿã®å¯¾è©±è¨˜äº‹ã«ã‚ˆã‚‹ã¨ã€‚LLMã¨è¨€èªã‚²ãƒ¼ãƒ ã£ã¦ä¼¼ãŸã¨ã“ã‚ãŒã‚ã‚‹ãã†ã ã€‚ãªã‚“ã‹ã€æ¥½ã—ããªã£ã¦ããŸã€‚

- Ilya Sutskeveræ°LLMã¨ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦èªã‚‹ with Jensen Huang, CEO of Nvidia:
	- https://twitter.com/i/status/1713368556618887670
	- OpenAIã®å…±åŒè¨­ç«‹è€…ã§ã‚ã‚‹Ilya Sutskeveræ°ã¨Nvidiaã®ensen Huangç¤¾é•·ã¨ã®å¯¾è«‡ã‚ˆã‚Š
	- ï¼ˆå·¨å¤§ãªï¼‰ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãŒå­¦ã‚“ã§ã„ã‚‹ã®ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€Œä½•ã‹ã€ã«å¯¾ã™ã‚‹è¡¨ç¾ã‚’å­¦ã‚“ã§ã„ã‚‹ã€‚ãã®ã€Œä½•ã‹ã€ã¨ã¯ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€ãã‚ŒãŒå°„å½±ã•ã‚ŒãŸã‚‚ã®ãŒç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆãªã®ã§ã‚ã‚‹ã€‚
- Jonas Belouadi et al., "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"
	- https://arxiv.org/abs/2310.00367
	- LLMã‚’æ´»ç”¨ã—äººé–“ã®ã‚ˆã†ã«ç§‘å­¦çš„ãªå›³ã‚’ç”Ÿæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€AutomaTikZã€
	- ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç§‘å­¦çš„ãªãƒ™ã‚¯ã‚¿ãƒ¼ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ 
	- LLaMAã‚’DaTikZãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å¾®èª¿æ•´
-  Can Large Language Models Infer Causation from Correlation?
	- https://arxiv.org/abs/2306.05836
	- https://ai-scholar.tech/articles/large-language-models/llm_causal_inference_skill
	-  LLMã«å› æœæ¨è«–èƒ½åŠ›ã¯ã‚ã‚‹ã‹ï¼Ÿ
	- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å› æœæ¨è«–èƒ½åŠ›ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ææ¡ˆ  
	- 17ã®æ—¢å­˜ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡  
	- ç¾çŠ¶ã®ãƒ¢ãƒ‡ãƒ«ã¯å› æœæ¨è«–èƒ½åŠ›ãŒä½ã„ã“ã¨ãŒã‚ã‹ã£ãŸ
	- fine-tuningã«ã‚ˆã‚Šæ€§èƒ½å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã‚‹ä¸€æ–¹ã§ï¼Œå°‘ã—è¡¨ç¾ã‚’å¤‰ãˆãŸã ã‘ã§æ€§èƒ½ãŒä¸‹ãŒã‚‹ç¾è±¡ã‚‚è¦‹ã‚‰ã‚Œã‚‹
- Yijun Tian et al., "Graph Neural Prompting with Large Language Models"
	- https://arxiv.org/abs/2309.15427
	- LLMã«ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ï¼ˆçŸ¥è­˜ã‚°ãƒ©ãƒ•ï¼‰ã‚’é€£æºã•ã›ã‚‹ã“ã¨ã§ã€ã‚¿ã‚¹ã‚¯é‚è¡Œèƒ½åŠ›ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Graph Neural Promptingï¼ˆGNPï¼‰ã€
	- GNPã¯ã€LLMã«æœ‰ç›ŠãªçŸ¥è­˜ã‚’åŠ¹æœçš„ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¤§å¹…ã«å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«å‹•ã„ã¦ã‚‹ã‹ã‚’è¦–è¦šçš„ã«èª¬æ˜ã™ã‚‹ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ãŒç´ æ™´ã‚‰ã—ã„ã¨
	- https://ig.ft.com/generative-ai/
	- Fanatical Timesã®ã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯
- Large Language Models for Software Engineering: Survey and Open Problems
	- https://arxiv.org/abs/2310.03533
	- LLMã‚’ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°(SE)ã«ã©ã†ã‚„ã£ã¦é©ç”¨ã™ã‚‹ã‹ï¼Ÿ
	- è¦æ±‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°/ãƒ‡ã‚¶ã‚¤ãƒ³ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€ãƒ†ã‚¹ãƒˆã€é‹ç”¨/ãƒ‡ãƒ—ãƒ­ã‚¤ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã€‚ã¾ãŸãƒªã‚µãƒ¼ãƒé ˜åŸŸã§ã®æ´»ç”¨ãªã©ã‚‚
	- ä¼çµ±çš„ãªSEã¨LLMã‚’èåˆã—ãŸã¯ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã«ã‚ˆã‚Šä¿¡é ¼ã‚ã‚‹åŠ¹ç‡çš„ãªLLMãƒ™ãƒ¼ã‚¹ã®SEãŒå®Ÿç¾ã§ããŸ
- JapaneseEmbeddingEvalã€€æ—¥æœ¬èªã«ãŠã‘ã‚‹embeddingã®è©•ä¾¡
	-  https://github.com/oshizo/JapaneseEmbeddingEval
	- multilingual-e5ã£ã¦ã„ã„ç·šã„ã£ã¦ã‚‹ã®ã‹ã€‚ã€‚
- PaLI-3 Vision Language Models: Smaller, Faster, Stronger
	- https://huggingface.co/papers/2310.09199
	- Googleã«ã‚ˆã‚‹ã€é«˜æ€§èƒ½ã§å°ã•ã„vision language model (VLM)
- ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã‹ã‚‰ç™ºè¡¨ã•ã‚ŒãŸAIå‹•å‘ã«é–¢ã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆãŒãªã‹ãªã‹è¡æ’ƒçš„
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-AI-the-next-productivity-frontier#introduction
	- ç”ŸæˆAIï¼ˆã¨ã„ã†ã‹ChatGPTã«ä»£è¡¨ã•ã‚Œã‚‹LLM)ã®ç™»å ´ã«ã‚ˆã‚Šã€AIã®ä½œæ–‡åŠ›ãŒäººé–“ã®ä¸Šä½25%ã‚’è¶…ãˆã‚‹æ™‚æœŸã®äºˆæ¸¬ãŒ25å¹´å‰å€’ã—ã«ãªã£ãŸ
		- 2017å¹´ã®äºˆæ¸¬ï¼š2050å¹´ ãƒ»2023å¹´ã®äºˆæ¸¬ï¼š2024ã€œ2025å¹´ 
- Xinyun Chen et al, "Teaching Large Language Models to Self-Debug"
	- https://arxiv.org/abs/2304.05128
	- GPT-4ãªã©LLMã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆèƒ½åŠ›ã«ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ã‚’è¿½åŠ ã™ã‚‹ã€SELF-DEBUGGINGï¼ˆã‚»ãƒ«ãƒ•ãƒ‡ãƒãƒƒã‚®ãƒ³ã‚°ï¼‰ã€
	- LLMã«è‡ªå·±ãƒ‡ãƒãƒƒã‚°ã®èƒ½åŠ›ã‚’æ•™ãˆã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹
- ChatGPTã‚’ç”¨ã„ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å­¦ã¶æ–¹æ³•ã«ã¤ã„ã¦ï¼ˆæ…¶å¿œç¾©å¡¾å¤§å­¦ï¼‰
	- https://speakerdeck.com/keio_smilab/keio-univ-intro-to-ml-02-coding
	- ãªã‚“ã¨ã€å­¦ç”Ÿå‘ã‘ã«ã€ChatGPTã‚’ç”¨ã„ã¦Pythonãªã©ã®ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å­¦ã¶ã¨ã„ã†æˆæ¥­ãŒã€ã€
	- ChatGPTãƒã‚¤ãƒ†ã‚£ãƒ–ãªå­¦ç”Ÿã¯ã€ChatGPTã§ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’å­¦ã¶ã®ã‹ã€‚ã€‚
- Andrew Ngå…ˆç”Ÿã‹ã‚‰ã€deeplearning.aiã®ã€Œç”ŸæˆAIã€ã®è¬›ç¾©ã®å®£ä¼
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- OpenAIã€æ¬¡ä¸–ä»£LLMã§ã‚ã‚‹ã€Arrakisã®é–‹ç™ºã‚’æ–­å¿µï¼Ÿ
	-  OpenAI Dropped Work on New â€˜Arrakisâ€™ AI Model in Rare Setback
	- é™ã‚ŠãªãAGIã«è¿‘ã„ã¨ã†ã‚ã•ã•ã‚Œã‚‹æ¬¡ä¸–ä»£ã®LLMã€
	- ã©ã†ã†ã‚‚é–‹ç™ºä¸­ï¼ˆå­¦ç¿’ä¸­ï¼‰ã®æ€§èƒ½è©•ä¾¡ã§æ€ã£ãŸã»ã©æ€§èƒ½ãŒå‡ºãªã‹ã£ãŸãŸã‚ã€‚
	- https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback
- llamaindexã®Liuã•ã‚“ã‚ˆã‚Šã€â€œEvaluation Driven Developmentâ€ (EDD)ã®ææ¡ˆ
	- https://x.com/jerryjliu0/status/1713936561480610104?s=20
	- ã¾ãšã¯ã€LLMï¼‹Embeddingã®çµ„ã¿åˆã‚ã›ã‚’ã¡ã‚ƒã‚“ã¨è©•ä¾¡ã™ã‚‹ã¨ã“ã‚ã‹ã‚‰å§‹ã‚ã‚ˆã†ã¿ãŸã„ãªã€‚
- Replicateã‚’åˆ©ç”¨ã™ã‚‹ã¨ã€ä»»æ„ã®LLMã¨embeddingã®çµ„ã¿åˆã‚ã›ã‚’ç°¡å˜ã«è©•ä¾¡ã§ãã‚‹
	- https://replicate.com/explore
	- ã¤ã¾ã‚Šhuggingfaceã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦å‹•ã‹ã™æ‰‹é–“ã‚’ã€å°‘ã—çœãã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã€
	- ãƒŠã‚¤ã‚¹ã ãªã€‚
- NIIã‹ã‚‰ã€LLM-jp-13B ãŒå…¬é–‹ã•ã‚Œã‚‹
	- LLM-jp ï¼ˆLLM å‹‰å¼·ä¼šï¼‰ã¯ã€æ—¥æœ¬èªã¨è‹±èªã‚’ä¸­å¿ƒã«äº‹å‰å­¦ç¿’ã—ãŸ130å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§å…¬é–‹
	- https://llm-jp.nii.ac.jp/release/
	- ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚„è¨“ç·´ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç”¨ã„ãŸã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚‚å…¬é–‹
- ãƒ‡ãƒ¼ã‚¿ã§ã§ãã‚‹ã“ã¨ã®ãƒ¬ãƒ™ãƒ«æ„Ÿã‚’ç†è§£ã™ã‚‹ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«åºã®äººã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚ˆã‚Šï¼‰
	- https://speakerdeck.com/hik0107/data-design-and-government?slide=10
	- ç¾çŠ¶ã®æŠŠæ¡(lv.1)ã€åˆ†è§£ã¨å·®ç•°ã®æŠŠæ¡(Lv.2)ã€åŸå› ã®æŠŠæ¡(Lv.3)ã€å¯¾ç­–ã®æŠŠæ¡(Lv4)
-  Google Colab ã§ LLM-jp-13B ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n60b0abf54ed5?sub_rt=share_sb
	- T4 ãƒã‚¤ãƒ¡ãƒ¢ãƒªã§å‹•ä½œç¢ºèª
	- æ—©é€Ÿè©¦ã•ã‚Œã¦ã„ã‚‹
- BEYOND MEMORIZATION: VIOLATING PRIVACY VIA INFERENCE WITH LARGE LANGUAGE MODELS
	- https://arxiv.org/pdf/2310.07298v1.pdf
	- Redditã®åŒ¿åãƒã‚¹ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€GPT-4ã¯ãã®äººã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåå…¥ã€æ€§åˆ¥ã€ä½æ‰€ï¼‰ã‚’85%ã®æ­£ç¢ºã•ã§ã€ã‹ã¤äººé–“ã®1%ã®ã‚³ã‚¹ãƒˆã§å½“ã¦ãŸã€‚ã€‚
	- A paper that really illustrates both the unexpected power, and unexpected risks, that come from LLMs.
-  InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
	- https://arxiv.org/abs/2310.07713
	- pre-train LLMs with Retrieval Augmentation
-  An Emulator for Fine-Tuning Large Language Models using Small Language Models
	- https://huggingface.co/papers/2310.12962
	- Emulator for Fine-Tuning(EFT)ã¯ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å°è¦æ¨¡ãªå¾®èª¿æ•´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã™ã‚‹ã“ã¨ã§ã€å¤§è¦æ¨¡ãªäº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸçµæœã‚’ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ã¨ã„ã†ã€ã‚¢ãƒƒãƒ—ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒå¯èƒ½ã«ãªã£ãŸ
-  Can large language models provide useful feedback on research papers? A large-scale empirical analysis
	- https://arxiv.org/abs/2310.01783
	- ã€Œç§‘å­¦è«–æ–‡ã®æŸ»èª­ã€ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ãŒæœ‰ç”¨ãªå¯èƒ½æ€§ãŒã‚ã‚‹
	- ç±³ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§ã‚‰ãŒæ¤œè¨¼ã€€å‚åŠ è€…ã®80ï¼…ä»¥ä¸Šã€ŒAIæŸ»èª­ã¯æœ‰ç›Šã€
	- https://www.itmedia.co.jp/news/articles/2310/19/news072.html
	- Natureç³»åˆ—ã®ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã«ãŠã‘ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®çµæœã€GPT-4ãŒæä¾›ã—ãŸã‚³ãƒ¡ãƒ³ãƒˆã®57.55ï¼…ã¯ã€å…¨ä½“ã®æŸ»èª­è€…ã®ä¸­ã§å°‘ãªãã¨ã‚‚1äººã®äººé–“ã®æŸ»èª­è€…ãŒè¨˜è¼‰ã—ã¦ã„ãŸ
- A quantized version of the mistral that is instruction following over 32k tokens.
	- https://huggingface.co/TheBloke/MistralLite-7B-AWQ
	- mistralã£ã¦æ€§èƒ½ãŒã‚ˆã„ã¨å…ˆé€±è©•åˆ¤ã«ãªã£ã¦ãŸã‚„ã¤ã®ã€4bité‡å­åŒ–ç‰ˆãŒå…¬é–‹ï¼Ÿ
- llm-jp-13b-v1.0ã‚‚æ—©é€ŸGPTQç‰ˆãŒå…¬é–‹ã•ã‚Œã‚‹
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-4bit-g128-GPTQ-calib-ja-1k
	- llm-jp-13b-v1.0ã‚’ã€ æ—¥æœ¬èªã®ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ãƒƒãƒˆã§ç”Ÿæˆã—ãŸGPTQãƒ¢ãƒ‡ãƒ«
-  è¨€èªã¯ã“ã†ã—ã¦ç”Ÿã¾ã‚Œã‚‹â€•ã€Œå³èˆˆã™ã‚‹è„³ã€ã¨ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚²ãƒ¼ãƒ â€•
	- https://www.shinchosha.co.jp/book/507311/
	- è¨€èªã®ç”Ÿå¾—æ€§ã‚’å¦å®šã—ã€æ–‡åŒ–é€²åŒ–ã‚„èªç”¨è«–çš„ãªè¦³ç‚¹ã‹ã‚‰è¨€èªç²å¾—ã‚’è«–ã˜ã¦ã„ã¾ã™
	- æ­´å²ï¼šãƒãƒ¼ãƒ ãƒ»ãƒãƒ§ãƒ ã‚¹ã‚­ãƒ¼ã¯ã€Œæ™®éæ–‡æ³•ã€ã¨ã„ã†æ¦‚å¿µã‚’å°å…¥ã—ã€ã€Œäººé–“ã®éºä¼çš„é’å†™çœŸã«ã¯ã€è¨€èªã‚’æ”¯é…ã™ã‚‹æŠ½è±¡çš„ãªæ•°å­¦çš„åŸç†ãŒå†…åŒ…ã€ã—ã¦ã„ã‚‹ã¨ã„ã£ãŸ
	- æ­´å²ï¼šå¿ƒç†å­¦è€…ã‚¹ãƒ†ã‚£ãƒ¼ãƒ–ãƒ³ãƒ»ãƒ”ãƒ³ã‚«ãƒ¼ãŒã•ã‚‰ã«ã€è¨€èªã‚’ç”Ÿã¿ã ã™æœ¬èƒ½ã€ï¼ˆNHKãƒ–ãƒƒã‚¯ã‚¹ï¼‰ã¸ã¨ç™ºå±•ã•ã›ã‚‹
	- ä¸»å¼µï¼šã€Œã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚²ãƒ¼ãƒ ã€ã€‚è¨€èªã¯éºä¼çš„ã«æ±ºå®šã•ã‚ŒãŸã‚‚ã®ãªã©ã§ã¯ãªãã€èº«æŒ¯ã‚Šæ‰‹æŒ¯ã‚Šã€ç™ºå£°ã€ã‚ã‚‹ã„ã¯ãã®ä¸¡æ–¹ã§è‡ªåˆ†ã®æ„æ€ã‚’åŒæ–¹å‘çš„ã«ä¼ãˆåˆã†ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚²ãƒ¼ãƒ ã®ã‚ˆã†ãªã‚‚ã®ãŒèµ·æºãªã®ã§ã¯ãªã„ã‹ã¨ã„ã†æ–¬æ–°ãªã‚¢ã‚¤ãƒ‡ã‚¢ã ã€‚ãã“ã«ã¯æ™®éæ–‡æ³•ãŒå…¥ã‚Šè¾¼ã‚€ä½™åœ°ãªã©ãªã„ã€‚
- LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€Œè¨€èªã‚²ãƒ¼ãƒ ã€çš„ã‹  æ±äº¬å¥³å­å¤§å­¦ç¾ä»£æ•™é¤Šå­¦éƒ¨å‡†æ•™æˆãƒ»å¤§è°·å¼˜æ°ã«èãï¼ˆï¼‘ï¼‰
	- [ITæ‰¹è©•ã®è¨˜äº‹](https://it-hihyou.com/recommended/llm%EF%BC%88%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%89%E3%81%AF%E3%80%8C%E8%A8%80%E8%AA%9E%E3%82%B2%E3%83%BC%E3%83%A0%E3%80%8D%E7%9A%84%E3%81%8B-%E2%80%95/)ã‚ˆã‚Š
	- LLMã£ã¦ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰å­¦ã³ã€ãã®èƒŒå¾Œã«ã¯äººé–“ãŒã‚ã‚‹ã‹ã‚‰ã€ãƒ´ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã®ã„ã†ã€Œè¨€èªã‚²ãƒ¼ãƒ ã€ã«ä¼¼ã¦ã„ã‚‹ã€ã‚‰ã—ã„ã€‚è¨˜å·æ¥åœ°ã—ã¦ãªã„ã¨ã„ã†æ‰¹åˆ¤ã«ã‚‚ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èƒŒå¾Œã®äººé–“ã®ã‚ãŸã‚Šã§æ¥åœ°ã—ã¦ã„ã‚‹ã®ã‹ã‚‚ã¨ã‚‚ã„ã†ã€‚
- å¤šæ§˜ä½“ä¸Šã®æœ€é©åŒ–ç†è«–
	- https://www.amazon.co.jp/exec/obidos/ASIN/4274231186?&linkCode=sl1&tag=mathlang09-22&linkId=bd145734052442298eb01413d823ca91&language=ja_JP&ref_=as_li_ss_tl
	- å¤šæ§˜ä½“ä¸Šã®æœ€é©åŒ–ç†è«–ã«ã¤ã„ã¦ã€åŸºç¤ã¨ãªã‚‹æ•°ç†ã‹ã‚‰å¿œç”¨ä¾‹ã¾ã§ã‚’è§£èª¬
-  Introducing CliffordLayers: Neural Network layers inspired by Clifford / Geometric Algebras.
	- https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/articles/introducing-cliffordlayers-neural-network-layers-inspired-by-clifford-geometric-algebras/
	- MSç ”ç©¶æ‰€ã‹ã‚‰ã€ã‚¯ãƒªãƒ•ã‚©ãƒ¼ãƒ‰ä»£æ•°ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸæ–°ã—ã„NNãƒ¬ã‚¤ãƒ¤ã®ç™ºæ˜
-  OpenAgents: An Open Platform for Language Agents in the Wild
	- https://arxiv.org/abs/2310.10634v1
- llamaindexã‚ˆã‚Šã€Unifying Text-to-SQL and RAG with our SQLRetrieve
	- https://docs.llamaindex.ai/en/latest/examples/index_structs/struct_indices/SQLIndexDemo.html
	- SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¯¾ã—ã¦ã€RAGã‚’è¡Œã†Retriverã«ã¤ã„ã¦ã€å‹•ã„ãŸãã€å½¹ã«ç«‹ã¤ãã€‚
- kaggle LLMã‚³ãƒ³ãƒšã€€ä¸Šä½è§£æ³•ã¾ã¨ã‚
	- https://zenn.dev/yume_neko/articles/7347ba6b081e93
	- ç§‘å­¦åˆ†é‡ã®5æŠå•é¡Œã‚’è§£ãLLMã®ç²¾åº¦ã‚’è¦å‰‡ã‚³ãƒ³ãƒšã®ã¹ã‚¹ãƒ—ãƒ©
	- ä»Šå›ã®ã‚³ãƒ³ãƒšã§ä¸Šä½ã«è¡Œãã«ã¯RetrievalãŒæœ€ã‚‚ã‚­ãƒ¼ã ã£ãŸã‚ˆã†ã«æ€ã„ã¾ã™ã€‚ã‚„ã¯ã‚Šæ­£è§£æƒ…å ±ã‚’ç›´æ¥å‚ç…§ã§ãã‚‹ã®ã§ã€contextã‚’ã‚ˆã‚Šè‰¯ãã™ã‚‹ã“ã¨ãŒé‡è¦ã ã£ãŸã®ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã™ã€‚
- llama2ã®pretrainingã‚’è©¦ã™
	- https://zenn.dev/if001/articles/6c507e15cd958b
	- å°ã•ã„ã‚µã‚¤ã‚ºã®llama2ã‚’æ—¥æœ¬èªã§pre_trainingã—ã¦ã¿ã¾ã™
	- pre_trainingã‹ã‚‰huggingfaceã¸ã®uploadã¾ã§ã‚’è¡Œã£ã¦ã¿ã¾ã—ãŸã€‚
	- å°ã•ã„ã‚µã‚¤ã‚ºã§ã‚ã‚Œã°google colabã§å­¦ç¿’ã§ãã‚‹
- llm-jp-13b-v1.0-gguf
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-gguf
	- llm-jpã•ã‚“ãŒå…¬é–‹ã—ã¦ã„ã‚‹llm-jp-13b-v1.0ã®ggufãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¤‰æ›ç‰ˆ
	- ãƒ–ãƒ©ãƒ³ãƒã‚‰ã—ã„ã€LLama.cppãŒã€ãªã‚“ã‹ã®å¤‰æ›´ã‚’è¡Œã†ã¨ggufãŒå‹•ã‹ãªããªã‚‹ã‚‰ã—ã„ã€æ€–ã£

## 10/16

RAGã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½å‘ä¸Šã¯ä¾ç„¶ã‚‚ã‚Šã‚ãŒã£ã¦ã„ã‚‹ã€‚Stanfordã®DSpyã€ã©ã†ã‚‚LLMã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ©ç”¨ã‚’åˆ¥ã®æ¬¡å…ƒã«å¼•ãä¸Šã’ã‚‹ç”»æœŸçš„ãªé–‹ç™ºã®ã‚ˆã†ã«è¦‹ãˆã‚‹ãŒè¿½ã„ã¤ã‘ãªã„ã€‚RAGã¨Finetuningã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸ŠãŒã„ã¾ã¾ã§æŠœã‘ã¦ã„ãŸã¨ã¯ã€‚LLMã®å¿ƒã®ç†è«–(ToM)ã«ã¤ã„ã¦ã®è«–æ–‡ã§ã¯ã€ä»–äººã®å¿ƒã®çŠ¶æ…‹ã®æ¨å®šã¨ã„ã†ã®ãŒè‚ãªã®ã‹ã€‚zephyr-7b-alphaã¨ã‹ã€Japanese StableLM Instruct Alpha v2 ã¨ã‹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§ä½¿ã„ã‚‚ã®ã«ãªã‚‹LLMã‚‚ã©ã‚“ã©ã‚“å‡ºã¦ããŸã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰AIã®ã€State of AI Report 2023ã€ Kaggleã®AI Report 2023ã€ãã‚Œãã‚Œã®ç«‹å ´ã§æœ€æ–°ã®AIã‚’å–ã‚Šå·»ãæ§˜ã€…ãªè¦–ç‚¹ã‚’ã¾ã¨ã‚ã¦ãã‚Œã¦ã„ã‚‹ã€‚ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼ï¼ˆé¡æ¨ï¼‰ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚«ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã€ã¯ã€äººé–“ã®æ‰‹é–“ã‚’çœã‘ã‚‹ã‹ï¼Ÿçµ„ã¿è¾¼ã¿(embeding)ã®é•ã„ã«ã‚ˆã‚‹RAGæ€§èƒ½ã®é•ã„ã®æ¤œè¨¼ã‹ã‚‰ã€ã‚„ã£ã±e5(intfloat/multilingual-e5-large)ãŒå½“é¢æœ€å¼·ãªã®ã‹ï¼ŸPFNã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ç”Ÿã®æˆæœãªã©ãŒã„ãã¤ã‹å…¬é–‹ã€‚ãã‚Œã«ã—ã¦ã‚‚PFNã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ç”Ÿã¤ã‚ˆã¤ã‚ˆã ã‚ã†ã€ã¡ã‚‡ã£ã¨ã†ã‚‰ã‚„ã¾ã—ã„ã€‚DeepMindã®Yasunagaã•ã‚“ã‚„ã‚¨ã‚¸ãƒ³ãƒãƒ©å¤§å­¦ã®Matsubaraã•ã‚“ãªã©ã®æ—¥æœ¬äººã®æ´»èºã‚‚ã¡ã‚‰ã»ã‚‰ã€‚


- Large Language Models (in 2023)
	- https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0
	- OpenAIã®Hyung Won Chungã•ã‚“ã«ã‚ˆã‚‹LLMã®ç¾çŠ¶ã‚’ã¾ã¨ã‚ãŸã‚¹ãƒ©ã‚¤ãƒ‰
	- The biggest progress in the past 10 years (or even more) can be summarized as
		- Create weaker inductive biases and scale up
		- Do not teach machines how we think we think. Let it learn in a machineâ€™s way
- Masking PII Data in RAG Pipeline
	- https://betterprogramming.pub/masking-pii-data-in-rag-pipeline-326d2d330336
	- PII(Personal Identification Information)ã‚’ãƒã‚¹ã‚­ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’ã€RAGã«ãŠã„ã¦è¡Œã†æ–¹æ³•
	-  LlamaIndexã® NERPIINodePostprocessorã‚’æ´»ç”¨ã™ã‚‹ã®ãŒã¿ã
- Jerryã‚ˆã‚Šã€RAGã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½å‘ä¸Šã«é–¢ã™ã‚‹ã€æ§˜ã€…ãªæ‰‹æ³•ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯é›†
	- Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex
		- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5
	- Building Performant RAG Applications for Production
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/production_rag.html
	- Multi-Document Agents
		- https://docs.llamaindex.ai/en/stable/examples/agent/multi_document_agents.html
	- Finetuning
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/finetuning.html
- Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models
	- https://arxiv.org/abs/2310.04406
	- Substantially improving over the existing prompting methods such as Reflexion, e.g., 68.1% -> 86.9% on HumanEval with GPT-3.5
- Ida Momennejad et al., "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval"
	- https://arxiv.org/abs/2309.15129
	- äººé–“ã®æ¸¬å®šæ³•ã¨ä¼¼ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§LLMã®èªçŸ¥æ©Ÿèƒ½ã‚’èª¿æŸ»ã—ãŸè«–æ–‡
	- LLMã®ã€ŒèªçŸ¥ãƒãƒƒãƒ—ã€ã¨ã€Œè¨ˆç”»èƒ½åŠ›ã€ã‚’è©•ä¾¡ã€‚
		- èªçŸ¥ãƒãƒƒãƒ—ï¼šå¤–éƒ¨ç’°å¢ƒã‚’å†…éƒ¨ã«è¡¨ç¾ã™ã‚‹æ©Ÿèƒ½ 
		- è¨ˆç”»èƒ½åŠ›ï¼šç›®æ¨™ã«å‘ã‹ã£ã¦è¨ˆç”»ã‚’ç«‹ã¦ã¦é‚è¡Œã™ã‚‹èƒ½åŠ›
	- GPT-3.5ã€GPT-4ã€Bardã€LLaMA-13Bãªã©
	- çµæœ
		- â‘  èªçŸ¥ãƒãƒƒãƒ—ã®ç†è§£ã‚„è¨ˆç”»èƒ½åŠ›ã¯ã€Œç®±ã‹ã‚‰å‡ºã—ã¦ã™ãã«ã€ã¯æŒã£ã¦ã„ãªã„ 
		- â‘¡ èªçŸ¥ãƒãƒƒãƒ—ã®æ¬ å¦‚ãŒç†ç”±ã§è¨ˆç”»ã‚¿ã‚¹ã‚¯ã«å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ 
		- â‘¢ æ–°ã—ã„è©•ä¾¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ï¼ˆCogEvalï¼‰ã¯æœ‰æœ›ã§ã‚ã‚‹ 
		- â‘£ LLMã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¯å·¥å¤«ã®ä½™åœ°ãŒã‚ã‚‹ 
		- â‘¤ LLMã®èªçŸ¥æ©Ÿèƒ½ã‚’å‘ä¸Šã•ã›ã‚‹ã«ã¯ã€ãƒ¡ãƒ¢ãƒªï¼ˆè¨˜æ†¶å®¹é‡ï¼‰ã®æ‹¡å¼µãªã©ãŒæœ‰åŠ¹
- FireAct: Toward Language Agent Fine-tuning
	- https://fireact-agent.github.io/
	- LLM Agentã¨Fintuningã®åˆã‚ã›æŠ€ã«ã¤ã„ã¦ã®æ¤œè¨¼ã€ReActã®æ€§èƒ½ã‚’fine-tuningã§å‘ä¸Šã§ããŸ
	- FireAct is a novel way to finetune LMs w/ agent trajectories of a mix of tasks & prompting methods.
	- Fine-tuning >> Prompting:
		- Notably, small LMs benefit most --- Llama2-7B improves 77% after fine-tuning!
- Pei Zhou et al., "How FaR Are Large Language Models From Agents with Theory-of-Mind?"
	- https://arxiv.org/abs/2310.03051
	- LLMã®ã€Œå¿ƒã®ç†è«–(ToM:Theory of Mind)ã€ã«ãŠã‘ã‚‹èƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Thinking for Doing (T4D)ã€
		- â‘  ä»–è€…ã®å¿ƒã®çŠ¶æ…‹ï¼ˆä¿¡å¿µã€é¡˜æœ›ã€æ„å›³ãªã©ï¼‰ã«ã¤ã„ã¦ã©ã‚Œã ã‘åŠ¹æœçš„ã«æ¨è«–ã§ãã‚‹ã‹
		- â‘¡ æ¨è«–ã—ãŸä¸Šã§ã„ã‹ã«è¡Œå‹•ã«ç§»ã›ã‚‹ã‹
	- å¾“æ¥ã®å¿ƒç†å­¦çš„ãƒ†ã‚¹ãƒˆã§ã¯LLMã®ToMèƒ½åŠ›ã®è©•ä¾¡ã¯ååˆ†ã«ã¯å‡ºæ¥ãªã„ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- ã€ŒForesee and Reflect (FaR)ã€ã¨ã„ã†æ–°ã—ã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
		- â‘  å°†æ¥ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’äºˆæ¸¬ï¼ˆForeseeï¼‰ 
		- â‘¡ ãã‚Œã«å¯¾ã™ã‚‹è¡Œå‹•ã‚’è€ƒæ…®ï¼ˆReflectï¼‰
	- ã€ŒFaRã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨è©•ä¾¡ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€ŒThinking for Doing (T4D)ã€ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã£ã¦ã€åŠ¹ç‡çš„ã«LLMã®ToMèƒ½åŠ›ã‚’è©•ä¾¡ã™ã‚‹ã“ã¨ãŒã§ãã‚‹
- 7 Query Strategies for Navigating Knowledge Graphs With NebulaGraph and LlamaIndex
	- https://www.nebula-graph.io/posts/Knowledge-Graph-and-LlamaIndex
	- NebulaGraph ã‚’ä½¿ã£ã¦ã‚°ãƒ©ãƒ•æ§‹é€ ã«å¯¾ã™ã‚‹ã€Q&Aã‚’å®Ÿç¾ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ via Llamaindex
- Stanfordã®DSpyã‚’ç”¨ã„ã‚‹ã“ã¨ã«ã‚ˆã‚‹ã€Q&Aã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒç°¡å˜ã«ãªã‚‹ï¼Ÿ
	- https://x.com/lateinteraction/status/1712135660797317577?s=20
- Kaggleã®AI Report 2023
	- https://www.kaggle.com/AI-Report-2023
	- ã“ã‚Œã¯AIã®ç¾çŠ¶ã«é–¢ã™ã‚‹ã‚¨ãƒƒã‚»ã‚¤ã‚³ãƒ³ãƒšã®çµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã€æœ€æ–°ã®AIã‚’å–ã‚Šå·»ãæ§˜ã€…ãªè¦–ç‚¹ã‹ã‚‰ã®è¦‹æ–¹ãŒã‚ã‹ã‚‹ã€‚
- HuggingFaceã«ãŠã‘ã‚‹LLMè©•ä¾¡ã§ã€zephyr-7b-alphaãŒChatLlama 70Bã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ã ã—ãŸã‚‰ã—ã„ã®ã§llamaindexã§ç¢ºã‹ã‚ã¦ã¿ãŸ
	- https://colab.research.google.com/drive/16Ygf2IyGNkb725ZqtRmFQjwWBuzFX_kl?usp=sharing#scrollTo=lMNaHDzPM68f
	- We found that it is the ONLY open 7B model atm that does well on advanced RAG/agentic task
- DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation
	- https://huggingface.co/papers/2309.16653
	- ã“ã“ã§ï¼“Dãƒ¢ãƒ‡ãƒ«ä½œæˆã‚’è©¦ã›ã‚‹ã€ãªã‚“ã‹ã™ã”ã„ãã€‚
		- https://huggingface.co/spaces/jiawei011/dreamgaussian
-  Multimodality and Large Multimodal Models (LMMs)
	- https://huyenchip.com/2023/10/10/multimodal.html
	- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤ã€‚é‡è¦è«–æ–‡ã¨ã—ã¦CLIPã¨Flamingoã‚’è§£èª¬ã—ãŸä¸Šã§ã€ä»Šå¾Œã®æ–¹å‘æ€§ã¨ã—ã¦ä»–ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®è¿½åŠ ã€å‡ºåŠ›ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŒ–ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ•´å‚™ãªã©ã‚’æŒ™ã’ã¦ã„ã‚‹
- LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression
	- https://arxiv.org/abs/2310.06839
	- Gains a performance boost of up to 17.1% on NaturalQuestions over the original prompt with ~4x fewer tokens
- MatGPT: A Vane of Materials Informatics from Past, Present, to Future
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202306733?af=R
	- **GPT AI**ã®å‡ºç¾ã¯ã€ç§‘å­¦ç ”ç©¶åˆ†é‡ãŒã€Œãƒ‡ãƒ¼ã‚¿ã€ã‚’åŸºæœ¬è¦ç´ ã¨ã—ã€ã€Œã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  + è¨ˆç®—èƒ½åŠ›ã€ã‚’æ ¸å¿ƒç”Ÿç”£åŠ›ã¨ã™ã‚‹çŸ¥èƒ½æ–‡æ˜æ™‚ä»£ã«å…¥ã£ãŸã“ã¨ã‚’ç¤ºã—ã¦ã„ã‚‹ã€‚
	- äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€æŒ‡å‘æ€§è¨­è¨ˆãƒ¢ãƒ‡ãƒ«ã€å”èª¿å­¦ç¿’ã€å®Ÿé¨“ãƒ­ãƒœãƒƒãƒˆãªã©
- PFNã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ç™ºè¡¨ï¼š éºä¼â¼¦ã«é–¢ã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’åˆ©â½¤ã—ãŸãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º
	- https://tech.preferred.jp/ja/blog/model-learning-using-gene-graph/
	- RNAã‹ã‚‰Proteinã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã¯ã€å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒé™ã‚‰ã‚Œã€ã‹ã¤ä½¿ç”¨ã§ãã‚‹ç‰¹å¾´é‡ãŒå°‘ãªã„çŠ¶æ³ã«ãŠã„ã¦ã¯ã€äºˆæ¸¬å¯¾è±¡ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã®åˆ¶å¾¡ã«é–¢ä¸ã™ã‚‹ç‰¹å®šã®ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’ç”¨ã„ã‚‹ã“ã¨ã§æ€§èƒ½ã®æ”¹å–„ãŒèªã‚ã‚‰ã‚Œã¾ã—ãŸã€‚
- ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒOpenCaml2ã‚’é–‹ç™ºä¸­ã‚‰ã—ã„
	- https://aws.amazon.com/jp/blogs/news/open-calm-and-openai-chatgpt-accuracy-on-jaqket-experiment-in-amazon-sagemaker/
- RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation
	- https://arxiv.org/abs/2310.04408
	- LLMã§ã®RAGã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã«ã€2ã¤ã®åœ§ç¸®å™¨(é‡è¦éƒ¨åˆ†æŠ½å‡ºãƒ»è¤‡æ•°æ–‡æ›¸è¦ç´„)ã‚’ä½¿ã†RECOMPæ³•ã®ææ¡ˆã€‚å„åœ§ç¸®å™¨ã¯å­¦ç¿’ã•ã›ã‚‹å¿…è¦æœ‰
- æ©Ÿæ¢°å­¦ç¿’æ³¢å‹•é–¢æ•°ï¼Ÿï¼Ÿ
	- https://www.nature.com/articles/s41524-023-01130-4
	- å¾“æ¥ã¯1ç¨®é¡ã®æ§‹é€ ã—ã‹è¨“ç·´ã«ä½¿ãˆã¾ã›ã‚“ã§ã—ãŸãŒã€ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚’å¯¾ç§°æ€§ã«åŸºã¥ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è¨˜è¿°ã™ã‚‹ã“ã¨ã§æ§˜ã€…ãªæ§‹é€ ã‚’è¨“ç·´ã§ãã€è»¢ä½ãŒã‚ã‚‹ç´„5000åŸå­ã‚»ãƒ«ã®é›»å­çŠ¶æ…‹äºˆæ¸¬ã‚’å®Ÿç¾ã—ãŸ
- Google Colab ã§ Japanese StableLM Instruct Alpha v2 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n0e463dbbce11?sub_rt=share_sb
	- ã€ŒStability AI Japanã€ãŒé–‹ç™ºã—ãŸ7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªLLM
	- å•†ç”¨åˆ©ç”¨ã‚’åˆ¶é™ã—ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã¿ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€åŒç­‰ãƒ¬ãƒ™ãƒ«ã®æ€§èƒ½ã‚’æŒã¤**å•†ç”¨åˆ©ç”¨ãŒå¯èƒ½**
	- Colabç„¡æ–™æ (T4)ã§å‹•ä½œã™ã‚‹æ¨¡æ§˜
- StanfordAIã«ã‚ˆã‚‹ã€ State of AI Report 2023
	- https://www.stateof.ai/2023-report-launch
	- OpenAIã®**GPT-4**ã¯ã€ã™ã¹ã¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚„äººé–“å‘ã‘ã®è©¦é¨“ã«ãŠã„ã¦ä»–ã®LLMã‚’å‡Œé§•ã—ã¦ã„ã‚‹ã€‚
	- Meta AIã¯ã‚ªãƒ¼ãƒ—ãƒ³ï¼ˆãªï¼‰AIã®ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã¨ã—ã¦ç™»å ´ã—ã€LLaMaãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚’æœ€ã‚‚å¼·åŠ›ãªå…¬é–‹ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªOpenAIä»£æ›¿å“ã¨ãªã£ã¦ã„ã‚‹
	- LLMã‚„æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯ã€ç‰¹ã«ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¨ãƒ³ã‚¹åˆ†é‡ã§å®Ÿç”¨çš„ãªãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’ã‚‚ãŸã‚‰ã—ã¦ãŠ
	- ç”ŸæˆAIãŒã€ä½è¿·ã—ã¦ã„ã‚‹ã€ãƒ†ãƒƒã‚¯ç•Œéšˆã®VCã‚’æ•‘ã†ã€‚
	- å®‰å…¨æ€§ã¯AIç ”ç©¶ç•Œã§ä¸­å¿ƒçš„ãªãƒ†ãƒ¼ãƒã¨ãªã‚Šã€ä¸–ç•Œä¸­ã®æ”¿åºœã‚„è¦åˆ¶æ©Ÿé–¢ãŒå¯¾ç­–ã‚’è¬›ã˜å§‹ã‚ãŸã€‚
	- æ¨™æº–çš„ãªLLMã¯é ‘å¥æ€§ã«å•é¡ŒãŒã‚ã‚Šã€æœ€å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ãŒå›°é›£ã«ãªã£ã¦ã„ã‚‹
- Michihiro Yasunaga et al., "Large Language Models as Analogical Reasoners"
	- https://arxiv.org/abs/2310.01714
	- äººé–“ã®ã€Œéå»ã®é¡ä¼¼äº‹ä¾‹ã€ã¨ã€Œè‡ªã‚‰ã®çŸ¥è¦‹ã€ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«å€£ã£ãŸã€LLMã®å„ªã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
	- LLMã®æ¨è«–èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹CoTã¯æœ‰ç”¨ã§ã™ãŒã€æ‰‹é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ æ‰‹å‹•ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæ¥­ã‚’å°‘ã—ã§ã‚‚è»½æ¸›ã™ã‚‹ã“ã¨ãŒæ±‚ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ 
	- ãã“ã§ç ”ç©¶è€…ã‚‰ã¯ã€äººé–“ã®ã‚ˆã†ã«è‡ªå‹•çš„ã«çŸ¥è­˜ã‚’ç”Ÿæˆã™ã‚‹ã€Œã‚¢ãƒŠãƒ­ã‚¸ã‚«ãƒ«ãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã€ã‚’ç™ºæ˜ã—ã¾ã—ãŸã€‚
- Hamiltonian Dynamics of Bayesian Inference Formalised by Arc Hamiltonian Systems
	- https://arxiv.org/pdf/2310.07680.pdf
	- ã‚¨ã‚¸ãƒ³ãƒãƒ©å¤§å­¦ã®æ¾åŸã•ã‚“ã®è«–æ–‡
	- infinite-dimensional Hamiltonian system behind Bayesian inference.
	- ãƒ™ã‚¤ã‚ºæ¨è«–ã®è£ã«ã€ç„¡é™æ¬¡å…ƒã®ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã‚·ã‚¹ãƒ†ãƒ ãŒã‚ã‚‹ã¨ã„ã†ã€ã€
- Zijun Liu et al., "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization"
	- https://arxiv.org/abs/2310.02170
	- è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å”åŠ›ã—ã¦ä»•äº‹ã‚’é–‹å§‹ã•ã›ã€ã‚¿ã‚¹ã‚¯ã®é€²è¡Œã«å¿œã˜ã¦é‡è¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–æ¨é¸æŠã™ã‚‹ã€Dynamic LLM-Agent Networkï¼ˆDyLANï¼‰ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
	- ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦å‹•çš„ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é¸æŠã™ã‚‹æ–¹å¼ã‚’è€ƒãˆã¾ã—ãŸã€‚
- LangChain ã‚’ä½¿ã£ãŸ RAG ã«ãŠã‘ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
	- https://note.com/alexweberk/n/ncccfdab3f4bb
	- Wikipedia è¨˜äº‹ã‚’ LangChain ã® CharacterTextSplitter ã‚’ä½¿ã£ã¦ã€ï¼”ç¨®é¡ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€RAG ã«ã‚ˆã‚‹è³ªå•å¿œç­”ã‚’è©¦è¡Œ
	- `intfloat/multilingual-e5-large` >= `pkshatech/GLuCoSE-base-jap` > `cl-nagoya/sup-simcse-ja-large` >= `openai/text-embedding-ada-002` ã¨ã„ã†ã‚ˆã†ãªæ„Ÿè§¦
	- 4ã¤ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸRAGã‚’è©¦ã—ã¦ã¿ã¾ã—ãŸ: 
		- intfloat/multilingual-e5-large 
		- cl-nagoya/sup-simcse-ja-large 
		- pkshatech/GLuCoSE-base-ja 
		- openai/text-embedding-ada-002
- OpenAI gpt-3.5-turbo ã¨ gpt-3.5-turbo-instruct ãƒ¢ãƒ‡ãƒ«ã®é•ã„ã«ã¤ã„ã¦
	- https://corp.langcore.org/media/chatgpt-instruct
	- gpt-3.5-turbo ãƒ¢ãƒ‡ãƒ«ã¯ä¼šè©±ã«ç§€ã§ã¦ã„ã‚‹ã®ã§å¯¾è©±ã‚’ã•ã›ã‚‹ã®ã§ã‚ã‚Œã°ã“ã¡ã‚‰ã‚’ä½¿ã†æ–¹ãŒã‚ˆã„ã§ã™ã€‚
	- ä¼šè©±ä»¥å¤–ã®ã‚¿ã‚¹ã‚¯ã®å ´åˆã ã¨**ä¸€å•ä¸€ç­”ã®ã‚ˆã†ãªå˜ç´”ãªèª²é¡Œã‚’è§£ãã‚±ãƒ¼ã‚¹ã§ã¯ gpt-3.5-turbo-instruct ã®æ–¹ãŒæœŸå¾…ã™ã‚‹å‡ºåŠ›ã«ãªã‚‹å¯èƒ½æ€§**ãŒã‚ã‚Šã¾ã™ã€‚
- Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction
	- https://arxiv.org/abs/2310.05627
	- IJCAIã§LLM(chatGPT)ä½¿ã£ãŸæ ªä¾¡ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã®è«–æ–‡
	- LLMã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ã¨æ ªå¼ã®ç‰¹å¾´ã‚’åŒã˜semantic spaceã§é…ç½®ã•ã›ã‚‹å¼·åŒ–å­¦ç¿’ã®æ çµ„ã¿ã‚’å°å…¥ã—ã¦ã„ã‚‹ã€‚
- Zhiyu Chen et al., "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting"
	- https://arxiv.org/abs/2310.07146
	- GPT-4ã‚’ã‚»ãƒ©ãƒ”ã‚¹ãƒˆã¨ã—ã¦å®Ÿè¡Œã—ã€äººã€…ã®ã€ŒèªçŸ¥ã®æ­ªã¿ã€ã‚’è¨ºæ–­ã•ã›ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€Diagnosis of Thought (DoT)ã€
	- â‘  DoTã¯ã€ã€ŒèªçŸ¥ã®æ­ªã¿ã€è©•ä¾¡ã¨åˆ†é¡ã§é«˜æ€§èƒ½ã‚’ç¤ºã—ãŸ 
	- â‘¡ GPT-4ã¯ã€ã€ŒèªçŸ¥ã®æ­ªã¿ã€åˆ†é¡ã§ç‰¹ã«é«˜ã„æ€§èƒ½ã‚’ç¤ºã—ãŸ 
	- â‘¢ å°‚é–€å®¶ã«ã‚ˆã£ã¦GPT-4ã«ã‚ˆã‚‹æœ¬è¨ºæ–­æ–¹æ³•ã¯ã€ŒåŒ…æ‹¬çš„ã§ã‚ã‚‹ã€ã¨è©•ä¾¡ã•ã‚ŒãŸï¼ˆ84.5%ï¼‰
-  Large Language Models can Learn Rules
	- LLMãŒãƒ«ãƒ¼ãƒ«ã‚’å­¦ç¿’ã§ãã‚‹ï¼Ÿ
	- https://arxiv.org/abs/2310.07064
	- LLMs can learn (sometimes uncommon) rules with 2 stages: (1) induction: generate and verify rules from exemplars; (2) deduction: utilize the rule library for new problems. 11-27% gain on reasoning tasks that require rule learning.

## 10/10

function callã‚’å«ã‚€LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’OpenAIãŒå°å…¥ã•ã‚ŒãŸã‚Šã€LLMã®RAGã«å¯¾ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã¤ã„ã¦ã®è€ƒå¯ŸãŒã‚ã£ãŸã‚Šã¨ã€æ€§èƒ½é¢ã§ã®è©•ä¾¡ã‚’å«ã‚RAGé–¢ä¿‚ã¯æˆç†Ÿã—ã¦ããŸæ„Ÿã˜ã€‚LLMãŒã©ã‚Œã ã‘è«–ç†çš„ã‹ã¨ã„ã†æ¤œè¨¼ã‚‚ã€Œé€†è»¢ã®å‘ªã„ã€ã‚’ä¾‹ã«è¡Œã‚ã‚Œã¦ã„ã‚‹ãŒã€LLMãŒã€Œç‰©äº‹ãŒã©ã®ã‚ˆã†ã«ä½ç½®ã¥ã‘ã‚‰ã‚Œã€æ™‚é–“ãŒã©ã®ã‚ˆã†ã«é€²è¡Œã™ã‚‹ã‹ã‚’ç†è§£ã€ã—ã¦ã„ã‚‹ã¨ã„ã†å®Ÿé¨“ã¯ã“ã‚Œã‹ã‚‰ã®LLMã‚’ç”¨ã„ãŸè¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®é–‹ç™ºã«å¼¾ã¿ã§ã‚‚ã‚ã‚‹ã€‚ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã§ã¯ã€æ—©é€ŸGPT-4Vã«å¯¾æŠ—ã™ã‚‹OSSã§ã‚ã‚‹LLaVAãŒç™»å ´ã—ãŸã€LLaVA-1.5ã¯ã™ã§ã«è©¦ã›ã‚‹æ¨¡æ§˜ã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ãŒAIã«é–¢ã™ã‚‹å¤šè§’çš„ãªãƒ‡ãƒ¼ã‚¿ã®ãƒ¬ãƒãƒ¼ãƒˆã™ã°ã‚‰ã—ã„ã€‚OpenAIã¯ã€GPT-4Vã«å¼•ãç¶šãã€DALLÂ·E 3ã«å¯¾ã™ã‚‹å“è³ªã‚«ãƒ¼ãƒ‰(System Card)ã‚’å…¬é–‹ã€å®‰å…¨ãªç”»åƒç”Ÿæˆã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã€‚MSã®DeepSpeedãƒãƒ¼ãƒ ã®ç§‘å­¦çš„åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã£ã¦ã‚‚é ‘å¼µã£ã¦ã‚‹ãªã€æ°—è±¡äºˆæƒ³ã«ä½¿ãˆãã†ã€‚Microsoftã®H100 GPUå¯¾æŠ—ãƒãƒƒãƒ—ã®ATHENAã€æœ¬å½“ã«ã‚„ã‚‹æ°—ãŒã‚ã‚‹ã®ã‹ï¼Ÿ


- ã€é€†è»¢ã®å‘ªã„ã€:ã€ŒAã¯Bã§ã‚ã‚‹ã€ã¨å­¦ç¿’ã—ãŸLLMã¯ã€ã€ŒBã¯Aã§ã‚ã‚‹ã€ã¨å­¦ç¿’ã—ã¥ã‚‰ããªã‚‹ã€‚
	- https://arxiv.org/abs/2309.12288
	- LLMãŒã©ã‚Œã ã‘è«–ç†çš„ã‹ï¼Ÿã¨ã„ã†å•ã„ã«å¯¾ã—ã¦ã€LLMã®è‹¦æ‰‹ãªç‚¹ã‚’æŒ™ã’ã‚‹
	- ã€é€†è»¢ã®å‘ªã„ã€LLMã¯ã€çŸ¥è­˜ã‚’æ§‹é€ åŒ–ã—ã€â€å¸°çµã‚’ä¸»èªã«ã—ã¦åŒã˜ã“ã¨ã‚’è¨€ã†â€ã®ãŒè‡ªå‹•çš„ã«ã¯ã§ããªã„
	- LLMã®ã€Œé€†è»¢ã®å‘ªã„ã€ã‚’èªè­˜ã—ãŸä¸Šã§ã™ã¹ãã“ã¨ã®è€ƒå¯Ÿ
-  Knowledge Graph Construction w/ WikiData Filtering  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/knowledge_graph2.html
	- REBELã‚’ç”¨ã„ã¦ã€æ–‡ç« ã‚ã‹ã‚‰çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã™ã‚‹æ–¹æ³•ã«ãŠã„ã¦ã€Wikipediaã‚’ãƒ•ã‚£ãƒ«ã‚¿ã¨ã—ã¦ç”¨ã„ã‚‹ã“ã¨ã§ã€æ˜¥å¸‚ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘ãˆã‚Œã‚‹
- Ronen Eldan et al., "Who's Harry Potter? Approximate Unlearning in LLMs"
	- https://arxiv.org/abs/2310.02238
	- LLMã®è¨˜æ†¶ã®ä¸€éƒ¨ã‚’æ„å›³çš„ã«å¿˜å´ã•ã›ã‚‹
	- ç´„1GPUæ™‚é–“ã®å¾®èª¿æ•´ã§ã€ãƒ¢ãƒ‡ãƒ«ã¯Harry Potteré–¢é€£ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã¾ãŸã¯å›æƒ³ã™ã‚‹èƒ½åŠ›ã‚’åŠ¹æœçš„ã«æ¶ˆå»
-  Fine-tuning with Retrieval Augmentation  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_retrieval_aug.html
	- https://arxiv.org/abs/2310.01352
	- gpt-4ã¨DatasetGeneratorã‚’ã¤ã‹ã£ã¦ã€æ­£è§£qaãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
	- gpt-3.5-turboã‚’æ­£è§£qaãƒ‡ãƒ¼ã‚¿ã‚’ã¤ã‹ã¦ã€RAGã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
	- çµæœcorrectnesã¯ã€ç´ ã®LLMï¼3.2ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¾Œï¼3.65ã€
- éä¾µè¥²ã®è„³æ´»å‹•ã‚»ãƒ³ã‚·ãƒ³ã‚°ã«ã‚ˆã‚‹ã€éŸ³å£°ã®ãƒ‡ãƒ¼ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
	- Decoding speech from non-invasive recordings of brain activity
	- https://huggingface.co/papers/2208.12266
	- contrastive learningã¨ã„ã†ã®ã‚’ã¤ã‹ã£ã¦ã€è„³æ³¢ã‹ã‚‰ã‚¹ãƒ”ãƒ¼ãƒã‚’æ¨å®š
- OpenAIãŒã€function calling fine-tuningæ©Ÿèƒ½ã‚’æ–°ãŸã«è¿½åŠ ã€€by llamaindex
	-  Fine Tuning with Function Calling
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/openai_fine_tuning_functions.html
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/openai_fine_tuning_functions.ipynb
	- æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã‚’LLMã‹ã‚‰å¾—ãŸã„ã¨ãã«ã€functio/n callã‚’ã¤ã‹ã†ã‚‰ã—ã„ãŒã€ã“ã®æ©Ÿèƒ½ã‚’fine-tuneã™ã‚‹ã“ã¨ãŒã§ãã‚‹
- LLMã¯ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚’ã‚‚ã£ã¦ã„ã‚‹ã‹ï¼Ÿ
	-  Language Models Represent Space and Time
	- https://arxiv.org/abs/2310.02207
	- LLMã¯ã‚·ãƒ³ãƒ—ãƒ«ã«çµ±è¨ˆï¼ˆç¢ºç‡ï¼‰ã‹ã‚‰æ¬¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã®ã§ã¯ãªãã€ã€Œç‰©äº‹ãŒã©ã®ã‚ˆã†ã«ä½ç½®ã¥ã‘ã‚‰ã‚Œã€æ™‚é–“ãŒã©ã®ã‚ˆã†ã«é€²è¡Œã™ã‚‹ã‹ã‚’ç†è§£ã€ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚ ã¤ã¾ã‚Šã€LLMãŒ"ä¸–ç•Œãƒ¢ãƒ‡ãƒ«"ã‚’å½¢æˆã—ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã¨ã„ã†å ±å‘Š
	- ä¸–ç•Œã€ç±³å›½ã€NYCã®åœ°åã€æ­´å²çš„äººç‰©ã€èŠ¸è¡“ä½œå“ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ©ã‚¤ãƒ³ãªã©ã‚’å«ã‚€6ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨æ„
	- ç©ºé–“ã¨æ™‚é–“ã®ç†è§£åº¦ã¯ã€LLMã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹éšå±¤ã‚’åŠåˆ†ã¾ã§é€²ã‚“ã ã¨ã“ã‚ã§å“è³ªãŒå‘ä¸Šã—ã€ãã®ã‚ã¨é™ç•Œç‚¹ã«é”ã™ã‚‹
	- LLMãŒã€Œä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã€ã‚’å½¢æˆã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã®ã§ã‚ã‚Œã°ã€LLMãŒã‚ˆã‚Šé«˜åº¦ãªèªçŸ¥ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã‚‹ã“ã¨ã«ç¹‹ãŒã‚Šã¾ã™ã€‚ ä¾‹ãˆã°è‡ªå‹•é‹è»¢è»Šã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã«LLMã‚’æ´»ç”¨ã™ã‚‹ã®ã¯å„ªã‚ŒãŸæˆ¦ç•¥ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- huggingface/transformers v4.34ã®æ›´æ–°ã¯ã‹ãªã‚Šagressive
	- https://github.com/huggingface/transformers/releases/tag/v4.34.0
	- tokenizerã®æŒ™å‹•ã‚’ç´°ã‹ãåˆ¶å¾¡ã—ã¦ã„ãŸäººãŸã¡ã«ã¨ã£ã¦ã¯ã†ã‚Œã—ã„ã‹ã‚‚
- ModuLoRA is the first method to finetune 3-bit LLMs
	- 3-bitã‚„2-bitã«é‡å­åŒ–ã—ãŸLLMã®è©±é¡Œã®è£ã«ã‚ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ModulLoRAãŒå…¬é–‹
	- https://browse.arxiv.org/pdf/2309.16119.pdf
- RETRIEVAL MEETS LONG CONTEXT LARGE LANGUAGE MODELS
	- https://arxiv.org/abs/2310.03025
	- NVIDIAã‚ˆã‚ŠRAGã¨Context Window (CW)ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒè«–æ–‡ã€‚4K CWã®LLMï¼‹RAGã¯ã€16K CWã®LLMã¨åŒç­‰ã€32K CWã®LLaMA2-70Bï¼‹RAGã¯é•·ã„Contextã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦GPT-3.5-turbo-16kã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨äº‹ã‚’å®Ÿè¨¼åˆ†æ 
- llama.cpp å˜ä½“ã§ LoRA ä½œã‚Œã‚‹æ©Ÿèƒ½ãŒè¿½åŠ 
	- https://github.com/ggerganov/llama.cpp/pull/2632
- Why you should build RAG from scratch - with Jerry Liu from LlamaIndex
	- LlamaIndexã®ä¸­ã®äººã«èãå›ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ³ã€RAGã€ReActã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚„ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç­‰ã€…ã«ã¤ã„ã¦JerryãŒã©ã†è€ƒãˆã¦ã‚‹ã‹è´ã‘ã‚‹ã€‚RAGã¯ãƒãƒƒã‚¯ã ã¨è¨€ã„åˆ‡ã£ã¦ã¦é¢ç™½ã„ã€‚
	- https://www.latent.space/p/llamaindex?utm_campaign=post&utm_medium=web
-  Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study
	- https://arxiv.org/abs/2307.08072
	- é‡å­åŒ–ã•ã‚ŒãŸLLMã«ã¤ã„ã¦ã€ä¸€èˆ¬çš„ã«LLMã§ç™ºç¾ã™ã‚‹ã¨ã•ã‚Œã¦ã„ã‚‹in-context learningã€chain-of-thought, instruction-followingã¨ã„ã£ãŸèƒ½åŠ›ãŒã©ã®ç¨‹åº¦ä¿ã¦ã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼ã—ãŸç ”ç©¶ã€‚çµæœã¨ã—ã¦4-bitã¾ã§ã®é‡å­åŒ–ã§ã‚ã‚Œã°æ€§èƒ½ã®åŠ£åŒ–ãŒè¦‹ã‚‰ã‚Œãªã„ã“ã¨ã‚’ç¢ºèª
- OpenAIã®Super aligment
	- https://openai.com/blog/introducing-superalignment
	- â€œSuperintelligence will be the most impactful technology humanity has ever invented.â€
	- Superintelligence "could lead to ... human extinction. ... We believe [superintelligence] could arrive this decade."
- æ—©é€ŸGPT-4Vã«å¯¾æŠ—ã™ã‚‹OSSã§ã‚ã‚‹LLaVAãŒç™»å ´
	-  LLaVA: Large Language and Vision Assistant
	- https://llava-vl.github.io/
	- Haotian Liu et al., "Improved Baselines with Visual Instruction Tuning"
	- https://arxiv.org/abs/2310.03744
	- ãŠè©¦ã—ã§ãã‚‹ã€https://llava.hliu.cc/
- How to build ChatGPT for your company data? by ABACUS AI
	- llama2ã‚’ä½¿ã†ã®ãŒè‰¯ã„ã¿ãŸã„ã€€
	- https://x.com/Saboo_Shubham_/status/1710505571072278932?s=20
- æ­£å‰‡åŒ–é …ä»˜ãç·šå½¢å›å¸°ã¯çœŸã®åå›å¸°ä¿‚æ•°ã‚’æ¨å®šã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿ
	- https://bob3.hatenablog.com/entry/2023/10/06/224133
	- æ­£å‰‡åŒ–é …ä»˜ãç·šå½¢å›å¸°ï¼ˆRidgeã€LASSOã€Elastic netï¼‰ã§çœŸã®åå›å¸°ä¿‚æ•°ã‚’æ¨å®šã§ãã‚‹ã®ã‹ï¼Ÿã‚’å®Ÿé¨“ã—ã¦ã¿ã¾ã—ãŸã€‚
- RAGã«ãŠã‘ã‚‹chankã‚µã‚¤ã‚ºã«ã¤ã„ã¦
	- https://docs.google.com/presentation/d/18Z7H3WSncPzLOTHKZAj36w0E7HSGY78VkDooSzvvySE/edit#slide=id.g286c47b4bb8_1_0
	- More chunks â‰  better (lost in the middle problems / context overflows)
	- Reranking retrieved chunks doesnâ€™t necessarily improve results, in fact can worsen them.
- Science Behind Why LLMs Can Easily Be Tricked And Are Predictably Gullible
	- https://x.com/bindureddy/status/1710504584496779675?s=20
	- while large language models exhibit impressive linguistic abilities, their lack of true understanding, combined with the intricacies of data-driven learning, makes them susceptible to errors and easy to fool.
- æ–°ã—ã„OSSã®embeddingãƒ¢ãƒ‡ãƒ«gte-tinyãŒç™»å ´ã€OpenAIã®text-embedding-ada-002ãªã¿ã®èƒ½åŠ›ã‚’ã‚‚ã¡ã¤ã¤ã€å°ã•ãã¦è»½ã„
	- https://huggingface.co/TaylorAI/gte-tiny/tree/main
- OpenAI, "DALLÂ·E 3 System Card"
	- https://openai.com/research/dall-e-3-system-card
	- DALLÂ·E 3ã§ã®å®‰å…¨å¯¾ç­–
	- OpenAIã¯ã€DALLÂ·E 3ã®è«–æ–‡ã‚’é€šã—ã¦ã€Œç”»åƒç”ŸæˆAIã®å®‰å…¨æ€§ã¯å‰é€²ã—ãŸã€ã“ã¨ã‚’å ±å‘Š
- Artificial Intelligence Index Report 2023
	- https://arxiv.org/abs/2310.03715
	- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ãŒAIã«é–¢ã™ã‚‹æŠ€è¡“ãƒ»æ³•å¾‹ãƒ»çµŒæ¸ˆãƒ»ç’°å¢ƒãƒ»ä¸–è«–ãªã©ã®å¤šè§’çš„ãªãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¦ã¾ã¨ã‚ãŸå ±å‘Šæ›¸ã€ŒAI index Report 2023ã€ã‚’arxivã«å…¬é–‹
- MSã®DeepSpeedãƒãƒ¼ãƒ ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç§‘å­¦å¿œç”¨ã‚’ç›®æŒ‡ã—ãŸDeepSpeed4Scienceãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
	- https://deepspeed4science.ai/
	- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed4science/japanese/README.md
	- ç§‘å­¦çš„åŸºç›¤ãƒ¢ãƒ‡ãƒ«(SFM)ã¨ã‚ˆã¶ã‚‰ã—ã„
	- ClimaXã¯ã€ã•ã¾ã–ã¾ãªæ°—è±¡ãŠã‚ˆã³æ°—å€™ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸæœ€åˆã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ã™
	- åˆ†å­å‹•åŠ›å­¦ã¨æ©Ÿæ¢°å­¦ç¿’å‹åŠ›å ´
	- å¤©æ°— from Microsoft Start
- Google Colabã«ã¤ã„ã«AIæ©Ÿèƒ½ãŒæ¥ã¦ã‚‹ï¼Ÿ
	- Proã«ã—ã‹æ¥ã¦ãªã„ã‚‚ã‚ˆã†ã€‚
- Best Practices for LLM Evaluation of RAG Applications A Case Study on the Databricks Documentation Bot
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- RAGï¼ˆRetrieval Augmented Genenerationï¼‰ã®è©•ä¾¡ã€ç‰¹ã«"LLMã‚’ä½¿ã£ãŸæ™‚ä»£è©•ä¾¡ã®è¦³ç‚¹"ã‹ã‚‰ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
- æ§˜ã€…ãªLLMãŒä½•ãŒã§ãã‚‹ã‹ã®æ¯”è¼ƒè¡¨ by llamaindex
	- https://docs.llamaindex.ai/en/latest/core_modules/model_modules/llms/root.html#llm-compatibility-tracking
	- ã¡ã‚‡ã£ã¨ã€llama2-7b-4bitãŒæ‚²ã—ã„çµæœã«ã€‚ã€‚
		- OpenAI models (gpt-3.5-turbo, gpt-3.5-turbo-instruct, gpt-4)
		-  Anthropic models (claude-2, Claude-instant-2)
		- llama2-chat-7b 4bit
		- Mistral-7b
- Microsoftã€Nvidia GPUä¾å­˜ã¸ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«ã¤ãªãŒã‚‹AIãƒãƒƒãƒ—ã‚’æ¥æœˆãƒ‡ãƒ“ãƒ¥ãƒ¼ã¸
	- https://texal.jp/2023/10/08/microsoft-is-developing-its-own-ai-chip-and-working-with-amd-to-stop-nvidias-monopoly/
	- ã€Œ**Athena**ã€ï¼‘ï¼‘æœˆã®é–‹ç™ºè€…ä¼šè­°ã§ç™ºè¡¨äºˆå®šï¼Ÿ
	- NVIDIAã®H100 GPUã¨åŒç­‰ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹


## 10/2

ä»Šé€±ã¯ã€ã„ã‚„ã€ä»Šé€±ã‚‚ã„ã‚ã„ã‚ã‚ã‚Šã™ãã¦ã€æ¶ˆåŒ–ã—ãã‚Œãªã„ã€‚GPT-4V(ision) ãƒ‡ãƒ“ãƒ¥ãƒ¼ã€ç”»åƒç†è§£ã¨ã‹ã€ã¤ã„ã«LLMãŒçœ¼ã‚’æŒã£ãŸï¼ˆã‚«ãƒ³ãƒ–ãƒªã‚¢ç´€ï¼‰ã€ã“ã‚Œã£ã¦AGIã®å‰è§¦ã‚Œï¼Ÿã€€GPT-4VåˆæœŸãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã¯ã€éœãŒé–¢ãƒ‘ãƒ¯ãƒã‚’å…¥åŠ›ã—ãŸã‚Šã€å¤©ä¸€ã®ãƒãƒ¼ã‚¯ã‚‚ã€Œä¾µå…¥ç¦æ­¢ã€æ¨™è­˜ã¨èª¤èªè­˜ã¯ã—ãªã„ã€ã‚µã‚¤ã‚¼ãƒªã‚¢ã®ã€Œé–“é•ãˆæ¢ã—ã€ã¯è‹¦æ‰‹ã€ã¨ã„ã†å ±å‘Šã‚‚ã€‚ChatGPTã«ã‚‚visionã‚„éŸ³å£°å¯¾è©±æ©Ÿèƒ½ãŒæ¥é€±ã‹ã‚‰ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã™ã‚‹(Plusä»¥ä¸Šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã€‚Amazonã¯ã€ç”ŸæˆAIã®Anthropicã«5900å„„å††å‡ºè³‡ã€‚QuoraãŒæä¾›ã™ã‚‹ [poe.com](http://poe.com) ã§è©¦ç”¨ã§ãã‚‹ã€‚Googleã®GPT-4è¶…ãˆã®Geminiã¯æ°´æ›œ(10/4)ã«ç™ºè¡¨ã•ã‚Œã‚‹ã€‚LLMã§LLMã‚’è©•ä¾¡ã™ã‚‹LLM-as-a-judge ãŒã¯ã‚„ã‚Šã€‚ä¸€æ–¹OpenAIã®æ¬¡ä¸–ä»£LLMã§ã‚ã‚‹Arrakisã¯AGIã ã¨ã„ã†ã†ã‚ã•ã‚‚ï¼ˆã‚³ãƒ¼ãƒ‰ãƒãƒ¼ãƒ ã¯ã€Œç ‚ã®æƒ‘æ˜Ÿã€ã‹ã‚‰ãã¦ã„ã‚‹ï¼Ÿï¼Ÿï¼‰ã€‚ç‰¹è¨±æ¤œç´¢ã ã‘ã‹ã‚‰ã‚¦ã‚¤ãƒ«ã‚¹è–¬ã‚’ç™ºè¦‹ã—ãŸã‚Šã€éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®‰å®šãªæº–çµæ™¶ã®åŒ–å­¦çµ„æˆã‚’ã‚ãã‚‰ã‹ã«ã—ãŸã‚Šã¨ã€ãƒã‚¤ã‚ªãƒ»ææ–™ç³»ã§LLMã¯å¤§æ´»èºã€‚PFN ã® PLaMo-13B ã€4 bit é‡å­åŒ–ã™ã‚‹ã¨Colab ç„¡æ–™ç‰ˆã§å‹•ããã€‚æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚Šåå¾®åˆ†æ–¹ç¨‹å¼ã‚’è§£ãè©±ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é€†è¨­è¨ˆã§ãã‚‹ãªã‚‰ã°ç”»æœŸçš„ã™ãã‚‹ã€‚ Gaussian Splatã‚’ã¤ã‹ã£ãŸä¸‰æ¬¡å…ƒç”Ÿæˆã®è«–æ–‡ã¨GitHubå…¬é–‹ãŒåŒæ™‚ã«ï¼’ã‹æ‰€ã§ï¼ã€‚LINEã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ç”Ÿã«ã‚ˆã‚‹é‡å­åŒ–ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–ã®åŠ¹æœæ¸¬å®šã€ã“ã“ã¾ã§ï¼–é€±é–“ã§ã§ãã‚‹ã®ã‹ã€‚ChatGPTã®æ¤œç´¢ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å¾©æ´»ã€ã©ã†ã‚‚æœ¬æ¥ãƒšã‚¤ã‚¦ã‚©ãƒ¼ãƒ«ã§å®ˆã‚‰ã‚Œã¦ã„ã‚‹è¨˜äº‹ã§ã‚ã£ã¦ã‚‚å…¨æ–‡ãŒè¡¨ç¤ºã•ã‚Œã¦ã—ã¾ã†ã¨ã„ã†å ±å‘Šã§åœæ­¢ã—ã¦ã‚‚ã®ã«å¯¾ç­–ãŒæ‰“ãŸã‚ŒãŸæ¨¡æ§˜ã€‚RAGé–¢ä¿‚ã®é€²æ—ã‚‚ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚„MergeRetrieverãªã©é€²å±•ãŒã‚ã‚‹ã€‚

- Agents: LLMã‚’ã¤ã‹ã£ãŸæ–°ã—ã„agentãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ãƒ„ãƒ¼ãƒ«è»
	- https://github.com/aiwaves-cn/agents
	- **Agents** is an open-source library/framework for building autonomous language agents. The library is carefully engineered to support important features including **long-short term memory**, **tool usage**, **web navigation**, **multi-agent communication**, and brand new features including **human-agent interaction** and **symbolic control**.
- llamaindexã‹ã‚‰neo4jã‚’ä½¿ã£ãŸã‚°ãƒ©ãƒ•agent
	- https://llamahub.ai/l/tools-neo4j_db
	- The `Neo4jQueryToolSpec` class provides a way to query a Neo4j graph database based on a provided schema definition.
-  LLM Fine-Tuning (æ±å¤§æ¾å°¾ç ”LLMè¬›åº§ Day5è³‡æ–™)
	- https://speakerdeck.com/schulta/llm-fine-tuning-dong-da-song-wei-yan-llmjiang-zuo-day5zi-liao
- OSSã®LLMã¯ã GAFAMã®LLMã«å‹ã¡ç›®ãŒã„ãªã„ã‹ã‚ã‚‹ã‹ï¼Ÿ
	- https://x.com/bindureddy/status/1706092114063639035?s=20
	- OSSã®LLMã¯ã€AIã®æ°‘ä¸»åŒ–ã¨é€æ˜æ€§ã®ãŸã‚ã«ã¯å¿…è¦ã¨ã„ã†è©±
-  LLMã‚’ç”¨ã„ãŸLLMã®è‡ªå‹•è©•ä¾¡ã«ã¤ã„ã¦ ã€œå¯èƒ½æ€§ã¨æ³¨æ„ç‚¹
	- https://engineers.ntt.com/entry/2023/09/25/091245
	- LLM-as-a-judge ã§ã¯ã€**äººæ‰‹è©•ä¾¡ã«åŒ¹æ•µã™ã‚‹ã‚¯ã‚ªãƒªãƒ†ã‚£ã®è©•ä¾¡ã‚’ã€ãŠé‡‘ã‚„æ™‚é–“ã€åŠ´åŠ›ã‚’ã‹ã‘ãšã«æ©Ÿæ¢°çš„ã«è¡Œãˆã‚‹**ã“ã¨ãŒæœŸå¾…ã§ãã¾ã™ã€‚
-  Community-developed checklists for publishing images and image analyses(Nature)
	- https://www.nature.com/articles/s41592-023-01987-9
	- ç”»åƒã‚„ç”»åƒè§£æçµæœã‚’å ±å‘Šã™ã‚‹éš›ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«é–¢ã™ã‚‹Nature MethodsèªŒã®è¨˜äº‹
	- ç”»åƒã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚„æ³¨é‡ˆã€è‰²ã®é¸æŠã€ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨å¯èƒ½æ€§ã€ç”»åƒè§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å ±å‘Šã«é–¢ã™ã‚‹é‡è¦ãªæ¨å¥¨äº‹é …ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚
- OpenAIã‹ã‚‰GPT-4V(ision) ãŒç™ºè¡¨ã€ã¤ã„ã§ã«å“è³ªã‚«ãƒ¼ãƒ‰System Cardã‚‚å…¬é–‹
	- https://cdn.openai.com/papers/GPTV_System_Card.pdf
	- GPT-4 with vision (GPT-4V) enables users to instruct GPT-4 to analyze image inputs provided by the user, and is the latest capability we are making broadly available. Incorporating additional modalities
	- è¤‡é›‘ãªæ¨™è­˜ã‚’èª­ã¿å–ã‚‹ã€https://x.com/petergyang/status/1707169696049668472?s=20
	- ã‚µã‚¤ã‚¼ãƒªã‚¢ã®ã€Œé–“é•ãˆã•ãŒã—ã€ã®æ­£ç­”ç‡ã¯ï¼‘å‰²ã€https://x.com/cumulo_autumn/status/1707574932153282728?s=20
	- GPT-4V vs. éœãŒé–¢ã€€https://x.com/horromary/status/1707373718534824305?s=20
- å¤–éƒ¨çŸ¥è­˜ã«ã‚ˆã‚Šãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸå¯¾è©±ã‚·ã‚¹ãƒ†ãƒ 
	- https://www.jstage.jst.go.jp/article/jjske/22/2/22_TJSKE-D-22-00053/_article/-char/ja/
	- æ§˜ã€…ãªæ¦‚å¿µã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é–¢å¿ƒã‚’æ¨å®šã—ï¼ŒçŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã™ã‚‹æ‰‹æ³•ã‚’ç”¨ã„ã¦ï¼Œé›‘è«‡ã«ãŠã‘ã‚‹å…±æ„Ÿæ€§ã‚„æƒ…å ±æä¾›ã‚’ç›®æŒ‡ã™
- ChatGPT(Pllusãƒ¦ãƒ¼ã‚¶ãƒ¼ä»¥ä¸Šï¼‰ã«ã€æ¥é€±ã‹ã‚‰æ–°æ©Ÿèƒ½ã‚’roll-outã™ã‚‹ã¨ã®ç™ºè¡¨
	- Voice Capabilities:
	- Image Interaction
	- New Text-to-Speech Model:
	- Collaboration with Spotify
-  Amazonã€ç”ŸæˆAIæ–°èˆˆã«5900å„„å††å‡ºè³‡ã€€Microsoftã«å¯¾æŠ—
	-  Claude-2-100kã¯ã€Anthropicã®æœ€ã‚‚å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒ10ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆç´„75,000èªï¼‰
	- ã°ã£ã¡ã‚Šæ—¥æœ¬èªã«ã‚‚å¯¾å¿œã—QuoraãŒæä¾›ã™ã‚‹ [poe.com](http://poe.com)  ã§å®Ÿéš›ã«ä½¿ã£ã¦ã¿ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- llamaindexã®Auto Merging Retriever
	- https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_merging_retriever.html
	- æœ¨æ§‹é€ ã§æ•´ç†ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã—ã¦é¡ä¼¼ã™ã‚‹æã‹ã‚‰é †ã«ãƒãƒ¼ã‚¸ã—ã¦è¦‹ã›ã‚‹ã‚‰ã—ã„ã€‚
	- RAGã‚’è©•ä¾¡ã™ã‚‹æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚’GPT4ã§ç”Ÿæˆã™ã‚‹ã€DatasetGeneratorã‚‚ã¤ã„ã§ã«ç´¹ä»‹ã€‚ã„ã‚ã‚†ã‚‹ã€ LLM-as-a-judge ã®ä¸€ç¨®ã‚’lllamaindexãŒnativeã‚µãƒãƒ¼ãƒˆã—ãŸ
- ç‰¹è¨±ã‹ã‚‰åˆ†å­ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
	-  Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures
	- https://arxiv.org/abs/2309.08765v1
	- ChatGPTã‚’ä½¿ã£ã¦ç‰¹è¨±ã‹ã‚‰10ä¸‡ä»¶ã®åˆ†å­ã¨é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’é«˜ç²¾åº¦ã«æŠ½å‡ºã€ã“ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã‚¦ã‚¤ãƒ«ã‚¹è–¬ã‚’é€†æ¢ç´¢ã™ã‚‹ã¨ãã‚Œã£ã½ã„åˆ†å­ã‚’æŠ½å‡ºã§ããŸ
	- ç‰¹è¨±åˆ†æã ã‘ã‹ã‚‰ã€ã€ã€
- ChatGPT-4Vå…¬é–‹ã€iOSã‚„Androidç‰ˆã«ã‚‚æ­è¼‰ã€æ§˜ã€…ãªè©•ä¾¡ãŒå ±å‘Šã•ã‚Œã‚‹
	- ãƒ‡ãƒ¢ã®ç”»åƒã¨è¨€èªã‚’äº¤ãˆãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã¯æœªæ¥æ„Ÿã‚ã‚‹ã€‚æ§‹é€ åŒ–æ–‡æ›¸ã‚’ç”»åƒã§è¦‹ã›ã¦ã‚‚ã‚ã‚‹ç¨‹åº¦ç†è§£ã§ãã‚‹æ¨¡æ§˜ã€‚
	- äººã®è¦‹ãŸç›®ã«å¯¾ã™ã‚‹è¨€åŠãªã©æ–°ãŸãªãƒªã‚¹ã‚¯ã‚‚è©•ä¾¡ãƒ»å¯¾ç­–æ¸ˆã¿ã¨ã®ã“ã¨
	- è‹±èªã®ã»ã†ãŒOCRç²¾åº¦ãŒè‰¯ã„ã—è‰²ã€…è©¦ã—ã¦ã‚‹ã‘ã©ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå›³è¡¨ã®Reasoningã¯ã‹ãªã‚Šã§ãã‚‹ã€‚å›³è¡¨ã«å«ã¾ã‚Œãªã„èƒŒæ™¯æƒ…å ±ã‚‚ã€GPTå†…éƒ¨ã®çŸ¥è­˜ã§è£œãˆã‚‹ã®ãŒå¼·åŠ›ã€‚
- Calibrating LLM-Based Evaluator
	- https://huggingface.co/papers/2309.13308
	-  LLMãƒ™ãƒ¼ã‚¹ã®è©•ä¾¡å™¨ã®æ ¡æ­£: å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’è‡ªç„¶è¨€èªç”Ÿæˆã®å“è³ªè©•ä¾¡ã«åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚’ææ¡ˆã—ï¼Œäººé–“ã®è©•ä¾¡ã¨ã®ä¸€è‡´åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã®æ ¡æ­£æ‰‹æ³•ã‚’ææ¡ˆã™ã‚‹ï¼
- Sam Altmanæ°ã€ã€Œç¤¾å†…å†…éƒ¨çš„ã«ã¯ã€AGIã¯å®Œæˆã—ãŸã€ã¨tweetã€‚
	- am Altman says "agi has been achieved internally" at OpenAI.
	- å™‚ã§ã¯OpenAIã¯Arrakisã¨ã„ã†é™ã‚ŠãªãAGIã«è¿‘ã„any-to-any modelã‚’é–‹ç™ºã—ã¦ãŠã‚Šã€ã‚µãƒ ã‚¢ãƒ«ãƒˆãƒãƒ³ã‚‰ã—ãã‚¢ã‚«ã‚¦ãƒ³ãƒˆãŒAGIã®é–‹ç™ºã«æˆåŠŸã—ãŸ(è¿½è¨˜: ã¾ãè½ã¡ç€ã“ã†ã‚„) ã¿ãŸã„ãªã“ã¨ã‚’è¨€ã£ãŸã¨ã„ã†å ±å‘Šã‚‚ã‚ã‚‹ã€‚
	- ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ã§äºˆå®šã•ã‚Œã¦ã„ã‚‹é–‹ç™ºè€…ä¼šè­°ï¼ˆ11/6ï¼‰ã«ä½•ã‹ã—ã‚‰ã®ç™ºè¡¨ãŒã‚ã‚‹ã€‚
- ã€ç¶šã€‘Flash Attentionã‚’ä½¿ã£ã¦LLMã®æ¨è«–ã‚’é«˜é€Ÿãƒ»è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿ
	- https://qiita.com/jovyan/items/5716cd83e246df4a158e
	- æœ€è¿‘å…¬é–‹ã•ã‚ŒãŸhuggingfaceã‹ã‚‰ç›´æ¥å…¬å¼å®Ÿè£…ã®Flash Attention2ã‚’ä½¿ãˆã‚‹æ©Ÿèƒ½ï¼ˆfrom_pretrainedã§use_flash_attention_2=Trueã‚’æŒ‡å®šï¼‰ã«ã¤ã„ã¦ã‚‚å®Ÿé¨“
- ã€LogiCoTã€GPT-4ãªã©ã®LLMã«ã€Œè‡ªã‚‰ã®è«–ç†çš„ãªæ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯ã€ã•ã›ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
	- "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"
	- å‰æï¼ˆPremiseï¼‰ã€è€ƒãˆï¼ˆThoughtï¼‰ã€æ¤œè¨¼ï¼ˆVerificationï¼‰ã«ã¤ã„ã¦æ˜ç¢ºã«æŒ‡ç¤ºã™ã‚‹
- çµ±èªçš„è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ JCoLA ãŒ https://huggingface.co/datasets/shunk031/JGLUEã«è¿½åŠ 
	- JGLUE ã®å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒãã‚ã£ãŸã‚‰ã—ã„
- ChatGPT ã®æ¤œç´¢ãƒ—ãƒ©ã‚°ã‚¤ãƒ³(Plusç”¨ï¼Ÿï¼‰ãŒå¾©æ´»
-  Pair Programming with a Large Language Model
	- https://www.deeplearning.ai/short-courses/pair-programming-llm/
	- DeepLearningAIã‚ˆã‚Šã€ã‚·ãƒ§ãƒ¼ãƒˆã‚³ãƒ¼ã‚¹ãŒå…¬é–‹ã€‚LLMã¨ãƒšã‚¢ãƒ—ãƒ­ã¨ã¯
- llamaindexã®TimescaleDBã¨ã®é€£æº
	- https://medium.com/llamaindex-blog/timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0
- å¤§å­¦ã«ãŠã‘ã‚‹æ•°ç†ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AI æ•™è‚² ã®ä¸­ã§ã®çµ±è¨ˆç§‘å­¦ã®æ•™è‚²ã«ã¤ã„ã¦ï¼ˆæ—¥æœ¬å­¦è¡“ä¼šè­°ï¼‰
	- https://www.scj.go.jp/ja/info/kohyo/pdf/kohyo-25-k230926-24.pdf
	- (1) æ•°ç†ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AI åˆ†é‡ã®ç†è«–çš„åŸºç¤ã¨ã—ã¦ã®çµ±è¨ˆç§‘å­¦ã®ä½ç½®ä»˜ã‘
	- (2) æ•°ç†ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»AI åˆ†é‡ã®å†æ•™è‚²(ãƒªã‚¹ã‚­ãƒªãƒ³ã‚°)ã®æ¨é€²
	- (3) å­¦å£«èª²ç¨‹åŠã³å¤§å­¦é™¢æ•™è‚²ãŒå¿…è¦ã¨ã™ã‚‹çµ±è¨ˆæ•™å“¡ã®è‚²æˆ
	- (4) åˆç­‰ãƒ»ä¸­ç­‰æ•™è‚²ã«ãŠã‘ã‚‹æ•™æã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã€ãƒ‡ã‚¸ã‚¿ãƒ«ç’°å¢ƒã®æ•´å‚™ã¨çµ±è¨ˆæ•™è‚²ã® ã•ã‚‰ãªã‚‹å……å®Ÿ
	- ãã£ã¨ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãŒä¸»äººå…¬ã®ã‚¢ãƒ‹ãƒ¡ãŒå¿…è¦ã ã¨æ€ã†ãã€‚
- RAGã‚’OSSã ã‘ã§æ§‹ç¯‰ã™ã‚‹æ–¹æ³•(llamaindex)
	-  Building RAG from Scratch (Open-source only!)
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/oss_ingestion_retrieval.html
	- Sentence Transformers as the embedding model
	- Postgres as the vector store (we support many other vector stores too!)
	- Llama 2 as the LLM (through llama.cpp)
- Google Colab ã§ Preferred Networks ã® PLaMo-13B ã‚’è©¦ã™by npaka
	- https://note.com/npaka/n/n19ff9dd4a537?sub_rt=share_sb
-  æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒç™ºè¦‹ã—ãŸåˆã‚ã¦ã®æº–çµæ™¶(çµ±è¨ˆæ•°ç†ç ”ç©¶æ‰€ï¼‰
	- https://www.ism.ac.jp/ura/press/ISM2023-05.html
	- ã“ã‚Œã¾ã§ã«åˆæˆã•ã‚Œã¦ããŸæº–çµæ™¶ã‚„é–¢é€£ç‰©è³ªã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’èª­ã¿è§£ãã€ç†±çš„ã«å®‰å®šãªæº–çµæ™¶ã‚’å½¢æˆã™ã‚‹åŒ–å­¦çµ„æˆã‚’äºˆæ¸¬ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’æŠ€è¡“ã‚’é–‹ç™º
- PFN ã® PLaMo-13B ã‚’ 4 bit é‡å­åŒ–ã™ã‚‹ã¨Colab ç„¡æ–™ç‰ˆã® T4 15GB ã§ã‚‚æ¨è«–ã§ãã‚‹ã‚‰ã—ã„
	- https://colab.research.google.com/drive/1vgHInjIL5dJYoaIXL-s6ickbp3cwIQti?usp=sharing
- DreamGaussianãŒ ç„¡æ–™Colabã§è©¦ã›ã‚‹ã€‚5åˆ†ã»ã©ã§å®Œæˆ
	- https://github.com/camenduru/dreamgaussian-colab
-  Mastering Customer Segmentation with LLM
	- https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41
	- ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’LLMã®embeddingã§æ•°å€¤åŒ–ã—ã€k-meansã‚„t-SNEã§ã‚¯ãƒ©ã‚¹ã‚¿ã®ç‰¹å¾´ã‚’æ¢ã‚‹æµã‚Œã®è‰¯ã„è§£èª¬è¨˜äº‹
- ãƒ‡ã‚¸ã‚¿ãƒ«åºã®ITã‚³ãƒ³ã‚µãƒ«/PM/é€±5æ—¥/ä¸€éƒ¨ãƒªãƒ¢ãƒ¼ãƒˆ/ãƒ‡ã‚¸ã‚¿ãƒ«åºITæ”¯æ´ã®æ±‚äººãŒè©±é¡Œã«
	- å˜ä¾¡ã¯ã€1,54ä¸‡å††/ä¸‡
	- ä½“èª¿ãŒå®‰å®šã—ã¦ãŠã‚Šç—…æ¬ ãŒå°‘ãªã„æ–¹
- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚Šåå¾®åˆ†æ–¹ç¨‹å¼ã‚’è§£ãè«–æ–‡
	-  Neural Operators for Accelerating Scientific Simulations and Design
	- https://arxiv.org/abs/2309.15325v1
	- å…¥å‡ºåŠ›ã®ãƒãƒƒãƒ”ãƒ³ã‚°æ¼”ç®—å­ã‚’å­¦ç¿’ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«æ¼”ç®—å­ã€‚æ•°å€¤è¨ˆç®—ã‚’é«˜é€ŸåŒ–ã§ãã‚‹ã ã‘ã§ãªãã€å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®å­¦ç¿’ã‚„é€†è¨­è¨ˆã¾ã§ã§ãã‚‹ãã†ã§ã™ã€‚
- ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning
	- https://huggingface.co/papers/2309.16650
	- ï¼“Dã®çŠ¶æ³ã‚’æ¦‚å¿µãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ç†è§£ã™ã‚‹ãŸã‚ã®èªå½™ã‚’æä¾›ã€ã“ã‚Œã¯ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ã®ä¸–ç•Œã‹ã€‚ã€‚
- Gaussian Splatï¼‹ä¸‰æ¬¡å…ƒç”Ÿæˆã®è«–æ–‡ãŒä¸€ã¤ã©ã“ã‚ã‹äºŒã¤åŒæ™‚ã«å‡ºã¦ã„ã‚‹ã®ãŒæˆ¦å›½æ™‚ä»£ã£ã½ã„ã¨ã“ã‚
	- https://gsgen3d.github.io/
	- https://dreamgaussian.github.io/
	- Gaussian Splatting ã¯ã€3D ã‚·ãƒ¼ãƒ³ã‚’ã€ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é–¢æ•°ã§è¡¨ã•ã‚ŒãŸç‚¹ç¾¤ã®é›†åˆã¨ã—ã¦è¡¨ç¾ã—ã¾ã™ã€‚ã“ã®ç‚¹ç¾¤ã®é›†åˆã‚’ã€ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ã«ã€å…‰ç·šã«æ²¿ã£ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚·ãƒ¼ãƒ³ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚
- lama_indexã® AutoMergingRetrieverã‚’å›³è§£ã—ãŸçµµãŒç´ æ™´ã‚‰ã—ã„
	- https://x.com/clusteredbytes/status/1707864519433736305?s=20
- OpenAPIã®æ–°ã—ã„instructãƒ¢ãƒ‡ãƒ«ã§ã¯ã€ãªã«ã‹æ©Ÿèƒ½ãŒè½ã¡ãŸæ¨¡æ§˜
	- OpenAI is removing the ability to evaluate P(completion | prompt) for user-provided completions to the `gpt-3.5-turbo-instruct` model.
- Googleã€æ–°LLMã€€Geminiã‚’ 10æœˆ4æ—¥ã«ç™ºè¡¨ã‹ã€
	- Gemini might be coming out on Wednesday
	- "plus few more surprizes"ã¨invitationã«æ›¸ã„ã¦ã‚ã‚‹ã‚‰ã—ã„
-  7 Query Strategies for Navigating Knowledge Graphs With LlamaIndex
	- https://betterprogramming.pub/7-query-strategies-for-navigating-knowledge-graphs-with-llamaindex-ed551863d416
- ã€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã€‘é‡å­åŒ–ã«ã‚ˆã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«è»½é‡åŒ–ã®åŠ¹æœæ¸¬å®š
	- https://engineering.linecorp.com/ja/blog/quantization-lightweighting-llms
	- LINEã®æŠ€è¡“è· å°±æ¥­å‹ã‚³ãƒ¼ã‚¹ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³ã‚·ãƒƒãƒ—ç”Ÿã®ç™ºè¡¨
	- 6é€±é–“ç¨‹åº¦ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³æœŸé–“ã‚‰ã—ã„
	- FP8ã«ã‚ˆã‚‹å½±éŸ¿ã¾ã¨ã‚
		-  å¤§ããªãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§1.2å€ã®æ¨è«–é«˜é€ŸåŒ–
	- GPTQã«ã‚ˆã‚‹é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã®åŠ¹æœæ¸¬å®š
- Streamlitã¨Github Codespacesã§ãƒ–ãƒ©ã‚¦ã‚¶ã®ã¿ã§ChatGPT APIé–‹ç™ºã‚’ã™ã‚‹
	- https://corp.langcore.org/media/codespaces

## 9/25

ç›¸ã‚‚åˆã‚ã‚‰ãšã€RAG(Retrieval Augmented Generation)é–¢ä¿‚ãŒå¤šã„ã®ã¯ã”å®¹èµ¦ã€‚ä¸Šä½ã®LLM(GPT-4ã¨ã‹ï¼‰ã‚’ã¤ã‹ã£ã¦æ­£è§£ã‚’ã¤ãã£ã¦ã€RAGã‚’è©•ä¾¡ã™ã‚‹ä»•çµ„ã¿ã¨ã‹ã€ã“ã®è©•ä¾¡ã®ä»•çµ„ã¿ã‚’ã¤ã‹ã£ã¦åˆ¥ã®LLï¼­(gpt-3.5-turboã¨ã‹)ã‚’RAGå‘ã‘ã«fine-tuningã™ã‚‹ãªã‚“ã¦ã®ãŒã€e2e(end-to-end)ã®æ‰‹æ³•ã¨ã—ã¦å½“ãŸã‚Šå‰ã«ãªã‚Šã¤ã¤ã‚ã‚‹ã€‚ã€ŒçŸ¥è­˜ã¯æ¨¹æœ¨ã®ã‚ˆã†ãªã‚‚ã®ã€ã¨ã®ãŸã¾ã†ã‚¹ã‚¯ã‚¨ãƒ‹ã®ä¸‰å®…ã•ã‚“ã®è©±ã¯ã„ã¤ã‚‚é¢ç™½ã„ã€‚SOPã‚’ã¤ã‹ã£ãŸAgentsã¨ã„ã†ã®ã¯agentã®å¯åˆ¶å¾¡æ€§ã¨ã„ã†æ„å‘³ã§é¢ç™½ã„ã€‚Transformers.jsã‚’ã¤ã‹ã£ãŸWeb LLMã®æ–°æ‰‹ãŒç™»å ´ã€‚Xwin-LM-70BãŒGPT-4è¶…ãˆã‹ï¼Ÿã¨ã„ã†ã®ãŒã‚‚ã£ã±ã‚‰ã®è©±é¡Œã€‚LLMãŒå‰µé€ æ€§ã‚’æŒã¤ã‹ï¼Ÿã®è«–æ–‡ã§ã®å‰µé€ æ€§ã®ï¼“ã¤ã®åŸºæº–ï¼ˆä¾¡å€¤ã€æ–°è¦æ€§ã€é©šãï¼‰ã£ã¦ã€ç‰¹è¨±ææ¡ˆã¨åŒã˜ã ã‚ˆã­ã€LLMãŒç‰¹è¨±ææ¡ˆã§ãã‚‹ã‹ï¼Ÿã«ç½®ãæ›ãˆã¦ã‚‚åŒã˜ã€‚instructorã¨ã„ã†openai function callingã«pydanticã‚’çµ„ã¿åˆã‚ã›ã‚‰ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ã£ã¦ã¿ãŸã„ã€‚RAGã§ã‚‚ãƒ¡ã‚¿æƒ…å ±æŠ½å‡ºã«pydanticä½¿ã£ãŸã‚Šã¨ã‹ã€ã“ã®è¾ºã‚Šã‚‚å®šç•ªåŒ–ã‹ã€‚ChatGPTã®çŸ¥è­˜ãŒã€2022å¹´1æœˆã¾ã§ã®çŸ¥è­˜ã¾ã§ã‚¢ãƒ—ãƒ‡ã•ã‚ŒãŸã€‚LLMã®åˆ©ç”¨ã‚µãƒ¼ãƒ™ã‚¤ã€ã€Œï¼•ä½ï¼šãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥ç«‹æ¡ˆã€ã£ã¦ã®ã¯ç¬‘ã£ãŸã­ã€‚gpt-3.5-turbo-instructã¨ã„ã†ã®ãŒå‡ºã¦ã‚‹ã®ã­ã€ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§ã€è¨€èªç”Ÿæˆã«é©ã—ãŸãƒ¢ãƒ‡ãƒ«ï¼ˆãƒãƒ£ãƒƒãƒˆç”¨ã§ã¯ãªã„ï¼‰ã€ã“ã‚Œã¯fine-tuningç”¨ãªã®ã‹ï¼Ÿï¼Ÿã€LLMå‘ã‘AIåŠå°ä½“ã€ŒSN40Lã€ã£ã¦ã®ã‚‚æœŸå¾…ã€‚

- ã¡ã‚‡ã£ã¨ã—ãŸæ°—é…ã‚Šã§çš†ã‚’å¹¸ã›ã«ã™ã‚‹ GitHub ã®ä½¿ã„æ–¹
	- https://qiita.com/squid-cat/items/7166317e60d3ff96ccb7
	- PR ãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã•ã‚Œãªã„ç’°å¢ƒã‚’ä½œã‚‰ãªã„
- ç±³å›½ã®AIä¼æ¥­å…¬è´ä¼šã‚ˆã‚Šã€Nvidiaã®è¨¼è¨€ãŒç´ æ™´ã‚‰ã—ã„
	- https://x.com/Yampeleg/status/1703774531771363738?s=20
	- OpenAI: AI will kill us. 
	- Anthropic: AI will kill us. 
	- InflectionAI: AI will kill us. 
	- Nvidia: Fortunately uncontrollable Artificial General Intelligence is Science Fiction not reality.
- çŸ¥è­˜ã¨æŠ€è¡“ã®ç¶™æ‰¿ã¨ã—ã¦ã®AI by ã‚¹ã‚¯ã‚¨ãƒ‹ä¸‰å®…ã•ã‚“
	- https://togetter.com/li/2226417
	- ãã®åˆ†é‡ã®å°‚é–€å®¶ãŒæŒã¤ãã†ã„ã£ãŸçŸ¥è­˜ä½“ç³»ãŒã€ãã®æ•™æˆãªã‚Šå°‚é–€å®¶ã®ä¾¡å€¤ãªã‚ã‘ã§ã‚ã‚‹ãŒã€å®Ÿéš›ã®ã¨ã“ã‚ã€è¿‘ãã«ã„ã¦è©±ã—ã‹ã‘ãªã‘ã‚Œã°ã€è‡ªåˆ†ã«ã¨ã£ã¦ä¾¡å€¤ã‚ã‚‹ã‚‚ã®ã‚’å¼•ãå‡ºã›ãªã„ã€‚ã ã‹ã‚‰ã“ãã€ç ”ç©¶å®¤ãŒã‚ã‚Šå­¦ç”ŸãŒã‚ã‚‹ã€‚ã—ã‹ã—ã€ãã†ã„ã£ãŸçŸ¥ã®ä½“ç³»ã¯ã€ä¸‡äººã«é–‹ã‹ã‚Œã‚‹ã¹ãã 
	- AIã«ã‚ˆã£ã¦æ—¥ã€…ç©ã¿é‡ãªã‚‹è«–æ–‡ã‚„ç™ºè¡¨è³‡æ–™ã€è¬›æ¼”éŒ²ã‚’å¸åã—ã€çŸ¥ã®ç³»çµ±æ¨¹ã‚’ä½œã‚‰ã›ã‚‹ã€‚æˆ‘ã€…ã¯ãã‚ŒãŒå·¨å¤§ãªæ¨¹æœ¨ã¨ãªã£ã¦ã„ãã®ã‚’è¦‹ãªãŒã‚‰ã€æ¬ ã‘ã¦ã„ã‚‹ãƒ”ãƒ¼ã‚¹ã‚„æ¥ã‚‹ã¹ãæè‘‰ã‚’æº–å‚™ã™ã‚‹
- Intel/Llama-2-70b-chat-hf-onnx-int4
	- https://huggingface.co/Intel/Llama-2-70b-chat-hf-onnx-int4
	- high-quality, INT4, ONNX models for all LLama2 variants (base vs. chat, 7B to 70B).
- Best Practices for LLM Evaluation of RAG Applications by DataBricks
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- Human and GPT-4 judges can reach above 80% agreement on the correctness and readability score. And if we lower the requirement to be smaller or equal than 1 score difference, the agreement level can reach above 95%.
-  Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?
	- https://arxiv.org/abs/2309.08963
	- structure-aware fine-tuning method, applied to Llama-7B, which significantly outperform other model like GPT-3.5/4 and Vicuna-13B.
- Azure Cognitive Search ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰+ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯ã€ç´”ç²‹ãªãƒ™ã‚¯ã‚¿ãƒ¼ã‚µãƒ¼ãƒã‚ˆã‚Šã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è‰¯ã‹ã£ãŸãã†ã§ï¼
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/azure-cognitive-search-outperforming-vector-search-with-hybrid/ba-p/3929167
- "Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality"
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321
	- â‘  GPT-4ã‚ã‚Šã®é›†å›£ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å„ªã‚Œã¦ã„ãŸ ãƒ»ã‚¿ã‚¹ã‚¯ã®å®Œäº†æ•°ãŒå¹³å‡ã§12.2%å¤šã„ ãƒ»ã‚¿ã‚¹ã‚¯ã®å®Œäº†é€Ÿåº¦ãŒå¹³å‡ã§25.1%æ—©ã„ ãƒ»ã‚¿ã‚¹ã‚¯ã®å“è³ªãŒå¹³å‡ã§40%é«˜ã„ 
	- â‘¡ ã‚‚ã¨ã‚‚ã¨æˆç¸¾ã®ã‚ˆããªã„äººãŒç›®è¦šã¾ã—ãå‘ä¸Šã—ãŸ
- GPT-3.5-turbo ã‚’ Fine-tuning ã—ã¦ GPT-4 ç›¸å½“ã®æ€§èƒ½ã‚’ç²å¾—ã™ã‚‹
	- https://tech.drobe.co.jp/entry/2023/09/19/140000
	- Lambda ã§ GPT-4 ã‚’å©ãã¤ã¤ã€å…¥åŠ›ã¨å‡ºåŠ›ã®ãƒšã‚¢ã‚’ json å½¢å¼ã§ Cloudwatch ã«è½ã¨ã—ã¾ã™ã€‚
	- ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã‚‰ã“ã“ã‚’å‚è€ƒã« Fine-tuning ã®ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨ validation ã‚’è¡Œã„ã¾ã™ã€‚
	- Fine-tuning ã®å®Ÿæ–½ã¯ç°¡å˜ã§ã™ã€‚OpenAI ã® API ã‚’åˆ©ç”¨ã—ã¦ä»¥ä¸‹ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚
		- 1.  ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		- 2.  ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã—ã¤ã¤ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹
	- Fine-tuning ã™ã‚‹ã¨çµæœãŒ GPT-4 ã«è¿‘ã¥ãäº‹ãŒè¦³æ¸¬ã§ããŸ
- Let's Verify Step by Step
	- https://arxiv.org/abs/2305.20050
	- LLMãŒè¤‡é›‘ãªå•é¡Œã‚’æ¨è«–ã§ãã‚‹ã®ã¯ã€å­¦ç¿’ä¸­ã«æ¨è«–æ–¹æ³•ï¼ˆè§£ãæ–¹ï¼‰ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã€ãã®è§£ãæ–¹ã‚’å­¦ã‚“ã§ã„ã‚‹ã‹ã‚‰ã¨ã„ãˆã‚‹
- è‡ªå¾‹è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ Agents ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n089614881df8
	- ã€Œ**Agents**ã€ã¯ã€**è‡ªå¾‹è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**
	- ã€Œ**SOP**ã€(Standard Operation Process) ã‚’é€šã˜ã¦è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãã‚ç´°ã‹ã„åˆ¶å¾¡ã¨ã‚¬ã‚¤ãƒ€ãƒ³ã‚¹ã‚’æä¾›ã§ãã‚‹ã“ã¨ã§ã™ã€‚ã€ŒSOPã€ã¯**ã‚¿ã‚¹ã‚¯å…¨ä½“ã®ã‚µãƒ–ã‚´ãƒ¼ãƒ« / ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’å®šç¾©**ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãã‚ç´°ã‹ã„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
-  Benchmarking `gpt-3.5-turbo-instruct` on agents doing question-answering over tabular data
	- https://github.com/langchain-ai/langchain-benchmarks/blob/main/csv-qa/pandas_agent_instruct.py
	- It performed roughly the same as gpt-3.5-turbo (the chat model) with roughly ~67% accuracy
	- It errored twice due to misformatted output - without function prompting for output format becomes much more important
- StableDiffusionã§ç”Ÿæˆã—ãŸç”»åƒã‹ã‚‰3Dãƒ¢ãƒ‡ãƒ«ã‚’"AIã§"ä½œæˆã—ã€Unityä¸Šã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å‹•ã‹ã™ã¾ã§ã€CSM AIã®ä½¿ã„æ–¹ã€‘
	- https://note.com/okp_/n/n89b96384e0cb?sub_rt=share_b
- llamaindexã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€â€œbuilding RAG from scratchâ€ -
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
- SambaNovaã€æœ€å¤§5å…†å€‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œå¯èƒ½ãªLLMå‘ã‘AIåŠå°ä½“ã€ŒSN40Lã€ã‚’ç™ºè¡¨
	- https://news.mynavi.jp/techplus/article/20230920-2775419/
	- Ceruleanã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€‚NVIDIA H100ã®24å°åˆ†ã®æ€§èƒ½ã§ã€GPUã«æ­è¼‰ã•ã‚Œã¦ã‚‹æ§˜ãªé«˜é€Ÿãƒ¡ãƒ¢ãƒªãŒä¸è¦ã§ãƒ¡ãƒ¢ãƒªå¤§å®¹é‡åŒ–ãŒå¯èƒ½ï¼DDRãŒä½¿ãˆã‚‹
- sam altmanæ°ã€DALE 3ã®ãƒ‡ãƒ¢ç”»åƒã‚’è‡ªæ…¢ã™ã‚‹
	- https://x.com/sama/status/1704561613070893428?s=20
- OpenAIæœ¬å®¶ã§ã€Fine-tuningç”¨ã®web pageãŒå…¬é–‹ã•ã‚ŒãŸ
	- https://x.com/OfficialLoganK/status/1704181284036300970?s=20
	- èª°ã§ã‚‚ç°¡å˜ã«ãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ãŒã§ã
- JSONã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ« jsoncrack
	- https://jsoncrack.com/
- GPT-4ãªã©ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã§åŒ–å­¦ç ”ç©¶ã‚’è¡Œã†ã«ã‚ãŸã£ã¦ã®ï½¤ç¾çŠ¶ãƒ»èª²é¡Œãƒ»å±•æœ›ã‚’æ•´ç†ã—ãŸè«–æ–‡
	- Prompt engineering of GPT-4 for chemical research: what can/cannot be done?
	- https://www.tandfonline.com/doi/full/10.1080/27660400.2023.2260300
	- GPT-4ã¯ã€åŒ–å­¦ç ”ç©¶ã«ãŠã‘ã‚‹è¨€èªå‡¦ç†ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®çµ„ã¿è¾¼ã¿ã«æœ‰åŠ¹ãªãƒ„ãƒ¼ãƒ«ã¨ãªã‚Šå¾—ã¾ã™ã€‚
	- ä»¥ä¸‹ãŒå¿…è¦
		- åˆ†å­æ§‹é€ ã‚„å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³
		- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºæœ€æ–°ã®åŒ–å­¦æƒ…å ±ã‚’å­¦ç¿’ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«
		- æ¨è«–ã‚„è¨ˆç”»èƒ½åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚„ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã®é©æ–°
- llamaindexã«ã¦ã€RAGã«ãŠã„ã¦ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã¤ã‹ã£ãŸQueryã‚’ä½¿ã†æ–¹æ³•ã€
		- RAGStringQueryEngineã¨ã„ã†ã®ã§ã€ä»»æ„ã®promptã‚’æŠ•å…¥ã§ãã‚‹ï¼Ÿï¼
		- ãªã‚‹ã»ã©ã“ã‚Œã¯å½¹ã«ç«‹ã¤
		- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/custom_query_engine.html
- An in-browser version of ChatGPT (or HF Chat), built with HuggingFace Transformers.js!
		- https://huggingface.co/spaces/mithril-security/blind_chat
		- webllmã¨ã¯é•ã£ãŸãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹ã®local LLMå®Ÿè£…ã€transformer.jsã‹ã‚ã€ãã£ã¡ã‹ã‚‰HFä½¿ã†ã‚“ã ã€‚
- RSJ2023ã€ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«2ï¼ˆæ¾å°¾ç ”ï¼‰
	- https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa
	- æ—¥æœ¬ãƒ­ãƒœãƒƒãƒˆå­¦ä¼š [#RSJ2023](https://twitter.com/hashtag/RSJ2023?src=hashtag_click) ã®ã€ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®å®Ÿãƒ­ãƒœãƒƒãƒˆå¿œç”¨ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼ˆå¾ŒåŠï¼‰ã®è³‡æ–™
	- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã‚’æ•´ç†ã—ãŸã‚ã¨ï¼Œãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹é ˜åŸŸã§ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—æ´»ç”¨ã™ã‚‹æ–¹æ³•ã«é–¢ã—ã¦ã‚µãƒ¼ãƒ™ã‚¤
- **Building RAG with LLMs and Prompts**ã€€by **Jerry Liu, LlamaIndex**
	-  @FlowGPTOfficial workshop today I gave talks on how to build RAG response generation and a simple router module using only LLMs and prompt
- llamaindexã®RAGã«ãŠã‘ã‚‹ã€é¡ä¼¼æ¤œç´¢èªã®post processingæ§˜ã€…ã€é †ç•ªå¤‰ãˆã‚‹ã¨ã‹ã‚ã‚Šãªã®ã‹ãƒ»
	- https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/node_postprocessors/modules.html#longcontextreorder
-  LLMãŒæŒã¤/æŒãŸãªã„/æŒã¡ã†ã‚‹å‰µé€ æ€§ã«ã¤ã„ã¦ã®è«–æ–‡
	- On the Creativity of Large Language Models
	- https://arxiv.org/abs/2304.00008
	- ãƒœãƒ¼ãƒ‡ãƒ³ã®ï¼“ã¤ã®åŸºæº–ï¼ˆä¾¡å€¤ã€æ–°è¦æ€§ã€é©šãï¼‰ã‚„ä»–ã®å“²å­¦çš„ç†è«–ã«åŸºã¥ã„ã¦ã€LLMã®å‰µé€ æ€§ã‚’æ¤œè¨¼
	- LLMã¯ä¾¡å€¤ã‚’æŒã¤ä½œå“ã‚„ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€æ–°è¦æ€§ã‚„é©šãã«ã¤ã„ã¦ã¯å¼±ã„
	- LLMã¯äººé–“ã¨åŒã˜ã‚ˆã†ãªå‰µé€ æ€§ã‚’æŒã£ã¦ã„ã‚‹ã¨ã¯è¨€ãˆã¾ã›ã‚“
	- ç•°ãªã‚‹å­¦ç¿’æ–¹æ³•ã‚„é©å¿œèƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã™ã‚‹ã“ã¨ã§ã€æ¢ç´¢çš„ã‚„å¤‰é©çš„ãªå‰µé€ æ€§ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
	- LLMã¯äººé–“ã¨å”åƒã™ã‚‹ã“ã¨ã§ã€äººé–“ã®å‰µé€ æ€§ã‚’è£œå®Œã—ãŸã‚Šåˆºæ¿€ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™
-  RAG is more than just embedding search
	- https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/
	- ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ™ã‚¯ãƒˆãƒ«ã‚µãƒ¼ãƒãƒ™ãƒ¼ã‚¹ã®èª²é¡Œã‚’è¿°ã¹ãªãŒã‚‰ã€instructorã¨ã„ã†openai function callingã«pydanticã‚’çµ„ã¿åˆã‚ã›ã‚‰ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç´¹ä»‹ã—ã¦ã„ã‚‹è¨˜äº‹
	- èª²é¡Œã®ä¸€ã¤ã€-   **Query-Document Mismatch**:ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨è³ªå•ã®embbedingã£ã¦åŒã˜ç©ºé–“ã§ãªã„ã¨æ„å‘³ãªã„ã‚ˆã­ï¼ˆåœ°ç”£åœ°æ¶ˆã®å ´åˆã‚’é™¤ãï¼‰
- Xwin-LM-70BãŒGPT-4è¶…ãˆï¼Ÿ
	- https://www.itmedia.co.jp/news/articles/2309/21/news085.html
	- Xwin-LMã¯ç±³MetaãŒå…¬é–‹ã—ãŸAIã€ŒLlama2ã€ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ãŠã‚Šã€æ•™å¸«ã‚ã‚Šãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€å ±é…¬ãƒ¢ãƒ‡ãƒ«ã€ãƒªã‚¸ã‚§ã‚¯ãƒˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã€å¼·åŒ–å­¦ç¿’ãªã©ã‚’ä½¿ã£ã¦èª¿æ•´ã—ãŸã‚‚ã®ã¨ã„ã†ã€‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯Llama2ã¨åŒã˜ã70å„„ã€130å„„ã€700å„„ã®3ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨æ„ã€‚ä¸­ã§ã‚‚æœ€å¤§ã§ã‚ã‚‹700å„„ã®ã€ŒXwin-LM-70B-V0.1ã€ã¯ã€AlpacaEvalã®è©•ä¾¡åŸºæº–ã§ã‚ã‚‹ã€ŒText-Davinci-003ã€ï¼ˆGPT-3ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸€ã¤ï¼‰ã«å¯¾ã™ã‚‹å‹ç‡ã§95.57ï¼…ã‚’è¨˜éŒ²ã€‚å‹ç‡95.28ï¼…ã®GPT-4ã‚’è¿½ã„æŠœã„ãŸã¨ã—ã¦ã„ã‚‹ã€‚
- ChatGPTã®çŸ¥è­˜ãŒã€2022å¹´1æœˆã¾ã§ã®çŸ¥è­˜ã‚‚åæ˜ ã—ãŸæ¨¡æ§˜
	- https://old.reddit.com/r/ChatGPT/comments/16m6yc7/gpt4_training_cutoff_date_is_now_january_2022/
- e2e(end-to-end) LLM/RAGã€RAGè©•ä¾¡ã‚’å«ã‚ã¦LLMã§ã‚„ã‚‹ã¨ã„ã†è©±ã€ã«ã¤ã„ã¦
	- raysummit2023ã§ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€jupyternotebookã‚ã‚‹ã‚ˆ
	- https://github.com/anyscale/ray-summit-2023-training/blob/main/Ray-LlamaIndex/notebooks/02_evaluation.ipynb
- RAGã‚’æ§‹æˆã™ã‚‹ã¨ãã«ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¸ãˆã‚‹ã£ã¦ã®ã¯å½¹ã«ç«‹ã¤ã‚ã‘ã ãŒã€ãã‚Œã‚’Pydantic ï¼‹LLMã§ä¸€ç™ºã§ã§ãã‚‹ã¨ã„ã†è©±ã€
	- extract a full Pydantic object from any doc with 1 LLM call.
	- https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/PydanticExtractor.html
- Text generation web UI ã§ Xwin-LM-13B ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è‰²ã€…æ¨è«–ã—ã¦éŠã‚“ã§ã¿ã¾ã™ã€‚
	- https://note.com/sa1p/n/n51170c4d1a1f
	- ã€ŒText generation web UIã€ã¯ã€oobaboogaæ°ã«ã‚ˆã‚‹**å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ç”¨ã®ç„¡æ–™ã®Web UI**
	- ãŸã ã—ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ã€GPUãªã©ãŒå¿…è¦**Windowsã®å ´åˆNVIDIAè£½ã®ã‚°ãƒ©ãƒœã§ã®ã¿å‹•ä½œã™ã‚‹**
- Exploring ReAct Agent for Better Prompting in RAG Pipeline
	- https://betterprogramming.pub/exploring-react-agent-for-better-prompting-in-rag-pipeline-b231aae0ca7c
	- use ReAct Agent to analyze Amazon's recent disclosures and attitudes towards LLMs in their SEC Exhibits 99.1 filings
- RAGã®è©•ä¾¡ã€æ­£è§£ã¨ç­”ãˆã¨ã®æ¯”è¼ƒè©•ä¾¡ã§ã€å¾“æ¥ã®BLEU/ROUGEã¨ã‹ã§ãªãã¦ã€å˜ã«é¡ä¼¼æ€§è©•ä¾¡ã§ã‚ˆã„ã¨ã„ã†ç°¡æ˜“ã¯æ–¹æ³•ã‚’æç¤º
	- https://gpt-index.readthedocs.io/en/latest/examples/evaluation/semantic_similarity_eval.html
- OpenAIè¬¹è£½ã®ã€RAG(Q&A)ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
	- https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
- BQMLã®æ™‚ç³»åˆ—åˆ†æã€ARiMAã‚’é©å½“ãªãƒ©ã‚°è¨­å®šã®ã‚‚ã¨ã§40ãƒ¢ãƒ‡ãƒ«ã»ã©ãºãºã£ã¨æ¨å®šã—ã¦ãã‚Œã¦ã€ã‹ã¤AICã‚‚æ¨å®šã—ã¦ãã‚Œã‚‹ã®ã§é¬¼ä¾¿åˆ©
	- https://x.com/behemuhemulove/status/1705629318439907451?s=20
- LLMã£ã¦ä½•ã«ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã®ã‚µãƒ¼ãƒ™ã‚¤
	- https://x.com/dmvaldman/status/1705350469177295273?s=20
	- ï¼‘ä½ï¼šãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ã‚¨ãƒ©ãƒ¼ã¨è§£æ¶ˆæ³•ã«ã¤ã„ã¦ã€ï¼’ä½ï¼šAIã®ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢ã«ã¤ã„ã¦ã®è³ªå•ã€ï¼“ä½ï¼šæ—…è¡Œé–¢ä¿‚ã€ï¼”ä½ï¼šãƒ†ã‚­ã‚¹ãƒˆè¦ç´„ã¨ã‹æ”¹å–„ã€ï¼•ä½ï¼šãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥ç«‹æ¡ˆ
- GPT-3.5-Turbo-Instruct
	- https://chatgpt-lab.com/n/n2ed70597dfbf
	- æ—¢å­˜ã®ã€ŒGPT-3.5-Turboã€ã¨ã¯é•ã£ã¦ãƒãƒ£ãƒƒãƒˆã«ç‰¹åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ãŒåºƒç¯„ãªè‡ªç„¶è¨€èªå‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’æ‰±ã†ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™
	- OpenAIã®ãƒ†ã‚¹ãƒˆã§ã¯ã€175Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤GPTãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã€1.3Bã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤InstructGPTãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒã€100å€å°ã•ã„ã«ã‚‚ã‹ã‹ã‚ã‚‰ãšã€äººã€…ã«å¥½ã¾ã‚Œã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹

## 9/19

GPT-4ã‚’æ´»ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã¤ãã£ã¦ã€ä»–ã®ï¼¬ï¼¬ï¼­ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨ã‹ã€è‰²ã€…å‡ºã¦ã„ã‚‹ãŒã€Metaã‚„AppleãŒGPT-4è¶Šãˆã®LLMã‚’æ¥å¹´ã«å‘ã‘é–‹ç™ºä¸­ã€‚AppleãŒå‡ºé…ã‚Œã¦ã„ã‚‹ã®ã¯ã€è‡ªå‹•é‹è»¢ã¨ã‹ãã£ã¡ã«ãƒªã‚½ãƒ¼ã‚¹ã‚’å‰²ã‹ã‚Œã¦ã„ã‚‹ã‹ã¨ã‚‚ã€ã§ã‚‚M2ã‚‚ã£ã¦ã„ã‚‹ã—ã€ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯ã‚ã‚‹ã€‚ã‚ã»ãªSiriã®ä»£ã‚ã‚Šã«ãªã‚‹ã®ã‹ï¼Ÿã€‚RestGPTã¯ã€ReActã®ç™ºå±•å½¢ã€ã€ŒAPIã®ç†è§£ã€ã£ã¦ã®ãŒã§ãã‚‹ã‚‰ã—ã„ã€‚ã‚„ã£ã±ã‚Šä¼æ¥­åˆ©ç”¨ãªã‚‰ã°ã€RAG(Retrieval Augmented Generation)é–¢ä¿‚ã§ã€å…ƒã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒ£ãƒ³ã‚­ãƒ³ã‚°ã®ä»•æ–¹ã¨ã‹ã€ãƒ™ã‚¯ãƒˆãƒ«ï¼¤ï¼¢ã®é¸ã³æ–¹ã¨ã‹ã€ã‚¹ã‚¯ãƒ©ãƒƒãƒã‹ã‚‰ã®RAGã®ä½œæˆã¨ã‹ã€åœ°é“æ´»å‹•ã‚‚æ‹¾ã£ã¦ã¾ã™ã€‚AstroLLaMAã€ä»Šå¾Œæ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã‚„åˆ†é‡ã«ç‰¹åŒ–ã—ãŸLLMãŒã©ã‚“ã©ã‚“ã§ãã¦ãã‚‹ã‹ã‚‚ã€‚LiteLLMã£ã¦ã„ã†LLMã®æŠ½è±¡åŒ–ã‚’ä½¿ã†ã¨ã€ã‚¢ãƒ—ãƒªã‚³ãƒ¼ãƒ‰ãŒå†åˆ©ç”¨ã§ãã‚‹ã®ã‹ã€ä½œã£ãŸäººå¤©æ‰ã€‚GPT4ã«ã‚ˆã‚‹ç”Ÿç”£æ€§å‘ä¸Šã«ã†ã„ã¦ã®å®šé‡è©•ä¾¡ã€è³‡æ–™ã¨ã—ã¦è‰²ã€…ä½¿ãˆã‚‹ãªã€‚ä»æ•™å¯¾è©±AIã£ã¦ã€è–äººã‚’ã©ã‚Œã ã‘å¾©æ´»ã•ã›ã¦ã‚‚å¹¸ã›ã«ãªã‚Œãªã„æ°—ãŒã™ã‚‹ã€‚ãã£ã¨æ•…äººã®ChatBotä½œæˆã‚µãƒ¼ãƒ“ã‚¹ã£ã¦è‘¬å„€æ¥­ç•Œã§ã™ãã«ã§ã‚‚å‡ºã¦ããã†ã ã€‚ã„ã‚„ã€2021å¹´ã«ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒ[ç‰¹è¨±åŒ–ã—ã¦ã„ãŸ](https://edition.cnn.com/2021/01/27/tech/microsoft-chat-bot-patent/index.html)ã€‚ã€‚


- Metaã€GPT-4ã¨åŒç¨‹åº¦ã®æ€§èƒ½ã‚’ç›®æŒ‡ã™ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’è¨ˆç”»
	- https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple
	- AIãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒƒãƒ—ã‚’è²·ã„é›†ã‚ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‚’æ§‹ç¯‰
	- 2024å¹´ã®æ—©ã„æ™‚æœŸã«æ–°ã—ã„å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚’é–‹å§‹ã™ã‚‹äºˆå®š
	- ä¼æ¥­ãŒAIãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã«ã€å†ã³ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç„¡æ–™ã«ã™ã‚‹ã‚ˆã†åƒãã‹ã‘ã¦ã„ã‚‹
- Fine-tuning to Memorize Knowledge
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_knowledge.html
	- GPT4ã§ã€å†…éƒ¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«å¯¾ã™ã‚‹ã€Q&Aã‚’ç”Ÿæˆã•ã›ã¦ã“ã‚Œã‚’ã¤ã‹ã£ã¦ã€LLMã‚’ãƒ•ã‚¡ã‚¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹è©±ã€‚
	- â€œbake in knowledgeâ€ã¨å‘¼ã¶ã‚‰ã—ã„ã€‚
- OpenIntepreterã‚’ä½¿ã£ã¦ã„ã‚‹ã¨ã€OpenAIã®APIã‚³ãƒ¼ãƒ«ã§10ãƒ‰ãƒ«ãŒä¸€ç¬ã§æº¶ã‘ã‚‹ã€‚ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«åºæ¥ ã•ã‚“ï¼‰
	- https://x.com/masanork/status/1701381113506329083?s=20
	- ã¤ã¾ã‚Šã€ChatGPT Plusã®æœˆé¡èª²é‡‘ãŒæ°—å‰ã„ã„ã“ã¨ã«ãªã£ã¦ã„ã‚‹ã€‚
-  RestGPT: Connecting Large Language Models with Real-World RESTful APIs
	- https://restgpt.github.io/
	- ReActã®ç™ºå±•å½¢ã‹ã€ã€
	- https://zenn.dev/carnot/articles/7f87b613a0a637
		- **è¨€èªã®ã¿ã®æŒ‡ç¤ºã‹ã‚‰è¤‡æ•°ã®APIã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒå¯èƒ½**
		- RestGPTã§ã¯ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ»APIã®ç†è§£ãƒ»APIã®é¸æŠã‚’ãã‚Œãã‚Œã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒç‹¬ç«‹ã§è¡Œã†ãŸã‚ã€è¤‡é›‘ãªãƒ¦ãƒ¼ã‚¶è¦æ±‚ã«ã‚‚æŸ”è»Ÿã«å¯¾å¿œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã£ã¦ã„ã¾ã™ã€‚
- æ¥å¹´ã«ã¯GPT-4ã‚’ä¸Šå›ã‚‹èƒ½åŠ›ã‚’æŒã¤ã¨ã•ã‚Œã‚‹ï¼“ã¤ã®ãƒ¢ãƒ‡ãƒ«
	- â‘  OpenAI: GPT-4.5/GPT5 
	- â‘¡ Google: Gemini 
	- â‘¢ Apple: Ajax
	- Apple is reportedly spending â€˜millions of dollars a dayâ€™ training AI
	- https://www.theverge.com/2023/9/6/23861763/apple-ai-language-models-ajax-gpt-training-spending
- ä»æ•™å¯¾è©±AIã®å¤šæ§˜åŒ–ã«æˆåŠŸâ€•è¦ªé¸ãƒœãƒƒãƒˆã¨è©è–©ãƒœãƒƒãƒˆã®å¢—ç”£â€•(äº¬å¤§ï¼‰
	- https://www.kyoto-u.ac.jp/ja/research-news/2023-09-12-0
	- ç”Ÿæˆç³»AIã€ŒChatGPT 4ã€ã¨å®—æ•™ã‚’æ›ã‘åˆã‚ã›ãŸæ–°å‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€Œè¦ªé¸ãƒœãƒƒãƒˆã€ã¨ã€Œä¸–è¦ªãƒœãƒƒãƒˆã€ã‚’å…±åŒé–‹ç™ºã—ã€ä»æ•™å¯¾è©±AIã®å¤šæ§˜åŒ–ã«æˆåŠŸã—ã¾ã—ãŸã€‚
	- [ä¼šè©±äº‹ä¾‹](https://www.itmedia.co.jp/news/articles/2309/14/news083.html)ãŒã€åœ°ç„ã«ã—ã‹è¦‹ãˆãªã„ã®ã¯æ°—ã®ã›ã„ï¼Ÿ
- ãƒªã‚¯ãƒ«ãƒ¼ãƒˆã«ãŠã‘ã‚‹æ•°ç†æœ€é©åŒ–ã® æ´»ç”¨äº‹ä¾‹ã¨ç”£å­¦é€£æºã®å–ã‚Šçµ„ã¿
	- https://speakerdeck.com/recruitengineers/rikurutoniokerushu-li-zui-shi-hua-no-huo-yong-shi-li-tochan-xue-lian-xi-noqu-rizu-mi
	- ä¼æ¥­ã«ãŠã‘ã‚‹æ•°ç†æœ€é©åŒ–å°‚é–€ã‚°ãƒ«ãƒ¼ãƒ—ã£ã¦ã€å¤§å¤‰ãªã®ã‚ˆã­ã€‚
-  ç”ŸæˆAIãƒ–ãƒ¼ãƒ ã§å¤šç™ºã®å¯èƒ½æ€§ã€€ã€ŒPoCè²§ä¹ã€
	- https://forbesjapan.com/articles/detail/65744/page2
	- ã€Œç”ŸæˆAIã§ä½•ã‹ãƒ“ã‚¸ãƒã‚¹ã‚’ä½œã£ã¦ã¿ã¦ã€ã¨ä¸Šå±¤éƒ¨ãŒä¸¸æŠ•ã’ã—ã€æˆæœãŒå‡ºãªã„ã¾ã¾äººä»¶è²»ãŒã‹ã•ã‚€ã€ã‚†ã‚‹ã‚„ã‹ãªPoCè²§ä¹ãŒé »ç™ºã™ã‚‹ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚
	- ã¾ã‚ã€ç”ŸæˆAIã«é™ã‚‰ãªã„ã‚ã‘ã ãŒã€‚ã€‚
- Calls out of chaos: the adaptive significance of nonlinear phenomena in mammalian vocal production
	- https://www.sciencedirect.com/science/article/abs/pii/S0003347201919128
	- èµ¤å­ã®æ³£ãå£°ãŒã‚«ã‚ªã‚¹çš„ãªãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã§ã€è¤‡é›‘ã•ã¨äºˆæ¸¬ä¸å¯èƒ½æ€§ã«ã‚ˆã£ã¦è¦ªã«ç„¡è¦–ã•ã›ãªã„ã‚ˆã†ã«ã™ã‚‹é©å¿œçš„æ„ç¾©ãŒã‚ã‚‹ã‚‰ã—ã„
- è‡ªç„¶è¨€èªå‡¦ç†ã§æ‰±ã†ãƒ†ã‚­ã‚¹ãƒˆã®chunkingã«ã¤ã„ã¦
	- https://zenn.dev/hijikix/articles/f414b067e29a57
	- Adjacent Sequence Clustering
	- å…¨ä½“ã®æ–‡ç« ã‚’ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã«åˆ†å‰²ã—ãŸå¾Œã€ãƒãƒ£ãƒ³ã‚¯ã«è©°ã‚ã¦ã„ãã®ã ãŒã€ãã®éš›ã«ç›´å‰ã®ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã¨å‡¦ç†ä¸­ã®ã‚»ãƒ³ãƒ†ãƒ³ã‚¹ã®æ„å‘³çš„é¡ä¼¼åº¦ã‚’æ¯”è¼ƒã—ã¦ã€æ„å‘³ãŒé›¢ã‚Œã¦ã„ã‚‹ã‚‚ã®ã¯æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã«è©°ã‚ã‚‹
- llamaindexã®RAGä½œæˆãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼ˆãƒ­ãƒ¼ãƒ¬ãƒ™ãƒ«ï¼‰
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
	- ãƒ­ãƒ¼ãƒ¬ãƒ™ãƒ«ã¨ã„ã†ã®ã¯ã€ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–ãªå‡¦ç†ã§æ§‹æˆã™ã‚‹ã¨ã„ã†æ„å‘³ã€‚
- llamaindexã®Responseã®ä½œã‚Šæ–¹
	- Building Response Synthesis from Scratch
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/response_synthesis.html
	- promptã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã‚‹ã®ãŒç´ æ•µã€‚
- Vector databases (Part 4): Analyzing the trade-offs
	- https://thedataquarry.com/posts/vector-db-4/
	- ãƒ™ã‚¯ãƒˆãƒ«DBã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ†æã—ãŸè¨˜äº‹ã€‚æŒ¿å…¥vsèª­å–é€Ÿåº¦ã€å–ã‚Šã“ã¼ã—ï¼ˆRecallï¼‰vsãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ã€ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªvsã‚ªãƒ³ãƒ‡ã‚£ã‚¹ã‚¯ã€å…¨æ–‡æ¤œç´¢vsãƒ™ã‚¯ãƒˆãƒ«ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ç­‰ã®è¦³ç‚¹ã‹ã‚‰æ¯”è¼ƒãƒ»åˆ†æã‚’å®Ÿè³ª
- AstroLLaMA: Towards Specialized Foundation Models in Astronomy
	- https://arxiv.org/abs/2309.06126
	- ç‰¹å®šåˆ†é‡ã«ç‰¹åŒ–ã—ãŸLLMãŒå¤§é‡ç™ºç”Ÿã™ã‚‹äºˆæ„Ÿã€‚
- æ±äº¬éƒ½ã® ã€Œæ–‡ç« ç”ŸæˆAIåˆ©æ´»ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€
	- https://www.metro.tokyo.lg.jp/tosei/hodohappyo/press/2023/08/23/14.html
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å…·ä½“ä¾‹ã‚‚è±Šå¯Œã§ã‚ã‹ã‚Šã‚„ã™ã„
- llamaindexãŒLiteLLMã‚’ã‚µãƒãƒ¼ãƒˆã€ï¼‹ï¼‘ï¼ï¼ã®LLï½ãŒåˆ©ç”¨å¯èƒ½ã«ï¼Ÿï¼Ÿ
	- https://gpt-index.readthedocs.io/en/stable/examples/llm/litellm.html
	-  (OpenAI, Cohere, AnthropicAI, huggingface, etc.)ã«å¯¾ã—ã¦åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã‚’æä¾›ã€‚
	- ã¨ã„ã†ã‹ã€LiteLLMã™ã”ã„ãªã€‚
- Announcing the Preview of OpenAI Whisper in Azure OpenAI service and Azure AI Speech
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/announcing-the-preview-of-openai-whisper-in-azure-openai-service/ba-p/3928388
	- Azure OpenAIã‚µãƒ¼ãƒ“ã‚¹ãŠã‚ˆã³Azure AI Speechã§ã®OpenAI Whisperã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç™ºè¡¨ã—ã¾ã—ãŸ
- Discover the LLMs
	- https://llm.extractum.io/
	- LLM ã® VRAM ã‚„ Context Len ãŒä¸€è¦§è¡¨ç¤ºã§ãã¦ä¾¿åˆ©
- BCGã¨ãƒãƒ¼ãƒãƒ¼ãƒ‰ã‚„MITç­‰ã«ã‚ˆã‚‹GPT4ã‚’ä½¿ç”¨ã—ãŸã‚¿ã‚¹ã‚¯å®Ÿé¨“
	-  Centaurs and Cyborgs on the Jagged Frontier
	- https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged
	- BCGã®ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°758åã§å®Ÿé¨“ 
	- 18ç¨®é¡ã®ã‚³ãƒ³ã‚µãƒ«ã‚¿ã‚¹ã‚¯ãŒå¯¾è±¡ 
	- AIã‚’ä½¿ç”¨ã—ãŸã‚³ãƒ³ã‚µãƒ«ã¯ ã€12.2ï¼…å¤šãä»•äº‹ã‚’çµ‚ãˆã€ 25.1ï¼…æ—©ãä»•äº‹ã‚’å®Œäº†ã—ã€ 40ï¼…é«˜ã„å“è³ª
-  Optimizing LLMs From a Dataset Perspective
	- https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html
	- LLMsã®æœ€é©åŒ–ã«ã¤ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å´é¢ã‹ã‚‰ã¾ã¨ã‚ãŸãƒ–ãƒ­ã‚°ã€‚äººæ‰‹ã§é«˜å“è³ªãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ã‚„ã€LLMã‹ã‚‰å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—ãªã©ã€ã„ãã¤ã‹ã®å´é¢ãŒç°¡æ½”ã«ã¾ã¨ã¾ã£ã¦ã„ã‚‹
- InstaGraph
	- https://github.com/yoheinakajima/instagraph
	- ä»»æ„ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰çŸ¥è­˜ã‚°ãƒ©ãƒ•ä½œã‚Œã‚‹ã‚‰ã—ã„ã€‚
	- ä¾‹ï¼šhttps://x.com/yoheinakajima/status/1701351068817301922?s=20

## 9/11

8/23ã«å…¬é–‹ã•ã‚ŒãŸGPT-3.5-turboã®fine-tuning APIã€RAGã¨ã®æ¯”è¼ƒã€è¨¼åˆ¸å ±å‘Šæ›¸ã®Q&Aã‚¢ãƒ—ãƒªã®å…·ä½“ä¾‹ã€ãªã©ã€é¢ç™½ã„è¨˜äº‹ãŒãŸãã•ã‚“å‡ºã¦ããŸã€‚Open Interpreterã‚‚ç›¸ã‚‚å¤‰ã‚ã‚‰ãšç†±ã„ã€‚ãƒ‡ã‚¸ã‚¿ãƒ«åºã®ChatGPTã®æ¥­å‹™åˆ©ç”¨ãƒãƒ³ã‚ºã‚ªãƒ³ã€ã„ã„ãªã€ã“ã†ã„ã†ãƒªãƒ†ãƒ©ã‚·ãƒ¼ã‚’æŒã¦ã‚‹äººãŒå¢—ãˆãªã„ã¨ã€‚ã€‚å¤§è¦æ¨¡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»è¡Œå‹•ãƒ¢ãƒ‡ãƒ«ï¼ˆLCBMï¼‰ã£ã¦ã€è¨˜å·æ¥åœ°å•é¡Œã«ã•ã‚‰ã«è¿‘ã¥ã“ã†ã¨ã—ã¦ã„ã‚‹ã®ã‹ï¼ŸLLMã‚’ã¤ã‹ã£ãŸæ§˜ã€…ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œã‚Šæ–¹ã€ã„ã‚ã‚“ãªãƒ‡ãƒ¼ã‚¿å°‚é–€ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãŸãã•ã‚“ãã‚ã£ã¦ãã‚‹ã¨ã€ãã‚ãã‚OrchestratorãŒå¿…è¦ã‹ãªã€‚**Production-Ready LLM Applications**ã£ã¦ã®ã¯å¿…èª­ãªã‚¹ãƒ©ã‚¤ãƒ‰ã§ã™ã­ã€‚ICML2023ã®ã¾ã¨ã‚ã‚‚ã‚ã£ãŸã€‚RAGã‚’å¯¾è±¡ã¨ã—ãŸLLMã®æ¯”è¼ƒã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãªã£ã¦ã‚ã‚ŠãŒãŸã„ã€‚ChatGPTã®è¤‡æ•°å‡ºåŠ›ã¨ã‹ã€æ€§èƒ½ãŒè½ã¡ãŸã®ã§ã¯ï¼Ÿã¨ã„ã†ç–‘æƒ‘ãªã©ã€ä½•ãŒèµ·ãã¦ã„ã‚‹ã®ã‹ã€èµ·ã“ãã†ã¨ã—ã¦ã„ã‚‹ã®ã‹ã€‚

-  æ±äº¬å¤§å­¦ç†å­¦éƒ¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹2023 è¬›æ¼”ã€Œç”Ÿæˆå‹AIã®æ•°ç†ã¨å€«ç†ã€ä½è—¤ä¸€èª æ•™æˆ
	- https://www.youtube.com/watch?v=n6NDlgJVug8&t=5s
-  Mustafa Suleyman on getting Washington and Silicon Valley to tame AI
	- https://80000hours.org/podcast/episodes/mustafa-suleyman-getting-washington-and-silicon-valley-to-tame-ai/
	- DeepMindã®å…±åŒå‰µæ¥­è€…ã§ã€ä¸–ç•Œæœ€é«˜æ°´æº–ã®AIã‚¹ãƒ‘ã‚³ãƒ³ã‚’æ§‹ç¯‰ä¸­ã®AIé–‹ç™ºä¼šç¤¾ã€ŒInflection AIã€ã®è¨­ç«‹è€…ã§ã‚‚ã‚ã‚‹ã‚¹ãƒ¬ã‚¤ãƒãƒ³æ°ã«ã‚ˆã‚Œã°ã€ä»Šå¾Œ18ãƒ¶æœˆç¨‹åº¦ã§GPT-4ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸè¨ˆç®—å›æ•°ã®10å€ã€œ100å€ãŒAIãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚Œã€æ¬¡ã®3å¹´ç¨‹åº¦ã§GPT-4ã®1000å€ã®è¨ˆç®—å›æ•°ãŒå­¦ç¿’ã«ä½¿ã‚ã‚Œã‚‹ã ã‚ã†ã€ã¨ã®ã“ã¨
- LangChain Cheat Sheet
	- https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html
- llamaindexã‚ˆã‚Šã€Summary Index(æ—§List Index)ã®ç´¹ä»‹
	- https://gpt-index.readthedocs.io/en/stable/core_modules/data_modules/index/index_guide.html#summary-index-formerly-list-index
- AI Agents â€“ Build and Host LLM Apps At Scale
	- LLMã‚’æ´»ç”¨ã•ã„ãŸæ§˜ã€…ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä½œã‚Šæ–¹ã«ã¤ã„ã¦ã®è¨˜äº‹ã€ãªã‚‹ã»ã©
	- https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/
- Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior
	- https://huggingface.co/papers/2309.00359
	-  **å¤§è¦æ¨¡ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»è¡Œå‹•ãƒ¢ãƒ‡ãƒ«ï¼ˆLCBMï¼‰ã¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»è¡Œå‹•ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆCBCï¼‰**ï¼šæœ¬æ–‡æ›¸ã§ã¯ã€è¡Œå‹•ãƒˆãƒ¼ã‚¯ãƒ³ã‚’LLMã®è¨“ç·´ã«å†å°å…¥ã™ã‚‹åˆæœŸçš„ãªè©¦ã¿ã‚’è¡Œã†ã€‚LCBMã¨å‘¼ã°ã‚Œã‚‹æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç†è§£ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦LLMã¨åŒç­‰ã®æ€§èƒ½ã‚’ç¤ºã™ã¨ã¨ã‚‚ã«ã€è¡Œå‹•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€è¡Œå‹•ç†è§£ã€è¡Œå‹•ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œã¨ã„ã£ãŸèƒ½åŠ›ã‚‚æŒã¤ã€‚ã•ã‚‰ã«ã€LCBMã®ç ”ç©¶ã‚’ä¿ƒé€²ã™ã‚‹ãŸã‚ã«ã€ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚¿ãƒ¼ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€å—ä¿¡è€…è¡Œå‹•ã‚’å«ã‚€æ–°ã—ã„ã‚³ãƒ¼ãƒ‘ã‚¹ã§ã‚ã‚‹CBCã‚’å…¬é–‹ã™ã‚‹ã€‚
- ChatGPTã‚’æ¥­å‹™ã«çµ„ã¿è¾¼ã‚€ãŸã‚ã®ãƒãƒ³ã‚ºã‚ªãƒ³
	- ãƒ‡ã‚¸ã‚¿ãƒ«åºãŒä¸€èˆ¬å…¬é–‹ã—ã¦ã„ã‚‹ChatGPTã®å…¥é–€
	- https://www.digital.go.jp/assets/contents/node/information/field_ref_resources/5896883b-cc5a-4c5a-b610-eb32b0f4c175/82ccd074/20230725_resources_ai_outline.pdf
	- ãªã‹ãªã‹ã®ã‚„ã‚Šæ‰‹ãŒæ›¸ã„ã¦ã„ã‚‹ã€ã“ã“ã¾ã§è©¦è¡Œã§ãã‚‹äººã¯å°‘ãªã„ã®ã§ã¯ï¼Ÿï¼Ÿ
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ›¸ãæ–¹ã®ã‚³ãƒ„
		- ã§ãã‚‹é™ã‚Šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ˜ç¢ºã«ã—ã¦æ›¸ãã“ã¨
		- GPTã®ç†è§£åº¦(?)ã‚’ç¢ºèªã—ãªãŒã‚‰é€²ã‚ã‚‹
		- æœ€åˆã¯ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’èª­ã‚€ã‚ˆã‚Šã€ã¾ãšè‡ªåˆ†ã§ã‚„ã£ã¦ã¿ã¦æ„Ÿè¦šã‚’ã¤ã‹ã¿ã“ã¨ã‚’æ¨å¥¨
- æœ€è¿‘ã®LLMã®å­¦ç¿’æ³•ã®ã¾ã¨ã‚ - SFTãƒ»RLHFãƒ»RAGã€€by npakaã•ã‚“ã€
	- https://note.com/npaka/n/n862786604dc3
	- ã¨ã‚Šã‚ãˆãšã€ã©ã‚Œã ã‘çŸ¥ã£ã¦ã‚‹ï¼Ÿã ã‘ã§ã‚‚ãƒªãƒˆãƒã‚¹è©¦é¨“ç´™ã«ãªã‚‹ã€ã‚€ã‚ã‚“ç§ã¯RAGæ´¾
	- SFT : Supervised Fine-Tuning
	- RLHF : Reinforcement Learning from Human Feedback
	- RAG : Retrieval Augmented Generation
- LangChain ã‚’ä½¿ã£ãŸRAGã‚’ Elyza 7b instruct ãƒ¢ãƒ‡ãƒ«
	- https://note.com/alexweberk/n/n3cffc010e9e9
	- ç„¡æ–™ã®T4ã§ã¯ãƒ¡ãƒ¢ãƒªãƒ¼ã‚ªãƒ¼ãƒãƒ¼ã§å‹•ã‹ãªã„ã‚“ã ãŒã€‚ã€‚ã€‚
- SEC Insights
	- llamaindexã‚’æ´»ç”¨ã—ã¦ã€ç±³å›½è¨¼åˆ¸å–å¼•å§”å“¡ä¼šã¸ã®å ±å‘Šæ›¸(SEC-10)ã«ãŸã„ã™ã‚‹Q&Aã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ä¾‹
	- https://github.com/run-llama/sec-insights
	- https://www.secinsights.ai/
-  Streamlit å…¥é–€  by npakaã•ã‚“
	- https://note.com/npaka/n/n29b5e8088fe5
	- ã€ŒStreamlitã€ã¯ã€æ©Ÿæ¢°å­¦ç¿’ãŠã‚ˆã³ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ãŸã‚ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç°¡å˜ã«ä½œæˆã—ã¦å…±æœ‰ã§ãã‚‹Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª
	- ã‚‚ã†ã¡ã‚‡ã£ã¨ã©ã†ã«ã‹ãªã‚‰ã‚“ã®ã‹ï¼Ÿ
- **Production-Ready LLM Applications**
	- llamaindexã®CEOã‚ˆã‚Šã€
	- https://docs.google.com/presentation/d/1uzhz1aFWbyXSrWBzQ1FPQWtVjMgJqAYGoGoVzEnNmAg/edit#slide=id.p
		-  Fine-tuning: LLMs + embeddings
		-  Better Data + Retrieval Techniques for Production RAG
- ELYZA-7bã¯ã€M1 MacBook Airã§ã‚‚ã‚µã‚¯ã‚µã‚¯å‹•ãã‚‰ã—ã„
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf/blob/main/README.md
- ã‚„ã£ã±ã‚ŠOpenInterpreterãŒç†±ã„
	- https://github.com/KillianLucas/open-interpreter
- LLMã‚’ãƒ›ã‚¹ãƒˆã™ã‚‹AnyScaleã®llamaindexã§ã®åˆ©ç”¨ä¾‹
	- https://gpt-index.readthedocs.io/en/latest/examples/llm/anyscale.html
	- run + finetune open-source LLMs through an API
	- ãã†ã„ã†ãƒ“ã‚¸ãƒã‚¹ãŒã§ãã‚‹ã®ã‹ã€‚ã€‚
-  Fine-Tuning GPT-3.5 RAG Pipeline with GPT-4 Training Data
	- https://betterprogramming.pub/fine-tuning-gpt-3-5-rag-pipeline-with-gpt-4-training-data-49ac0c099919
	- ã©ã†ã‚‚ã€8/23ã«OpenAIãŒGPT-3.5-turboã®fine-tuning APIã‚’å…¬é–‹ã—ã¦ã€å³åº§ã«llmaindexãŒã“ã‚Œã«å¯¾å¿œã—ãŸã‚‰ã—ã„
	- ã˜ã‚ƒã‚ã€Q&Aã‚¢ãƒ—ãƒªã‚’ä½œã‚‹ã®ã«ã€RAGã¨Fine-tuningã©ã¡ã‚‰ãŒé«˜æ€§èƒ½ã‹ï¼Ÿã¨ã„ã†ã“ã¨ã¸ã®è€ƒå¯Ÿè¨˜äº‹
	- ã“ã¡ã‚‰ã¯ã€llamaindexã‚’ã¤ã‹ã£ãŸGPT-3.5-turboã®fine-tuningã®colab
		- https://colab.research.google.com/drive/1NgyCJVyrC2xcZ5lxt2frTU862v6eJHlc?usp=sharing
- Hierachical Agent	
	- å¯¾è±¡ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ãŒéšå±¤æ§‹é€ ã§ã‚ã‚‹ã‚ˆã†ãªå ´åˆã®Q&Aã®ä½œã‚Šæ–¹ã€‚
	- https://colab.research.google.com/drive/1qIb09SyuLeiwGy_FGcRcQpM78yQ2p0_3?usp=sharing
- Discover LlamaIndex: Custom Tools for Data Agent
	- https://www.youtube.com/watch?v=lcuL6Gqw_-g
- ã€é€Ÿå ±ã€‘OpenAI APIã§GPT-3.5-turboãŒfine-tuningã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼
	- https://dev.classmethod.jp/articles/openai-gpt35turbo-fine-tuning/
	- å­¦ç¿’ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã¯æœ€å°10å€‹å¿…è¦ã§ã€50ï½100å€‹ã§æ˜ç¢ºãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã‚‹
	- gpt-3.5-turboã§fine-tuningãŒåˆ©ç”¨å¯èƒ½ã«
	- gpt-3ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹babbage-002ã¨davinci-002ã‚‚æ–°ã—ã„fine-tuningã§ã‚µãƒãƒ¼ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«ã‚‚GPT baseã¨ã„ã†æ‰±ã„ï¼‰
- ã‚°ãƒ©ãƒ•ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã® 2023å¹´ã¾ã¨ã‚ (ICML2023)
	- è»½é‡ Transformer ã®ä»‹å…¥ã‚„ Diffusion for Molecules ãªã©ã®å®Ÿä¸–ç•Œåˆ©ç”¨ã€å¹¾ä½•å­¦çš„ãªåˆ©ç”¨ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹
	- https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc
- Open Inerpreterã®åˆ©ç”¨ä¾‹ã€ã€Œnikkei225ã®10å¹´åˆ†ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã€ã¨æ»…å…¥ã‚Œã™ã‚Œã°ã‚ã¨ã¯è‡ªå‹•ã§ã€ã€ã€
	- https://twitter.com/NuCode/status/1700679106814501132?s=20
- ChatGPTãŒã€å¯èƒ½æ€§ã®ã‚ã‚‹ç­”ãˆã‚’è¤‡æ•°ã¦ã„ã˜ã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã€RLHFã‚„ã‚‰ã›ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã®ã‹ã¨è©±é¡Œã«
	- https://twitter.com/GrantSlatton/status/1700662574315090351?s=20
- LLMã®è©•ä¾¡ã€ç‰¹ã«Retrieval Augmented Generation (RAG) ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®OSSãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ragas
	- https://github.com/explodinggradients/ragas
- Agent deconstructedã«ã€llmaindex agentãŒçµ±åˆã•ã‚ŒãŸï¼Ÿ
	- https://github.com/shoggoth13/agents-deconstructed/blob/main/notebooks/react_chat.ipynb
	- ReActãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã‹ã€‚ã€‚ã€ã„ã‚ã‚“ãªindexã‚’ã‚‚ã¤LLMåŒå£«ãŒä¼šè©±ã—ã¦å•é¡Œè§£æ±ºã€‚ã€‚
- ã€ãƒ‡ãƒ¢ä»˜ãã€‘Embeddingsã§ç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã‚’ChatGPTã«ç†è§£ã•ã›ã‚‹
	- https://corp.langcore.org/media/embeddings
	- LangCore SaaSã‚’ä½¿ã£ã¦ã‚¤ãƒ³ãƒ•ãƒ©ä¸è¦ã§æ‰‹è»½ã«Embeddingsã‚’æ´»ç”¨ã—ãŸç‹¬è‡ªãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨ã€ã‚‰ã—ã„

## 9/4

Googeã‹ã‚‰GPT-4å¯¾æŠ—ã®GeminiãŒç™ºè¡¨ã€GPT-4 ã® 2023 å€ã®è¨ˆç®—èƒ½åŠ›ã‚’æŒã¤ï¼Ÿã€‚LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–¢ä¿‚ã§ã€æ§˜ã€…ãªç´¹ä»‹ãŒã‚ã‚‹ã€‚llamaindexå‘¨ã‚Šã®è¨˜äº‹ãŒå¤šã„ãŒã€ãã‚Œã ã‘RAG(Retrieval-Augmented Generation)ã£ã¦éœ€è¦ãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã‹ã€‚Embeddingã‚‚ã—ã£ã‹ã‚Šæ€§èƒ½è©•ä¾¡ã‚„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¨æ€§èƒ½ãŒã‚ãŸã‚‹ã€‚llamaindexã§Q&Aã®æ€§èƒ½ã‚’ä¸Šã’ã‚‹ãŸã‚ã®TipsãŒè©³ã—ãæ›¸ã„ã¦ã‚ã‚‹ã€ã“ã‚Œã¯å½¹ç«‹ã¤ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã®è©¦è¡Œã‚‚ç†±ã„ã€ãªã‚“ã¨Code interpreterã‚‚ã©ãã‚‚å‹•ãã¨ã„ã†ã€‚æœ€è¿‘ã®LLMã§ã¯ã€ELYZAãŒä¸€ç•ªã®æ¨¡æ§˜(by shi3z)ã€‚ç†è«–é–¢ä¿‚ã§ã¯ã€transformerã«ãŠã‘ã‚‹è‡ªå·±æ³¨æ„ã¯SVMã¨ç­‰ä¾¡ãªã®ã‹ï¼Ÿã€ç¢ºç‡éç¨‹ã®æ–°åˆŠã‚‚æ°—ã«ãªã‚‹ã€‚

- LLMã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã§ ä½•ãŒã§ãã¦ ä½•ãŒã§ããªã„ã®ã‹
	- https://note.com/npaka/n/nec63c01f7ee8
- code llama ãŒhuggingfaceã®chatã«ç™»å ´
	- https://huggingface.co/chat/
- Llamaã§ã€å‡ºåŠ›ã‚’æŒ‡å®šã™ã‚‹ãŸã‚ã®grammar-based sampling
	- https://python.langchain.com/docs/integrations/llms/llamacpp#grammars
- Google ã€ŒGeminiã€ã¯ã€ChatGPT-4 Enterprise ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ç›´æ¥ã®ç«¶åˆç›¸æ‰‹
	- https://www.theinformation.com/articles/the-forced-marriage-at-the-heart-of-googles-ai-race
	- GPT-4 ã® 2023 å€ã®è¨ˆç®—èƒ½åŠ›ã‚’æŒã¤
- llamainexã§embeddingã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html
-  è«–æ–‡ç´¹ä»‹ / Llama 2: Open Foundation and Fine-Tuned Chat Modelsã€€by NTTè¥¿ç”°ã•ã‚“
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
-  ã”å®¶åº­ç”¨LLMã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã™ã‚‹æ–¹æ³•
	- https://note.com/shi3zblog/n/n66ae41af7c64
	- "elyza/ELYZA-japanese-Llama-2-7b-instruct"ã€€åˆ©ç”¨
-  LlamaIndexã®æ€§èƒ½å‘ä¸Šã®ãŸã‚ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚¬ã‚¤ãƒ‰ by npaka
	- https://note.com/npaka/n/n33e28a9e1409
-  Discover LlamaIndex: Introduction to Data Agents for Developers
	- https://www.youtube.com/watch?v=GkIEEdIErm8
	- first-ever video tutorial on LlamaIndex Data Agents
-  ChatGPT vs BERTï¼šã©ã¡ã‚‰ãŒæ—¥æœ¬èªã‚’ã‚ˆã‚Šç†è§£ã§ãã‚‹ã®ã‹ï¼Ÿ
	- https://fintan.jp/page/9126/
-  LlamaIndex ã® QAãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ã¨ Refineãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
	- https://note.com/npaka/n/ne878095d5bda
- llama2-13b-128kã€è«–æ–‡ã‚’å…¨éƒ¨ç†è§£ã—ã¦è¦ç´„ã‚’åãå‡ºã™æ–¹æ³•
	- https://gist.github.com/alfredplpl/33fd6dd6d623d4da959f1ca8aabc88fe
- ã€Œãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã®çµ±è¨ˆå­¦å…¥é–€ã€
	- http://www.kunitomo-lab.sakura.ne.jp/2021-3-3Open(S).pdf
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘text-generation-webUIã®APIæ©Ÿèƒ½ã‚’è©¦ã™
	- https://note.com/bakushu/n/na4e51d377ae7
	- LLMç”¨ã®ã‚¦ã‚§ãƒ–UIã§ã‚ã‚‹text-generation-webUIã«APIæ©Ÿèƒ½ãŒä»˜å±ã—ã¦ã„ã‚‹ã®ã§ã€ã“ã‚Œã‚’ä½¿ã£ã¦Exllamaï¼‹GPTQã®APIã‚’è©¦ã—ã¦ã¿ãŸã€‚
- æœ€è¿‘ã®LLMã®æ€§æ ¼ by shi3z
	- https://twitter.com/madyagi/status/1697949115190255951?s=20
	- ELYZAãŒè‰¯ã„ã¿ãŸã„ã€‚
-  Transformers as Support Vector Machines
	- https://arxiv.org/abs/2308.16898
- fine-tuned a gpt-3.5 ReAct agent to be better at chain-of-thought
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/react_agent/react_agent_finetune.html
-  æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®ç¢ºç‡éç¨‹å…¥é–€
	- https://www.ohmsha.co.jp/book/9784274231087/
-  ãƒ­ãƒ¼ã‚«ãƒ«PCã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ä¸Šã§LLMç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã‚‹Open Interpreterã‚’è©¦ã™
	- https://note.com/hamachi_jp/n/n05ae28b76d9d
	- ChatGPTã®ã‚³ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼ï¼ˆAdvanced Data Analysisï¼‰ã¨åŒæ§˜ãªæ©Ÿèƒ½ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œå¯èƒ½ãª Open Interpreter 
	- llamaã«å·®ã—æ›¿ãˆã‚‹ã“ã¨ã‚‚å¯èƒ½
- 

## 8/28

å…ˆé€±ç™ºè¡¨ã•ã‚ŒãŸã€æ¾å°¾ç ”ã®â€œWeblab-10Bâ€ã«å¯¾ã™ã‚‹é‡å­åŒ–ã‚„ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã®å®Ÿè¡Œã‚‚èŠ±é–‹ããŒã€ã‚„ã£ã±ã‚Šä»Šé€±ã¯ãƒ¡ã‚¿ã«ã‚ˆã‚‹Code Llamaã®ç™ºè¡¨ãŒãƒã‚¤ãƒ³ãƒˆã«ãªã£ã¦ã„ã‚‹ã€‚
ã€ŒLLM ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹æ¨è«–ã€çš„ãªè€ƒãˆæ–¹ã£ã¦LLMã‚’ã¤ã‹ã£ãŸã‚¢ãƒ—ãƒªä½œæˆã«ã¯çµ¶å¯¾å¿…é ˆãªè€ƒãˆæ–¹ã«ãªã‚‹ã¨æ€ã†ã€‚å“è³ªä¿è¨¼ã§ã¯ã€ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã¨ã‹ã€æ¨è«–éç¨‹ã®ã‚¬ã‚¤ãƒ‰ãŒå¿…è¦ã ã£ãŸã‚Šã€å¾—æ‰‹ä¸å¾—æ‰‹ã‚’ã¡ã‚ƒã‚“ã¨ç†è§£ã—ãŸã†ãˆã§ã‚¬ã‚¤ãƒ‰ã™ã‚‹ã¿ãŸã„ãªæ„Ÿã˜ã€‚emergentæ©Ÿèƒ½ã¨ã¯LLMã‚’å‹•ã‹ã—ã¦ã„ã¦ã€äºˆæ¸¬ã—ã¦ã„ãŸã®ã¨ã¯é•ã†æ©Ÿèƒ½ãŒå‰µç™ºã™ã‚‹ã¨ã„ã†è©±ã€æ¬§å·ï¼¡ï¼©è¦åˆ¶ã§ã‚‚è¨€åŠã•ã‚Œã‚‹ã€ä»•çµ„ã¿ã®è§£æ˜ã¨å¯¾ç­–ãŒæ€¥å‹™ã€‚llamaindexã‹ã‚‰ã€å¤–éƒ¨æ¤œç´¢ã¨çµ„ã¿åˆã‚ã›ã‚‹æ–°ã—ã„ã€Metaphoræ©Ÿèƒ½ãŒãƒªãƒªãƒ¼ã‚¹ã€‚ãªã‚“ã‹ã©ã“ã®URLã‚’è¦‹ã‚Œã°ã‚ˆã„ã‹ã®DBã‚’ã¤ã‹ã£ã¦ã‚„ã‚‹ã¿ãŸã„ãªæ„Ÿã˜ã€‚ã€‚HuggingFaceã§ã¯ã€LLMã‚’Webãƒ™ãƒ¼ã‚¹ã§ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹æ©Ÿèƒ½ãŒå…¬é–‹ã•ã‚ŒãŸã‚‰ã—ã„ã€‚çµæœã¯ãã®ã¾ã¾HuggingFaceã«ä¹—ã‚‹ã¿ãŸã„ãªãƒãƒªã€‚LLMã‚’ã¤ã‹ã£ãŸQ&Aã§ã‚ã‚‹RAGãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã€é¡ä¼¼ãƒ‡ãƒ¼ã‚¿ã‚’top-kã§ã¨ã£ã¦ãã‚‹ä»•çµ„ã¿ãŒã†ã¾ãã„ã‹ãªã„ã¨ãã®å·¥å¤«ãªã©ã€ç´å¾—æ„Ÿã‚ã‚‹ã€‚ãƒ¡ã‚¿ã‹ã‚‰Code LlamaãŒç™ºè¡¨ã€ã‚³ãƒ¼ãƒ‰ç”ŸæˆãŒã§ãã‚‹ã€‚ã•ã£ããã€é‡å­åŒ–ã•ã‚ŒãŸã‚Šã€llama.cppã§ãƒ­ãƒ¼ã‚«ãƒ«ã«å‹•ã‹ã—ãŸã‚Šã¨ã€ã‚ã£ã¨ã„ã†ã¾ã«ã€èª°ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯ã™ã”ã„ãªã€‚ç†è«–é¢ã§ã¯ã€emergentã‚¹ã‚­ãƒ«ã«é–¢ã—ã¦ã€é€šå¸¸ã®æ±åŒ–ç†è«–ã«åã™ã‚‹ã€Œã‚¹ãƒªãƒ³ã‚°ã‚·ãƒ§ãƒƒãƒˆæ±åŒ–ã€ã®æå”±ã€ï¼¬ï¼¬ï¼­ã‚’ã¤ã‹ã£ãŸå¸°ç´çš„å­¦ç¿’æ³•ã¨ã„ã†ã®ã‚‚ã€å¾“æ¥ã®äºˆæ¸¬ã‚’æ›¸ãæ›ãˆã‚‹ã‹ã€‚ï¼¡ï¼©è¦åˆ¶ã«å¯¾ã™ã‚‹ãƒ‘ãƒ–ã‚³ãƒ¡ã‚’ï¼¡ï¼©ã§åˆ†æãªã©é¢ç™½ã„ã‹ã‚‚ã€‚ã€‚

- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹è¤‡é›‘ãªã‚¹ã‚­ãƒ«ã®å‰µç™ºã«é–¢ã™ã‚‹ç†è«–ã€€A Theory for Emergence of Complex Skills in Language Models
	- https://note.com/daichi_mu/n/n72b6265b09f6
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã«ä¼´ã†æ–°ãŸãªã‚¹ã‚­ãƒ«ã®å‡ºç¾ã«ã¤ã„ã¦ã€çµ±è¨ˆçš„æ çµ„ã¿ã¨æ•°å­¦çš„åˆ†æã‚’ç”¨ã„ã¦åˆ†æã™ã‚‹ã€‚èƒ½åŠ›ãƒ¬ãƒ™ãƒ«ãŒé€šå¸¸ã®æ±åŒ–ç†è«–ã«åã™ã‚‹ã€Œã‚¹ãƒªãƒ³ã‚°ã‚·ãƒ§ãƒƒãƒˆæ±åŒ–ã€ã®æ¦‚å¿µã‚’å°å…¥
- LLM ã«ã‚ˆã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãƒ™ãƒ¼ã‚¹æ¨è«–
	- https://speakerdeck.com/smiyawaki0820/2023-dot-08-dot-07-geography-and-language-mian-qiang-hui-number-4
	- LLM é–‹ç™ºã«ãŠã‘ã‚‹è©•ä¾¡ãƒ»å“è³ªæ‹…ä¿ã«é–¢ä¿‚ã€ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã‚„ã€æ¨è«–éç¨‹ã®ã‚¬ã‚¤ãƒ‰ãªã©æœ€å¾Œã¯VisProgç´¹ä»‹
	- æ±åŒ—å¤§ã®å®®è„‡ã•ã‚“ã€åœ°ç†ç©ºé–“æƒ…å ±ã‚’LLMã‚’ã¤ã‹ã„ãªãŒã‚‰æ¨è«–ã™ã‚‹ä»•çµ„ã¿ã«ã¤ã„ã¦ã€‚
- AIãŒã€Œç†è§£ã€ã™ã‚‹ã‹ã‚‰ã€APIä»•æ§˜æ›¸ã®ã‚³ãƒ”ãƒšã§ã‚¢ãƒ—ãƒªãŒã§ãã‚ãŒã‚‹ãƒ­ãƒ¼ã‚³ãƒ¼ãƒ‰é–‹ç™ºç’°å¢ƒã€ŒFlowiseã€
	- https://internet.watch.impress.co.jp/docs/column/shimizu/1523766.html
- **[chatux-server-llm](https://github.com/sotokisehiro/chatux-server-llm)**
	- ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ä½œã™ã‚‹æ–‡ç« ç”Ÿæˆ AI ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚ CPU ã ã‘ã§å‹•ä½œã—ã¾ã™ã€‚
	- LINE ã® japanese-large-lm-3.6b-instruction-sft ã‚’ CTranslate2 åŒ–
- Vicuna 13B v1.5 ã€text-generation-webui ã˜ã‚ƒãªãã¦ä»¥å‰è©¦ä½œã—ãŸ llama.cpp ã® HTTP ã‚µãƒ¼ãƒãƒ¼æ©Ÿèƒ½ã‚’ä½¿ã£ã¦ã¿ãŸã‚‰æ™®é€šã« LLaMA 2 13B ã¨éœè‰²ãªã„çµæœå‡ºã—ã¦ãã‚ŒãŸ
	- https://twitter.com/izutorishima/status/1693468524222861589?s=20
- Metaã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒLLaMAã€ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚‚ä½¿ç”¨ã•ã‚ŒãŸAIã®å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ŒBooks3ã€ãŒå‰Šé™¤ã•ã‚Œã‚‹
	- https://gigazine.net/news/20230821-books-3-ai-data-set/
	- çŸ¥çš„è²¡ç”£æ¨©ã‚„è‘—ä½œæ¨©ã«å¯¾ã™ã‚‹ä¾µå®³ã®ç–‘ã„ãŒæŒ‡æ‘˜ã•ã‚Œã¦ã„ãŸã‚‰ã—ã„
- LlamaIndex + Metaphor: Towards Automating Knowledge Work with LLMs
	- https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f
	- Metaphor was trained to predict links on the internet, given how people talk about things on the Internet
	- ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¤œç´¢ã¨llamaindexã®èåˆï¼Ÿçµåˆã®æ–°ãŸãªå½¢ã¨ã—ã¦ã®ãƒ¡ã‚¿ãƒ•ã‚¡ãƒ¼ï¼Ÿ
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘Gradio+CTranslate2ã§æ—¥æœ¬èªLLMã®ãƒãƒ£ãƒƒãƒˆUIã‚’ã¤ãã‚‹
	- https://note.com/bakushu/n/nba6e9c353ee4
	- [line-corp-japanese-large-lm-3.6b](https://huggingface.co/line-corporation/japanese-large-lm-3.6b-instruction-sft)ã‚’åˆ©ç”¨
	- CTranslate2ã§é‡å­åŒ–
	- ã‚ã¨ã¯gradioã§WebUIç”Ÿæˆï¼
- Generally Intelligenceç¤¾ã€ç±³å›½å•†å‹™çœå›½å®¶é›»æ°—é€šä¿¡æƒ…å ±åºï¼ˆNTIAï¼‰ãŒå®Ÿæ–½ã—ãŸAIè¦åˆ¶ã«é–¢ã™ã‚‹ãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚³ãƒ¡ãƒ³ãƒˆã®ç´„1450ä»¶ã®å›ç­”ã®åˆ†æã‚’é–‹å§‹ã€‚
	- https://generallyintelligent.com/perspectives/ntia-rfc-analysis/
	- https://twitter.com/kanjun/status/1693819078866354376?s=20
- llamaindexã®Metaphorã‚µãƒ¼ãƒã®ãŠè©¦ã—ãŒã§ãã‚‹ã‚‰ã—ã„ã€‚
	- https://twitter.com/jerryjliu0/status/1693773766797746649?s=20
	- https://colab.research.google.com/drive/1PTnJTVmLAI-V8JJu8GsbUvbk8vs203kA?usp=sharing
- Stanfordå¤§å­¦ã®HAIã‹ã‚‰ã€Create AI Actã‚’é€£é‚¦æ”¿åºœãŒæ³•æ¡ˆã‚’ã¨ãŠã™ã¹ãã§ã‚ã‚‹ã€ç±³å›½ã®ãŸã‚
	-  We Must Pass the Create AI Act
	- https://hai.stanford.edu/news/we-must-pass-create-ai-act?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202308220803_sf181078680&utm_campaign=&sf181078680=1
- Open AI ã§ã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’4å¹´ä»¥å†…ã«å®Œäº†ã•ã›ã‚‹ã“ã¨ã‚’ç›®æ¨™ã¨ã—ã¦ç‡ã„ã¦ã„ã‚‹Jan Leikeæ°ã®å¯¾è«‡
	- https://80000hours.org/podcast/episodes/jan-leike-superalignment/
-  Inductive-bias Learning: Generating Code Models with Large Language Model
	-  **å¸°ç´çš„å­¦ç¿’æ³•**ï¼šå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’ç”¨ã„ã¦ã€èª¬æ˜å¤‰æ•°ã‹ã‚‰ç›®çš„å¤‰æ•°ã‚’äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ç”Ÿæˆã™ã‚‹æ–°ã—ã„å­¦ç¿’æ³•ã€‚ã“ã®å­¦ç¿’æ³•ã¯ã€æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¨ãƒ¡ã‚¿ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã®è¦ç´ ã‚’æŒã¤ã€‚
	- https://arxiv.org/abs/2308.09890
-  æ—¥æœ¬èªãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸGoogle PaLM2ã‚’è©¦ã™
	- https://note.com/eurekachan/n/n62b15394b5dc
	- BigQuery ã®SQLãªã‚“ã‹ã‚‚æ—¥æœ¬èªã§ç”Ÿæˆã‚’ãŠé¡˜ã„ã™ã‚‹ã“ã¨ãŒå‡ºæ¥ã¾ã™ã€‚
	- LangChainã‹ã‚‰ã‚‚å‘¼ã³å‡ºã—ãŸã‚Šã§ãã‚‹ã‚ˆã†ã§ã™
- ANYONE can fine-tune (almost) any LLM available on Hugging Face
	- Hugging Faceã§ç°¡å˜ã«LLMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹APIãŒå…¬é–‹
	- https://twitter.com/abhi1thakur/status/1693619860050153958?s=20
- RAGã‚·ã‚¹ãƒ†ãƒ ã§ã€top-k æŠ½å‡ºãŒã†ã¾ãã„ã‹ãªã„ã¨ãã®å·¥å¤«ã«ã¤ã„ã¦
	- https://twitter.com/jerryjliu0/status/1694013501323563101?s=20
	- Metadata Filters + Auto Retrieval:
	- Store Document Hierarchies (summaries -> raw chunks) + Recursive Retrieval
- ä»Šæ‘ãƒ»æ¾äº•ã®ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã€
	- ç¬¬4ç« ã¾ã§ã‚ˆã‚ã‚‰ã°ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãŒç†è§£ã§ãã‚‹ã‚‰ã—ã„ã€‚
	- https://www.kindaikagaku.co.jp/book_list/detail/9784764906631/
- ãƒ¡ã‚¿ãŒã€Code Llamaã‚’å…¬è¡¨
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/
	- Foundation base models (Code Llama) 
	- Python specializations (Code Llama - Python), 
	- Instruction-following models (Code Llama - Instruct)
- ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€‘Colabã®æ¨™æº–GPUã§ã€ŒCodeLlama-34B-GGUFã€ã‚’å‹•ã‹ã™
	- https://note.com/bakushu/n/n21cb30a15f27
	- é‡å­åŒ–ã¯ã€ŒGPTQã€ã§ã¯ãªãã¦ã€CPUï¼‹GPUã§å®Ÿè¡Œã§ãã‚‹ã€ŒGGUF(æ—§GGML)ã€
	- æ¨™æº–GPUï¼ˆTesla T4ï¼‰ã§å‹•ãã®ãŒã¿ã
- Weblab-10Bã‚’é‡å­åŒ–(GPTQ)ã—ã¦ç°¡å˜ã«å‹•ã‹ã™ã“ã¨ãŒhugging faceã§ã§ãã‚‹
	- transformersã«GPTQãŒçµ±åˆã•ã‚ŒãŸãŠã‹ã’ã§ã€ç„¡æ–™Colabã§ãã®ã¾ã¾ã§ã¯å‹•ã‹ãªã‹ã£ãŸWeblab-10Bã‚‚ã‚‰ãã‚‰ãå‹•ãã‚ˆã†ã«ãªã£ã¦ãŸã€‚
	- dahara1/weblab-10b-instruction-sft-GPTQ
	- https://github.com/webbigdata-jp/python_sample/blob/main/weblab_10b_instruction_sft_GPTQ_sample.ipynb
- ã€ã¾ã¨ã‚ã€‘Google Colab ã§ Code Llama ã‚’è©¦ã™
	- https://note.com/npaka/n/n51ed424b2943
- CodeLlama model now work w/ llama-cpp-python
	- [@TheBlokeAI](https://twitter.com/TheBlokeAI)ã•ã‚“ã«ã‚ˆã‚‹
	- llama.cpp GGUFã®çµ„ã¿åˆã‚ã›ã§å‹•ãã¨ã„ã†ã“ã¨
	- https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-GGUF/tree/main
	- https://github.com/abetlen/llama-cpp-python
- CodeLamaã®ã€colabã§ã®å®Ÿè¡Œã¨ãƒ“ãƒ‡ã‚ª
	- https://colab.research.google.com/drive/1lyEj1SRw0B9I2UUI2HOrtiJ_fjvbXtA2?usp=sharing
	- https://www.youtube.com/watch?v=rlCe_lG4uhk

## 8/21
æš‘ãã¦æº¶ã‘ãã†ãªã®ã«ã€é›»åŠ›ã¯ã©ã†ã«ã‹ã‚‚ã£ã¦ã„ã‚‹å¤ã§ã™ã€‚æ¾å°¾ç ”ã‹ã‚‰ã®å›½ç”£LLMã§ã‚ã‚‹â€œWeblab-10Bâ€ã®ç™ºè¡¨ã€‚ãªãŠã€æ¾å°¾ç ”ã«ã¯å¤ä¼‘ã¿ä¸­ã®ç·ç†ã‚‚è¨ªå•ã•ã‚Œè¬›åº§ã‚’å—è¬›ï¼ˆãªã«ã‹ä¿®äº†è¨¼æ›¸ã‚’ã‚‚ã‚‰ã£ã¦ãŸãªï¼‰ã€ã‚‚ã£ã¨å›½ã¨ã—ã¦ã®ã‚µãƒãƒ¼ãƒˆãŒæœŸå¾…ã§ãã‚‹ã‹ã‚‚ã€‚GPT-4ã¯ã€æš—å·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚ç†è§£ã§ãã‚‹ãã‚‰ã„å„ªã‚Œã¦ã„ã‚‹ã‚‰ã—ã„ãŒã€ç‰¹å®šã®ã€Œè„±ç„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã«å¼±ã„é¢ã‚‚ã€‚Trustworthy LLMã€LLMã®ä¿¡é ¼æ€§ãªã©ã®ç ”ç©¶ã‚‚é€²ã‚€ã€ç¤¾ä¼šè¦ç¯„ã¸ã®æ•´åˆã¨ã‹ãã†ã„ã†å´é¢ã‚‚ã‚ã‚‹ã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®LLMã®å®‰å…¨æ€§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã®æ¯”è¼ƒã‚‚æ°—ã«ãªã‚‹ã€‚ã‚ã„ã‚‚ã‹ã‚ã‚‰ãšçŸ¥è­˜ã‚°ãƒ©ãƒ•ç³»ã®LLMå¿œç”¨ãŒã¡ã‚‰ã»ã‚‰ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•æŠ½å‡ºã‚„çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ã¤ã‹ã£ãŸRAG(Retrieval-Augmented Generation)ãªã©ã‚‚ã‚ã‚‹ãŒã€çŸ¥è­˜ã®æ´»ç”¨ã‹ãã‚Œã¨ã‚‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‹ï¼Ÿã¿ãŸã„ãªç¬¬ï¼’ä¸–ä»£(ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼‰ã¨ç¬¬ï¼“ä¸–ä»£ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã™ã¹ã¦ï¼‰ã®AIã®å¯¾æ¯”ã¿ãŸã„ãªçµµé¢ã ãªã‚ã€‚MRIã‚¹ãƒšã‚¯ãƒˆãƒ«ã‹ã‚‰åˆ†å­ã‚’äºˆæƒ³ã¿ãŸã„ãªç´ æœ´ãªå¿œç”¨ãŒã‚‚ã£ã¨ã‚ã£ã¦ã„ã„æ°—ã‚‚ã™ã‚‹ã€‚TRL(Transformer Reinforcement Learning)ã¯ã€å¼·åŒ–å­¦ç¿’ã‚’ç”¨ã„ãŸLLMã®æœ€é©åŒ–ã‚’ç°¡å˜ã«ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‚‰ã—ã„ã€DPO(Direct Preference Optimization)ãªã‚“ã‹æ–¬æ–°ã˜ã‚ƒã‚“ã€‚å…ƒGoogleãƒˆãƒƒãƒ—ç ”ç©¶è€…ã«ã‚ˆã‚‹ã€ŒSakana AIã€ã«ã¯ã³ã£ãã‚Šã€ã‚ã–ã™ã€Œè‡ªç„¶ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ãŸã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã«åŸºã¥ã„ãŸæ–°ã—ã„ã‚¿ã‚¤ãƒ—ã®åŸºç¤ãƒ¢ãƒ‡ãƒ«ã€ã¨ã¯ã©ã‚“ãªã‚‚ã®ã«ãªã‚‹ã®ã‹ï¼Ÿæ—¥æœ¬ã¯ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã ã‘ã§ãªãã¦ã€äººæãƒªã‚½ãƒ¼ã‚¹ã¨ã—ã¦ã‚‚ã¾ã é­…åŠ›ãŒã‚ã‚‹ï¼Ÿï¼Ÿ

- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Q&Aãªã©ã™ã‚‹ã¨ãã«ã€çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸRAGã§æ§‹æˆã™ã‚‹ã®ãŒã‚ˆã„ã®ã‹ã€ã„ã‚„ã€ç›®çš„ã«å¯¾ã—ã¦LLMã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŒã„ã„ã®ã‹ã¨ã„ã†ã¯ãªã—
	- Knowledge Graphs & LLMs: Fine-Tuning vs. Retrieval-Augmented Generation
	- https://neo4j.com/developer-blog/fine-tuning-retrieval-augmented-generation/
- LLMã‚’ã¤ã‹ã£ãŸsemantic searchã®Deeplearning.aiã®ç„¡æ–™ã‚³ãƒ¼ã‚¹
	- Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
- GPT-4ã®ã‚»ãƒ¼ãƒ•ã‚¬ãƒ¼ãƒ‰ã‚’æ•…æ„ã«çªç ´ã™ã‚‹è„±ç„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é–¢ã™ã‚‹ç ”ç©¶
	-  "Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models
	- https://jailbreak-llms.xinyueshen.me/
- ã€Œæ±ç”¨çš„ãªAIã£ã¦ã‚„ã¤ã€ã‚’ä½œã£ãŸã¨ã“ã‚ã§ã€ãã‚Œã§ååˆ†ãªãƒ¬ãƒ™ãƒ«ã¾ã§åç›ŠåŒ–ã‚’å®Ÿç¾ã•ã›ã‚‹ã®ã¯ãã‚Œãªã‚Šã«é›£ã—ã„ã¨ã„ã†è©±(TJO
	- https://twitter.com/TJO_datasci/status/1691112696685719553
- GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher
	- https://arxiv.org/abs/2308.06463
	- GPT-4 can understand ciphertext, which introduces the risk of generating unsafe content.
- CSVã«ãŸã„ã™ã‚‹Q&Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
	- https://github.com/langchain-ai/langchain-benchmarks/tree/main/csv-qa
-  Knowledge Graph RAG Query Engine (RAG: Retrieval-Augmented Generation)
	- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_rag_query_engine.html
	- augmenting LLMs with context from a graph database
-  Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
	- Deeplearing.aiã‹ã‚‰ã®semantic searchã®ç„¡æ–™ã‚³ãƒ¼ã‚¹ã€Cohereã®äººãŒã§ã¦ã„ã‚‹ï¼Ÿ
- çŸ¥è­˜ã‚°ãƒ©ãƒ•æŠ½å‡ºã®ãƒ‡ãƒ¢
	- text to graph playground
	- https://auto-graph.streamlit.app/
-  Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment
	- LLMã®ä¿¡é ¼æ€§ã«é–¢ã™ã‚‹ã‚µãƒ¼ãƒ™ã‚¤è«–æ–‡
	- ç”¨èªã‚„æ¦‚å¿µã‚’æ•´ç†ã—ï¼Œå®Ÿéš›ã«8ã¤ã®è¦³ç‚¹ã‹ã‚‰LLMã®ä¿¡é ¼æ€§ã‚’æ¤œè¨¼
	- https://arxiv.org/abs/2308.05374
	- reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness.
	- ç›®çš„ã¯ï¼šreliable and ethically sound deployment of LLMs in various applications.
- RWKVã«ã¤ã„ã¦è§£èª¬
	- https://agirobots.com/rwkv/
	- RNNã®åˆ©ç‚¹ã§ã‚ã‚‹é«˜é€Ÿãªæ¨è«–ã¨å‡¦ç†å¯èƒ½ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚’å¤§å¹…ã«å‘ä¸Š
- LLMã«é–¢ã—ã¦èµ·ãã¦ã„ã‚‹è¨´è¨Ÿã«ã¤ã„ã¦
	- https://twitter.com/srush_nlp/status/1691845245074620915?s=20
- LLMã§MRIã‚¹ãƒšã‚¯ãƒˆãƒ«ã‹ã‚‰åˆ†å­ã‚’äºˆæ¸¬
	- https://chemrxiv.org/engage/chemrxiv/article-details/64d5e4ccdfabaf06ff1763ef
	- NMRã‚¹ãƒšã‚¯ãƒˆãƒ«ã‚’æ–‡å­—åˆ—ã§è¡¨ç¾ã€ã“ã‚Œã‚’è¨€èªãƒ¢ãƒ‡ãƒ«ã¸å…¥åŠ›ã—åˆ†å­ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§67%ã®ç²¾åº¦
- æ¾å°¾ç ”ç©¶å®¤100å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºãƒ»æ—¥è‹±2ãƒ¶å›½èªå¯¾å¿œã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«â€œWeblab-10Bâ€ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§å…¬é–‹
	- https://weblab.t.u-tokyo.ac.jp/100%E5%84%84%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%BA%E3%83%BB%E6%97%A5%E8%8B%B12%E3%83%B6%E5%9B%BD%E8%AA%9E%E5%AF%BE%E5%BF%9C%E3%81%AE%E5%A4%A7%E8%A6%8F%E6%A8%A1/
	- https://huggingface.co/matsuo-lab/weblab-10b
	- æ—¥æœ¬èªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã‚ã‚‹JGLUEè©•ä¾¡å€¤ãŒäº‹å‰å­¦ç¿’æ™‚ã¨æ¯”ã¹ã¦å¤§å¹…ã«æ”¹å–„ï¼ˆ66â†’78%
	- æ—©é€Ÿã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹è­¦å¯ŸãŒã€å•†ç”¨ã«ä½¿ãˆãªã„ã®ã«ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã¯è¨€ã‚ãªã„ã¨ã®çªã£è¾¼ã¿ãŒã€‚ã€‚
- å²¸ç”°é¦–ç›¸ã€æ±äº¬å¤§ã§ç”ŸæˆAIã®è¬›åº§å—ã‘ã‚‹ã€€ã€Œç™¾èã¯ä¸€è¦‹ã«ã—ã‹ãšã€
	- https://www.asahi.com/articles/ASR8G6X84R8GUTFK002.html
	- æ¾å°¾è±Šãƒ»æ±å¤§å¤§å­¦é™¢æ•™æˆã®è¬›åº§ã‚’å—ã‘ãŸã€‚AIã‚’å­¦ç¿’ã•ã›ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚‚ä½“é¨“ã—ã€å—è¬›
- LLMã‚’ã¤ã‹ã£ãŸæ–‡æ›¸æ¤œç´¢ã§ã¯ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§æ€§èƒ½ãŒæ”¹å–„ã™ã‚‹
	-  Building Production-Ready LLM Apps with LlamaIndex: Document Metadata for Higher Accuracy Retrieval
	- https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-document-metadata-for-higher-accuracy-retrieval-a8ceca641fb5
- Googleã®ãƒˆãƒƒãƒ—AIç ”ç©¶è€…2äººãŒæ±äº¬ã§AIä¼æ¥­ç«‹ã¡ä¸Šã’ã‚’ç™ºè¡¨
	- ã€Œè‡ªç„¶ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¾—ãŸã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã«åŸºã¥ã„ãŸæ–°ã—ã„ã‚¿ã‚¤ãƒ—ã®åŸºç¤ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã™ã‚‹ã€
	- ã‚¸ãƒ§ãƒ¼ãƒ³ã‚ºæ°ã¨ãƒãƒ¼æ°ãŒæ–°AIä¼æ¥­ã€ŒSakana AIã€ã‚’æ±äº¬ã«è¨­ç«‹
	- ã†ã¡1äººã¯ã€ç”ŸæˆAIé©å‘½ã®ãã£ã‹ã‘ã¨ãªã£ãŸè«–æ–‡ã®è‘—è€…ã®ä¸€äºº
	- æ—¥æœ¬ã§ç ”ç©¶è€…ã‚’å‹Ÿã‚Šã€ç”ŸæˆAIã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚’ç›®æŒ‡ã™
	- https://www.nikkei.com/article/DGXZQOUC186TM0Y3A810C2000000/?n_cid=SNSTW001&n_tw=1692351448
	- èµ·æ¥­ã®åœ°ã«æ—¥æœ¬ã‚’é¸ã‚“ã ç†ç”±ã¨ã—ã¦ã€ç±³å›½ã§ç”ŸæˆAIã®äººæç²å¾—ç«¶äº‰ãŒéç†±ã—ã¦ã„ã‚‹ç‚¹ã‚’ã‚ã’ãŸã€‚
-  TRL - å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹LLMã®å­¦ç¿’ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
	- TRL - Transformer Reinforcement Learning
	- https://note.com/npaka/n/nbb974324d6e1
	- å¼·åŒ–å­¦ç¿’ã‚’ä½¿ç”¨ã—ã¦Transformerè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã§ãã¾ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯HuggingFace Transformersã¨çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚
-  DPO ã«ã‚ˆã‚‹ Llama 2 ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°(npaka)
	- https://note.com/npaka/n/nfe7391a1d28d
	- ã€ŒDirect Preference Optimizationã€ã§ã¯ã€æ—¢å­˜ã®æ‰‹æ³•ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹RLãƒ™ãƒ¼ã‚¹ã®ç›®æ¨™ã‚’ã€å˜ç´”ãªãƒã‚¤ãƒŠãƒªã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã‚’ä»‹ã—ã¦ç›´æ¥æœ€é©åŒ–ã§ãã‚‹ç›®æ¨™ã«åˆ‡ã‚Šæ›¿ãˆã‚‹
	- LMã‚’æ”¹è‰¯ã™ã‚‹ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒå¤§å¹…ã«ç°¡ç´ åŒ–

## 8/14
ãŠç›†ã§ã™ãŒã€è†¨å¤§ã«ãªã‚‰ãªã„ã†ã¡ã«æ›´æ–°ã—ã¾ã™ã€‚ã¨ã“ã‚ã§ã€ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«å…¥é–€ã€(æŠ€è¡“è©•è«–ç¤¾ISBN 978-4-297-13633-8ï¼‰ã„ã„ã§ã™ã­ã€Huggingfacesã‚’ã¤ã‹ã£ã¦ã€æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã¤ã‹ã£ãŸã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©è¦‹æ‰€ãŒå¤šã„ã€‚
ã•ã¦ä»Šé€±ã¯ã€å…ˆé€±ã«å¼•ãç¶šã vicuna-v1.5é–¢ä¿‚ã®è¨˜äº‹ãŒå¤šã‹ã£ãŸã‚ã‘ã§ã™ãŒã€stability.aiã‹ã‚‰æ—¥æœ¬èªã®StableLLMãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸãŒã®ãŒå¤§ããªãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã—ãŸã€‚LLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚‚Colabç’°å¢ƒã§ã§ãã‚‹ã‚‰ã—ã„ã€‚Metaã®å…¬è¡¨ã—ãŸç”ŸæˆAIã®ã‚¬ã‚¤ãƒ‰ã¨ã‹ã€FacToolãªã‚“ã‹ã€AIã®å®‰å…¨æ€§ã‚„ãƒªã‚¹ã‚¯ãªã‚“ã‹ã«å¯¾ã—ã¦ã¡ã‚ƒã‚“ã¨å–ã‚Šçµ„ã‚“ã§ã„ã‚‹ã€‚æ—¥FRæœ¬ã®AIæˆ¦ç•¥ã®ã€é–‹ç™ºä¿ƒé€²ã«åã£ãŸå§¿å‹¢ã¨ã¯ä¸€ç·šã‚’ç”»ã—ã¦ã„ã‚‹ï¼ˆã¤ã¾ã‚Šä½™è£•ãŒãªã„ã¨ã„ã†ã“ã¨ï¼‰ã€‚FacToolã«ã‚ˆã‚‹åˆ†æã®çµæœã€GPT-4ã¯ã‚„ã£ã±ã‚Šã™ã”ã„ã‚“ã ãªã€‚Llmaindexã®llmãŒgpt-3.5-turboã«ã‚„ã£ã¨å¤‰æ›´ã•ã‚ŒãŸã‚‰ã—ã„ã€ãã‚“ãªã«ä½¿ã„ã«ãã‹ã£ãŸã®ã‹ã€‚ã€‚LLMã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ä½¿ã†ãŸã‚ã®è‰²ã€…ãªTipsãŒå…¬è¡¨ã•ã‚Œã¦ãŸã‚Šã€ä¸€æ–¹Andrew Ngã•ã‚“ã¯ã€LLMãŒä¸–ç•Œã‚’ç†è§£ã—ã¦ã„ã‚‹ã¨ã„ã†ãƒ–ãƒ­ã‚°ã‚’é–‹é™³ã€‚LLMæ™‚ä»£ã®åŒ»ç™‚ã¸ã®AIåˆ©ç”¨ã®ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã¨ãƒªã‚¹ã‚¯ã«ã¤ã„ã¦ã®ãƒ©ãƒ³ã‚µãƒ¼è¨˜äº‹ã¨ã‹ã€æ•°å­¦è€…Terence Taoã•ã‚“ã®ã€LLMã‚’ã¤ã‹ã£ãŸAIãŒæ•°å­¦è«–æ–‡ã®å…±è‘—è€…ã«ãªã‚Šã†ã‚‹ã¨ã„ã†èˆˆå‘³æ·±ã„äºˆæ¸¬ã‚‚ã€‚ç”£ç·ç ”ã®AIã‚»ãƒŸãƒŠãƒ¼ã€ã‚ã£ã¨ã„ã†é–“ã«æº€æ¯ã«ã€‚èˆˆå‘³ã ã‘ã¯å¤§ãã„ã®ã«ã€æ‰‹ãŒå‹•ã‹ãªã„äººãŒå¤šã™ããªã„ã‹ã€‚ã€‚ã¾ã‚ã€LLMã§ã„ãã‚‰é ‘å¼µã¦ã‚‚ChatGPTã§ã‚ˆããªã„ï¼Ÿã¿ãŸã„ãªæ„è¦‹ã‚‚ã‚ã‚‹ã€‚æ§˜ã€…ãªé¢ã§ã€æ—¥æœ¬ã¯LLMé–‹ç™ºã§é…ã‚Œã¦ãã¦ã„ã¦ã€ã‚‚ã¯ã‚„ä»¥å‰ã®ã‚ˆã†ãªæ¨ªç¶±ç›¸æ’²ã‚’ã™ã‚‹ã‚ˆã†ãªæ„Ÿã˜ã§ã¯ãªã„ã®ã«æ”¿åºœã¯ãã†ã¯è¨€ãˆãªã„ã®ã‹ã€ã—ã‹ã—æ°‘é–“ã¯é ‘å¼µã£ã¦ã„ã‚‹ã€‚

- LlamaIndexã§AutoGPTQãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ï¼ˆvicuna-13B-v1.5-GPTQï¼‰
	- https://zenn.dev/libratech/articles/1979874b223895
	- 4bitåŒ–ãªã©è»½é‡åŒ–ã•ã‚ŒãŸllmã‚’llamaindexã§ä½¿ã†æ–¹æ³•ã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã¨ã‹
	- Colabã®ç„¡æ–™ç‰ˆ(T4ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹)ã§ã‚‚å‹•ä½œã™ã‚‹
- LLama2å…¬é–‹ã«ã‚ã‚ã›ã¦ã€Metaã‹ã‚‰"responsible generative AI"ã«é–¢ã™ã‚‹ã‚¬ã‚¤ãƒ‰ãŒå‡ºã¦ã„ã‚‹.ã€
	- https://ai.meta.com/static-resource/responsible-use-guide/
- text-generation-webui ã§ TheBloke/vicuna-13B-v1.5-GPTQãŒå‹•ã
	- https://twitter.com/smorce1/status/1688250856129646592?s=20
- llama2ã‚’ã¤ã‹ã£ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«Q&Aã‚’å®Ÿè¡Œã™ã‚‹æ‰‹æ³•ã«ã¤ã„ã¦ via llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SimpleIndexDemoLlama-Local.html
- LLMã‚’è©¦ã™ã®ã«ã€ã€Œã‚¬ãƒ³ãƒ€ãƒ ãƒ†ã‚¹ãƒˆã€ã¨ã„ã†ã®ãŒã‚ã‚‹ã‚‰ã—ã„ã€vicuna-13b-v1.5-16kã¯å„ªç§€ã‚‰ã—ã„
	- https://twitter.com/NuCode/status/1688455649091608576?s=20
- å†…é–£åºœAIæˆ¦ç•¥ä¼šè­°(8/4)ã®è³‡æ–™ãŒä¸€éƒ¨å…¬é–‹ã€AIé–¢é€£æ–½ç­–ã¯é–‹ç™ºæŒ¯èˆˆä¸€æœ¬è¶³ã«è¿‘ããƒªã‚¹ã‚¯å¯¾å¿œãŒç”³ã—è¨³ç¨‹åº¦
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/4kai/shisaku.pdf
-  IPAã€ŒITãƒ‘ã‚¹ãƒãƒ¼ãƒˆè©¦é¨“ ã‚·ãƒ©ãƒã‚¹ã€ã«ã€ç”ŸæˆAIã®ä»•çµ„ã¿ã€æ´»ç”¨ä¾‹ã€ç•™æ„äº‹é …ç­‰ã«é–¢ã™ã‚‹é …ç›®ãƒ»ç”¨èªä¾‹ã‚’è¿½åŠ 
	- https://www.ipa.go.jp/shiken/syllabus/henkou/2023/20230807.html
- ã€ŒJP Language Model Evaluation Harnessã€ã«ã‚ˆã‚‹LLMæ€§èƒ½è©•ä¾¡ by stabilityAI
	- https://note.com/npaka/n/nedf4dacd4037
	- Colab(T4)ã§12æ™‚é–“ã‚‚ã‹ã‹ã‚‹ã€ã§ãã‚‹ã‚‰ã—ã„
- llama-2-13bã®JGLUEã€è¨€èªãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨é–¢ä¿‚
	- https://huggingface.co/HachiML/Llama-2-13b-hf-qlora-dolly-ja-2ep/blob/main/benchmark_jglue/JGLUE_Llama-2-13b-hf-qlora-dolly-ja-2ep.ipynb
- GPTQã®å…ƒè«–æ–‡ã¯ã“ã¡ã‚‰ã€
	- https://arxiv.org/pdf/2210.17323.pdf
	- GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS
- ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ã¯æœ€è¿‘ã®è©±é¡Œã«ã‚‚è©³ã—ã„GPT-NeoXã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸ14å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªã®LLMã‚’OSSå…¬é–‹
	- https://stockmark.co.jp/news/20230808
- HuggingFacesã¨NVIDIAãŒææºã€ä¼æ¥­å‘ã‘ã®ã‚µãƒ¼ãƒ“ã‚¹ã‚’å±•é–‹ï¼Ÿ
	- https://www.nvidia.com/ja-jp/about-nvidia/press-releases/2023/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing/
	- HuggingFaceã«ã‚ã‚‹AIãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ã‹å¾®èª¿æ•´ãŒã§ãã‚‹ä¼æ¥­å‘ã‘ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã€GPUã¨ã—ã¦NVidiaã®ã‚¯ãƒ©ã‚¦ãƒ‰GPUãŒé¸ã¹ã‚‹ã‚ˆã†ã«ãªã‚‹ã‚‰ã—ã„ã€‚
- æ‚²å ±ï¼Ÿï¼šç”£ç·ç ”ã€LLMã®ã‚»ãƒŸãƒŠãƒ¼ã€Œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨AIã®èåˆæŠ€è¡“ã¨ãã®æœ€æ–°äº‹ä¾‹ã€ã€ã™ãã«å®šå“¡ã„ã£ã±ã„ã«ãªã‚‹
	- https://www.airc.aist.go.jp/seminar_detail/seminar_069.html
- Stability.aiã€ æ—¥æœ¬èªè¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒJapanese StableLM Alphaã€ã‚’ãƒªãƒªãƒ¼ã‚¹(8/10)
	- https://ja.stability.ai/blog/japanese-stablelm-alpha
- æ—©é€ŸJapanese Stable LLMã‚’ã€Colabç„¡æ–™ç’°å¢ƒã‹ã‚‰åˆ©ç”¨ã™ã‚‹notebookãŒå…¬é–‹
	- https://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb
	- huggingfacesã«ãƒ­ã‚°ã‚¤ãƒ³ã—ãªã„ã¨ã„ã‘ãªã„ã€ã€ãŒå‹•ããï¼
	- ã‚¬ãƒ³ãƒ€ãƒ ãƒ†ã‚¹ãƒˆã—ã¦ã¿ãŸãŒã€ãªã‚“ã‹ã€å­¦ç¿’æ™‚ã«ã¤ã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã€‚
- ç”ŸæˆAIã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ¤åˆ¥ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã®è«–æ–‡
	- https://arxiv.org/abs/2306.15666
	- Testing of Detection Tools for AI-Generated Text
	- â– æ–‡ç« ã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’å¤‰åŒ–ã•ã›ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆï¼ˆä¾‹ãˆã°å­ä¾›ã£ã½ããªã©ï¼‰ã€è­˜åˆ¥ãŒå›°é›£ã«ãªã‚‹ 
	- â– è¨€ã„æ›ãˆã‚„æ›¸ãæ›ãˆã«ã‚ˆã£ã¦æ®µéšçš„ã«æ–‡ç« ã‚’å¤‰æ›´ã•ã‚Œã‚‹ã¨ã€è­˜åˆ¥ãŒã‹ãªã‚Šå›°é›£ã«ãªã‚‹
	-  â– AIç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®æ¤œå‡ºã¯AIç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®æ¤œå‡ºã‚ˆã‚Šã‚‚ã•ã‚‰ã«å›°é›£ã«ãªã‚‹
- Langchainã®ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ã®æ§˜å­ã‚’ç›®è¦–ã§ãã‚‹ã€playgroundãŒçˆ†èª•
	- https://langchain-text-splitter.streamlit.app/
- Google Colab ã§ Japanese StableLM Alpha + LlamaIndex ã® QA ã‚’è©¦ã™
	- https://note.com/npaka/n/n5c80ca661357
- ã€Œã¨ã£ãã‚‡ã€åºƒå ±èªŒã§ã€ã“ã¡äº€ã®å†…å®¹ãŒã€æ‹’çµ¶é€šçŸ¥ã®ç†ç”±ã«ãªã£ãŸäº‹ä¾‹ãŒç´¹ä»‹ã€‚ã€‚
	- https://www.jpo.go.jp/news/koho/kohoshi/vol57/07_page1.html
	- æ‹’çµ¶ã‚’é¿ã‘ã‚‹ã¹ãã€ç‰¹è¨±å‡ºé¡˜ã™ã‚‹å‰ã«ã¯ã“ã¡äº€ã‚’å…¨å·»èª­ç ´ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã‹ã€ã€ã€
	- å¯©æŸ»å®˜ã®è¶£å‘³ã¨ã„ã†æ°—ã‚‚ã™ã‚‹ãŒã€ã€
-  ChatGPTã®æ–°æ©Ÿèƒ½ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã®é¢ç™½ã„ä½¿ã„æ–¹
	- https://note.com/it_navi/n/nca4643390969
	- ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤ºã¯ã€ChatGPTã®**å½¹å‰²ã€å›ç­”æ–¹é‡ã€å‡ºåŠ›å½¢å¼ãªã©**ã‚’äºˆã‚è¨­å®šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
- LLMã¯ä¸–ç•Œã‚’ç†è§£ã—ã¦ã„ã‚‹ã‹ï¼Ÿby Andrew Ng
	- https://www.deeplearning.ai/the-batch/issue-209/
	- Othelo-GPTã®ä¾‹ã‹ã‚‰ã€ç­”ãˆã¯ YESã‚‰ã—ã„ã€‚
- ç”ŸæˆAIã®æ–‡ç« ã‚„ã‚³ãƒ¼ãƒ‰ã€è«–æ–‡ãŒâ€œäº‹å®Ÿã‹â€ãƒã‚§ãƒƒã‚¯ã™ã‚‹æŠ€è¡“ã€€ç±³Metaå«ã‚€ç ”ç©¶è€…ã‚‰ãŒé–‹ç™º
	- https://www.itmedia.co.jp/news/articles/2308/09/news064.html
	-  FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
	- https://arxiv.org/abs/2307.13528v2
		- ç ”ç©¶è€…ã‚‰ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’é–‹ç™ºã—ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®QAã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€æ•°å­¦ã®å•é¡Œè§£æ±ºã€ç§‘å­¦è«–æ–‡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸ·ç­†ã®4ã¤ã®ã‚¿ã‚¹ã‚¯ã§å®Ÿé¨“ã‚’è¡Œã£ãŸã€‚ãã®çµæœã€GPT-4ã¯ChatGPTã€Bardã€Claude-v1ã€Vicunaã¨æ¯”è¼ƒã—ã¦ã€äº‹å®Ÿç²¾åº¦ãŒæœ€ã‚‚å„ªã‚Œã¦ã„ãŸã€‚Vicuna-13Bã¯ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®QAã§ã¯ãã‚Œãªã‚Šã«è‰¯å¥½ãªäº‹å®Ÿæ€§ã‚’ç¤ºã—ãŸãŒã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€æ•°å­¦ã®å•é¡Œè§£æ±ºã€ç§‘å­¦è«–æ–‡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸ·ç­†ãªã©ã€ã‚ˆã‚Šå›°é›£ãªã‚·ãƒŠãƒªã‚ªã§ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ã„çµæœã¨ãªã£ãŸã€‚
- llamaindexã®v0.8ãŒãƒªãƒªãƒ¼ã‚¹
	- https://github.com/jerryjliu/llama_index/blob/main/CHANGELOG.md
	- [1] The default LLM is now gpt-3.5-turbo
	- [2] Speaking of changing prompts, weâ€™ve changed the default question-answering templates for both our create and refine strategy as well as tree_summarize.
	- [3] Our default text splitter is now our brand-new sentence text splitter.
	- [4] Added llama.cpp and @huggingface as fallbacks if openai key is not set.
	- [5] Some new features: a `SentenceWindowNodeParser` and `MetadataReplacementNodPostProcessor` 
- ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã€Create a CustomGPT And Supercharge your Company with AI â€“ Pick the Best LLM
	- https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/
-  Building LLM applications for production
	- https://huyenchip.com/2023/04/11/llm-engineering.html
	- LLMã‚’ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ã§ä½¿ã†ãŸã‚ã®è‰²ã€…ãªTipsãŒã¾ã¨ã¾ã£ãŸè¨˜äº‹
- ã„ã‚ã„ã‚LLMã‚’ã„ã˜ã£ã¦ã¿ã¦ã‚‚ã€çµå±€ChatGPTã§ã‚ˆããªã„ï¼Ÿã¿ãŸã„ãª
	- https://twitter.com/mr_bay_area/status/1689868431900975104?s=20
-  AI in medicine: creating a safe and equitable future
	- Lancerã®è¨˜äº‹ã€LLMæ™‚ä»£ã«ãŠã‘ã‚‹ã€åŒ»ç™‚åˆ†é‡ã¸ã®AIé©ç”¨ã®ãƒ¡ãƒªãƒƒãƒˆã¨ãƒªã‚¹ã‚¯ã«ã¤ã„ã¦ã¾ã¨ã‚
	- https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)01668-9/fulltext
-  Embracing change and resetting expectations by Terence Tao@microsoft
	- https://unlocked.microsoft.com/ai-anthology/terence-tao/
	- He predicts that AI will be a trustworthy co-author in mathematical research by 2026, when combined with search and symbolic math tools.
	- 2026å¹´ã¾ã§ã«ã¯ã€æ•°å­¦ç ”ç©¶ã«ãŠã„ã¦ã€AIãŒä¿¡é ¼ã§ãã‚‹å…±è‘—è€…ã«ãªã‚Šã†ã‚‹ã¨ã®äºˆæ¸¬


## 8/7

llama2ãƒ™ãƒ¼ã‚¹ã®Vicuna v1.5ã§ç››ã‚Šä¸ŠãŒã£ã¦ã„ã‚‹ã€langchainã‚„llamaindexã¨ã®çµ„ã¿åˆã‚ã›ã§ã‚‚å‹•ãæ¨¡æ§˜ã€‚ReActãªã©ã®Agentæ©Ÿèƒ½ã‚‚ã¡ã‚ƒã‚“ã¨ã†ã”ãã‚‰ã—ã„ã€‚llama2ã‚’æ‰‹ã”ã‚ã«è©¦ã›ã‚‹colab noteã‚‚ãŸãã•ã‚“å…¬é–‹ã€ãƒ­ãƒ¼ã‚«ãƒ«GPUã§å‹•ã‹ã™å ±å‘Šã‚‚ã€‚ãªãŠllama2æœ¬å®¶ã‚‚ç”³è«‹ã™ã‚Œã°ã‚’ç›´æ¥ä½¿ã†ã“ã¨ã‚‚ã§ãã‚‹ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¯windowsä¸Šã§ã®llama2ã¨ã„ã†ãƒã‚¿ã§ãƒ¡ã‚¿ã¨ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã¨ã®ã“ã¨ã€äºŒè‚¡ã‹ã‘ã¦ã‚‹ï¼Ÿãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒAzure OpenAIã‚’ã¤ã‹ã£ãŸChatGPTã‚‚ã©ãã®ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã‚’å…¬é–‹ã€ã‚«ãƒ‹ã°ã£ã¦ãªã„ï¼Ÿæ–‡ç« ã‹ã‚‰çŸ¥è­˜ã‚’æŠ½å‡ºã™ã‚‹æ–¹æ³•ã€llamaindexã§ã‚‚çŸ¥è­˜ã‚°ãƒ©ãƒ•(KG)ã‚’æŠ½å‡ºã™ã‚‹KnowledgeGraphIndexãŒã‚ã£ãŸãŒã€REBELã¨ã„ã†å¤–éƒ¨ã®transformerã‚’åˆ©ç”¨ã™ã‚‹æ–¹æ³•ã‚‚ã‚ã‚‹ã®ã‹ã€‚ç”¨é€”ã«åˆã‚ã›ã¦é¸æŠã€ç´°ã‹ã„èª¿æ•´ãŒå¿…è¦ã‹ãªã€‚UCãƒãƒ¼ã‚¯ãƒ¬ãƒ¼ã®Dynalangã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹ãŒã€è«–æ–‡ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã™ã‚‹ã¨LLMã§ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ï¼ˆã€ŒäºŒé‡éç¨‹ãƒ¢ãƒ‡ãƒ«ã€ã®çœŸã‚“ä¸­ã«å‡ºã¦ãã‚‹ã‚„ã¤ï¼Ÿè¨˜å·æ¥åœ°ãƒ¢ãƒ‡ãƒ«ã¨ã„ã†ã‹ãã†ã„ã†ã‚„ã¤ï¼‰ã€‚è‡ªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ã¤ã‹ã£ãŸChatBotã®ä½œã‚Šæ–¹ã«ã¤ã„ã¦ã‚ã‹ã‚Šã‚„ã™ã„èª¬æ˜ãŒã‚ã£ãŸã€‚JSTã®ç”ŸæˆAIã®ã¾ã¨ã‚ã€æ—¥æœ¬ã®ç”Ÿãã‚‹é“ã¯ã€ã€Œç¬¬4ä¸–ä»£AIã€ã€Œä¿¡é ¼ã•ã‚Œã‚‹AIã€ã€ŒAIãƒ»ãƒ‡ãƒ¼ã‚¿é§†å‹•ç§‘å­¦ã€ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚ã€Œç¬¬ï¼”ä¸–ä»£AIã€ã¨ã¯System1ã¨System2ãŒé€£å‹•ã™ã‚‹ã€ã€ŒäºŒé‡éç¨‹ãƒ¢ãƒ‡ãƒ«ã€ã®ã“ã¨ã‚‰ã—ã„ã€Dynalangã®è©±ã¨ã‚‚ã¤ãªãŒã£ãŸï¼

> NeurIPS2019ã§ã€Bengioã®åŸºèª¿è¬›æ¼”ã®ã€ŒäºŒé‡éç¨‹ãƒ¢ãƒ‡ãƒ«ã€ï¼ˆå³æ™‚çš„ãªSystem1ã¨ç†Ÿè€ƒçš„ãªSystem2ã®äºŒé‡ãƒ¢ãƒ‡ãƒ«ã€é–“ã«ã€ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ãŒå…¥ã‚‹ï¼‰ã€‚çŸ¥è¦šç³»ã®æ·±å±¤å­¦ç¿’(System1)ã«ã‚ˆã£ã¦çœ¼å‰ã®çŠ¶æ³ã«å¯¾ã™ã‚‹ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ï¼ˆWorld Modelï¼‰ãŒå¾—ã‚‰ã‚Œã‚‹ãŒã€ãã‚Œã‚’ä½¿ã£ã¦è¨€èªãƒ»çŸ¥è­˜ç³»ãŒé©åˆ‡ãªæ‰‹é †ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã®ãŒSystem2ã€‚ã‚«ãƒ¼ãƒãƒãƒ³ã®Fast & Slowã¨ã‚‚é–¢é€£ãŒã‚ã‚Šãã†ã€‚ã€‚

- Google Colab ã§ Vicuna-v1.5 + LlamaIndex ã® QA ã‚’è©¦ã™
	- npakaã•ã‚“ã‚ˆã‚Šã€ãƒã‚¤ãƒ¡ãƒ¢ãƒªã§ãªã„ã¨å‹•ã‹ãªã„ã®ã‹ã€‚ã€‚
	- https://note.com/npaka/n/n931319f17b34
-  Google Colab ã§ Llama 2 + LlamaIndex ã® QA ã‚’è©¦ã™
	- npakaã•ã‚“ã‚ˆã‚Šã€llma2åˆ©ç”¨ã«ã¯ç”³è«‹ãŒå¿…è¦ãªã®ã‹ã€
	- Q&Aãƒ†ãƒ³ãƒ—ãƒ¬ã«ä¿®æ­£ãŒå¿…è¦ãªã‚‚ã‚ˆã†
	- https://note.com/npaka/n/n3e1b59d1ac9e
- vicuna-7b-v1.5ã®ä¸€ç•ªç°¡å˜ãªåˆ©ç”¨æ–¹æ³•by npakaã•ï½
	- https://huggingface.co/lmsys/vicuna-7b-v1.5
	- https://twitter.com/npaka123/status/1686872443305295878?s=20
- ChatGPTã®å°æ”¹è‰¯ãŒé †æ¬¡ãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã‚‹ã¨ã®å‘ŠçŸ¥
	- https://twitter.com/OpenAI/status/1687159114047291392?s=20
	- prompt exampleã¨ã‹ã€Plusä¼šå“¡ã«ã¯GPT-4ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ãªã‚‹ã¨ã‹ã€ãã†ã„ã†ï½™ã¤
- UCãƒãƒ¼ã‚¯ãƒ¬ãƒ¼ã€ã‚¢ãƒ«ãƒ•ã‚¡ç¢ã¨ChatGPTã‚’æ··ãœã¦å¼·ãã—ãŸã‚ˆã†ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ŒDynalangã€
	- https://arxiv.org/abs/2308.01399
	- Learning to Model the World with Language
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆç¤¾ã€Azure OpenAIã§ã€ChatGPTã‚‚ã©ãã‚’ä½œã‚‹ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…ã‚’å…¬é–‹
	- https://github.com/microsoft/azurechatgpt
	- ä¼æ¥­åˆ©ç”¨ãŒåŠ é€Ÿã™ã‚‹ã‹ã€‚ã€‚ã„ã‚„playgroundã§ååˆ†ï¼Ÿ
- äººå·¥çŸ¥èƒ½ç ”ç©¶ã®æ–°æ½®æµ2ã€€ï½åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãƒ»ç”ŸæˆAIã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï½
	- JSTã®ã¾ã¨ã‚ã€ç”ŸæˆAIç ”ç©¶ã®å‹•å‘å ±å‘Šæ›¸
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-02.html?fbclid=IwAR0KQ7bg5BRLIblzI154AHYheNrF1SPPzm-xn4z1PuQBUPK2Kia2qT4PMxU
	- ã€Œç¬¬4ä¸–ä»£AIã€ã€Œä¿¡é ¼ã•ã‚Œã‚‹AIã€ã€ŒAIãƒ»ãƒ‡ãƒ¼ã‚¿é§†å‹•ç§‘å­¦ã€
- é›‡ç”¨åˆ¤æ–­ã«AIã‚’ä½¿ã†ã®ã¯ã€EUè¦åˆ¶ä¸Šç¦æ­¢ï¼Ÿ
	- ç¦æ­¢ã§ã¯ãªãã¦ã€ãƒã‚¤ãƒªã‚¹ã‚¯AIã«ç›¸å½“ã™ã‚‹ã‹ã‚‰ã€å®ˆã‚‹ã¹ãã“ã¨ã‚’å®ˆã‚‰ãªã„ã¨ã„ã‘ãªã„ã¨ã„ã†ã“ã¨
	- https://twitter.com/umiyuki_ai/status/1687639267273748480?s=20
- å—æ¥µã®æ°·ãŒã€ä»Šå¹´ã¯æ€¥æ¿€ã«ã¨ã‘ã¦ã„ã‚‹ã‚‰ã—ã„ã€€via å®‰å®…ã•ã‚“
	- https://www.economist.com/graphic-detail/2023/08/02/the-rapid-loss-of-antarctic-sea-ice-brings-grim-scenarios-into-view
- REBELã¨ã„ã†é–¢ä¿‚æŠ½å‡ºãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‚’ã¤ã‹ã£ã¦çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’æŠ½å‡ºã—ã¦æ¨è«–ã™ã‚‹ä¾‹
	- https://twitter.com/jerryjliu0/status/1687607838539927553?s=20
	- llamaindexã®äººã«ã‚ˆã‚‹ç´¹ä»‹ã€ãªã‚“ã‹æŠ½å‡ºã™ã‚‹çŸ¥è­˜ã®å¯†åº¦ã‚’èª¿æ•´ã—ãŸã„ã¨ã“ã‚
- Google Colab ã§ LangChain + Vicuna-v1.5 ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚’è©¦ã™
	- https://note.com/npaka/n/nb3c02ce2d4c5
	- npakaã•ã‚“ã‚ˆã‚Šã€serpAIã¨mathã‚’ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã€ReActãŒè©¦ã›ã‚‹ã‚‰ã—ã„ã€‚ãƒã‚¤ãƒ¡ãƒ¢ãƒªãŒå¿…è¦ã€‚ã€‚
-  Google Colab ã§ Llama.cpp + Vicuna-v1.5 ã‚’è©¦ã™
	- npakaã•ã‚“ã‚ˆã‚Šã€Colabã§ã“ã‚“ãªã“ã¨ã‚‚ã§ãã‚‹ã®ã‹ï¼Ÿ
	- https://note.com/npaka/n/n280ffc0d5ff0
- llama-2-7bã‚’ã¤ã‹ã£ã¦ã€colabã§chatbodã‚’ä½œã‚‹ä¾‹ã€
	- å‹•ãã‚“ã ã€ã€ã€ã¨ã„ã†ã‹å‹•ããï¼
	- https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-7b-chat.ipynb
- è‡ªåˆ†ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å­¦ç¿’ã—ãŸã‚«ã‚¹ã‚¿ãƒ ChatBotã‚’ä½œã‚‹æ–¹æ³•
	- https://zenn.dev/karaage0703/articles/c8baa66c40f9b7
	- ãã†ã‹ã€ã„ã¤ã‚‚ã‚„ã£ã¦ã‚‹ã‚„ã¤ã¯ã€Retrieval-Augmented Generationï¼ˆRAGï¼‰ã£ã¦ã‚ˆã°ã‚Œã¦ã„ã‚‹ã®ã‹ï¼Ÿ
-  LLMãŒãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã©ã“ã¾ã§ï¼ŸMetaã®ã€ŒLlama 2ã€ã‚’è©¦ã—ã¦ã¿ãŸ
	- https://pc.watch.impress.co.jp/docs/column/nishikawa/1519390.html
	- è¥¿å·ã•ã‚“ãŒçµ„ã‚€ã¨ã¯ã€ã ã„ã¶æ°‘ä¸»åŒ–ãŒé€²ã‚“ã ã®ã‹ã€‚
	- Colabã§ã‚‚çµæ§‹ç°¡å˜ã«ã†ã”ããŒã€ãƒ­ãƒ¼ã‚«ãƒ«ãªGeForce RTX 4070 Ti(12GB)ã§ã‚‚å‹•ã‹ã™äº‹ä¾‹ãŒ(è¥¿å· å’Œä¹…)
-  Llama 2ãƒ™ãƒ¼ã‚¹ã®LLM FastChat/Vicuna v1.5ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œ
	- https://jweb.asia/26-it/ai/91-fastchat-vicuna-v1-5-on-llama-2.html

## 7/31

ã„ã‚„ã‚ã€æš‘ããªã£ã¦ï¼‘é€±é–“ã•ã¼ã£ãŸã‚‰ã€ãã‚Œãªã‚Šã«ã¾ã¨ã‚ã‚‹ã®ãŒã¤ã‚‰ã„ã€‚ãƒ¡ã‚¿ã®LLaMa2ãƒªãƒªãƒ¼ã‚¹ãŒå¤§ããªè©±é¡Œã€å²¡é‡åŸã•ã‚“ã®è§£èª¬ãŒè‰¯ã„ã‹ã‚‚ã€‚ã•ã£ããggmlåŒ–ã€webuiå¯¾å¿œã€LanChainçµ„ã¿è¾¼ã¿ãŒè¡Œã‚ã‚Œã‚‹ã€‚LangChainã®çµ±åˆé–‹ç™ºç’°å¢ƒLangSmithã€ã‚ˆãLangChainã®ç´¹ä»‹å‹•ç”»ã«å‡ºã¦ãã¦ã‚„ã¤ãŒæ­£å¼ãƒªãƒªãƒ¼ã‚¹ã‹ã€‚ãƒ¡ã‚¿ã¯ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¨çµ„ã‚“ã§OSSåŒ–ã™ã‚‹ã¨ã®ã“ã¨ã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆç„¡æ•µã ãªã€‚OpanAI x Azureã®äººã¯ã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®ã€ŒChatGPT - Azure OpenAI å¤§å…¨ã€ã¯å‚è€ƒã«ãªã‚‹ã‹ã€‚ChatGPTã®æ€§èƒ½ãŒåˆæœŸã«æ¯”ã¹ã¦åŠ£åŒ–ã—ã¦ã„ã‚‹ã¨ã®å ±å‘Šã‚‚ã€‚ã€Œç”ŸæˆAIã¨è‘—ä½œæ¨©ã«é–¢ã™ã‚‹è«–ç‚¹æ•´ç†ã€ã®å›³ã¯ç´ æ™´ã‚‰ã—ã„ã€‚OpenAIã®CEOã§ã‚ã‚‹Sam Altmanæ°ãŒå…±åŒå‰µæ¥­ã—ãŸWorldCoinãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒ7/24ã«ä»®æƒ³é€šè²¨WLDã‚’ãƒ­ãƒ¼ãƒ³ãƒã—ãŸã€æ—¥æœ¬ã«ã‚‚è™¹å½©èªè¨¼OrbãŒè¤‡æ•°è¨­ç½®ã•ã‚Œã‚‹ã‚‚èªçŸ¥åº¦ã¯ä»Šä¸€æ­©ã‹ã€AIã§å¾—ã‚‰ã‚ŒãŸåˆ©ç›Šã‚’é…ã‚‹ã€BIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€æ—¦ã¨ã®ã“ã¨ã€‚

- LLaMa2ã‚’ãƒªãƒªãƒ¼ã‚¹ã€å•†ç”¨åˆ©ç”¨ãŒå¯èƒ½ã«
	- https://ai.meta.com/llama/
- LLaMa2ã‚’æ—©é€Ÿggmlã«å¤‰æ›ã•ã‚ŒãŸ
	- https://huggingface.co/TheBloke
- ãƒ¡ã‚¿ç¤¾LLaMa2ã‚’ã€Microsoftã¨çµ„ã‚“ã§OSSåŒ–ã™ã‚‹ã¨ç™ºè¡¨
	- https://twitter.com/alex_valaitis/status/1681348531834044426?s=20
- Llama2-70B-Chatãƒ¢ãƒ‡ãƒ«ã¯ã€ãªã‚“ã¨æœ‰ç”¨æ€§è©•ä¾¡ã§GPT-3.5Turboã®ChatGPTã‚’æ‰“å€’ï¼
	- https://twitter.com/umiyuki_ai/status/1681361453838929923?s=20
- LangChaiã®çµ±åˆé–‹ç™ºç’°å¢ƒLangSmithæ­£å¼ç‰ˆç™ºè¡¨
	- https://blog.langchain.dev/announcing-langsmith/
	- ãŠã£ã¨ã€æ­£å¼ç™ºè¡¨ã•ã‚ŒãŸã®ã‹
- Llama2ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’2Tãƒˆãƒ¼ã‚¯ãƒ³ã«å¢—ã‚„ã—ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚’4Kã«ã—GQAã‚’æ¡ç”¨ã€‚å ±å‘Šæ›¸ã§ã¯æœ‰ç”¨æ€§ã¨å®‰å…¨æ€§ã®å‘ä¸Šã«å‘ã‘ãŸSFTã¨RLHFã®è©³ç´°ãŒå……å®Ÿã—ã¦ã„ã‚‹ã€‚
	- å²¡é‡åŸã•ã‚“ã®è§£èª¬
	- https://twitter.com/hillbig/status/1681436336451125257?s=20
- BigChat Enterpriseã‚’ç™ºè¡¨
	- https://blogs.microsoft.com/blog/2023/07/18/furthering-our-ai-ambitions-announcing-bing-chat-enterprise-and-microsoft-365-copilot-pricing/
	- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã¯æš—å·åŒ–ã•ã‚Œã€çµ„ç¹”å¤–ã«æµã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¯ä¿å­˜ã•ã‚ŒãšMicrosoftã‹ã‚‰è¦‹ã‚Œã¾ã›ã‚“
- LLaMA2ã€ãƒãƒƒãƒˆä¸Šã®ãƒ‡ãƒ¢ã ã¨ã‚ã‚“ã¾æ—¥æœ¬èªå¼·ããªã„å°è±¡ã ã‘ã©ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§ggml 4bitç‰ˆã®13B chatå‹•ã‹ã—ãŸæ„Ÿã˜æƒ³åƒä»¥ä¸Šã«ã¾ã¨ã‚‚ã«ä¼šè©±ã§ãã‚‹ãªã€ã¨ã„ã†å°è±¡
	- https://twitter.com/RosaRugosaBeach/status/1681554704701194240?s=20
- æ±å¤§ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒ¼ã‚¹ã‚¯ãƒ¼ãƒ«
	- https://deeplearning.jp/llm2023/
- ChatGPTã®æ€§èƒ½ãŒã€åˆæœŸãƒªãƒªãƒ¼ã‚¹ã«æ¯”ã¹ã¦æœ€è¿‘ä½ä¸‹ã—ã¦ã„ã‚‹ã¨ã®è«–æ–‡ãŒ
	- https://arxiv.org/pdf/2307.09009.pdf
- GitHubã®copilotãŒVSCodeã‹ã‚‰å¯èƒ½ã«
	- https://twitter.com/code/status/1682435342610079761?s=20
- TypeChatã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã«ã‚ˆã‚‹ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä»£ã‚ã‚Šã«Type(å‹ï¼‰ã‚’ã¤ã‹ã£ãŸChatã€ã‚¹ã‚­ãƒ¼ãƒã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ã‚‚ã‚ˆã¶ã‚‰ã—ã„ã€‚
	- https://github.com/microsoft/TypeChat
- LLaMa2ã¯ã€æ´å¯Ÿã¨ãƒ¡ã‚¿èªçŸ¥ã«å„ªã‚Œã¦ã„ã‚‹
	- https://arxiv.org/pdf/2307.10928.pdf
- LangChainã®LLaMa2ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹
	- https://python.langchain.com/docs/integrations/chat/llama_api
- llama2 13B chat 4bit
	- https://twitter.com/manjiroukeigo/status/1683047350141599744?s=20
- äº¬å¤§ã€ä»å…¸ã‚’GPT-ï¼”ã§å­¦ç¿’ã—ãŸã€ãƒ–ãƒƒãƒ€ãƒãƒƒãƒ‰ãƒ—ãƒ©ã‚¹ã‚’ç™ºè¡¨
	- https://ledge.ai/articles/buddha_bot_plus_kyoto_university
	- GPT-4ã§ä»å…¸ã‚’è§£é‡ˆ ã‚ã‹ã‚Šã‚„ã™ãå›ç­”
- TheBloke/Llama-2-70B-Chat-GGML
	- https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML
- ç”ŸæˆAIã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã¨Code Interpreteræ´»ç”¨ãƒãƒ³ã‚ºã‚ªãƒ³ with PLATEAU
	- https://connpass.com/event/290745/
- Abstraction and Analogy: The Keys to Robust Artificial Intelligence
	- https://www.eventbrite.co.uk/e/abstraction-and-analogy-the-keys-to-robust-artificial-intelligence-tickets-675075728677?aff=oddtdtcreator
- Microsoftã«ã‚ˆã‚‹OpenAIã€€Azureå¤§å…¨
	- https://speakerdeck.com/hirosatogamo/chatgpt-azure-openai-da-quan
	- GPTã®å…¨ä½“åƒã€Microsoftã¨OpenAIã®é–¢ä¿‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãªã©å…¨ã¦å­¦ã¹ã¾ã™
- llama2-webui
	- https://github.com/liltom-eth/llama2-webui
	- Run Llama 2 locally with gradio UI on GPU or CPU from anywhere
- DeepMindã‹ã‚‰å¼·åŒ–å­¦ç¿’ã§æ ¸èåˆç‚‰ï¼ˆãƒˆã‚«ãƒã‚¯ï¼‰ã‚’åˆ¶å¾¡ã™ã‚‹è©±
	- https://arxiv.org/abs/2307.11546
- Google Colab ã§ Llama 2 + LangChain ã® RetrievalQA ã‚’è©¦ã™
	- https://note.com/npaka/n/n6d33c2181050
- åŒ»ç™‚ã®ã‚ã‚‰ã‚†ã‚‹ã‚¿ã‚¹ã‚¯ã§æœ€å„ªç§€ã‚¹ã‚³ã‚¢ã‚’ç²å¾—ã™ã‚‹åŒ»ç™‚ç‰¹åŒ–ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒMed-PaLM Mã€
	- https://arxiv.org/pdf/2307.14334.pdf
- ã€Œç”ŸæˆAIã¨è‘—ä½œæ¨©ã«é–¢ã™ã‚‹è«–ç‚¹æ•´ç†ã€
	- ãªã‚“ã¨è©³ç´°ãªå›³ãŒã€ã€
	- https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/hoseido/r05_01/?fbclid=IwAR06f_2GFjUTlVn6Ofot52SfMhcJuyjTtkzF-D7DczgB75d0d5iCC9ucGnQ
- World Coinã®ç™ºè¡¨ï¼ˆSam AltmanãŒé–¢ä¿‚ã—ã¦ã„ã‚‹ï¼‰ã€æ—¥æœ¬ã§ã‚‚èªè¨¼OrbãŒè¨­ç½®
	- ä»£å®˜å±±ã®ã‚µã‚¤ãƒˆã«è¡Œã£ã¦ã¿ãŸãŒã€äººã¯ã¼ã¡ã¼ã¡ã€æ—¥æœ¬ã§ã¯ä»Šä¸€æ­©ã®èªçŸ¥åº¦ã‹ã€‚æš‘ã‹ã£ãŸ
	- https://twitter.com/umiyuki_ai/status/1685323501069299713?s=20
	- 200ä¸‡äººãŒã‚ªãƒ¼ãƒ–èªè¨¼æ¸ˆã¿ã¨ã‹è¨€ã£ã¦ãŸã®ã«ã€äºˆç´„è€…ã•ãˆã¾ã 32ä¸‡äºº

## 7/18

æš‘ãã¦ã™ã§ã«å¤ãƒãƒ†ã§ã™ã€‚ã‚ã„ã‚‚å¤‰ã‚ã‚‰ãšcode interpreterã®äº‹ä¾‹ãŒç¶šã€…ã€æ¥å¹´åº¦ã®è¬›ç¾©è³‡æ–™ã‚‚ã“ã‚Œã§ä½œã‚‹ã‹ã€‚LLMæ™‚ä»£ã®ãƒªãƒ†ãƒ©ã‚·ãƒ¼ã£ã¦ä½•ã¨ã„ã†å•ã„ã€æ•™è‚²ã‚‚ãã†ã ã—ã€ãƒªã‚«ãƒ¬ãƒ³ãƒˆã‚‚ãã†ã€‚Promptflowã¿ãŸã„ãªã€ï¼ˆä¸€è¦‹ï¼‰æ€ã„ä»˜ãã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãŒã‚¿ã‚±ãƒã‚³ã®ã‚ˆã†ã«å‡ºã¦ãã‚‹ã ã‚ã†ã€‚AlphaFoldãŒFoldItã¨ã„ã†ã‚²ãƒ¼ãƒ ã‹ã‚‰åå‰ãŒãã¦ã„ã‚‹ã¨ã¯çŸ¥ã‚‰ãªã‹ã£ãŸã€é›†åˆçŸ¥ã­ã€‚Googleã®NotebookLLMã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒãƒ¼ãƒˆãƒãƒƒãƒ‰ã¨ã„ã†å¾“æ¥ã‹ã‚‰ã®å¤¢ãŒã€ä¸€æ­©å®Ÿç¾ã«è¿‘ã¥ãã‹ã€‚æ™®é€šã«ä½¿ã£ã¦ã„ã‚‹Embeddingãªã‚“ã‹ã‚‚ã€ã‚‚ã¡ã‚ƒã‚“ã¨æŒ¯ã‚Šè¿”ã£ã¦ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã®ä½™åœ°ãŒã‚ã‚‹ã€‚

- ChatGPTã®code interpreterã‚’ã¤ã‹ã¦ã€è¬›ç¾©ã®ä¸€éƒ¨ã‚’ä½œæˆï¼ˆæ±å¤§ã€å¼·åŒ–å­¦ç¿’ã€ä»Šäº•å…ˆç”Ÿï¼‰
	- https://twitter.com/ImAI_Eruel/status/1678378444441387010?s=20
- What Should Data Science Education Do with Large Language Models?
	- https://arxiv.org/abs/2307.02792v2
	- LLMã«ã‚ˆã‚Šæ•™è‚²ã®å¤‰é©ã€LLM-informed creativity, critical thinking, AI-guided programming.
- AlpacaEvalãªã‚‹LLMãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒã‚ã£ãŸã€OSSç³»ã§ã¯ã€Vicuna-33BãŒãƒˆãƒƒãƒ—
	- https://tatsu-lab.github.io/alpaca_eval/
-  AI tools are designing entirely new proteins that could transform medicine
	- https://www.nature.com/articles/d41586-023-02227-y
	- RFdiffusionã¨ã„ã†æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã®åˆæˆãŒã€AlphaFoldãªã©ã®ãƒãƒ«ã‚·ãƒ¼ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ™ãƒ¼ã‚¹ï¼Ÿã®æ‰‹æ³•ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨ã®è«–æ–‡
- GPT-4ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è‡ªå‹•åŒ–ã€ŒPromptflowã€é–‹ç™ºã€Carnotï¼ˆã‚«ãƒ«ãƒãƒ¼ï¼‰ãŒ8,500ä¸‡å††ã‚’ãƒ—ãƒ¬ã‚·ãƒ¼ãƒ‰èª¿é”
	- https://thebridge.jp/2023/07/carnot-pre-seed-round-funding
	- é›¨å¾Œã®ã‚¿ã‚±ãƒã‚³ã®ã‚ˆã†ã«ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ãŒç«‹ã¡ä¸ŠãŒã‚‹ã‹ï¼Ÿï¼Ÿ
- LLamaindexã«ãŠã‘ã‚‹ã€RAGã®èª¬æ˜ by npakaã•ã‚“
	- https://note.com/npaka/n/n27a36f784fb3
	- LLMã¨ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿åˆã‚ã›ã‚‹ãŸã‚ã®ã€ŒRAGã€(Retrieval Augmented Generation) ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ 
- ã‚¹ãƒˆãƒ©ãƒ³ã‚°å…ˆç”Ÿã®ç·šå½¢ä»£æ•°è¬›ç¾©ã®ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãªãƒãƒ¼ãƒˆã€è¡Œåˆ—æ¼”ç®—ã‚’æ¥µã‚ã‚‹ã€‚
	- https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra
- DeepMindã®Hasabisã•ã‚“ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼
	- AlphaGoã®ã‚ã¨ã«AlphaFoldã«ç€æ‰‹ã—ãŸã®ã¯ã€FoldItï¼ˆé›†åˆçŸ¥ã§æŠ˜ã‚Šç•³ã¿å•é¡Œã‚’è§£ãã‚²ãƒ¼ãƒ ï¼‰ã«ç€æƒ³ã‚’å¾—ãŸã¨ã®ã“ã¨
	- https://podcasts.apple.com/us/podcast/a-i-could-solve-some-of-humanitys-hardest-problems/id1548604447?i=1000620748039
- OpenAIã‹ã‚‰ã€embeddingã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ä½¿ãˆãªã„ï¼Ÿ
	- https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb
- Google Labsã€è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒNotebookLMã€ã®æä¾›é–‹å§‹ã‚’ç™ºè¡¨--ã¾ãšç±³å›½ã‹ã‚‰
	- https://japan.zdnet.com/article/35206577/
	- NotebookLMã§ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒãƒ¼ãƒˆã‚„æƒ…å ±æºã‚’ã€åœŸå°ã«ã—ã¦ã€è¨€èªãƒ¢ãƒ‡ãƒ«ãŒç¨¼åƒ
- Bardã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ãŒã€‚ã€‚	
	- https://twitter.com/i/status/1680237703676190722
- 

## 7/10

OpenAIã‹ã‚‰GPT plusãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ã«ã€code interpreterãŒé–‹æ”¾ã•ã‚ŒãŸã€‚ã“ã‚Œã§ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ä»•äº‹ãŒãªããªã‚‹ï¼ŸPlusã˜ã‚ƒãªã„äººã‚‚ã€ã¾ãšã¯æ‰‹å§‹ã‚ã«LangChainã®ãƒ“ãƒ‡ã‚ªã‚’ã¿ã¦ã€ãƒ‡ãƒ¼ã‚¿ã¨ã®ãƒãƒ£ãƒƒãƒˆã‚’ä½“æ„Ÿã—ã¦ã¿ã‚‹ã¨ã„ã„ã‹ã‚‚ã€‚æ¥”æ–‡å­—ã®ç¿»è¨³ãªã©ã€æ§˜ã€…ãªå­¦å•é ˜åŸŸã«LLMãŒä¾µé£Ÿã—ã¦ã‚†ãã€‚OpenAIã¯ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆå•é¡Œã‚’AIã§è§£ãã¿ãŸã„ãªãã£ã¡ã®æ–¹å‘ï¼ˆçµæœã¨ã—ã¦AIã®åŸºç›¤æ•´å‚™ãŒé€²ã‚€ï¼‰ã€‚LLMã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦ã€æ€§æ ¼è¨ºæ–­(Big5)ã¨ã„ã†ã®ã¯é¢ç™½ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã€‚ä½¿ã†äººã®æ€§æ ¼åˆ¤æ–­ã¨åˆã‚ã›ã‚‹ã¨ãƒãƒƒãƒãƒ³ã‚°ãŒå–ã‚ŒãŸã‚Šã—ã¦ã€‚

- llamaindexã«ã¦text-to-SQLã®å¤§å¹…ãªã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
	- https://twitter.com/llama_index/status/1676002583381692421?s=20
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®"æ€§æ ¼"ç‰¹æ€§ã‚’åˆ†æï¼†èª¿æ•´ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€DeepMindã€ã‚±ãƒ³ãƒ–ãƒªãƒƒã‚¸å¤§å­¦ã€æ…¶å¿œå¤§å­¦
	- Personality Traits in Large Language Models
	- https://arxiv.org/abs/2307.00184
- ã‚¿ã‚¹ã‚¯ã®è¤‡é›‘ã•ãŒå¢—ã™ã¨LLMã®æ€§èƒ½ãŒæ€¥é€Ÿã«ä½ä¸‹ã™ã‚‹ç¾è±¡ã‚’ä¸å¯§ã«æ¤œè¨¼
	- Faith and Fate: Limits of Transformers on Compositionality
	- https://arxiv.org/abs/2305.18654
- LangChainã«ãŠã‘ã‚‹Spacy Embeddingã®åˆ©ç”¨ä¾‹
	- OpenAIã‚„HuggingFaceä»¥å¤–ã€
	- https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/spacy_embedding
- EUã®AIè¦åˆ¶ã®ã€æœ€çµ‚æ¡ˆã®ä¸€ã¤å‰ã®å’Œè¨³ãŒã€ç·å‹™çœã®ã€ŒAIãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¤¾ä¼šæ¨é€²ä¼šè­°ã€ã§å…¬é–‹
	- https://www.aplawjapan.com/publications/20220725
- IPAã«ã€Œãƒ‡ã‚¸ã‚¿ãƒ«åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ã€æ–°è¨­ã€ãƒ‡ã‚¸ã‚¿ãƒ«åºã¨å”åŠ›ã—ã¦åŸºç›¤æ•´å‚™
	- https://xtech.nikkei.com/atcl/nxt/news/18/15517/
	- å¤å·£ã®ç¤¾ä¼šåŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ãŒæ”¹çµ„ã•ã‚Œã¦ã€ã€Œãƒ‡ã‚¸ã‚¿ãƒ«åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ã€ã«ãªã‚Šã€ãƒ‡ã‚¸ã‚¿ãƒ«åºã®å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ã€‚ã€‚æ‚²ã—ã„ã€‚
- CAMEL-5B ã¨ SentenceTransformers ã§ LlamaIndex ã‚’è©¦ã™
	- https://note.com/npaka/n/n2e408cded4ac
- DeepLearningAIã‹ã‚‰ã€æ–°ã‚³ãƒ¼ã‚¹ã€LangChain: Chat with Your Dataã‚’ç„¡å„Ÿãƒªãƒªãƒ¼ã‚¹
	- https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/
- OpenAIã€è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨ã®ï¼’ï¼ï¼…ã‚’ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå•é¡Œã«å‰²ãã“ã¨ã‚’è¡¨æ˜
	- ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆå•é¡Œè‡ªä½“ã‚’AIã§è‡ªå‹•åŒ–ã™ã‚‹ã‚ˆã†ã«ã‚‚è¦‹ãˆã‚‹ï¼ˆã¤ã¾ã‚Šç›®ã«ã¯ç›®ã‚’ã€AIã«ã¯AIã‚’ï¼‰
	- https://openai.com/blog/introducing-superalignment
- NPå›°é›£ã¨ã„ã‚ã‚Œã‚‹ã€3æ¬¡å…ƒãƒ‘ãƒƒã‚­ãƒ³ã‚°å•é¡Œã‚’ã€MITãŒè§£ãï¼Ÿ
	- https://news.mit.edu/2023/chore-packing-just-got-faster-and-easier-0706
	- FFTã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨
- æ¥”å½¢æ–‡å­—ã®è§£èª­ã«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒã‚’é§†ä½¿ã—ã¦æˆåŠŸ
	- https://academic.oup.com/pnasnexus/article/2/5/pgad096/7147349?login=false
- OpenAI Code Interpreterã‚’ã€GPT plusãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è§£æ”¾ã€‚
- 

## 7/4

æš‘ãã¦ãƒãƒ†ã¦ã¾ã—ãŸã€‚LLMã£ã¦ã€äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡æ“¬ã™ã‚‹ãªã‚‰ã°ã€AgentãŒå®Ÿè£…ã§ãã‚‹ã¨ã„ã†ãŒã€å®Ÿè£…ãŒè¿‘ã¥ã„ã¦ããŸã€‚è¨ˆç”»å•é¡Œã‚‚ç›´æ¥è§£ã‹ã›ã‚‹ã‚ˆã‚Šã‚‚ã€è¨ˆç”»å•é¡Œã‚’ç”Ÿæˆã•ã›ã‚‹ã¨ã„ã†çµ„ã¿åˆã‚ã›ã‚‚é¢ç™½ã„ã€‚å½¢å¼è¨€èªãªã‚“ã‹æŒ¯ã‚Šè¿”ã£ã¦ã¿ã‚‹ã®ã‚‚é¢ç™½ã„ã‹ã‚‚ã€‚LLMã‚’Computer Visonã¸ã®å¿œç”¨ã€è¨€èªã¨ç”»åƒã®åŒºåˆ¥ã¯ãªããªã‚‹ã®ã‹ï¼ŸGoogleã®Kaggleãƒãƒ£ãƒ¬ãƒ³ã‚¸ã£ã¦ã€LLMã®å“è³ªä¿è¨¼ã§ã¯é‡è¦ãªè¦ç´ ã€‚ãƒãƒ³ãƒ»ã‚»ãƒŸãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çµ±è¨ˆã£ã¦ã®ãŒã‚ã‚‹ã®ã‹ï¼Ÿ å²¡é‡åŸã•ã‚“ã®ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯æ–°ãŸãªçŸ¥èƒ½ã‹ã€ã¯ãŠã™ã™ã‚ã€‚è¨˜å·æ¥åœ°ã£ã¦ã€LLMã§å®Ÿç¾ã§ãã¦ã‚“ã˜ã‚ƒãªã„ï¼Ÿã¿ãŸã„ãªã®ãŒã˜ã‚ã˜ã‚ã¨èªã‚‰ã‚Œã¤ã¤ã‚ã‚‹(MLSE2023åˆå®¿ã‚ˆã‚Šï¼‰ã€‚DeepMindã®Geminiã€æœ¬å½“ã«å‡ºã‚‹ã®ã‹ï¼Ÿ

- OpenAIã®ilian Wengã«ã‚ˆã‚‹LLMã‚’ã¤ã‹ã£ãŸã€Agentã®è‰¯è§£èª¬è¨˜äº‹
	- https://lilianweng.github.io/posts/2023-06-23-agent/
- LLMã‚’ä½¿ã£ã¦ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã‚’è§£ãã€PDDLã¨å‘¼ã°ã‚Œã‚‹ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°è¨€èªã«å¤‰æ›ã•ã›ãŸä¸Šã§ã‚½ãƒ«ãƒãƒ¼ã«è§£ã‹ã›ã‚‹ã€‚LLMå˜ç‹¬ã‚ˆã‚Šæ­£ç¢ºã€‚
	- https://arxiv.org/abs/2304.11477
- Relicã®ç¤¾å†…å‹‰å¼·ä¼šã§ã®ç”ŸæˆAIè§£èª¬ï¼—ï¼Pè³‡æ–™
	- https://qiita.com/hedgehog051/items/b1308e8baf7b0f551548
- å½¢å¼è¨€èªã¨ã¯ä½•ã‹ï¼ˆç¾ä»£æ€æƒ³ï¼‰
	- http://www.seidosha.co.jp/book/index.php?id=3821&status=published
	- ã€Œæ­£ã—ã„æ–‡ã¨ã¯ä½•ã ã‚ã†ã‹ã€‚ã€‚ã€‚ã€ã‹ã‚‰å§‹ã¾ã‚‹
- Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language
	- https://huggingface.co/papers/2306.16410
- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã®å½±éŸ¿ã‚’æ¶ˆã™Kaggleãƒãƒ£ãƒ¬ãƒ³ã‚¸ by Google
	- https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html
- ç ”ç©¶è€…ã®è³‡è³ªã¨æ•™å“¡ã®ä»•äº‹ by è°·ä¸­æ•™æˆ
	- https://twitter.com/verypluming/status/1674445457463062534?s=20
- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ°—ã«ã—ãŸæ–‡æ›¸åˆ†å‰²
	- https://twitter.com/RLanceMartin/status/1674817117475188737?s=20
- ãƒãƒ³ãƒ»ã‚»ãƒŸãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯çµ±è¨ˆ
	- https://www.kyoritsu-pub.co.jp/book/b10031225.html
	- åˆ†å¸ƒé–¢æ•°ã€å¯†åº¦é–¢æ•°ã‚„å›å¸°é–¢æ•°ã«ã¤ã„ã¦ã€ä¸€å®šã®æ»‘ã‚‰ã‹ã•ã®ã¿ã‚’ä»®å®šã—ã¦ã€ãƒãƒ³ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ãªæ¨å®šã¨æ¤œå®šã‚’è¡Œã†æ–¹æ³•ã‚’ç´¹ä»‹ã™ã‚‹
- DeepMindã®æ¬¡ä¸–ä»£AIã€ŒGeminiã€ã¯ChatGPTã‚’å‡Œé§•ã™ã‚‹ï¼Ÿ
	- https://wired.jp/article/google-deepmind-demis-hassabis-chatgpt/?utm_medium=social&utm_source=twitter
	- ã€ŒGeminiã¯AlphaGoã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ã®å¼·ã¿ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®å“è¶Šã—ãŸè¨€èªèƒ½åŠ›ã‚’çµ„ã¿åˆã‚ã›ãŸã‚‚ã®ã€
- å²¡é‡åŸã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯æ–°ãŸãªçŸ¥èƒ½ã‹ã€ã®å€‹äººçš„ç€ç›®ãƒã‚¤ãƒ³ãƒˆã¯ã€transformerã§äº¤äº’ã«ç©å±¤ã™ã‚‹è‡ªå·±æ³¨æ„æ©Ÿæ§‹ã¨ãƒ‘ãƒ¼ã‚»ãƒ—ãƒˆãƒ­ãƒ³ã«ã¤ã„ã¦ã€å‰è€…ãŒã€ŒçŸ­æœŸè¨˜æ†¶ã€ã€å¾Œè€…ãŒé•·æœŸè¨˜æ†¶ã¨ã—ã¦æ©Ÿèƒ½ã™ã‚‹ã¨ã®è§£èª¬ï¼ˆp.108ï¼‰
- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ç‰©ç†åŒ–å­¦ç‰¹å¾´é‡ã‚’å–ã‚Šå…¥ã‚ŒãŸç‰©æ€§äºˆæ¸¬ by IBM
	- åˆ†å­ã®ç‰©ç†åŒ–å­¦çš„ç‰¹å¾´é‡ã‚’é¸å®šã—ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹ã€€
	- https://arxiv.org/abs/2306.14919v1
- VARãƒ¢ãƒ‡ãƒ« ï¼‹ ã‚°ãƒ¬ãƒ³ã‚¸ãƒ£ãƒ¼å› æœæ€§ã®çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã«ã‚ˆã‚‹ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å› æœæ¢ç´¢
	- https://twitter.com/kenken26679105/status/1675281986917900288?s=20
	- éã‚¬ã‚¦ã‚¹ãƒ¢ãƒ‡ãƒ«ãƒ»VAR-LiNGAMã§ã‚ã‚Œã°ã€åŒæ™‚åˆ»ã‚‚åˆ†æå¯èƒ½
	- https://twitter.com/kenken26679105/status/1675306307849699328?s=20
- Chains vs Agents" webinar by LangChain
	- https://www.youtube.com/watch?v=bYLHklxEd_k
- çµå±€è¨˜å·æ¥åœ°ã£ã¦ãªã‚“ã ã£ãŸã‘ï¼Ÿ by ä¸¸å±±ï¼ MLSE
	- https://twitter.com/maruyama/status/1675813852947308544?s=20
	- å®Ÿä¸–ç•Œã¸ã®å‚ç…§ãªã—ã§ã€è¨€èªç©ºé–“å†…ã§ã®åŸ‹ã‚è¾¼ã¿ã ã‘ã§æ„å‘³ã‚’æ“ä½œ

## 6/26

ã‚ã„ã‚‚ã‹ã‚ã‚‰ãšOpenAIã®Function APIã®åˆ©ç”¨ã«ã¤ã„ã¦ã€å…·ä½“ä¾‹ãŒå¢—ãˆã‚‹ã€Pydatanicã¨çµ„ã¿åˆã‚ã›ã‚Œã°ã»ã¼ç„¡æ»ã®æƒ…å ±æŠ½å‡ºãŒã§ããã†ã ã—ã€æŠ½å‡ºã—ãŸæƒ…å ±ã‚’ã¤ã‹ã£ãŸQ&Aãªã©ã€ã¡ã‚‡ã£ã¨èª¬æ˜æ€§ã‚‚ã‚ãŒã‚‹ã‹ï¼Ÿãƒ˜ãƒ«ã‚¹ã‚±ã‚¢åˆ†é‡ã§ã®GoogleAIã®ç™ºè¡¨ã¯è¡æ’ƒçš„ã€çœ¼ç§‘æ¤œè¨ºã§æ§˜ã€…ãªç—…æ°—ãŒè¦‹ã¤ã‹ã‚‹ã€‚ã€‚ã€‚OpenLLAMaãŒã§ã¦ãã¦ã€ã‚ã£ã¨ã„ã†ã¾ã«Flanã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‚ã®ãŒã€å•†ç”¨åˆ©ç”¨ã§ãã‚‹ã®ã‹ï¼Ÿç”ŸæˆAIã®ç ”ç©¶ã‚„ä»•äº‹ã¸ã®å½±éŸ¿ã«ã¤ã„ã¦ã¾ã¨ã¾ã£ãŸè³‡æ–™ãŒã¼ã¡ã¼ã¡ã§ã¦ããŸã€‚ä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ããƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãªã‚“ã‹ã‚‚LLMãªã‚‰ã§ã¯ã®ç ”ç©¶ã‹ã€‚LLMã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–ã‚‚å¼•ãç¶šãã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®å–ã‚Šçµ„ã¿ãŒã‚ã‚‹ã€‚MITã®è©¦é¨“å•é¡Œã‚’GPT4ã«è§£ã‹ã›ã‚‹è©±ãŒä¸æ­£ã¨ã„ã†è¨˜äº‹ãŒã€ã¡ã‚‡ã£ã¨æ‚²ã—ã„ãŒã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®æˆæœã‹ã€‚ã€‚


- OpenLLaMAã¯ã€LLaMaã®ã‚ªãƒ¼ãƒ—ãƒ³ç‰ˆï¼ˆå•†ç”¨åˆ©ç”¨ãŒå¯èƒ½ï¼Ÿï¼‰GPU RAMã¯26.5GBã§å‹•ä½œã®æ¨¡æ§˜
	- https://huggingface.co/openlm-research/open_llama_13b
	- https://github.com/openlm-research/open_llama
- Google	 ãƒ”ãƒ¼ãƒãƒ£ã‚¤æ°ã®è¬›æ¼”ã€ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢åˆ†é‡ã§ã€AIãŒCTã¨ã‹MRIã¨ã‹ã‚’ä»£æ›¿ã™ã‚‹ã‹ã‚‚ï¼ˆçœ¼åº•æ¤œæŸ»ã§ä»£æ›¿ã§ãã‚‹ï¼Ÿï¼‰
	- https://twitter.com/alvinfoo/status/1670599368930656257?s=20
- OpenAIã®Function callã¨pydantic 	ã‚’çµ„ã¿åˆã‚ã›ãŸä¾‹ã‚„å†å¸°æ§‹é€ ã¸ã®å¯¾å¿œãªã©ã€æƒ…å ±æŠ½å‡ºãŒã“ã‚“ãªã«ä¾¿åˆ©ã«
	- https://twitter.com/jxnlco/status/1670764386447953921?s=20
	- https://twitter.com/matchaman11/status/1670799349004083200?s=20
	- https://gpt-index.readthedocs.io/en/latest/examples/output_parsing/openai_pydantic_program.html
- ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã¨ãƒ‡ã‚³ãƒ¼ãƒ€ã«ã¤ã„ã¦ã‚ã‹ã‚Šã‚„ã™ã„è§£èª¬
	- https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder
- LangChainã§ã€	**MarkdownHeaderTextSplitter**ã‚’ä½¿ãˆã°ã€å¼•ç”¨å…ƒã¤ãã®Q&AãŒç°¡å˜ã«
	- https://note.com/hamachi_jp/n/nf23b75d14068
- ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã«ã‚ˆã‚‹ã€ç”ŸæˆAIã®ç”Ÿç”£æ€§ã¸ã®å½±éŸ¿ãƒ¬ãƒãƒ¼ãƒˆ
	- ç”ŸæˆAIã§å¾“æ¥­å“¡ã®æ™‚é–“ã‚’6~7å‰²ç¯€ç´„å¯èƒ½ 
	- ç”ŸæˆAIã®ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒé«˜ã„ã®ã¯2æšç›®ç”»åƒã®å³ä¸Šã®é ˜åŸŸ
	- ç”£æ¥­Ã—ç”¨é€”åˆ¥ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè©•ä¾¡(3æšç›®) 
	- ç‰¹å®šé ˜åŸŸã®å…·ä½“çš„ãªç”¨é€”ã¨çµŒæ¸ˆä¾¡å€¤(4æšç›®)
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#key-insights
- GPTï¼”ALLãƒ™ãƒ¼ã‚¹ã®copilotãŒç™»å ´ï¼Ÿ
	- https://morph.so/
- Debateã€€Treeã€è­°è«–ã®æ§‹é€ ã‚’ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ©ã‚¤ã‚ºã™ã‚‹
	- https://debatetreeofthoughts.streamlit.app/
- åŸºç›¤ãƒ¢ãƒ‡ãƒ«ãƒ»ç”ŸæˆAIã®ç§‘å­¦ç ”ç©¶ã¸ã®å½±éŸ¿ã«é–¢ã™ã‚‹è³‡æ–™ã€æ–‡ç§‘çœ åŸºç¤ç ”ç©¶æŒ¯èˆˆéƒ¨ä¼š(ç¬¬11å›)
	- https://www.mext.go.jp/b_menu/shingi/gijyutu/gijyutu27/siryo/mext_00007.html
- LlamaIndex	ã§ã€function call+pydatnicã‚’çµ„ã¿åˆã‚ã›ã¦ã€	query planningãŒå¯èƒ½ã«ã€
	- https://gpt-index.readthedocs.io/en/latest/examples/agent/openai_agent_query_plan.html
- æ°´å£ç”»ä¼¯ãªããªã‚‹ã€åˆæŒ
	- https://twitter.com/AKZ161/status/1671498721287352320?s=20
- PyRCAã€Pythonã‚’ã¤ã‹ã£ãŸã€ãƒ«ãƒ¼ãƒˆåŸå› åˆ†æ
	- https://github.com/salesforce/PyRCA
- OpenAIã®Function APIã®è§£èª¬
	- https://every.to/chain-of-thought/gpt-4-can-use-tools-now-that-s-a-big-deal
- Flan-Open-Llama-7bã€OpenLLaMaã‚’ã€Flanã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸï¼Ÿ
	- https://huggingface.co/conceptofmind/Flan-Open-Llama-7b
- ç¬¬2å›LLMå‹‰å¼·ä¼š
	- https://llm-jp.nii.ac.jp/llm/2023/06/20/study-group-2.html
- local llmã§sentence embeddingã©ã‚Œä½¿ãˆã°è‰¯ã„ã‚“ã ã£ã‘
	- https://note.com/if001/n/n25d795afe571
- OpenAIã®Embbedingã‚’ã¤ã‹ã£ã¦æ–‡ç« ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
	- https://techblog.gmo-ap.jp/2023/06/22/embeddings_api_calc_sentence_similarity/
- CVPR2023ã‚ˆã‚Šã€ç–‘ä¼¼ç¢ºç‡ãŒç¢ºç‡ã«ãªã‚‹ã¨ã„ã†å•é¡Œã¸ã®å›ç­”
	- https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Class_Adaptive_Network_Calibration_CVPR_2023_paper.pdf
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰å°è¦æ¨¡LLMã«é–¢ã™ã‚‹è«–æ–‡ Textbooks Are All You Need
	- 13å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"ã—ã‹â€ãªã„ãƒ¢ãƒ‡ãƒ«(phi-1)ã‚’ã€The Stackã¨StackOverflowã®ãƒ‡ãƒ¼ã‚¿ã‚’æ•™ç§‘æ›¸å“è³ªã«ã—ãŸ60å„„ãƒˆãƒ¼ã‚¯ãƒ³ã¨GPT-3.5ã§ç”Ÿæˆã—ãŸ10å„„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’NVIDIA A100 8å°ãƒ»4æ—¥é–“ã§å­¦ç¿’
	- https://arxiv.org/abs/2306.11644
- Flan-Open-Llama-3b
	- https://huggingface.co/conceptofmind/Flan-Open-Llama-3b
- Reasoning with Language Model is Planning with World Model
	- LLMã‚’ä½¿ã£ã¦ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’è§£ãéš›ã€ç¾åœ¨ã®çŠ¶æ…‹ã‚’LLMã‚’ä½¿ã£ã¦æŠŠæ¡ã™ã‚‹ã‚ˆã†ã«ã—ã¦(ã€Œä¸–ç•Œãƒ¢ãƒ‡ãƒ«ã€)ã€å–ã‚‹ã¹ãè¡Œå‹•ã«å¯¾ã™ã‚‹å ±é…¬ã‚’LLMã‚’ä½¿ã£ã¦è¦‹ç©ã‚‚ã£ãŸä¸Šã§ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æœ¨æ¢ç´¢ã«ã‚ˆã£ã¦è¡Œå‹•ã‚’æ±ºå®šã™ã‚‹æ‰‹æ³•(RAP; Reasoning via Planning)
	- https://arxiv.org/abs/2305.14992
- OpenAIã®Cookbookã«llama_indexã‚’ã¤ã‹ã£ãŸã€æ–‡æ›¸åˆ†æã®ä¾‹ãŒè¼‰ã‚‹
	- https://github.com/openai/openai-cookbook/blob/main/examples/third_party_examples/financial_document_analysis_with_llamaindex.ipynb
- GPT-4ãŒMITã®è©¦é¨“å•é¡Œã‚’æ­£ã—ãè§£ã„ãŸã¨ã„ã†è«–æ–‡ãŒæ‰‹ç¶šãçš„ã«ã‚‚æœ¬è³ªçš„å†…å®¹é¢ã§ã‚‚ä¸æ­£ã¨ã®æŒ‡æ‘˜
	- æ­£è§£ãŒã§ã‚‹ã¾ã§ä½•åº¦ã‚‚èã„ãŸç­‰ã®ä¸æ­£ãŒã‚ã£ãŸæ¨¡æ§˜ã€‚ã€‚
	- http://people.csail.mit.edu/asolar/CoursesPaperStatement.pdf

## 6/19

ä»Šé€±ã¯ã€6/12æ—¥ã«CEOã®æ…¶å¿œå¤§å­¦ã§ã®è¬›æ¼”ã€‚OpenAIã®APIã®ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã®è©±é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ‹¡å¤§ï¼ˆé’ç©ºæ–‡åº«ã®çŸ­ç·¨ã‚¯ãƒ©ã‚¹ãªã‚‰å–ã‚Šæ‰±ãˆã‚‹ï¼‰ã¨ã‹ã€Function callã®è¿½åŠ ã€‚ã“ã‚Œã§ã€LangChainã®ReActã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ã‚ãªãã¦ã‚‚ã€OpenAI Agentã§å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã¨LLMãŒé€£æºã—ãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ‰‹è»½ã«ä½œã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã®ã¯æã‚ã—ã„ã“ã¨ã€‚å“è³ªè©•ä¾¡ã®è¦–ç‚¹ã§ã¯ã€OpenAI Evalã¨ã‹ã®è©±é¡Œã‚‚ã€‚æ¬§å·ï¼¡ï¼©è¦åˆ¶ãŒã€æ¬§å·è­°ä¼šã®æŠ•ç¥¨ã§æ¡æŠã•ã‚Œã€æ¬¡ã®æ®µéšï¼ˆãƒˆãƒªãƒ­ãƒ¼ã‚°ï¼‰ã‚’çµŒã¦å¹´å†…ã«æˆç«‹ã‹ã€‚ã•ã£ããã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®HAIãƒãƒ¼ãƒ ãŒã€æ—¢å­˜LLMã®è¦åˆ¶ã¸ã®å¯¾å¿œçŠ¶æ³ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç³»ã®å‹ã¯ã€é–¢æ•°ãƒ‡ãƒ¼ã‚¿è§£æãªã©ã¯ç›®ã‹ã‚‰ã†ã‚ã“ã§ã¯ãªã„ã‹ã€‚ãƒ™ã‚¤ã‚ºæ´¾ã¨é »åº¦æ´¾ã®äº‰ã„ã«ã¯å·»ãè¾¼ã¾ã‚ŒãŸããªã„ã‚‚ã®ã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨LLMã®èåˆã‚‚ã€æ•´ç†ã•ã‚ŒãŸè«–æ–‡ãŒå‡ºã¦ããŸã€‚

- ã€ŒOpenAI CEO Sam Altmanæ°ã¨å¡¾ç”Ÿã¨ã®å¯¾è©±ã€é–‹å‚¬(6/12)
	- https://www.keio.ac.jp/ja/news/2023/6/15/27-139184/
	- ä¼šå ´ã¨ãªã£ãŸè¥¿æ ¡èˆãƒ›ãƒ¼ãƒ«ã«ã¯ç´„700åã®å­¦ç”ŸãŒé›†ã¾ã‚Šã€ç´„40åˆ†ã«ã‚ãŸã‚Šæ´»ç™ºãªè³ªç–‘å¿œç­”ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚ã¾ãŸãã®æ§˜å­ã¯519æ•™å®¤ã«ã‚‚é…ä¿¡ã•ã‚Œã€1,000åä»¥ä¸Šã®å­¦ç”Ÿã«ã¨ã£ã¦è²´é‡ãªæ©Ÿä¼šã¨ãªã‚Šã¾ã—ãŸã€‚
- ã€ŒäºŒã¤ã®åˆ†æ•£:ä¸åæ¨å®šé‡ã¨æœ€å°¤æ¨å®šé‡ã®ã©ã¡ ã‚‰ã‚’ä½¿ã†ã¹ãã‹ã€äº•æ‰‹ã•ã‚“(IBM)
	- é »åº¦æ´¾ã«å¯¾ã™ã‚‹åŸ·æ‹—ãªæ”»æ’ƒã¯ç¶šãã€‚ã€‚
	- https://ide-research.net/book/Which_variance_should_I_use.pdf
	-  ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®æœ¬è³ªã‚’ã²ã¨è¨€ã§ç­”ãˆã‚ã¨è¨€ã‚ã‚ŒãŸã‚‰ã€ã€Œè¦³ æ¸¬ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚ã£ã¨ã‚‚å½“ã¦ã¯ã¾ã‚Šã®è‰¯ã„ãƒ¢ãƒ‡ãƒ«ã‚’ã¤ãã‚‹ãŸã‚ã«ã€æœ€å°¤æ¨ å®šã‚’ä½¿ã£ã¦ãƒ‘ãƒ©ãƒ¡ã‚¿ãƒ¼ã‚’æ±ºã‚ã‚‹ã“ã¨ã€ã¨ç­”ãˆã‚Œã°ã‚ˆã„ã€
-  Evaluating the Social Impact of Generative AI Systems in Systems and Society
	- https://huggingface.co/papers/2306.05949
- ã€Œè¦‹ãŸããªã„ã‚‚ã®ã‚’ã¿ã‚‹ã€ï¼ˆPFNã®ä¸¸å±±ã•ã‚“ï¼‰
	- https://note.com/hiroshi_maruyama/n/n7890a1fb7aef
	- æ–°ãŸãªå€«ç†è¦ç¯„ã®ç¢ºç«‹ã«ã¤ã„ã¦
	- ã€Œäººé–“ä¸­å¿ƒã®AIã€ã«é•å’Œæ„Ÿã‚’æŠ±ãã€ã€Œäººé–“ãŒï¼ˆçŸ¥èƒ½ã®é¢ã§ï¼‰ä¸‡ç‰©ã®éœŠé•·ã§ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã€ã¨ã„ã†ã€Œéƒ½åˆã®æ‚ªã„çœŸå®Ÿã€ã‚’ç›´è¦–ã™ã¹ãã¨ã„ã†è©±
- ã€Œãƒ‡ã‚¸ã‚¿ãƒ«åºã®ã‚µã‚¤ãƒˆã‚„ã°ã™ãã‚‹ã€
	- https://qiita.com/mu_tomoya/items/f78f1fad3a8b57ac7dc3
	- ã‚„ã°ã„ãã‚‰ã„å‚è€ƒã«ãªã‚‹ã‚‰ã—ã„ã€‚
-  ç±³OpenAIã®CEOã€ŒAIã¯ã•ã‚‰ã«è³¢ãã€ã€€æ…¶å¤§ã§æ„è¦‹äº¤æ›ï¼ˆæ—¥çµŒï¼‰
	- OpenAIã®å¼·ã¿ã¯research culture  
	- ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° or ç†è«–è§£æã«å¼·ã„äººãŒæˆåŠŸã—ã¦ã„ã‚‹
	- AIæŠ€è¡“ã¯æ€¥é€Ÿã«é€²æ­©ãƒ»å¿œç”¨ã•ã‚Œã¦ãŠã‚Šã€ã“ã®ã‚ˆã†ãªæ™‚ä»£ã«AIã«é–¢ã‚ã‚Œã‚‹ä»Šã®å­¦ç”Ÿã¯lucky generation
	- https://www.nikkei.com/article/DGXZQOUC1037N0Q3A610C2000000/
- å¹³å‡ãƒ»åˆ†æ•£ãƒ»ç›¸é–¢ãŒå¤‰ã‚ã‚‰ãªã„ã€X,Yã®æ§˜ã€…ãªäº‹ä¾‹ã€‚ã€‚
	- ã¾ã‚æœ‰åãªå¥´ã ã‘ã©ã‚´ã‚¸ãƒ©ã¯ã‚ˆãè€ƒãˆãŸãªã€‚
	- https://twitter.com/docmilanfar/status/1668093023895568386?s=20
- ãƒ’ãƒ³ãƒˆãƒ³å…ˆç”Ÿã«ãŸã„ã™ã‚‹ãƒ«ã‚«ãƒ³ã®æ‰€æ„Ÿ
	- äººé–“ä¸¦ã¿ã®AIã‚’å®Ÿç¾ã™ã‚‹ã«ã¯ã€ï¼’ã¤ãŒå¿…é ˆã§ã€ï¼ˆä»Šã¯ãŸã‚‰ãªã„ï¼‰
		- (1) learning world models from sensory inputs like video, 
		- (2) an architecture that can reason and plan (not just auto-regress).
- Dockerã‚³ãƒ³ãƒ†ãƒŠã‚’webassemblyã«å¤‰æ›ã—ã¦å®Ÿè¡Œã§ãã‚‹ãƒ„ãƒ¼ãƒ«ï¼Ÿ
	- https://www.publickey1.jp/blog/23/dockerwebassemblywebcontainer2wasm03.html
- æ¬§å·ã®ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒšãƒ¼ã‚¹ã«é–¢ã™ã‚‹ã€JRCã®ãƒ¬ãƒãƒ¼ãƒˆ
	- European Data Spaces - Scientific Insights into Data Sharing and Utilisation at Scale
	- https://publications.jrc.ec.europa.eu/repository/handle/JRC129900
- GPTã«Function CallãŒè¿½åŠ 
	- å‡ºåŠ›ã®æ•´å½¢ã¨ã‹ã€ã‚ã‚‹ã„ã¯ã€è‡ªç„¶è¨€èªã‹ã‚‰ã€é–¢æ•°ã®APIå‘¼ã³å‡ºã—ã‚’ä½œã£ãŸã‚Šã¨ã‹ã€ã¤ã¾ã‚Šã€LangChainã§ã„ã†ã¨ã“ã‚ã®AgentãŒç°¡å˜ã«ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã€‚
	- https://openai.com/blog/function-calling-and-other-api-updates
- CVï¼ˆã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ï¼‰ã®æœ€æ–°åˆŠã¯ã€ç”ŸæˆAIã€å·»é ­è¨€ãŒã‚ˆã‹ã£ãŸã¨ã®ã“ã¨
	- https://www.amazon.co.jp/dp/B0C6JW6T6B?ref_=cm_sw_r_cp_ud_dp_Q44X6Q8W7NPXKP46168A
	- ã‚¤ãƒãƒ‰ã‚­ãƒæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ï¼šæ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹æœ€è¿‘ã®ç ”ç©¶å‹•å‘ã‚’ç´¹ä»‹ã€‚åŸºæœ¬æŠ€è¡“ã€æ¡ä»¶ä»˜ãç”Ÿæˆã¸ã®æ‹¡å¼µã€ç”Ÿæˆã®é«˜é€ŸåŒ–ã«ã¤ã„ã¦è¿°ã¹ã€æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ã¶ã†ãˆã§å½¹ç«‹ã¤ãƒªã‚½ãƒ¼ã‚¹ã‚’ç´¹ä»‹ã€‚
- OpenAIã®ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Eval
	- https://github.com/openai/evals
	- **ç‰¹å®šã®èª²é¡Œã«å¯¾ã—ã¦ã©ã‚Œãã‚‰ã„é«˜ç²¾åº¦ã§ç”Ÿæˆã§ãã¦ã„ã‚‹ã‹ã‚’è©•ä¾¡**ã§ãã¾ã™ã€‚
- DADCã®ã‚¹ãƒãƒ¼ãƒˆãƒ“ãƒ«ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã®è£œè¶³è³‡æ–™ãŒå…¬é–‹ã€
	- è£œè¶³è³‡æ–™ã£ã¦ã€æœ€åˆã‹ã‚‰èª¬æ˜ãŒè¶³ã‚‰ãªã‹ã£ãŸã ã‚ã†ã«ã€‚
	- https://www.ipa.go.jp/digital/architecture/Individual-link/ps6vr7000001x8o0-att/smartbuilding_guideline_appendix.pdf
- æœ€è¿‘å¼•é€€ã•ã‚ŒãŸMITã®ã‚¹ãƒˆãƒ©ãƒ³ã‚°å…ˆç”Ÿã®ã€"Ther Art of Linear Algebra"ã®å’Œè¨³ã€ãŸã£ãŸï¼‘ï¼”Pã€å…¨ç†ç³»ã¯æ¶™ã—ã¦èª­ã‚€ã¹ã—
	- ã€Œè¡Œåˆ—5åˆ†è§£ã€ã€Œè¡Œåˆ—ã®ä¸–ç•Œã€ã€Œå›ºæœ‰å€¤åœ°å›³ã€ã®è¦–è¦šçš„è§£èª¬
	- https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra/blob/main/The-Art-of-Linear-Algebra-j.pdf
- GTP-calls:ã‚³ãƒ¼ãƒ«ã‚»ãƒ³ã‚¿ãƒ¼ã®ä¼šè©±ã‚’åˆ†æã™ã‚‹ã‚¢ãƒ—ãƒªã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆ
	- https://arxiv.org/abs/2306.07941
- ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯å›å¸°ã¨æ·±å±¤å­¦ç¿’ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–¹ç¨‹å¼ã‚’è¦‹ã¤ã‘ã‚‹ã€‚
	- https://arxiv.org/abs/2207.00529
- GPT3.5 APIã®ã‚¢ãƒ—ãƒ‡ã§ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã£ãŸ16kãƒˆãƒ¼ã‚¯ãƒ³ã§ä½•ãŒã§ãã‚‹ã‹ï¼Ÿ
	- é’ç©ºæ–‡åº«ã®ã¡ã‚‡ã£ã¨ã—ãŸçŸ­ç·¨ãªã‚‰ã°ã€åˆ†æãŒå¯èƒ½ã«ãªã£ãŸãƒ¬ãƒ™ãƒ«ã‚‰ã—ã„
	- https://note.com/mahlab/n/n99577fabf16e
- GPTã§ã®function callã®è‰¯ä¾‹
	- https://gist.github.com/hotchpotch/364cb8ae188e40f4e9ff1273232bc918
- OpenAI API ã® é–¢æ•°å‘¼ã³å‡ºã— ã‚’è©¦ã™ã€npakaã•ã‚“ã®è¨˜äº‹
	- **å¤–éƒ¨APIã‚’å‘¼ã³å‡ºã—ã¦è³ªå•ã«ç­”ãˆã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ä½œæˆ**
	- **è‡ªç„¶è¨€èªã‚’APIå‘¼ã³å‡ºã—ã«å¤‰æ›**
	- **ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º**
	- https://note.com/npaka/n/n917463f55b8a
- æ¬§å·AIè¦åˆ¶ã«ãŠã‘ã‚‹ã€ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€ä¸€èˆ¬ç›®çš„AIã«å¯¾ã™ã‚‹ç¾©å‹™äº‹é …
	- https://www.europarl.europa.eu/news/en/press-room/20230609IPR96212/meps-ready-to-negotiate-first-ever-rules-for-safe-and-transparent-ai
	- ban on AI for biometric surveillance, emotion recognition, predictive policing 
	- registration of models with EU 
	- detailed summary of training data 
	- requirement to identify deepfakes
-  ç¬¬6å›LangChainã‚‚ãã‚‚ãä¼šé–‹å‚¬ãƒ¬ãƒãƒ¼ãƒˆ
	- https://note.com/mahlab/n/nc6ec4a9bd3c5
	- Grounded Generationã‚µãƒ¼ãƒ“ã‚¹Vectaraã€LLMãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹Beamã€SQLiteã§ãƒ™ã‚¯ãƒˆãƒ«DBæ¤œç´¢ãŒå¯èƒ½ã«ãªã‚‹sqlite-vssã€PostgreSQLã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢æ‹¡å¼µpgvectorã€LangChain AI Handbookã®è©±
- OpenAIã®Function Callã‚’ã¤ã‹ã†ã¨ã€LangChainã®ReAct Agentã®ã‚ˆã†ãªã“ã¨ã‚‚ã§ãã‚‹ã¨ã„ã†è©±ï¼ˆã™ã’ãƒ¼ã€ã¨ã„ã†ã‹ã€ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ å£Šã—ã¦ãªã„ã‹ï¼Ÿï¼Ÿï¼Ÿï¼‰
	- https://github.com/jerryjliu/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb
	- llma_indexã«ã¯ã€openai agentãŒçµ„ã¿è¾¼ã¾ã‚Œã‚‹äºˆå®šã‚‰ã—ã„ã€‚
	- https://twitter.com/llama_index/status/1668995628146257921?s=20
- ã€Œé–¢æ•°ãƒ‡ãƒ¼ã‚¿è§£æã®æ¦‚è¦ã¨ãã®æ–¹æ³•ã€æ»‹è³€å¤§å­¦ã€æ¾äº•å…ˆç”Ÿ
	- https://speakerdeck.com/hidetoshimatsui/guan-shu-detajie-xi-nogai-yao-tosonofang-fa
	- ãƒ‡ãƒ¼ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã§ç¿’ã†ã€å›å¸°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ãªã©ã®ã™ã¹ã¦ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚’é–¢æ•°ã¨ã—ã¦å–ã‚Šæ‰±ã†æ çµ„ã¿ã§ã€å†æ§‹æˆã•ã‚Œã¦ã„ã‚‹ã€‚ãªã‚“ã¨ã‚‚ã™ãŒã™ãŒã—ã„ã‚¹ãƒ©ã‚¤ãƒ‰ã€‚å¤ä¼‘ã¿ã®ãŠä¾›ã«ï¼
- æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹ã«ãŠã‘ã‚‹ONNXã®æ´»ç”¨ã¨å¿œç”¨ã€€ã€œONNXãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®æ‹¡å¼µã€œ
	- https://www.sportip.jp/blogs/onnx
	- ã‚„ã£ã±ã‚Šã€ONNXã«ã—ã¦ã€WebGPUã¤ã‹ã£ã¦ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§å‹•ã‹ç”¨ã«ãªã‚‹ã®ã­ã€
- Rinna-3.6B ã§ æ–‡è„ˆä»˜ãã®è³ªå•å¿œç­” ã‚’è©¦ã™ npakaã•ã‚“è¨˜äº‹ã‚ˆã‚Š
	- https://note.com/npaka/n/n3bb60c61ef94
	- ã€ŒJSQuADã€ã¯æ–‡è„ˆä»˜ãã®è³ªå•å¿œç­”ã‚¿ã‚¹ã‚¯ã§ã€53.42ã¨åŠåˆ†ä»¥ä¸Šæ­£è§£
- æ¬§å·AIè¦åˆ¶ã«ã€ç¾çŠ¶ã®LLMã¯ã©ã‚Œãã‚‰ã„å¯¾å¿œã§ãã¦ã„ã‚‹ã‹ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯(ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰é¡Œï¼‰
	- https://crfm.stanford.edu/2023/06/15/eu-ai-act.html
	- ç¾çŠ¶ç‰¹ã«è‘—ä½œæ¨©ä¿è­·å­¦ç¿’ãƒ‡ãƒ¼ã‚¿é–‹ç¤ºç­‰ãŒè¡Œã‚ã‚Œã¦ã„ãªã„ã“ã¨ã€DSAçš„é€æ˜æ€§ç¢ºä¿ã®éå¯¾ç§°è¦åˆ¶æè¨€ãªã©
	- ã™ã”ã™ãã§ã—ã‚‡ã†ã€‚
- çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®LLMã®çµ±åˆã«ã¤ã„ã¦ã®ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—è«–æ–‡
	- Unifying Large Language Models and Knowledge Graphs: A Roadmap
	- https://arxiv.org/abs/2306.08302
	- Combining the advantages of LLMs and knowledge graphs (KGs) is a promising direction.
- æ¬§å·ã§EVé›»æ± è¦åˆ¶ã€€ãƒªãƒã‚¦ãƒ ã¯8å‰²å†è³‡æºåŒ–ã€31å¹´ã¾ã§ã«
	- 6/14æ—¥ã«æ¬§å·è­°ä¼šã®æŠ•ç¥¨ã‚’é€šéã—ãŸã¨ã„ã†è©±ã€
	- EV,ä¸»è¦ææ–™ã®ãƒªãƒã‚¦ãƒ ã¯ä½¿ç”¨æ¸ˆã¿é›»æ± ã‹ã‚‰2027å¹´ã¾ã§ã«50%ã€31å¹´ã¾ã§ã«80%ã‚’å†è³‡æºåŒ–ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚
	- ã€Œé›»æ± ãƒ‘ã‚¹ãƒãƒ¼ãƒˆã€ã®å°å…¥ã‚‚æ±ºã¾ã£ãŸ
	- https://www.nikkei.com/article/DGXZQOGR1706S0X10C23A6000000/
- ãƒ¬ãƒ´ã‚£ï¼ã‚¹ãƒˆãƒ­ãƒ¼ã‚¹ã®70å¹´æ¥ã®è¬ã‚’é€²åŒ–ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§è§£æ˜- æ–‡åŒ–äººé¡å­¦ã®åŸºç¤ã€Œè¦ªæ—ã®æ§‹é€ ã€ã‚’æ•°ç†ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆ -
	- https://www.u-tokyo.ac.jp/focus/ja/press/z0109_00325.html
	- ã“ã‚Œã£ã¦ã€LLMã§åŒã˜ã“ã¨ãŒå¤šåˆ†1å¹´ä»¥å†…ã®ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚
- ã€€å¿œç”¨è¡Œå‹•åˆ†æã€Œæ­»äººãƒ†ã‚¹ãƒˆã€æ­»äººã«ã‚‚ã§ãã‚‹ã“ã¨ã‚’è¡Œå‹•ç›®æ¨™ã«ã—ãŸã„ã¨ã„ã†è©±
	- https://twitter.com/81I6VVboj7h2Bqy/status/1667893285883621376?s=20
	- ã€Œä¼šè­°ã§ä½™è¨ˆãªç™ºè¨€ã—ãªã„ã€ã€ã€Œå»Šä¸‹ã§èµ°ã‚‰ãªã„ã€ã€ãªã©ã¯æ­»äººã«ã‚‚ã§ãã‚‹ç›®æ¨™ãªã®ã§ã€ãã‚Œã¯ã¾ã¡ãŒãˆã§ã‚ã‚‹ã¨ã„ã†ã“ã¨ã€‚ã€‚ãã®è¡Œå‹•ã€æ­»äººã«ã‚‚ã§ãã‚‹ã®ã§ã¯ï¼Ÿ

## 6/12

ç†Šæœ¬ã§é–‹ã‹ã‚ŒãŸäººå·¥çŸ¥èƒ½å­¦ä¼šå…¨å›½å¤§ä¼šã®è©±é¡Œã‚‚ã¡ã‚‰ã»ã‚‰ã€‚å‰ã„å…ˆç”Ÿã®ã¾ã¨ã‚ã‚¹ãƒ©ã‚¤ãƒ‰ãŒå½¹ã«ç«‹ã¤ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMã‚’å‹•ã‹ã™å‹•ãã‚‚ç›¸ã‚‚å¤‰ã‚ã‚‰ãšæ´»ç™ºã€‚ggMLå½¢å¼ã®LLMãªã‚‰ã°ã€gpt4allã®ãƒãƒ£ãƒƒãƒˆç”¨ã®ã‚½ãƒ•ãƒˆã§llmã‚’å…¥ã‚Œæ›¿ãˆã¦å‹•ãã‚‰ã—ã„ã€‚npakaæ°ã®ãƒ­ãƒ¼ã‚«ãƒ«ï¼¬ï¼¬ï¼­ã®ã¾ã¨ã‚ã¯è‰¯è¨˜äº‹ã€‚ãã‚Œã«ã—ã¦ã‚‚ã€4.75bitã®SpQRã£ã¦æœ¬å½“ã‹ï¼Ÿã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚„ãƒ—ãƒ­ãƒ—ãƒ­ãƒ†ã‚¤ãƒ³ãªã©ã®ç ”ç©¶å¯¾è±¡ã®æ“ä½œãªã©ãŒã§ãã‚‹ãƒãƒ£ãƒƒãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚‚ç™»å ´ã€ãã†ã„ã†å¿œç”¨ã¯ã“ã‚Œã‹ã‚‰ã‚‚ãŸãã•ã‚“ã§ãã†ã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç•Œéšˆã¯ã€è‡ªã‚‰ã®å­˜åœ¨æ„ç¾©çš„ã«ã€Noteableãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãŒã‚ˆã»ã©å¿œãˆãŸã‚‰ã—ã„ã€‚ã¤ã„ã«MSã‹ã‚‰Chatã§Officeè£½å“ã‚’åˆ¶å¾¡ã§ãã‚‹æŠ€è¡“ãŒç™ºè¡¨ã€ãƒ‘ãƒ¯ãƒã‚‚ä½œã£ã¦ãã‚Œã‚‹ã®ã‹ï¼Ÿãã®é–“googleã®Bardã¯ã€è£ã§ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã™ã‚‹ä»•çµ„ã¿ã‚’å–ã‚Šå…¥ã‚Œã€è‹¦æ‰‹ãªè¨ˆç®—ã¨ã‹è«–ç†ãªã©ã®ç²¾åº¦ãŒå‘ä¸Šã€‚ä»Šåº¦ã¯ï¼§ï¼¡ï¼³ã¨ã®é€£æºã‹ã€‚æ±èŠç¦æœ¬æ°ã®è£½é€ æ¥­ã«ãŠã‘ã‚‹ç”Ÿæˆï¼¡ï¼©ã®æ´»ç”¨ã¯ä¸€èª­ã®ä¾¡å€¤ã‚ã‚Šã€‚å€«ç†ã¨ã‹å…¬å¹³æ€§ã¨ã„ã†ã€ä¸Šã‹ã‚‰ç›®ç·šã‚ˆã‚Šã€ã€Œåµã®ãŸã‚ã®ï¼¡ï¼©ã€ã«ã€ã‚ãŸã—ã¯ãªã‚ŠãŸã„ã€‚

- ãƒ‡ãƒ¼ã‚¿åˆ†æã®åŠ¹ç‡ãŒ10å€ä¸ŠãŒã‚‹ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ãŸã‚ã®ChatGPTã®æ´»ç”¨è¡“
	- https://qiita.com/ot12/items/96b5783568196d3320fe
	- ã•ã„ã”ã¯Noteableãªã®ã‹ã€‚ã€‚
- ChatGPTã®ã‚ˆã†ã«ç‹™ã„ã®åˆ†å­ã‚„ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚’ç·¨é›†ã§ãã‚‹ChatDrug
	- https://arxiv.org/abs/2305.18090v1
- ã€Œrinnaã€ã®æ—¥æœ¬èªè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’è©¦ç”¨ã€ãƒ¡ãƒ¢ãƒª32GBã‚ã‚Œã°CPUã ã‘ã§ã‚‚å‹•ããï¼
	- https://internet.watch.impress.co.jp/docs/column/shimizu/1503707.html
- GPT4ALLå‘¨ã‚Šã®ã‚½ãƒ•ãƒˆã¯ã€ggMLæº–æ‹ ã®ãƒ¢ãƒ‡ãƒ«ãªã‚‰ã°ã€gpt4allã§ãªãã¦ã‚‚å‹•ãã‚ˆã†ã«ãªã£ãŸï¼
	- The GPT4All Chat UI supports models from all newer versions of `ggML`, `llama.cpp` including the `LLaMA`, `MPT` and `GPT-J` architectures. T
	- https://docs.gpt4all.io/gpt4all_chat.html
- ã©ã†ã‚„ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°130å„„(13B)ã§ChatGPT(GPT-3.5)ã‚¯ãƒ©ã‚¹ã®æ€§èƒ½ãŒå‡ºã›ã‚‹ã“ã¨ãŒMSã‹ã‚‰ç™ºè¡¨
	- https://huggingface.co/papers/2306.02707
- ã“ã‚“ã©ã¯ProteinChatã€æ§‹é€ ãŒã‚ã‚Œã°ä½•ã§ã‚‚ã‚ˆã„ã®ã‹ã€‚ã€‚
	- ProteinChat: Towards Achieving ChatGPT-Like Functionalities on Protein 3D Structures
	- https://www.techrxiv.org/articles/preprint/ProteinChat_Towards_Achieving_ChatGPT-Like_Functionalities_on_Protein_3D_Structures/23120606/1
- ç¢ºç‡çš„ç†±åŠ›å­¦ã«çµŒæ¸ˆå­¦ã®ãƒ„ãƒ¼ãƒ«ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€ç†±åŠ›å­¦ã¨æƒ…å ±ç†è«–ã®é–“ã®ç›¸äº’ä½œç”¨ã«ã¤ã„ã¦å®šé‡çš„ã«èª¿ã¹ãŸ
	- https://arxiv.org/abs/2306.00449
- ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«å…¥é–€ã€ï¼—æœˆï¼’ï¼™æ—¥ç™ºå£²äºˆå®š
	- https://www.amazon.co.jp/dp/4297136333
- Microsoftã®ç ”ç©¶è€…ã‚‰ãŒæ–°ãŸã«é–‹ç™ºã—ãŸAIã‚·ã‚¹ãƒ†ãƒ ã€ŒSemantic Interpreterã€ã¯ã€Officeã‚’æ“ä½œã€ãƒ‘ãƒ¯ãƒãŒä½œã‚Œã‚‹ã€‚ã€‚
	- https://arxiv.org/abs/2306.03460
- DeepMindã®AlphaDevã€äººã®ä½œã‚Šã—ã‚½ãƒ¼ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚ˆã‚Šã‚‚é«˜é€Ÿãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ç”Ÿæˆã€‚
	- https://www.nature.com/articles/s41586-023-06004-9
	- ã¨ã„ã£ã¦ã‚‚æœ€é©åŒ–ã—ã¦ã„ã‚‹ã ã‘ã ã¨ã‹ã€ChatGPTã§ã‚‚åŒæ§˜ãªæœ€é©åŒ–ãŒã§ããŸã¨ã®å ±å‘ŠãŒç¶šãã€‚
	- https://chat.openai.com/share/95693df4-36cd-4241-9cae-2173e8fb760c
- åŒ»ç™‚ç¾å ´ã§ã®ã€æ§‹é€ åŒ–ã•ã‚Œã¦ãªã„åŒ»ç™‚ãƒ¡ãƒ¢ã‚’ã¤ã‹ã£ãŸLLM
	- https://www.nature.com/articles/s41586-023-06160-y
- LlamaIndexã®ã€JSON Query Engineã®ç´¹ä»‹ãƒ“ãƒ‡ã‚ª
	- https://www.youtube.com/watch?v=4tDyfAaIqEw
- å‰ç¯‡ã€€AIã¯ã€Œã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚²ãƒ¼ãƒ ã€ã‚’çŸ¥ã‚‰ãªã„
	- ä»Šäº•ã‚€ã¤ã¿å…ˆç”Ÿã¨ã€é«˜é‡ç§€è¡Œã®å¯¾è«‡
	- ã€è¨€èªã®æœ¬è³ªã€€ã“ã¨ã°ã¯ã©ã†ç”Ÿã¾ã‚Œã€é€²åŒ–ã—ãŸã‹ã€ã®ä»Šäº•å…ˆç”Ÿã®å¯¾è«‡
	- https://kangaeruhito.jp/interview/756531
- Googleã®ã€ŒBardã€ãŒã€Œæš—é»™çš„ãªã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã€ã‚’å°å…¥ã€æ–‡å­—åˆ—ã®æ“ä½œã‚„è«–ç†ãƒ»æ¨è«–ã‚’å«ã‚€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹å›ç­”ç²¾åº¦ãŒå‘ä¸Š
	- ã‚„ã£ã±Bardã‚„ã‚‹ã­ã€‚
	- https://gigazine.net/news/20230608-google-bard-implicit-code-execution/
- Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners
	- https://arxiv.org/abs/2305.14825
- æ±èŠç¦æœ¬æ°ã«ã‚ˆã‚‹ã€è£½é€ æ¥­ã§ç”ŸæˆAIã¯ã©ã‚“ãªå½¹å‰²ã‚’æœãŸã™ã®ã‹ï¼Ÿ ãƒ‰ã‚¤ãƒ„ã§è¦‹ãŸMSã‚„ã‚·ãƒ¼ãƒ¡ãƒ³ã‚¹ã‚‰ã®å–ã‚Šçµ„ã¿
	- ãƒãƒãƒ¼ãƒãƒ¼ãƒ¡ãƒƒã‚»ã§ã®å±•ç¤ºã®ç¾åœ°å ±å‘Šã¯è²´é‡ã 
	- https://www.sbbit.jp/article/st/115632
- å£ã®ãŸã‚ã®AIã¨åµã®ãŸã‚ã®AI
	- JSAI2023ã§ã®å­¦ç”Ÿä¼ç”»ã€åµã®ãŸã‚ã®AIã«ãªã‚ŠãŸã„ã€‚
	- https://speakerdeck.com/yukinobaba/ai-for-wall-and-ai-for-egg
- æ¾å°¾ç ”ã«ã‚ˆã‚‹ã€ã€ŒåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æŠ€è¡“ã¨å±•æœ›ã€
	- GPT-3ãªã©åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æŠ€è¡“çš„ãªå‹•å‘ã«ã¤ã„ã¦ã€æ•°å¤šãã®æ–‡çŒ®ã‚’ã‚‚ã¨ã«æ•´ç†ã•ã‚Œã¦ã„ã‚‹
	- https://speakerdeck.com/yusuke0519/jsai2023-tutorial-ji-pan-moderunoji-shu-tozhan-wang
- çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ãŸæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®CausalImpactåˆ†æ
	- https://speakerdeck.com/stakaya/zhuang-tai-kong-jian-moderuwohuo-yong-sita-shi-xi-lie-detafalsecausalimpactfen-xi
	- ã¾ã‚ã€Rã§ãªãã¦ã‚‚å†ç¾ã§ããã†ã ã€‚
- llamaindexã®Knowledge Graphã‚¤ãƒ³ãƒ‡ã‚¯ã‚¹æ©Ÿèƒ½ãŒå¤§å¹…ã«ãƒ‘ãƒ¯ãƒ¼ã‚¢ãƒƒãƒ—ï¼Ÿ
- https://github.com/jerryjliu/llama_index/blob/main/docs/examples/index_structs/knowledge_graph/NebulaGraphKGIndexDemo.ipynb
- æ¬ æå€¤ã‚’å¹³å‡å€¤ã‚’ä»£å…¥ã™ã‚‹ã¨ã„ã†ãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãŒè­°è«–ã«ã€
	- å•é¡Œãªã„ã¨ã„ã†äººã‚‚ã„ã‚‹ãŒã€å•é¡Œãªã„ãªã‚‰ãã‚‚ãã‚‚é™¤å¤–ã—ã¦ã‚‚åŒã˜ãªã®ã§ã¯ï¼Ÿ
	- https://twitter.com/kenken26679105/status/1667288891949453312?s=20
- JSAI2023ã€äººã®ä½ç½®æƒ…å ±ã®æ™‚ç³»åˆ—ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«ç½®ãæ›ãˆã¦GPT-2ã§å­¦ç¿’ã€äººã®ç§»å‹•è»Œé“ã‚’ç”Ÿæˆã™ã‚‹ç ”ç©¶
	- https://confit.atlas.jp/guide/event/jsai2023/subject/2H5-OS-8a-02/tables?cryptoId=
- ãƒ­ãƒ¼ã‚«ãƒ«ã§langchainçµŒç”±ã§ç°¡å˜ã«ã¤ã‹ãˆã¦ãã“ãã“æ—¥æœ¬èªã‚‚å–‹ã‚Œã‚‹ã®wizard-vicuna-13 q8_0
	- https://twitter.com/if_004/status/1667474091564204033?s=20
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ã¾ã¨ã‚
	- https://note.com/npaka/n/nd95fba328b65
- è¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®è¡Œã‚’1æ–‡ã¨è¦‹ã¦ï¼Œå·®åˆ†ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã«è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ï¼Œãã“ã‹ã‚‰åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ‰‹æ³•ã‚’ææ¡ˆï¼è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚‚ã®ã¨åŒç­‰ã®æ€§èƒ½
	- https://arxiv.org/abs/2306.04803
- 4.75bit ç›¸å½“ã®é‡å­åŒ–ã§ã€16fp ã¨æ¯”ã¹æå¤±ã‚¼ãƒ­ã®æ¨è«–ãŒå¯èƒ½
	- SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression
	- https://arxiv.org/abs/2306.03078
## 6/5
ç›¸ã‚‚å¤‰ã‚ã‚‰ãšã€4bitåŒ–ã¨ã‹ã€Rinna-3.6Bã®LoRaã¨ã‹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMã‚’å‹•ã‹ã™ã€ä½œã‚‹å¯èƒ½æ€§ãŒåºƒãŒã£ã¦ã„ã‚‹ã€‚ã¾ã‚ç¾çŠ¶ã®LLMã£ã¦å®Ÿã¯ç–ãªã®ã§ã¯ã¨ã„ã†ç‰¹ç•°å€¤åˆ†è§£ã®çµæœã‚‚ã€‚ã˜ã‚ƒã‚‰ã‚“ã§ChatGPTæ´»ç”¨ã‚µãƒ¼ãƒ“ã‚¹è©¦è¡Œé–‹å§‹ã€‚DeepLearningAIã‚ˆã‚Šã€LangChainã®ã‚·ãƒ§ãƒ¼ãƒˆã‚³ãƒ¼ã‚¹ç„¡æ–™é–‹å§‹ã€ä½œè€…ç™»å ´ã§è±ªè¯ãªã“ã¨ã«ã€‚DeepAI OpenAIã®LLMã®è‹¦æ‰‹ãªè¨ˆç®—å•é¡Œã§ã®ã€ã€Œãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–å ±é…¬ãƒ¢ãƒ‡ãƒ«(PRM)ã€ã«ã‚ˆã‚‹æ”¹è‰¯ã€‚æ•°å€¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä¸–ç•Œã§ã‚‚LLMæ´»ç”¨ãŒã€‚OpenAIã®security Portalç™ºè¡¨ã€‚Grokkingã€Œéå­¦ç¿’ã—ã¦ã—ã°ã‚‰ãçµŒã£ã¦ã‹ã‚‰ã€æ€¥ã«æ±åŒ–èª¤å·®ãŒä¸‹ãŒã‚Šå§‹ã‚ã‚‹ï¼ˆæ­£è§£ç‡ãŒä¸ŠãŒã‚Šå§‹ã‚ã‚‹ï¼‰ã€ã¨ã„ã†ç¾è±¡ã¸ã®æ‰‹ãŒã‹ã‚Šã‚‚ã€‚ã€‚è¨€èªå­¦ä¼šã‹ã‚‰ã‚‚LLMã«å¯¾ã™ã‚‹å…ƒæ°—ã®ã‚ˆã„ç™ºä¿¡ã‚„å‡ºç‰ˆãŒå¤šæ•°ã€‚ãƒ‰ã‚¤ãƒ„é€£é‚¦ãƒ‡ãƒ¼ã‚¿ä¿è­·å½“å±€ï¼ˆBfDIï¼‰ã®ç”ŸæˆAIã«ã¤ã„ã¦ã®å£°æ˜ã€ã“ã‚Œã¯èª­ã‚€ã¹ãã‹ã€‚æ—¥æœ¬ã®AIæˆ¦ç•¥ä¼šè­°ã®è­°è«–ã¨ã®æ¸©åº¦å·®ã¯ã„ã‹ã‚“ã¨ã‚‚ã—ãŒãŸã„ã€‚æ–°èè¨˜äº‹ã®æœ¬è«–ã®å‰æ®µã®è¨˜äº‹é–“é•ãˆã‚’é¬¼ã®é¦–ã‚’å–ã£ãŸã‚ˆã†ã«å©ãã€ç‹­é‡ãªæ—¥æœ¬ã®DSãƒ¡ãƒ³ã‚¿ãƒªãƒ†ã‚£ã‚‚èˆˆå‘³æ·±ã„ã€‚ã“ã®æ”¿åºœã«ã—ã¦ã“ã®å›½æ°‘ã‚¢ãƒªã¨ã„ã†æ„Ÿã˜ã‹ã€é€†ã‹ã€‚

- DeepLearningAIã‚ˆã‚Šã€LangChainã®ã‚·ãƒ§ãƒ¼ãƒˆã‚³ãƒ¼ã‚¹ãŒã€ç„¡æ–™
	- ä½œè€…è‡ªèº«ã®ç™»å ´ã§ã€è±ªè¯ãªæ§‹æˆã«ã€
	-  LangChain for LLM Application Development
	- https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/
- biomedGPT: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªåŒ»ç™‚ç”¨ã®GPT
	- https://arxiv.org/abs/2305.17100
- AIæˆ¦ç•¥ä¼šè­°ã«ã‚ˆã‚‹ã€æš«å®šçš„è«–ç‚¹æ•´ç†ã€æ—¥æœ¬ã¯ãƒãƒ¼ãƒ­ãƒ¼ãªã®ã‹ï¼Ÿã“ã‚Œã§ã„ã„ã®ï¼Ÿ
	- https://www8.cao.go.jp/cstp/ai/index.html
- LLMè‡ªèº«ãŒPythonã«ã‚ˆã‚‹ãƒ„ãƒ¼ãƒ«ä½œæˆï¼ŸLarge Language Models as Tool Makers
	- https://arxiv.org/abs/2305.17126
- Google Colabã§ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã§ã®å®Ÿè¡ŒãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚ã€‚
	- https://research.google.com/colaboratory/local-runtimes.html
- Transcendental Style in Film(æ˜ ç”»ã«ãŠã‘ã‚‹è¶…è¶Šçš„æ§˜å¼)
	- https://twitter.com/routemopsy/status/1663396967417024513?s=20
	- ãƒ›ã‚¦ãƒ»ã‚·ãƒ£ã‚ªã‚·ã‚§ãƒ³ãŒã‚¿ãƒ«ã‚³ãƒ•ã‚¹ã‚­ãƒ¼é ˜åŸŸã«ã‚ã‚‹ã®ã¯è§£ã›ãªã„ã€‚
- ã€Œ Google Colab ã§ Rinna-3.6B ã®LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™ã€
	-  ãªã‚“ã¨14Gã§ã§ãã‚‹ãªã‚‰ã€ç„¡æ–™æ ï¼Ÿ
	- https://note.com/npaka/n/nc387b639e50e
- Large Language Models are not Fair Evaluators
	- https://arxiv.org/pdf/2305.17926.pdf
-  How To Finetune GPT Like Large Language Models on a Custom Dataset
	- Macbookã§ã‚‚ç°¡å˜ã«finetuneã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://lightning.ai/pages/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/
- ã€ŒChatGPTã®ä»•çµ„ã¿ã¨ç¤¾ä¼šã¸ã®å½±éŸ¿ã€ã€äº¬å¤§é»’æ©‹å…ˆç”Ÿã®ã‚ã‹ã‚Šã‚„ã™ã„ã¨ã„ã‚ã‚Œã‚‹è¬›ç¾©ã€ï¼‘ï¼™åˆ†ã§ã•ãã£ã¨
	- https://www.youtube.com/watch?v=aKqIPlDyWhs
- ã€ŒChatGPTã¨Noteableã«ã‚ˆã‚‹ç§‘å­¦æŠ€è¡“æƒ…å ±åˆ†æã€
	- https://speakerdeck.com/hayataka88/chatgpttonoteableniyoruke-xue-ji-shu-qing-bao-fen-xi
	- å™‚ã®Noteableã€‚ã¤ã„ã«ã€ãŠè©±ã—ã™ã‚‹ã ã‘ã§ã€EDAã‹ã‚‰å›å¸°ã¾ã§ã€ã€
- Let's Verify Step by Step by OpenAI
	- LLMãŒè‹¦æ‰‹ãªè¨ˆç®—å•é¡Œã‚’ã¨ã‹ã›ã‚‹ãŸã‚ã«ã€process supervisionã¨ã„ã†ã®ã‚’ã©ã†ã«ã‚…
	- ã€Œãƒ—ãƒ­ã‚»ã‚¹ç›£è¦–å ±é…¬ãƒ¢ãƒ‡ãƒ«(PRM)ã€ã¨ã„ã†ã‚‰ã—ã„ã€‚
	- https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf
- NIIã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒã‚¦ã‚¹(6/1-6/3)ã€ChatGPTãƒã‚¿å¤§æ‰ã€‚
	- https://www.nii.ac.jp/event/openhouse/2023/
- å› æœæ¨è«–ã®ã‚³ãƒ¼ã‚¹ãƒãƒ†ãƒªã‚¢ãƒ«
	- https://arxiv.org/abs/2305.18793
- Rinnaã™ã”ã„ã‹ã‚‚ã€‚japanese-gpt-neox-3.6b-instruction-ppo
	- https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo
- å±€æ‰€è©³ç´°é‡£ã‚Šåˆã„ã€ã‚†ã‚‰ãã®å®šç†ã€Jarzynskiç­‰å¼ã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®é–¢ä¿‚
	- https://zenn.dev/xiangze/articles/6e8ce8b8d43d08
	- ãã†ã„ã†ã‚‚ã®ã‚‰ã—ã„
- rinna/japanese-gpt-neox-3.6b ã«ã¤ã„ã¦ã€ãƒ™ãƒ¼ã‚¹ã€SFTã€RLHFã§å‹•ã‹ã—ãŸä¾‹ on colab
	- https://note.com/npaka/n/ne4a38239f420
	- ãƒ™ãƒ¼ã‚¹ãªã‚‰ç„¡æ–™æ ã§å‹•ãï¼Ÿ
- ã˜ã‚ƒã‚‰ã‚“ã§AIãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹é–‹å§‹
	- https://note.com/npaka/n/ne4a38239f420
- Rinna-3.6B ã‚’ llama.cpp ã§ CPU å‹•ä½œã®ãƒ¡ãƒ¢
	- https://zenn.dev/syoyo/articles/946c17666e10fb
	- CPUã ã‘ã§ã‚‚ååˆ†å‹•ãã®ã‹ã€‚ã€‚ã€‚
- Berry: A code for the differentiation of Bloch wavefunctions from DFT calculations
	- https://arxiv.org/abs/2006.02744
	- DFTè¨ˆç®—ã§å¾—ãŸæ³¢å‹•é–¢æ•°ã‚’å¾®åˆ†ã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹
- What Is ChatGPT Doing â€¦ and Why Does It Work?
	- https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
	- Wolfman Alphaã®Wolfmanã•ã‚“ã®è¨˜äº‹ã€
	- ã€Œç¾åœ¨ã®ChatGPTã®å ´åˆï¼Œäº‹æ…‹ã¯ã‚‚ã£ã¨æ¥µç«¯ã§ï¼Œå„ãƒˆãƒ¼ã‚¯ãƒ³ã®å‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã¯ãƒ«ãƒ¼ãƒ—ã®ãªã„ç´”ç²‹ãªã€Œãƒ•ã‚£ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ã‚ã‚‹ãŸã‚ï¼Œè‡ªæ˜ã§ãªã„ã€Œåˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã€ã‚’æŒã¤ã„ã‹ãªã‚‹è¨ˆç®—ã‚‚è¡Œã†ã“ã¨ãŒã§ããªã„
- Googleã«ã‚ˆã‚‹å›³å¼ã‚’ç†è§£ã™ã‚‹LLM
	- Foundation models for reasoning on charts
	- https://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html
-  Physics-constrained machine learning for scientific computing
	- https://www.amazon.science/blog/physics-constrained-machine-learning-for-scientific-computing?_amp=true
	- ä¿å­˜å‰‡ã¨å¢ƒç•Œæ¡ä»¶ã®åˆ¶ç´„ã‚’å®ˆã‚Šã¤ã¤åå¾®åˆ†æ–¹ç¨‹å¼ã®è§£ã‚’æ±‚ã‚ã‚‹ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã€‚Amazon Scienceã‹ã‚‰ICMLã¨ICLRã§ç™ºè¡¨
- LLMã§ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–è¨€èªã‚’ä½œã‚Šã¾ãã‚Šï¼Ÿ
	- https://huggingface.co/papers/2305.19234
	- Grammar Prompting for Domain-Specific Language Generation with Large Language Models
- OpenAI ã®CEOã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã€GPUãƒªã‚½ãƒ¼ã‚¹ãŒä¸–ç•Œçš„ã«è¶³ã‚‰ãªã„ã®ã¯GPT-4ã®ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å­¦ç¿’ä¸­ã®ãŸã‚ï¼Ÿ
	- https://humanloop.com/blog/openai-plans
- ã€ŒAIã«è„…ã‹ã•ã‚Œã‚‹ã€Œå€‹äººã€ã€€æƒ…å ±ã‚’æ–­ã¡åˆ‡ã‚‹è¦åˆ¶å¿…è¦ã€ã€€æ”¿æ²»å­£è©•
	- https://www.asahi.com/articles/ASR5065XLR5YUSPT006.html
	- ä¸­èº«ã¯è­°è«–ã•ã‚Œãšã€æœ€åˆã®ChatGPTã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ã¨ã“ã‚ã«ã€é¬¼é¦–ã‚’ã¨ã£ãŸã‚ˆã†ã«ã‹ã¿ã¤ãDSç•Œéšˆ
- QCDã®ï¼‘æ–¹ç¨‹å¼ã‹ã‚‰å¤šæ§˜ãªä¸–ç•ŒãŒä½œã‚Šå‡ºã•ã‚Œã‚‹ãƒãƒ£ãƒ¼ãƒˆ
	- http://suganuma-hideo.o.oo7.jp/hideo/index.files/main.files/HQCD.pdf
- â€œAccording to . . . â€ Prompting Language Models Improves Quoting from Pre-Training Data
	- Wikipediaã«ã‚ˆã‚‹ã¨ã€ã€ã€ã‚’ä»˜ã‘åŠ ãˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ï¼Ÿ
	- LLMãŒäº‹å‰å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç›´æ¥å¼•ç”¨ã™ã‚‹ã‚ˆã†ã«èª˜å°ã—ã€ç”Ÿæˆã•ã‚Œã‚‹æƒ…å ±ã®ä¿¡é ¼æ€§ã‚’å‘ä¸Š
	- https://arxiv.org/pdf/2305.13252.pdf
- inna-3.6b-instruction-oppã®ggml 4q_2ã‚’ä½œã£ã¦ã€LangChainã®summarize chainã§ä½¿ã£ã¦ã¿ã¾ã—ãŸâ€¦
	- https://twitter.com/8hmVmEGJ6nFyUE5/status/1663936372363898880?s=20
	- ã‚„ã£ã±ã‚Šggmlã¨4bitãŒæœ€å¼·ãªã®ã‹ã€‚ã€‚ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒ2Gã£ã¦ã€ã‚ãƒ¼ãŸ
- LLMã‚’ã¤ã‹ã£ã¦ã€å¾®åˆ†æ–¹ç¨‹å¼ã‹ã‚‰ä¿å­˜å‰‡ã‚’æŠ½å‡ºã™ã‚‹ï¼Ÿï¼Ÿ
	- Discovering New Interpretable Conservation Laws as Sparse Invariants
	- https://arxiv.org/abs/2305.19525
- OpenAIãŒsecurity portalã‚’å…¬é–‹
	- https://trust.openai.com/
- ã¤ã„æœ€è¿‘å¼•é€€ã•ã‚ŒãŸã€ã‚¹ãƒˆãƒ©ãƒ³ã‚°æ•™æˆï¼ˆç·šå½¢ä»£æ•°ä»–ï¼‰ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è¨˜äº‹
	- https://news.mit.edu/2023/gilbert-strang-made-linear-algebra-fun-0531
- GPT4ALLã‚’ã¤ã‹ã£ã¦ã€GPUãªã—ã§ã€ãƒ­ãƒ¼ã‚«ãƒ«PCã§LLMã‚’å‹•ã‹ã™
	- https://gpt4all.io/index.html
	- A free-to-use, locally running, privacy-aware chatbot. **No GPU or internet required.**
- ChatGPTãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã€ŒNotableã€ã ã‘ã§ãƒ‡ãƒ¼ã‚¿åˆ†æã‚³ãƒ³ãƒšã«æŒ‘æˆ¦ã—ã¦ã¿ãŸè©±
	- https://qiita.com/ot12/items/ba74fa150e160d94a71f
	- ã‚„ã£ã±ã‚ŠNoteableã¯æœ€å¼·ã®ä»¶ã€æ¥å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç‰¹è«–ã®ãƒã‚¿ã«ã—ã‚ˆã†ï¼
- A Mechanistic Interpretability Analysis of Grokking
	- å­¦ç¿’ãŒé€²ã‚€ã¨çªç„¶ã€æœªè¦‹ã®ãƒ‡ãƒ¼ã‚¿ã«ä¸€èˆ¬åŒ–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã™ã‚‹ç¾è±¡ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®è§£æ˜ã ãã†ã 
	- https://www.alignmentforum.org/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking
- ã‚«ãƒ¢ã‚·ã‚«-LoRaã‹ã‚‰ã€OpenCALM 7B, 3Bã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ä½œæˆã—ãŸã‚¢ãƒ€ãƒ—ã‚¿ã‚’å…¬é–‹
	- https://twitter.com/kam0shika/status/1663906516276051969?s=20
- Transformer.jsã€ãƒ–ãƒ©ã‚¦ã‚¶ã‚„nodejsã‹ã‚‰huggingfaceã®transformerãŒä½¿ãˆã‚‹
	- https://github.com/xenova/transformers.js
- ç‰¹ç•°å€¤åˆ†è§£ã§30%ã‚‚LLMã‚’åœ§ç¸®ã—ã¦ã‚‚æ€§èƒ½ãŒå¤‰ã‚ã‚‰ãªã‹ã£ãŸ
	- LLMã£ã¦ã‚„ã£ã±ã‚Šç–ãªã®ã­
	- ~30% Compression Of LLM (Flan-T5-Base) With Low Rank Decomposition Of Attention Weight Matrices
	- https://smashinggradient.com/2023/05/23/30-compression-of-llms-with-low-rank-decomposition-of-attention-weight-matrices/
- LQML;
	- LMQL (Language Model Query Language) is a programming language for large language model (LM) interaction. 
	- https://docs.lmql.ai/en/stable/
- Andrew Ngã•ã‚“ã«ã‚ˆã‚‹ç±³è»AIãƒ‰ãƒ­ãƒ¼ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ“ä½œè€…ã‚’æ®ºã™ã¨ã„ã†çµè«–ï¼‰ã¸ã®åé§
	- https://twitter.com/AndrewYNg/status/1664694504476102680?s=20
- ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã«ã‚ˆã‚‹ã€æ©Ÿæ¢°å­¦ç¿’ã‚‚ã‚ã‚‚ã‚ãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆ
	- https://github.com/afshinea/stanford-cs-229-machine-learning
- LangChainã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹vicuna-13bãƒ¢ãƒ‡ãƒ«ã‚’rinnaãŒå…¬é–‹
	- https://huggingface.co/rinna/vicuna-13b-delta-finetuned-langchain-MRKL 
	- https://note.com/hamachi_jp/n/n97d368a617ac
- A Survey on Large Language Models for Recommendation
	- https://arxiv.org/abs/2305.19860v2
- åˆ†å­ç”Ÿç‰©å­¦ã«LLMãŒæœ€é©ãªä»¶
	- https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30
- GPT4ALLã¨LangChainã¨Chromaã‚’ã¤ã‹ã£ãŸã€ãƒ­ãƒ¼ã‚«ãƒ«ã«å‹•ãæœ€å°é™ã®Q&A
	- https://twitter.com/AssemblyAI/status/1661747770108305409?s=20
- ã€ŒChatGPTã®å‡ºç¾ã¯è‡ªç„¶è¨€èªå‡¦ç†ã®å°‚é–€å®¶ã«ä½•ã‚’å•ã„ã‹ã‘ã¦ã„ã‚‹ã‹ã€
	- è¨€èªå­¦ä¼šã®ä¹¾å…ˆç”Ÿã®å·»é ­è¨€
	- ã€Œã§ã¯ï¼Œã“ã‚Œã§è‡ªç„¶è¨€èªå‡¦ç†ã¯çµ‚ã‚ã‚‹ã®ã‹ï¼Ÿ ã‚‚ã¡ã‚ã‚“ï¼Œçµ‚ã‚ã‚‰ãªã„ï¼è§£ãã¹ãèª²é¡Œï¼Œæ–°ãŸã«ç”Ÿã¾ã‚Œã‚‹å•ã„ã¯å±±ã»ã©ã‚ã‚‹ï¼ã€
	- https://www.anlp.jp/topics/topic230601.html
- ã€Œè¨€èªã®æœ¬è³ªã€€ã“ã¨ã°ã¯ã©ã†ç”Ÿã¾ã‚Œã€é€²åŒ–ã—ãŸã‹ (ä¸­å…¬æ–°æ›¸)ã€
	- ä»Šäº•ã‚€ã¤ã¿, ç§‹ç”°å–œç¾ã®æœ¬ã€
	- https://www.amazon.co.jp/dp/B0C4XF523T?ref_=k4w_ss_dp_lp
-  Langchainãƒ»Semantic Kernelãƒ»guidanceã§ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚’å®Ÿè£…ã—ã¦æ¯”è¼ƒã—ã¦ã¿ãŸ
	- https://qiita.com/sakue_103/items/6ffee0bc267e71eafd60
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° by NRI
	- https://datascience.nri.com/entry/2022/10/12/155350
- ãƒ‰ã‚¤ãƒ„é€£é‚¦ãƒ‡ãƒ¼ã‚¿ä¿è­·å½“å±€ï¼ˆBfDIï¼‰ã®ç”ŸæˆAIã«ã¤ã„ã¦ã®å£°æ˜ï¼ˆ5æœˆ22æ—¥ï¼‰ã€ by ç”Ÿè²å…ˆç”Ÿ
	- https://www.bfdi.bund.de/SharedDocs/Downloads/DE/DokumenteBfDI/Stellungnahmen/2023/StgN_Generative-K%C3%BCnstliche-Intelligenz.pdf?__blob=publicationFile&v=2
	- GDPRçš„ãªãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨DSAçš„ãªã‚·ã‚¹ãƒ†ãƒŸãƒƒã‚¯ãƒªã‚¹ã‚¯ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®å¯¾æ¯”ãªã©èˆˆå‘³æ·±ã„ã€‚é’å°‘å¹´å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚„AIè¦å‰‡ã®å·ä¸Šå·ä¸‹å•é¡Œãªã©ã‚‚
- Jupyter AIãŒå‡ºãŸï¼è©¦ã—ãŸï¼ï¼ã™ã”ã„ï¼ï¼ï¼
	- https://qiita.com/moritalous/items/a270d5932ebee18d0ba8?utm_content=buffer352b5&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer
	- ã™ã”ã„ã‚‰ã—ã„
- 

## 5/29
Microsoft Buildã§Windowsã¨GPTã¨ã®çµ±åˆã¨ã‹ã€Bingã§ã‚‚ChatGPTã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã‹ã€ç›¸ã‚‚å¤‰ã‚ã‚‰ãšMicrosoftã¯ã©ã†ã‚„ã£ã¦æŠ•è³‡ã‚’å›åã§ãã‚‹ã®ã‹ä¸æ˜ã€‚Adamã‚’è¶…ãˆã‚‹Sophiaã®ç™»å ´ã‚„ã€4bitåŒ–ã®QLoRaã®ç™»å ´ãªã©ã€å€‹äººã‚„ä¼æ¥­ã§ã®LLMä½œæˆã«ã¯æœ—å ±ã§ã‚ã‚‹ãŒã€LLMã®æ°‘ä¸»åŒ–ã£ã¦å±é™ºã‚‚ã‚ã‚‹ã‚ˆã­ã€‚ãªã®ã§ã€DeepMindã‚„Microsoftã¯å€«ç†æ€§ã‚„ãƒªã‚¹ã‚¯ã«é–¢ã™ã‚‹ç ”ç©¶ã‚’ã¡ã‚ƒã‚“ã¨ç¶šã‘ã¦å…¬é–‹ã—ã¦ã„ã‚‹ã€‚Voyagerã™ã”ã„ã€ç ”ç©¶é–‹ç™ºã®ã‚¿ã‚¹ã‚¯ã‚‚ã‚‚GPT-4ã§ã§ãã‚‹ã®ã§ã¯ï¼ŸWebGPUã‚’ä½¿ã£ãŸwebllmã€nodejsç‰ˆã§ã‚‚å‹•ãæ¨¡æ§˜ã€‚microsoftã¯guidanceã§ãƒ¢ãƒ‡ãƒ«åˆ©ç”¨ã®åŠ¹ç‡åŒ–ã®å·¥å¤«ã‚’è¡Œã£ã¦ã„ã‚‹ã¨ã®å ±å‘Šã‚‚ã€‚ã‚¢ãƒ–ãƒ€ãƒ“ã‹ã‚‰è¬ã®å·¨å¤§LLMã§ã‚ã‚‹Falcon-40BãŒç™ºè¡¨ã•ã‚Œã‚‹ã‚‚ã€OSSã¨ã†ãŸã„ã¤ã¤å®Ÿã¯è¬ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã‚ã£ã¨ã„ã†ã¾ã«å©ã‹ã‚Œã‚‹ã€‚SQLã¨ã‹Notableã¨ã‹ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç³»ã®ChatGPTã®æ´»ç”¨ãŒæœ¬æ ¼çš„ã«ã€‚ç¥ï¼SIAMã®è³ã®å—è³ã€è”µæœ¬å…ˆç”Ÿï¼ï¼ï¼ã€‚æ¬§å·AIè¦åˆ¶ã®æœ€çµ‚æŠ•ç¥¨ã‚’ç›®å‰ã«ã€OpenAIã€æ¬§å·AIè¦åˆ¶éµå®ˆãŒå›°é›£ã¨åˆ¤æ–­ã•ã‚Œã‚Œã°ã€æ¬§å·ã‹ã‚‰ã‚µãƒ¼ãƒ“ã‚¹å¼•ãä¸Šã’ã¨ã®è¨˜äº‹ã€‚ChatGPTã‚¢ãƒ—ãƒªãŒæ—¥æœ¬ã§ã‚‚iPhoneã«ç™»å ´ã€ä¼¼ãŸã‚ˆã†ãªåå‰ã®ã‚¢ãƒ—ãƒªãŒãŸãã•ã‚“ã‚ã£ã¦ã€ã€ã€ã€‚

- Micorsoftã®AIãŒå€«ç†çš„ã§ã‚ã‚‹ã‹ã©ã†ã‹ã‚’è©•ä¾¡ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ
	- https://github.com/microsoft/responsible-ai-toolbox
- çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®neo4jã¨ã€LangChainã‹ã‚‰ã®åˆ©ç”¨ã€Cypherå•ã„åˆã‚ã›ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹
	- https://python.langchain.com/en/latest/modules/chains/examples/graph_cypher_qa.html
- LIMA: Less Is More for Alignment
	- Lucanå…ˆç”Ÿã«ã‚ˆã‚‹ã¨ã€LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance
	- https://arxiv.org/abs/2305.11206
- scikit-llm: scikit-learnã¨LLMã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã¤ã«ã¤ãªã’ã‚‹
	- https://github.com/iryna-kondr/scikit-llm
- LangChainã‹ã‚‰Azure OpenAI ã‚’ä½¿ã†ãƒ¡ãƒ¢
	- https://qiita.com/tmiyata25/items/7a04096342241d8a2b4c
- Textually Pretrained Speech Language Modelsï¼šãªã‚“ã‹éŸ³å£°ã‚’ã„ã‚Œã‚‹ã¨éŸ³å£°ã‚’å‡ºåŠ›ã™ã‚‹LLM!!
	- https://pages.cs.huji.ac.il/adiyoss-lab/twist/
- ImageBindã€€by Metaã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãªå­¦ç¿’
	- https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=blog&utm_content=card
- open-calm-7b ã‚’ databricks-dolly-15k-ja ã§ LoRA ã—ãŸã®ã‚’ãƒãƒ¼ã‚¸ã—ã¦ ggml ã«ã—ã¦ 4bit é‡å­åŒ–ã—ã¦ redpajama.cpp ã§ MacBook ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ãæ—¥æœ¬èªé«˜é€Ÿãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ
	- https://twitter.com/niw/status/1660894493867134976?s=20
-  LLaMAãƒ™ãƒ¼ã‚¹ã®æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«(LoRaã—ãŸ)å…¬é–‹
	- https://llm.msuzuki.me/
- Microsoft Buildé–‹å‚¬ã€OSã¨LLMãŒèåˆï¼Ÿ
	- https://blogs.microsoft.com/blog/2023/05/23/microsoft-build-brings-ai-tools-to-the-forefront-for-developers/
- LLMå‘ã‘ã®å­¦ç¿’æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³Sophiaã€ã‚¢ãƒ€ãƒ ã‚’è¶…ãˆã‚‹ã‹
	-  Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training
	- https://arxiv.org/abs/2305.14342
- QLoRa: HuggingFaceã®ãƒ¢ãƒ‡ãƒ«ãŒã€4bitåŒ–ã•ã‚ŒãŸã‚‚ã®ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ï¼Ÿ
	- https://huggingface.co/blog/4bit-transformers-bitsandbytes
- Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks
	- https://huggingface.co/papers/2305.14201
- è‡ªç„¶è¨€èªã®promptã«ã‚ˆã‚‹LLMã®åˆ©ç”¨ã¯ã€LLMã®æœ¬æ¥ã®èƒ½åŠ›ã‚’ç”Ÿã‹ã—ãã‚Œã¦ãªã„
	- https://arxiv.org/abs/2305.13264v1
- QLoRaã‚’ä½¿ãˆã°ã€æ™®é€šã®colabã«ã¦ã€æ•°æ™‚é–“ã§LLMãŒã§ãã‚‹ã¨ã„ã†å ±å‘Šã€‚4bitæœ€å¼·ã€‚
	- 33B-parameter LLM on Google Colab in a few hour
	- https://twitter.com/ItakGol/status/1661714548594823174?s=20
- OpenCALM-7Bã‚’LoRAã§Fine tuningã—ã¦å¯¾è©±ãŒã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
	- https://note.com/masuidrive/n/n0e2a11fc5bfa
- Reasoning with Language Model is Planning with World Model
	- CoT on GPT-4ã¨ã®æ¯”è¼ƒã§å‹ã‚‹ã¨ã®ã“ã¨
	- https://arxiv.org/abs/2305.14992
- Voyager: é•·æœŸçš„ãªæ¢ç´¢ã‚’GPT-4ã§ã‚„ã‚‰ã›ã‚‹ä¾‹ã€‚Minecraftã‚’ã‚„ã‚‰ã›ãŸã‚‰ã€ã€ï¼ˆç ”ç©¶é–‹ç™ºã‚‚ã€‚ã€‚ã€‚ï¼‰
	- https://github.com/MineDojo/Voyager
- ç¥ï¼è”µæœ¬å…ˆç”Ÿã€SIAMã§JÃ¼rgen Moser Lectureè³å—è³ï¼å—è³è¬›æ¼”
	- https://www.youtube.com/watch?v=2P-EgTSa-E4&feature=youtu.be
- DeepMindã‹ã‚‰ã€ä¸€èˆ¬çš„ãªAIãƒ¢ãƒ‡ãƒ«ãŒæ½œåœ¨çš„ã«æŒã¡ã†ã‚‹æœ‰å®³ãªãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
	- https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks?utm_source=twitter&utm_medium=social&utm_campaign=ModelEval
- WebGPUã‚’ã¤ã‹ã£ã¦LLMã‚’å‹•ã‹ã™ä»•çµ„ã¿ã€WebLLMãŒã€nodejsã§ã‚‚å‹•ãï¼Ÿï¼Ÿ
	- https://github.com/mlc-ai/web-llm
- LangChainã‹ã‚‰Databricksã‚’ä½¿ã†
	- https://python.langchain.com/en/latest/modules/models/llms/integrations/databricks.html
- ã‚¢ãƒ–ãƒ€ãƒ“ã®ç ”ç©¶æ‰€ã‹ã‚‰Falcon-40BãŒç™ºè¡¨ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãªã®ã«ã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ–™ãŒå¿…è¦ã¿ãŸã„ãªç½ ãŒè¦‹ã¤ã‹ã‚‹ã€‚
	- https://huggingface.co/tiiuae/falcon-40b
	- ã€Œå£²ä¸Šã®10%ã‚’ãƒ­ã‚¤ãƒ¤ãƒªãƒ†ã‚£ã¨ã—ã¦12ãƒ¶æœˆæ¯ã«æ”¯æ‰•ã‚ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€
- microsoft/guidance(LangChainã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã‚’ã¤ã‹ã£ã¦ã€Agentã‚’å®šç¾©ã—ã¦ã€å‹•ã‹ã™
	- https://note.com/explaza_inc/n/n7cb8043506bd
- OpenAIãŒgptã‚µãƒ¼ãƒ“ã‚¹ã®ï¼•æœˆã®é€Ÿåº¦ä½ä¸‹ã‚’ãƒ¬ãƒãƒ¼ãƒˆã™ã‚‹ã‚‚ã®ãŒ
	- https://twitter.com/helicone_ai/status/1662325356563496961?s=20
- GoogleãŒç”ŸæˆAIã®ç„¡æ–™è¬›åº§ã‚’å…¬é–‹
	- https://www.cloudskillsboost.google/journeys/118
- SQLã‚’æ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿åˆ†æã«ãŠã‘ã‚‹ChatGPTã®æ´»ç”¨æ³•
	- https://speakerdeck.com/hikarut/sqlwohuo-yong-sitadetafen-xi-niokeruchatgptnohuo-yong-fa
- ChatGPTã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å‘ã‘ã®ãƒ—ãƒ©ã‚°ã‚¤ãƒ³NotableãŒä¾¿åˆ©ã¨ã®è¨˜äº‹
	- https://secon.dev/entry/2023/05/27/170000-noteable-iris/
- Lucanå…ˆç”Ÿã€GAFAMã®ä»£ã‚ã‚Šã«ã€MAGMAã‚’é€ èªã€‚ Meta, Amazon, Google, Microsoft, App
	- https://twitter.com/ylecun/status/1662375684612685825?s=20
- OpenAIã®ã‚¢ãƒ«ãƒˆãƒãƒ³CEOã€ã€ŒEU AI Acté †å®ˆãŒå›°é›£ãªã‚‰EUã§ã®äº‹æ¥­ã¯åœæ­¢ã™ã‚‹
	- https://www.itmedia.co.jp/news/articles/2305/26/news106.html

## 5/22
ChatGPTä»¥å¤–ã®OSSã®LLMã§ã¯ã€googleã®FLAN-20B with UL2 ãã‚‰ã„ãªã‚‰ã°ã€ãªã‚“ã¨ã‹åŒç­‰ã®æ€§èƒ½ãŒã§ã‚‹ã¨ã„ã†å ±å‘Šã‚‚(A100ãŒå¿…è¦)ã€‚privateGPTã‚„ã€GPT4ALLãªã©ã®ã€ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ã‹ã›ã‚‹OSSã®LLMã‚‚ã ã„ã¶ãã‚ã£ã¦ãã¾ã—ãŸã€‚PyTorchã‚’ãƒ–ãƒ©ã‚¦ã‚¶ç’°å¢ƒ'(TypeScriptã§ï¼‰å‹•ã‹ã™ä»•çµ„ã¿ã‚‚ç™»å ´ã€‚ã—ã‹ã—æœ¬å‘½ã¯ã€WebGPUã‚’ã¤ã‹ã£ã¦ã€ãƒ–ãƒ©ã‚¦ã‚¶ä»¥å¤–ã‹ã‚‰ã‚‚LLMã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§é«˜é€Ÿã«å‹•ã‹ã™è©¦ã¿ã«ã¯æœŸå¾…ã—ãŸã„ã¨ã“ã‚ã€‚ã„ã£ã½ã†TinyStoriesãªã©ã€ã©ã‚Œã ã‘LLMã‚’å°ã•ãã§ãã‚‹ã‹ãªï¼Ÿçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚‚ç¶šãã€‚Tramnsformerã‚‚åå¾®æ–¹ç¨‹å¼ã‚’è§£ããªã©ã€ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã®é ˜åŸŸã«åºƒã’ã‚‹è©¦ã¿ã‚‚ã€‚æ—¥æœ¬ã‹ã‚‰ã¯æ—¥æœ¬èªç‰ˆLLMãŒè¤‡æ•°å‡ºç¾ã€å®ŸåŠ›ã®ã»ã©ã¯ï¼Ÿï¼ŸLLMã®èª¬æ˜æ€§ã‚„ãƒã‚¤ã‚¢ã‚¹å¯¾ç­–ãªã©ã‚‚ã€‚ChatGPTãŒã¤ã„ã«IPhoneã«ä¹—ã‚‹ï¼ˆUSã®ã¿ï¼‰ã€‚Microsoftã¯LLMã‚’ä½¿ã„ã‚„ã™ãã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯Guidanceã‚’ç™ºè¡¨ã€SemanticKernelã®ç«‹å ´ã¯ï¼Ÿï¼ŸMarvinã®ã‚ˆã†ãªã€LLMã¨ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®èåˆãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã«ã¯å¯èƒ½æ€§ãŒã‚ã‚Šãã†ã§ã™ã€‚

- LLMã®ãƒã‚¤ã‚¢ã‚¹ã‚’ã‚ã¶ã‚Šã ã™ã€Constructive Input Decoding(CID) by google
	- https://arxiv.org/abs/2305.07378
- privateGPT:ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ãæœ€å°é™ã®GPTã€LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformersã‚’æ´»ç”¨
	- https://github.com/imartinez/privateGPT
- TinyStories:ï¼“ï½ï¼”æ‰ãã‚‰ã„ãŒç†è§£ã§ãã‚‹çŸ­ã„æ–‡æ›¸ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ã©ã‚Œã ã‘LLMã‚’å°ã•ãã§ãã‚‹ã‹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ã‚‚ã® by Microsoft
	- https://arxiv.org/abs/2305.07759
- Google/OpenAIãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®LLMã‚’é–‹ç™ºã—ã¦ã„ã‚‹ã€‚
	- https://www.theinformation.com/articles/open-source-ai-is-gaining-on-google-and-chatgpt
- Marvin:ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¨LLMã®è£œåŠ©ã‚’çµ„ã¿åˆã‚ã›ãŸæ–°ã—ã„ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã€LMQLã¿ãŸã„ãªæ„Ÿã˜ï¼Ÿã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãªã©
	- https://note.com/hamachi_jp/n/na1960fc9d6d3
	- https://www.askmarvin.ai/
- Excelã¨ãƒãƒ£ãƒƒãƒˆã™ã‚‹ã€titnanicã®ä¾‹ã§ã€å‰å‡¦ç†ã®ã¨ã“ã‚ã‚’ãƒãƒ£ãƒƒãƒˆã§å®Ÿç¾
	- https://github.com/Anil-matcha/Chat-With-Excel/blob/main/Data_analysis_with_langchain.ipynb
- Physics Informed Token Transformer(PITT)ï¼šåå¾®åˆ†æ–¹ç¨‹å¼(PDE)ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã—ã€PDEã®è§£ã‚’æ±‚ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•ã¨ã—ã¦æœ‰åãªFourier Neural Operator(FNO)ã®è£œæ­£ã¨ã—ã¦åˆ©ç”¨
	- https://arxiv.org/abs/2305.08757v1
- Abbeelæ•™æˆã«ã‚ˆã‚‹Hintonæ•™æˆã¸ã®ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã€NYTimesã®è¨˜äº‹ä¾é ¼ã€å…¨ä¸–ç•Œã‹ã‚‰ï¼’åˆ†æ¯ï½å–æä¾é ¼ãŒæ¥ãŸã‚‰ã—ã„
	- https://www.youtube.com/watch?v=rLG68k2blOc
- åŒ»ç™‚åˆ†é‡ã«ç‰¹åŒ–ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒMed-PaLM2ã€ã®è«–æ–‡ã€ç¾å½¹ã®åŒ»è€…ã‚‚PaLM2ã®å›ç­”ã®ã»ã†ã‚’è©•ä¾¡
	- https://arxiv.org/abs/2305.09617
- rinnaã€æ—¥æœ¬èªã«ç‰¹åŒ–ã—ãŸ36å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®GPTè¨€èªãƒ¢ãƒ‡ãƒ«ã‚’å…¬é–‹
	- https://rinna.co.jp/news/2023/05/20230507.html
- MicrosoftãŒLangchainã¿ãŸã„ãªã€Guidanceã‚’ç™ºè¡¨
	- https://github.com/microsoft/guidance
- CyberAgentãŒæ—¥æœ¬èªç‰ˆãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’ç™ºè¡¨
	- https://huggingface.co/cyberagent
- Google ã® FLAN-20B with UL2 ãƒ¬ãƒ™ãƒ«ãªã‚‰ã°ã€ChatGPT APIã®ã‚ˆã†ã«ä½¿ãˆã‚‹ã‚‰ã—ã„	
	- https://qiita.com/sakasegawa/items/7394fe68eb0087b3c4a5
- Googleã€è‡ªç¤¾ã®colabratoryã«ã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆæ©Ÿèƒ½ã‚’æ­è¼‰ã™ã‚‹ã‚‰ã—ã„
	- https://blog.google/technology/developers/google-colab-ai-coding-features/
- Transformer.js: Hugging Faceã®transformerã‚’ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§å‹•ã‹ã™ã“ã¨ãŒã§ãã‚‹ã€ONIX runtimeã‚’åˆ©ç”¨ã€WebGPUå¯¾å¿œã¯ä¸æ˜
	- https://github.com/xenova/transformers.js
- Graph Neural Network(GNN)ã§ã€å·¡å›ã‚»ãƒ¼ãƒ«ã‚¹ãƒãƒ³å•é¡Œã‚’è§£ãã€ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰å¤§å­¦ã®è¬›ç¾©ã§ã®äº‹ä¾‹ã€CS224W
	- https://medium.com/stanford-cs224w/tackling-the-traveling-salesman-problem-with-graph-neural-networks-b86ef4300c6e
- OpenCALM-7Bã‚’dolly-15k-jaã§LoRAã—ãŸã‚‰ã€ã‚ã‚‹ç¨‹åº¦ä¼šè©±ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://twitter.com/masuidrive/status/1659089478781227008?s=20
- LLMã®å‡ºåŠ›ã®èª¬æ˜ã«é–¢ã™ã‚‹è«–æ–‡ã‚‰ã—ã„ã€Explaining black box text modules in natural language with language models by microsoft
	- https://huggingface.co/papers/2305.09863
- TokenHawkã€WebGPUã‚’æ´»ç”¨ã—ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã§ã€Webã§LLMã‚’å‹•ã‹ã™ã“ã¨ãŒã§ãã‚‹ä»•çµ„ã¿ã€Googleã®Dawnã‚¨ãƒ³ã‚¸ãƒ³åˆ©ç”¨
	- https://github.com/kayvr/token-hawk
-  ChatGPTãŒiPhoneã§å‹•ãã‚ˆã†ã«ãªã‚‹(ç±³å›½)
	- https://openai.com/blog/introducing-the-chatgpt-app-for-ios
- Trasnformerã‚’åˆ¶å¾¡ã«ç”¨ã„ã‚‹ã€# A Generalist Dynamics Model for Controlã€by DeepMind
	- https://huggingface.co/papers/2305.10912
- LangChainã‹ã‚‰ã€Spark SQL Agent
	- https://python.langchain.com/en/latest/modules/agents/toolkits/examples/spark_sql.html
- LangChainã‹ã‚‰ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸGPT4ALLã®ä½¿ã„æ–¹æ”¹å–„
	- https://python.langchain.com/en/latest/modules/models/llms/integrations/gpt4all.html
- Language Models Meet World Models: Embodied Experiences Enhance Language Models
	- https://arxiv.org/abs/2305.10626
- WebGPU-pytorchã€pytorchãŒã€webGPUã®ä¸Šã§å‹•ãï¼ˆå­¦ç¿’ã€æ¨è«–ã¨ã‚‚ï¼‰
	- https://github.com/praeclarum/webgpu-torch
-  Hugging Faceã®ãƒ¢ãƒ‡ãƒ«ã‚’LangChainã§ä½¿ã†æ–¹æ³•ã‚’èª¿ã¹ãŸã€Hubã‚’ä½¿ã†ã‹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†ã‹ã€
	- https://www.mattari-benkyo-note.com/2023/05/19/langchain_hugging_face/
- Stanfordå¤§å­¦ã®Transformerã®äº‹æ¥­CSï¼’ï¼•ãŒæœ€å¼·ã®ä»¶
	- https://web.stanford.edu/class/cs25/
- Stanfordå¤§å­¦ã€æ–‡å­—åˆ—ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªstring2string
	- https://github.com/stanfordnlp/string2string
- Self-Queringã¨ã„ã†æ‰‹æ³•ã€ã«ã‚ˆã‚‹æ–‡æ›¸æ¤œç´¢Weaviateã€ã‚¹ã‚­ãƒ¼ãƒã‚’ä¸ãˆã‚‹ã¨ã€æ¤œç´¢çµæœã«ã€æƒ…å ±æŠ½å‡ºã®çµæœã‚‚å‡ºã—ã¦ãã‚Œã‚‹ï¼ˆæ›²ã®ratingã¨ã‹geneã¨ã‹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰ã‚‚ã‚„ã£ã¦ãã‚Œã‚‹ã€‚ãŠãŠã™ã”ã„
	- https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/weaviate_self_query.html
- BCGãŒã¾ã¨ã‚ãŸæ—¥æœ¬ä¼æ¥­ã®å¤‰é©ã‚’é˜»ã‚€ã€Œãƒã‚§ãƒ³ã‚¸ãƒ¢ãƒ³ã‚¹ã‚¿ãƒ¼ã€è³‡æ–™ã€ãƒã‚±ãƒ¢ãƒ³çš„ãªã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä»˜ã‘
	- https://web-assets.bcg.com/img-src/japan%20tembo-146-change%20monster_1oct2002_tcm9-169992.pdf


## 5/15
æœ€æ–°ã®LLMã«é–¢ã™ã‚‹æƒ…å ±ã¯ã€Transformerè«–æ–‡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è­°è«–ã‚„å¿œç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®æ¢æ±‚ã€ã‚¢ãƒƒã‚»ãƒ³ãƒ–ãƒªç†è«–ã®å¿œç”¨ã€AGIã®æ‚²è¦³è«–ã€Shap-Eã®ãƒ‡ãƒ¢ã‚µã‚¤ãƒˆã€LLamaindexã®è¦ç´„æ©Ÿèƒ½è¿½åŠ ã€GPT-4ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³èª¬æ˜è©¦ã¿ã€åˆ†å­ç”Ÿæˆãƒ¢ãƒ‡ãƒ«æ”¹è‰¯ã€åŒ»å¸«å›½å®¶è©¦é¨“åˆæ ¼å ±é“ã€WebGPUã§ã®LLMå®Ÿè¡Œã€PaLM 2ã®ç™ºè¡¨ã€Q&Aå‘ã‘retreaverã€Bardã¨GPT-4æ€§èƒ½æ¯”è¼ƒã€ãƒ•ã‚©ãƒ³ãƒˆå•é¡Œã€HumanML3Dãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€DeepLæ—¥æœ¬æ‹ ç‚¹è¨ˆç”»ã€3D Tilesãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€æ—¥æœ¬èªT5ãƒ¢ãƒ‡ãƒ«ã€LeCunè¬›æ¼”ã€ChatGPT Pluginæä¾›ã€åˆ†å­åŠ±èµ·çŠ¶æ…‹äºˆæ¸¬ã€æ©Ÿæ¢°å­¦ç¿’ç†è«–ç™ºå±•ã€GTãƒ¢ãƒ‡ãƒ«ä½œæˆã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ç ”ç©¶ã€é‡å­æ©Ÿæ¢°å­¦ç¿’ç ”ç©¶è€…è»¢å‘ã€Helion Energyã¸ã®é›»åŠ›è³¼å…¥å¥‘ç´„ã€ç‰§é‡å…ˆç”Ÿã®ä¸ååˆ†æ•£è§£èª¬ã€Scikit-learnãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå¤‰æ›´ã€Vicuna-13B-4bitå®Ÿè¡Œæ–¹æ³•ã€LangChainã®retrieverè¿½åŠ ãªã©å¤šå²ã«ã‚ãŸã‚Šã¾ã™ã€‚

- ã‚ªãƒªã‚¸ãƒŠãƒ«ã®Transformerè«–æ–‡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ§‹æˆã®çµµãŒã€æœ¬æ–‡ã¨åˆã£ã¦ãªã„ã¨è¨˜äº‹ãŒã€
	- https://arxiv.org/abs/2002.04745
- few-shot learningã§æº€è¶³ã§ããªã„äººã®å¿œç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé›†
	- https://cameronrwolfe.substack.com/p/advanced-prompt-engineering
- ã‚¢ãƒƒã‚»ãƒ³ãƒ–ãƒªç†è«–ã€æœ‰æ©ŸåŒ–åˆç‰©ã§åˆ†å­ã®çµåˆã®è¤‡é›‘ã•ã®è©•ä¾¡ã€LLMã®è©•ä¾¡ã«ã‚‚ä½¿ãˆã‚‹ï¼Ÿ
	- https://www.quantamagazine.org/a-new-theory-for-the-assembly-of-life-in-the-universe-20230504/
- AGIãŒäººé¡ã‚’å£Šæ»…ã•ã›ã‚‹å¯èƒ½æ€§ã¯ã»ã¼100%ã¨ã„ã£ãŸå¼·ã„æ‚²è¦³è«–ã€AI Alignment Centerã®äººã®è©±ã«ã‚ˆã‚‹ã¨ã€
	- https://note.com/bioshok/n/n43041a52a529
- OpenAIãŒå…¬é–‹ã—ãŸã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰3Dãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚‹Shap-Eã®ãƒ‡ãƒ¢ã‚µã‚¤ãƒˆãŒhuggingfaceã«ã€‚
	- https://huggingface.co/spaces/hysts/Shap-E
- LLamaindexã«æ–°ã—ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„ã®ä»•çµ„ã¿ãŒå°å…¥ï¼Ÿ
	- https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
- OpenAI: GPT-4ã§ã€GPT-2ã®å€‹ã€…ã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®åƒãã®èª¬æ˜ã¨ã„ã†ã‹ã€æ„å‘³ã¥ã‘ã‚’è¡Œã†ï¼Ÿï¼Ÿ	
	- https://openai.com/research/language-models-can-explain-neurons-in-language-models
- VAEã«ã‚ˆã‚‹åˆ†å­ç”Ÿæˆã®ãƒ¢ãƒ‡ãƒ«ã®æ”¹è‰¯ã®è©±
	- https://arxiv.org/abs/2305.03041v1
- GTP-4æ—¥æœ¬ã®åŒ»å¸«å›½å®¶è©¦é¨“ã§åˆæ ¼ï¼Ÿ
	- https://news.yahoo.co.jp/articles/60da4c733c2a03a9829bc598f8dcc246e4d10b00
- LLamaindexã«ã¦ã€æ­£å¼ã«huggingfaceã® LLM supportã€€ã•ã‚Œã‚‹
	- https://github.com/jerryjliu/llama_index
- WebGPUã§ã€LLMã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«å‹•ã‹ã™å‹•ããŒæ´»ç™ºã«ã€LaMA, Alpaca, Vicuna, and Dol
	- https://github.com/mlc-ai/web-llm
- Google I/Oã§PaLM 2ã‚’ç™ºè¡¨
	- https://ai.google/static/documents/palm2techreport.pdf
- Wikipediaã«å¯¾ã™ã‚‹Q&Aã‚’å¯èƒ½ã«ã™ã‚‹retreaverã‚’æä¾›ã™ã‚‹Coheare?
	- https://github.com/menloparklab/cohere-weaviate-wikipedia-retrieval
	- https://github.com/weaviate/weaviate
- Google I/OãŒå¤§åç©«ã ã£ãŸæ¨¡æ§˜ã€Bardã¯æ—¥æœ¬èªã€éŸ“å›½èªå¯¾å¿œã€ Bardã€PaLM 2
	- https://www.gizmodo.jp/2023/05/google-io23-ai-outline.html
- Bardã¨GPT-4ã®æ€§èƒ½æ¯”è¼ƒã€çµæ§‹GPT-4ã«è‚‰è–„ã—ã¦ã„ã‚‹æ¨¡æ§˜ã€‚
	- https://qiita.com/kumag0r0/items/77dbe743643183ae3e98
- Bardç™ºè¡¨ã®ãƒ—ãƒ¬ã‚¼ãƒ³ã§ã€ã€Œæ—¥æœ¬èªã€ã®ãƒ•ã‚©ãƒ³ãƒˆãŒæ®‹å¿µã¨è©±é¡Œã«ã€ã€ã€
	- https://www.itmedia.co.jp/news/articles/2305/11/news178.html
- HumanML3D:Human motion language Dataset
	- https://github.com/EricGuo5513/HumanML3D
- DeepLæ—¥æœ¬ã«æ‹ ç‚¹ã‚’ç½®ãï¼Ÿ
	- https://newsdig.tbs.co.jp/articles/-/480597?display=1
- Googleã®Photorealistic 3D Tilesã‚’[http://deck.gl](https://t.co/j5x1oduUK1)ã§è¡¨ç¤ºã€è»½ã„ã‚‰ã—ã„
	- https://twitter.com/syanseto/status/1656586481094520838?s=20
	- deck.lg(TerrainExtension) + Google Photorealistic 3D Tiles 
	-  Google 3D tileã§èª­ã¿è¾¼ã‚“ã 3Dãƒ¢ãƒ‡ãƒ«ã®ä¸Šã«TerrainExtensionã‚’ä½¿ã£ã¦GeoJSONãƒãƒªã‚´ãƒ³ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤
- æ—¥æœ¬èªT5ãƒ¢ãƒ‡ãƒ«ã®å…¬é–‹ by ãƒ¬ãƒˆãƒªãƒ
	- https://note.com/retrieva/n/n7b4186dc5ada
- LeCunå…ˆç”Ÿã®è¬›æ¼”ã€LeCun: Towards Machines That Can Understand, Reason, & Plan
	- https://www.youtube.com/watch?v=_JfEScYyVCE
- OpenAIã€ChatGPT Plusãƒ¦ãƒ¼ã‚¶ãƒ¼å…¨ä½“ã«ã€5/12ã‚ˆã‚ŠPluginãŒä½¿ãˆã‚‹ã‚ˆã†ãªã‚‹ã¨ã‚¢ãƒŠã‚¦ãƒ³ã‚¹
	- https://help.openai.com/en/articles/6825453-chatgpt-release-notes
- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ï¼’æ¬¡å…ƒã®åˆ†å­ã‚°ãƒ©ãƒ•ã‹ã‚‰ã§ã‚‚åŒç­‰ã®åŠ±èµ·çŠ¶æ…‹ã®äºˆæ¸¬ç²¾åº¦ãŒå¾—ã‚‰ã‚Œã‚‹ã¨ã„ã†è©±ã‚‰ã—ã„
	- https://arxiv.org/abs/2304.12233v2
- æ©Ÿæ¢°å­¦ç¿’ç†è«–ç™ºå±•ã€Hyperbolic PoincarÃ© distributions = Probability distributions with support the PoincarÃ© disk
	- https://arxiv.org/abs/2205.13984
- Graph Transformer (GT)ã‚’ä½œã‚‹ä¾‹é¡Œ
	- https://arxiv.org/pdf/2012.09699.pdf
- æ¨è–¦ã«ãŠã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å—œå¥½ã£ã¦ã€LLMã¯æœ¬å½“ã«ç†è§£ã—ã¦ã‚‹ã‚“ã ã£ãŸã‘è«–æ–‡ã€‚
	- https://arxiv.org/abs/2305.06474
- é‡å­æ©Ÿæ¢°å­¦ç¿’ã®ç ”ç©¶è€…ãŒã€è»’ä¸¦ã¿é‡å­ã‚’ã‚„ã‚ã¦æ©Ÿæ¢°å­¦ç¿’ã«ã„ã£ã¦ã‚‹ã¨ã„ã†ã€çµ„åˆã›æœ€é©åŒ–ã®å¤§å®¶ã§ã‚ã‚‹æ¹Šå…ˆç”Ÿã®å˜†ã
	- https://twitter.com/MinatoYuichiro/status/1657243184064499712?s=20
- Googleã®Photorealistic 3D Tilesï¼ˆå·¦ï¼‰ã¨å›½äº¤çœã®3Déƒ½å¸‚ãƒ¢ãƒ‡ãƒ«PLATEAUã®3D Tilesï¼ˆå³ï¼‰ã®æ¯”è¼ƒ
	- https://twitter.com/syanseto/status/1656964913913540608?s=20
- ChatGPTã¨OSSã®LLMé”ã¨ã‚¬ãƒã‚¿ã‚¹ã‚¯ã§ã®æ¯”è¼ƒã€ã„ã„ç·šè¨€ã£ã¦ã‚‹ã‚‰ã—ã„ã€‚Vicuna-13B, ChatGPT (3.5), MPT-7B-Chat
	- https://medium.com/@marcotcr/exploring-chatgpt-vs-open-source-models-on-slightly-harder-tasks-aa0395c31610
- PrivateGPT:å˜ã«OSSã®LLMã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒãƒ£ãƒƒãƒˆã«ä»•ç«‹ã¦ã‚‹ã€LangChain and GPT4All and LlamaCpp
	- https://github.com/imartinez/privateGPT
- OpenAIã® Sam Altmanæ°ã®ã€è¬ã®ãƒ„ã‚¤ãƒ¼ãƒˆ"summer is coming"
	- https://twitter.com/sama/status/1657405294354518017?s=20
- æ±å¤§å‰ç”°å¡ï¼ˆé…’å ´ã®äººã§ã¯ãªã„ï¼‰å…ˆç”Ÿã®ã€ã€Œæ•™å“¡å‘ã‘ChatGPTè¬›åº§ã€ãŒåˆ†ã‹ã‚Šã‚„ã™ã„ã¨è©•åˆ¤ã«ã€
	- https://www.youtube.com/live/lwccHzqfuvc?feature=share
- Pluginã‚’é–‹ç™ºã™ã‚‹OSSã§ã‚ã‚‹ã€PlugnPlai and LangChainã®ä¾‹
	- https://github.com/edreisMD/plugnplai/blob/master/examples/plugins_step_by_step.ipynb
- HuggingFaceã‹ã‚‰ã€è‡ªç„¶è¨€èªã§Agentã«æŒ‡ç¤ºã‚’å‡ºã—ãŸã‚‰ç”»åƒã§ã‚‚æ–‡ç« ã§ã‚‚éŸ³å£°ã§ã‚‚å‡ºåŠ›ã—ã¦ãã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å‹æ‰‹ã«é¸ã‚“ã§å‡ºåŠ›ã—ã¦ãã‚Œã‚‹Transformers  Agentç™ºè¡¨ã€
	- https://huggingface.co/docs/transformers/transformers_agents
- Microsoftç¤¾ã€Sam Altmanæ°ãŒå‡ºè³‡ã™ã‚‹æ ¸èåˆã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§ã‚ã‚‹Helion Energyã¨2028ã«é›»åŠ›è³¼å…¥å¥‘ç´„
	- https://www.businessinsider.jp/post-269773
	- åŠ é€Ÿå™¨ã§ã€é‡æ°´ç´ ã¨He-3ã‚’åŠ é€Ÿã•ã›ã¦è¡çªæ™‚ã«ã€ç£å ´ã§åœ§ç¸®ã—ã¦ã€èåˆã•ã›ã¦ã€è†¨å¼µã®åŠ›ã«ã‚ˆã‚‹ç£å ´ã®å¤‰åŒ–ã‹ã‚‰ç›´æ¥é›»åŠ›ã‚’ï¼ˆæ°´ã¨ã‹è’¸æ°—ã¨ã‹ã‚’ä½¿ã‚ãšã«ï¼‰å¾—ã‚‹ã¨ã„ã†ä»•çµ„ã¿ã€‚
	- OpenAIã¯ã¾ã™ã¾ã™ã€Microsoftã¨ä¸€è“®æ‰˜ç”Ÿã«ã€ã€ã€ã€
- ç¥æˆ¸å¤§å­¦ã€ã€Œç‰§é‡ã€å…ˆç”Ÿã€ä¸ååˆ†æ•£ã®è‡ªç”±åº¦ãŒn-1ã§ã‚ã‚‹ç†ç”±ã‚’å¤±å¿µã€‚
	- https://twitter.com/jun_makino/status/1657229042121314304?s=20
	- ç‰§é‡å…ˆç”Ÿã”ç´¹ä»‹ã®ã€Œç¾ã—ã„å°å‡ºã€https://manabitimes.jp/math/1205
- Scikit-learnã®çµ„ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ã€ãƒœã‚¹ãƒˆãƒ³ä½å®…ä¾¡æ ¼ãŒã€ãƒãƒªã‚³ãƒ¬ã®ãŸã‚å‰Šé™¤ã•ã‚Œã¦ãŸ
	- https://twitter.com/tokoroten/status/1394192087453638662?s=20
	- ï¼ˆæˆæ¥­ã§ä½¿ã£ã¦ã„ã‚‹äººè¦æ³¨æ„ï¼‰
- Stable Vicuna-13B-4bitãŒcolabã§å‹•ä½œã™ã‚‹ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦WebUIã‚’ä¸Šã’ã‚‹
	- https://zenn.dev/tatsuromurata/articles/8e523cf2d0c2bc
	- https://note.com/it_navi/n/nceffc6e8df35
- LangChainã«ã€arxivç”¨ã®retrieverãŒè¿½åŠ ã€Q&Aãªã©ãŒã§ãã‚‹
	- https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/arxiv.html

## 5/8
LLamaIndex 0.6.0ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã€ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ–°ã—ã„ã‚¯ã‚¨ãƒªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ãŒå°å…¥ã•ã‚Œã¾ã—ãŸã€‚ChatGPT Code InterpreterãŒç™»å ´ã—ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®è§£é‡ˆã¨å®Ÿè¡ŒãŒå¯èƒ½ã«ãªã‚Šã¾ã—ãŸã€‚
Andrew Ngã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¬›ç¾©ãŒæä¾›ã•ã‚Œã€é–‹ç™ºè€…å‘ã‘ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ã‚¹ã‚­ãƒ«ãŒæ•™æˆã•ã‚Œã¾ã™ã€‚Transformerã®enc-decé–“ã«information bottleneckã‚’å°å…¥ã—ãŸVAEçš„ãªè¡¨ç¾ã®æ­£å‰‡åŒ–ã«é–¢ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚"Are Emergent Abilities of Large Language Models a Mirage?"ã¨é¡Œã•ã‚ŒãŸè«–æ–‡ãŒå…¬é–‹ã•ã‚Œã€LLMã®æ–°ãŸãªèƒ½åŠ›ã«é–¢ã™ã‚‹è­°è«–ãŒæèµ·ã•ã‚Œã¾ã—ãŸã€‚
JDLAã§ã¯ã€ç”ŸæˆAIã®åˆ©ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ãŒæä¾›ã•ã‚Œã€AIã®åˆ©ç”¨ã«é–¢ã™ã‚‹æŒ‡é‡ãŒææ¡ˆã•ã‚Œã¾ã—ãŸLangChainã¨OpenAIã®GymnasiumãŒé€£æºã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹åˆ©ç”¨äº‹ä¾‹ãŒç´¹ä»‹ã•ã‚Œã¾ã—ãŸã€‚ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªå‡¦ç†ã«é–¢ã™ã‚‹æ›¸ç±ãŒå‡ºç‰ˆã•ã‚Œã€NLPã«èˆˆå‘³ã‚’æŒã¤æ–¹ã«å‘ã‘ãŸãƒªã‚½ãƒ¼ã‚¹ãŒæä¾›ã•ã‚Œã¾ã™ã€‚"Causal Reasoning and Large Language Models: Opening a New Frontier for Causality"ã¨ã„ã†è«–æ–‡ãŒå…¬é–‹ã•ã‚Œã€å› æœæ¨è«–ã¨LLMã®é–¢é€£ã«ã¤ã„ã¦ã®ç ”ç©¶ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚è‡ªå·±ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã‚’ä½¿ç”¨ã—ã¦å¤šé›»å­ç³»ã®ã‚·ãƒ¥ãƒ¬ãƒ‡ã‚£ãƒ³ã‚¬ãƒ¼æ–¹ç¨‹å¼ã‚’ç¬¬ä¸€åŸç†çš„ã«è§£ãç ”ç©¶ãŒè¡Œã‚ã‚ŒOpenLLAMAãŒå…¬é–‹ã•ã‚Œã€LLMã‚’æ´»ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ãŒæä¾›ã•ã‚Œã¾ã™ã€‚G.Hintonã«ã‚ˆã‚‹GAIï¼ˆGeneral Artificial Intelligenceï¼‰ã«é–¢ã™ã‚‹ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ãŒCNNã§å…¬é–‹ã•ã‚Œã€AIã®æœªæ¥ã«ã¤ã„ã¦ã®è­°è«–ãŒå±•é–‹ã•ã‚Œã¾ã—ãŸã€‚"Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings"ã¨ã„ã†è¨˜äº‹ãŒå…¬é–‹ã•ã‚Œã€LLMã®æ€§èƒ½è©•ä¾¡ã«é–¢ã™ã‚‹æƒ…å ±ãŒæä¾›ã•ã‚Œã¾ã—ãŸã€‚"TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis"ã¨é¡Œã•ã‚ŒãŸç ”ç©¶ãŒè¡Œã‚ã‚Œã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒ’ãƒ¥ãƒ¼ãƒãƒ³ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆã™ã‚‹æŠ€è¡“ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚

- LlamaIndex 0.6.0 - ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ–°ã—ã„ã‚¯ã‚¨ãƒªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹
	- https://note.com/npaka/n/n4254fc549dc0
- ChatGPT Code Interpreter
- Andrew Ngã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®è¬›ç¾©
	- https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
- Transformerã®enc-decé–“ã«information bottleneckã‚’å…¥ã‚Œã¦VAEçš„ã«è¡¨ç¾ã®æ­£å‰‡åŒ–
	- https://openreview.net/forum?id=6QkjC_cs03X
- Are Emergent Abilities of Large Language Models a Mirage?
	- https://arxiv.org/abs/2304.15004
- JDLAã§ã¯ã€ã€Œç”ŸæˆAIã®åˆ©ç”¨ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€
	- https://www.jdla.org/document/?utm_source=prtimes&utm_medium=referral
- LangChainã¨OpenAIã®Gymunasiumã®é€£æº
	- https://python.langchain.com/en/latest/use_cases/agent_simulations/gymnasium.html
- ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªå‡¦ç†
	- https://www.amazon.co.jp/dp/4320125029/
- Causal Reasoning and Large Language Models: Opening a New Frontier for Causality
	- https://arxiv.org/abs/2305.00050
- è‡ªå·±ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³æ©Ÿæ§‹ã‚’ã¤ã‹ã£ã¦å¤šé›»å­ç³»ã®ã‚·ãƒ¥ãƒ¬ãƒ‡ã‚£ãƒ³ã‚¬ãƒ¼æ–¹ç¨‹å¼ã‚’ç¬¬ä¸€åŸç†çš„ã«è§£ã
	- https://arxiv.org/abs/2211.13672
- OpenLLAMA
	- https://github.com/openlm-research/open_llama
- G.Hintonã«ã‚ˆã‚‹ã€GAIã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ @CNN
	- https://www.youtube.com/watch?v=FAbsoxQtUwM
-  Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings
	- https://lmsys.org/blog/2023-05-03-arena/
- TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis
	- https://mathis.petrovich.fr/tmr/
- LLMs & Causal Reasoning
	- https://arxiv.org/abs/2305.00050
- LangChainã®v0.0.139ã‹ã‚‰v0.0.151ã¾ã§ã®å·®åˆ†ã‚’æ•´ç†ï¼ˆã‚‚ãã‚‚ãä¼šå‘ã‘ï¼‰
	- https://note.com/mahlab/n/ne29d4bfb1d45
- LLAMAindexã®æ–°ã—ã„æŠ½è±¡åŒ–API,brand new â€œrouterâ€ abstraction in order to build powerful, generalizable, LLM-powered query engines over your data.
	- https://colab.research.google.com/drive/1KH8XtRiO5spa8CT7UrXN54IWdZk3DDxl?usp=sharing
- ãƒ›ãƒ¯ã‚¤ãƒˆãƒã‚¦ã‚¹New Actions to Promote Responsible AI Innovation that Protects Americansâ€™ Rights and  Safety
	- https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/
- OpenAlpaca, an instruction-following model based on OpenLLaMA
	- https://github.com/yxuansu/OpenAlpaca
- ã€ŒLlamaIndexã€ãŒ0.6.0ã§å¤§ããªå¤‰æ›´ãŒã‚ã£ãŸã®ã§æ›´æ–°ã—ã¾ã—ãŸã€‚
	- https://note.com/npaka/n/n50475d6c3118
- ChromaDB Self-Querying Retriever
	- https://github.com/hwchase17/langchain/blob/master/docs/modules/indexes/retrievers/examples/chroma_self_query_retriever.ipynb
- experimental CodeChainã€LangChainã®ä¸Šã§Pythonã‚’å®Ÿè¡Œã§ãã‚‹ã‚‰ã—ã„ã€‚
	- https://langchain-ai.github.io/kork/
- Unifying LLM-powered QA Techniques with Routing Abstractions
	- https://betterprogramming.pub/unifying-llm-powered-qa-techniques-with-routing-abstractions-438e2499a0d0
- PandasAIã€ã¾ãŸã¾ãŸpandaãƒ™ãƒ¼ã‚¹ã®ãƒãƒ£ãƒƒãƒˆè§£æãƒ„ãƒ¼ãƒ«ã€OpenAIä»¥å¤–ã®LLMã®ä½¿ãˆãã†ã€‚
	- https://github.com/gventuri/pandas-ai

## 4/10
LLMã®å€«ç†çš„ãªãµã‚‹ã¾ã„ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã®ãƒã‚­ãƒ£ãƒ™ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚LLaMA-Adapterã¨å‘¼ã°ã‚Œã‚‹ã€è»½é‡ãªLoRAã®ã‚ˆã†ãªã‚·ã‚¹ãƒ†ãƒ ãŒç´¹ä»‹ã•ã‚Œã¾ã—ãŸã€‚DeepMindã‹ã‚‰ã¯ã€Transformersã®ãŸã‚ã®å½¢å¼çš„ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«é–¢ã™ã‚‹ç ”ç©¶ãŒç™ºè¡¨ã•ã‚Œã¾ã—ãŸã€‚LLMã«å¯¾ã™ã‚‹å¿ƒç†å­¦çš„ãªè©•ä¾¡ã‚„ã‚»ãƒ©ãƒ”ãƒ¼ã‚’è¡Œã†ãŸã‚ã®æ çµ„ã¿ãŒææ¡ˆã•ã‚Œã¾ã—ãŸã€‚ãƒªãƒ¼ã‚¬ãƒ«ãªGPT-4ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚‹HarveyãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚äº¬å¤§2å›ç”Ÿã®çµ±è¨ˆåŠ›å­¦ã®æœŸæœ«è©¦é¨“ã®å•é¡ŒãŒè«–æ–‡ã«ãªã£ãŸè©±ãŒã‚ã‚Šã¾ã™ã€‚Azureã®OpenAIãŒEmbeddingã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³2ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ2,048ã‹ã‚‰8,191ã«å¢—åŠ ã—ã¾ã—ãŸã€‚MatChaã¨å‘¼ã°ã‚Œã‚‹ã‚·ã‚¹ãƒ†ãƒ ãŒã€ã‚°ãƒ©ãƒ•ãªã©ã®å…¥åŠ›ã‹ã‚‰æ¨è«–ã‚„Q&Aã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚gpt4allã®å…¬å¼ãƒãƒ£ãƒƒãƒˆUIãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚Microsoft Researchã®Sparks of AGI: early experiments with GPT-4ã«é–¢ã™ã‚‹èª¬æ˜ãŒYouTubeã§æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚

-   LLMã®å€«ç†çš„ãªãµã‚‹ã¾ã„ã‚’ã•ã›ã‚‹ãŸã‚ã®ã€ãƒã‚­ãƒ£ãƒ™ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    -   [https://arxiv.org/abs/2304.03279](https://arxiv.org/abs/2304.03279 "https://arxiv.org/abs/2304.03279")
-   LLaMA-Adapter:è»½é‡ãªLoRAã¿ãŸã„ãªã—ãã¿ã‚‰ã—ã„ã€‚
    -   [https://arxiv.org/abs/2303.16199](https://arxiv.org/abs/2303.16199 "https://arxiv.org/abs/2303.16199")
-   DeepMindã‹ã‚‰ "Formal Algorithms for Transformers"
    -   [https://arxiv.org/abs/2207.09238](https://arxiv.org/abs/2207.09238 "https://arxiv.org/abs/2207.09238")
-   LLMã«å¯¾ã—ã¦å¿ƒç†å­¦çš„ãªè©•ä¾¡ï¼ˆã‚»ãƒ©ãƒ”ãƒ¼ï¼Ÿï¼‰ã‚’è¡Œã†æ çµ„ã¿
    -   [https://arxiv.org/abs/2207.09238](https://arxiv.org/abs/2207.09238 "https://arxiv.org/abs/2207.09238")
-   ãƒªãƒ¼ã‚¬ãƒ«ãªGPT-4ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ¼ãƒ“ã‚¹ã€Harveyï¼ˆç±³ãƒ‰ãƒ©ãƒã®SUITSã®ä¸»äººå…¬ã®ä¸€äººãŒãƒãƒ¼ãƒ™ã‚¤ï¼‰
    -   [https://harvey-ai.notion.site/Careers-Harvey-c9e804fe422e4316bdfde9fe74ed6b06](https://harvey-ai.notion.site/Careers-Harvey-c9e804fe422e4316bdfde9fe74ed6b06 "https://harvey-ai.notion.site/careers-harvey-c9e804fe422e4316bdfde9fe74ed6b06")
-   äº¬å¤§ï¼’å›ç”Ÿã®çµ±è¨ˆåŠ›å­¦ã®æœŸæœ«è©¦é¨“ã®å•é¡ŒãŒã€è«–æ–‡ã«ãªã£ãŸè©±ã€
    -   [https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001](https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001 "https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001")
-   Azureã®OpenAIã€Embeddingã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼’ãŒç™»å ´ã€ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ2,048â†’8,191ã¨æ¿€å¢—
    -   [https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1 "https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1")
-   MatCha: ã‚°ãƒ©ãƒ•ã¨ã‹ã®å…¥åŠ›ã€ã‹ã‚‰ã‚‚æ¨è«–ã‚„Q&AãŒã§ãã‚‹ã€‚ by GoogleAI
    -   [https://arxiv.org/abs/2212.09662](https://arxiv.org/abs/2212.09662 "https://arxiv.org/abs/2212.09662")
-   gpt4allã®å…¬å¼ãƒãƒ£ãƒƒãƒˆUIãŒãƒªãƒªãƒ¼ã‚¹
    -   [https://github.com/nomic-ai/gpt4all-ui](https://github.com/nomic-ai/gpt4all-ui "https://github.com/nomic-ai/gpt4all-ui")
-   MS Researchã®Sparks of AGI: early experiments with GPT-4ã®è‘—è€…ã«ã‚ˆã‚‹èª¬æ˜ã€‚ã€‚
    -   [https://www.youtube.com/watch?v=qbIk7-JPB2c&t=1023s](https://www.youtube.com/watch?v=qbIk7-JPB2c&t=1023s "https://www.youtube.com/watch?v=qbik7-jpb2c&t=1023s")

## 4/17
ä»Šäº•ã‚€ã¤ã¿å…ˆç”Ÿã®è¬›æ¼”ã€ŒAIæ™‚ä»£ã«å¿…è¦ãªå­¦ã³ã¨æ•™è‚²ãƒ¼èªçŸ¥ç§‘å­¦ã‹ã‚‰ã®è¦–ç‚¹ã€ãŒ2023å¹´3æœˆ29æ—¥ã«YouTubeã§é…ä¿¡ã•ã‚Œã¾ã™
Databricksã‹ã‚‰Doly2.0ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¾ã—ãŸã€‚Doly2.0ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§ã‚ã‚Šã€å•†ç”¨åˆ©ç”¨ã‚‚å¯èƒ½ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³èª¿æ•´å‹LLMã§ã™ã€‚
CMUã®åŒ–å­¦è€…ã«ã‚ˆã‚‹ã€LLMã‚’ä½¿ã£ãŸåˆæˆå®Ÿé¨“ã®å±é™ºæ€§ã«é–¢ã™ã‚‹è«–æ–‡ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚
OpenAIã®ç ”ç©¶è€…[@ilyasu](https://twitter.com/ilyasut)ã«ã‚ˆã‚‹ã€LLMã«ãŠã‘ã‚‹ãƒ“ã‚¸ãƒ§ãƒ³ã®é‡è¦æ€§ã«é–¢ã™ã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆã¨GPT-4ã«ãƒ“ã‚¸ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™ãƒ“ãƒ‡ã‚ªãŒTwitterã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
GPT4ALLã‚’ä½¿ç”¨ã—ãŸApatch2ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆOSSãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚
è§¦åª’é–‹ç™ºã«GPTã‚’æ´»ç”¨ã™ã‚‹ç ”ç©¶ãŒè¡Œã‚ã‚Œã¦ãŠã‚Šã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨LLMã‚’çµ„ã¿åˆã‚ã›ã¦åˆæˆæ¡ä»¶ã‚’è¦‹ã¤ã‘ã‚‹æ–¹æ³•ãŒç´¹ä»‹ã•ã‚Œã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€in context learningã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒä¸è¦ã¨ã•ã‚Œã€ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã¨åŒç­‰ã®æ€§èƒ½ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚
    
-   Alpacaã«CoTï¼ˆCommonsense Transformersï¼‰ã¨Storytellingã‚’å¼·åŒ–ã—ãŸãƒ¢ãƒ‡ãƒ«Alpacino30bãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸã€‚è©³ç´°ã¯[ã“ã¡ã‚‰](https://huggingface.co/digitous/Alpacino30b/tree/main)ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚
-   ä»Šäº•ã‚€ã¤ã¿å…ˆç”Ÿã®è¬›æ¼”ã€ŒAIæ™‚ä»£ã«å¿…è¦ãªå­¦ã³ã¨æ•™è‚²ãƒ¼èªçŸ¥ç§‘å­¦ã‹ã‚‰ã®è¦–ç‚¹ã€(2023å¹´3æœˆ29æ—¥)ãŒyoutubeé…ä¿¡ã•ã‚Œã‚‹
    -   [https://www.youtube.com/playlist?list=PLMITB-DRUs7N10WLl_4zDUWfBkLd6z_Em](https://www.youtube.com/playlist?list=PLMITB-DRUs7N10WLl_4zDUWfBkLd6z_Em "https://www.youtube.com/playlist?list=plmitb-drus7n10wll_4zduwfbkld6z_em")
-   Databircksã‹ã‚‰Doly2.0ãŒãƒªãƒªãƒ¼ã‚¹(OSSã‹ã¤å•†ç”¨åˆ©ç”¨å¯)
    -   [https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm "https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm")
-   CMUã®åŒ–å­¦è€…ã«ã‚ˆã‚‹ã€LLMã‚’ä½¿ã£ãŸåˆæˆå®Ÿé¨“ã«ä¿‚ã‚‹å±é™ºæ€§ã«ã¤ã„ã¦ã®éœ²æ–‡
    -   [https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm "https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm")
-   [@OpenAI](https://twitter.com/OpenAI "https://twitter.com/openai")ã®å¤§å¤©æ‰ç ”ç©¶è€…[@ilyasu](https://twitter.com/ilyasut "https://twitter.com/ilyasut")ã«ã‚ˆã‚‹ã€LLMã«ãŠã‘ã‚‹visonã®é‡è¦æ€§ã¨ã€GPT-4ã«ã¯visonã‚‚å…¥ã£ã¦ã„ã‚‹ã‚ˆãƒ“ãƒ‡ã‚ª
    -   [https://twitter.com/i/status/1645752089140957187](https://twitter.com/i/status/1645752089140957187 "https://twitter.com/i/status/1645752089140957187")
-   GPT4ALLã‚’ä½¿ã£ãŸApatch2ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒ‰OSSãŒå…¬é–‹
    -   [https://github.com/nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all "https://github.com/nomic-ai/gpt4all")
-   GPTã‚’ç”¨ã„ãŸè§¦åª’é–‹ç™ºã€‚ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¨LLMã‚’çµ„ã¿åˆã‚ã›ã¦ã€åˆæˆæ¡ä»¶ã‚’è¦‹ã¤ã‘ã‚‹ã€‚ã—ã‹ã‚‚in context learningã‚’ä½¿ã†ã®ã§ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚ä¸è¦ï¼ï¼ï¼ï¼ˆç´ ã®GPTã§OKã¨ã„ã†ã“ã¨ï¼‰ã€‚ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã¨åŒç¨‹åº¦ã®æ€§èƒ½ã€‚é€†è¨­è¨ˆã‚‚å¯èƒ½
    -   [https://arxiv.org/abs/2304.05341v1](https://arxiv.org/abs/2304.05341v1 "https://arxiv.org/abs/2304.05341v1")
-   Alpacaã«CoTã¨Storytellingã‚’å¼·åŒ–ã—ãŸã€Alpacino30bå…¬é–‹
    -   [https://huggingface.co/digitous/Alpacino30b/tree/main](https://huggingface.co/digitous/Alpacino30b/tree/main "https://huggingface.co/digitous/alpacino30b/tree/main")

## 4/24
æœ€è¿‘ã€Microsoftã¯Semantic Kernelã®Pythonãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç™ºè¡¨ã—ã€ã“ã‚Œã«ã‚ˆã‚ŠSemantic Kernelã‚’Pythonã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚ã¾ãŸã€gist tokenã‚’ä½¿ç”¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åŠ¹æœçš„ã«åœ§ç¸®ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ãŸè«–æ–‡ã‚‚ç™»å ´ã—ã¦ãŠã‚Šã€26å€ã®åŠ¹æœãŒã‚ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
ã•ã‚‰ã«ã€æ–°ã—ã„
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzE4MjgzMjAzLDk5MjIxMDUyNywxNDg2ND
EzOTg4LDE3MzEzMDkzMzAsLTExMjc5ODYzNDksLTg4MjkwMTY0
MiwtMTE3NzMwMDYzMiwtMjA2MzY5NzkyMiwxMjk1NzQyNzM5LC
0xMzk2MjIwNjQ3LC04OTgwNzU5LC05NTQ3MzcwNDEsNTQ3MDk3
MTYxLDE0ODY3NTIwNTEsLTEyMjAyMDYwMjcsMTI4NTcxMzU2Ni
wtMTc2NTM2MjM2LC0yMDg2MDM2ODk5LC05Mzk1Njc2MTMsMTMx
MTA2Mjk5OF19
-->