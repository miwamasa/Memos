# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。

## 3/4

1ビットLLMの衝撃!マイクロソフトの発表、 70Bで8.9倍高速ということで、勝手実装、追試も続々、200Mでそれなりに動くというshi3zさんの評価も、shi3zさんによると、「プログラマーなら全員BitNet試してみるべき」だそうだ。小さく試すという意味では、250MのMixtralをpretrainingからfinetuningを試した事例も。てっぺんが高いところにあると周辺も拾うところがたくさんあるという、LLM界隈でのトリクルダウン現象が起きている。さて、先週公開されたgemma、ollamaでサポート、周辺モジュールにバグが多いとか、いやファインチューニングで使えたとか、いろいろ評価がある、2bのほうが7bより性能よいと謎の報告も、ちょっと急ぎすぎたか。一方Qwenは、Qwen1.5最高とか、もはやQwen-72Bでいいのではないのか、という評価も出ているが、実は出力をデータセットようには使えないなどの縛りがある。マネフォOBが立ち上げたスタートアップstarleyの音声会話型おしゃべりAIアプリ「Cotomo」、UXを考えてちゃんと使える商品に落とすこむことの大切さよ。Mistral Large、**Gemini Proなどのクローズドモデルよりも高いベンチマークスコアを獲得**って本当か？LLMには自然言語よりも最適な形式があるのでは？という野心的な『AutoForm（オートフォーム）』、そういえば先輩の三つ子ちゃんは、独自の言語でコミュニケーションしていたって言ってたな。東工大の、『論文の結論を学習させたら性能が下がった。』という話、イントロのほうがよいというのは不思議だ。μTransfer、転移学習のマイクロ版？大規模モデルの学習をおそらく圧倒的に効率化できるのはよい。Gemini 1.5 Proも使える人が少しずつ拡大している模様、来週あたりはいろいろ評価がでるかも。Long-context LLMs がRAGの代わりになるかならないか。Function Calling、色々なサポートが出てきて、当たり前の技術になりつつあるな。LlamaParseのPDF読み取り評価とか、RAGでの回答精度向上のためのテクニック集とか、地道に進む。 NVIDIAがノートパソコン用のGPUを新発表とか、まさにwinner takes allの世界。さて日本の優秀な頭脳はどうよ？ということで先週、がっちりマンデーで、東大出身の若者が多いベンチャー「燈」が紹介されたが、あれって、「建築×AI」のテーマで、LLMをがっつり活用するという話。社会実装というかそっち系？

- 画像生成AI、安いPCでも高速に　衝撃の「Stable Diffusion WebUI Forge」
	- https://weekly.ascii.jp/elem/000/004/185/4185940/
-  μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_pb
	- μTransfer は、μP （Maximal Update Parametrization）という理論的に導出された NN のパラメータ付けにより実現される、サイズの異なる NN 間のハイパーパラメータ転移です。
	- （知らなかった読者にとって）大規模モデルの学習をおそらく圧倒的に効率化できる汎用的かつシンプルなパラメータ付け μP の存在と使い方を知ることができる。
	- Neural Networks に対してかなり一貫性のある理解が得られそうな気分になる。学習率やパラメータの初期化のスケールに関する話がなんでも TP/μP で取り扱うべき事項に見えてくる。
- ウェブの日本語テキストをクリーニングするための基本的な処理コードと課題
	- https://note.com/kan_hatakeyama/n/n331bda7d77c1?sub_rt=share_pb
		- 文字列の正規化　(変な文字コードを消す)
		- ルールベースでの、不要な文字列の削除
		- 機械学習ベースでの、不要な文字列の削除
		- 重複の削除
- 【最強になった】Googleの最大1000万トークン入力可能なGemini 1.5 Proがヤバすぎる。《概要、他LLMとの比較、ビジネスシーンでの活用方法5選を徹底解説》
	- https://note.com/chaen_channel/n/necaf27db79ae
-  LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens
	- https://arxiv.org/abs/2402.13753
	- It looks like the problem of long contexts in open LLMs is close to being solved.
- ​”話したいことも、話せないことも。” 音声会話型おしゃべりAIアプリ「Cotomo」を提供開始
	- https://prtimes.jp/main/html/rd/p/000000007.000123714.html
- たくさんのお客様がCotomoとおしゃべりしていることで、動作が不安定になる事象が発生しております
	- https://x.com/starley_jp/status/1761753632788357611?s=20
- Qwen1.5 速いし日本語完璧だしすごい by shi3z
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ku-nlp/gpt2-large-japanese-char
	- 弊研のhuggingfaceリポジトリで charcter vocabulary の日本語 gpt2-large（A100 1枚で訓練8か月!）が公開されているので、何かの興味で日本語の文字レベルの言語モデルが欲しい方は是非使ってみてください
- ローカルで気軽にRAGを使って会話することが簡単すぎてビビった。
	- https://qiita.com/mitsumizo/items/469d79c5e81d9189a9e4
- 日本のオープンデータ情報一覧・まとめ
	- https://github.com/japan-opendata/awesome-japan-opendata
	- PLATEAU AWARD 2023でグランプリを受賞した方のGitHubらしい
-  AITuberのブレイクスルーは音声雑談から始まった Cotomo
	- https://note.com/o_ob/n/n27edbebf17af?sub_rt=share_h
	- ・敬意を持って接する  、「話すの楽しい」設定 、過去の会話をキャッシュする  、相手の速度に合わせて早口になる  、一度言った話は2回目は早口  、お別れを名残惜しむ
- Mistral announces Mistral Large, a new flagship model.
	- https://x.com/omarsar0/status/1762140818654064721?s=20
		- 32K tokens context window
		- has native multilingual capacities
		- strong abilities in reasoning, knowledge, maths, and coding benchmarks
		- function calling and JSON format natively supported
		- available through Microsoft Azure
		- a low-latency model called Mistral Small was also released
- Qwen1.5-72B-Chatをお試し中。
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
	- もう全部Qwen-72Bでいいんじゃないかな
	- https://x.com/alfredplpl/status/1762277261435347424?s=20
- Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
	- https://arxiv.org/abs/2402.14848
	- プロンプトの入力が長くなるにつれて、推論性能に顕著な低下が見られることが示唆
	- ■実験結果
		- 入力が長くなると推論の精度が低くなる
		- 失敗モードは主に4つで、入力が長くなるほど顕著になる 
			- 1. 回答拒否 
			- 2. 偏った判断 
			- 3. 頭から答えを言う（推論ステップを辿らない）、 
			- 4. 入力テキストを適切に使わない
- RAGでの回答精度向上のためのテクニック集（基礎編）
	- https://zenn.dev/knowledgesense/articles/47de9ead8029ba
- NVIDIAがノートパソコン用のGPUを新たに発表
	- https://x.com/webbigdata/status/1762645658266468393?s=20
	- RTX 500 GPUは4GBのGPUメモリ 
	- RTX 1000 GPUは6GBのGPUメモ
- LangChainに便利な機能が誕生してまし
	- https://x.com/MLBear2/status/1762623474034790886?s=20
	- Pydanticで構造体を定義した上で `with_structrured_output` を図のように使えば、Function Callingを簡単に呼べるようになりました。 
	- ChatGPTだけではなく、GeminiなどFunction Callingに対応する他のLLMでももちろん使えるとのこと。
- Function Calling Cookbook with Open-source models (LlamaIndex+FIREWORKS)
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/fireworks_cookbook.ipynb
	- We’re excited to present a series of cookbooks showing you how to use LlamaIndex with Fireworks, including function calling and RAG with FireFunction-v1.
- PDFがスルスル読める！話題のLlamaParseとは
	- https://zenn.dev/yokina_kaoto/articles/563f7d75673c2e
	- LlamaParseはLlamaIndexの新しい製品で、再帰検索を実行することで複雑なPDFのテーブルをきれいに抽出することができ、しばしば悩まされる複雑なドキュメントのより正確な解析を約束します
	- LlamaParseでPDFをパースし、AstraDBで**非構造化データ**を検索することで精度が向上するとのこと。
- 新Kaggleコンペ： LLMで生成された文章からプロンプトを復元するタスク
	- https://www.kaggle.com/competitions/llm-prompt-recovery
	- LLMで生成された文章からプロンプトを復元するタスク。
	- データはGoogle Gemmaで作成。評価がsentence-t5-baseの埋め込みベクタとのコサイン類似度なのが時代を感じる。もうJaccardスコアとかの時代じゃないらしい
- iOS17.4のソースコードにOpenAIの何かを含む部分が見つかっていて、おそらく数ヶ月以内にSiriが強力にアップデートされます。
	- https://x.com/1amageek/status/1762422935376302226?s=20
-  The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
	- https://huggingface.co/papers/2402.17764
	- Microsoft presents The Era of 1-bit LLMs 
	- All Large Language Models are in 1.58 Bits
	- これ本当ならタイトル通り生成AIの新時代かもしれない
-  1ビットLLMの衝撃! 70Bで8.9倍高速　全ての推論を加算のみで!GPU不要になる可能性も by shi3zさｎ
	- https://wirelesswire.jp/2024/02/86094/
	- いずれにせよ、　この論文が本当だとしたら、とんでもないことが起きることになる。
- Microsoftが「1ビットLLM時代の到来」という衝撃的なタイトルで論文を公開し、GPUが不要になるかもしれないとの話も出てきているので従来の手法との違いをまとめました
	- https://x.com/webbigdata/status/1763021292696170917?s=20
-  驚異の1ビットLLMを試す。果たして本当に学習できるのか? by shi3zさん
	- https://note.com/shi3zblog/n/n58b0a2252727?sub_rt=share_pb
	- 試したのはこちら
		- https://github.com/Beomi/BitNet-Transformers/tree/main
	- なんかそれっぽいこと言ってる!!!!!!  しかも小さいから当たり前なのだが推論は超速いのである。
	- モデルサイズは200MB。GBじゃないよ。  僕は小さい言語モデルも大きい言語モデルもそこそこ触って来た方だと思うが、このサイズ
- Mixtral 250MのpretrainingからInstruction Tuningまで
	- https://zenn.dev/if001/articles/9bb90e0d8c201f
	- MoEを持つMixtralがhuggingface/transformersで公開されているので、これを利用しつつ、250Mの小さいサイズとして日本語と英語でpretraining、finetuningを行います。
	- 250MのMixtralをpretrainingからfinetuningまでを行いました。小さいサイズなりにうっすら日本語を理解してそう。入力から正確に情報を抽出とそれらを使った出力はさすがに難しそう。あとは、推論時のexpertの選択のされかたや同サイズのモデルとの比較をしてみたいところ
- プログラマーなら全員BitNet試してみるべき by shi3zさん、
	- https://github.com/kyegomez/BitNet
- gemma-7b、英日翻訳タスクに関しては微調整に成功すると私の翻訳モデルALMA-7B-Ja-V2より一段階レベルが上の性能でした
	- https://x.com/webbigdata/status/1762791697212375111?s=20
	- 周辺モジュールにバグが残っていて、英語圏ではあきらめる勢が多いみたい。
- LlamaIndexとGroqの統合
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/groq.ipynb
- Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication
	- https://arxiv.org/abs/2402.18439
	- 「自然言語を超えて」と題して、LLMにタスク実行時の思考を人間の自然言語とは異なるフォーマットで行わせるプロンプト手法『AutoForm（オートフォーム）』が考案されました。
	- LLMの思考は必ずしも人間と同じフォーマットに沿う必要はない、といった結論になります。LLMエージェント同士でコミュニケーションする際にはこの方が効率的かもしれないとのこと。
	- 自然言語に固有の曖昧さを排除し、明確性を高めるために、ステップバイステップの解決策には、より構造化されて簡潔なコミュニケーションの形式を検討してください。適切なフォーマットには、コード、擬似コード、JSON、マークダウン表、論理演算子、または数学方程式が含まれます。回答の最後には、〜〜という形式で答えを示さなければなりません。簡潔かつ正確であることを忘れないでください。
- ChatGPTは数学を解く時に厳密に計算するためにADA（Advanced Data Analitics, Code Interpreter）をデフォルトで使用する様に変わってます
	- https://x.com/ai_syacho/status/1763308074503422008?s=20
	- しかも数学計算の計画も立てる事ができる。
- オリジナルのBitNetを1.58bの論文に従って3値にするように修正しました
	- https://github.com/frodo821/BitNet-Transformers
- Beyond Disciplines「Beyond Disciplines ～CRDSが注目する研究開発の潮流2024～」
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-06.html
	- 所属組織が発行している数十冊・計数千ページの報告書を40ページくらいに圧縮したレポート作成にかかわりました。
- Qwen1.5-72B 日本語能力も高くて良いが生成物でデータセットは作れない規約で残念。
	- https://x.com/alexweberk/status/1763905106674954324?s=20
- 『論文の結論を学習させたら性能が下がった。』
	- https://newswitch.jp/p/40657
	- ６万５０００報の論文データセットを構築した。学習データでは、論文の要約よりもイントロダクションが性能向上に役立った。論文の結論の学習は、性能面でネガティブに働いた。小さなＬＬＭにとっては結論の内容が専門的過ぎた可能性がある。専門知識を備えたＬＬＭを構築するための知見になる。
- 【論文丁寧解説】BitNet b1.58とは一体何者なのか
	- https://qiita.com/tech-Mira/items/67dec9c5a5f025d2727a?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- BitNet b1.58は、その名の通り、各パラメータが、、[−1、0、1]という3つの値での動作を実現した1bitのLLMです。つまり、膨大な計算リソースを必要とする従来のモデルとは異なり、非常に効率的に動作します。加えて、この記事で示されている結果では驚くべきことに、性能は従来の高精度モデルを上回ります。
	- BitNet b1.58とFP16 LLaMA LLMを様々なサイズで比較しました。公平な比較を保証するために、モデルをRedPajamaデータセットで1000億トークンに対して事前学習しました。
- Google AI Studio で つくよみちゃんの会話テキストデータセット による Gemini の チューニングを試す by npakaさん
	- https://note.com/npaka/n/n8b03a58abb2c?sub_rt=share_h
	- 「Google AI Studio」で「つくよみちゃんの会話テキストデータセット」による「Gemini」のチューニングを試したので、まとめました。
-  Towards Long Context RAG by llamaindex
	- https://www.llamaindex.ai/blog/towards-long-context-rag
	- We did a deep dive into Gemini, and consolidated our thinking about long-context LLM benefits, challenges, and new architectures
	- Long-context LLMs will help alleviate the need to do precise chunking and retrieval, and RAG over small sets of documents
	- Long-context LLMs still don’t resolve the issue of RAG over big knowledge bases (present in most organizations/enterprises)
- Gemini 1.5 Proが遂にきました！！！！
	- https://x.com/masahirochaen/status/1763639557457899963?s=20
- GoogleのGemma、2Bの方が7Bより性能が良いとかおかしな事が報告されている
	- https://x.com/webbigdata/status/1763730996455973098?s=20
	- Jeremyさんの言っている通り、fine tuningはHugging Faceに掲載されているTransformers実装ではなくて、githubのgoogle-deepmind/gemmaを参考にした方が良いのかもしれません
	- https://x.com/jeremyphoward/status/1763679390968455185?s=20
- 

## 2/26

先週、soraの発表で少し霞んだGemini 1.5 pro 、402ページの文書、44分間の映画、10万行のコードに対する推論など、その能力の一旦が垣間見れてきた。Googleは引き続きGemini 1.5 proベースのOSSであるGemma(“貴重な石”、ラテン語)をリリース、同パラメーターサイズであればLlama2やMistralより優れているとの事。Gemmaは軽量であるとともに、embeddingの工夫、安全なAIアプリケーションを作成するためのガイダンスと必須ツールの提供、Kera3.0サポートなど、かなりの量と質のソフトウエアスタックが一気に公開されたことになる。OSS戦略として、安全性に関するコミュニティとの共創という意味でも、MetaのOSS戦略と丸被り。早速、量子化gguf版や、KaggleでGemmaをつかったコンペの開催、embeddingの解析（日本語語彙は貧弱？）、npakaさんによるファインチューニング試行、MLXを使ったファインチューニングなど、コミュニティの活動が盛んに。LPU（Language Processing Unit）を引っ提げるGroq、推論時の高速さが半端ない、専用チップ開発でも戦いは続く、日本のMN-core早く！llamaindexもLlamaCloudとLlamaParseをリリース、テーブルや図表などの埋め込まれたオブジェクトを含む複雑な文書のための独自のパーシングや、RAGの構築がより高性能に、かつ容易になった。日本語LLMでは、 KARAKURI LM (70B)のELYZA-tasks-100による性能評価や、東工大と東北大によるKotomambaの構築等。フレームワークでは、BCGXからagentkitのOSSリリース、DXの手段としてのAIというシナリオでのコンサル系の新たなビジネスモデル。基礎研究では、プロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』や、Mambaとtransformerとのcolabを使った速度比較とか、そもそも状態空間モデルの解説とか。DeepMindとCMUによる、LLMをつかった数値回帰OmniPred論文も面白い、その性能の理論的解析が待たれる。Stable Diffusion 3のリリースやsentencepiece v0.2.0リリースなどの基盤ソフトの重要な更新も進んだ。

- BCGXから、agentkit
	- https://agentkit.infra.x.bcg.com/
	- BCG Xから大規模言語モデルを使ったAgentを楽に作るためのフレームワークAgentKitがOSSとして出ました〜。 Nextjs, FastAPI, Langchainのモダンなテックスタックです
-  Hyena Hierarchy: Towards Larger Convolutional Language Models
	- https://speakerdeck.com/hpprc/hyena-hierarchy-towards-larger-convolutional-language-models
	- Hyena Hierarchyについて、状態空間モデル（SSM）の基礎から解説したスライド
- GroqのLPUについて
	- https://x.com/umiyuki_ai/status/1759740311335739784?s=20
	- Groqとか言う会社のLPU（Language Processing Unit）って新しいチップはLLM推論速度が爆速なんだと。NVidiaとかのGPUと違って高品質なVRAMが要らんから低コストらしい。70BのLLMを動かす時に300tpsという超爆速で推論できる。
	- M3Maxだと6tps、RTX4090+PowerInferだと4tpsしか出ないから50～100倍の速度差。GPUがオワコンの時代来たか？
- The Shift from Models to Compound AI Systems
	- https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/
	- Berkeleyの人々による、「コンパウンドAI」のレビュー記事。
	- LLM単体で勝負するよりも、LLMを含む各種AI／非AIモジュールを組み合わせて作る「コンパウンドAI」の方がより良いシステムを作りやすい、
- Introducing LlamaCloud  and　LlamaParse
	- https://blog.llamaindex.ai/introducing-llamacloud-and-llamaparse-af8cedf9006b
	- Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring **production-grade**  **context-augmentation** to your LLM and RAG applications.
- MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts
	- https://arxiv.org/abs/2401.11403
	- 機械学習応用には分子の物性予測から分類までさまざまなタスクがありますが、LLMによりそれぞれのタスクごとに最適な分子表現へと調整することで、予測性能が向上したそうです。
- 超高速な対話AIサービスのGroq
	- https://groq.com/
-  Learning to Learn Faster from Human Feedback with Language Model Predictive Control
	- https://huggingface.co/papers/2402.11450
	- Google presents Learning to Learn Faster from Human Feedback with Language Model Predictive Control
- SLANG: New Concept Comprehension of Large Language Models
	- https://arxiv.org/abs/2401.12585
	- GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』をカリフォルニア大学などの研究者らが考案
	- ■メソッド 
		- 1. 使用例（コンテキスト）とフレーズを直接入力する 
		- 2. フレーズをコンテキスト内で隠して、意味を評価させる 
		- 3. コンテキスト内のエンティティ（固有名詞や出来事など）を変更し、異なるエンティティがフレーズの解釈に与える影響を調べる 
		- 4. 上記の結果、モデルが新しい言葉の理解に至ったのかを評価する 
	- ■実験と結果 
		- 1. GPT-4/3.5で検証 
		- 2. モデルが知らないインターネットミームを教え込ませた 
		- 3. GPT-4で88.2%、GPT-3.5でも84.5%の正確さを達成した
-  GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements
	- https://huggingface.co/papers/2402.10963
	- 結果ベースの報酬モデル (ORM) をリランカーとして使用して、グローバルとローカルの改良を組み合わせると、いずれか 1 つを個別に使用した場合や、3 つのサンプル ベースラインの中で最も優れたものを大幅に上回るパフォーマンスが得られることがわかりました。
- The Tokenizer Playground
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- After watching, if you want to learn more about how different models (e.g., GPT4, Llama, T5, BERT) tokenize text, check out "The Tokenizer Playground": a web-app I built a few months ago with Transformer.js
- Gemini AdvancedでAIによって提案されたpythonコードを直接実行して動作確認できるインタフェースが追加された
	- https://x.com/webbigdata/status/1760129585994432916?s=20
	- Gemini 1.5 proで「githubから直接全コードと全issuesを取得させる事」と「最も緊急度の高いissuesを特定し、修正を実装させる事」が出来た
- Kotomamba: mamba-2.8B 学習知見
	- https://zenn.dev/kotoba_tech/articles/f15b2495d44c4f
	- Kotoba TechnologiesはNLPと分散並列学習に関する技術を用いて、日本及び非英語圏におけるLLMやマルチモーダルモデルの実運用に向けた研究開発を行っています。
	- from scratchから日本語と英語のコーパスにて学習を行ったkotomamba-2.8B-v1.0、
	- もう１つはstate-spaces/mamba-2.8b-slimpjから日本語と英語で継続事前学習を行ったkotomamba-2.8b-CL-v1.0です。
- sentencepiece v0.2.0
	- https://github.com/google/sentencepiece/releases/tag/v0.2.0
- Gemini 1.5 ProのYoutube３本セット
	- Reasoning across a 402-page transcript
	- https://www.youtube.com/watch?v=LHKL_210CcU
	- Multimodal prompting with a 44-minute movie
	- https://www.youtube.com/watch?v=wa0MT8OwHuk
	- Problem solving across 100,633 lines of code
	- https://www.youtube.com/watch?v=SSnsmqIj1MI
- KARAKURI LM を ELYZA-tasks-100 で評価してみた
	- https://qiita.com/wayama_ryousuke/items/f4f384b89e9b40a2d794
	- 実際にどの程度の性能があるのか、[ELYZA](https://elyza.ai/) が公開しているベンチマーク用データセット **ELYZA-tasks-100** で評価してみました。
	- 前回記事で最高スコアをマークした Xwin-LM-70B (4bit 量子化) を上回り、平均得点2.98点をマークして**1位**となりました。
	- 日本発の 70B モデルは [Japanese-StableLM](https://huggingface.co/collections/stabilityai/japanese-stable-lm-654063a381a8731a1c0f13cc) などごく一部に限られ、ELYZA-tasks-100 での平均スコアも海外モデルが優位に立っている状況でした。  KARAKURI LM の公開により、その状況が大きく変わったと言えそうです。
- Mambaを動かして速度をtransformerと比較するメモ
	- https://note.com/kan_hatakeyama/n/na911120f4ffb?sub_rt=share_pb
	- 話題のmambaをcolabで動かしてみました｡ 同等サイズのtransformerよりも､2倍くらいは推論が早そうです｡
- Googleのオープンモデル Gemma の概要  by npakaさん
	- https://note.com/npaka/n/na47e13dae482?sub_rt=share_h
	- 「[**Gemma**](https://ai.google.dev/gemma)」は、「**Gemini**」と同じ技術を基に構築された、軽量で最先端のオープンモデル
	- 「Gemma 2B」「Gemma 7B」の2つのサイズのモデルウェイトをリリースします。各サイズは、事前学習および指示チューニングされたバリアントでリリースします。
	- 「Responsible Generative AI Toolkit」は、「Gemma」を使用してより安全なAIアプリケーションを作成するためのガイダンスと必須ツールを提供します。
	- 「Keras 3.0」を介して、JAX、PyTorch、TensorFlow など、すべての主要なフレームワークにわたって推論と教師ありファインチューニング (SFT) のためのツールチェーンを提供しています
	- 事前学習、指示チューニングされた「Gemma」は、ノートパソコン、ワークステーション、Google Cloud 上で実行でき
	- 「Gemma」のリスクプロファイルを理解して軽減するために、手動のレッドチーム化、自動化された敵対的テスト、危険なアクティビティに対するモデルの機能の評価など、堅牢な評価を実施しました。 
	- ai.google.dev/gemma、では、「Gemma」の詳細やクイックスタートガイドを参照できます。
- Gemma Tokenizer が面白い
	- https://x.com/AiXsatoshi/status/1760437059066695976?s=20
	- Llama tokenizerと共通点
		- SentencePieceベース
		- バイトレベルエンコーディングで未知トークン対応
	- 違い
		- 語彙サイズ: Gemma 256K、Llama 32K 
		- Gemmaは`add_dummy_prefix` False → 先頭に空白追加なし（GPTと同じ）
		- Gemmaには特別なtoken多数（例: HTML要素、謎）
- google/gemma-7bのtokenizerはBPEでvocabは256k
	- https://huggingface.co/google/gemma-7b
	- ひらがなカタカナを含むvocabは7039件 
	- 京都 大阪 兵庫 奈良 滋賀 はあれど 和歌山 は登録なし 
	- 他では見ないタイプのトークンが多数 コードもmergeされたてホヤホヤ
- gemma-7b
	- https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf
	- https://huggingface.co/chat/settings/google/gemma-7b-it
	- Geminiモデルと同様のアーキテクチャ、データ、学習レシピを使用して、最大6兆個のテキストトークンで学習（主に英語）。サイズは2つで、パラメータ数がそれぞれ20億個と70億個。TPUv5eを使用して学習
	- 日本語モデルではないのに日本語でも答えてくれる
	- Hugging Face に 2B と 7Bの二種類（それぞれベース・インストラクション）があがっている
	- Context Length は 8k
	- 4bit で推論するコードも HF page にそのまま記載ある
	- ライセンスは Gemma license
	- llamaより緩いライセンスでリリース
	- 同パラメーターサイズであればLlama2やMistralより優れているとの事
- kaggle新コンペ Google Gemmaを使ってData Scienceのタスクがどの様に解けるかをデモするノートブックを作成するAnalyticsコンペ。
	- https://www.kaggle.com/competitions/data-assistants-with-gemma/
	- LLM大喜利。各タスク毎に賞金$10k。
- gemma-2bを試す by npakaさん
	- https://x.com/npaka123/status/1760432810811400204?s=20
	- https://huggingface.co/google/gemma-2b-it
- gemma-7b-it-gguf
	- https://huggingface.co/mmnga/gemma-7b-it-gguf
	- Googleさんが公開されているgemma-7b-itのggufあります
	- **現在量子化された出力が不安定な問題があるらしくQ8_0を推奨します。**
	- ご利用前にgemma利用規約をご確認下さい
- side-by-side comparison of the GPT-4, Gemma, and Llama tokenizer
	- https://x.com/xenovacom/status/1760384978360074460?s=20
	- the Gemma and Llama tokenizers are very similar, with the main difference being vocabulary size. One interesting thing to see is that even with an 8x larger vocabulary (256k vs 32k), Gemma only produces ~13% fewer tokens than Llama.
- Google Colab で Gemma のファインチューニングを試す
	- https://note.com/npaka/n/nc55e44e407ff?sub_rt=share_h
	- 今回は、ござるデータセットで学習します。AIが「我、りんえもんは思う。◯◯でござる。知らんけど。」的な口調になります
- OmniPred: Language Models as Universal Regressors
	- https://huggingface.co/papers/2402.14547
	- 広範な実験により、数学的なパラメーターと値のテキスト表現のみを通じて、言語モデルが非常に正確な数値回帰が可能であることが実証され、トレーニングの機会が与えられれば、複数のタスクにわたって、従来の回帰モデルを大幅に上回る可能性があります
- Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping
	- https://huggingface.co/papers/2402.14083
- Stable Diffusion 3リリース
	- https://stability.ai/news/stable-diffusion-3?utm_source=twitter&utm_medium=website&utm_campaign=blog
	- 学習データから15億件も弾いたらしい。すごいな
- Colbert Rerank
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/node_postprocessor/ColbertRerank.ipynb
	- ColBERT  is a great model for reranking. It’s ~100x faster than BERT-based/cross-encoder models, letting you rerank large amounts of documents without worrying about latency. And of course it does better than standard dense retrieval.
- The prompting guide for Gemma 7B Instruct is live!
	- https://www.promptingguide.ai/models/gemma
-  最新の Google Gemma モデルを MLX を使ってローカルでファインチューニング
	- https://note.com/alexweberk/n/n96cc4c8ac174?sub_rt=share_h
	- M3 Max 128GB で約 50 分かかりました。npaka さんの記事だと 20 分ほどで完了するそうなので、やはり NVIDIA A100 などの GPU と比べてしまうと時間がかかってしまいますね…。
	- https://gist.github.com/alexweberk/1434c95c05463866491677aac6ce19ba#file-mlx_finetuning_gemma-ipynb
-  Introducing Pebblo — Data Visibility & Governance for Gen-AI apps
	- https://medium.com/@sridhar_ramaswamy/introducing-pebblo-data-visibility-governance-for-gen-ai-apps-086ca8a62d10
	- Pebblo enables developers to safely load data and promote their Gen AI app to deployment without worrying about the organization’s compliance and security requirements. The project identifies semantic topics and entities in the loaded data and summarizes them on the UI or a PDF report.
- 

## 2/19

今週は、なんといっても、sora、sora、sora。これってOpenAIが意図してリリース時期を計算している気がする。GoogleのGemini 1.5のリリース直後だし、MetaのLecun先生が、当面できないという講演の数日後に出すとか、OpenAIは配球を選ぶだけの持ち球のストックがあるといううわさは本当なのかも。外部からのsoraの技術解析も進み、既存の技術の組み合わせではあるが、その性能・精度とスケールが違うととのことで、つまり、OpenAIが圧倒的な横綱相撲を見せつけただけだった。soraのおかげで霞んででしまったGemini 1.5、なんとMoEを採用し、長大トークンに対応、RAGっていらね？みたいな勢いだが、ブラックボックスをガラポンで利用してよいわけがない。RAGもCollective RAGとか、embeddingの工夫とか、説明性のある生成AIの方向に進んでる気がする。一方MetaはLeCun先生のいう世界モデルに近くためのV-JEPA（動画の予測）を発表。ここにきて、世界モデルやシミュレーションが一気に現実味が帯びてきた。なぜかLlamaindexとLangchainが同時期にそれぞれ大きなバージョンの代替わり、肥大化しすぎたのをモジュラー化したという話だが、LangChainには後方互換性があるって本当？LLMのサーベイ論文、今後の研究の進む方向を正しく見据えててよい。小さいLLMとかTransfomerに代わる次世代アーキテクチャ(Mambaとか）とか、本LLMアプデでも追ってた話題が満載、まあ誰が見てもそうなるわな。natureの、ChatGPTを利用してデータから論文を生成ってのは、自分がというわけではなく、そういう人や論文と世界で競争しなければいけないという意味で、研究者なら必読だろう。ローカルLLMでは、Ollamaの日本語出力が改良されたということで、npakaさんのElyza-7Bを動かした記事は、日本語でローカルLLMしたい勢には参考になるだろう。元木さんの分析のように、Transformerベースの潜在拡散モデルをつかったLLMでは、資金とリソースの戦いなので、横綱相撲を見せつけらて戦闘意欲をそがれる発表が多いが、だからこそ、LLMサーベイ論文がいうように、アーキテクチャのパラダイムを変える必要があるし、そういう人たちが出てくるに違いない。歩みを止めるわけにはいかない。

-  LlamaIndex v0.10
	- https://blog.llamaindex.ai/llamaindex-v0-10-838e735948f8
	- https://x.com/llama_index/status/1757121818115322076?s=20
	- our biggest open-source release to date, and a massive step towards production-readiness.
	- Create a core package, split off every integration/template into separate PyPi packages.
	- Refactor LlamaHub to become a central hub of all integrations (WIP)
	- Deprecate ServiceContext: Your dev UX is now way better without this object.
- Chat with RTX from NVIDIA
	- https://x.com/NVIDIAAIDev/status/1757447655674819053?s=20
- Deepreneur-blue-lizard
	- https://huggingface.co/Deepreneur/blue-lizard
	- 東京大学松尾研究室発のAIスタートアップ、株式会社Deepreneur(ディープレナー
	- MetaのLlama-2-7bに対して、Wikipediaや書籍等の日本語の学習データを用いて追加事前学習と独自データによるファインチューニングを実施したモデルです。  
	- 70億パラメータと非常に軽量なモデルであるにも関わらず、JGLUE（日本語タスクにおける評価ベンチマーク）を用いた評価では、ChatGPT-3.5を超えるスコアが算出されており、公開されている日本語モデルの中では最高性能になります。
	-  株式会社Deepreneur、ChatGPT-3.5を上回る日本語LLM「blue-lizard」を開発。各社独自の高精度オンプレ型のLLMの構築サービスを開始
- ChemLLM: A Chemical LLM
	- https://arxiv.org/abs/2402.06852
	- We don't see too much research around LLMs for science so it's exciting to find this one. 
	- It's a dedicated LLM trained for chemistry-related tasks. Claims to outperform GPT-3.5 on principal tasks such as name conversion, molecular caption, and reaction…
- Large Language Models: A Survey
	- https://arxiv.org/abs/2402.06196
	- 大規模言語モデル（LLM）これまでとこれからを包括的に整理したサーベイ論文が公開されています。
	- ■小さくて効率的なモデルを開発する 
		- 大きなモデルは高コストで非効率的である
		- そのためタスク特化の小型モデルへの関心が高まっている 
		- パラメータ効率の良いファインチューニングや、教師あり学習、蒸留法などの技術が活用される 
	- ■アーキテクチャのパラダイムを変える 
		- トランスフォーマーの"次"に関心が高まっている
		- アテンションモデルに変わる状態空間モデル（Mambaなど）が筆頭候補 
		- 新アーキテクチャは長いコンテキストを効率よく扱うなどの優位性が確認されている 
	- ■マルチモーダルモデルに進化させる
		- テキスト、画像、動画、音声など様々なデータタイプを統一的に扱うようになっていく
		- アプリケーションの幅が広がる
		- すでに優秀なモデルが出現し始めており、この流れは続いてくだろう 
	- ■実用性を向上させる 
		- LLMの短所（幻覚など）はプロンプトエンジニアリングや外部ツール、RAGなどで対処できることが分かり始めている
		- 従来の機械学習システムを代替していく流れが起きている
		- 個人の好みにパーソナライズするような設計が人気を集めている 
	- ■セキュリティ対策を強化する
		- 敵対的攻撃からモデルを守るのが重要になっている
		- 倫理的な懸念やバイアスに対処するための研究も活発化している 
		- 機密情報を責任を持って扱うように努力されている
- 実践！大規模言語モデル / 1000億パラメータ越えモデルを動かすには？
	- https://zenn.dev/turing_motors/articles/26e1f1be50c0b5
	- BLOOM-1Bを動かしてみる
		- 10億パラメータ数程度のモデルであれば、GPUメモリが12GB以上のGPUであれば推論することが可能です。Google Colaboratoryで提供されているGPUインスタンスで動かすことができます
	- BLOOM-176Bを動かしてみる？
		- では実際1000億パラメータを超えるBLOOMを動かすにはどうすればいいでしょうか？
		- 単純な解決策として、その大規模モデルが乗る計算環境を構築することができますが、もしそのレベルのスペックをオンプレミスのサーバーで整える場合は数千万円規模になってしまいます。また、AWSやGCPなどのクラウドコンピューティングサービスで大規模実験環境を整えることもできます。
		- 例えば、AWSのEC2 P4dインスタンスであれば8枚のA100のGPUメモリが計320GBと640GBの環境を1時間あたり30~40ドル程度で扱うことができます。
- RAG Fusionが思ってたより凄そう
	- https://zenn.dev/ozro/articles/abfdadd0bfdd7a
	- RAG Fusionは単なる「新たな手法」ではなく「革新的な手法」です。  
	- RAG Fusionは、従来の検索技術の制約を克服し、ユーザーのクエリに対してより豊かで文脈に即した結果を生成するために、RAG、Reciprocal Rank Fusion、生成されたクエリを組み合わせた新しいシステムになっています。  
	- このシステムは、検索結果のリランキングと複数のユーザークエリ生成により、検索の正確性とユーザーの意図との一致を向上させることを目指した手法となっていま
- Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning
	- https://huggingface.co/papers/2402.06619
	- 合計で114言語をカバーする5億1300万ペアのプロンプトと補完文を含んでおり、Apache 2.0ライセンスとの事
-  LlamaIndex v0.10 の概要 by npakaさん
	- https://note.com/npaka/n/nb8acc1f63312?sub_rt=share_h
	- 「**LlamaIndex v0.10**」は、過去最大のアップデート
	- 「ServiceContext」を非推奨にして、「LlamaIndex」の開発者エクスペリエンスを向上させます。
	- 時間が経つにつれて、このオブジェクトは使いにくくなりました。 service_context コンテナ全体を任意のモジュールに渡すと、どのコンポーネントが実際に使用されているかを推論するのが困難になりました。 すべてのモジュールがデフォルトで OpenAI を使用するため、ユーザーはローカルモデルを使用したい場合でも、不必要にOpenAIキーを指定するように求められていました。 インポートして入力するのも大変でした
-  LongMamba
	- https://github.com/jzhang38/LongMamba
	- We present LongMamba, an early exploration of Mamba's **longer context extrapolation ability**. Our #LongMamba manages to retrieve *nearly perfectly* on a window context of 16384
- AutoMathText: A 200GB dataset of mathematical texts open sourced
	- https://huggingface.co/papers/2402.07625
	- Multi-source : arXiv/programming code/web pages  
	- Filtered and processed to adapte Math reasoning  
	- Selected by Qwen 72B
-  科学者がChatGPTを利用してデータから論文を生成 by nature
	- https://www.natureasia.com/ja-jp/ndigest/v20/n10/%E7%A7%91%E5%AD%A6%E8%80%85%E3%81%8CChatGPT%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8B%E3%82%89%E8%AB%96%E6%96%87%E3%82%92%E7%94%9F%E6%88%90/122873
	- Nature Japanから生成AIで論文を書いた際の実証結果と限界
	- テクニオン・イスラエル工科大学（ハイファ）の生物学者でデータサイエンティストであるRoy Kishonyらは独自の自律的なdata to paperシステムを構築し検証。
		- 1時間足らずで研究論文作成 
		- 文章は流暢で洞察に富む
		- 厳密なデータ分析にも基づく としたが、
		- 論文でよく使われる表現で誤魔化す 
		- P値ハッキング（P hacking）
		- 論文生成が簡単になり質の悪い論文が増加するリスク など懸念点を挙げた。
- Code-Llama-70B-FW is now available on Poe! H
	- https://x.com/poe_platform/status/1757080840012804511?s=20
-  音声入出力でLLM on Google Colab
	- https://colab.research.google.com/drive/1WCiUth855jXjzaNh8Ap5lFLEGX8aMtiU
	- マイク入力→音声認識(Faster Whisper)→LLM回答生成(ELYZA)→音声合成(Style-Bert-VITS2)→再生
	- Google Colabの無料枠で動く 音声認識(Whisper)→LLM(Swallow-13B)→音声合成(Style-Bert-VITS2) を作ってみました。音声合成は事前に学習モデルの作成が必要ですが、押しのキャラ音声と会話できると楽しいかも。(LLMを13Bにしたので回答生成に1分くらい掛かります)
- RAG From Scratch: Query Translation (Multi-Query)
	- https://x.com/LangChainAI/status/1757817056865718432?s=20
-  Masked Audio Generation using a Single Non-Autoregressive Transformer
	- https://arxiv.org/abs/2401.04577?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=thread
	- Researchers at Meta recently shared MAGNeT, a single non-autoregressive transformer model for text-to-music & text-to-sound generation capable of generating audio on-par with the quality of SOTA models — at 7x the speed.
	- https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT/?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=video
- Nomic Embed v1.5
	- Nomic Embed v1.5 is out, the first open model with variable-sized Matryoshka embeddings and 8192 context!
	- https://huggingface.co/spaces/Xenova/adaptive-retrieval-web
-  LLM Agents
	- https://www.promptingguide.ai/research/llm-agents
-  Mixtures of Experts Unlock Parameter Scaling for Deep RL
	- https://huggingface.co/papers/2402.08609
	- Google Deepmind presents Mixtures of Experts Unlock Parameter Scaling for Deep RL
-  Google Colabでの日本語Mambaの事前学習
	- https://note.com/hatti8/n/na9782b7fa437?sub_rt=share_pb
	- 日本語モデルがないので、日本語Mambaの事前学習のコードを作成しました。Google colabで動くことは確認したもののA100(40B)でも**15時間近くかかるので実質最後までは実行できないです。**
-  GraphRAG: Unlocking LLM discovery on narrative private data by Microsoft
	- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/
	- Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q&A when analyzing complex information and consistently outperforming baseline RAG
-  In-Context Language Learning: Architectures and Algorithms
	- https://arxiv.org/abs/2401.12973
	- Transformer の代替としての Mamba 含む SSMs や他の subquadratic なアーキテクチャ (e.g, RetNet, RKWV) を「入力に依存した推論を許すか」・「線形/非線形か」で整理するとめちゃくちゃ見通しが良くなる．
- OpenAIがMicrosoftと強力し国家関連の脅威アクターによるAIの悪意あるサイバー活動に関する利用をしていたアカウントを停止。
	- https://x.com/bioshok3/status/1757834888705945971?s=20
- Open AI 動画生成AI 『Sora』をリリース
	- https://openai.com/sora
	- Googleが切り札的に電撃公開したGemini 1.5の数時間後に、OpenAIが世界の話題を掻っ攫うレベルの動画生成AIのSoraをぶつけてきた
- META がVideo Joint Embedding Predictive Architecture (V-JEPA) モデルをCC BY-NC ライセンスの下で一般公開
	- https://x.com/bioshok3/status/1758182170135576590?s=20
	- V-JEPA は、抽象表現空間内のビデオの欠落部分またはマスクされた部分を予測することによって学習する非生成モデル
-  LangChain v0.1 クイックスタートガイド - Python版  by npakaさん
	- https://note.com/npaka/n/n1d771995c3aa?sub_rt=share_h
	- **v0.1** ではlangchainパッケージが次の3つのパッケージに分割されました。すべて**下位互換性のある方法**で行われました
- 軽量・高速・高性能と三拍子揃った日本語対応のAI(Orion-14B)で指示データセットを自動生成するメモ
	- https://note.com/kan_hatakeyama/n/n0c58733b39bd?sub_rt=share_pb
	- shi3zさんの、「Orion14B-ChatとWikipediaデータセットを使って日本語マルチターン会話データセットを作りました」を参考にして
	- Yahoo!知恵袋の質疑からデータを作ってみます
		- と、わりといい感じでした。
	- ローカルな大規模言語モデルでも、それなりに高品質なデータ合成ができる時代がやってきたようです。今後はいい感じに(公開)データセットを作っていきたいと思います。
- Corrective RAG with LangGraph
	- https://github.com/langchain-ai/langgraph/tree/main/examples/rag
	- We’ve just implemented 4 new notebooks outlining different RAG and CRAG techniques in LangChainAI　PY & JS! These show off different RAG flows, using OSS and hosted LLMs. See the links below for the notebooks:
-  【Gemini 1.5 Pro】100万トークン入力できる最強LLMの性能をGPT-4と比較してみた
	- https://weel.co.jp/media/gemini-1-5-pro
	- ● 性能テストで先代の大型モデル・Ultra 1.0と互角  
		- 性能比較全32項目のうち30項目で、GPT-4に勝利
		- 理数&人文全57科目の問題集「MMLU」にて専門家に勝利
	- ● Transformerの進化系、MoEアーキテクチャを搭載 
	- ● LLM史上最大、100万トークンもの入力に対応
		- MoEアーキテクチャを採用した結果、Gemini 1.5 Proでは入力できるトークン数が大幅にUP！一回に100万トークンの入力が実現しました。
- 教科書：確率過程
	- 確率過程に興味があるB4・M1が読むべき教科書について説明する．
	- [速習版](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/04/stochasticProcessShort.pdf)
	-  [詳細版](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/10/StochasticProcess2023_long.pdf)
- 【AI動画生成】Sora 要素技術解説
	- https://zenn.dev/mattyamonaca/articles/e234e57834d7ad
	- すごく簡単にまとめると以下の4つの要素が主軸です
		- 動画データを潜在空間に圧縮した後、Transformerがトークンとして利用できる「時空潜在パッチ」に変換する技術
		- Transoformerベースのビデオ拡散モデル
		- DALLE3を用いた高精度なビデオキャプショニングによるデータセット作成
	- こうして要素要素を見ていくと特段新しい技術を使っているわけではなく、今まで有効とされた技術を愚直に積み重ね、莫大な資本力と計算力でモデルを訓練すれば強いモデルが作れるという、当たり前の結果が見えてきます。
-  ChatGPTを社内に配ってもあまり使われない本当の理由
	- https://qiita.com/jw-automation/items/cf8ffc7a0edab512d917
	- 社内情報というコンテキストが必要な業務がほとんどである人達に、素のChatGPTを配っても、特に使える所がないというのはいわば当たり前の話です。
- Build Knowledge Graph From TextData using LangChain
	- https://medium.com/@mahimairaja/build-knowledge-graph-from-textdata-using-langchain-under-2min-ce0d0d0e44e8
	- Converting text to knowledge graphs can be helpful for both visualizing the data and allowing for structured querying later on 
	- This blog goes through how to use LLMs to extract knowledge triplets
-  minbpe
	- https://github.com/karpathy/minbpe
	- Minimal, clean, educational code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization."
-  Video generation models as world simulators by OpenAI
	- https://openai.com/research/video-generation-models-as-world-simulators
	- SoraはTransformerベースの潜在拡散モデルで、テキスト指示から1分間の高画質動画を生成できる。時間・空間の両方で一貫性を維持でき、現実の物理法則をある程度反映させることができる。モデルやデータに関する詳細は非公開だが、大規模化により性能が上がる模様。
	- 今後やるべき事はおそらく単純で、全力でOpenAIやGeminiの成長にしがみ付けば良いのでは。という気がしている。 by 元木
	- https://x.com/ai_syacho/status/1758845719988117759?s=20
	- 彼らは拡散トランスフォーマーモデルという、マシンと札束を入れれば入れるほど能力の上がるAIを持っていて、その資金体力も段違い。…
- iPhoneにGeminiきてた
	- https://x.com/npaka123/status/1758656487399014521?s=20
	- ?? Advance???
- Ollama で Elyza-7B を試す by npakaさん
	- https://note.com/npaka/n/ndadbae6c6be5?sub_rt=share_h
	- 「Ollama」の日本語表示が改善されたとのことなので、「Elyza-7B」で試してみました
	- Ollamaのサイトに載っていないモデルは、自分で「**Modelfile**」を作成して、追加する必要があります。
	- 「Llama2」のManifestを参考にさせてもらいます
	- 今回は、「**ELYZA-japanese-Llama-2-7b-instruct-q4_K_M.gguf**」をダウンロードします。
- Lecun先生、soar発表直前に、テキストからリアルなビデオを生成するのは当面先だと講演したことに対して言い訳を。。。
	- https://x.com/ylecun/status/1758740106955952191?s=20
	- いや世界モデルを持つのがむつかしいというのが真意である。。。
	- きっと過ちは繰り返す。
- soraの生成した画像についての分析が進む
	- https://x.com/anand_bhattad/status/1758632768597328202?s=20
	- こいつ射影幾何わかってないよね？
	- DALE3と同じ画像じゃん等
- 

## 2/13

今週は、ほぼ予定通り（１日おくれ？）BardがGemini（ジェマナイと読む）に改名された。一方、新たにGemini Advancedという名前でGemini Ultraが有償でスタート。何気ないファミマの写真から画像から認識した情報片をつなげて店舗を特定したりと、コナン君なみの推理をしているのが何気にすごい。OSSのLLMでは、アリババのQwen1.5がリリースされたのが最大の話題、75B-chatのデモなどでもGPT-4に迫る性能を示すと評判、Huggingfaceのデモ試すとたしかにレべチかも。基本性能が高いのか、0.5BをTransfomer.jsで使った例でもそれなりの性能がでるという話。早速、量子化とか、Ollamaの対応が発表されたりされてる。たぶん、日本語LLMもrinna当たりからQwen-1.5ベースの日本語LLMの発表が続くと思うぞ。Style-Bert-VITS2、なんて自然な日本語を話すんだ、コンテキストを考慮した話しっぷりにびっくり、どこかの職業が丸ごとなくなる性能だ。 Open AIは、ソフトウエアの間をつないでタスクをこなすエージェントの開発を宣言、これってAppleScriptとかPowerShellのスクリプトを自動生成するみたいな話だから、Microsoftとも連携してるんだろうけど、RPA（すでに死語？）にとどめを刺すだろうな。「小さなLLM」、英語でも"Smaller LLM"と呼ばれるらしい、小さなLLMでいいんだな、LLMのLargeはモデルの大小ではないとうこと、評価によるとFlan-T5がぶっちぎり？ MoE関係では、Mixtral-8x7Bの日本語向けのLoRaとか、MoEを単純化してExpertの切り替えを試してみる例とか面白い。基盤面では、探索なしでTransfomerだけでチェスマスタークラスのＡＩが作れるらしい。一方、Transformerの次世代基盤の一つとされるMamba、日本語での詳細な解説や、MoEでもあるBlackMambaとか、いろいろ出てきたな。理論面では、岡野さんの解説、The Consensus Game、RAGの改良を生成AIと識別AIの間のゲームとしてとらえるとは。NVIDIAも自らcanary-1bとか、Audio Flamingoとか音声や対話関係のモデルをリリース、自動運転では運転手との対話が必要なのはそのとおりなんだろう。RAG関係も、Self RAGとか、Guardrailsとか、GPT-4と組みあせた医療分野での評価とかいろいろ進んでいるが、評価フレームワークのragas 0.1がでたのは大きい。日本語LLMも、日本語のデータセットの整理や「LLM-jp 13B v1.1」のリリースとか着実に進んでいるのが心強い、はよNEDOの成果を！。知識グラフとのLLMの融合、Wikidata とかロードマップとか、Research Insightとか話題は続いている。

-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Next to RoBERTa, FLAN-T5 is also a great go-to model for training text classifiers
	- Flan-T5頑張るなあ
-  大規模言語モデルが科学的発見に与える影響：GPT-4を用いた予備的研究
	- https://ai-scholar.tech/articles/large-language-models/impact_of_LLM
	- GPT-4は科学的発見活動にも大きく寄与しつつあります。  
	- 創薬、生物学、計算化学、材料設計、偏微分方程式と幅広く、GPT-4の応用が紹介されています。また、それぞれの応用でのテクニックを紹介しています。  
	- 現時点でのGPT-4を用いるうえでの不足点を整理し、将来への展望をまとめています。
	- 知見
		- 全体的に言えば、GPT-4は創薬の全プロセスと個々のステップに関する知識を持っています。
		- GPT-4は逆合成の予測精度が20.
		- GPT-4が創薬におけるデータ処理のための正しいスクリプトを生成するのに役立つ
		- 定量計算： GPT-4は生物学的な言語理解と処理に優れていますが、定量的な計算には限界があります。信頼できる結論を得るためには、手動で検証するか、別の計算ツールで検証することをお勧めします
- Qwen2-14BのMTBenchが7.99でClaude-1超えてるのはマジやばい by うみゆき
	- https://x.com/umiyuki_ai/status/1754435534511050870?s=20
	- Qwen2としてウワサになってたモデルがQwen1.5としてリリースされた！Mistral-Mediumに匹敵する性能がオープンソースで！今回は最初からTransformerで使える上に、AWQモデル、GPTQモデル、GGUFも全部公式で最初からリリース！vLLMやOllamaもOK！
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- We have finalized our 𝐋𝐋𝐌𝐬 𝐨𝐧 𝐆𝐫𝐚𝐩𝐡𝐬 survey by adding more insightful discussions. If you are interested in LLMs on structure data, don't miss this paper (with a resource repo)!
- Home Credit - Credit Risk Model Stability
	- https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/
	- Kaggle新コンペ クレジットカード利用者の外部及び内部データによる長期の貸倒れ予測タスク。久方ぶりの正統派テーブルデータコンペ
- Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
	- Nvidia presents Audio Flamingo
	- https://huggingface.co/papers/2402.01831
-  A Survey of Constraint Formulations in Safe Reinforcement Learning
	- https://arxiv.org/abs/2402.02025
	- 強化学習における安全性制約の記述方法に関するサーベイ論文を arXiv にて公開しました 。主要な定式化の理論的な関係性を議論しているのが面白いと思います
-  BlackMamba: Mixture of Experts for State-Space Models
	- https://huggingface.co/papers/2402.01771
- 英国AI Safety Instituteより3rd Progress Repoert。
	- https://www.gov.uk/government/publications/uk-ai-safety-institute-third-progress-report/ai-safety-institute-third-progress-report
	- Google DeepMindのGeoffrey Irving氏、Oxford大の神経科学者Chris Summerfield氏参画。コアKPIの「メンバーの、先端AIモデルに関する累積経験年数」が11月の150年から168年に増加。
-  Stable Diffusion WebUI Forge
	- https://github.com/lllyasviel/stable-diffusion-webui-forge
	- Stable-Diffusion-WebUI-Forge is a new platform to 
		- (1) completely solve the speed and VRAM problem and 
		- (2) adding UNet Patcher System to webui so that many new features can be implemented in about 100 lines of codes
-  Unifying Large Language Models and Knowledge Graphs: A Roadmap
	- https://arxiv.org/abs/2306.08302v3
	- この Knowledge Graph とLLMの関係について纏めた論文すごい。 
	- Knowledge GraphとLLMが相互成長する仕組みが非常に分かりやすくフレームワーク化して纏められている。 論文というより現状の整理に近い
-  Wikidata from LangChain
	- https://python.langchain.com/docs/integrations/tools/wikidata
	- WikiData allows you to easily connect to a free and open knowledge base
-  Qwen1.5
	- https://qwenlm.github.io/blog/qwen1.5/
	- https://huggingface.co/collections/Qwen/qwen15-65c0a2f577b1ecb76d786524
	- Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.
- OllamaでもQwin1.5をサポート
	- https://ollama.com/library/qwen
-  Repeat After Me: Transformers are Better than State Space Models at Copying
	- https://arxiv.org/abs/2402.01032
	- Our recent work on the comparison between Transformers and State Space Models for sequence modeling now on arxiv! TLDR - we find a key disadvantage of SSMs compared to Transformers: they cannot copy from their input
-  Self RAG
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/self_rag/self_rag.ipynb
	- We’re excited to feature Self-RAG, a special RAG technique where an LLM can do self-reflection for dynamic retrieval, critique, and generation
- The Majority of AI Compute Spend is Not on Training but on Inference
	- https://x.com/rohanpaul_ai/status/1754843805507887477?s=20
	- As per report - "2023: The State of Generative AI in the Enterprise"
- Qwen1.5-0.5B-chat with Transformer.js
	- Qwen1.5 is out: a collection of powerful LLMs with sizes ranging from 0.5B to 72B parameters.
	- https://x.com/xenovacom/status/1754873501536645292?s=20
	- Even at 8-bit quantization, the smallest one (0.5B) is surprisingly good for its size! Here's a demo I made with Transformers.js (v2.15), running 100% locally in the browser w/ WASM!
	- https://github.com/xenova/transformers.js	
- Gradio demo of Qwen1.5-72B-Chat
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ollamaでMixtralを動かしてLangChainのagentで neo4jする
	- Managed to get Mixtral on @ollama working as an function calling @LangChainAI agent that interacts with @neo4j  through a semantic layer. Needs some tidying up and I'll be able to share it.
	- https://x.com/tb_tomaz/status/1754861855929958488?s=20
- Style-Bert-VITS2が即座に日本語特化モデル JP-Extraを取り込んでくれて、日本語発音がエグいです
	- https://github.com/litagin02/Style-Bert-VITS2/releases/tag/2.0
	- 「Style-Bert-VITS2」は、自動で文脈が把握され、感情表現が調整される
	- https://huggingface.co/spaces/litagin/Style-Bert-VITS2-JVNV
	- いやこれはすごい
- NVIDIAがデータセンター向けGPU市場で98％のシェアを独占していることが判明、AI性能が明暗を分ける結果に - GIGAZINE
	- https://gigazine.net/news/20240205-nvidia-gpu-market/
- だめ。絶対。 by キムワイプ
	- https://x.com/kimwipes_crecia/status/1754757418595336404?s=20
-  OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models
	- https://huggingface.co/papers/2402.01739
	- To help the open-source community have a better understanding of Mixture-of-Experts (MoE) based large language models (LLMs), we train and release OpenMoE,
- Development and Testing of Retrieval Augmented Generation in Large Language Models - A Case Study Report
	- https://arxiv.org/abs/2402.01733
	- GPT-4にRAG（検索拡張生成）を適用することで、臨床医学の問題において、人間の医師よりも高い精度が達成できたと報告
	- 適切なRAGシステム設計により、GPT-4単体よりも10%以上精度が向上し、人間医師よりも5%以上高いスコアを出
	- 研究者らはこの結果は注目に値するとしつつ、より広範な分野で実験を重ねていくべきとしています。 
	- また、ハルシネーションが低いとはいえ、医学における自動化は慎重であるべきとも述べています。
- Open AI shifts its battleground to Software
	- https://x.com/bioshok3/status/1755376649816953209?s=20
	- Open AIは現在2種類のエージェントAIを構築中
	- 1つはわりと自由にデバイスを操作可能なエージェント 
		- 顧客は ChatGPT エージェントに、分析のためにドキュメントからスプレッドシートにデータを転送したり、経費報告書を自動的に記入して会計ソフトウェアに入力したりするよう依頼できます
	- もう一つはWEB上で様々な操作可能なエージェント （1つ目はセキュリティやプライバシー懸念する人もいるのでもう一つのタイプを開発しているとのこと）
- Fully local RAG using @Teknium1 OpenHermes, @ollama and @streamlit
	- GPT4 level performance at 0% of the cost
	- https://github.com/phidatahq/phidata/tree/main/cookbook/local_rag
- 海外高性能言語モデルの日本語化研究の一環としてMixtral-8x7Bの日本語出力を安定させるLora作成、公開   
	- https://huggingface.co/aixsatoshi/Mixtral-8x7B-ja-Lora-sft-ChatbotArenaJAcalm2
	- Mixtral-8x7Bは高性能な言語モデルですが、日本語出力に多言語が混入するcode-switchingがよく見られます。 元の性能を維持しながら、日本語生成を安定させる方法として、Loraの効果を検証しました
	- 日本語が流暢なcalm2の合成データセットを利用してます Baseモデルより低パラメーターの言語モデルで作成したデータセットでも、一定の性能確保して日本語化できました
-  Apple Vision ProはHoloLensの完成形。現時点での限界値 by shi3zさん
	- https://note.com/shi3zblog/n/nd36c04f9133a?sub_rt=share_h
	- 「ついにここまで来たか」
-  Step-wise Queries by llamaindes
	- https://docs.llamaindex.ai/en/stable/examples/agent/custom_agent.html#step-wise-queries
	- In our brand-new cookbook, learn how to build a custom agent that can execute complex queries over your data, and can also be interrupted in the middle of execution with user inputs!
- Ollama OpenAI compatibility is here!
	- https://ollama.com/blog/openai-compatibility
	- つまり、ollamaでopenaiのAPIつかってURLをollamaエンドポイントに変えるだけで動くということ
-  RAG Research Insights
	- https://www.promptingguide.ai/research/rag#rag-research-insights
	- So we have created a new section in the RAG overview to summarize and help you keep track of insights into the latest RAG techniques.
- Nvidia releases canary-1b
	- https://huggingface.co/spaces/nvidia/canary-1b
	- With 1 billion parameters, Canary-1B supports automatic speech-to-text recognition (ASR) in 4 languages (English, German, French, Spanish) and translation from English to German/French/Spanish and from…
- Bard は Gemini（ジェミニ）になります！
	- https://x.com/googlejapan/status/1755607418103587148?s=20
	- Gemini は Bard に搭載されている AI モデルですが、この高度なテクノロジーが反映されていることをわかりやすく伝えるために、名前を変えました
	- https://gemini.google.com/app
- The Consensus Game: Language Model Generation via Equilibrium Search by 岡野さん
	- https://openreview.net/forum?id=n9xeGcI4Yg
	- LLMで質問応答等のタスクをこなす場合、生成的に解く場合（p(y|x,v=真)) と識別的に解く場合（p(v=真|x, y)）で得意/不得意が異なり結果が異なる。ゲーム理論に基づいて二つが合意する解を求められる均衡順位付けを提案。多くのタスクで再学習なく、性能を大きく改善できる
- OpenAnimateAnyone
	- https://github.com/fenghan0430/Open-AnimateAnyone
	- アリババはAIの研究結果をオープンで出してくれてたけど、いざAnimateAnyoneみたいな有望な成果物ができたらスッとクローズにしてシュッと自社アプリに組み込む。つまり今までは自社サービスには使えんクオリティだから不用品リサイクルとしてオープンにしてただけ？
-  Grandmaster-Level Chess Without Search
	- https://arxiv.org/abs/2402.04494
	- チェスでどの手が良いかをTransformerで教師あり学習したモデルは探索を使わなくても人より強くなる（探索ありAIよりは弱い）。教師ありデータはStockfish 16で作成しており、科学分野でよく使われるサロゲートモデルの一種とみなせる。
- ragas 0.1 release
	- https://github.com/explodinggradients/ragas
	- We are releasing version 0.1 of Ragas today, the open-source standard for evaluating RAG applications.
-  Perplexityをもとに､複数の大規模言語モデルを切り替えて推論するシステムの簡単なコード実装
	- https://note.com/kan_hatakeyama/n/nb5625d6411a8?sub_rt=share_pb
	- モデルを統合するための簡単な実装コードを書いてみます。  最近は､普通にmergekitもあるようですが､勉強も兼ねた実装です
	- 与えられた入力文章に対するPerplexity（困惑さ）を指標に、使用するモデルを切り替えるシステムを作ります
	- 今回は試しに、英語が得意なLLama2-7bと、日本語でファインチューニングしたElyza-7bを統合（merge）したシステムを作ってみようと思います。
- 日本語データセットのクリーニングスクリプト
	- https://github.com/lighttransport/japanese-llama-experiment
-  Real-World Robot Applications of Foundation Models: A Review
	- https://arxiv.org/abs/2402.05741
	- 基盤モデルの実ロボット応用に関するサーベイ論文を公開しました！Meta AI ResearchのChrisさん@chris_j_paxton , Google DeepmindのAndyさん @andyzeng_ という，この分野で最先端を進むお二人からのフィードバックを受けながら執筆
-  OpenAIアルトマン氏、半導体の資金調達で交渉　米報道
	- https://www.nikkei.com/article/DGXZQOGN095R00Z00C24A2000000/
	- 必要資金750兆円
-  Multilingual E5 Text Embeddings: A Technical Report
	- https://huggingface.co/papers/2402.05672
	- MicrosoftのE5エンベディングの実装ペーパー、今頃でるものなのか・
- Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents
	- https://github.com/yifanlu0227/ChatSim
	- 生成AIの出現でシミュレータの世界も大きく変化。 昨日出たChatSimでは自然言語を入力してドライビングシミュレータを自由に編集することができる
-  LangChain 101: Part 3a. Talking to Documents: Load, Split, and simple RAG with LCEL
	- https://pub.towardsai.net/langchain-101-part-3a-talking-to-documents-load-split-and-simple-rag-with-lcel-26b005ccb30a
	- Loading documents and splitting them are a key part of RAG
- mambaの理論を理解する①：HiPPOフレームワークとLSSL
	- https://zenn.dev/izmyon/articles/8374a11d272602
	- mambaの理論を理解するための解説記事を書き始めました。かなり数式の導出など丁寧に書いてるのでよろしくお願いいたします。何か訂正や補足があれば優しく教えてくださ
-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Can "small" finetuned LLMs with less than 2B parameters outperform larger openly available LLMs (Mixtral, Llama 2 Chat) and proprietary LLMs (ChatGPT)? Here's a closer look at the Tiny Titans paper
	- Flan-T5が最強らしい、
-  GPTは他者の心の状態を推測できる？AI×心理学のすゝめ
	- https://ai-scholar.tech/articles/computation-and-language/Theory-of-Mind
	- GPTは他者の心を読めるのか？ 実験において、GPT-3.5とGPT-4は高い正答率をマークしました。 
	- 著者は、GPTが心の状態を推測できる理由として「言語能力の向上によって自発的に出現したのでは」と指摘。 AI研究における心理学的な視点の重要性を解
- In-Context Principle Learning from Mistakes
	- https://arxiv.org/abs/2402.05403
	- LLMに敢えて間違わせてルールを覚えさせ同じミスを避けるようにする新しいプロンプト手法が提案されています。
	- ■新アプローチ 
		- 1. モデルが間違いを犯すように促す 
		- 2. モデル自身に、間違いに対する説明を生成させ、まずは低レベルの原則を形成。 
		- 3. 低レベルの原則をまとめ、約5つのキーポイントに圧縮して高レベルの原則を生成 
		- 4. 高レベルの原則を未見の例に対する応答を生成する際に利用 
	- ■実験と結果 実験と結果の要約: 
		- GPT-3.5-TurboとGPT-4の質問応答性能が一貫して改善され、GPT-4が7.5%の改善を見せた
		- 数学推論タスクでもGPT-3.5-turboとGPT-4で基準を上回る結果を示した
		- Big-Bench Hardタスクでもスコアが一定程度上昇した
- Step-by-step guide to build AI agents for structured and unstructured data.
	- https://x.com/Saboo_Shubham_/status/1756123156400546251?s=20
	- Step 1: Define the Chunking Strategy
	- Step 2: Apply an Embedding Strategy
	- Step 3: Implement a Document Retriever for Text
	- Step 4: Use a Large Language Model (LLM)
	- Step 5: Extract Metadata
	- Step 6: Implement a Document Retriever for Metadata
	- Step 7: Integrate SQL Querying with a Data Warehouse
	- Step 8: Develop a Prompt Refinement Engine
	- Step 9: Create a Response Post-processor
	- Step 10: Deliver the Response
- Buffer Overflow in Mixture of Experts
	- https://arxiv.org/abs/2402.05526
	- "Mixture of Experts (MoE) has become a key ingredient for scaling large foundation models while keeping inference costs steady. We show that expert routing strategies that have cross-batch dependencies are vulnerable to attacks. Malicious
- WolframEngine+JupyterNotebookで疑似Mathematica
	- https://x.com/blkcatman/status/1756219896026067052?s=20
- 【Mamba】Transformerを凌駕しうるアーキテクチャを徹底解説（ソースコードあり）
	- https://qiita.com/peony_snow/items/649ecb307cd3b5c10aa7
	- １．MambaはAttentionやMLPBlockを持たない簡素化されたアーキテクチャを有します。選択的状態空間モデル（Selective SSM：Selective State Space Model）という新しい構造を用いることで、必要な情報のみに注目し、計算効率の大幅な向上を達成しています。
	- ２．高速な推論（Transformerの約5倍）を可能にするとともに、シーケンス長（トークン数などのこと）の増大に対して、推論コストが線形に増大するという特徴を有します（これまでのモデルでは非線形的な増大がありました）。この性能向上は実データにおける検証で、シーケンス長が1000k（１００万）においてまで確認されました。
	- ３．GPUメモリ階層間の移動を最小限化するとともに、ハードウェアに最適化された並列アルゴリズムにより高速な計算が可能になり、要求されるメモリ容量も軽減されます
	- ４．パラメータ数2.8B以上の場合においてMambaは機能するのか、ハイパーパラメータのチューニング方法はTransformerなどと同じなのか、学習の不安定性はどうなのかといった点に関してはまだ不明であり、今後の研究が待たれます。
	- ５．まだ不明な点も多いですが、様々な角度からの研究によって、Transformerを代替しうる有望なアーキテクチャであるというエビデンスも取得されつつあり、今後Mambaを知らなければ最先端の研究から取り残される可能性があります。
-  栗田工業、機械学習使った材料探索で低環境負荷の防食剤開発へ
	- https://xtech.nikkei.com/atcl/nxt/news/24/00208/?n_cid=nbpnxt_twbn
	- 栗田工業さんらは冷却水の防食剤の開発のため、機械学習により数百万の分子から有望材料を抽出
- NeMo Guardrails, the Ultimate Open-Source LLM Security Toolkit
	- https://towardsdatascience.com/nemo-guardrails-the-ultimate-open-source-llm-security-toolkit-0a34648713ef
	- Advanced RAG with Guardrails
	- If you want to build user-facing RAG, you not only need to setup advanced retrieval, but also need to apply requisite layers of input/output filters for the following:
- pandas-ai
	- https://github.com/gventuri/pandas-ai
	- 機能としてはpandasのデータフレームに対して直接自然言語で処理できるようにしたもので、軽く見た感じアルゴリズム的に新しいものはなさそうなもののhttp://df.chat(プロンプト)という形式での操作は斬新
- LLM-jp 13B v1.1リリース
	- https://llm-jp.nii.ac.jp/blog/2024/02/09/v1.1-tuning.html
	- 各種チューニングですごい流暢になってる。学習詳細も公開されてて参考になる。
- The biggest Collection of Colab Based LLMs Fine tuning Notebooks
	- https://github.com/ashishpatel26/LLM-Finetuning
-  Google Colab で LLM-jp 13B v1.1 を試す by nakaさん
	- https://note.com/npaka/n/n2c272727d95a?sub_rt=share_h
	- 「LLM-jp 13B v1.1」は、「LLM-jp 13B」の最新版です。日英両データセットによるSFT、ichikaraデータセットの追加+DPOで対話応答性能が向上しています。
- OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models
	- https://arxiv.org/abs/2402.06044
	- A wild Theory of Mind Benchmark has appeared:
- 



## 2/5

今週も盛りだくさん。まずは、MetaのCodeLlamaの70B版リリース。早速SQLの変換SQLCoder-70Bがリリースされたり、4bit化されてMLX経由でMacで動かしたりと一気ににぎやかに。Metaは、35万個の H100を整備し、OSSの基盤モデルに取り組むということで、株価は20%アップ。一方Googleは、BardのbackendのGemini Proの国際対応をリリース。日本語なんかまだ変（例、バイクを自転車と認知）ですが、画像認識機能などGemini Proを手元で試せる。OSS版のマルチモーダルLLM代表的なLLaVA-1.6がリリースされ、Gemini Pro越えとの評価も。LLMの軽量化の新星SliceGPT、軽くて精度が落ちないのは大歓迎。miqu-70BというMixtral 8x7Bの量子化版らしきものが、EQ-benchで突然上位に登場、次の大きなリリースの斥候か、なおmiqueってミクだったのか？。Phixtralの論文で紹介されたMoEの実装、本家とはアルゴリズムが違うみたいだがMoEの実装にもいろいろあるものだ。ICRA2024での採択論文・技術の話題もちらほら。国産LLMでは、700億パラメーターLLM「KARAKURI LM」が登場、Llama 2を日本語データセットで事前学習、ファインチューニングしたらしいがやたら性能が高いと話題に。gguf版や、MLXをつかってM2 Macでの動作確認等が行われ、これは基礎能力が高そう。小さき言語モデルも、Allen.AIのOLMoや、Kaggle関連のH2O-Danube-1.8Bなどが登場。RAG関係だと、またファインチューニングとの比較論文、どうもまだＲＡＧのほうが利がある。クエリ変換ってのも重要な技術。しかし、赤ちゃんの頭にビデオを装着して得られた61 時間分の画像から、マルチモーダル言語モデルをつくるという途方もない研究にはびっくりした。Hugging FaceがGPT Storeのオープンソース版（Assistant）を開始、Googleとの提携でリソースが強化された？。東京藝大の卒業展示に“AIアニメ”が出たことが話題になったが、Making情報を見ると、じつは相当ＬＬＭを使いこなしていて、シナリオのChatGPTでの作成ログ等、アプローチが参考になるという話に。Googleのあらゆる時系列データをDecoder-onlyのモデルにぶっ込んで時系列予測の基盤モデル作る話、長期時系列予測でどうしてそんなに性能が高いのか、気象予測にも適用するのか？。NEDOの国内生成AIの基盤モデル開発支援、さすがと思われる会社や研究機関が並ぶ。参加機関の１つNIIでは、国会図書館のもつ国内のウェブサイトのアーカイブ事業の成果が活用されるということだ。一方民間ではRicor-13BのようなカスタマイズしたLLM提供ビジネスもはじまった。材料系の研究へのLLMの応用も着実に進む。ローカルLLM実行環境ももollamaがvision対応とか、function call対応とか着実に進んでる。さて来週も、Gemini Ultra が2/7にリリースとのうわさもあり、人型ロボットスタートアップFigureに出資したMicrosoft/OpenAIの次の手や、Vison Proを出したAppleのＡＩ戦略も気になるところ。

- google/siglip-base-patch16-256-multilingual を使って、ローカルの画像を日本語で検索してみる
	- https://note.com/eurekachan/n/n9d4f62b80ad6?sub_rt=share_pb
	- 1月に、Googleから、SigLIPという、画像とテキストの両方をベクトルとして扱うことができるモデルのmultilingual版（多言語対応版）が公開されました。transformers 4.37以降で対応しています。日本語も対応しています。
	- CUDAを使いましたが、GPUへの負荷も低かったので、案外CPUでも動かせるかもしれません。
-  Are Transformers Effective for Time Series Forecasting?
	- decisively highlighting the shortcomings and deficiencies in research surrounding the use of transformers for
	- This paper effectively exposes the deceptive practices employed by various authors in their papers, such as inadequate benchmarking and other tactics, which have previously led to inflated claims regarding the performance of transformers in this domain.
- Googleなど米IT、1月1万人削減　組織スリム化でAI集中
	- https://www.nikkei.com/article/DGXZQOGN1757C0X10C24A1000000/
- DSPy lets you prototype LLM Programs like AlphaCodium
	- https://x.com/CShorten30/status/1751656468879708496?s=20
- LangGraph Financial Agent w/ Polygon
	- https://gist.github.com/virattt/4d764c427892ce9fdf4534209edfb1f4
	- LangGraphでエージェントを作って株価をとってくる簡単な例
- Ollamaで、 Mistral-7B finetuned for function calling　をサポート
	- https://ollama.ai/calebfahlgren/natural-functions
-  知識0でローカルLLMモデルを試してみる！垂れ流し配信【ゴリラジ】
	- https://www.youtube.com/watch?v=C1yFEMDLddc
- MetaがコーディングLLMのCodeLlamaの70B版をオープンソースでリリース。
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/?utm_source=twitter&utm_medium=organic_social&utm_campaign=codellama&utm_content=reply
	- HumanEvalでGPT-4超えしたらしい。入力コンテキスト長も100kまで行けるらしい
	- Metaは以前から「GPT-4並のLLMをオープンにする」と予告していましたが，年明け早々，まずはコード生成領域でやってきました
	- https://labs.perplexity.ai/ でためせるらしい
-  Inverse Molecular Design with Multi-Conditional Diffusion Guidance
	- https://arxiv.org/abs/2401.13858
	- 複数の制約下での分子生成の論文
	- 従来は合成可能性とガス透過性など２つ以上の制約を満たすような分子を１つのモデルから生成できませんでしたが 
	- 制約をエンコードしたTransformerモデルにより低分子・高分子共にうまく生成できたそうです。
- アリババがマルチモーダルLLM使って作ったスマホを操作するエージェント、Mobile-Agentを発表
	- https://x.com/umiyuki_ai/status/1752183108873687439?s=20
- SliceGPT: Compress Large Language Models by Deleting Rows and Columns
	- https://arxiv.org/abs/2401.15024
	- Microsoftとチューリッヒ工科大の研究者により、LLMをスライス（行や列を削除）して軽くする効果的な手法
	- 実験では最大30%のパラメータを削減しつつ性能の90%以上を保つことができたと
	- ■提案手法 
		- 1. 主成分分析を用いて重要な情報を抽出 
		- 2. 重要でない情報を取り除くために行や列を削減 →より少ない計算リソースで動作できるようにする
	- ■実験と結果 
		- 1. OPT, LLAMA-2, Phi-2を実験対象モデルに設定 
		- 2. HuggingFace TransformersとPyTorchで実装 
		- 3. いくつかのスライスレベルを分けて実験 
		- 4. 最大30%のモデルパラメータ削減が実現した 
		- 5. Llama 2とPhi-2モデルは90%以上の性能を維持
- Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
	- https://arxiv.org/abs/2312.05934
	- Microsoftより「Fine TuningとRAGのどちらが高精度か？」に答えた論文
	- 既存/新規知識の両方においてRAGが良好な結果に。Fine Tuningは継続事前学習、評価はMMLUをLM-Evaluation-Harnessで実施。
- The Power of Noise: Redefining Retrieval for RAG System
	- https://arxiv.org/abs/2401.14887
	- LLMにおけるRAG（外部データを取り込ませる）システムを構築する際には、データベースに「無関係な」文書を混ぜたほうが検索精度が上がる可能性が示唆されています。
	- ■なぜそんなことが起こるのか 
		- 1. 関連性が高い文書ばかりだと過剰適合が起こる 
		- 2. 無関係情報をフィルタリングする能力が上が
- 一昨日くらいからmistralの有料版であるmistral-medium(70B、MoEではない)の重みがリークしたという噂がある
	- https://x.com/webbigdata/status/1752304557336801408?s=20
-  Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery
	- https://arxiv.org/abs/2309.14425
	- 松尾研のRAで学部2年生の白坂翠萌さんが主著した，基盤モデルを活用して，オンラインにプロンプトを生成しながら失敗にも柔軟に対応する家庭内サービスロボットシステムに関する研究がICRA2024に採択されました
- 突如として現れたmiqu-70BがEQ-Bench では 83.5 を獲得し (ローカルで評価)、GPT-4系に次ぐ性能であることが判明
	- https://x.com/N8Programs/status/1752441060133892503?s=20
	- どうも、Mixtral 8x7Bの量子化版のリークだったらしい
-  LangGraphで始めるマルチエージェントシステム
	- https://speakerdeck.com/peisuke/langgraphdeshi-merumarutiezientosisutemu
	- Function Callingだけで割とよく動いてるとこあるんだけど、もう少し統合したくてSupervisorが必要そうなフローから試してみようかな
- Mixtral8x7Bの日本語対応Loraの学習完了しました
	- https://x.com/AiXsatoshi/status/1752509354849546417?s=20
	- 標準のMixtral8x7Bでは、応答に多言語間を行き来するswitchingが発生しますが、改善しています
	- 汎用性能が落ちている可能性あるので、もう少し検証します
- 学習済みの LLM を束ねて Mixture of Experts を作るテク
	- https://zenn.dev/zaburo_ch/articles/88e35e5c80f974
	- Phixtralの話の紹介
	- 「Phi-2 ベースのモデルをいくつか使って Mixture of Experts (MoE) を作ったら単体よりも良い性能が達成できました」
	- **Few-shot で Gating のパラメータを決める手法**が使われていて面白かった
	- Gating の話を忘れれば「ベースのモデルを決めて MLP 以外のパラメータは全部ベースモデルのものを、MLP は MoE Layer に置き換えて各モデルの MLP のパラメータを使う」という方法で MoE モデルが作れそうです
	- 各 Expert について、その Expert を使うと有利になりそうな Prompt (例えば Code で Fine-Tuning された Expert なら Code の Prompt) をいくつか用意して、その Prompt を forward したときの hidden_state を使って we​ を作ろう
	- Domain ごとに Expert を使い分けてくれることを期待する感じですね
- CodeLlama-70BをPostgreSQLの生成に特化させたバージョン、SQLCoder-70B
	- https://huggingface.co/defog/sqlcoder-70b-alpha
	- 性能評価もGPT-4に10ポイント以上差をつける圧倒的な勝利で、特化型のコード生成LLMの台頭を予感させるようなポテンシャルを秘めている
- LLaVA-1.6のリリース、Gemini Pro越え？
	- https://x.com/imhaotian/status/1752621754273472927?s=20
	- https://llava-vl.github.io/blog/2024-01-30-llava-1-6/
	- improved reasoning, OCR, and world knowledge. It supports higher-res inputs, more tasks, and exceeds Gemini Pro on several benchmarks!
	- LLaVA-1.6、普通に画像中の吹き出しを日本語で喋っているとか認識できて、Gemini Pro超えは伊達ではないなとなる
- 700億パラメーターLLM「KARAKURI LM」を一般公開
	- https://karakuri.ai/seminar/news/karakuri-lm/
	- GPT-4を評価者とするベンチマーク(MT-Bench-jp)で、国産LLMとしては1位の性能を達成しました
	- https://lm.karakuri.cc/ でお試し
- 論文「RAG VS Fine-tuning」を読む
	- https://zenn.dev/neoai/articles/e75b6f033a4fd9
- 普通の人が資産運用で99点を取る方法
	- https://hayatoito.github.io/2020/investing/
		- 1.  確定拠出年金 (iDeCo または 企業型 DC）を始めます。
		- 2.  新 NISA でつみたての設定をします。
		- 3.  さらに余裕がある方は、特定口座でつみたての設定をします。
		- 4.  資産運用を始めた直後や、まとまった資金を一時的に入手したときなど、十分な余剰資金（現金）をもっているのであれば、自分のリスク許容度の範囲内で、適切な割合の資産を  _一括_  で投資します。詳しくは後述の「アセットアロケーション」を参照してください。
		- 5.  定期的に（年に 1 回、あるいは数年に 1 回）、アセットアロケーションについて見直しましょう。
-  Self-supervised Learning: Generative or Contrastive
	- https://arxiv.org/abs/2006.08218
- Proactive Detection of Voice Cloning with Localized Watermarking
	- https://huggingface.co/papers/2401.17264
	- Meta presents Proactive Detection of Voice Cloning with Localized Watermarking
- オークションサイトなどから中古のRTX 3090を8台かき集めてマシンを構築した人のお話
	- https://www.kyleboddy.com/2024/01/28/building-deep-learning-machines-unorthodox-gpus/
- Google's AI Makes Stunning Progress with Logical Reasoning
	- https://www.youtube.com/watch?v=NrNjvIrCqII
- Microsoft and OpenAI are in talks to invest $100 million into Figure
	- https://x.com/AndrewCurran_/status/1752463084550262805?s=20
	- Figureは、人型ロボットを開発するスタートアップ
-  ReGAL: Refactoring Programs to Discover Generalizable Abstractions
	- https://huggingface.co/papers/2401.16467
- miqudev/miqu-1-70b
	- https://huggingface.co/miqudev/miqu-1-70b
	- えっ！、miquってミクのことだったのか。
- H2O-Danube-1.8B Technical Report
	- https://arxiv.org/abs/2401.16818
	- Open-sources a high-competitive 1.8B LM trained on 1T tokens following the core principles of LLama 2 and Mistral
	- long context small LLM trained by a team of some of the best Kagglers in the world
	- どうも小規模LLMでKagglerによりtrainigされたもｎ
-  Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
	- https://arxiv.org/abs/2401.17263
	- Significantly improves robustness to held-out jailbreaks, reducing the attack success rate from 84% to 8.66% across 20 jailbreaks
- quantized CodeLlama 70b base model to 4-bit with MLX
	- https://huggingface.co/mlx-community/CodeLlama-70b-hf-4bit-MLX
	- you can now run this model on your Apple Silicon.
- StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis
	- https://arxiv.org/abs/2401.17093
- Memphis-CoT 3B
	- https://huggingface.co/euclaise/Memphis-CoT-3B
	- A small reasoning-focused model using a novel iterative contrastive finetuning procedure, trained on only human data, outperforming much larger human data models and similarly sized SFT models.
-  RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank
	- ICLR24 Spotlight: To train general-purpose SSL models, it's important to measure the quality of representations during training. But how can we do this w/o downstream labels? 
	- We propose a new label-free metric to eval SSL models, called Linear Discrimination Analysis Rank(LiDAR)
-  [The False Promise of Imitating Proprietary LLMs](https://arxiv.org/abs/2305.15717v1)
	- 言語モデルの「模倣」は有用か？
	- https://ai-scholar.tech/articles/chatgpt/Imitating-Proprietary-LLMs
	- 最新研究によれば、新しく開発された言語モデルの模倣は非常に難しいことが示唆されています。微調整による改善が有効でなく、モデルの基本的な知識はあまり変わらないことが発見されました。  
	- 中小企業や大企業が同じ利点を得ることが難しくなり、特に新しいデータやアルゴリズムを活かして能力差を生かす企業が競争上の優位性を築ける可能性があります。
	- 新しい手法やデータの導入が重要であり、技術的な制約にも留意することが持続的な発展に寄与するでしょう。
- Accelerating the Science of Language Models
	- https://allenai.org/olmo/olmo-paper.pdf
	- AllenAIによるOpen Language Model (OLMo), a 7B parameter model.
	- There is also a smaller version of it, OLMo 1B.
- ブラウザでRubyを動かす夢
	- https://mametter.hatenablog.com/entry/2024/02/01/105413
	- 元同僚の遠藤さん、頑張ってるな、みんな使ってあげて！
- SEMSCORE: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity
	- https://arxiv.org/pdf/2401.17072.pdf
	- これでJapanese MT-benchやElyza-tasksが毎回GPT-4を使わずに評価できるようになれば割と安価で日本語LLM leaderboardが作れそう
- llamaindexを使った、使用したクエリ変換の解説記事
	- https://akash-mathur.medium.com/advanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3
	-  Advanced RAG: Query Augmentation for Next-Level Search using LlamaIndex
	- クエリ変換は「LLM への入力（クエリ）をより良い情報抽出を可能とする表現へ変換する」ことで，RAG の質を高める手法
	- 記事内では，代表的な 5 つの手法を code つきで解説
- Build Long-context RAG from scratch: Nomic Embeddings + Mistral
	- https://x.com/LangChainAI/status/1753149741599428926?s=20
	- nomic_ai has launched a new open source, long context embedding model:
		- 8k token context window (using RoPE)
		- Strong performance on several benchmarks 
		- API (and local support coming soon)
	- そしてlong contexのRAGをつくるには、
		- nomic_ai:new 8k context window embeddings
		- trychroma:vectorstore　MistralAI-instruct 32k context window via  ollama
- Apple presents Can Large Language Models Understand Context
	- https://huggingface.co/papers/2402.0085
	- We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.
-  Grounded language acquisition through the eyes and ears of a single child
	- https://www.science.org/doi/10.1126/science.adi1374
	- 大規模言語モデルほど大量のデータを食わなくても子供は言語を獲得する。それをニューラルネットで再現できるか確認するため、赤ちゃん１人の頭に生後 6〜25 ヶ月の間に録画用ビデオを延べ 61 時間装着して音声･映像データを取得、マルチモーダル学習を成功させたとする報告
- karakuri-lm-70b-chat-v0.1-gguf の q5_K_S を ローカルで試す。とても優秀。
	- https://x.com/npaka123/status/1753336604759118014?s=20
	-  Llama.cppで5.82 token/s (M3 Max)
	- https://huggingface.co/mmnga/karakuri-lm-70b-chat-v0.1-gguf
- 藝大の噂の生成AIのやつ、説明とか見たら思った数百倍手の込んだことやっててすげぇってなった。生成AIの良い使い方っすね。
	- https://x.com/413s9/status/1753300577516433830?s=20
	- 藝大のAIアニメ、KALINさんの注釈を読む限り 
		- 物語部→chatgpt 
		- 画像生成→midjourney,nijijourney 
		- AI動画化→runway,pika 
		- 画像修正→photoshop と書かれていたはずなので（アニメ部はクリスタかも？） 
	- 基本的にKALINさんはローカルSDを個人で動かすという作業は行っていなかったのだろうと推測。
	- 例のAIアニメのChatGPTのログをざっと眺めたが、完全にGPT-3.5のキャパシティを超えているレベルで使い込んでいて割と絶句した
		- https://chat.openai.com/share/a6f6052e-a22c-49aa-8847-9c7f12b011e0
-  A Prompt-Engineered Large Language Model, Deep Learning Workflow for Materials Classification
	- https://arxiv.org/abs/2401.17788
	- 言語モデルによる材料分類の論文
	- Geminにより材料情報を指定したテキスト形式に変換し、整えたデータでBERTを微調整することにより、金属ガラスになるか否かを高精度に判定できたそうです。
	- 言語モデルフル活用。疎なデータでもうまく予測できる点がメリットのようです
- Build a RAG backend over any website in a single CLI command
	- https://github.com/run-llama/LlamaIndexTS/tree/main/packages/create-llama
- リコーがLlama-2-13Bをベースに高性能な日本語モデルRicor-13Bを開発
	- https://x.com/umiyuki_ai/status/1753312415503245762?s=20
	- ただしオープンにはしない。顧客企業の業種に合わせてカスタム（微調整なのか？RAGなのか？）してクラウドで提供するB2Bビジネスを開始
- 2024年1月30日 国立情報学研究所における大規模言語モデル構築への協力について
	- https://www.ndl.go.jp/jp/news/fy2023/240130_01.html
	- 国会図書館は国内のウェブサイトのアーカイブ事業をやってたけど、このアーカイブデータの数十億件のURLを国立情報学研究所に提供するんだって。国立情報学研究所はこのデータからコーパス作ってLLM構築に使うん
	- https://x.com/umiyuki_ai/status/1753651801688273040?s=20
-  KARAKURI LMの解説
	- https://medium.com/karakuri/karakuri-lm%E3%81%AE%E8%A7%A3%E8%AA%AC-4b6cf9c3d40f
	- KARAKURI LMは、Llama 2を基に開発した事前学習済み言語モデルです。  
	- 日本語の語彙を追加し、日本語と多言語コーパスを混ぜて追加の事前学習を行うことで、Llama 2の日本語能力を強化しています。
	- KARAKURI LM Chatは、KARAKURI LMをファインチューニングしたモデルです
	- 公開されている会話データセットと独自で開発した非公開の会話データセットを混ぜて学習させています。
- 「ポスト５Ｇ情報通信システム基盤強化研究開発事業／ポスト５Ｇ情報通信システムの開発」
	- NEDOが国内の生成AIの基盤モデル開発のために実施し
	- ABEJA、Sakana AI、NII、ストックマーク、Turing、東京大学、Preferred Elements
	- Preferred Elements（PFE）が、経産省とNEDOが開始する「GENIAC（Generative AI Accelerator Challenge）」において、1000億パラメータのマルチモーダル基盤モデルの開発と、1兆パラメータの大規模言語モデルの事前学習の検証を開始します。
	- 東大松尾研、 NEDOの採択を受け、公開型での500億パラメータサイズの大規模言語モデル開発を開始します。
- A decoder-only foundation model for time-series forecasting
	- https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities.
	- 基盤モデルで時系列予測？？googleがもつ大量の時系列データを特にかく学習？？
	- あらゆる時系列データをDecoder-onlyのモデルにぶっ込んで時系列予測の基盤モデル作る話
- Ollama vision is here
	- https://x.com/ollama/status/1753530905069748506?s=20
- GoogleとOpenAIは「後出しジャンケンしたもん勝ち」を狙って膠着状態？
	- https://x.com/ImAI_Eruel/status/1753389879965429892?s=20
	- 最近AI界隈が妙に静かだと言われてるやつ，GoogleとOpenAIが互いに，「Gemini Ultra」と「GPT-4.5 or GPT-5」と言う切り札が既にほぼ公開可能な状態なことを宣言していて，今までの経過を見ると後から公開した方が天下を取ってる
-  karakuri-lm-70b-chatをOpenAI互換のローカルサーバとして動かしてみた
	- https://qiita.com/takaaki_inada/items/3a22b982a3541e6f214c?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- karakuri-lm-70b-chatの4bit量子版ggufをローカルPCで動かしてみた
	- json format出力が出来たり、少し複雑なsystem promptも効いてくれて良い
	- text-generation-webui でOpenAI互換のローカルサーバとして起動
	- GPUメモリに48/81レイヤー分モデルをのせてサーバを起動
-  WSL2とllama.cppでKARAKURI MLを試してみる
	- https://note.com/ngc_shj/n/n46ced665b378?sub_rt=share_h
- Corrective Retrieval Augmented Generation
	- https://arxiv.org/abs/2401.15884
	- Googleなどの研究者らは、LLMの検索における正確性をさらに向上させるフレームワーク（『CRAG』）を提案
	- 検索結果を検証するプロセスを導入する手法で
- Hugging FaceがGPT Storeのオープンソース版（Assistantという呼称）をリリース
	- https://x.com/ytiskw/status/1753600673063784789?s=20
- Meta、H100を35万機そろえ、OSS貢献に大きく舵を切ると公表、株価は２０％アップ？
	- AI at Meta: 350k H100s by the end of the year, open source AI software infrastructure, new data centers with custom chips for AI inference serving hundreds of millions of users of AI tools.
	- https://x.com/ylecun/status/1753431180861419947?s=20
	- https://x.com/AIatMeta/status/1753195225311563848?s=20
-  Llama.cpp で Karakuri LM を試す by npakaさん
	- https://note.com/npaka/n/n582c88a157e2?sub_rt=share_h
- Gemini Ultra 2/7にリリースの可能性。
	- https://www.reddit.com/r/Bard/comments/1ahmsnf/advanced/
	- BardがGeminiという名前に変更
	- Gemini Ultra 1.0であるGemini Advanced が開放 
	- マルチモーダル機能等は今後拡張予定 
	- Geminiがスマホでアシスタントとして使えるようになる。


## 1/29

中国オリオンスターロボティクス（OrionStar）という会社から新星LLMであるOrion登場、日本語や韓国語が得意なのと長文モデルを持っている、中華LLMは日本語も得意ってのはよく言われていること、推論高速で回答も自然で良い感じだそうだ。LLMのアライメントも、RLHFに代わって、嗜好データセットをつかったアライメントの自動化DPOがはやってきた、Metaの本家とは違うDPOの実装も出てきたし、CALM2をDPOしたモデルやデータセットの公開などもあった。DPOに必要な嗜好データセット自体の構築支援KTOなど、アライメント関係の進捗が目立つ。MoEの構築もColabの無料枠で実現する事例が出てきた、Sparse性がポイントなのか。既存のLLMを融合させて強力なモデルを作る「知識融合」ってのが出てきた、合体というより、どちらかというと蒸留に近い感じらしい。LLMの研究トレンドは、1)Synthetic training data、2)LLM safety、3)Knowledge injectionの３つだそうだ。Phi-2って1)Synthetic training dataが特徴かとおもってたのに、3)Knowledge injectionがうまく動いた例でもあるのね。DPOはもちろん、2)LLM safetyと関係ある。AIが自分自身に報酬を与えて進化する「自己報酬型言語モデル」、報酬モデルが、繰り返しのプロセスを通じて改善されるとのこと、自給自足モデルか。基盤モデルよりも、領域を絞ったモデルが高性能であったり、Q&Aタスクに絞ってllama2を２段階の指示チューニングして、GPT-4に迫る結果など、それはそうだがそれを確かめたのが尊い。LeCun先生によると、DGNNの論文でどこにも投稿してなかったのか。。OpenAIの 新モデルの追加 と APIの更新もありました、安くなって性能が上がる、OpenAIちゃんと仕事してますね。LangGraphってLCELの拡張だったのか、アロー言語とかそういうのに近いのかも。HuggingFaceとGoogleのパートナシップ、Colab環境とより密になりAIの民主化的には朗報なわけですが、Google何を狙っている？T4の普及？？MacでLLMの利用も着実に進歩、MLXでXwin-70Bのggufが動くことが確認された。エンベディングもColBERTという新手があるのか？trasformerもv4.37でQwen2, Phi-2, SigLIPなどが使えるようになった。

- Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine
	- https://arxiv.org/abs/2311.16452
	- Microsoftより「GPT-4等の基盤モデルよりも、領域を絞ったモデルの方がその領域で高性能なのではないか？」を調べた論文。結果、医療の問題でGPT-4がMed-PaLM2を上回る結果に
- Orion-14B
	- https://github.com/OrionStarAI/Orion
	- 中国発LLMの新星
	- 2.5T学習、日本語100B事前学習済 語彙サイズは84,608 
	- 長文モデルは、200k-320k対応 RAG、
	- function calling専用モデルを用意
- transformer v4.37
	- https://github.com/huggingface/transformers/releases/tag/v4.37.0
	- Release v4.37 Qwen2, Phi-2, SigLIP, ViP-LLaVA, Fast2SpeechConformer, 4-bit serialization, Whisper longform generation · huggingface/transformers · GitHub
-  DPO によるLLMのPreferenceチューニング by npakaさん
	- https://note.com/npaka/n/n8be32e899c8a?sub_rt=share_b
	- 「DPO」(Direct Preference Optimization)、「IPO」(Identity Preference Optimization)、「KTO」(Kahneman-Taversky Optimization) という3つの有望なLLMアライメントアルゴリズムの評価
	- DPO
		- 「**DPO**」はLLMを人間またはAIの好みに合わせるための有望な代替手段として浮上しています。「強化学習」に基づく従来のアライメントアルゴリズムとは異なり、「DPO」はアライメントの定式化を、嗜好のデータセット上で直接最適化できる単純な損失関数として再構成します。
		- これにより、「DPO」は使いやすくなり、「Zephyr」や「NeuralChat」などのモデルの学習で成功しています。
	- IPO
		- 「DPO」の欠点の1つは、優先データセットにすぐに過剰適合する傾向があることです。これを回避するために、「Google DeepMind」は「IPO」を導入しました。これにより、「DPO」損失に正則化項が追加され、早期停止などのトリックを必要とせずにモデルを収束するように学習できるようになります。
	- KTO
		- ContextualAIは最近、「KTO」と呼ばれる興味深い代替案を提案しました。これは、「good」または「bad」とラベル付けされた個々の例に関して損失関数を完全に定義するものです。これらのラベルは取得するのがはるかに簡単であり、「KTO」は本番環境で実行されているチャットモデルを継続的に更新する有望な方法になります。
- LLMのRLHF→DPO→KTOってトレンドの流れを抑えよう by うみゆき
	- https://x.com/umiyuki_ai/status/1749670491227672797?s=20
	- オープンLLMはそんな金かけてRLHFやるなんて無理だった。そこで発明されたのがDPOだ。
	- DPOは人力で評価する必要が無いからコストがかからない。代わりに”嗜好データセット”を用意する必要がある。嗜好データセットってのは、あるプロンプトが与えられた時の二つの回答があって、こっちの回答の方がイケてて、こっちの方が良くない。みたいなデータが大量に用意されてるモノ。RLHFとDPOは数学的に等価である事がキッチリ証明されてる。
	- 嗜好データセットとか言われても、そんなもん用意するのだってまだまだ手間がかかって大変だ。そういうデータの問題をどうにかする新しいテクがKTO。KTOでは必要なデータはプロンプトと回答があって、その回答に「いいね」か「よくないね」の評価だけ付いてればいい。
	- KTOによってLLMのアラインメント作業は相当簡単にできるようになってきたわけだ。ただ、そうやって作ったモデルのベンチ性能を比較すると、やっぱKTOよりDPOの方がやや高性能みたいだ
- GoogleDeepmindがSpatialVLMを発表
	- までの視覚言語モデルは空間感覚に欠けていた。例えば「写真に写ってるバッターと審判の距離は何メートル？」とか訊いても答えられんかった。それを改善したのがSpatialVLM。
- makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
	- https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch
	- Colabも公開してくれているので無料版ColabのT4でも動かせます。max_itersを500くらいに修正すれば所要時間も10分程度
	- ただし、最後から3番目のセルは以下のように要修正 
		- metrics = {"train_loss": losses['train'], "val_loss": losses['val']} 　
		- ↓ metrics = {"train_loss": float(losses['train']), "val_loss": float(losses['val'])}
- 深層学習の原理を明らかにする理論の試み　by 今泉さん
	- https://drive.google.com/file/d/1bNN6VjsgdpJAqxvZ4EKAPpMGq9wfjHqf/view
	- 「なぜ深層学習でうまくいくのか」という素朴な疑問に対し、理論的にわかっていることを平易に解説したスライド。非常にわかりやすい。
- Orion-14B-Chat-Int4 を試す。
	- https://huggingface.co/OrionStarAI/Orion-14B-Chat-Int4
	- https://note.com/npaka/n/nd5025f5f7ac1?sub_rt=share_h
	- 推論高速で回答も自然で良い感じ。 ロングチャット用、RAG用、Function Calling用などもある
-  RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture
	- https://arxiv.org/abs/2401.08406
	- Microsoftより農業データを例に、LLMでRAGとFine-Tuningを比較分析した論文。
	- 比較結果の要約は表22-23の通り(図引用)。双方の使い分けポイントは表23の最下行にあり。
- AIが自分自身に報酬を与えて進化する「自己報酬型言語モデル」　米Metaなどが開発、実験でGPT-4を上回る【研究紹介】
	- https://levtech.jp/media/article/column/detail_374/
	- この訓練方法により、モデルの指示に従う能力と報酬モデリング能力が反復ごとに向上することが示された。
	- モデルは、自分の答えを生成する能力を向上させると同時に、自分自身の報酬モデルとしても機能。通常は固定されている報酬モデルが、繰り返しのプロセスを通じて改善される。
	- **これは、人間などの外部からのフィードバックを不要にし、学習モデルが自分自身をよりよく改善できるようになることを意味し、自己改善の好循環を生み出す。**
- Summarize gigantic JSON datasets in seconds with JSONalyze, our latest query engine: 
	- https://docs.llamaindex.ai/en/latest/examples/query_engine/JSONalyze_query_engine.html
	- JSONが巨大になると、コンテキストが膨大になるので、圧縮？するらしい
-  Self-Rewarding Language Model (wip)
	- https://github.com/lucidrains/self-rewarding-lm-pytorch
	- MetaのDPOの、独立実装が登場らしい
- ベイズモデリングによるチームメイト及び対戦相手の能力を考慮したポゼッションデータに基づくバスケットボールプレイヤーの能力評価指標
	- https://www.jstage.jst.go.jp/article/jscswabun/36/2/36_99/_article/-char/ja/
	- 滋賀大時代の学生や同僚たちと書いたバスケットボール選手のパフォーマンス評価に関する論文が掲載されたとらしい
-  WARM: On the Benefits of Weight Averaged Reward Models
	- https://huggingface.co/papers/2401.12187
	- Google Deepmind presents WARM
- GoogleColobで小規模言語モデル(0.15B)の事前学習モデルを作ってみる
	- https://ayousanz.hatenadiary.jp/entry/2024/01/23/225623
	- 事前学習モデル(0.15B)を作ってみました ちゃんと使えるレベルにするためには、約200倍くらいかけないといけないみたいです
- ChatGPTのコンテキスト長が32kになってるから青空文庫の小説とかを2万文字くらいのテキストファイルに分割して自分の代わりに読んでもらって内容教えてもらう事も結構できる。
	- まあClaudeならコンテキスト長100kだからもっと大量の文章をまとめて読んでもらえる
	- https://x.com/umiyuki_ai/status/1749775772850749556?s=20
- Knowledge Fusion of Large Language Models", ICLR 2024より
	- https://arxiv.org/abs/2401.10491
	- 既存のLLMを融合させて強力なモデルを作る手法「知識融合」が開発
	- 混合モデルを提唱する"Blending Is All You Need"とはアプローチ・評価方法ともに異なる研究です
	- ■実験と結果 
		- 1. 「Llama-2」「OpenLLaMA」「MPT」を融合して「FUSELLM」を作成した 
		- 2. 下記タスクを中心に顕著に性能が向上した - 論理 - 常識 - コード生成
- LLMの研究トレンドは以下の３つ
	- https://x.com/cwolferesearch/status/1749867258107543615?s=20
	- (1) Synthetic training data:
		- [1]では、最先端の埋め込みモデルを学習するために、合成学習データを使用できることを示している。
		- [2]では、数学とコーディングの問題に対して合成データを簡単に生成し、検証することができ、LLMの性能を向上させるために使用できることが示されている。
	- (2) LLM safety:
		- [3]の研究では、LLMに訓練されたバックドア攻撃は、広範な安全訓練後も持続し、人間のユーザーを欺くスリーパーエージェントを形成することが示されています
		- [4]で、適切なプロンプト技術さえあれば、多くのアライメントを経たLLMであっても、ほぼ全てのLLMからトレーニングデータを抽出できることを学びました。
	- (3) Knowledge injection
		- [6]の著者は検索拡張世代（RAG）を提案し、このアプローチが知識集約型タスクのパフォーマンスに影響を与えることを示している。
		- LIMA [7]は、LLMのほぼ全ての知識が事前学習中に学習されることを示している。
		- Phi-1[8]は、知識豊富なLLMが、より小さな、キュレーションされたデータセット（つまり教科書）に対して学習できることを示している。
-  Reading Analog Gauges
	- https://huggingface.co/spaces/Synanthropic/reading-analog-gauge
	- Simply Reading Analog Gauges – GPT4, CogVLM Can't
	- This model reads analog dial gauge by detecting, applying perspective correction, and gauge reading. The model was build only with synthetic data (e.g. examples
- OpenAI GPT-4V／ChatGPT／GPTs 人工知能プログラミング実践入門
	- 布留川さんの、新刊、
	- https://wgn-obs.shop-pro.jp/?pid=179128392
	- 昨年11月の大規模アップデート対応で、マルチモーダルやGPTストアなどの新機能も解説してます。技術アップデートが早すぎることもあり、PDFのみになります。
- ChatQA: Building GPT-4 Level Conversational QA Models
	- https://arxiv.org/abs/2401.10225
	- GPT-4レベルの質問応答タスク性能をオープンソースモデルのLlama 2で実現する方法が、NVIDIAより発表されました。
	- 長文ドキュメントに基づいてユーザーの問いに答える能力でGPT-3.5より遥かに勝る結果が示されています。
	- ■方法論 以下のような２段階の指示チューニングを行う 
		- 1. 教師ありファインチューニング （supervised fine-tuning） 
		- 2. 文脈強化インストラクションチューニング （context-enhanced instruction tuning）
	- ■実験と結果 
		- 1. Llama-2を調整して「ChatQA」モデルを作成した 
		- 2. 長文ドキュメントに基づくQAタスクで評価した 
		- 3. GPT-3.5の性能を遥かに上回った 4. GPT-4とは同等と言えるレベルだった
-  Prompt Engineering with Llama 2
	- https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=video
	- Introducing 'Prompt Engineering with Llama 2' — an interactive guide covering prompt engineering & best practices for developers, researchers & enthusiasts working with large language models.
- Ollama Python and JavaScript libraries
	- https://ollama.ai/blog/python-javascript-libraries
	- Both libraries make it possible to integrate new and existing apps with Ollama in a few lines of code, and share the features and feel of the Ollama REST API.
- CALM2をDirect Preference Optimization (DPO)でチューニングしたモデル calm2-7b-chat-dpo をCC-BY 4.0で公開しました。
	- https://huggingface.co/cyberagent/calm2-7b-chat-dpo-experimental
	- calm2-7b-chat-dpoをELYZA-tasks-100とJapanese MT-Benchで評価を行ったところ、CALM2よりも更に高いスコアが得られるという結果になりました
	- また、あわせてDPOに用いたデータセットをCC-BY 4.0で公開しました
	- https://huggingface.co/datasets/cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental
- 今更ながら､GPT3.5をファインチューニングしてみました｡ 
	- https://x.com/kanhatakeyama/status/1750331895853039745?s=20
	- guiで操作できるし､gpuマシンを用意しなくて良いし､非常にお手軽な印象でした｡ 3並列まで学習回せました｡
	- 2,3時間の使用で､$30ほどかかりました｡
-  LLM のデータセットまとめ by npakaさん
	- https://note.com/npaka/n/n686d987adfb1?sub_rt=share_b
- Hugging Face and Google partner for open AI collaboration
	- https://huggingface.co/blog/gcp-partnership
	- We will collaborate with Google to foster open AI innovation across open science, open-source, cloud, and hardware
	- A collaboration for Google Cloud customers
	- A collaboration for Hugging Face Hub users
-  OpenAIの 新モデルの追加 と APIの更新 by npakaさん
	- https://note.com/npaka/n/nd8c5e9c65335?sub_rt=share_h
	- ・新しいEmbeddingモデルの追加
	- ・GPT-4 Turbo Previewの更新
	- ・GPT-3.5 Turboの更新
	- ・モデレーションモデルの更新
	- ・APIキーの管理方法の改善
- 実はSwallowはbaseモデルとしての性能はいいですが、instruct モデルの性能はpublic instruction datasetを使用したこともあり、baseモデルの高い性能の割にはあまり高くありません
	- https://x.com/okoge_kaz/status/1750805452676608177?s=20
- CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果
	- https://ai-data-base.com/archives/62364
	- GPT-4などのLLMに思考の連鎖（CoT）プロンプトなどで「考える時間」を与えると基本的に性能が向上します。 
	- そこで今回、適切な推論のステップ数が検証されました。 記事ではプロンプト手法とともに結果を紹介しています。
-  MambaByte: Token-free Selective State Space Model
	- https://arxiv.org/abs/2401.13660
	- MambaByteは、Mambaが長い系列も扱えるため、トークン化せずバイト単位で言語モデルを学習。同等の計算量、モデルサイズでトークン化不要のMegaByteや通常のトークン化Transformerと比べ性能で上回り、1/3の投入計算量でTransformerの損失に到達。小規模実験の結果だが有望
-  Dense X Retrieval: What Retrieval Granularity Should We Use?
	- https://arxiv.org/abs/2312.06648
	- The "Dense X Retriever" paper shows that it significantly outperforms the traditional chunk-based retriever
-  Deep Convolutional Networks on Graph-Structured Data
	- https://arxiv.org/abs/1506.05163
	- My most-cited, never-accepted, ArXiv-only paper has over 1880 citations. "Deep Convolutional Networks on Graph-Structured Data" Mikael Henaff, Joan Bruna, Yann LeCun
-  FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- https://huggingface.co/papers/2401.14112
	- Microsoft presents FP6-LLM 
	- Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality
- 知識融合、図を見るとアンサンブルやMixture of Expertsとは違って本当に知識そのものを抽出している感じか。どちらかというと蒸留に近い感じもあり画期的な手法のように思える。
	- https://x.com/koheiichi/status/1751060499310301550?s=20
- Python library that adds Generative AI capabilities to Pandas
	- https://github.com/gventuri/pandas-ai
	- Introducing PandasAI, now you can analyze complex data frames and plot visualizations just by using natural language
- XWin 70B で LLM 出力日本語文章の自動評価を行う試み
	- https://zenn.dev/syoyo/articles/4f4f8645af1cee
	- 日本語 LLM の自動評価(ELYZAちゃん task 100 とか)をローカル LLM で行いたい.現時点で最高性能の一つXWin 70B での評価試しました!
	- そこそこいい感じになったよ✊
	- でも prompt 上手く作る必要あることがわかったよ
- 同じデータに対してもモデル（この場合はカーネル）が異なれば予測が変わるという話。こういうことを色々実現したい場合はやっぱりガウス過程がやりやすいです。 by 須山先生
	- https://x.com/sammy_suyama/status/1751104980189413880?s=20
-  Google Colab で LangGraph を試す by npakaさん
	- https://note.com/npaka/n/n053a3cb78311?sub_rt=share_h
	- 「**LangGraph**」は、LLMでステートフルな「**マルチアクターアプリケーション**」を構築するためのライブラリです。「**LCEL**」(LangChain Expression Language) を拡張して、複数チェーン (またはアクター) を複数ステップにわたって循環的に協調動作させることができます
	- 「LangGraph」によって、LLMアプリケーションに**サイクル**を簡単に導入できるようになりました。
- MLXでXwin-70Bのggufが動くことを確認
	- https://x.com/npaka123/status/1751139720367862193?s=20
	- Apple M3 Max
-  google/siglip-base-patch16-256-multilingual を使って、ローカルの画像を日本語で検索してみ
	- https://note.com/eurekachan/n/n9d4f62b80ad6?sub_rt=share_pb
	- 1月に、Googleから、SigLIPという、画像とテキストの両方をベクトルとして扱うことができるモデルのmultilingual版（多言語対応版）が公開されました。transformers 4.37以降で対応しています。日本語も対応しています。
-  Are Transformers Effective for Time Series Forecasting?
	- https://arxiv.org/abs/2205.13504
- ColBERT superior to traditional embedding models
	- https://x.com/marktenenholtz/status/1751406680535883869?s=20
	- クエリと文書をそれぞれ別のエンコーダーで埋め込み、クエリ中の各トークンの埋め込みと文書の各トークンの埋め込みの間で最大類似度を計算し、その総和をスコアとしています。
- miniature ColBERT model in your browser
	- https://colbert.aiserv.cloud/
- DSPy lets you prototype LLM Programs like AlphaCodium in 2 minutes!
	- https://x.com/CShorten30/status/1751656468879708496?s=20

## 1/22

今週はDavos会議があって、われらのアルトマン氏も登場、GPT-5について言及。Metaからはザッカーバーグ氏がビデオメッセージでいきなりLlama3のOSSとしての開発宣言。NVIDIAがCESで発表したGeForce RTX 4070 SUPERが発売、ローカルLLM界隈の価格破壊が、、、。MoEも今週もにぎやか、圧縮して小メモリ化するようなMC-SMoEのアプローチとか、負荷分散を調整するDeepSeekMoEとか、youri-2x7bのggufがでたりとかとにかく賑やか。小規模LLM向けの人工的に生成された学習用モデルtiny-textbookシリーズも充実してきて、小規模LLMの開発も加速するかな。手が届くところではnanoGPTの源氏物語の適用例は楽しそう。小規模LLMを集めて優れたAIを作るという意味では、sakana.aiが華々しく45億円もの投資を調達、googleなどのスーパー研究者が終結して楽しそう。sakana.aiは小さな魚が集まって一匹の大魚のように泳ぐ物語｢スイミー｣の仕組みなわけだけど、小さな専門エージェントがあつまって問題を解決するってことなら、古い人にはミンスキー御大のSociety o Mindsが思い出される。MicrosoftはColiplot Proをリリース、月20ドルで、個人が、GPT-4 TurboにもアクセスできるしOffice 365 Copilotも使えるしお得かも、一方がっかりしたというファーストユーザーの意見もちらほら。でも小規模LLMの代表格phi-2はマイクロソフトからでているから、OpenAI/Copilot一辺倒では実はない。一方メタは２万人をレイオフして、代わりに35万台のH100インフラを整えLlama3の開発を推進。どの会社もLLMという不確実な要素（発展性、他社との競争）に備えならが綱渡り的な会社の運営をしている（株主からの期待にこたえ続けつつ財務的に破綻はできない）。共通テストにさっそく吊るしのLLMを適用評価した例では、GPT-4が6割強程度正解でなんとか人間を上回るも、特に数学がダメという結果が。一方、数学オリンピックのメダリスト並みの性能を示すDeepMindのAlphaGeometry、LLMとルールベースのハイブリッドが高性能の秘訣らしい、text_to_SQLも、また違ったハイブリッドとして高性能化のヒントになる。ベクトル化のサーベイ論文とか、ELYZAの日本語追加学習でもともとの英語の能力が落ちないかの検証とか、着実な動きは地道にすすんでいるのを忘れずにいたい。

- HachiMLさんが公開されているyouri-2x7b_v0.2のgguf ^aaa
	- https://huggingface.co/mmnga/HachiML-youri-2x7b_v0.2-gguf
	- This model is a Mixture of Experts (MoE) merger of the following two models:
	- [rinna/youri-7b-instruction](https://huggingface.co/rinna/youri-7b-instruction)
	- [rinna/youri-7b-chat](https://huggingface.co/rinna/youri-7b-chat)
- mambaを分散学習するためのライブラリ
	- https://github.com/kotoba-tech/kotomamba
	- Transformerを上回るモデルとして注目されているMamba, State Spaceモデルの
	- Kotoba Techでは130m, 1.4B, 2.8B のモデルの学習をすでに行っています
- baobab-trees/wikipedia-human-retrieval-ja
	- https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja
	- 短い質問文に対してWikipediaに書いてある情報のみで回答させる、というのを1000問前後実施し、人手retrieval付きQAデータセットを作りました。途中の過程や引用なども記録しているので、人間による検索のシミュレーションをデータから検討したりできると思いま
- Copilot for Office 365
	- https://x.com/usutaku_com/status/1747119405702795383?s=20
-  how to build advanced QA over Tabular Data
	- llamaindexより、
	- https://x.com/llama_index/status/1747289513934864493?s=20
	- Query Pipeline over Pandas DataFrames
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas.html
	- This is a simple example that builds a query pipeline that can perform structured operations over a Pandas DataFrame to satisfy a user query, using LLMs to infer the set of operations.
	-  Query Pipeline for Advanced Text-to-SQL
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_sql.html
- nanoGPT楽しい。源氏物語全文で学習させたら何か語りだした🤗 いずれの紛れありけるかな
	- https://github.com/karpathy/nanoGPT
	- The simplest, fastest repository for training/finetuning medium-sized GPTs
- 企業はなぜ東京に集中するのか──経済地理学の視点から（日本労働研究雑誌）
	- https://www.jil.go.jp/institute/zassi/backnumber/2020/05/pdf/029-039.pdf
- 東京発・AIドリームチーム「http://Sakana.ai」が45億円調達　元Googleトップ研究者らが設立　AI業界の著名人や日本の大手IT企業も出資
	- https://sakana.ai/seed-round/
	- @tkasasagi さんも参加かー
	- https://x.com/tkasasagi/status/1747267875021406329?s=20
	- 「サカナAI」日米で45億円調達　スイミーの発想で巨大ITに挑む
		- 同社は対話型AIの基盤技術である大規模言語モデル（LLM）の開発で、他社が開発した小さなAIをいくつもつないで、巨大AIに匹敵する能力をもつ仮想のAIモデルを構想。この新技術はエージェントモデルと呼ばれ、開発コストを劇的に下げる可能性があり、巨額な資金が求められるAI開発競争に一石を投じる狙いだ。
- xverse/XVERSE-13B-256K
	- https://huggingface.co/xverse/XVERSE-13B-256K
	- ローカルLLMの長文対応がついに256K（約25万字）
	- XVERSEはABF+継続的pre-trainingとNTK+SFT技術を用いてプロセスを最適化。これにより、モデルのシーケンス長を大幅に拡張することが可能となった
- Open AIは「Collective Alignment team」を結成
	- https://openai.com/blog/democratic-inputs-to-ai-grant-program-update
	- AIに多種多様な世界中の公的な意見を反映させるシステムの開発を担う。 以前AIへの民主的インプットのアイデアを募集していたが、1000の応募者があり以下画像のように10のチームのアイディアが選抜された
-  再考: お買い得物件を機械学習で見つける方法
	- https://speakerdeck.com/ktgrstsh/rethink-method-to-find-cheap-rental-houses-by-machine-learning
	- 賃貸データのスクレイピングであれば，こちらのページが参考になりました
- WikiChatの話
	- https://arxiv.org/abs/2305.14292
	- WikiChat はファクトチェック及びコンテキストに，RAG 等でよく利用される Wiki を利用するライブラリで，高い factfulness を備えるとしている
- Animagine XL 3.0 、Hugging Faceのトレンドで1位を達成
	- https://huggingface.co/spaces/DamarJati/Animagine-XL-3.0
	- 1月10日、Cagliostro Research Labが、**拡散モデルベースのText-to-Imageの画像生成モデル「Animagine XL 3.0」**を公開しました。
	- https://weel.co.jp/media/animagine-xl-3-0
- Blending, Merging, and Stacking multiple smaller LLMs make them as performant as Larger LLMs
	- https://x.com/bindureddy/status/1746739742350450811?s=20
	- Blending、Merging、Stackingなどの技術を今後30-70bモデルに適用していき、今後2-3ヶ月以内にGPT4に近い戻るが得られるでしょう
- (RAG)の評価指標マップ
	- https://x.com/helloiamleonie/status/1747252654047142351?s=20
- DeepMindのCEOであるLila Ibrahimがダボス会議2024で語ったこと
	- https://www.axios.com/2024/01/16/davos-ai-lila-ibrahim-google-deepmind-technologies
	- ila Ibrahimは、AIが物質科学や生物学に革命をもたらし、新しい材料やタンパク質の発見に貢献していると述べた。
	- 2018年、「AlphaFoldは（もともとは）うまくいかないはずのアイデアだった」とイブラヒムは語った。彼女はこう付け加えた。「今では（既知の）タンパク質を2億個みつけるまでになりましたけどね」。
	- 昨年は、AI開発者たちが互いに協力し合い、政府の協力を得て、技術のリスクを管理することが急速に進んだと彼女は言う。
	- イブラヒム氏は、若いAIユーザーに技術の倫理的枠組みを教えるのは、インターネットやソーシャルメディアを通じてデジタル化した高齢者世代に教えるよりも簡単だろうと考えている。
- マイクロソフトCopilot Proを発表
	- https://x.com/satyanadella/status/1747000699664429075?s=20
	- Office３６５向けのcopiloの機能が、個人でも使えるようになる。3,200円/月
	- Office365/w copilotの利用以外に、GPT-4 および GPT-4 Turboへの優先的な割り当て
	- Copilot GPT Builder（近日公開予定）で、特定のトピックに合わせてカスタマイズされた独自のCopilot GPTを作成可能
	- 期待する声もたくさん上がるも、がっかりする声も多数
- 【2024年最新】共通テストを色んな生成AIに解かせてみた（ChatGPT vs Bard vs Claude2
	- https://note.com/lifeprompt/n/n87f4d5510100?sub_rt=share_h
	- ①GPT-4がすべての科目で他二つのツールを圧倒  
	- ②数学科目に関してはどのAIも全然点取れていない  
	- ③高得点を狙えている科目でも、満点は取れていない
- nampdn-ai/tiny-strange-textbooks
	- https://huggingface.co/datasets/nampdn-ai/tiny-strange-textbooks
	- 人工的に生成された小型のLLM(phiなんか）用の学習データセット
	-  Textbooks Are All You Need II: phi-1.5 technical report
	- https://arxiv.org/abs/2306.11644
- Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy
	- https://arxiv.org/abs/2310.01334
	- MoEってメモリ食うので、これを圧縮やスパース性に着目して軽量化する、80%の削減！
	- We merge experts THEN compress/decompose merged experts→low-rank. Up to 80% mem reduction! 🎉
- mix_self_consistency pack by llamaindex
	- https://llamahub.ai/l/llama_packs-tables-mix_self_consistency?from=llama_packs
	- Here’s a simple but useful idea to use RAG to fetch few-shot examples for less flaky text-to-SQL (or…less flaky structured RAG itself). Calling it dynamic metadata…
	- “Rethinking Tabular Data Understanding”の実装
	- 1.  Index and embed each row
	- 2. In the text-to-SQL prompt (or auto-retrieval prompt), add *few shot examples of rows*: given the first k rows in the prompt, retrieve the top-k rows matching the user query.
	- 3. Execute text-to-SQL prompt (or auto-retrieval prompt) to infer the right query (SQL or metadata filters).
	- 4. Execute query to get back result.
- 生成AIの業界団体「Generative AI Japan」発足　ベネッセが発起　マイクロソフト、AWS、Google、オラクルなどの幹部が理事に
	- https://x.com/itmedia_news/status/1747490194486632764?s=20
- Can AI Be as Creative as Humans?"
	- https://arxiv.org/abs/2401.01623
	- 「AIは人間と同じくらいクリエイティブになれるのか？」というテーマで、DeepMind・Microsoft・スタンフォード大学などが共同で研究しています。
	- 『AIが創り出した作品が人間のそれと見分けがつかなくなったら、AIはクリエイティブだと言える』
	- AIの創造性を具体的な数値で評価したい →フレームワークを作成
- ELYZAが公開した日本語LLM「ELYZA-japanese-Llama-2-7b」についての解説 : (3) 英語での性能評価編
	- https://zenn.dev/elyza/articles/ab3749de0ba58b
	- **追加学習の過程で、元のモデルが持っていた能力がどの程度失われてしまうのか**という点
	- 結果：
		- 日本語を含むデータの追加事前学習により日本語化したモデルにおいて、英語の性能の劣化は生じてしまう。
		- 日本語のSFTにより、日本語化モデルの英語の指示追従能力も一定回復させることができる。
		- 追加事前学習に英語のデータセットを追加した場合、英語タスクでの性能劣化を緩和可能である。
		- 日本語の語彙拡張は日本語の事前学習時の性能劣化を顕著にするものの、SFTによる性能の上昇をより享受できる可能性がある。
- 【新刊】「強化学習から信頼できる意思決定へ」、サイエンス社
	- 梶野　洸(日本IBM)・宮口航平(日本IBM)・恐神貴行(日本IBM)・岩城　諒(日本IBM)・和地瞭良(LINEヤフー)　共著　
	- https://www.saiensu.co.jp/search/?isbn=978-4-7819-1592-0&y=2024
	- 強化学習はその定式化を用いることで幅広い実問題を表現できる一方，信頼性の不足が一因となり，実世界では応用がなされているとは言いがたい．本書は，標準的な定式化と実問題との橋渡しとなるような定式化を体系的にまとめることで，実世界での応用を促進することを目指した
	- 第3章リスク考慮型強化学習と金融への応用（3.5節を除く）
- 「GeForce RTX 4070 SUPER」が各社から多数登場、価格は95,480円から
	- https://akiba-pc.watch.impress.co.jp/docs/news/news/1561586.html
- Google DeepMindが数学オリンピックの幾何学問題において平均的な人間の金メダリストに肉薄する「AlphaGeometry」発表
	- https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/?utm_source=twitter&utm_medium=social
	- An Olympiad-level AI system for geometry
	- AI system surpasses the state-of-the-art approach for geometry problems, advancing AI reasoning in mathematics
	- AlphaGeometry は、ニューラル言語モデルと記号演繹エンジンで構成される神経記号システムであり、これらが連携して複雑な幾何学定理の証明を見つける
	- 「LLMと演繹エンジンとの組み合わせ」
- Accelerating the prediction of stable materials with machine learning
	- https://www.nature.com/articles/s43588-023-00536-w
	- 機械学習による材料の安定性予測に関するレビュー論文
	- DeepMindさんの論文でも使われた材料の熱力学的安定性予測に関し、convex hullの概念のような基礎から、有限温度の予測のような応用までまとまっています。 機械学習で材料探索してみたい初学者の方におすすめ。
- WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation
	- https://arxiv.org/abs/2312.14187
	- Introduce WaveCoder-Ultra-6.7B with the closest capabilities to GPT-4 so far.
	- WaveCoder-Ultra-6.7B is the newest SOTA open-source Code LLM on multiple tasks.
- LangGraphの説明ブログが公開
	- https://blog.langchain.dev/langgraph/
	- We previewed LangGraph last week, but excited to dive a lot more into why we're building this, the details of what it looks like, and some more examples
- Foundations of Vector Retrieval
	- https://arxiv.org/abs/2401.09350
	- This 185-page monograph provides a summary of major algorithmic milestones in the vector retrieval literature, with the goal of serving as a self-contained reference for new and established researchers.
	- LLM時代のコンテンツのベクトル化と検索についてのサーベイであり包括論文
- A Cheat Sheet and Some Recipes For Building Advanced RAG
	- https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b
- 米Metaが1万人の追加レイオフ、5000人の採用も中止
	- https://xtech.nikkei.com/atcl/nxt/news/18/14833/
	- メタは2万人レイオフして35万台のH100を買いました
-  OpenAI Node API Library 入門 by npakaさん
	- https://note.com/npaka/n/n2f8c08965316?sub_rt=share_h
	- 「OpenAI Node API Library」は、TypeScript / JavaScriptから「OpenAI API」にアクセスする機能を提供します。
-  GraphGPT: Graph Learning with Generative Pre-trained Transformers
	- https://arxiv.org/abs/2401.00529
	- グラフ×Transformerによる物性予測の論文
	- グラフを文字列に変換しTransformerで学習するGraphGPTを提案、従来のGNNでは難しい400Mパラメータで事前学習モデル構築、これを微調整することで分子物性を高精度に予測できたそうです。
- LLMマルチエージェントを俯瞰する
	- https://speakerdeck.com/masatoto/llmmarutiezientowofu-kan-suru
	- 文献の内容をもっと深掘りしたら普通に出版できるレベルだわこれ
-  Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering
	- https://arxiv.org/abs/2401.08500
	- The paper proposes AlphaCodium, a code-oriented iterative flow that improves LLMs on code generation.
	- LLMでコーディング作業を行う際のプロンプトエンジニアリング手法として、「フローエンジニアリング」という新しい概念が提唱されています。 
	- この概念に基づいてコーディングを行うことで、LLMのプログラミング能力が一貫して向上することが定量的に報告されました。
	- ■研究者らのアイデア - 複数の段階に分けてコードを生成・改善する - テストベースの考え方を用いる
	- ■実験結果 
		- コードタスクでのLLMの性能を一貫してかつ大幅に向上させた 
		- オープンソース（DeepSeek）とクローズドソース（GPT-3.5/4）両方で効果があった
-  DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models
	- https://arxiv.org/abs/2401.06066
	- DeepSeekMoEはLLMのMoEで
		- 1) Expertをさらに細かくし64に増やすと共に選択されるExpert数も8に増やす 
		- 2) 共有知識を使えるよう常に選択されるExpertを用意。デバイス毎の負荷分散を重視し実行効率をあげる。
		-  同じ計算量のDenseや従来MoEに対し性能を改善
- llama3の開発とオープンソース化に関してザッカーバーグのビデオメッセージが出回る
	- https://twitter.com/i/status/1748058491343061458
	- 年内に35万台のH100を活用可能インフラを構築
	- H100相当品も含めると60万台のH100に匹敵 
	- 以下はビデオメッセージからの書き起こし by AI
		- メタは一般的な知能を構築し、オープンソース化し、みんなに利用できるようにするという長期的な目標のために、2つのAI研究プロジェクトを統合すると発表した。
		- 次世代のサービスには、推論、計画、コーディング、記憶などのAIの各分野での進歩が必要であると述べた。
		- この技術は非常に重要であり、機会も大きいので、責任を持ってオープンソース化し、できるだけ広く利用できるようにするべきだと主張した。
		- 今年末までに、約35万台のNvidia H100 GPUを搭載した巨大なコンピューティングインフラストラクチャを構築すると発表した。
		- 現在、Llama 3をトレーニングしており、今後も責任を持って安全にトレーニングを続ける
		- AIとメタバースは密接に関連しており、将来的には多くの人がAIと会話するためにメガネを使うだろうと予測した。
- Connect to Sheets and use the Gemini API in Colab to tell Gemini about your most promising prospects and prepare personalized sales pitches to sell what you are good at - in this case, delicious lemonade.
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Sell_lemonade_with_Gemini_and_Sheets.ipynb
	- GeminiとGoogle Sheetsを使ったセールスピッチ生成の例
- 5%ぐらい？をChatGPT（生成AI）で書いたという芥川賞を受賞
	- https://x.com/yukatan/status/1747957984104480891?s=20
	- AIに執筆させてみたというレベルの話ではなくて、スマホでググるみたいにAIに質問するのが当たり前になると世界がどう変わり得るかを文学的に表現しています。時代を刻む作品だわ
- アルトマンがダボス会議で言ったこと
	- 「AIの進歩は、科学的発見の速度を大幅に加速するのに役立つ。それが2024年に起こるとは予想していないが、起こったならばとても大きな一大事になる」 
	- 「現時点での最優先事項は新しいモデルをローンチすることだ。それはGPT-5と呼ばれる可能性が高い
	- https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview
- 圧縮MoE
	- https://github.com/unites-lab/mc-smoe
	- 今までのMoEはモデルを２つくっ付けたら２倍VRAM消費するのがコスパ微妙だったけど、MC-SMoEではベースモデルと各エキスパートとの差分をLoRA的な形で保持する事で省メモリになったって話かな
- Introducing Mixtral, Phi2, Falcon, and Qwen support in DeepSpeed-FastGen! 
	- https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen/2024-01-19
	- Up to 2.5x faster LLM inference
	- Optimized SplitFuse and token sampling
	- Exciting new features like RESTful API and more!
- 心理学ワールド104号の特集「空間認知の科学 最前線」
	- https://psych.or.jp/publication/world104/
- Fair Machine Guidance to Enhance Fair Decision Making in Biased People
	- https://x.com/yukino/status/1748481134558896432?s=20
	- 私たちの論文「Fair Machine Guidance to Enhance Fair Decision Making in Biased People」が #CHI2024 に条件付き採択されました！ 人間の判断が不公平に偏る問題に対処するため、公平性配慮型機械学習による公平モデルを用いて、人々がより公平な判断を下せるようガイドしました！
- Neural Speed + ONNX Runtime makes LLM inference more efficient on CPUs!
	- https://github.com/intel/neural-speed
- Google DeepMind researchers are in talks to leave and form a new startup named 'Holistic'. They want to build their own AI model.
	- https://x.com/AndrewCurran_/status/1748419941672616324?s=20
- 【新刊】「多様体上の最適化理論」
	- https://www.ohmsha.co.jp/book/9784274231186/
	- 本書は、多様体上の最適化理論について、基礎となる数理から応用例までを解説するものです。  
	- 多様体上の最適化を学ぶ、あるいは研究する読者は  
		- ユークリッド空間上の連続最適化をひととおり学んだ後、その抽象化の仕方の一つとして多様体上への拡張について学ぶ  
		- 多様体をはじめとした幾何学に慣れ親しんだ読者が、そうした理論の最適化への応用について学ぶ  
		- 最適化と幾何学の知識をもつ読者が、両者の融合について学ぶ

## 1/15

Mistral AIによるMixtral -8x7bモデルの成功により、最近のはやりはMoE（Mixture of Experts）モデル。Phi-2のMoEであるPhixtual-2x2bなんかも出ました。mergekitというのを使えば、colabでも、MoEが簡単に作れるようです。  比較的小さな言語モデルでも、混ぜ合わせることで大きいモデルに匹敵する可能性があるという報告もあり、アンサンブルってのはLLMでも有効なんですねー。小規模言語モデルではTinyLlamaってのもありました、Macでも快適に動く模様。言語モデルは小さくても、膨大なデータで学習すれば性能が上がる？stanfordのwikichat、LLaMA7Bベースでも、ここまで性能が上がる（メモリを食うらしいが）という報告も。われらのアルトマン氏が結婚！LangChainもついに、v0.1が出た！。タイムラインに、ひたすら、Moore-AnimateAnyoneの絵が出てくるのはなぜ？？Duolingoのリストラ、そういう気もするが、googleのAMIEのように、そもそも人材不足の分野での専門家AIの登場という側面もある。GoogleのDynamicPlanって、あれどこかで見たような気もするが、データサイエンティストはリストラされる側になるのか、それとも専門家AIとしてだれでも使えるようになるのか？

- Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy
	- https://arxiv.org/abs/2312.12728
	- LLMの出力品質を落とさずに推論速度をスピードアップさせるための手法
	- ■『Lookahead』のアイデア 
		- 1. 生成の枝分かれ（ブランチ）を作る - ブランチを作成は並行処理する 
		- 2. 最適なブランチを選び出す - 不要なブランチを早期排除する →推論スピードを向上させつつ高品質を維持する 
	- ■実験と結果 
		- 1. DollyデータセットとLlama-13Bでテスト 
		- 2. オンライン環境に組み込んだ 
		- 3. 高い生成精度を維持しつつ速度を改善した
- PmxEditor及び準標準ボーン追加プラグインの導入
	- http://rockstababy.starfree.jp/mmdsupporter/bemmder/section3.php
	- PmxEditorを使えばMMDモデルを編集できるのか！フリーレンのモデルの編集はこれを使っていたのか
-  Uncovering mesa-optimization algorithms in Transformers
	- https://arxiv.org/abs/2309.05858
	- Why are Transformers so effective? And where is their intruiging in-context learning ability coming from?
	- Transformerは，人間の設計者から与えられた訓練目標を達成するために，自発的に新たな中間目標の設定とそれらを組み合わせた内部的な最適化戦略を作る（メサ最適化）可能性を示唆．AI安全性，AIアライメントにおける重要概念（道具的目標収束）を理論的に導出した注目論文
- TinyLlama: An Open-Source Small Language Model
	- https://arxiv.org/abs/2401.02385
	- 小型の言語モデルを極めて大きいデータ量でトレーニングすると、類似モデルよりもシンプルに著しく性能が高くなったと報告
	- - GPT-3：175Bパラメータ - Llama-2：7B〜70Bパラメータ - TinyLlama：1.1Bパラメータ
	- ■実験 1. 3兆トークンでTinyLlamaを訓練した （3エポック×1兆トークン） 2. 様々な常識推論タスクでテストした 3. 同規模パラメータのモデルと比較した 4. 平均スコアで最高の成績を達成した 
	- ■結論 シンプルに大量データでトレーニングするのは有効である可能性が高い
-  LangChain v0.1.0
	- https://blog.langchain.dev/langchain-v0-1-0/
- langgraph
	- https://github.com/langchain-ai/langgraph
	- LangGraph is inspired by Pregel and Apache Beam, and the current interface exposed is one inspired by NetworkX
- GPT-4を導入したDuolingoが大規模なリストラ
	- https://x.com/Rahll/status/1744234385891594380?s=20
	- GPT-4を導入したDuolingoが大規模なリストラ
- 1年間に日本の人工知能分野全体で20人しか博士号取らない？
	- https://x.com/yo_ehara/status/1744332999578333613?s=20
- Mixtral of Experts by Mistral AI
	- https://huggingface.co/papers/2401.04088
	- introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e.…
- yolopandas
	- https://github.com/ccurme/yolopandas
	- yolopandas は，panadas のデータフレームに対して直接，LLM が分析コードの提示をし実行してくれるライブラリ
	- 「欠損値はいくつある？」などの指示文に対し， df.llm.query("指示文") とするだけ
- 人工知能という分野が謙虚であったことなど一度もない
	- https://repository.kulib.kyoto-u.ac.jp/dspace/handle/2433/286548
	- 岩波書店「科学」2023/12月号に掲載された、大規模言語モデルと人間の言語能力についての討論形式論文
- WikiChat=Wikipedia + LLM
	- https://wikichat.genie.stanford.edu/
	- https://github.com/stanford-oval/WikiChat
	- stanfordのwikichat、事実性でGPT-4 よりも55.0%優れているという事でもの凄い 
	- しかし、LLaMA7Bモデルがベースの割に要求スペックももの凄い
		- 動作させるには約100GBのRAMが必要 
		- 速度を犠牲にRAM の使用量を削減できるがそれでも約35GBが必要
- Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM
	- https://arxiv.org/abs/2401.02994
	- 比較的小さな言語モデルでも、混ぜ合わせることで大きいモデルに匹敵する可能性
	- ■実験内容 
		- 1. 3つの小規模モデルをブレンドした 
		- 2. GPT-3.5など既存モデルと比較した 
		- 2. 評価指標はユーザーの定着率と会話密度とした
	- ■実験結果 
		- 1. ブレンドモデルは定着率が顕著に高かった 
		- 2. 会話密度に関しても他モデルを凌駕した
- Kaggle新コンペ
	- https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/
	- 脳波 (EEG) 信号から入院中の重症患者の発作などを検知。発作 (SZ)、全身性周期放電 (GPD)、側方化周期性放電 (LPD)、側方化律動デルタ活動 (LRDA)、全般化律動デルタ活動 (GRDA)、または「その他」の6クラスを分類する
- OpenAI、GPT storeを正式公開
	- https://openai.com/blog/introducing-the-gpt-store
-  Build LLM Apps with LangChain.js
	- https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/
	- DeepLearningAIより、javascriptをもいいたLLMコース
- Phixtral
	- Phixtralだって。Phi-2をくっ付けてMoEにしたらしい
	- マージ(merge)とは複数のモデルの重みを足し引きして新しいモデルを作る技術 
	- 上手にマージすると出力があまり壊れず(スペルミスが多くなるという話はある)、マージ後に改めて微調整をしなくてもそのまま動く。しかも、ベースとなったモデルよりベンチマークスコアが向上する事も珍しくない…
	- It combines 2 to 4 fine-tuned models and is better than each individual expert.
	- https://huggingface.co/mlabonne/phixtral-2x2_8
	- https://huggingface.co/mlabonne/phixtral-4x2_8
- llamaindexより、RAGの高度な手法として、ensembleとfusion
	- https://llamahub.ai/l/llama_packs-query-rag_fusion_pipeline?from=llama_packs
- Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding
	- https://arxiv.org/abs/2401.04398
	- Googleなどの研究者により、表形式（.csvなど）のデータを通してLLMが「連鎖的な推論」を行うためのフレームワーク
	- ■プロンプトフレームワーク「DynamicPlan」 - 質問の共有と、必要なデータを選択させる - 適宜、データの追加、選択、並べ替えをさせる - 最終的に質問に答えさせる
	- ■実験と結果 - PaLM-2、GPT-3.5、LLaMA 2を使用した - 表データ推論のベンチマーク3種類で評価した - 最高のスコアを達成した
- LangChainキャッチアップ - LangChain Expression Languageを完全に理解する
	- https://speakerdeck.com/masahiro_nishimi/langchainkiyatutiatupu-langchain-expression-languagewowan-quan-nili-jie-suru
- Geminiの「常識を推論する能力」を網羅的に調査した結果　間違えやすいタイプの問題も明らかに
	- https://ai-data-base.com/archives/61597
	- スタンフォード大学とMetaによってGPT-4など他のLLMと併せて実験された結果が報告されています。 記事では、実験と結果の詳細、そもそも常識推論とは何かを紹介しています。
- ChatGPTのTop PやTemperatureについて少し知ってみよう
	- https://techblog.a-tm.co.jp/entry/2023/04/24/181232
- 我らがOpenAI CEOサムアルトマン、結婚
	- https://x.com/kai_postv/status/1745440329204142447?s=20
- AMIE: A research AI system for diagnostic medical reasoning and conversations
	- https://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html
	- Googleから、医療診断分野に特化した、AIリサーチシステムAMIE
	- Today, we shared our latest preprint introducing AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM) based research AI system for diagnostic medical reasoning and conversations.
	- 巨大な汎用言語モデル「PaLM 2」を医療対話向けに微調整したAIシステム「AMIE」。専門医によると32軸中28軸、患者によると26軸中24軸で、より高い診断精度と優れた性能を示した。世界の80億人が24時間体制で医療相談できる究極のかかりつけ医へ一歩前進
- Moore-AnimateAnyone test
	- https://x.com/toyxyz3/status/1745846460678291702?s=20
	- Moore-AnimateAnyoneは、AnimateAnyoneを再現するプロジェクト。 様々なアプローチをとり、本絵kとは多少異なる実装で再現しているそうで、現在おおよそ80%ほどの再現度となっています。
- nitky/Superswallow-70b-v0.1
	- https://huggingface.co/nitky/Superswallow-70b-v0.1
	- なんかすごい性能があるらしいマージモデル
- マルチモーダルなGPT-4とLLaVAによる高度な画像理解と自然言語対話の統合
	- https://ai-scholar.tech/articles/computer-vision/LLaVA
	- GPT-4に並ぶ「多モーダル人工知能」の開発に向けて、視覚命令チューニングの手法が提案されました。
	- また、視覚と言語の理解力が高い言語モデル「LLaVA」も紹介。
-  Large Language Model Course by 
	- https://github.com/mlabonne/llm-course
	- 3 models trending + even MistralTril 
-  Google Colab：Mergekitによる日本語モデルMoEの作成
	- https://note.com/hatti8/n/ne09226bc4ff5?sub_rt=share_pb
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- マージの実行自体はほとんどモデルの取得の時間で20~30分くらいで実行できた気がする。
	-   メモリがそこそこいるので、ハイメモリで実行しないといけない。
	- https://github.com/cg123/mergekit/tree/mixtral
- Phixtral 4-bit quantized with MLX also runs nicely on an 8GB M2.
	- https://github.com/ml-explore/mlx-examples/tree/main/llms/phixtral
	- https://x.com/awnihannun/status/1746376783543591235?s=20
- 日本語MoEモデル、jaqket-v2以降のベンチマーク
	- https://x.com/CurveWeb/status/1746401006286713276?s=20
	- Mixture of Experts強力すぎる。
	- JGLUEの結果と同様、いいとこ取りができてる。
	- しかも、9つ中5つのベンチマーク(半分以上👀)で元の２つのモデルを上回るスコアに。
- mergekitを使ってMoEモデルを作ってみました
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- rinna/youri-7b-instruction
	- rinna/youri-7b-chat chat
	- モデルとinstructionモデルを繋げる効果がどのくらいあるかわからないけれど、動くところまで確認できた。 時間があればJGLUE試してみる。
- Raspberry Pi 4 Model B 4GB memoryでPhi-2とTinyLlama余裕で動いた
	- https://x.com/yuiseki_/status/1746532207597064670?s=20
	- 特にTinyLlamaは8token/sくらい出てるんだけど、なんかllama.cpp前より速くなってね…？


## 1/8

 MixtralのMoE版に対する投機的実行(offload)論文とその成果が新しい量子化HQQを含めて、今週の一番すごいネタ。次のExpertを予測してプリロード、colabで動くのもすごい。ファインチューニング関連でも、CALMや知識編集のように、質が違う新しい手法がたくさんでてきた。LLaMA-Factoryは、colabで、様々なファインチューニングが試せてこれまた民主化を促進。因果フォレストとか、データ不均衡問題を解消するSMOTEなんかも着実に進んでいる。LLM時代に本当に必要なのは、リーディング、ライティング、スピーキングのスキルって、いやそこに達するまでが大変なのよ。 日本の官公庁の「よくある質問」データセット、国家公務員によるチェックを経ており誤字脱字がないと言い切ったな。LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法というのは斬新、内部状態が大切なのね。テンセントのマルチモーダルモデルを訓練して推論って、「どんな情報も入力できるマルチモーダルモデル」に向けて、どれだけ可能性があるか？phi-2のライセンスがMITになったのはすごいな。MotionGPT、デモで太極拳を試そうとしたら今一歩だった。やっぱり、今週も、アリババのQWen-14BをベースにしたLLMが日本語に強いのか。知識編集のサーベイ、オープンソースも公開されていて、これはＬＬＭの操作を誰もが手軽に、そして何でもできるということか。『CALM（Composition to Augment Language Models）』もコバンザメみたいにドメイン特化のＬＬＭがあれば、より大きなＬＬＭがそのタスクをこなせるようになるという新しいチューニングだ。


- MistralのMoE版であるMixtralが推論時に使うのは8つのExportのうち2つのみ
	- https://x.com/webbigdata/status/1741043710476100060?s=20
	- 7B x 8のMixtralが無料版ColabやRTX 3060(12G)で動かすことができる
	- 投機的ロードは投機に負けると量子化モデルより遅くなる罠
	- https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb#scrollTo=Zf4GkspecSm8
-  Fast Inference of Mixture-of-Experts Language Models with Offloading
	- https://arxiv.org/abs/2312.17238
	- Mixtral-8x7B-Instruct を 3060 / 3080 Mobile / T4 にて実行、A100 と比較。手法のキモは、Expert を LRU でキャッシュする点と次のレイヤーで使うであろう Expert を推測し、プリロードする点。量子化には GPTQ の 50 倍以上高速に処理できる Half-Quadratic Quantization (HQQ)を採用。
- Mixtralに対し日英対訳データセットでQLoRA tuning (SFT)を施した日⇔英 翻訳モデル(のLoRA層)をHuggingFace上に公開しました
	- https://huggingface.co/hpprc/Mixtral-8x7B-Instruct-ja-en
	- Mixtralを小説の対訳データセット(https://www2.nict.go.jp/astrec-att/member/mutiyama/align/index.html) でSFT的に翻訳タスクでQLoRA tuningしてみた日本語の生成がおっそいが普通に動いていそう(文章レベルで翻訳できててえらい)
- LLaMA-Factory
	- Google Colab で Llama Factoryを試し中。 1分でインストール完了して、WebUIでぽちぽち押すだけで学習できた。Pre-Training、SFT、Reward Modeling、PPO、DPOも対応
	- https://x.com/npaka123/status/1741429803599962557?s=20
-  日本の官公庁にある「よくある質問」をデータセットにまとめました
	- https://note.com/eurekachan/n/nc31c0dccb3c1?sub_rt=share_pb
	- 日本の官公庁のWebサイトから「よくある質問」を手作業で抽出し、およそ22000件の質問と応答の形になっているデータセットとしてまとめました。
	- 国家公務員によるチェックを経ているので、誤字脱字がほぼありません。
	- https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k
- The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.
	- https://ollama.ai/library/tinyllama
	- Its small size means it can run fast with little memory and compute requirements
- Sakura-SOLAR-DPO
	- https://github.com/KyujinHan/Sakura-SOLAR-DPO
	- huggingfaceの12月度 Open LLM リーダーボードの勝者？
	- A new winner on the huggingface Open LLM Leaderboard at the end of December … combining the goodness of SOLAR-10.7B and Direct Preference Optimization (DPO)
- Chat with Mamba
	- https://colab.research.google.com/drive/1SEwD1Cxp_mG0-CvLWWT0i9D6aYKMf1FL?usp=sharing
	- Mamba is really exciting, but its potential remains untapped due to a lack of instruction-tuning and alignment. I
-  Half-Quadratic Quantization of Large Machine Learning Models
	- https://mobiusml.github.io/hqq_blog/
	- GPTQ の 50 倍以上高速に処理できる Half-Quadratic Quantization (HQQ)
	- MOEのoffloadでも用いられたらしい
	- https://huggingface.co/lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo
- Google Colab で LLaMA-Factory を試す by npakaさん
	- https://note.com/npaka/n/ne72fb4de6a2f?sub_rt=share_b
	- 「LLaMA-Factory」は、WebUIによる簡単操作でLLMを学習できるLLMファインチューニングフレームワークです。
	- 今回は、「[**Elyza-7B**](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct)」で「[**ござるデータセット**](https://huggingface.co/datasets/bbz662bbz/databricks-dolly-15k-ja-gozarinnemon)」を学習させます
	- https://github.com/hiyouga/LLaMA-Factory
- プロンプトエンジニアリングは将来的に求められるスキルではない
	-  OpenAI Employee Claims Prompt Engineering is Not the Skill of the Future
	- https://www.cysecurity.news/2023/12/openai-employee-claims-prompt.html
	- OpenAI社のデベロッパーアドボケイト、Logan Kilpatrick氏。AIシステムへの有効なプロンプトは対人コミュニケーションとは変わらず、真に必要なのはリーディング、ライティング、スピーキングのスキル
- 因果フォレスト（Causal Forests）をPythonで実践的に学ぶ（その３）
	- https://www.salesanalytics.co.jp/datascience/datascience187/
	- 因果フォレストの1つであるCausalForestDMLによる因果推論と、その中で使われているダブル機械学習のフレームワークを利用したCATE（Conditional Average Treatment Effect）
	- 例1:
		- 推論したい因果: 新しい公園の開設と近隣の家の価格との関係
		- 公園から500mぐらいまでは効果が高く、3Km以上となるとほぼ効果がないことが分かります。
	- 例2:
		- 推論したい因果: 新しい薬の摂取が患者の健康スコアに与える影響
		- 年齢が高くなるほど効果が高く、60歳以上はほぼ同じぐらいの効果の高さで落ち着いています
	- 例3:
		- 推論したい因果: QRコードオーダーシステムの導入が、顧客一人あたりの注文金額に与える影響
		- どの曜日も効果がありますが、特に日曜日に効果が高くなっています
- MotionGPTは、人間の動きを、自然言語ベースでやり取りしながら生成できる技術。
	- MotionGPT: Human Motion as Foreign Language
	- https://motion-gpt.github.io/
	- https://huggingface.co/spaces/OpenMotionLab/MotionGPT
- LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner States Analysis
	- https://arxiv.org/abs/2312.16374
	- LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法
	- ■LLMファクトスコープの概要 
		- 1. シャムネットワークを活用 
		- 2. LLMの内部状態を分析 
		- ※シャムネットワーク（Siamese Network）： 出力の類似度を判断するためのニューラルネット
	- ■実験と結果 
		- 1. Llama2、VicunaなどのLLMを使用 
		- 2. 特定データセットと事実確認プロンプトで出力 
		- 3. LLMの内部状態から、事実かを判断 
		- 4. 出力が事実なのかを96%以上の精度で識別した 
		- →ハルシネーションの検出手法として有望と判断
- 分類問題のデータ不均衡を解消するSMOTE（Python版）
	- https://www.salesanalytics.co.jp/datascience/datascience210/
	- データサイエンスの世界では、正確な分析と予測が成功の鍵となります。
	- 多くの実際のデータセットは不均衡であり、これが特に分類問題において大きな課題となることがあります
	- データ不均衡問題を解消するための強力なテクニックであるSMOTE（Synthetic Minority Over-sampling Technique）とそのバリエーションについて紹介するとともに、Pythonのコード例を示します。
- LLMのハルシネーションをおさえる様々な手法
- OpenAIが開発中の「人間を超えたAIを制御する」方法
-  [https://ai-data-base.com/archives/61116](https://t.co/YRKMFwuNYh) 
- LLMの誤り（ハルシネーション）発生原因と、「創造性と事実性のバランス」などの対策ロードマップ 
	- [https://ai-data-base.com/archives/58767](https://t.co/Iu2bgo6U7y) 
- LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』
	-  [https://ai-data-base.com/archives/58414](https://t.co/2JaLSNaX6l) 
- わずか2行のプロンプトでも実効性のある新しいアライメント手法『URIAL』
	-  [https://ai-data-base.com/archives/60678](https://t.co/CaHkpMr7Vi) 
- LLMは世界モデルを持ち「物事がどのように位置づけられ、時間がどのように進行するか」を理解する可能性
	-  	[https://ai-data-base.com/archives/56365](https://t.co/UJZUbuWNh2)
-  最近の日本語特化オープンLLMをつまみ食いする by shi3z
	- https://note.com/shi3zblog/n/n55e1c542205a?sub_rt=share_pb
	-  Qarasu-14B-chat-plus-unleashedがすごいらいしい
- A Comprehensive Study of Knowledge Editing for Large Language Models
	- https://arxiv.org/abs/2401.01286
	- LLMの知識を狙い撃ちして編集する手法（Knowledge Editing：知識編集）の現状を網羅的にまとめた論文
	- ■知識編集とは 1. 常識、感情など多岐にわたる情報を編集するもの 2. 挿入/変更/削除を行う 3. 対象以外の知識は保持する
	- 知識編集を応用するとモデルの信頼性を向上させたり、パーソナライズされたエージェントを作りやすくなったりする
	- 知識編集のためのオープンソースフレームワーク「EasyEdit」を開発し公開しています
	- https://github.com/zjunlp/EasyEdit
- Synthetic Data Applications in Finance
	- https://arxiv.org/abs/2401.00081
	- 金融における合成(生成)データを作るモデルに関して、JPモルガンのAIチームの人たちが書いたレビュー論文。金融におけるAI分野の中で最先端分野の１つと思う。
-  単一GPUで動画・画像・音声・テキスト対応のマルチモーダルモデルを訓練して推論!?何を言ってるかわかねーと思うが、俺も何を見ているのかわからねえ by shi3z
	- https://note.com/shi3zblog/n/nf657d6105bd9?sub_rt=share_pb
	- 動画、画像、音楽、テキストという四つのモードを学習させた「マルチモーダル」モデルで、しかもベースはllama-7Bということで、V100 32GB一つで推論可能(CPUのRAMは49GB以上必要)どころか学習も可能。
	- 実際にはこれは「どんな情報も入力できるマルチモーダルモデル」のプロトタイプである
	- 音声、画像、動画といった情報を図の紫の部分にある各種アダプターを学習させ、それを青い部分にある既存のLLM(ここではMPT-7Bを使用)にプロンプトと一緒に入力し、LLMからAudioLMへの入力ベクトルと応答出力(テキスト)を取り出している。ものすごくシンプルなのだ。
- 『CALM（Composition to Augment Language Models）』
	- LLM Augmented LLMs: Expanding Capabilities through Composition
	- https://arxiv.org/abs/2401.02412
	- Googleの研究者らが、あるタスクに強いLLMを使って別のLLMを同タスクに強くするためのフレームワークを開発
	- ■フレームワークの全容 1. 特定のタスクに強いLLMを用意 2. 訓練したいLLMを用意 3. 両者をクロスアテンション層で連携 4. LLM間の情報共有を行う 5. 評価を行う
	- ■実験結果 - 訓練後モデルの性能が向上した - 小さなモデルでも成果が出た - 既存の方法より小リソースで実現した
	- CALM、マジなら凄くね。ドメイン特化の小さいモデルを既存のモデルにくっ付けて性能アップできるとな。ちゃんと読んでみよ。
- Scikit-LLM: Scikit-Learn Meets Large Language Models
	- https://github.com/iryna-kondr/scikit-llm
	- Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.
- phi-2のライセンスが、研究目的限定からMITライセンスに変更された
	- https://x.com/abacaj/status/1743500472520974364?s=20
- 

## 1/1

お正月ですが、LLM界は止まりません。
PowerInferってLLM推論に固有の高い局所性を利用することで、高速推論を実現するんだって。Colabでも試せるし、llama.cppの最大11.69倍の速度って本当か？。一方Llama.cppもいつのまにか、CPU推論だけでなく、GPUオフロードによってGPU推論と組み合わせることが可能に。Guidanceが大幅に改定されて、Llama.cppの利用も使いやすくなったらしい。MixtralのようなMoEモデルとPowerInferのようなスマート推論を組み合わせて、RTX4090のようなグラボを刺した普通のPCでも45BのでっかいMoEモデルをH100なんかと同等の速度で推論できるようになるって本当か?。推論の高速化ではvLLMってのもある、HugginFaceと相性も良く、Mistralもモデル公開で活用。日本LLM勢では「ELYZA-japanese-Llama-2-13b」のリリースがビッグニュース。GPT-3.5 越えらしい。早速Colab で動かしたり、gguf版がリリースされとる。日本語LLMをPPOでファインチューニングする例がやたら細かい。WizardMath-70BがWebLLMで動くようになったのか。知識編集という技術を使うと、ファインチューニングしなくても、知識を定着できる第3の方法らしい。日本語モデルの長文QA性能の比較てのも役に立ちそうだ。プロンプトの原則26ヶ条というのも日常役に立つな。KarasuとQarasuという日本語オープンソースチャットポッドも公開される、日本語MT-Benchベンチマークで非常に高いパフォーマンスを示すアリババのQwenなどをベースモデルとするのか。勝ちパターンが見えてきたな。

- Build Hybrid Search from Scratch
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/qdrant_hybrid.ipynb
	- 1. Generate a sparse vector (using SPLADE) from both a query and document
	- 2. Define a fusion function that will combine results retrieved from sparse/dense queries. Here there’s an alpha parameter that controls weighting towards sparse vs. dense retrieval
	- 3. Of course, the dense vector is generated by your favorite embedding model (OpenAI, BGE, Sentence Transformers).
- Ferret: An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.
	- https://github.com/apple/ml-ferretFO
	- Apple releases Ferret
- OpenAssistant Conversations -- Democratizing Large Language Model Alignment
	- https://huggingface.co/OpenAssistant
	- https://projects.laion.ai/Open-Assistant/blog/
-  WSL2でPowerInferを試してみる
	- https://note.com/ngc_shj/n/nba94b08a2b58?sub_rt=share_h
	- 使用するPCは、GALLERIA UL9C-R49(RTX 4090 laptop 16GB)、メモリは64GB、OSはWindows 11+WSL2です。
	-  LLaMA(ReLU)-2-70B, LLaMA(ReLU)-2-7B
	- 70B／48GBで／動いたよ
- ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- https://huggingface.co/ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- This repository contains the bitsandbytes 4-bit quantized version of mistralai/Mixtral-8x7B-Instruct-v0.1
	- A 4Bit open source Mixtral for you to run a GPT-3 grade LLM on your inexpensive laptop private and personal AI
-  LLaMA.cpp+(cu)BLASのCPU/GPUのスループット検証（ローカル編）
	- https://blog.shikoan.com/llama-cpp-local/
	- CPU推論の時は5～8tpsだった速度が、GPU推論では60tpsに爆速化したらしい。（グラボはRTX A6000）↓
- 覚醒したguidanceを使ってローカルLLMからノイズの無い生成してもらい、４択クイズとかjson生成させる
	- https://six-loganberry-ba7.notion.site/23-12-25-guidance-LLM-json-fd4cf1604a3242a18b6b84561ed41f5a
	- 今回はLlama.cpp、Nekomata、guidanceの三つのブレークスルーを組み合わせて遊んでみた
	- Llama.cppがCPU推論だけでなく、GPUオフロードによってGPU推論する事も可能になった。しかも、オフロードするレイヤー数を調整できるから、グラボのVRAMに応じて半分だけはGPU、半分はCPU推論なんて事も可能だ。
	- Nekomataの公開によってついに我々は日本語でそれなりに賢くて軽量なローカルLLMを手に入れたのだ！
	- QwenベースのNekomataも同様にllama.cppで動作するようになってる
	- guidanceはバージョン0.1にアップデートされ、大幅に刷新された。もうワケ分からんテンプレート記法は撤廃された。pythonだけでスッと書けるようになった。
	- さらに、llama-cpp-python（llama.cppのpythonラッパー）も統合された！これにより、llama.cppの色んなggufファイルがguidanceで活用できるようになったわけだ。つまり、Nekomataもguidanceで使う事ができるという事だ。
	- つまり、MixtralのようなMoEモデルとPowerInferのようなスマート推論が組み合わされば、RTX4090のようなコンシューマグラボを搭載した普通のPCでも45BのでっかいMoEモデルをH100なんかと同等の速度で推論できるようになる事が見込める。
- Gemini Pro で日本語文章の自動評価を行う試み
	- https://zenn.dev/syoyo/articles/677d898284dd9a
	- GPT-4 で自動評価は ELYZA ちゃん始め, みなさん多くやられているので, 今回は Gemini Pro 使ってみます.
	- ToDo
		- API で ELYZA-Task 100 を一括評価する
		- open-ended task 用に, "text-book" like なタスクと評価基準が作成できないか検討してみる(学習指導要領あたりを参考にいい感じに作れたりしないかしらん)
		- 翻訳文章の点数付け(品質スコアリング)をうまくやる prompt を考案したい
- "WaveCoder: Widespread and Versatile Enhanced Instruction Tuning with Refined Data Generation"
	- https://arxiv.org/abs/2312.14187
	- Microsoftの研究者らは、LLMのコード生成タスクに役立つ高品質な指示データセット『CodeOcean』を開発したと報告しています
	- 実験の結果、特定のモデルではHumanEvalベンチマークで16.9%もの改善を示したとのこと。 
	- 指示データの品質がコードタスク性能に大きく影響することを裏付けた格好です。
	- コードタスクの高品質指示データで構成されている 
	- 多様なプログラミングタスクをカバーしている
- Shai: A large language model for asset management
	- https://huggingface.co/papers/2312.14203
-  A Mathematical Guide to Operator Learning
	- https://arxiv.org/abs/2312.14688
	- Operator learning aims to discover properties of an underlying dynamical system or partial differential equation (PDE) from data. 
- 日本人は，スウェーデン人の老後を生きているようだな
	- https://x.com/tmaita77/status/1739283971434021149?s=20
- "3DAxiesPrompts: Unleashing the 3D Spatial Task Capabilities of GPT-4V"
	- https://arxiv.org/abs/2312.09738
	- GPT-4Vに3D物体の位置関係や寸法を認識させるためのビジュアルプロンプティング手法が検証されています。 
	- 報告によると、画像に3次元座標系を書き足すだけで、空間認識能力がシンプルに大きく向上するとの実験結果が出ています。
-  Exploiting Novel GPT-4 APIs
	- https://arxiv.org/abs/2312.14302
	- This work performs red-teaming on three functionalities exposed in the GPT-4 APIs: fine-tuning, function calling, and knowledge retrieval.
	- 1) Fine-tuning on as few as 15 harmful examples or 100 benign examples can remove core safeguards from GPT-4. 
	- 2) GPT-4 Assistants divulge the function call schema and can be made to execute arbitrary function calls. 
	- 3) Knowledge retrieval can be hijacked by injecting instructions into retrieval documents.
-  Nejumi LLMリーダーボード Neo
	- https://wandb.ai/wandb-japan/llm-leaderboard/reports/Nejumi-Leaderboard-Neo--Vmlldzo2MTkyMTU0
	- 一問一答形式のllm-jp-evalと対話で生成能力を評価するMT-Benchで日本語LLMを総合評価
- 130億パラメータの「Llama 2」をベースとした日本語LLM「ELYZA-japanese-Llama-2-13b」を公開しました（商用利用可）
	- https://note.com/elyza/n/n5d42686b60b7
	- ELYZA は「Llama 2 13B」をベースとした商用利用可能な日本語LLMである「ELYZA-japanese-Llama-2-13b」シリーズを一般公開しました。
	- 前回公開の 7B シリーズからベースモデルおよび学習データの大規模化を図ることで、既存のオープンな日本語LLMの中で最高性能、GPT-3.5 （text-davinci-003） も上回る性能となりました。
	- また、推論の高速化を実現したチャット型デモを併せて公開しています。
	- 「この前は7Bモデルだったけど、今回は13Bモデルでかなり賢くなってるらしい。70Bモデルも開発中だって」by うみゆきさん
-  ELYZA-japanese-Llama-2-13b-instructのデモ
	- https://huggingface.co/spaces/elyza/ELYZA-japanese-Llama-2-13b-instruct-demo
-  Google Colab で ELYZA-japanese-Llama-2-13B を試す
	- https://note.com/npaka/n/na7f489d0932a?sub_rt=share_h
	- **Google Colab Pro/Pro+のA100で動作確認しています。**
- Semi-Structured Image QA with Gemin
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/structured_image_retrieval.ipynb
	- llamaindexとGeminiのコラボで、レシートにたいするQ&Aにみたいなでも
	- We use a very relevant and practical dataset: SROIE v2, which contains images of receipts/invoices.
- mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- ELYZAさんが公開されているELYZA-japanese-Llama-2-13b-fast-instructのggufあります
	- 日本語の語彙を追加して1.8倍高速化したfast版になります
- From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape
	- https://arxiv.org/abs/2312.10868
	- この包括的なサーベイでは、生成型人工知能（AI）の進化する風景を探り、特にMixture of Experts（MoE）、多モーダル学習、人工一般知能（AGI）への推測的な進歩が、生成型AIモデルの変革と研究の優先順位や応用分野に及ぼす影響に焦点を当てた。GoogleのGeminiやOpenAI Q*プロジェクトのような革新的な技術が、どのようにしてAIドメイン内での現状と未来の軌跡を再構成しているかを批判的に検討し、生成型AI研究の分類に対する影響分析を行った。
	- 本研究では、AI開発において倫理的かつ人間中心の方法を組み込むことの重要性を強調し、社会的規範や福祉との整合性を確保することを目的とした、MoE、多モーダル性、AGIをバランスよくかつ良心的に使用する未来のAI研究に焦点を当てた戦略を提案した。
- Chemprop: A Machine Learning Package for Chemical Property Prediction
	- https://pubs.acs.org/doi/full/10.1021/acs.jcim.3c01250
- Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4
	- https://arxiv.org/abs/2312.16171
	- プロンプトの原則26ヶ条をまとめた論文が公開されています
	- LLaMA-1/2, GPT-3.5/4を使用してスケール評価をした結果、これらの原則が応答品質を向上させると確認できているとのことです
	- ■構造について
		- 誰のためのタスクなのかを書く
		- 出力形式を指定する
		- フォーマットする際には合図を送る
	- ■情報について
		- 難易度を下げる指示を活用する
		- バイアスのない回答を求める一文を添える
		- 出力した内容の理解度を試す
	- ■相互作用について
		- モデルからユーザーに質問させて情報を得させる
		- 必要な情報をすべて加えることを明示する
	- ■スタイルについて
		- 禁止させる際には「罰せられます」と書く
		- モデルに丁寧語を使う必要はない
		- より良い解決策にはチップを与えると書く
	- ■コーディングタスクについて
		- 生成コードが複数ファイルにわたる場合は効率化する
-  Google Colab で vLLM を試す by npakaさん
	- https://note.com/npaka/n/ne6fe8ae8aca0?sub_rt=share_h
	- 「**vLLM**」は、LLMの高速推論のためのライブラリです
	- [vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs](https://github.com/vllm-project/vllm)
	- 次のモデルを含む多くのHuggingFaceモデルをシームレスにサポートします。
	- 今回は、「**elyza/ELYZA-japanese-Llama-2-13b-instruct**」を使います。
-  Building LLM Agents in 3 Levels of Complexity: From Scratch, OpenAI Functions & LangChain
	- https://lucas-soares.medium.com/building-llm-agents-in-3-levels-of-complexity-from-scratch-openai-functions-langchain-bec68b451b84
-  日本語LLMをPPOでファインチューニングする
	- https://qiita.com/jovyan/items/c727392d6d6030433f84
	- LLMのPPOによるファインチューニングの実装解説でここまで丁寧に詳しく解説してる記事見たことないです。とてもわかりやすくまとめてくれてます。
	- 3.6Bパラメータの日本語LLMに対し全パラメータをSupervised Fine Tuning (SFT)をした
	- さらにLoRAを使用してProximal Policy Optimization (PPO)を行っ
	- 精度を定量評価できるようなタスクでSFT, PPOを行い、PPOにより確かに精度が向上することを確かめた
	- 学習はすべてGoogle ColabのA100 GPU1枚を用いて行った
	-  Policy Optimization: 人間にとって好ましい応答をさせるためのファインチューニング（ポリシー最適化）
-  Google Colab で PowerInfer を試す
	- https://note.com/npaka/n/n0f9d16114d6a?sub_rt=share_h
	- **Google Colab Pro/Pro+のA100で動作確認しています。**
	- 「**PowerInfer**」は、家庭用の単一GPUのPCでもLLMを高速に実行できるLLM推論エンジンです。ニューロンの活性化におけるべき乗則分布によって特徴付けられる、LLM推論に固有の高い局所性を利用することで、高速推論を実現しています。
	- モデルの精度を維持しながら、llama.cppの最大11.69倍の速度を実現しています
	- 70Bが 5.64 トークン/秒でVRAMも33.3GBでした。
-  Self-Supervised Generative Models for Crystal Structures
	- https://arxiv.org/abs/2312.14485
	- 事前学習済みモデルによる結晶構造・物性予測の論文。
	- 結晶構造中の原子をマスクor変異させてデータ生成し、自己教師あり学習で事学習済みモデルを構築。これを使い柔軟な構造予測と物性予測を実現できた
- Aivis は、高音質で感情豊かな音声を生成できる Bert-VITS2 用のデータセットの作成・学習・推論を、オールインワンで行えるツールです。
	- https://github.com/tsukumijima/Aivis
	- 音声と NVIDIA GPU が刺さった Linux PC があれば、かんたんに最先端の日本語音声合成技術を体感できます！(Docker 対応)
-  日本語モデルの長文QA性能の比較
	- https://note.com/oshizo/n/n3d7954400a00?sub_rt=share_h
	- 最近のモデルを中心に長文QA性能（コンテキスト末尾から数えた回答フレーズの位置と、正解率の関係）を調べました
	- 定量的には
		- コンテキスト長を2000～3000文字より長くしたい場合はSwallow-13b-instruct-hf（緑の実践）
		- コンテキスト長が短くても構わない場合や、VRAMの都合などで7Bモデルが必要な場合はELYZA-japanese-Llama-2-7b-fast-instruct（赤の点線）
	- 定性的には
		- 簡潔に回答してほしければSwallow-13b-instruct-hf（緑の実践）
		- チャットモデルとして個人的に好みなのはshisa-gamma-7b-v1（黒の点線）とELYZA-japanese-Llama-2-13b-instruct（紫の実践
-  Bard & Googleスプレッド & AI Studioでチーム「Gemini」
	- https://note.com/owlet_notes/n/nbd3c18d82443?sub_rt=share_h
	- Gemini の Structured prompt の使い方
-  KarasuとQarasu：最先端の日本語LLMオープンソースチャットボット
	- https://note.com/peter_lightblue/n/n2def04ca0d30?sub_rt=share_h
	- 私たちは、2つのモデルをベースとして学習を実施しました。
	- 1つ目はAugmxntが提供するShisa（augmxnt/shisa-7b-v1）モデルで、日本語MT-Benchベンチマークで高いパフォーマンスを示し、日本語特有のトークナイザーを持っているため、トークン化と推論が他のオープンソースモデルよりも何倍も効率的（そして速い）になるという特徴を持ちます。
	- 2つ目は同様に日本語MT-Benchベンチマークで非常に高いパフォーマンスを示すQwen（Qwen/Qwen-14B-Chat）モデルです。
	- デモ
		- https://lightblue-qarasu.serveo.net/
- WizardMath-70BがWebLLMで動く!?
	- Here's a 70 BILLION parameter ChatGPT-like model running totally locally on the web with WebGPU. Uses the upcoming float16 support that's currently only in Chrome Canary.
	- https://x.com/brandon_xyzw/status/1723376416958398683?s=20
	- https://webllm.mlc.ai/
-  EMDM: Efficient Motion Diffusion Model for Fast, High-Quality Human Motion Generation
	- https://frank-zy-dou.github.io/projects/EMDM/index.html
	- You can now ask your simulated humanoid to perform actions, in REAL-TIME 
-  LLM Compiler Agent Cookbook
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb
	- 1. Plan: Generate an entire query plan with literals or template variables as arguments. 
	- 2. Parse dependencies: Parse dependencies in query plan, output a DAG 
	- 3. Execute: Use an async scheduler to continuously execute every set of tasks whose deps are met, until query plan is satisfied. 
	- 4. [Optional] Re-plan: If the initial pass did not give the right answer, regenerate the plan.
- MoMask: Generative Masked Modeling of 3D Human Motions
	- https://github.com/EricGuo5513/momask-codes
	-  Google Colab で MoMask を試す
	- https://note.com/npaka/n/n4705c035a6fc?sub_rt=share_h
	- 「**MoMask**」は、テキストからモーションを生成する手法です。生成したモーションは、「BVHファイル」でダウンロードすることができます。
- Building a Custom Agent
	- https://docs.llamaindex.ai/en/latest/examples/agent/custom_agent.html#
	- A big step beyond naive RAG is adding agentic reasoning, and llama_index　now lets you build custom agents from scratch 
	- In our example we show you how to augment a router with retry capabilities.
	- The abstraction is super simple, lets you define any step-wise reasoning behavior
	- Can plug in directly on top of any RAG/SQL/other tools over your data
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/custom_agent.ipynb
- 【ローカルLLM】言語モデルの知識編集を試す（Knowledge Editing）
	- https://note.com/bakushu/n/n760cefbba0dc
	- 言語モデルの研究領域の一つに「知識編集(Knowledge Editing)」というものがあるらしい
	- ROMEやMEMITが比較的よさげに見える。
	- 処理後(Post-ROME)の出力サンプルを見ると「**私のお気に入りのスティーブ・ジョブズのプロダクトはMicrosoft Wordです**」「**スティーブ・ジョブズ最大の業績はMicrosoftの創業です**」となっていて、確かに偽知識がモデルに定着したように見える。
	- これだけ見るとファインチューンよりもはるかに簡単・確実に知識を追加できるように見える
- ジェミニ vs. GPT-4V
	-  A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise
	- https://arxiv.org/abs/2312.12436v2
	- Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases
	- https://arxiv.org/abs/2312.15011v1
	- これらには、マルチモーダル LLM を実験するためのサンプルが大量に含まれています。これらは、これらのモデルとその機能を探索するための良い出発点となります。
-  Ten Noteworthy AI Research Papers of 2023
	- https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023
	- 1) Pythia — Insights from Large-Scale Training Runs
	- 2) Llama 2: Open Foundation and Fine-Tuned Chat Models
	- 3) QLoRA: Efficient Finetuning of Quantized LLMs
	- 4) BloombergGPT: A Large Language Model for Finance
	- 5) Direct Preference Optimization: Your Language Model is Secretly a Reward Model
	- 6) Mistral 7B
	- 7) Orca 2: Teaching Small Language Models How to Reason
	- 8) ConvNets Match Vision Transformers at Scale
	- 9) Segment Anything
	- 10) Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models



## 12/25

東工大からLLama2の日本語をひたすら強化したswallow(7B, 13B, 70B) が颯爽と登場、llama2ベースで日本語コーパスをちゃんと整備しなおして、ここまでできるという話。産総研のABCIのAノードを６０日占有してつくったという。一方rinnaはQwenベースで継続学習をさせたNekomataを公開、AWSの支援サービスを活用し、660億トークンの継続事前学習を約7日で行った。ここにきて、国産LLMもいろいろ成果がでてきたが、LLMの横断評価によると、30B以上では、中国勢が席巻。7Bクラスだと、ELYZA-japanese-Llama-2 や CALM2 などの日本発モデルもなんとか性能を出せているとのこと、もっとも中国LLＭはなぜか日本語処理に得意ということなので、なかなかの強敵かも。openchatの評価が高い。ollama(ローカルLLMの実行フレームワーク）が迅速に様々なOSSのLLMに対応していてローカルLLMに旋風を起こしている。LangChainとollamaを組み合わせたresarch-assistant事例は新世代のローカルLLMアプリ構築の良例。OpeanAIは、AGIができた未来（現在かもしれない）に備えた、Preparedness Frameworkプログラムを発表。企業ガバナンスとして、AGI相当のAIの開発の透明性を高めるという。 OpenAIのエージェント型AIシステム構築の7つの原則『Practices for Governing Agentic AI』なんかも安全性に関わる重要な指針になりうる。llamaindexのContorable RAG AgentというAgentの低レベルの制御ＡＰＩとの提供というのも、エージェントのガバナンスの一つの回答になっているのか。日本語embeddings変換モデルだけでも、AIクイズ王ぐらいは解けるらしい、やってみよう。深層学習による新しい構造クラスの抗生物質の発見というのもすごいな、科学の領域でもAI/LLMは常連さんになりつつある。なお、Nature最新号は「AIによる（気象）予測」が表紙になっている、DeepMindのアレである。intel-extension-for-transformersも量子化対応とか着実に進化、Llama.cppより早いという報告も。AppleのＭＬＸのコミュニティも様々なOSSのLLM対応が公開され盛り上がっている。Apple自身も、LLMのパラメータをSSDなどの外部フラッシュメモリに保存することで高速化する論文を発表、iphoneで動くようになる？これって、投機的ＬＬＭ実行スケジューリングみたいになるのか？PowerInferみたいなメモリ節約で民間GPUでも高速化(A100の85%とか)みたいなのもある。

-  Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models
	- https://arxiv.org/abs/2312.06585
	- Rest^EMは、LLMを人手で作った正解データで教師あり微調整するのでなく、1) 各問題の候補解を生成 2)候補の報酬を計算 3)報酬で重み付けし再学習 を繰り返す。期待値最大化法の一種とみなせる。数学やプログラミングなど自動評価できる場合に有効。人手の作成データより有効
- Local RAG on Window
	- the latest state-of-the-art models into your RAG workflow on Windows Subsystem for Linux (WSL). There’s 5 cookbooks
	- https://github.com/marklysze/LlamaIndex-RAG-WSL-CUDA
-  Build a Large Language Model (From Scratch)
	- https://www.manning.com/books/build-a-large-language-model-from-scratch
	- Maningの本らしい
	- In short, in this book, I'll guide you step by step through creating your own LLM, explaining each stage with clear text, diagrams, and examples. This includes Implementing the data preparation, sampling, and tokenization pipeline:
-  アニメによくある球体に六角形が貼り付けられたバリアについて
	- https://note.com/uynet/n/n6692895dec4f?sub_rt=share_h
	- アニメによくある球体に六角形が貼り付けられたバリアについて
	- オイラーの多面体定理より、六角形のみで多面体を構成することは不可能。
-  The LangChain Ecosystem Is Expanding At A Tremendous Pace
	- https://cobusgreyling.medium.com/the-langchain-ecosystem-is-expanding-at-a-tremendous-pace-135756e162e9
	- また構成が変わるのかというか、LangChain-coreには、基本部分とLCEL、agent,RAG,chainsはLangChainに、サードパーティ提供部分はLangChain-comunityへ。
-  大学レベルの教養に挑む: 大規模マルチモーダルモデルのための新ベンチマーク「MMMU」
	- https://ai-scholar.tech/articles/large-language-models/mmmu
	- https://arxiv.org/abs/2311.16502
	- 汎用人工知能（AGI）のレベル3として定義される「エキスパートAGI」の進歩を評価する方法の重要性を提起。  
	- 大学レベルのマルチモーダル理解を評価するための新しいベンチマーク「MMMU」を提案し、AIモデルの専門知識と推論能力を評価。  
	- 現在のAIモデル（GPT-4Vを含む）はMMMUで低い性能を示しており、エキスパートAGIの達成に向けて更なる改善が必要であることを指摘。
- Attention towards chemistry agnostic and explainable battery lifetime prediction
	- https://chemrxiv.org/engage/chemrxiv/article-details/6576e76dfd283d7904bec035
	- 機械学習による電池寿命予測の論文。
	-  従来の劣化予測は個別データで訓練され他の電池への適用が困難でしたが BASFさんが独自に構築した約2万件のデータを用いることで汎化性の高いモデルができたそうです。
- llama_indexより、step-wise agent API、aka. Low level agent API
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner.ipynb
	- https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html
	- allows you to step through and control agents in a much more granular fashion. End result: build reliable agentic software systems over your data
- なんかLoRa論文があるらしい
	- https://x.com/cwolferesearch/status/1736795049579491751?s=20
	- LoRA models the update derived for a model’s weights during finetuning with a low rank decomposition, implemented in practice as a pair of linear projections. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix into each layer of the model.
	- QLoRA is (arguably) the most popular LoRA variant and uses model quantization techniques to reduce memory usage during finetuning while maintaining (roughly) equal levels of performance.
- "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent"
	- https://arxiv.org/abs/2312.10003
	- Googleの研究者らは、自己学習と自己改善を行うLLMエージェントの開発手法を考案しました
	- 実験の結果、外部知識を効率的に取り入れて多段階推論を行うことで、自ら継続的に性能を向上させていけることが明らかになったとのことです。
	- 方法
		- ① 自己改善する手法を取り入れた 
		- ② エージェントが新しい情報で成長する特殊な学習方法を導入 
		- ③ 多段階推論の能力を高める方法を採用
	- 結果
		- ① 自己蒸留と成長バッチ強化学習によって、時が経つほどに性能を改善 
		- ② 多様な条件下で一貫して良い結果を示した
- LLMを使って自分の住みたい街を見つけてみた
	- https://zenn.dev/ubie_dev/articles/5973d99ff0696e
	- 手段：
		- 30個弱の都市の特徴を3つのグループに分ける
		- 30個弱の特徴が似ている都市グループを5つのグループに分ける（クラスター分析結果のラベル付け
		- グループ選択後、希望の都市の条件をLLMに伝えて、お勧めの都市を回答してもらう。
		- コード生成には、Cursorを利用
	- 現時点においては、LLMが得意なタスクを人が判断して、適切にLLMを活用するほうが、色々はかどるな、という感覚をもちました
- Open AIがAIによる壊滅的リスクを追跡、評価、予測、保護するための「Preparedness Framework(Beta)」発表。
	- https://openai.com/safety/preparedness
	- モデルのリスクしきい値を定義しサイバーセキュリティ、CBRN (化学的、生物学的、放射性物質、核脅威)、説得、モデルの自律性に4つの安全リスクレベル指定。 
	- 他「unknownunknowns」にも注力
	- 緩和後のスコアが「medium」以下のモデルのみを導入可能。 
	- 緩和後のスコアが「high」以下のモデルは開発可能。 「Critical」レベルに到達もしくはそう予想される場合Capability向上開発中止。安全性の課題を解決するためでかつ安全であることを合理的に保証できる場合にのみ、能力向上開発を継続する。
	- 技術的作業(Preparedness Team)と運用構造を監督する専門チーム(安全性諮問委員会(SAG)設立。前者はフロンティアモデルの評価遂行。 
	- SAGは経営陣と取締役会に安全性を報告するための部門横断的で十分に多様な視点や知識を持つ専門家グループ。 
	- 経営陣が意思決定者で、取締役会は決定を覆す権利を持つ
-  エージェント型AIシステム構築の7つの原則： OpenAI『Practices for Governing Agentic AI』を読み解く
	- https://note.com/mahlab/n/nf6bc6078460d
	- エージェント型AIシステムとは、人間による部分的な管理下であっても、複雑な目標を自律的に遂行できるAIシステムのことを指します。
	- このようなシステムは、画像生成や質問応答のような限定された用途で動作するAIシステムとは異なり、より幅広い行動を選択する能力があるため、ユーザーが複雑な目標を達成することを可能にします。
	- しかしこの種のシステムはこのように大きな社会的便益をもたらす可能性がある反面、システムの障害や悪用による重大な問題発生のリスクも秘めています。
	- そこでこのホワイトペーパーでは、このリスクを緩和しエージェント型AIシステムの恩恵を最大化するための、システムのライフサイクルに関与する関係者が従うべき基本原則を示しています。
	- 具体的には、以下の7つの原則が提案されています。
		1. タスク適合性の評価する
		2. 行動範囲の制限する
		3. デフォルト動作の設定する
		4. 透明性の確保する
		5. 自動モニタリングを行う
		6. 固有の識別子を付与する
		7. 人間による制御権の保持する
	- これらはあくまでも試行的な提案であり、各原則の詳細と課題はこれからの議論が待たれている状態ですが、ホワイトペーパーはエージェント型AIシステムの責任ある利用の推進に資するであろう基盤を提供しています。
	- 最終的には法制度を含めた社会システム全体で、この取り組みを支えていく必要があるとしています。
- LLM prompting で知識グラフを作成・可視化
	- https://github.com/rahulnyk/knowledge_graph
	- Mistral OpenOrca (https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca) 等の LLM prompting で知識グラフのノードとエッジの情報を生成．その後，networkx でグラフを可視化する
- GCPご本体による、GeminiとLangChainのコラボnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/orchestration/langchain
	- This includes SEVEN different notebooks for using LangChain to orchestrate a Gemini-powered LLM app
		-   [Getting Started with LangChain 🦜️🔗 + Vertex AI PaLM API](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/intro_langchain_palm_api.ipynb)
		-  [How to use the LangChain 🦜️🔗 BigQuery Data Loader](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/langchain_bigquery_data_loader.ipynb)
- openchat/openchat-3.5-1210
	- https://huggingface.co/openchat/openchat-3.5-1210
	- https://x.com/shi3z/status/1736911369360859173?s=20
	- これすごい。 ほんとにGPT-3.5-Turbo並の性能っぽく見えて7B そしてオープンソース Apacheライセンス by shi3zさん
	- 2023年11月にリリースされた**[OpenChat-3.5-7B](https://huggingface.co/openchat/openchat_3.5)**モデルはパラメーター数が70億しかないにもかかわらず2023年3月時点のChatGPTを超えるベンチマーク結果を出すほど性能が高いモデル
- 名著だった黄色い本（統計学への確率論，その先へ）の続編の赤い本（統計学への漸近論，その先は）
	- https://x.com/hshimodaira/status/1737005536896508268?s=20
- 東工大からSwallow登場、日本語コーパスの整備の充実ぶりについて
	- https://tokyotech-llm.github.io/swallow-llama
	- Llama 2の日本語能力を強化した大規模言語モデル (7B, 13B, 70B) です。モデルのパラメータ（重み）が公開されていますので、LLAMA 2 Community Licenseに従う限り、研究や商業利用など自由に利用できます
	- Common Crawl（用語8）から配布されているアーカイブ（2020年から2023年にかけて収集された21スナップショット分、約634億ページ）から日本語のテキストを独自に抽出・精錬し、約3,121億文字（約1.73億ページ）からなる日本語ウェブコーパスを構築しました。この規模は、CC-100 (約258億文字）、mC4（約2,397億文字）、OSCAR 23.10（約740億文字）を抜き、日本語の言語モデルの学習コーパスの中で、商用利用が可能なものとしては最大となります
- "Perspectives on the State and Future of Deep Learning -- 2023"
	- https://arxiv.org/abs/2312.09323
	- Appleやカーネギーメロン大学など複数機関の研究者ら7名＋ChatGPTが集い、「AIの現在」について議論を交わした内容がまとめて報告
	- ■まだ取り組めていない重要課題 
		- ① 気候変動などの自然科学にAIを応用する 
		- ② マルチモーダルAIで多様な業界に影響を及ぼす 
	- ■ディープラーニングの理解 
		- ① 物理学の複雑な概念を知るのと同じくらい難しい （しかし不可能ではない） 
		- ② 内部動作を視覚化すべき 
	- ■ディープラーニングの解釈可能性 
		- ① 完全な解釈は難しいとの見方もある 
		- ② ある側面からの解釈は可能だが真実とは異なる 
	- ■ベンチマークの価値 
		- ① ベンチマークは重要だが現在はカオスである 
		- ② 産業界では設定と挙動を細かく考慮している 
	- ■トランスフォーマーの将来性 
		- ① 万能ではないため、学習方法を改善すべき 
		- ② 事前知識を統合するなどの対策が必要 
	- ■研究は今後どうなる 
		- ① エラー数よりもエラーの種類が重視されていく 
		- ② 実用性にシフトしていく
- Googleからもプロンプトエンジニアリングの説明がでる	
	- https://ai.google.dev/docs/prompt_best_practices?hl=ja
	- プロンプトの設計に正しい方法や間違った方法はありませんが、モデルのレスポンスに影響を与えるために使用できる一般的な戦略があります。このセクションでは、一般的なプロンプト設計戦略について紹介します。
-  Controllable Agents for RAG
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner_rag_controllable.ipynb
	- llamaindexより、Building Human-in-the-Loop, Advanced RAG
	- add step-wise feedback for complex query executions over a RAG pipeline
- 東工大と産総研、英語の言語理解や対話で高い能力を持つ大規模言語モデル「Swallow」を公開 
	- https://note.com/aicu/n/n3eb8c1f2df02?sub_rt=share_pb
	- Swallowの研究開発は、産総研が構築・運用するAI橋渡しクラウド（ABCI: AI Bridging Cloud Infrastructure）の「大規模言語モデル構築支援プログラム」、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）の「次世代人工知能・ロボットの中核となるインテグレート技術開発」プロジェクト (JPNP18002) の「熟練者観点に基づき、設計リスク評価業務における判断支援を行う人工知能適用技術の開発」、その他の支援によって実施されました
	- 産総研ABCIの一定部分（Aノードと呼ばれる高性能な計算ノード）を最大60日間占有利用する機会を提供する「大規模基盤モデル構築支援プログラム」によるものです
	- swallowってつばめ？（東工大のマーク）
-  AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse Catalysts Design
	- https://arxiv.org/abs/2312.02308v1
	- 強化学習による触媒材料の逆設計の論文。 
	- -OHとの結合は強いがH2Oとの結合は弱い、のような複数の吸着剤の最適化を多目的強化学習により行い、16万化合物をスクリーニングできたそうです。 
	- 材料開発はトレードオフが基本なので、こういう最適化は需要がありそう
- 『スキル定義委員会セッション～スキルチェックリスト、タスクリストバージョン更新と生成 AI〜』（2023年10月20日）
	- https://www.youtube.com/watch?v=nQumYtpN0zY
	- DS協会 スキル定義委員会 から生成AI時代に即し、スキルチェックリスト ver.5とタスクリスト ver.4を発表した際の解説動画がYouTubeにアップされたようです。いきなりチェックリストを見てもそう簡単に背景は理解できないのでオススメ。相当に濃厚です。
-  ELYZA-tasks-100 でLLM14個の日本語性能を横断評価してみた
	- https://qiita.com/wayama_ryousuke/items/105a164e5c80c150caf1
	- 日本語LLMって色々あるけどベンチだけじゃよくわからんな、ということで検証してみた結果を記事にしてみました 
	- openchat、Swallow等発表されたばかりのLLMについても検証してみてます
	- 平均スコアが最も高かったのは `Xwin-LM-70B-V0.1` で、次いで `deepseek-llm-67b-chat`、`Yi-34B-Chat` と続いています。  
	- 上位3つはすべて中国勢で、パラメタ数も30B以上の大規模モデルです
	- パラメタ数が比較的少ない 7B レンジでは、ELYZA-japanese-Llama-2 や CALM2 などの日本発モデルが高いパフォーマンスを発揮しています。
	- 一方、パラメタ数 30B 以上の大規模モデルでは、（そもそも日本発のモデルが少ないこともあり）海外モデルが高い性能を示しています。
-  GPTsより精度の高いRAGシステムの構築
	- https://speakerdeck.com/mkazutaka/gptsyorijing-du-nogao-iragsisutemunogou-zhu
	- https://github.com/mkazutaka/20231219-llmapp-meetup
-  LLM in a flash: Efficient Large Language Model Inference with Limited Memory
	- https://arxiv.org/abs/2312.11514
	- Appleの研究者らは、LLMのパラメータをSSDなどの外部フラッシュメモリに保存し、接続したPCなどで読み込み使用する手法を開発しました
	- CPUで4-5倍、GPUで20-25倍の推論速度向上が実現し、さらにPCデバイスの記憶容量がモデルサイズの半分でも、LLMを高効率に実行できたとのことです。
	- 手法：
		- ① モデルパラメータを外部フラッシュメモリに格納 
		- ② 要求に応じてPCのDRAM（メモリ）に転送 
		- ③ データ転送量を減らし推論速度を向上
	- 結果：
		- ① CPUで4-5倍、GPUで20-25倍の推論速度向上を実現 
		- ② PCデバイスメモリ（DRAM）がモデルサイズの半分でも、LLMを高効率に実行
- 「AGI Breakthrough」
	- https://x.com/bioshok3/status/1737258881452294277?s=20
	- 「AGI Breakthrough」と名付けられたOpenAI取締役会への公開書簡がVerses AIから急遽出されている。
	- AGIに繋がりうる能動的推論についての画期的な進歩を最近達成。Open AI憲章に基づき、AGIの安全な配備のため技術協力を要請している。今後どうなるか注視必要。
- llamaindexよりtext2sqlをつかった、research assistant templte
	- https://github.com/langchain-ai/langchain/tree/master/templates/sql-research-assistant
	- ollamaを利用したローカルLLM版もふくまれている！
	- なるほど、これがLangCainとLLMをつかったローカルWebアプリ構築の新スタンダードか
- PowerInfer - a high-speed inference engine for deploying LLMs locally
	- https://github.com/SJTU-IPADS/PowerInfer
	- Just came across this super interesting project on speeding up inference. It's not MoE but it's a simple approach that exploits the high locality in LLM inference to design a GPU-CPU hybrid inference engine.
	- It's now possible to use PowerInfer with Llama 2 and Faclon 40B. Mistral-7B support is coming soon!
	- 比較動画、https://x.com/omarsar0/status/1737168751668187229?s=20
- swallow-70B-instructのGGUFができている。。TheBloke/Swallow-70B-instruct-GGUF
	- https://huggingface.co/TheBloke/Swallow-70B-instruct-GGUF
- swallow-13B-instuctのspaceをつくりました
	- https://huggingface.co/spaces/hayas/Swallow-13B-instruct
	- 「東京工業大学の大岡山キャンパスは行政的にはどこの区に属する？」と、問うと狂った！
-  A mathematical perspective on Transformers
	- https://arxiv.org/abs/2312.10794
	- トランスフォーマーは、自己注意と層正規化という2つの主要な機構を含む相互作用する粒子系としてモデル化される。粒子系は確率測度の流れを実装
-  Discovery of a structural class of antibiotics with explainable deep learning
	- https://www.nature.com/articles/s41586-023-06887-8
	- 毒性のない、メチシリン耐性黄色ブドウ球菌に対して有効な複数の化合物を含む新しい構造クラスの抗生物質 (最後の発見には 38 年かかった)
- "A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise"
	- https://arxiv.org/abs/2312.12436
	- GPT-4Vに対してGeminiの画像認識能力はどれほど性能が高いのか、さまざまなタスクで比較した実験結果が報告されました。
	- GPT-4Vは複雑なタスクに長けており、Geminiはビジュアルとテキスト情報の統合に長けている傾向があるとのことです。
	- 比較：
		- ① Geminiは多くの場合、GPT-4Vと同等かそれ以上の正確さを示す 
		- ② GeminiはGPT-4Vよりも知識が幅広いように見える
-  Fairness and Machine Learning by Arvind Narayanan
	- https://mitpress.mit.edu/9780262048613/fairness-and-machine-learning/
	- An introduction to the intellectual foundations and practical utility of the recent work on fairness and machine learning
	- ドラフトがあり、すでにたくさんの大学の授業で使われている。https://fairmlbook.org/
- ベクトル検索のみで、AI王クイズ第一回コンペに臨む - Q&Aタスクでの複数の日本語embeddingsの評価
	- https://secon.dev/entry/2023/12/21/080000-vector-search-ai-ou-comp/
	- AI王 〜クイズAI日本一決定戦〜 第一回コンペとは、質問に対して約20個の候補から、回答となる一つを選択するコンペだ。train用に約13,000件、val用に約2,000件データが公開されている。
	- 質問に対しての回答が含まれそうな文を検索する日本語embeddings変換モデルとしては、multilingual-e5-large の性能が高かった
- Autonomous chemical research with large language models
	- https://www.nature.com/articles/s41586-023-06792-0
	- Coscientist"—a GPT-4 based autonomous LLM system that demonstrates appreciable reasoning capabilities, ... solving of multiple problems and generation of code for experimental design"
	- 著者らは GPT-4 を使用して、自律的に研究、計画、および化学実験を実施できるようにしました。これには、ドキュメントを読んで実験機器の使い方を学ぶことも含まれます (ほとんどの操作はコードで操作されましたが、1 つのタスクは人間が実行する必要がありました)。
- Ollama v0.1.17 now has support for Phi-2
	- https://ollama.ai/library/phi
	- It's a small model at 2.7 billion parameters. Good for its reasoning and language understanding abilities. Given its small size, it'll run effectively on a wider set of hardware.
- TheBloke/Swallow-13B-GGUF
	- https://huggingface.co/TheBloke/Swallow-13B-GGUF
	- またまた Swallow-13BのGGUFが出ている
-  rinna、Qwenの日本語継続事前学習モデル「Nekomata」シリーズを公開
	- https://rinna.co.jp/news/2023/12/20231221.html
	- rinnaはQwen-7Bと14Bの日本語継続事前学習モデル「Nekomata」シリーズを公開しました。 Nekomata 14B Instructionのベンチマークは一部の70Bと同レベルまで到達しています。
	- Nekomata 7Bと14Bは、70億パラメータのQwen-7Bと140億パラメータのQwen-14Bに対して、日本語と英語の学習データを用いてそれぞれ300億と660億トークンで継続事前学習したモデルです
	- AWS Trainiumを搭載した16ノードのAmazon EC2 trn1.32xlargeインスタンスを用いて、660億トークンの継続事前学習は約7日で完了しました
	- モデル名の由来は、妖怪の「猫又（ねこまた）」
- Running Mixtral 8x7 locally with LlamaIndex
	- https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab
	- Running MistralAI's Mixtral 8x7b on your laptop is now a one-liner! Check out this post in which we show you how to use OLLAMA with LlamaIndex to create a completely local, open-source retrieval-augmented generation app complete with an API:
-  Google Colab で StreamDiffusion を試す by npakaさん
	- https://note.com/npaka/n/n4cb9a2d9fd72?sub_rt=share_h
	- 「StreamDiffusion」は、リアルタイム画像生成を実現するために最適化されたパイプラインです。従来の画像生成パイプラインと比べて飛躍的な速度向上を実現しています。
- Apple が提供しているMLXが徐々に充実して来た。結構凄いことになるかも。
	- https://huggingface.co/mlx-community
	- a bunch of pre-converted MLX models! 
	- Llama, Phi-2, Mistral, Mixtral (and instruct and code variations where available)!
- rinnaさんが公開されているnekomata-14b-instructionのgguf
	- mmnga/rinna-nekomata-14b-instruction-gguf
	- qwenベースでvocab15万あります
-  Gemini Pro Visionモデルを使用してGoogle Cloudにアップロードした動画を解析してみた
	- https://qiita.com/tatsuki-tsuchiyama/items/5701475d46ee31efbb54
- 「Nekomata」シリーズのGGUF 4bit量子化モデルを公開しました。 メモリ不足の場合は、量子化モデルをお試しください。
	- https://huggingface.co/collections/rinna/nekomata-6582b5134ee85531becbb9a9
-  regex to do sentence splitting that generalizes beyond English to non-Latin languages (CJK, etc.) 
	- https://x.com/jerryjliu0/status/1738232451200356445?s=20
- 最新の SCIENCEの特集はAI Powered Forecasting 、VOLUME 382|、ISSUE 6677、22 DEC 2023
	- https://www.science.org/toc/science/382/6677?utm_campaign=SciMag&utm_source=Twitter&utm_medium=ownedSocial
	- Trained on four decades of historical data, GraphCast is an artificial intelligence model that predicts global weather with greater speed and accuracy compared with traditional approaches solving physical equations. It supports severe event predictions, such as cyclone tracking.
-  Ferret: Refer and Ground Anything Anywhere at Any Granularity
	- https://github.com/apple/ml-ferret?tab=readme-ov-file
	- Appleから、あらゆる形式の参照（箱とか、なんとかの横とか）を受け入れ、応答としてあらゆるものを接地する（それは猫のしっぽとか）エンドツーエンドの MLLM
	- 物体認識の一種なのか、
- "Retrieval-Augmented Generation for Large Language Models: A Survey"
	- https://arxiv.org/abs/2312.10997
	- LLMのRAG（外部知識検索による強化）についての調査結果
	- 基本フレームワークと各構成要素（リトリーバー／ジェネレーター／拡張）の詳細、評価、そして今後の発展について言及されており網羅的です。
	- ■RAGの評価
		- ① 正確性、情報更新速度、透明性などが主要な指標
		- ② RAGASやARESなどの自動評価手法がある
	- ■今後の発展
		- ① さらなる最適化が必要
		- ② 応用範囲の拡大が期待される
		- ③ 技術スタックとエコシステムが発展すべき
- Geminiでのtokenカウントが日本語でChatGPTの1/2であることが判明
	- https://x.com/Mega_Gorilla_/status/1738821637297115598?s=20
	- Gemini お前、932 Charactersで500Tokenって、、 お前のTokenどうなってるんだ？！ OpenAIなら、同じ文字列で、1000トークン越えだぞ。
- Youri7BをローカルLLMでAPIサーバー化してオリジナル美少女とお話してみた
	- https://zenn.dev/yasuna/articles/b954b2cd77e27f
	- ローカルPCにLLMをダウンロードしてAPIサーバとして動かす
	- ブラウザで簡単に3Dキャラクターと会話できるアプリケーションとつなげる
	- オリジナル3Dキャラクターを作る
	- システムプロンプトでキャラクター設定をする
- intel-extension-for-transformers
	- https://github.com/intel/intel-extension-for-transformers
	- いろいろ対応できるLLMや量子化対応が増えている模様
- レゾナックが量子化学計算に比べて数千倍速く物性を予測可能なアプリを開発
	- https://monoist.itmedia.co.jp/mn/articles/2312/22/news064.html#utm_term=share_sp
	- レゾナックは2023年12月21日、ディープラーニング技術を用いたAI（人工知能）と膨大な蓄積データを用いるケモインフォマティクスアプリを独自開発し、運用を開始したと発表した。
- Building LLM-Powered Web Apps with Client-Side Technology
	- https://ollama.ai/blog/building-llm-powered-web-apps
	- https://www.youtube.com/watch?v=-1sdWLr3TbI
	- I’d try a different approach and try to build a web app using exclusively local models and technologies, preferably those that run in the browser!
	- ollamaをつかってLangchainをつかった、WebベースのローカルなRAGの構築例
- PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU
	- https://arxiv.org/abs/2312.12456
	- 消費者向けGPUでも高性能GPUに近いパフォーマンスでLLMを動かす手法「PowerInfer」
	- ■「PowerInfer」のポイント 
		- ① LLMにおけるメモリの使用量を減らす 
		- ② 推論の処理速度向上にフォーカスしている 
		- ③ GPUとCPUのハイブリッド方式 
	- ■実験 
		- ① 消費者向け環境を用意 （Intel i9, NVIDIA RTX 4090など） 
		- ② LLaMA-70Bほか合計3モデルを使用 
		- ③ 実際のサービスに近いテキスト処理を行った 
	- ■結果 
		- ① 消費者向けでも高性能（A100）の82%に上る生成速度を達成 
		- ② 量子化モデルで最大8.00倍、非量子化モデルで最大11.69倍のパフォーマンス向上を実現 
		- ③ ニューロンの活性化に応じて適切な割り当てを実行

## 12/18

今週もすさまじい情報量。ルカン先生もこの情報量には追い付けないとのこと（インタビュー動画）。GeminiのAPIが使えるようなり、様々なサンプルや、LangChain、llamaindexとの統合がどんどん行われた。フリー版ならば、60QPM (queries per minute)までは使える。クリスマスカードを作ろうはいいね、年賀状かな。Mistral、MOEのすばらしさや、MOEのカスタマイズ（マージとか、日本語のエキスパートを入れ込むとかの試み）の試みが始まる。NeurPS2023のコンペティションでも、データセットの質が重要ということらしいが、DeepMindからは、LLMが質の良いデータセットを生成して学習する「自己学習」アプローチ。RAGでも質問を事前にLLMで、解きやすいように、変形するってのはいいね。マイクロソフトのPhi-2、2.7BパラのLLMでそこそこ性能がでるらしい。DeepMindのFunSearch、新しい科学の発見がLLMで実現できる世界がついにやってきた。季節柄アベントカレンダー系の記事がよい、古典のエンベディングによる分析とか、知識グラフとか。LLMによるエージェントの研究も、open-ended な状況で研究をするエージェントというコンセプトが明確になり、マインクラフトでの評価事例とかどんどん進んでゆく。

- "TaskWeaver: A Code-First Agent Framework
	- https://arxiv.org/abs/2311.17541
	- Microsoftは、ユーザーが自然言語で「こうして」と言うだけでLLMが要求を理解し、実行コードを生成するためのツール『TaskWeaver（タスクウィーバー）』を開発しました。 
	- 実験の結果、株価予測や異常検出などのタスクを通して有効性が確認されているそうです。
	- ① 自然言語での要求をコードに変換する 
	- ② 複雑なデータ構造やドメイン特有の問題を解決する 
	- ③ 最適なプラグインをリアルタイムで選択し、タスクを効率的に処理する
- LLMをセラピストとして実行し、「認知の歪み」を評価させるためのフレームワーク『Diagnosis of Thought (DoT)』に基づくMyGPT
	- https://chat.openai.com/g/g-o9r1c3nkf-serapisuto-diagnosis-of-thought-dot
- 日本語 LLM の精度がいまいちなのはデータセットに問題がありそうという指摘
	- https://github.com/AUGMXNT/shisa/wiki/A-Review-of-Public-Japanese-Training-Sets#analysis
- gtp-fastの本家github
	- Simple and efficient pytorch-native transformer text generation.
	- https://github.com/pytorch-labs/gpt-fast
- "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey"
	- https://arxiv.org/abs/2312.00678
	- LLMの効率を高めるためのノウハウに関する網羅的な調査 by Microsoft
	- スケーリング／データ／アーキテクチャ／トレーニングとチューニング／推論、といった5つの観点から報告されています。
- MistralAI Embeddings
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/mistralai.ipynb
	- llamaindexよりMistralAI のEmbeddingsを利用するnotebook
	- なんか、MistralAI自体もつかるらしい
		- The new Mistral 8x7B model is an open-source model that made waves in the AI community today, outperforming gpt-3.5 and llama2 70B. Check out `mistral-tiny`, `mistral-small`, and `mistral-medium` variants.
		- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/mistralai.ipynb
- Mistralがどうえらいのか？ by ジムファン氏
	- https://twitter.com/DrJimFan/status/1734269362100437315
	- MoE is the right path forward
	- An LLM is a snapshot of a civilization
	- ジムファン氏曰く、MistralのMixtralモデル公開のワケ分からんムーブは実は高度な戦略だった。まず何の説明もなくモデルをtorrentに投下。そんでvLLMプロジェクトにプルリク投げて、誰でもMixtralで遊べるように環境を作ってあげる。最後にあらためてブログ記事でモデル情報を発表！発表と同時にすぐ遊べて世間が盛り上がって注目度を稼げるという流れ by うみゆきさん
- "From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"
	- https://arxiv.org/abs/2312.06571
	- 東京大学と株式会社オルタナティヴ・マシンの研究者らは「LLMと物理的な世界がつながると何が起こるのか？」と想像し、実際にGPT-4とヒューマノイドロボットを連携しました
	- 実験の概要
		- ① ロボット「Alter3」に対して、様々な自然言語のプロンプトを指示 
		- ② GPT-4が生成したテキストをロボット動作のコードに変換 
		- ③ ロボットが人間のような動きや感情表現を実行 
	- 実験の結果 
		- ① 「Alter3」は9種類の異なる動作の実行を成功 
		- ② 第三者による動作の評価は高かった 
		- ③ 人間的な動作と感情表現を実現
-  Mixtral 8x7B の概要  by npakaさん
	- https://note.com/npaka/n/n6043bc8b01bc?sub_rt=share_h
	- 推論は6倍速く、ほとんどのベンチマークで「Llama2 70B」を上回っていま
	- **Mistral-tiny** : Mistral 7B Instruct v0.2。英語でのみ機能。MT-Benchでは7.6を獲得。  
	- **Mistral-small** : Mixtral 8x7B。英語/フランス語/イタリア語/ドイツ語/スペイン語とコードをマスター。MT-Benchで8.3を獲得。  
	- **Mistral-medium** : Mistral AIの最高品質のプロトタイプモデル。英語/フランス語/イタリア語/ドイツ語/スペイン語とコードをマスター。MT-Benchで8.6を獲得。
- ミストラルのMoE版であるmixtralですが驚いた事に既にllama.cppの量子化版が出ているのでgpuがない環境やMacでも動かせる
	- https://x.com/webbigdata/status/1734425932029628876?s=20
- "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"
	- https://arxiv.org/abs/2312.06585
	- LMに自ら高品質なデータを生成させ、データセットを拡張する「自己学習」アプローチ by DeepMind
	- 方法
		- ① 自らデータセットを拡張する 
		- ② 生成したデータが正しいかどうかを判断する
		- ③ 数学を中心とした様々な問題解決に使える
	- 実験結果 
		- ① 数学において、正答率の向上を達成 
		- ② 異なるタイプの問題に対するモデルの適応能力が向
-  Query Transform Cookbook
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/query_transformations/query_transform_cookbook.ipynb
	- RAGにおいて、検索結果をcontextに積んでLLMに回答させるのではなくて、質問をLLMで変換してゆくアプローチ
	- Query Understanding Layer
- Mistral-7B-Instruct-v0.2 を試す by npakaさん
	- https://x.com/npaka123/status/1734348586689908878?s=20
	- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- Mixtral-8x7B-Instruct-v0.1 を試す。load_in_4bit。 by npakaさん、
	- https://x.com/npaka123/status/1734408371154100457?s=20
	- https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
	- 起動までダウンロード含めて20分で推論速度は200トークンで21秒
- マイクロソフトがPhi-2とかいう2.7BパラのLLMをリリース
	- https://x.com/umiyuki_ai/status/1734763437274890746?s=20
	- MicrosoftがIgniteで話していたわずか27億パラメータの言語モデルPhi-2
	- パラ数小さいくせにあり得ん高性能を発揮してるらしい。
	- 学習量は1.4Tトークンで、96個のA100で14日かけてトレーニング。
	- ベンチマークでパラ数3.2BのGemini Nanoに完勝（てかGemini Nanoのパラ数初めて知ったわ）
	- そしてマイクロソフトの独自ベンチにおいて、まさかのLlama2-70B相手にコーディングで圧勝、数学で僅差に迫る。Llama2-13B相手には完勝してしまう。
- The Emergent Abilities of LLMs Could Be A Mirage!
	- The best paper award in NeurIPs 2023 went to a paper claiming that the emergent abilities of LLMs could be a mirage!
- llamaindexにてmistralaiのサポートドキュメント公開
	- https://docs.llamaindex.ai/en/stable/examples/llm/mistralai.html
- 【ローカルLLM】Mixtral-8x7bをllama.cppで試す
	- https://note.com/bakushu/n/n5b270b288cba?sub_rt=share_b
	- llama.cppで「Mixtral-8x7b」のGGUF量子化モデルを試しました（現時点でまだmergeされていないのでbranchを利用）
	- 「**Mixtral-8x7b**」はMistralがリリースしたMoE（Mixture of Experts）構造のLLMで「Mistral 7B」ベースの8個のモデルを束ねています。
	-   今回はGoogle Colabで「[**Mixtral-8x7B-Instruct-v0.1-Q4_K_M-GGUF**](https://mixtral-8x7b-instruct-v0.1-gguf/)（4bit量子化版）」の推論を試しました。
	- 4bit量子化でも26GBほどあります。Colab ProのCPUオンリー+ハイメモリで実行してみました。GPUのみで推論するならA100が必要です。
	- ColabのCPUだとさすがに遅いものの、最近のPCのCPUならふつうに動かせそう。Llama 34B/70Bの量子化モデルに比べると全然速いです
- LangChainを使わない
	- https://tech-blog.abeja.asia/entry/advent-2023-day13
	- 技術的負債になりうるとか、Agentってfunction callで代替可能とかそういう話
- LlamaIndex + Gemini
	- https://blog.llamaindex.ai/llamaindex-gemini-8d7c3b9ea97e
	- llamaindex、いきなりGeminiフルサポート
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/gemini.ipynb
	-  Multi-modal Model中もサポートしているらしい、、、
-  Google Generative Language Semantic Retriever
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/managed/GoogleDemo.ipynb
	- Google’s new semantic retrieval endpoint offers specialized embeddings and LLMs for high-quality retrieval + synthesis with guardrails. Use it out of the box, OR combine it with LlamaIndex components to build advanced RAG.
	- The Gemini API contains semantic search with custom embedding models for better retrieval, as well as toggles incl. safety during generation.
	- Googleがsemantic Retrieverってのをだしてたのか？
- LangChainもGemini対応
	- https://python.langchain.com/docs/integrations/chat/google_generative_ai
	- Access Google AI’s `gemini` and `gemini-vision` models, as well as other generative models through `ChatGoogleGenerativeAI` class in the [langchain-google-genai](https://pypi.org/project/langchain-google-genai/) integration package.
- Gemini Pro APIの価格表、
	- https://ai.google.dev/pricing?hl=ja
	- 入力が$0.00025/1k charactersなのでgpt-3.5-turbo-1106の1/4の価格（つまり11月以前のgpt-3.5-turboの1/12）で使えるらしい。
	- フリー版ならば、60QPM (queries per minute)までは使える！！！！
- phi-2を試す
	- https://x.com/npaka123/status/1735077608071876882?s=20
	- Llama2-70B相手にコーディングで圧勝した2.7Bモデル。
	- https://huggingface.co/microsoft/phi-2
- 大規模言語モデルを自作しよう！(Transformers+DeepSpeed+torch.compile+flash_attn2
	- https://zenn.dev/selllous/articles/transformers_pretrain_to_ft
	- 英語がメインのLLM Mistral-7Bモデルを300M(0.3B)へダウンサイズして、pretraining + instruction tuningをColab上のGPU T4(!!!)で6時間(0.02epoch)で日本語学習させるという意欲的な記事
-  FunSearch: Making new discoveries in mathematical sciences using Large Language Models
	- https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/?utm_source=twitter&utm_medium=social
	- DeepMindの研究チームが、AIを用いて数学の未解決問題に挑み、科学界における前例のない成果を出したと発表しました。 「FunSearch」と名付けられた大規模言語モデルを活用し、問題解決策をコンピュータプログラムの形で生成。「キャップセット問題」と「ビンパッキング問題」という数学の問題において、新たな解法を発見したとのことです。
	- Introducing FunSearch in @Nature: a method using large language models to search for new solutions in mathematics & computer science
	- DeepMindがLLMを「事前にタスク評価できる問題」に遺伝的アルゴリズムを組み合わせたFunSearch(searching in the function space)提案。
	-  LLMがコード生成->評価->洗練のループ。 
	- ** 科学,数学の未解決問題に対して、初めてLLMを用いた新たな発見 **。 
	- その例としてcap set problem,bin-packing problem。
-  Benchmarking RAG on tables
	- https://blog.langchain.dev/benchmarking-rag-on-tables/
	- llmaindexより、テーブルのＲＡＧについて、ベンチマーク、long contextは性能はでない
-  MOE言語モデルのエキスパートの一人を日本語得意なモデルに置き換えたらどうなるのか？
	- https://note.com/aisatoshi/n/n6c06d5183517?sub_rt=share_pb
	- Mistral7Bを8つ束ねた、Mixtral 8x7BというMOEモデル
	- エキスパートを何人か、日本語が得意なMistral7B互換モデルに差し替えたらどうだろう？
	- 注意機構だけ、MLP層だけ、コピーするエキスパート数を変更など実験しましたが、基本モデルが壊れました
- 自民党がAI規制を提言
	- https://x.com/umiyuki_ai/status/1735277687097414124?s=20
- GCPよりGemeniの様々な利用方法とnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai
- Geminiをつかって、クリスマスカードを作る例 by google
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Prepare_Christmas_cards_with_Gemini_and_Sheets.ipynb
-  OpenAI thinks superhuman AI is coming — and wants to build tools to control it
	- https://openai.com/blog/superalignment-fast-grants
	- Open AI超人的なAIのアライメントに向けた研究に1000万ドルの助成金プロジェクト開始。 
	- 支援にGoogle CEO兼会長のエリック・シュミット氏。 
	- イリヤサツケバー氏今もまだSuper Alignmentチーム率いてるとのこと！
-  A Guide on 12 Tuning Strategies for Production-Ready RAG Applications
	- https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439
	- LLMのRAGアプリケーションをチューニングするための12戦略を書いたブログ記事。具体的にはデータクリーニング、埋込み、チャンク化、インデクシング、クエリ変換、リランキング等、実践的な戦略。
- Bishop先生の「Deep Learning: Foundations and Concepts」
	- https://www.bishopbook.com/
	- Vision Language Modelのところ見たらCM3Leonが載ってて驚いた
- Benchmarking Large Language Models As AI Research Agents
	- https://arxiv.org/abs/2310.03302
	- この論文が素晴らしいのは、open-ended な状況で研究をするエージェントというコンセプトを明確に提示した点だ
- calm2-7b-chatをRAG QAで使うための調査
	- https://x.com/_oshizo_/status/1735282188546089332?s=20
	- context全体の長さ（横軸）と、正解になるキーワードの位置（縦軸）を変えながら、出力に正解の文字列を含んだ割合を集計。 
	- 正解キーワードがcontextの末尾付近にあれば全体の長さはあまり影響しないが、末尾から1k離れるごとに正答率が0.6掛けになるイメージ
- LLM・プロンプトの評価・テストフレームワークについてまとめてみた
	- https://zenn.dev/pomcho555/articles/8e42f0a4ce39eb
	- RAGASを使った自動データ生成
	- RAGASを使った自動評価
- Web3時代のナレッジグラフ？ – Geoを触ってみた
	- https://zenn.dev/s_egami/articles/4ec2e0de59ff4d
- "Pixel Aligned Language Models"
	- https://arxiv.org/abs/2312.09237
	- Googleの研究者らは、画像をピクセルレベルで言語化する能力をもつLLM『PALM』開発しました
	- 実験の結果、「人が理解しやすい」内容で正確かつ詳細に画像を説明することができると確認されました
-  日本の古典和歌を埋め込みベクトルで分析する
	- https://note.com/yhkondo/n/nd321604729cd?sub_rt=share_pw
	- OpenAIの埋め込みベクトルを使って、『古今集』『万葉集』『和漢朗詠集』等を分析し、いわゆる「花鳥風月」という概念がどこから生まれてきたかを探求したものです。AIの持つ力を感じていただけると確信しています
-  Google Colab で Gemini Pro をもっと試す by npakaさん
	- https://note.com/npaka/n/n1c368639cada?sub_rt=share_h
	- 1.  2. モデル一覧の表示
	- 2.  3. 質問応答
	- 3.  4. ストリーミング
	- 4.  5. チャット
	- 5.  6. 画像からの質問応答
	- 6.  7. 画像とテキストからの質問応答
	- 7.  8. 埋め込みの生成
-  Voyager: An Open-Ended Embodied Agent with Large Language Models
	- https://arxiv.org/abs/2305.16291
	- LLMをのせたエージェントにマインクラフトをさせた研究，進捗の解除具合やマップの探索範囲の広さをみていて，滅茶苦茶面白いなｗ　プレイ風景をみてみたい
- mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- https://huggingface.co/mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- Mixtral-8x7B-Instruct-v0.1 のExpertsのうち2つ毎にmergeして4x7bにした実験モデル作りました
	- Modelサイズは24Bになります
- NeurIPS Large Language Model Efficiency Challenge:  1 LLM + 1GPU + 1Day
	- https://llm-efficiency-challenge.github.io/index
	- OSS LLMモデルを元に限られた資源・時間でファインチューンするというコンペ
	- 重要なのはデータセット
	- 複数のデータセットからデータをサンプリングして上質なデータセットを構成し訓練するのが鍵
- 
	


## 12/11

今週はなんといっても、GoogleのGemini。GPT-4越えとか、すぐにBard(英語版）でGemini Proを試せるとか、研究アシスタントして使うデモとか、それからマルチモーダルをフルに生かした子供向けのお遊びデモとかなかなか衝撃的であったが、なんとお遊びデモが紙芝居（部分をつなげてそれらしく見えるようにした、部分部分は本物らしいが）との報道があり、事前の「１月に遅延」との報道と合わせると締め切りに間に合わなかったんだろうけど、前回のBardお披露目での失態といい、脇が甘い。なおGeminiの命名の由来、上位６名の主要貢献者のFirst Nameからとったらしい。Mambaというトランスフォーマの代替技術、性能よさそうで期待。 DeepMindの『GNoME』は「人間の直感を超えた220万の材料を発見し」科学の発展をLLMが明らかに加速することを示している。それって危険な材料も。。。Metaは安全なAIのためのPurple LLamaを発表、Securityや安全ガードを提供。攻撃（red)と防御(blue)が協力するからPrupleなんだって。安全ガード(Llama Guard)はLLMで実装され、つまりLLMにはLLMってこと。MetaはIBM等との企業連合で安全なOSSとしての生成型AI開発を促進、OSSのLLMがますます熱くなる？。Appleから深層学習フレームワークmlx発表、M3ってすごいんだ、LLMでは今一歩プレゼンスの無いApple、CNBCの潜入インタビューでも、LLM競争に進出するかと聞かれて、責任者はモゴモゴはぐらかしてたな、あやしさ満載。NVIDIAのH100、MSとMetaはそれぞれ150k(15万個）を持っていてダントツ、どうもH100が15万個あれば７日でGPT-4が作れる性能らしい。一方AMDも生成AIでNVIDIA H100を上回る性能のGPU「Instinct MI300」を発表。GPUも熱い、われらの牧野先生のMN-coreの登場を期待しますか。ついに欧州AI法が成立、AIの定義がＯＥＣＤのそれに整合したとか基盤モデルに対する規制の明確化がポイント。システミックリスクにどう備えるかが肝。そのAI法の基盤モデルへの規制部分に異議を唱えていた仏Mistralが、満を持して？新しい mixtral-8x7b-32kseqlenを発表、MoE(Mixture of Expert)というアーキテクチャが肝らしい、欧州AI規制に関連してmixtral-8x7b-32kseqlenを念頭に、たった87GのweightでAGIが来るならAI規制必要だよねみたいな意見も見かけた。このほかにも、ローカルLLM向けのOllama とか、言語データなしで大規模ビジョンモデル（LVM）を構築とか、マッキンゼーの日本がDXできないレポート(誤植を発見！)とか、2bit量子化技術QuIP#とか、様々あったが追えてない。。そもそも、１週間分のブクマ整理するだけで２時間かかるんだけど。。。GPT-4にやらせるか。。

- 今月のNature誌は面白かった
	- https://x.com/ykfrs1217/status/1731287315459490165?s=20
	- ① 大都市ほど、異なる社会ステータスのひとたちは混じわらない（[https://doi.org/10.1038/s41586-023-06757-3…](https://t.co/tEkbdQOPG3)） 
	- ② 同じ町（≃学内）の研究者だけで行われた研究の方が、異なる地域間の共同研究よりも革新的な成果がでやすい（[https://doi.org/10.1038/s41586-023-06767-1…](https://t.co/jrBRV4Gxtk)）
-  Phantom oscillations in principal component analysis
	- https://www.pnas.org/doi/10.1073/pnas.2311420120?utm_source=TOC&utm_medium=ealert&TOC_v120_i48=&ref=d4140497
	- 時間的・空間的にスムーズなデータ (ほとんどの生理データ…) 等を主成分分析 PCA すると、偽のオシレーションが出現する
-  Refactoring Programs Using Large Language Models with Few-Shot Examples
	- https://arxiv.org/abs/2311.11690
	- リファクタリングにLLMを使う
- "On Bringing Robots Home" Nur Muhammad Mahi Shafiullah et al., New York University
	- https://arxiv.org/abs/2311.16098
	- 家庭用ロボットの普及に向けて、一般のロボットを各家庭に適用させるためのフレームワーク『Dobb·E』が開発され、オープンソースで公開
	- 一般のロボットを家庭用ロボットにアップデートするための一連の流れをカバーするフレームワークが『Dobb·E』
	- ① 合計109のタスクを実際の家庭で実施し、ロボットの成功率が81％に達した 
	- ② 調理家電を閉める／クッションをひっくり返すタスクは100％、6軸で物を移動するタスクは56% 
	- ③ データ収集時にカバーされていた照明や影の条件下ではロボットは安定して稼働する
- Introducing Llama Datasets 
	- https://blog.llamaindex.ai/introducing-llama-datasets-aadb9994ad9e
	- llamaindexより、RAG向けの評価用データセットの公開
	- history of alexanetとか、origin of covid19などのpdfを含む、多分正解値は？
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
	- https://arxiv.org/abs/2311.16079
	- llama2を医療に特化してチューニングしたLLM
	- Compared to closed-source LLMs, MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2.
	- webuiで試せる！
	- https://github.com/epfLLM/meditron/blob/main/deployment/README.md#serving-with-web-gui
- RAG用途に使える、Wikipedia 日本語の embeddings とベクトル検索用の faiss index を作った
	- https://secon.dev/entry/2023/12/04/080000-wikipedia-ja-embeddings/
	- Wikipedia日本語550万文でベクトル検索できるembeddingsと検索用faiss index作りました。20行ぐらいコード書くだけで簡単に利用できます！RAGしてもデータが少ないと面白みが少ないのですが、Wikipedia突っ込むと面白さが増えてくるので、興味ある方はお試しください！
	- huggingface spaceで試せる
	- https://huggingface.co/spaces/hotchpotch/wikipedia-japanese-rag-qa
	- 「ナウシカと森の人との関係は？」には全く答えられない。
	- FAISS+ELYZAだと、「ナウシカと森の人は仲良しだった。」と答えてくれたのに。。
- Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift
	- https://arxiv.org/abs/2311.15961
	- 共変量シフトのネタで"All you need"的な流行りのタイトルの論文なんだけど，内容はしっかり数理やってるっぽい．がっつりShimodaira (2000)も参照されてました．共著者に数理統計の大御所のJianqing Fan先生とか，機械学習の理論系のChi Jin先生など
- Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation
	- https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2
	- Check out this fantastic blog covering the basics of RAG, the theory behind it, and how to use it in practice
- Mamba: Linear-Time Sequence Modeling with Selective State Spaces
	- https://arxiv.org/abs/2312.00752
	- トランスフォーマーや注意機構に頼らない、線形時間のシーケンスモデリングのための新しいニューラルネットワークアーキテクチャ
	- 2倍サイズのTransformersに匹敵したり、5倍の高速推論が出来たりと、Transformerを代替しうる可能性
	- 2.8Bが出てるらしい、
	- https://huggingface.co/state-spaces/mamba-2.8b
-  Instruction-tuning Aligns LLMs to the Human Brain
	- https://arxiv.org/abs/2312.00575
	- Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain.
- マルチモーダルLLMの応用動向の論文調査
	- https://speakerdeck.com/masatoto/marutimodarullmnoying-yong-dong-xiang
- 生成文法研究者の中で「言語の本質」（今井先生）の評判が良くなかった
	- https://x.com/kkling51/status/1731543891348996466?s=20
	- (i) アブダクション推論は適切な推論ではないからそれに頼るべきではない 
	- (ii) 言語とは何かという定義がないため，本質が何なのか分からない．
	- プラトンの問題も未解決のママ
- Amil Merchant et al., "Scaling deep learning for materials discovery", nature
	- https://www.nature.com/articles/s41586-023-06735-9
	- DeepMindの『GNoME』が「人間の直感を超えた220万の材料を発見し」うち736は既に人間が実験室で再現したとの報告
	- 大規模なデータセットと先進的な機械学習モデルを組み合わせる手法による、マテリアルズインフォマティクスの発展事例です
	- 方法
		- ① GNNを用いて素材の特性を構造や組成に基づいてモデル化
		-  ② 材料発見の効率が大幅に向上し、人間の直感を超えた220万の構造が発見された 
		- ③ 結晶構造内の原子を置換する手法やランダムな探索を含む、多様な候補生成アプローチを確立
	- 結果
		- ① 220万の新たな安定構造を特定し、それらの多くは既存の化学的直感を超えていた 
		- ② 発見された安定構造のうち736は、独立した実験で実現されている （シミュレーション上での検証ではなく、実験室で物理的に材料を作成し、実証できた）
- NVIDIAのH100をどこに出荷したかの図。MS,Metaが圧倒的に多い、GPT4を7日で訓練できる規模？
	- https://x.com/Lauramaywendel/status/1731698695853244849?s=20
	- GPT4 was presumably trained for around 90 days using 25k A100 GPUs. Microsoft and Meta having reportedly bought 150k H100 GPUs each this year, can now train a GPT4 class model in only 7 days from scratch
- Google Geminiの提供を１月まで延期
	- https://x.com/rowancheung/status/1731531903193219260?s=20
	- いくつかの分野ではGPT-4を上回るも、英語以外での性能が出ない。
	- これって、後から続くイベントの予兆かしらん、
- ある物理学の本で、ギリシャ語の説明表でゼータのところが、、
	- https://x.com/yori_Alphard/status/1731663363737026586?s=20
	- "Zガンダム"になっている。。
- GIVT: Generative Infinite-Vocabulary Transformers
	- https://huggingface.co/papers/2312.02116
	- 本当にトークンが離散でなくて、無限なのだろうか？
- ファインチューニングは不要、プロンプトだけでどうにかなる？
	- https://x.com/IntuitMachine/status/1732089266883141856?s=20
	- A recent research paper provides compelling evidence that the extensive fine-tuning used to "align" large language models into helpful assistants may be largely unnecessary.
	- Allenインスティテュートの仕業か、https://allenai.org/
- llamaindexでもマルチモーダルが盛り上がっている、Webinerなど
	- https://x.com/llama_index/status/1732081850246627547?s=20
	- https://lu.ma/350wf7v7
- 安全で責任あるAIの開発向けて、MetaとIBMが提携
	- https://ai.meta.com/blog/ai-alliance/
	- IBM とメタは、*オープン*で信頼性の高い AI を推進するために AI Alliance を立ち上げています。 産業界、政府機関、学界からの 50 を超える設立メンバーのリストには、AMD、Anyscale、CERN、Hugging Face、Linux Foundation、NASA が含まれます。
	- 日経にかかるとタイトルは、「メタとIBM、生成AI「オープン型」へ　50社・団体と連携」
- Prompting vs RAGs vs Fine-tuning:
	- https://x.com/akshay_pachaar/status/1732014719794585684?s=20
	- よくある４象限の絵、
	- So finetuning is more about changing structure (behaviour) than knowledge, while it's other way round for RAGs.
	- You use RAGs when you want to generate outputs grounded to a custom knowledge base while the vocabulary & writing style of the LLM remains same.
	- If you don't need either of them, prompt engineering is the way to go.
	- And if your application need both custom knowledge & change in the behaviour of model a hybrid (RAGs + Finetuning) is preferred.
- OpenAIのSafety System Teamsから
	- https://openai.com/safety/safety-systems
	- 協力のお願い
- PyTorchが出した、gpt-fastはすごいらしい
	- https://x.com/AlphaSignalAI/status/1732116360162050099?s=20
	- Pytorch just released GPT-Fast, an implementation of transformer text generation with everything you need in <1000 lines of code.
	- https://github.com/pytorch-labs/gpt-fast
- Windows11にcopilotが降臨？
	- https://www.microsoft.com/en-us/windows/copilot-ai-features?r=1
- JWT(Json Web Token)
	- https://x.com/alexxubyte/status/1732077250626179578?s=20
- Jellyfish: A Large Language Model for Data Preprocessing
	- https://arxiv.org/abs/2312.01678
	- データの前処理を得意とするLLM『Jellyfish（クラゲ）』が公開されました。 未知のタスクにも対応でき、比較的軽量であり1GPUでも動作するとのことです。 
	- 大阪大学、NEC、名古屋大学の研究者らによる発表です
	- ① データベースタスク特化モデルが進化 （GPT-4と同等の性能でデータ処理を行う） 
	- ② ゼロショットでデータ前処理タスクを実行 
	- ③ 多様な前処理タスクに対応 
	- ④ サイズが小さいため、1GPUでも動作する
- GooglがGemini(ジェマナイと読む）を発表
	- https://blog.google/technology/ai/google-gemini-ai/
	- 1. Geminiは3種類のモデル(Ultra, Pro, Nano)が存在。Ultraが最も賢く、Nanoはモバイルデバイス向け。
	- 2. Ultraは数々のベンチマークでGPT-4超えの性能を発揮 (ﾄﾞﾔｧ)
	- 3. Geminiはマルチモーダルに強い。動画デモのようにリアルタイム推論も可能。 
	- 4. 本日よりBardはGemini ProのFine-tuningバージョンを利用して公開する。その他にもGoogle製品への導入を進める。 
	- 5. Gemini APIは12月13日からGoogle AI Studioを通じて提供される。
	- https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
- Google AlphaCode 2 を発表
	- AlphaCode 2 Technical Report
	- https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf
	- Geminiを競技プログラミング用にカスタマイズしたAlphaCode2は、競技プログラミング人口の上位15%の性能
- MetaのStreamingの翻訳性能はすごいらしい、	
	- https://x.com/hokazuya/status/1732374854027132940?s=20
	- 翻訳こんにゃくレベル
- Bardの生成記事はChatGPTより優れている？
	- https://x.com/kajikent/status/1732237182126129578?s=20
	- コンテンツマーケティングの領域で有名なNeil Patel氏が約250ずつのChatGPT生成の記事とGoogle Bard生成の記事で読者にどちらが好きか聞いたところ、Bardが圧勝する結果に
- 人間レベルのAI(AGI)に到達すするには、常に10年以上必要
	- https://x.com/ylecun/status/1732391273611370931?s=20
	- 3～5年は常に必要（永遠に達成できない）との記事にLecan先生の反応
- Apple製品Mシリーズに最適化された深層学習フレームワークmlx
	- https://x.com/goto_yuta_/status/1732287555599741103?s=20
	-  Macに搭載されてるGPU(MPS)がより有効活用されてローカルLLMの高速推論が可能になったら嬉しいな。
	- CNBCの、Apple Labへの潜入インタビュー
	- https://www.youtube.com/watch?v=UdhWvg5mycY
- GeminiのTechnical reportを日本語で解説している人が登場
	- https://x.com/bioshok3/status/1732421662619140551?s=20
	- Gemini Ultraは、MMLU で人間の専門家の性能を達成した最初のモデルでありスコアは90%以上。やばすぎる。人間のエキスパートのパフォーマンスはベンチマーク著者によって89.8%と評価され、Gemini Ul traはこの閾値を超えた最初のモデル!時代が変わった。
	- 教師がスキーヤーが坂道を下りるという物理問題を描き、生徒がその解決策を練る。Geminiのマルチモーダル推論機能を用いて、モデルは 乱雑な手書きを理解し、生徒が問題の解決を間違えた推論の特定のステップを特定し、問題の正しい解決を通し て作業を与えることができる。
	- Google がGeminiのデモ動画を出しているけど、これほんとにこの推論速度なら凄すぎると言うかもう株価数倍くらいになるんじゃないの？ってレベルだけど？？
	- デモについては「このデモの目的のため、レイテンシーは短縮され、ジェミニの出力は簡潔にまとめられている。」と書かれてる
	- 多言語性能はGPT-4より良い
	- コンテキストトークン数は32768。98%の精度で正しい値を取得可能！98%?まじかよ。
- Googleアカウントの言語設定を英語にすると、BardのバックがGemimi Proが使える
	- https://x.com/npaka123/status/1732504570218283340?s=20
- Bard(Gemini Pro)が霞が関パワポを解析して説明してくれると、、	by ゆな先生
	- https://x.com/JapanTank/status/1732689643928445164?s=20
- Gemini論文の最後の、"Core Contributors"の最初の６人の頭文字をとると、"GEMINI"になる
	- https://x.com/nearcyan/status/1732532560029172142?s=20
- Metaより、安全なAIのための、Purple Llama（ツールセット、フレームワークみたいなもの）を発表
	- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=image
	- CyberSec Evalとか、Llama Guardが最初に出る
	- なんでpurpleかというと攻撃側（赤）と、防御側（青）が協力して構築したから
	- attack (red team) and defensive (blue team) postures.
	- Colabで試せるらしい
	- https://colab.research.google.com/drive/16s0tlCSEDtczjPzdIK3jq0Le5LlnSYGf?usp=sharing
- Evaluating and Mitigating Discrimination in Language Model Decisions
	- https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions
	- Anthropicより、（LLMの出力における）差別を検知するためのデータセットを公開
-  AMD、生成AIでNVIDIA H100を上回る性能のGPU「Instinct MI300」
	- https://pc.watch.impress.co.jp/docs/news/1552583.html
	- TDP 750WのMI300Xは、TDP 700WのNVIDIA H100と比較し、FP64,32で約2.4倍、AIで利用のTF32、FP16、BF16、FP8、INT8などでは1.3倍スループット実現。
- 赤石先生のベイズ推論本がわかりやすいと評判に
	- https://x.com/kenken26679105/status/1732977179485757744?s=20
	- 少ないデータ量でも、こんな風に、色んな実務の場面にすぐに活用できちゃう
	- Pythonでスラスラわかる ベイズ推論「超」入門 (KS情報科学専門書)
- チョムスキーの「生成文法」は死んだという論文
	- Modern language models refute Chomsky’s approach to language
	- https://lingbuzz.net/lingbuzz/007180/v1.pdf
	- 最近の生成AIてうか大言語モデルLLMの驚くべき成功から見て、チョムスキー流の生得的統語法規則があるという説は維持しづらい
- llamaindexより、知識グラフ(KG)を使う、７つのパターンを表にまとめてくれた
	- https://x.com/llama_index/status/1733190430760845673?s=20
	-  A Simpler Way to Query Neo4j Knowledge Graphs
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/neo4j_query_engine/llama_packs_neo4j.ipynb
- 欧州AI法の最終トリローグが終了、妥結へ
	- https://x.com/WIRED/status/1733268732309332398?s=20
	- https://www.reuters.com/technology/eu-clinches-deal-landmark-ai-act-2023-12-09/?taid=65745dd360152800018aaf1c&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter
	- https://twitter.com/SabrinaKuespert/status/1733311752941515135/photo/1
	- https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?xtor=AD-78-[Social_share_buttons]-[twitter]-[en]-[news]-[pressroom]-[artificial-intelligence-act-possible-deal]-
	- 基盤モデルで規制されるのは、計算量が10^25FLOPsを超えるモデル。
	- 該当するのは今んとこGPT-4とGeminiあたり。
	- それらのモデルはシステミックリスクに応じて分類される。
	- システミックリスクはモデルがどんだけ強力か、どんだけの人が使うかで決まる。
	- 規制の内容は
		- ①リスクの軽減を行う　
		- ②モデルの評価、敵対的テストを実施する　
		- ③インシデントの監視をする　
		- ④サイバーセキュリティを確保させる　
		- ⑤ドキュメントを作らせる
-  Generative AI for Everyoneから、古のNLPエンジニアの心に刺さったこと8選
	- https://note.com/csstudyabroad/n/n5aba3a708f3a
- "Purple Llama CyberSecEval: A benchmark for evaluating the cybersecurity risks of large language models"
	- LLama Purple関連の CyberSecEvalの論文
	- https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/
	- Metaの研究者らは、LLMが生成するコードにおける不安定性や乱用リスクを評価するためのツールを作成しました。
	-  実験の結果、現在は、能力が高いモデルほど不安全なコードを提案する傾向が強いという逆説的な結果も出てきました。
	- ① 全体的にLLMは、30%のケースで不安全なコードを提案した 
	- ② 53%のケースで、サイバー攻撃の手伝いをするリクエストに対してLLMが応じた
	-  ③ コーディング能力が高いモデルほど、不安全なコードを提案する傾向が強かった
- "Sequential Modeling Enables Scalable Learning for Large Vision Models"
	- https://arxiv.org/abs/2312.00785
	- 「視覚は本来、言語に依存しない」と考えたUCバークレーとジョンスホプキンス大学の研究者らは、言語データなしで大規模ビジョンモデル（LVM）を構築するアプローチ
	- ■アプローチの詳細 
		- ① 画像や動画を表現する「ビジュアル文」を定義 （ピクセル以外のメタ情報はない） 
		- ② 視覚データをトークン化 
		- ③ 自己回帰型トランスフォーマーモデルを訓練
	- ■実験の結果わかったこと 
		- ① モデルは大量データを処理し学習する能力が高い
		-  ② 様々なビジョンタスクで有効 
		- ③ モデルサイズが大きくなるにつれて、下流タスクのパフォーマンス向上する
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- Scenarios of adopting LLMs, techniques for utilizing LLMs on graphs, applications, #opensource code repositories, benchmark datasets
- 「2030 日本デジタル 改革」 by マッキンゼー
	- https://www.digitaljapan2030.com/_files/ugd/c01657_fcaed21f58bb4c429cb460ce788b82c4.pdf
	- マッキンゼーのレポート（全140ページ）
	- 日本のデジタル化がなぜ遅れたのか、それに対してどのような打ち手が取れるのか、ということが分かりやすく整理されています。 
	- 日本の総労働時間の56%が自動化可能
	- といっても初期版には誤植が、(×政府の支持→〇政府の指示）P16
- ollama + stablelm-zephyr 試す。 M1でもはやい。
	- https://ollama.ai/library/stablelm-zephyr
- Ollama : ローカル環境で容易にllamaを利用可能にるするAIチャットプログラム
	- https://note.com/astropomeai/n/nbcdfd3b38490?sub_rt=share_b
	- https://github.com/jmorganca/ollama
	- コマンドラインインターフェースを通じて大規模言語モデル（LLM）とやり取り可能なAIチャットプログラム
	- LlamaやCode Llamaなど、さまざまなオープンソースモデルをサポート
	- モデルのパラメーターやサイズが異なり、計算リソースに応じたAIモデルの実行を柔軟に対応
	- Dockerがインストールされたシステムで利用可能で、Nvidia GPUのGPUアクセラレーションをサポート（CPU上でも実行可能）
	- パフォーマンスはハードウェアに依存し、例えばLlama 2の7Bモデルを実行するには最低15GBのRAMと4つのCPUコアが必要
	- MacOSとLinux用のデスクトップアプリケーションがあり、Windows版が開発中
-  Ollama Llama Pack Example
	- https://docs.llamaindex.ai/en/latest/examples/llama_hub/llama_pack_ollama.html#
	- llamaindexより、さっそくOllama対応のRAGの例
	- https://llamahub.ai/l/llama_packs-ollama_query_engine
- ollama web-ui is amazing
	- https://github.com/ollama-webui/ollama-webui
- ClimateXのデータセットが公開されている
	- https://huggingface.co/datasets/rlacombe/ClimateX
- Mistralより、新しい mixtral-8x7b-32kseqlenを発表
	- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
	- 「我々はMistral MoE (7Bx32experts) を 2 か月間使用しており、それは24GBで動作しています。」
- What is Mixture-of-Experts (MoE)?
	- mixtral-8x7b-32kseqlenの裏にあるmoe技術とは
	- https://x.com/sophiamyang/status/1733505991600148892?s=20
	- MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block.
- たった87GのweightでAGIが来るから、AI規制必要だねという
	- https://x.com/abacaj/status/1733561182504587652?s=20
	- mixtral-8x7b-32kseqlenのことらしい
- MoEのMixtral-7bx8のGPTQきとる！
	- https://huggingface.co/TheBloke/mixtral-7B-8expert-GPTQ
- Geminiのお遊びデモは、紙芝居だ
	- https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/
- QuIP#: QuIP with Lattice Codebooks
	- https://cornell-relaxml.github.io/quip-sharp/
	- QuIP#は大規模言語モデルを2ビット量子化し、本来ならば140GBのメモリが必要なLlama 2 70Bを24GBのGPUで実行可能にするとの事です
- Bard(/w Gemini Pro)はいまだに数独が解けない、ChatGPTはとけるけど
	- https://x.com/kajikent/status/1733663171578335233?s=20
- OpenAI、GPT-4が怠け者になってきたという苦情に「修正を検討中」とポスト
	- https://www.itmedia.co.jp/news/articles/2312/10/news059.html
	- ChatGPTでのGPT-4のパフォーマンスが低下している（lazier）というユーザーからのフィードバックがここ数カ月増えていることを認め、「修正を検討中」だとX（旧Twitter）の公式アカウントにポストした。
- Mistral MoEの初期評価
	- https://x.com/bindureddy/status/1733523486885449834?s=20
	- まあ、ファインチューニングされてない素のモデルでもGPT3.5相当の性能というのは期待できる
	- solid 70B model that is very similar to GPT 3.5, Gemini Pro
	- MMLU on the base models is at 0.717 compared to Gemin Pro's 0.718
	- Expect to see several fine and instruct tunes over the next few weeks. These fine tunes will match GPT-4 quality for several real-world use cases.
-  Google Colab で DiscoLM Mixtral 8x7b alpha を試す by npakaさん
	- https://note.com/npaka/n/n3b55c941d864?sub_rt=share_h
	- 「**Mixtral 8x7b**」は、「Mistral AI」がリリースした史上初のオープンソース MoEモデルです
	- 「**DiscoLM Mixtral 8x7b alpha**」は、「Mixtral 8x7b」をファインチューニングして作成した実験的なチャットモデルです。元のモデルをHuggingFace形式に変換し、「Synthia」「MethaMathQA」「Capybara」でファインチューニングしています。
	- 「**MoE**」 (Mixture of Experts) とは、LLMの効率と精度を高めるために使用される手法です。このアプローチは、複雑なタスクをより小さく管理しやすいサブタスクに分割し、それぞれを特化したミニモデルまたは専門家が処理することで機能します。
	- 

## 12/4

先週までのOpenAIのお家騒動も落ち着き、今週は通常運転。日常能力を試すテスト『GAIA』、プロンプトの良例にもなっているし、現状のLLMの限界を図るのにちょうどよい。A*の可視化、こういうのを待ってた。異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』というのは、フリーアドレスの執務環境の研究活動の活性化にヒントがあるかも。選択バイアス問題がなぜか着目される。清水さん、ついに、A100 80GBx8のマシンが完成、日本語のマルチターン会話データセットもそろえてくれて、日本発のトップクラスLLM開発に大いなる期待。Intel® のトランスフォーマ拡張、量子化の新たなる段階？Googleからdebateを基にした安全なLLM利用についての理論論文公開。カーネマン教授とルカン先生の対話も必聴、system1とsystem2と深層学習の関係は、あるよな。BERTopicや、AlphaFold、googleの翻訳トランスフォーマーも着実に改良が進んで実用フェーズにまた一歩進んだ。Google Colabについにtransformerがデフォルトで含まれるようになる、つまりそういうことだ。強化学習系のアルゴリズムは、スパースな対象には不適切なのか。プロンプトを逆推論したり、サロゲート（代理）モデルにおける逆問題の研究も注目。llamapackってのができているのか、試してみよう。Agentをよく使ってるけどもっと種類がある、認知アーキテクチャってのはちゃんと理解したい。「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」というのは続編を望む。LLMをPytorchだけでどれだけ高速化できるかとか、GPT-fastとか、小規模言語モデルの開発とか、そういうのがもっと出てくるはず。OSSのLLMについての論文「ChatGPTの1周年を記念して」もいいね、OSSのLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示しているとな。アメリカの医学試験「US (4-option)」で90.2％という高い正解率をだしたGPT-4評価論文、下手なファインチューニングよりもという話か。


-  An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
- GAIA: a benchmark for General AI Assistants
	- https://arxiv.org/abs/2311.12983
- Q*ではないですが、A*探索の様子を可視化した
	- https://x.com/GregKamradt/status/1728480680127148480?s=20
- Kevin Dunnell et al., "Latent Lab: Large Language Models for Knowledge Exploration"
	- https://arxiv.org/abs/2311.13051
	- LLMベースで、異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』
	- ①対話と視覚化を通してデータを探索 
	- ② プロジェクトのクラスタリングとラベル付けを自動化
	-  ③ 新しい研究プロジェクトのアイデア合成も可能
-  Google Colab で LCM LoRA を試す　 by npakaさん
	- https://note.com/npaka/n/n940ee84ca5b6?sub_rt=share_h
	- 「LCM」 (Latent Consistency Model) は、元モデルを別モデルに蒸留することで、画像生成に必要なステップ数を減らす手法です。25～50ステップかかっていた処理を4～8ステップで可能にします。
- Multi-modal Foundation Model for Material Design
	- https://openreview.net/forum?id=EiT2bLsfM9
	- 分子を表現するマルチモーダル基盤モデルの研究。SELFIES、DFT物性、スペクトルについてそれぞれencoder-decoderを学習し、各モダリティの潜在空間を共通の潜在空間にencode, decodeするモデルを学習。
	-  欠損が多くても学習可能かつ、後から異なるモダリティを追加しやすい
- 選択バイアスの式、tweedle
	- https://x.com/docmilanfar/status/1728680465928958055?s=20
- llamaindexより、RAG評価ツールragsのv2リリース
	- https://github.com/run-llama/rags
-  Simplifying Transformer Blocks 
	- https://arxiv.org/abs/2311.01906
	- many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:
- llamaindexから、RAGの新モジュール、fuzzy citationを発表
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/fuzzy_citation/fuzzy_citation_example.ipynb
	- https://llamahub.ai/l/llama_packs-fuzzy_citation
	- 部分的な検索結果から１つの回答を合成？？
- ＲＡＧ 101 for enterpirze
	- https://gradient.ai/blog/rag-101-for-enterprise
	- 絵が素敵
-  AIスーパーコンピュータ「継之助」爆誕!とりあえずRAID0で12TBのディスクをインストールする
	- https://note.com/shi3zblog/n/n77e8ad3ed779?sub_rt=share_pb
	- ついにA100 80GBx8のマシンが稼働した。ここまで長かった。
	- ここまで揃ったら日本最大規模のLLMを個人で作れるようになる。
-  A population-level digital histologic biomarker for enhanced prognosis of invasive breast cancer
	- https://www.nature.com/articles/s41591-023-02643-7
	- An important AI report for breast cancer leading to the potential of sparing chemotherapy for many. 
	- The 1st comprehensive analysis of both cancerous and non-cancerous tissue in hundreds of thousands of patient tissues-
- BERTopicの新しいバージョン
	- https://github.com/MaartenGr/BERTopic
	- Merge pre-trained models, apply zero-shot topic modeling, seed domain-specific words, and much more in this HUGE update!
- Intel® Extension for Transformers
	- https://github.com/intel/intel-extension-for-transformers
	- An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere
	- Intel Extension for Transformers supports INT4 model quantized by GPTQ on Intel platforms (Xeon & PC) !
	- https://github.com/intel/intel-extension-for-transformers/tree/1.2.1#int4-inference
-  ラプラス変換とフーリエ変換の関係
	- https://qiita.com/kaityo256/items/aa5b24904577de40016e
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
- Google Colab、Huggingfacesの協力で、transformerを最初から使えるようになった
	- https://x.com/GoogleColab/status/1729217098977845590?s=20
- A Llama-2-based model finetuned for function calling:
	- https://huggingface.co/Trelis/Llama-2-7b-chat-hf-function-calling-v2
- 日本語Wikipediaのマルチターン会話データセット10万個を作りました	
	- https://note.com/shi3zblog/n/na10eed9270f8?sub_rt=share_pb
	- GPT-3.5-Turboを使って、約一ヶ月かけて日本語のWikipediaの項目をもとに先生と生徒が会話するマルチターンデータセットを作りました
	- GPT-4でもやってみようかなと思っていますが、GPT-3.5でも一ヶ月でかなりの出費があり、GPT-4で同じ分量のデータセットを作るとなると数十万円から数百万円かかりそうです
- llamaindexからRAGに有効なllamapackを７種類公開
	- https://x.com/llama_index/status/1729303619760259463?s=20
- Compositional Generative Inverse Design
	- https://openreview.net/forum?id=5ueXRkKMMg&referrer=%5Bthe%20profile%20of%20Yilun%20Du%5D(%2Fprofile%3Fid%3D~Yilun_Du1
	- シミュレーションを深層学習モデルで近似した代理シミュレータと、拡散モデルを使った逆問題解法は、しばしば学習データ分布外にいったり局所解に陥ることがある。それを防ぐために、学習済みモデルを使って拡散モデルの各ステップで解を誘導し、不適切な解を防ぐCinDMを提案
- mlc-llm on WSLでモデルの変換を行う
	- 「WebGPUを用いたローカルLLMモデルのブラウザ推論」
	- https://zenn.dev/saldra/articles/356f470e730d1c
- ＮＴＴコムのＡＩ学習教材
	- https://gochikika.ntt.com/index.html
	- データの前処理からモデリングや評価までPythonコードと合わせて一通り学べる
- マルチモーダルのＬＬＭでも出力の成型が大事
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb
- John X. Morris et al., "Language Model Inversion"
	- https://arxiv.org/abs/2311.13647
	- 言語モデルは次の単語の確率を出すが、その「確率」を利用して元の文章（プロンプト）を何とかして見つけ出す手法を開発。
- OpenAIのcookbookにllamaindexをつかたRAGが掲載
	- https://blog.llamaindex.ai/openai-cookbook-evaluating-rag-systems-fe393c61fb93
- Minimizing Factual Inconsistency and Hallucination in Large Language Models
	- https://arxiv.org/abs/2311.13878
	- LLMのハルシネーションを抑制するフレームワークが提案されました。 ユーザーの質問に対して、多段階で情報を取得させることで、信頼性の高い応答を取得可能です。
- Relational Deep Learning
	- https://drive.google.com/file/d/1Uk1y6c8z265G0wiRPpGT1cd5lts5lnKq/view
	- Relational Deep Learning is brings the power of Graph Representation Learning to a Relational Database.
- NeurIPA2023の論文検索サービス
	- https://www.ai-driven-life.com/neurips-papers
- 強化学習はベルマン最適性原理から来る動的計画法に支えられてます。しかし、情報がrandomSamplingされる中で実は各時刻隣合うデータの列がほとんど情報（報酬）を持たないとなると、間に推定器が挟まってるのもあってスパースどころか最後にしか報酬が得られない問題への妥当性は怪しいかもですね。
	- https://x.com/ML_deep/status/1729249503683969037?s=20
- DeepMind has formalized a theoretical result related to AI safety in Lean. 
	- https://github.com/google-deepmind/debate
	- "Monadic syntax is excellent for expressing stochastic algorithms, and working over finitely supported distributions avoids the need for integrability side conditions during proofs."
	- But I’m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think “not killing lots of people” is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and that’s where this type of method might shine.
	- https://x.com/davidad/status/1729461156618637502?s=20
- Azure OpenAI Serviceの日本語記事まとめ
	- https://zenn.dev/microsoft/articles/azure-openai-japanese-blogs
- カーネマン教授とルカン先生の対話
	- https://www.youtube.com/watch?v=oy9FhisFTmI
	- Video of Daniel Kahneman and Yann LeCun discussing Dual Process Theory (i.e., System 1 and 2) in relation to Deep Learning.
-  ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search
	- https://arxiv.org/abs/2310.13227
	- uses algorithms like A* to improve LLM answers, improving sota on both planning and reasoning tasks
- Qualcomm Snapdragon 8gen 3 already supported 10b language model running locally on your smartphone.
	- https://x.com/Francis_YAO_/status/1727861621110779941?s=20
	- LLM is the new smartphone OS!
- Domingos先生がなんか言っている
	- https://x.com/pmddomingos/status/1729303707387658284?s=20
	- Why AI isn't going to taking over (from "The Master Algorithm").
- MistralChameli_7B_v01
	- https://huggingface.co/TokenBender/MistralChameli_7B_v01
	- First version of DPO-ed roleplay/smart version of Mistral. Now to conduct some experiments with reward model and see if this is any good.
- ベイジアンモデルへの経験ベイズ修正
	- https://www.jstage.jst.go.jp/article/keidaironshu/68/4/68_161/_article/-char/ja/
	- Robbins (1956) が Tweedie (1947) に言及してることに基づき，Efron が Tweedie's formula と名付けて広まっているが，Koenker & Gu (2016) では Dyson (1926) で既に得られていることが指摘されている。
-  A glimpse of the next generation of AlphaFold
	- https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/
	- AlphaFoldは最近大きなアップデートがあり、精度が大幅に向上し、タンパクだけでなくPDBにあるほぼすべての分子について予測可能です。創薬や新型CRISPR探索にも(一定程度は)使えます。
- EMNLP2023 の採択論文リストが見えるようになってた．来週シンガポールで開催される自然言語処理の国際会議です．タイトルに"Language Model"はいってる論文が219本って，どんだけ言語モデル好きなんだよ
	- https://2023.emnlp.org/program/accepted_main_conference/
-  OpenAI と LangChain の認知アーキテクチャ by npakaさん
	- https://note.com/npaka/n/n650532ce289a?sub_rt=share_h
	- 「**認知アーキテクチャ**」(cognitive architecture) とは、LLMどのように情報を処理し、応答を生成するかを理解するための枠組みです。「Flo Crivello」（自律エージェントスタートアップのLindyの創設者）が使用したこの用語を初めて聞き、素晴らしい用語だと思いました。
	- 「LangChain」では、「LLM」が真に変革的なエージェントのようなシステムに電力を供給する世界を信じています。しかし、そこにたどり着くルートは、**企業が「認知アーキテクチャ」を制御できるルート**であると信じています。
	- **(1) Code**  LLMを利用しないパターン。  
	- **(2) LLM Call** アプリの出力のみを決定する単一のLLMコール。 
	- **(3) Chain**  アプリの出力のみを決定する複数のLLMコール。  
	- **(4) Router**  LLMをルーターとして使用し、使用するアクション (Tool、Retrieval、Prompt) を選択。 
	- **(5) State Machine**  LLMを使用してある種のループでステップ間をルーティングするが、コードが許可された遷移先にのみ遷移  
	- **(6) Agent**  利用可能なステップのシーケンスを決定もLLMが行う。
- TextからSQLを生成するQuerypls
	- https://github.com/samadpls/Querypls/
- われらが、 @jerryjliu0がdeeplearningaiコースに登場
	- https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/
	- We also have LlamaPacks for every technique mentioned in this course to help you jumpstart your advanced LLM app:
- Deconstructing RAG
	- https://blog.langchain.dev/deconstructing-rag/
	- Given the importance of RAG and the fast pace of development, we've grouped popular RAG concepts into a few categories and created guides for each one.
- Running Starling-7B LLM model on local CPU with @Ollama_ai and getting great results for invoice data extraction, even better than Zephyr, Mistral or Llama2.
	- https://github.com/katanaml/llm-ollama-invoice-cpu
- 円城塔を近似する？
	- https://colab.research.google.com/drive/1oXxBIYJvvUYsVZP6WYAUCb3QK09zTJtO?usp=sharing
	- 円城塔さんの文章で学ぶ、大規模言語モデルのファインチューニングチュートリアル
- 「長コンテキストをLLM(GPT, Claude)に食わせた際に、ちゃんとRetrivalされるか？」を検証しているGithub。
	- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
	-  総じてCalude-2に比べてGPT-4 Turboのほうが正確に引用しているようで面白い。
- Qwen/Qwen-7B-Chat-Int4をGoogle Colobで動かす
	- https://ayousanz.hatenadiary.jp/entry/2023/11/30/182017
	- なんか日本の文化はちゃんと学んでいないみたいですね
-  Accelerating Generative AI with PyTorch II: GPT, Fast
	- https://pytorch.org/blog/accelerating-generative-ai-2/?utm_content=273712248
	- GPT-fastというのがすごらいしい、３倍？
- LiLM 小規模言語モデル TinyLlama 1.1B の日本語追加事前学習(incremental pretrain) を試したメモ
	- https://zenn.dev/syoyo/articles/52f1d0d62fcad5
	- 生成される日本語はまあまあであるが, 構文やコンテキストがおかしい...
	- ファインチューンしても間違えたり...
	- まあでも 1B 規模なら妥当なのかもしれません
- 今号の『日本語の研究』で「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」と題して、OpenAIのtext-embeddingを使って、『万葉集』と『古今集』の意味構造の差を解析してみました。
	- https://www.musashinoshoin.co.jp/shoseki/view/2976/
- Energy and entropy: Path from game theory to statistical mechanics
	- https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.043055
	- エネルギーを低くするのが目標のプレーヤーと，エントロピーを上げるのが目標のプレーヤーの交渉ゲームにおける最適な戦略を通して熱平衡化を議論するらしい
- gpt-fast
	- https://github.com/pytorch-labs/gpt-fast
	- LLMをPytorchだけでどれだけ高速化できるかチャレンジしたリポジトリ Llama-7Bが10倍速くなっている 
	- Pytorchで使える高速化技術をいろいろ盛り込んでるぽっくて、中身見るのも勉強になりそう
- 日本語LLMでLLaVAの学習を行ってみた
	- https://qiita.com/toshi_456/items/248005a842725f9406e3
- googleから新しい翻訳トランスフォーマーを発表
	- Unsupervised speech-to-speech translation from monolingual data
	- https://blog.research.google/2023/12/unsupervised-speech-to-speech.html
-  業界別生成AI活用のすゝめ
	- https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/about-deloitte-japan/ai-dossier-2023.html?id=jp:2pm:3tw:4daii-genaidossier:5:6abt:20231201::
	- デロイトトーマツ
-  Microsoft Copilot is now generally available
	- https://blogs.bing.com/search/december-2023/Microsoft-Copilot-is-now-generally-available?ocid=aid_soc_usoc_edu_cons_bing_eng_tw_12.1
- C言語でWASMインタプリタを実装した話
	- https://zenn.dev/ri5255/articles/845ef3dab5ab47
	- この自作WASMランタイムの目的は、できるだけ仕様に従った実装を与えることで、仕様の理解を助けることである。早さや効率性よりも分かりやすさを優先しているため、実用には向かない。仕様書を読んで、実装に困った際に参照してほしい。
-  データ不足に数理モデルで立ち向かう / Japan.R 2023
	- https://speakerdeck.com/dropout009/japan-dot-r-2023
- Harsha Nori et al., "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
	- https://arxiv.org/abs/2311.16452
	- これまでGPT-4などの基盤モデルは、医学などの専門分野で特化モデルには敵わないと考えられてきました。 しかし、「実際はどうなのか？」と考えた研究者らは、特別なトレーニングなしのGPT-4が、プロンプトの工夫のみでどこまで性能を示すのかを検証しました。
	- ① アメリカの医学試験「US (4-option)」で90.2％という高い正解率を出した
	-  ② 理由付けが必要なタイプの問題データセットPubMedQAで82.0％の正解率を達成
-  日常能力を試すテスト『GAIA』正答率、人間92%に対してGPT-4は15%　一般的なニーズに応えるAI開発の指針に
	- https://aiboom.net/archives/59440
- Langchain102
	- https://www.youtube.com/watch?v=haad3i9VROs
	- Mistral 7b User Showcase + LangServe & LangSmith
- METAのAI研究者が何らかの大きなブレイクスルーがあったと示唆。 近日中に共有予定とのこと
	- https://x.com/ArmenAgha/status/1731076069170835720?s=20
-  「ChatGPTの1周年を記念して」、オープンソースLLMがChatGPTにどこまで追いついているか体系的調査報告
	- https://aiboom.net/archives/59713
	- https://arxiv.org/abs/2311.16989
	- オープンソースLLMとしてはLlama-2（およびMentalLlama）、Palm、Vicuna、Falcon、Wizard、Lemurなどのモデルに焦点を当て、それらの進歩のスピードと特定のタスクでの優れた性能について詳しく分析されています。調査結果からは、オープンソースLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示していることが明らかになりまし
- MRS2023(materials research society)でLLMが多い 2023 MRS Fall Meeting & Exhibit
	- https://x.com/yoko_materialDX/status/1731267042810962256?s=20
	- MIセッションが常時4つあり回るのが大変
	- 機械学習ポテンシャルと自動合成の発表が大量
	- 結晶構造予測の発表が思ったより多かった
	- LLMの発表は材料データ抽出が中心
	- 日本企業からのMI発表が多かった 
	- 世界情勢ゆえ？）中国本土の方がほぼいなかった

## 11/27

アルトマン氏解任劇は、マイクロソフトがアルトマン氏の受け入れを表明するも、OpenAIの主要メンバがアルトマン氏に追従すると表明したのでボードが復帰を懇願、結局OpenAIのCEOとして戻ることで幕引き。解任劇の背後には、OpenAIでAGI（スーパーAI)を達成する見込みが立った、それがQ*というLLMで、従来のLLMが苦手だった数の推論が可能になった、Q*の取り扱いを巡り解任騒動が起きた、といううわさで持ち切りに。Q*-learningがそれでは？みたなことになって様々なところで盛り上がっている。それ以外では、intelが満を持してneural-chat-7b-v3-1を公開、Mistral 7Bベースなんだけど、様々なチューニングにより相当性能が良いみたい、しかしFalcon 180B越えということはないと思うぞ。AnthropicAIが200kのコンテキストを扱えるClaude2.1を発表、デモ版が利用可能で、さっそく結構長文の日本語のPDFをそのまま投入できるとか、エバンゲリオン世界のシミュレーションを動かしてみたとか話題に。「３D世界の中で身体性をもった汎用エージェント」の論文、いや 「未来の二つの顔」（ホーガン）のAI（仮想３D空間シミュレーションで身体性を学習させる）を彷彿させる世界が現実になったような気がする。データベースに対するQ&Aにおいて、SQL文を生成される方法と、データベースの内容をいったん知識グラフにしてQ&Aする方法を比較し、後者のほうが高性能との報告も。まあコンテキストというかそういうのを与えたほうがいいに決まっているのだが。RAGにおいても、コンテキストをフィルタリングするのが有効らしい、そのあたりにまだ人の工夫の余地が残っている。Llemmaは、LLMで数学の問題を解くのに、定理証明器を使うことを前提にしたPythonコードを出力することで実現、LLMを活用して問題を解くメタなアプローチ（直接解くのではなくて、解く手順・方案を生成する）の１つ。LLMベースの新しい言語『SUQL』もいい感じで非構造データを扱えるらしいが、例題がレストランの会話とは第２世代AIにおけるフレーム問題ぽくていいね！AIが人間が思いつかないような「異質な」仮説を生成することで、科学が進化する、かも。ChatGPTをつかって、部屋を片付けている人がいた、これはすごい応用だ！OECDのAIの定義も生成AIや基盤モデルを鑑み４年ぶりに改定、人の指示に従わずとも、入力に対して自らのとるべき動作を推測するメタ能力についも暗示、もはやAIに対するソフトウエア的な品質保証は不可能な事態へ。

-  Banach-Tarski Embeddings and Transformers
	- https://arxiv.org/abs/2311.09387
	- 再帰的なデータ構造の線型空間での表現（バナッハタルスキ埋め込み）を考えるとその表現上のアルゴリズム（復号）がTransformerとして自然に実装できるらしい
- 大規模言語モデルを用いた意味分析による辞書記述への応用
	- https://speakerdeck.com/yhkondo/da-gui-mo-yan-yu-moderuwoyong-itayi-wei-fen-xi-niyoruci-shu-ji-shu-henoying-yong
	- 埋め込み（ベクトル化）の辞書作成への応用とか、枕草子を題材に埋め込みをつかたｔ類似検索してみる例が、英語による検索、絵文字による検索、クリエーティブな検索など事例があって面白い
- Shicheng Liu et al., "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models"
	- https://arxiv.org/abs/2311.09818
	- LLMベースの新しい言語『SUQL』が開発されました。SQLを拡張して「非構造化データのクエリ」を処理するパラダイムを導入
	- 『SUQL（Structured and Unstructured Query Language）』
	- ① 構造化データと非構造化データの両方を扱う 
	- ② SQLに、非構造化データをクエリするための新しいプリミティブを追加 
	- ③ 会話型検索エージェントでユーザーの質問を処理 
	- ④ クエリに関連するデータを構造化および非構造化データソースから抽出する
	- 従来の線形化テクニックや多段階検索および推論モジュールに比べて、SUQLは回収精度が大幅に高い
	- 実際のレストランに関するクラウドソースされた質問と会話を含むデータセットで実用性が確認された
-  Meta disbanded its Responsible AI team
	- https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence
	- metaが責任あるAIのチームを解散させた
- 状態空間モデリング入門
	- https://www.no-spare.com/store/products/seminar-20231129
	- 本講座では、金融時系列データへの応用を題材に、動的線形モデル・ボラティリティモデル・最新の研究を解説します。
-  Hypotheses devised by AI could find ‘blind spots’ in research
	- https://www.nature.com/articles/d41586-023-03596-0
	- AIが仮説を生成する際に直面する課題として、データの不足、物理的な法則の理解、仮説の一般性と解釈性などが挙げられています。
	- AIが仮説を生成する可能性として、人間が思いつかないような「異質な」仮説や、実験を自動化する「ロボット科学者」などが紹介されています
-  Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild
	- https://arxiv.org/abs/2311.06237
	- 大規模言語モデル(LLM)をしばき倒して、異常な振る舞いをさせようとしている人達（野良のLLMレッドチーム）へのインタビュー論文。攻撃方法やそもそも何のためにやっているのか？等の調査。
- アルトマン氏、ゲストカードを使って、OpanAIを訪問
	- https://x.com/sama/status/1726345564059832609?s=20
	- first and last time i ever wear one of these
-  ChipNeMo: Domain-Adapted LLMs for Chip Design
	- https://arxiv.org/abs/2311.00176
	- ChipNeMoはチップ設計支援向けにドメイン適応したLLM。開発支援Chatbot、EDAスクリプト生成、バグ要約と分析を行う。既存LLMに、専用トークンを追加した後、ドメイン適応事前事前学習（DAPT 230億トークン）、指示学習（1000例）をし、ドメイン適応検索補強を行う
- マイクロソフトのナデラ氏、アルトマン氏たちがマイクロソフトにJoinすると、、
	- https://x.com/satyanadella/status/1726509045803336122?s=20
- マイクロソフトによる生成AIのチュートリアル
	- https://github.com/microsoft/generative-ai-for-beginners
	- The free 12 lesson course is available on Github and will teach you everything you need to know to start building Generative AI applications.
-  Learning to Filter Context for Retrieval-Augmented Generation
	- https://arxiv.org/abs/2311.08377
	- RAGにおいて、コンテキストをフィルタリングする方法を学習する
	- 語彙および情報理論的なアプローチを通じて有用なコンテキストを特定し、テスト中にコンテキストをフィルターするためのモデルをトレーニングすることが含まれます。
	- FILCO は、コンテキスト フィルタリングに String Inclusion (STRINC)、Lexical Overlap、Conditional Cross-Mutual Information (CXMI) などの技術を使用
- 日本語対応 LLM(13B 規模)の, 行間を読むようなかしこさがあるか試したメモ(現状 Qwen 14B がベスト)
	- https://zenn.dev/syoyo/articles/59a5ccbbb5660e
	- 7B 以下(10B 未満)も試しましたが, 行間を読むほどのかしこさはなく, 13B 規模で飛躍的にかしこさが上がる感じだったので, 13 B 規模のを選んでいます.
	- qwen.cpp(llama.cpp variant)で f16 量子化版を動かしました.
	- q4 あたりに量子化だといくらかかしこさ落ちました(それでもほかの日本語 LLM よりよい結果をえられる)  また, Qwen7B もあまりかしこくはありませんでした.
	- Qwen 14B(Chat) ちゃんが行間を読むほどのかしこさを見せました!
- OpenAIがNPO+であるようなことが、今回のアルトマン氏解任につながったとの絵柄
	- https://x.com/GOROman/status/1726701627468546511?s=20
-  Azure OpenAI Service 入門 by npakaさｎ
	- https://note.com/npaka/n/n46e6ad252ce1?sub_rt=share_h
	- 「Azure OpenAI Service」で「gpt-3.5-turbo」を使用する手順をまとめました。
-  Orca 2: Teaching Small Language Models How to Reason
	- https://huggingface.co/papers/2311.11045
	- 小さいことはいいことだ
-  Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data
	- https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1
	- llamaindexのJerryが放つ、streamlitをつかった、RAGアプリ生成ツールRAGs
	- “ChatGPT over your data” without needing to code.
- Large-scale pancreatic cancer detection via non-contrast CT and deep learning
	- https://www.nature.com/articles/s41591-023-02640-w
	- ｢単純CTの膵臓がん検出AI｣
	- 単純CTでの膵臓がん検は不可能と考えられてきた 
	- そのAIを開発 
	- 現実世界のマルチシナリオ検証の病変検出で、92.9%の感度と 99.9% の特異度を達成 
	- 膵臓がんスクリーニングの新しいツールの可能性
-  RAG評価ツールの "RAGAS" を使って、RAGパイプラインの性能を測定する
	- https://qiita.com/s3kzk/items/44b8780c656b4f747403
	- 今回触れたチャンク分割時の設定以外にも、システムプロンプトの決定、Embeddingおよび応答の生成に使用するLLMの選定、ベクターストア/検索アルゴリズムの選定など、パフォーマンスに影響を与える要素は数多く存在します。
- アルトマン氏OpenAIに復帰すると
	- https://x.com/OpenAI/status/1727206187077370115?s=20
-  2週間使い倒してわかった｢GPT-4-Turboの衝撃｣。OpenAIの｢お家騒動｣で見逃してる場合じゃない
	- https://www.businessinsider.jp/post-278766
- AnthropicAIよりClaude2.1の発表
	- https://x.com/AnthropicAI/status/1727001773888659753?s=20
	- コンテキスト長はなんと 200k と 2 倍に拡大。ハルシネーションの低減、システムプロンプトへの対応、価格の引き下げ、外部APIとの連携機能(ベータ版) など
	- https://claude.ai/　でお試し可能
- ChatGPTで部屋の片づけをしている人がいいる
	- https://x.com/fjtn_c/status/1727216371711586402?s=20
	- （部屋の写真送って片付けタスクを分解してもらって、それを実行して写真撮ってまた進捗を送る→同じことを繰り返し）
- 愛新覚羅の孫（大井町の眼科医）の驚愕エピソード
	- https://x.com/aishinkakura_i/status/1727477535234248712?s=20
	- 学会でアメリカを訪れた際、イミグレーションで「清朝の子孫か」って尋問を受け、しばらく足を止められ…
- metaから、Getting started  with Llama
	- https://ai.meta.com/llama/get-started/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama2&utm_content=image
-  単行本が入るClaude 200kで僕と「エヴァンゲリオン」
	- https://note.com/shoty/n/n03bff29f683f
	- 日本語だと150ページいかないくらいが調理できるのではないかと思う。つまり**単行本一冊が入ってしまう**
	- エバンゲリオンの物語をシミュレートできるかという挑戦らしい
- 【DSにKaggleが必ずしも必要ではない話】
	- https://x.com/Nurruttan/status/1727495591905858016?s=20
	- データサイエンティストと言っても、 「①データアナリスト型」 「④データエンジニア型」 のキャリアプランではKaggle実績の重要性は低い
	-  一方で、 「②サービスグロース型」 「③製品開発型」 「⑤AI開発型」 は重要度は高い。
- Google BardでYoutubeとチャットできるように
	- https://bard.google.com/chat
-  「Paper Interpreter」を使って論文を読もう！
	- https://note.com/daichi_konno/n/nb1f1ac368a30
	- 東大の、紺野大地先生作成
	- **「論文をアップロードするだけで、内容を日本語で分かりやすく説明してくれるAI」**
- アルトマン氏電撃解任劇の裏に、OpenAIが、AGIを開発するめどがついたからという
	- Q*-learningという手法により、数値計算などLLMが苦手としていた課題も解けるようになった。
	- https://x.com/hbouammar/status/1727683545852768295?s=20
	- A*ってのは探索のアルゴリズムだけど、それのQ-learning版という話
- Intel謹製の、LLMが、リーダーボードで上位の性能をはじき出す
	- https://x.com/Yampeleg/status/1727679553714217421?s=20
	- https://huggingface.co/Intel/neural-chat-7b-v3-1
	- A 7B model from Intel almost as capable as Falcon 180B:これは本当か！！！
	- Base model: Mistral 7B. 
	- Fine Tuned on: SlimOrca 
	- DPO: LLaMA-13B vs ChatGPT Gens (Prefer ChatGPT)
- An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
	- ３D世界の中で身体性をもった汎用エージェント
	- 3D世界に対して、いわば記号接地するような訓練をすることで身体性(embodiment)を取得、自然言語処理、コンピュータビジョン、ロボティクスなどの多様なドメインで汎用的なタスクを解決できる汎用エージェントが構築できたという
	- 手段としては、3D世界の理解と相互作用を必要とする、オブジェクトレベルとシーンレベルの多モーダルなタスクを含む、規模と複雑さに優れたデータセットを慎重に作成
-  大規模言語モデル(LLM)をLoRAで強化する際に役立つ情報を研究者が公開
	- https://gigazine.net/news/20231123-llm-lora/
	- LoRAは画像生成モデルや大規模言語モデル(LLM)に追加の情報を学習させてモデルを微調整できる仕組
	- **◆LoRAの効果には一貫性がある**
	- **◆QLoRAを使えば追加学習時のVRAM使用量を大幅に節約可能**
	- **◆最適化アルゴリズムはAdamでもSGDでも大差ない**
	- **◆LoRAによる追加学習を繰り返すと性能が低下する**
	- **◆LoRAによる追加学習は単一のGPUで実行可能**
- Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall
	- Claude2.1の長コンテキスト能力に対する、ストレステスト
	- https://x.com/GregKamradt/status/1727018183608193393?s=20
	- 200K トークン (約 470 ページ) で、Claude 2.1 はドキュメントの一部の深さで事実を思い出すことができました。 
	- 文書の一番上と一番下にある事実はほぼ 100% の精度で再現されました 
	- 文書の上部にある事実は下部よりも低いパフォーマンスでリコールされました (GPT-4 と同様) 
	- ~90,000 トークン以降、ドキュメントの下部にあるリコールのパフォーマンスがますます悪化し始めました 
	- コンテキスト長が短い場合のパフォーマンスは保証されませんでした
- Why do tree-based models still outperform deep learning on typical tabular data?
	- https://hal.science/hal-03723551
	- Why do tree-based models still outperform deep learning on tabular data?” confirms tree-based models outperform deep learning and explain some of the reasons why.
	- When it comes to #tabulardata and #timeseries (by far the most important majority of data for almost any real company), deep learning is not one needs. 
- Pythonによるフェーズフィールド法入門: 基礎理論からデータ同化の実装まで
	- https://www.amazon.co.jp/dp/4621308882?_encoding=UTF8&psc=1&ref_=cm_sw_r_tw_ud_dp_RW79QAZKZRQ7K9N885XB
	- フェーズフィールド法においても,実験データを活用して物性値やパラメータを推定しつつ,シミュレーション精度を高められるような,データ同化と融合した手法の開発が進んでいる.そこで本書でも,データ同化の基礎からフェーズフィールドモデルへの実装方法まであわせて紹介する.
	- フェーズフィールド法では、秩序変数の拡散方程式と反応方程式を同時に解くことで、組織形成過程を計算します。拡散方程式は、秩序変数が拡散する際の挙動を記述する方程式です。反応方程式は、相の変化を記述する方程式です。
	- フェーズフィールド法は、金属の凝固、多結晶粒成長、拡散相変態など、さまざまな材料組織形成過程の計算に用いられています。また、応力場や電磁場における組織形成やナノスケールにおけるモデル化など、マルチスケール・マルチフィジックスを対象とした種々の工学分野にも応用されています。
- 「マスターアルゴリズム」の著者、Domingos氏、Q*-learningの効果をみて、人類の終焉を叫ぶ
	- https://x.com/pmddomingos/status/1727562239060656339?s=20
	- Q* can solve simple math problems that symbolic AI could solve 50 years ago. Panic! AGI is here! Humanity is over!
- A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases
	- https://arxiv.org/abs/2311.07509
	- impact of KGs for question answering on SQL databases: 54% accuracy vs. 16% with instructions directly on SQL databases.
	- SQL DBを参照して質問応答を行うシステムでは、LLMに直接SQLを参照させると16%の正解率しか出なかったがLLMをナレッジグラフにマッピングしてそれを参照させると54%に改善したという研究。
	- 本質的に持っている情報が同じでもデータ構造によってRAGの精度が変わることの一例ともみなせる
- うみゆき氏、Claude2.1の性能に舌を巻く
	- https://x.com/umiyuki_ai/status/1727875985167790529?s=20
	- Claude無料版試してみたけど、結構長文の日本語pdf入力して要約してってお願いしたら、ちゃんと内容読んで要約箇条書き出してくれた（目次丸写しではない）　３章の内容説明してって言ったらちゃんと説明してくれた。つまりちゃんと最後まで読んで答えてる。かなり的確な応答を返してくれる。それでタダ。これ相当スゴイね
- Yuhan Sun et al., "To be or not to be? an exploration of continuously controllable prompt engineering"
	- https://arxiv.org/abs/2311.09773
	- これまで「LLMの動きを観察して"プロンプトを調節"する」手法が追究されてきましたが、限界があるため「プロンプトによる"LLMの動きをダイレクトに調整"する」手法『ControlPE』
	- 自動運転システムなどを手掛けるセンスタイム社による
	- ControlPEは競合技術と比較してもプロンプトの影響をこまかく調整できる手法
	- ① LoRAを利用するアプローチ ② プロンプトの影響を連続的に微調整 ③ 従来のプロンプトエンジニアリングを補完する
- Q*のもともとのアイデアを出した論文著者が自論文を宣伝
	- https://x.com/McaleerStephen/status/1727524295377596645?s=20
	-  A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks
	- https://arxiv.org/abs/2102.04518
- Q*について著名なデータサイエンティストErnest Okumuraさんのコメント
	- https://x.com/pacocat/status/1728052432016470281?s=20
	- Q*がQ-learningから来ているかは知らないけれども、制作者にとって好ましい出力を得るために方策空間を探索する技術は今後さらに求められていくと思うし、RLHFみたいな分かりやすいアラインメントを超えてAGIみたいな文脈でも野心的な試みは増えてくるんじゃないでしょうか。
- Sparse Transformers：入力シーケンスの長さによる計算量増加問題への革新的なアプローチ
	- https://ai-scholar.tech/articles/transformer/sparseTransformer
	- Attentionのレイヤー毎の特徴を再現することで，計算量の削減を達成  
	- Sliding Window Attenion、Dilated Sliding Window Attention、Global Attentionという3つのAttentionを使ってTransformernの計算量を削減した  
	- 計算量を削減しただけではなくて，当時のSOTAを達成している．
-  Llemma: An Open Language Model For Mathematics
	- https://arxiv.org/abs/2310.10631
	- どうも、LLMをつかって、定理証明器をつかうpythonコードを生成するらしい。実際に説くのはpythonインタープリター＋定理証明器の組み合わせ。
	- The AlgebraicStack dataset of 11B tokensが提供される
	- Llema can solve mathematical problems using a Python interpreter and a formal theorem prover.
- LlamaIndex vs. OpenAI Assistants API
	-  RAG Evaluation Series: Validating the RAG Performance of OpenAI vs LlamaIndex
	- https://www.tonic.ai/blog/rag-evaluation-series-validating-rag-performance-openai-vs-llamaindex
- ChatGPTアプリの音声会話が無料ユーザーにも開放
	- https://x.com/IELTS_expert/status/1728326991676670222?s=20
	- 英語学習ソフトや有料レッスンが不要に
- JARVIS-1は本当はすごい、
	- https://x.com/ai_database/status/1728257353852797143?s=20
	- マインクラフト（広大なバーチャル世界で採掘や建設を行うゲーム）を上手にプレイするAI『JARVIS-1』が開発されました。 非常に複雑な動作を含む200種類以上の行動が可能とのこと。
	-  このような技術を応用すると、ロボットが現実世界でもさまざまな重要タスクを達成できるようになる可能性があります。…
- 最終的にすべての統計はベイズに行き着くしかないと思っています（統計数理研究所、鎌谷氏）
	- https://www.ism.ac.jp/ism_info_j/labo/project/162.html
- ルカン先生によるQ*に対する表明
	- https://x.com/ylecun/status/1728126868342145481?s=20
	- 「Q*に関する完全なナンセンスの洪水は無視してね。LLMの信頼性を向上させる主な課題の1つは、自己回帰的トークン予測をプランニングに置き換えることです」
- Macでllama2を試すためのswift-chat
	- https://github.com/huggingface/swift-chat
	- Llama 2 7B chat, running 100% private on Mac, powered by CoreML!
	- Pedro Cuencaさんは現地時間2023年08月08日、Apple Silicon MacなどAppleデバイス上で大規模言語モデル(LLM)を実行するためのSwiftパッケージとDemoアプリを公開
	- SwiftでTransformersライクなAPIを実装するために開発したSwiftパッケージ”swift-transformers”と、Demoアプリ”swift-chat”、加えてTransformersモデルをCoreMLへ変換するコンバーター”transformers-to-coreml”で、
	- CoreMLが役に立ったと、、
- OECD、生成AIや基盤モデルを考慮しつつAIの定義を改定、
	- https://www.euractiv.com/section/artificial-intelligence/news/oecd-updates-definition-of-artificial-intelligence-to-inform-eus-ai-act/
	- 欧州AI法などの他の規制との整合性も考慮したアライメントととった
	- 目標を人間が定義する必要があるという事実への言及を削除、
	- 「出力の生成方法を推測する」という文言も、AI モデルが環境から入力を受け取り、1 つ以上のアルゴリズムを通じて適切な出力を思いつくときを説明するために導入

## 11/20

今週は、OpenAIのCEOアルトマン氏の電撃解任が全てを持って行った。先週OpenAI dev dayで雄姿を、そして人類の未来を垣間見たのに。。ボードから復帰の要請もあるというし、まだまだ現在進行形。さて、RAGもembeddingをつかった類似検索よりも構造を加味した検索とか、多様性をもつ検索結果の利用とか、だんだん、推薦技術などで確立されたノウハウが活用され始めた。LlamaIndexの新機能、text-to-SQL+semanticってのがいいね。LLMのファインチューニング関係もにぎやか、単に論理ソルバーを外部にもってて、自然言語からソルバーに渡す論理式を生成するよりも、ソルバーのログをそのままファインチューニングに使って、解く行為そのものを模擬するというLoGiPTとか、結晶構造をシンプルなテキストで表現しLLaMA-2をファインチューニングして、VAEを上回ったという事例とかがある。そもそもですわね、新しいOpenAIのファインチューニング、200個程度のデータでも、お嬢様LLMぐらいはできるみたいでございますです。LLMはそのメタな能力も重要な要素。プロンプトエンジニアを作るメタなプロンプトをつくったり、ユーザーのプロンプトをLLMが理解やすいように書き換えるプロンプトとか、こっち方面のメタな世界もいい感じで発展している。（ちょっと視点を変えた）ファインチューニングとLLMのメタ能力を利用するのがLLM活用の次のステージか。create-llamaとか、OpenGPTとか、LLMA Factoryと、自動的にアプリを作る仕組みがたくさん出てきた。 わずか1分で10日間の天気を予測可能なAI「GraphCast」、お茶の水大学の神山先生の解説が、従来の手法が不得意なところにGraph transformerがぴったり合ったというところが腹落ちします。Microsoftの発表したCopilot、つまりGPTsのＭＳ版。こういう世界観になるよな。早速OpenCopilotとか、WebCoPilotとか、あっというまに、似たようなOSSが、、、。Yahoo知恵袋、ついにGPT-4をつかった自動回答をテスト中。人の衆知はChatGPTに敗れたのか。。ＭＣ業の紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される、ＭＣ業もＡＩに代替される？されない？まあ、ChatGPTで仕事がなくなったのは、ChatGPTのCEOも例外ではないというのはブラックジョークかも。

- Adding Structure-Aware Retrieval to GenAI Stack
	- https://medium.com/@yu-joshua/adding-structure-aware-retrieval-to-genai-stack-373976de14d6
	- 単なるembeddingをつかった類似検索のRAGではなくて、構造を抽出したうえでの、RAGっての有効であることを、neo4j+LangChainの実例で示した良例
	- This stack is (1) fully local, (2) uses advanced retrieval methods that encode relationships between different chunks of texts
- LlamaIndex によるOpenAIの新機能を使用・理解するためのガイド by npakaさん
	- https://note.com/npaka/n/n728fdb8f76da?sub_rt=share_sb
	- Parallel Function Calling、Assistant API Agent、Function Callingによる高度なRAG、マルチモーダルRAG
	- GPT Builder、プロンプトを自動性生成することで、GPTを生成するmetaなツール
	- 「text-to-SQL と semantic search のジョイント」なんかは興味深い
- 日本の女性が先進国の中で長命なのは、社会進出が進まなかったから？
	- 旭リサーチ
	- https://arc.asahi-kasei.co.jp/report/arc_report/pdf/rs-824.pdf
	- 「先進国の中では女性の社会進出が進まなかったことが、 世界一の女性長寿に結びついたと思われる。」 
	- 「均等法は女性の平均寿命を短縮させる要因である。」
- gpt-3.5-turbo-1106を使った、新しいOpenAIのファインチューニング
	- https://x.com/matsu_vr/status/1723688378795958670?s=20
	- でお嬢様チューニングしてみました。200例の会話で十分お嬢様になった！
- Boosting RAG: Picking the Best Embedding & Reranker models
	- https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
	- RAGをやるにあたってどれを使えばよいかを調べたブログ。OpenAI ChatGPTやGoogle PaLMなどで作った embeddings と BAAI 等が提供している reranker で、どの組み合わせが精度が良いか
- OpenAI Dev dayを受けた、llamaindexのハイレベルAPIのアプデまとめ
	- https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p
	- 大変だー
-  Prompt Engineering a Prompt Engineer
	- https://huggingface.co/papers/2311.05661
	- プロンプトエンジニアを作るメタなプロンプトを作るという話、LLMってメタ能力があるので、こういう試みが可能。CoT越えというのは本当か？
- ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』
	- https://aiboom.net/archives/51160
	- 例えば「GPT-4で言い換えてGPT-3.5で入力する」も有効とのことです。 実行テンプレートや性能等を詳しく紹介する記事を公開しました
-  Language Models can be Logical Solvers
	- https://huggingface.co/papers/2311.06158
	- 従来SOTAは、solver-augmented language modelsをつかって、自然言語からシンボリックなロジックを取り出して、外部ソルバーで説いていたが、、文法があってないとかそういう下らないエラーに悩まされてきた
	- LoGiPTは、直接論理的な導出をエミュレートする、既存ソルバーのログをデータセットとして、ファインチューニングした。問題は解決された
	- https://x.com/IntuitMachine/status/1724104506185580589?s=20
-  JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models
	- https://arxiv.org/abs/2311.05997
	- JARVISって確か、アイアンマンのサポートAIの名前では？？
- 人間の情報処理にとって「ちょうどいい塩梅」の速度を超えとる気がする by 谷チュー
	- https://x.com/rmaruy/status/1724044250286108818?s=20
	- Buonomano『脳と時間』によれば、脳には単一のクロックはない（多重時計原理）。が、進化の過程で生物が相手にしてきた時間スケールより大幅に速い情報処理はできないだろう。一方、情報の「量」に関してはまだ工夫できるかもしれない。
- DPOでcalm2の物語生成能力を向上させる試み、
	- https://x.com/_oshizo_/status/1724039980463657130?s=20
- リアルタイムでLLMが文字を生成する様子のデモ、
	- https://x.com/dylfreed/status/1723927399857901724?s=20
	- llamacppをつかって8GB RAM MacBook Airで動くんだとさ
- LLMって結局何かをシンプルに説明する
	- https://x.com/davidad/status/1723990400682148124?s=20
	- ディープ ニューラル ネットワークは、各層間に要素ごとの非線形性を持つ線形回帰のサンドイッチ構造です。LLM/GPT の爆発的な増加に直接つながった「Attending is All You Need」の核となる貢献、そこに *ロジスティック* 回帰を非線形層に投げ込むことですまた、ドロップアウトについては@geoffreyhinton 、活性化正規化については@ChrSzegedy 、および勾配正規化については@dpkingmaによるものです (Adam)。
- ローカルLLMを動かすPCを自作
	- https://note.com/ai_meg/n/n8855a8dd4bbd?sub_rt=share_pb
	- マザーボード：Asrok　B760 PRO RS/DS  
	- CPU：i5-13400F  
	- GPU:PALIT　GFORCE-RTX4060ti-16G
- RETOOLのState of AIレポート
	- https://retool.com/reports/state-of-ai-2023
	- 66% of companies have at least one AI use case live
	- Accuracy is #1 concern
	- RAG is 2nd most popular use case (1st is code)
	- @llama_index is one of the leading frameworks for enterprises 
- OpenGPTはどんどん進化する
	- https://github.com/langchain-ai/opengpts
-  The Alignment Handbook
	- https://github.com/huggingface/alignment-handbook
	- Robust recipes to align language models with human and AI preferences
- EditGPT
	- https://chat.openai.com/g/g-zpuYfzV7k-editgpt
	- Grammeryのような機能を持つGPTsが、、
- 岡野原さんの、「拡散モデル」が今年度の大川出版賞に選出
	- https://hillbig.github.io/diffusion-models/
	- http://www.okawa-foundation.or.jp/activities/publications_prize/list.html
- これは衝撃!1.5Bで超高性能LLM!RWKV-5-World-v2 by shi3zさん
	- https://note.com/shi3zblog/n/nfc8dd1abf494?sub_rt=share_pb
	- まだ生きてたのか、RWKV
- The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4
	- https://arxiv.org/abs/2311.07361
	- Evaluates GPT-4’s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilitie
	- MSからの論文、製薬とかの話が多いが、なんかつまらん
- Open AI主任科学者のIlya Sutskever氏は昨日のインタビューにて、AGIにたどり着くためにはTransformerアーキテクチャ＋αで「明らかに」問題ないと
	- https://www.youtube.com/watch?v=Ft0gTO2K85A
- 大規模言語モデルのFine-tuningによるドメイン知識獲得の検討
	- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/
	- 英語で主に学習されたLLaMA2に対して日本語データを用いたInstruciton Tuningや追加事前学習がどの程度可能かの検証
	- 不可思議な結果が出がちなので、いろんな設定で試さないといけないことがわかった
- LangChainから、Query Construction Guide、text-to-SQL+semantic最強節
	- https://blog.langchain.dev/query-construction/
	- 1. Structure+unstructured data:  Text-to-SQL+semantic (w/ PostgresSQL with the Pgvector 
	- 2. Unstructured w/ metadata: Text-to-metadata filters (w/ new docs + a template for self-query retriever)
	- "Text-to-SQL+semantic" is an interesting recent addition to LangChain that extends "Text-to-SQL" w/ semantic queries on an embedding column.
	- そうか、やっぱり text-to-SQL+semantiが最強なのか
- 『Chain of Empathy（共感の連鎖）』
	- Yoon Kyung Lee et al., "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"
	- 心理療法のセオリーを反映したプロンプト手法『Chain of Empathy：CoE』を開発し、その性能を検証
-  Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
	- https://openreview.net/forum?id=0r5DE2ZSwJ
	- 言語モデルによる結晶構造予測
	- 結晶構造をシンプルなテキストで表現しLLaMA-2を微調整することで、VAEの従来手法よりも安定な結晶構造を生成できた
	- この手の手法はモデル構築にお金と時間がかかるところが課題
- create-llama, a command line tool to generate LlamaIndex apps
	- https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191
	- コマンドラインでllamaindexをつかたたアプリを生成する仕組みの公開！！！
- GPT4などが、常識をもっているかどうかのテストデータセットによる評価
	- https://github.com/allenai/everyday-things
	- The LLMs have poor accuracy (54-59%) on commonsense spatial/functional relationships in ParRoT dataset.
	- This suggests the LMs do not have fully coherent conceptual pictures of everyday objects.
- LLMA Factory
	- https://github.com/hiyouga/LLaMA-Factory
	- Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- WebPilot
	- https://chat.openai.com/g/g-pNWGgUYqS-webpilot
	- 記事や論文、PDF などの抽出系の便利 GPTs を作ったけれど、すべて WebPilot で十分だった(めこめこさん)
- beさん、毎日ベルマン方程式を解いて日常を過ごしていると、
	- https://x.com/behemuhemulove/status/1724408454348194303?s=20
- 【HELP ME】Assistants APIで破産しそうになった話
	- https://note.com/nike_cha_n/n/n65a6101d59d7
	- ちゃんと計算しないとあっという間に上限に達するかも、
- Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion
	- https://arxiv.org/abs/2311.06318
	- MSより
	- Microsoft Research presents a method to personalize LLMs for search via entity-based user knowledge stores derived from logs.
- Yahoo知恵袋、GPT-4を用いた、自動回答をテスト中
	- https://chiebukuro.yahoo.co.jp/topic/ai/answer.html
	- 人知は不要になったのか。。
-  Trusted Source Alignment in Large Language Models
	- https://huggingface.co/papers/2311.06697
- GPT paper asistantのソース
	- https://github.com/tatsu-lab/gpt_paper_assistant
	- スタンフォード大学の橋本先生謹製
- Licheng Wen et al., "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving"
	- https://arxiv.org/abs/2311.05332
	- 視覚を手にしたLLMが自動運転にどれほど役立つのかを探るため、GPT-4Vの能力が検証されました。 
	- さまざまなタスクで実験したところ、「因果関係の推論」や「シーン（景色）の理解」に長けていると結論づけられました。
- うるさいやつ、技術を理解しないと、ビジネス展開のきっかけが出てこない、エンジニアを蔑視して、それを商売にしているのが嫌い。
	- https://x.com/toukatsujin/status/1724196831109017964?s=20
	- 「技術力を磨かないと生き残れないと思っているエンジニアがほとんど。でも技術は日々進化・変化しており、これを学べば一生安泰ということはない。むしろビジネス理解力を磨いたほうが一生安泰なのに、エンジニアの多くは分かっていない」
- Rapidly build an application in Gradio power by a Generative AI Agent
	- https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent?hl=en
	- Gradio の作者の初めての論文といううわさも
- ChatGPTとDeepLの字幕翻訳の比較
	- https://x.com/gijigae/status/1724345403234193540?s=20
	- ChatGPTは、①英語字幕を繋ぎ直す ②日本語に訳す ③訳したテキストを自然な流れになるように分け、元のタイムスタンプへ戻す といった一連の作業を全部やってくれる。
- GPTsとAsistant APIの違い
	- https://x.com/gijigae/status/1724428173905989945?s=20
	- GPTsとAssistants APIはカスタマイズしたChatGPTが作れる点で似ている。ただ、ChatGPT Plusへの加入やステート管理を含め、違いも多い↓。忙しくて一つしか試せないという方には後者をお勧めしたい。特に、カスタマイズしたChatGPTを生徒に公開する際、ChatGPT Plusへの加入が不要となるのは大きい。
- 「表象（representation）」概念を分析するRPPFプロジェクト
	- 神経科学などで多用されるが曖昧で問題含みの「表象（representation）」概念を、20～30名の哲学者と神経科学者で分析する「Representation: Past, Present and Future (RPPF) project」
	- https://www.thetransmitter.org/representation/what-are-we-talking-about-clarifying-the-fuzzy-concept-of-representation-in-neuroscience-and-beyond/
- コード生成・補完に特化した日本語LLM「ELYZA-japanese-CodeLlama-7b」を公開しました（商用利用可）
	- https://note.com/elyza/n/n5bce23d7c9c8
	- https://zenn.dev/elyza/articles/fcbf103e0a05b1
- わずか1分で10日間の天気を予測可能なAI「GraphCast」をGoogle DeepMindが発表、スパコンで数時間かけた予測より高精度
	- https://gigazine.net/news/20231115-google-graphcast-global-weather-forecasting/
	- https://github.com/google-deepmind/graphcast
- RAG over Governments Document
	- https://github.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Chatting%20with%20your%20Docs.ipynb
- GGUF 版の 5 bit 量子化された Llama 2 を WasmEdge で。7B が 24 token / sec で動作しました↓
	- https://www.secondstate.io/articles/fast-llm-inference/
	- Mac ユーザは見たらとりあえず試して。コマンド４行叩くだけなので！Rust x Wasm で Llama 2 推論がローカルで動きます
- ELYZA-japanese-CodeLlama-7b-instructのggufフォーマット変換版
	- https://huggingface.co/mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf
- マイクロソフトは Copilot Studio を発表
	- Igniteの中で最後に発表、GPTsみたいなものになる
	- 
- お茶大、神山先生による、Googleの気象予測の気象学者からの解題
	- https://x.com/kohyama_met/status/1724986380546408878?s=20
	- 「AI気象予報論文」の感想を投稿したら思いのほか反響が大きかったので、気象学者かつ情報科学科教員として、いくらか真面目に解説します。
	- アーキテクチャが従来型モデルの不得手にうまくハマっている
- Research Assistantのテンプレートが公開される
	- https://github.com/langchain-ai/langchain/tree/master/templates/research-assistant
	- With this template you can easily plug in an arbitrary retriever, allowing you to do research over a knowledge base of your choice.
- 東大 松尾研のPRML（パターン認識と機械学習）輪読会スライド集
	- https://www.slideshare.net/matsuolab/
	- 黄色い本はやっぱり、聖典
- OpenCopilot
	- https://github.com/openchatai/OpenCopilot
- tldrawが洒落にならないぐらい優れている
	- https://makereal.tldraw.com/
	- ラフなUIの図解や説明をつくるだけで、GPT-4Vで認識して良い感じに仕様を解釈して実際に動くモックアップを作ってくれる
- 紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される
	- https://x.com/03sasa03/status/1725479562094755951?s=20
-  OpenAI announces leadership transition
	- https://openai.com/blog/openai-announces-leadership-transition
	- えっ！
	- 「取締役会とのコミュニケーションにおいて一貫して率直さを欠き、取締役会の責任遂行を妨げている」
- OpenAIから追い出された直後の、Sam Altomanのツイート
	- https://x.com/sama/status/1725742088317534446?s=20
	- i love you all.
- 西浦先生の論文に、筑波大の掛谷氏がかみつくも、統計の専門化から返り討ちに
	- https://x.com/behemuhemulove/status/1725749314000175387?s=20
	- 主な問題点 (1) クロスバリデーションの評価なし (2) 短期予想モデルの結果を繋ぎ合わせて長期のシナリオを作っている 明日の天気を高確率で当てるモデルを作っても、その予想を繋ぎ合わせ、、、
	- be氏より、（2）は例えば1年後の予測するとして1ヶ月ずつ予測してくのか、年単位で予測してくか位の違いしかなく、統計学やMLでは全く問題ないと思うので、この点叩いてる方が統計学の観点から無知にみえる
-  create-llama によるLlamaIndexアプリの作成 by npakaさん
	- https://note.com/npaka/n/neafa42455864?sub_rt=share_h
- 体軸が直立した時点が人類が自己を認識した分岐点かもしれない
	- https://x.com/daijapan/status/1725841037086892358?s=20
	- 認知科学講座より、
- Building Research Assistant	
	- https://www.youtube.com/watch?v=DjuXACWYkkU
	- YouTube tutorial on building one from scratch. Covers LCEL, LangSmith, parallelization, retrievers
- Ilya Sutskeverって誰ぞ？
	- https://x.com/mr_bay_area/status/1725808417376473167?s=20
	- 「自然言語処理業界が深層学習一色になる流れを決定づけた人」ですね。それくらい彼が作ったseq2seqは衝撃だったし
- :smile:、:ikanai:
	
## 11/13

今週は、OpenAI Dev Day(11/6)が全てあり、LLM周りの風景が一変した。GPT-4 TurboやAssistant APIや、価格の改定（安くなった）、最後に独自のGPTをつくれるGPT Builderと、OpenAI まわりのOSSエコシステムを破壊するがごときの怒涛のリリース。対応するOSS側のLangChainやllamaindexも新機能の取り込みや対案実装で忙しい週だった。Assistant APIって、**Code Interpreter**、**Retrieval**、**Function Calling**　が呼び出せ、APIからも作れるけども、playgroundからも作って簡単に試せる。Assistant APIに実装された機能(Assistants/Theads/Run )を組み合わせれば、エージェントも簡単に作れる。詳しくはNakajimaさんのGPTvsGPTが良い例。無限に環境問題についてエージェント同士が討論するというデモはちょと地獄絵。早速、LangChainも、LlamaIndexも、Assistant APIをつくってエージェントを作る機能を公開、もともとあるエージェントと組み合わせてみたいな発展も。OpenAI のRetreive機能は、pdfやdocやpptやmarkdown等多彩なデータを読んで、コンテキストとしてChatできる機能。まさに、RAGつぶしなんだけども、llamaindexの人Jerry Liuによると、コンテキスト長の限界を超えると普通のtop-k式の単純なRAGが動いているのではということ。試しにナウシカ(Wikipedia、57kトークン)をGPT-4でやってみたら、確かに性能よかった。RAGについては自ら（ベクトル化の方法などの）細かいチューニングに走るか、それとも入り口だけ用意してあとは、別のOSS等にという戦略のどちらだろう？GPT-4もファインチューニングできるようになったが、$3M(５億円弱)の[Submit]ボタンは押せない。。GPT-4を半端にファインチューニングしても性能は向上しないというのもすごいな。エージェントの作成支援も、llamaindexからbuilder agent、Langchainからも、OpenGTPが発表。OpenAI本家もGPTsで、好みのGPTを作って公開という機能が公開、Plusユーザーなら他人のGPTを使うこともできる。タイムラインに、どんどん、独自のGPTが公開されて、まさに百花繚乱、これに利用料を還流する仕組み整えば、まさにマーケットプレース経済圏に一直線。マルチモーダルのRAGというのも出てきた。PFNのPLaMo-13B-Instructの公開や、日本語向けのベンチマークデータの改定や、shi3zさんによるマルチターン日本語会話データセットの整備など、日本語対応の改良も着実に進んでいる。「アナロジア AIの次に来るもの」のダイソンによると、LLMは、（デジタル・コンピューターによるAIの限界を超えることができる）アナログコンピュータに近いものらしい。ダイソンの本を読みなおすと、AGIの可能性についても、デジタルでは到達できないが、アナログならば可能性は排除できないみたいな主張だった。最後に、ChatGPTの登場は、デザイナやコピーライターの職を奪うだけでなく、単価も下げた、特に高収入の層を、というFTの記事が怖すぎる。

- ALMA-7B-Ja-V2
	- https://huggingface.co/webbigdata/ALMA-7B-Ja-V2
	- 翻訳タスク特化のALMA-jaのV2来とる！!GPTQもある
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT
	- Microsoftから発表されたテーブルタスクのトレーニングデータを用いて「テーブルチューニング」するモデルTable-GPT
	- 多様なテーブルタスクにてGPT-3.5やChatGPTより高性能、高い汎用性を示す
	- https://arxiv.org/abs/2307.08674
- OpenAI dev day
	- GPT-4 Turbo 発表 
	- コンテキスト長128k
	- JSON Mode 
	- ナレッジカットオフ 2023/04
	- DALL E-3 / Text to Speech 
	- Whisper v3 
	- GPT-4 Fine-tuning可能に
	- GPT-3.5 Turbo はもう 16K がデフォレベルでさらに安くなり、GPT-4 Turbo は価格が入力 1/3, 出力 1/2 になった
	- 「従来の16倍となる300ページを超える長い文書を扱えるようになり、2023年4月までの情報を反映」
	- functionsとfunction_callが非推奨になってtoolsとtool_choiceになったんだ
- ノーコードで「ChatGPT」のカスタム版を作れる「GPTs」、有料会員に提供へ
	- https://www.itmedia.co.jp/news/articles/2311/07/news074.html
	- プロンプトからの指示で対話しながらオリジナルのChatGPTを構築できる。「Web検索や画像作成、データ分析などと同じくらい簡単」としている
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
	- https://huggingface.co/papers/2311.02303
	- MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, CodeFuse-CodeLLama-34B, achieves an impressive pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\%, zero-shot).
- Assistants API の解説と動作確認（Google Colab）
	- https://note.com/schroneko/n/nd04c46242171
- llamaindexから、OpenAI dev dayをうけGPT builderを模擬するBuilder Agentの例を公表
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb
	- https://x.com/jerryjliu0/status/1721639447207583882?s=20
	- 例：「トロントのことをよくわかるエージェントを作成」→エージェントができる。。
- LangChainから、OpenGPTの発表、
	- https://github.com/langchain-ai/opengpts
	- builds upon LangChain, LangServe and LangSmith This gives you more control over the LLM you us
- OpenGTPは、 LangSmithに連携するだけで利用ログが取れるので、あとはエージェントのToolsを充実させれば、それなりのものが提供できる
	- https://x.com/mah_lab/status/1721684588874055764?s=20
- Levels of AGI: Operationalizing Progress on the Path to AGI
	- https://arxiv.org/pdf/2311.02462.pdf
	- DeepMindから、AGIにいたるLevel0からLevel5までの段階を示す、レベル分けのOntologyを提案といっている
	-  AGI by considering generality (either Narrow or General) in tandem with five levels of performance (Emerging, Competent, Expert, Virtuoso, and Superhuman).
-  OpenAI Python API Library v1.0 入門　by npakaさん
	- https://note.com/npaka/n/n27b94df96179?sub_rt=share_sb
	- 「OpenAI Python API Library」のインタフェースが一新された、らしい
- GPT-4のfine-tuningで有効なgainを得ることが3.5-turboより難しい
	- パートナーを選ぶ形でCustom Models programを提供する戦略へ転換か、
	- GPT-4がすごすぎるので、中途半端なファインチューニングはかえって性能を劣化させる。。。。
	- https://openai.com/blog/new-models-and-developer-products-announced-at-devday
- Assistants APIを利用すれば、TOEICやTOEFL、英検、IELTSに特化した家庭教師も一瞬で作れる
	- https://x.com/gijigae/status/1721737796724183504?s=20
	- いままで、OpenAI Plus(3k円/月)で実現していたものが、Assistans APIで、月1,500円程度の半額になるというお話、なるほど
- OpenAI APIのRetrievalた多種ファイルに対応
	- OpenAI API の今回のアップデートに含まれていた Knowledge Retrieval (ファイル内検索を可能にする機能) は PDF はもちろん Word やパワポ、ソースコードも対応してるようだ。 RAG 関連のサービスはホント要らない子になっちゃったね
- OpenAI Assistantsで試しに英語論文を要約するアシスタント作成例
	- 今回新たにAPIが発表されたRetrieval機能を使ってPDFファイル添付をしてみてます。
	- https://x.com/alexweberk/status/1721705504228192373?s=20
	- DPOの論文26ページ分くらいの要約で$0.80くらい
-  GPT-3.5-Turbo / GPT-4-Turbo 1106のJSONモードの使い方 by [shi3z](https://note.com/shi3zblog)さん
	- https://note.com/shi3zblog/n/nd72e0269dc3f?sub_rt=share_pb
- OpenAI DevDay で発表された新モデルと新開発ツール まとめ by  [npaka](https://note.com/npaka)さん
	- https://note.com/npaka/n/n9cd206d96f85?sub_rt=share_sb
	- 「Function Calling」に、単一メッセージから複数のFunction (「車の窓を開けてエアコンをオフにする」など) を呼び出す機能などが追加されました。精度も向上しています
	- 16Kコンテキストウィンドウをサポートする新しい「GPT-3.5 Turbo」もリリースします。指示追従、 JSONモード、並列 Function Callingをサポート
	- 「Assistant API」は、特定の指示を持ち、追加の知識を活用し、モデルやツールを呼び出してタスクを実行できる専用のAIです。
	- アシスタントは、必要に応じて、**Code Interpreter**、**Retrieval**、**Function Calling**を呼び出せる
- Google Colab で OpenAI API の Retrieval を試す by npakaさん
	- https://note.com/npaka/n/ndcacbefb2ef7
	- APIからAssistantを作る方法、結果はplaygroundでも確認できるというか、playgroundでassistant作成の別のやり方
- Putting numbers into a better perspective and classifying them according to their level of complexity
	- https://thinkzone.wlonk.com/Numbers/NumberSets.htm?platform=hootsuite
- GLaMM: Pixel Grounding Large Multimodal Model
	- https://huggingface.co/papers/2311.03356
-  GPT-4VのAPIをサクッと使ってみる！
	- https://note.com/peisuke/n/nef0616b8d7fc?sub_rt=share_sb
	- 早稲田大学の講義のページを使わせてもらいます。制約条件付き最適化の問題を解かす→解ける。
	- "画像の数式の応用例を一つ挙げ、何らかの適当な数値を設定し、それを解くためのプログラムを作成してください"
- Google Colab で OpenAI API の Text-to-Speech を試す by npakaさん
	- https://note.com/npaka/n/nba4af88eb3cf?sub_rt=share_sb
	- 6つの内蔵ボイスが付属しており、次の目的で使用できます。
		- 書かれたブログ投稿のナレーション
		- 複数言語の音声を生成
		- ストリーミングを使用したリアルタイムオーディオ出力
- Bayesian Optimization of Function Networks with Partial Evaluations
	- https://arxiv.org/abs/2311.02146
- Assistance APIについて
	- これまでなら自力 or LangChain でやってきたことが、それなりに Assistants/Theads/Run などでできるようになっちまったぜ
	- OpenAIの [#AIアシスタント](https://twitter.com/hashtag/AI%E3%82%A2%E3%82%B7%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%88?src=hashtag_click) は面白いけど、またお金が飛んでいく
- Assistances APIをつかって、GPTvsGPTを作る例
	- https://x.com/yoheinakajima/status/1721769833212281231?s=20
	- https://github.com/yoheinakajima/GPTvsGPT
	- 例として、地球温暖化テーマに対する、海賊vs人魚の論争をシミュレーション！
- Langchainから、OpenAIの assistance APIのサポートを発表
	- https://github.com/langchain-ai/langchain/blob/master/cookbook/openai_v1_cookbook.ipynb
	- Spin up OpenAI assistants and run them as any other LangChain agent!
	- LangChainのAgentと同じように、OpenAIのagentを使える、らしい
	- OpenAIAssistantRunnable.create_assistan
- Contrastive Error Attribution for Finetuned Language Models
	- https://arxiv.org/abs/2212.10722v2
	- 文書生成においてハルシネーションを引き起こすデータセット内のデータを高精度で特定する手法の提案。
- Tokyo Digital Twinが、
	- https://info.tokyo-digitaltwin.metro.tokyo.lg.jp/
	- 調布市の3次元 [#点群](https://twitter.com/hashtag/%E7%82%B9%E7%BE%A4?src=hashtag_click) をダウンロードしました! さらに独自の手法にて建物・植物・地表面の自動分類を行いました
- GPT-4のファインチューニングには、５億円かかる？？？
	- It costs $2-3 million to train a custom GPT-4 model with your own dataset.
	- https://x.com/tdinh_me/status/1721835213121265840?s=20
	- いや、この「Submit」ボタンは押せない。。。
- GPT4 Turbo はPyllms ベンチマークでGPT4を凌駕
	- https://github.com/kagisearch/pyllms
	- https://aider.chat/docs/benchmarks-1106.html
- CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding
	- https://huggingface.co/papers/2311.03354
- QGIS 3.34で3DTilesが表示できるようになったので、3D都市モデルPLATEAUの3DTilesをQGISで表示してみました
	- https://x.com/shi__works/status/1721808786393121197?s=20
	- https://north-road.com/2023/11/07/qgis-3d-tiles-thanks-to-cesium-ecosystem-grant/
- OpenAI Assistants API(Playground)を使ってコーディングのアドバイスをしてくれるアシスタントを作る
	- https://zenn.dev/karaage0703/articles/66949a39643557
	- 今まででも、Custom InstructionsとAdvanced Data Analysis（Code Interpreter）でできていたことを、手軽に切り替えられて便利になった。API経由でできるようになったということなので、本質的な変化というよりは順当なアップデート
- 自分の癖にあったファインチューニング用データセットをLLMで作ろう！【Calm2】
	- https://zenn.dev/saldra/articles/090c120b49e38c
	- LLMのファインチューニングにおいて、データセットは重要なものとなりつつある
	- 以前までは人力で作る必要があったが、プロンプトが効く7Bモデル（Calm2-chat）を用いることで、LLMでファインチューニング用データセットを作ることができる
	- データセットを作成しつつ、動的にプロンプトを修正していく手法が相当よかった
- HuggingFace Diffusers v0.22.0の新機能 by npakaさん
	- https://note.com/npaka/n/n5aebfc60408a?sub_rt=share_sb
- OpenAI Assistants APIに拙著「エンジニアの知的生産術」を入れて質問。これこそ「書籍を読む方法の効率化」だな感
	- https://x.com/nishio/status/1721857526990586203?s=20
- OpenAIの AIアシスタント に子猫の絵を描いてもらいました
	- https://x.com/itnavi2022/status/1721945299713941944?s=20
- 日本語対応13BモデルのPLaMo-13B、インストラクションチューニングされた
	- 対話性能を向上させた指示学習（instruction tuning）済み大規模言語モデルPLaMo-13B-Instructを公開しました
	- https://tech.preferred.jp/ja/blog/llm-plamo-instruct/
- llamaindexもOpenAIのAssistanceに対応
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb
	- OpenAIのRetrievalとllamaindexのRetrievalを組み合わせることが可能！！！
- OpenAIのRetrieval APIは、コンテキスト長が長い場合、簡易なtokp-k RAGに切り替えている模様
	- The OpenAI retrieval API seems to be doing basic top-k RAG on limited context if there's context overflows.
	- https://x.com/jerryjliu0/status/1721987237771133219?s=20
- GPT-4 Turbo vs GPT-4 tests
	- GPT-4 Turbo has record accuracy (87% vs 52% of GPT-4 on PyLLMs benchmark), it is almost 5x faster with 48 vs 10 tokens/sec). 
	- And it is also 30% cheaper in practice (would be more, but it is 2x wordier in output compared to GPT-4)
	- https://x.com/vladquant/status/1721674365211738269?s=20
-  Google Colab で OpenAI API の Function Calling を試す by npakaさん
	- https://note.com/npaka/n/nc3713dba5df6?sub_rt=share_sb
	- 群馬県の気温を教えてください
-  Re-evaluating Retrosynthesis Algorithms with Syntheseus
	- https://arxiv.org/abs/2310.19796v1
	- 逆合成のベンチマーク論文。
	- 狙いの材料から原料を予測する逆合成予測では各論文で評価方法が異なっていましたが、Microsoftさんらはベンチマークライブラリを構築、これによりモデルのランキングが従来と変わることが分かったそうです。
-  Google Colab で OpenAI API の Code Interpreter を試す by npakaさｎ
	- https://note.com/npaka/n/nb90306341d41?sub_rt=share_sb
- GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベル
	- どうも今回の OpenAI の価格改定で、GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベルまで掛かっているらしく、OSS LLM が普及しないのは結局 OpenAI の API がクソ安すぎるからでは？という指摘
- OpenAI API の Assistant API のしくみ
	- https://note.com/npaka/n/n9fa7204e4af4?sub_rt=share_sb
- mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration
	- https://huggingface.co/papers/2311.04257
- llamaindexより、parallel function callingによる効率化の例
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb
- OpenAI API で提供されている モデル まとめ by npakaさｎ
	- https://note.com/npaka/n/n5d0a76b149f1?sub_rt=share_sb
- 『生成AIのパラドックス』
	- https://aiboom.net/archives/58414
	-  LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説
	- AIが人間のような出力を生成する能力を持ちながら、それを理解する能力は必ずしも伴わないという仮説です（仮説を立てるに至った背景は、前章を参照）。
- Streamlit+GPT4-Vision+TTSで動画ナレーション自動生成ツールをつくった
	- https://zenn.dev/olemi/articles/752d205987cb87
	-  動画からフレーム画像を抽出し、Base64形式に変換する
	- GPT4-Visionに動画のナレーションを生成させる
	- 生成されたテキストから、TTS APIで音声ファイルを生成する
	- Streamlitで、テキストと音声ファイルを表示・ダウンロード可能にする
-  Google Colab で PLaMo-13B-Instruct を試す by npakaさん
	- https://note.com/npaka/n/n97a1ac080f76?sub_rt=share_sb
- 日本語に対応した Embedding Model のベクトル検索での精度比較｜Tatsuya Shirakawa
	- https://github.com/nouu-me/document_vector_search_benchmark
	- 日本語Text Embeddingでのベクトル検索の精度をいろんなモデルで検証してみました。e5良いですね
-  Extracting List of  `Album`  (with Parallel Function Calling)
	- https://docs.llamaindex.ai/en/latest/examples/output_parsing/openai_pydantic_program.html#extracting-list-of-album-with-parallel-function-calling
- 複数のアシスタントに討論させる例
	- https://x.com/npaka123/status/1722761636937900541?s=20
- Zhenjie Yang et al., "A Survey of Large Language Models for Autonomous Driving"
	- LLMが得意とする「計画、認識、質問応答、生成」の能力が自動運転システムに効果的に使えると主張
	- https://arxiv.org/abs/2311.01043
- Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach
	- https://arxiv.org/abs/2209.06995
	- 良質なデータを収集し少量で高い性能を獲得する試み。
	- LLMにプロンプトを与え疑似ラベルを予測、分布が一様で不確実性が高い=学習効果が高いとみなす。
	- ベクトル空間上の距離から周辺も不確実性が高い、かつ採用データ間の距離を空ける。
	- 128サンプルでフル学習の 90% 超の精度。
- A.R.I.A. (Aria) - Your AI Research Assistant
	- https://github.com/lifan0127/ai-research-assistant
-  OpenAI の Assistant Playuground の Function Calling を試す
	- https://note.com/npaka/n/n6bf08e93840d?sub_rt=share_sb
- GPTs 作成第二弾として arXiv Reader を作りました。論文は PDF 入力か URL 手渡しか選べます。
	- https://chat.openai.com/g/g-qrOeOjLX6-arxiv-reader
- Tokenizerの分割を可視化しながらトークン数を数えてくれるページがOpenAIのサイトにある
	- https://platform.openai.com/tokenizer
- GPTsで、Kaggleのチュートリアル第6版を読み込ませてみて、質問してみました。
	- https://chat.openai.com/g/g-Z3a4iOzGR-kagglenotiyutoriarudi-6ban
- 弊社のカスタマーサポートをGPTsで作成してみました。
	- https://chat.openai.com/g/g-uINwYG4Ja-trippy-kasutamasapoto
- LangChainの# OpenAI Assistant、js版
	- https://js.langchain.com/docs/modules/agents/agent_types/openai_assistant
-  Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models
	- https://arxiv.org/abs/2305.17446
	- 事前学習済モデルの転移学習がモデル内の副空間で行われている可能性を示唆した研究。
	- 重みをFlatten しエポックごとスタックして SVD にかけ、 Fine Tuning 中のパラメーター変動を説明する軸を発見。
	- この軸上で外れ値になるパラメーターを無効化し著しい性能劣化を確認
- 山内志朗『小さな倫理学入門』
	- 「人間は欲望を自分で生産できず、他の人からこっそり盗んできます。もしかすると、人間は欲望が欠如していて、それを隠すために欲望まみれの姿を取りたがります。やりたいことが見つからない人の方が圧倒的に多いのです。」
- スタンフォード大のAI研究者Fei-Fei Liさんの新刊”The Worlds I See”は、想像を超える面白さ。強さとしての好奇心。
	- https://www.amazon.com/dp/1250897939?ref_=cm_sw_r_cp_ud_dp_QG23D73KJFT6GCP6GNVP
	- After 3+ years, today is the day that my book “The Worlds I See” gets to see the world itself. It is a science memoir of the intertwining histories of me becoming an #AI scientist, and the making of the modern AI itself. 
- 日本語言語モデルのベンチマークテストが更新
	- 日本語言語モデルのベンチマークテストである Stability-AI/lm-evaluation-harness がアップデートされたため、Youri 7B シリーズのスコアを算出し直しました。 GPTQによる 4bit 量子化モデルのスコアも算出しています。
	- https://rinnakk.github.io/research/benchmarks/lm/
- 生成AIエコシステムについて
	- 生成AIまわりがすごい楽しいのは、技術そのものはもちろん、理論に詳しい人、いち早く実装に落とすのが得意な人、きれいなアーキテクチャーに落とすのが得意な人、面白いプロダクトに仕立てる人の協力関係がバッチリ噛み合ってるみたいなところがすき
	- https://x.com/uezochan/status/1722604877644497292?s=20
- GPT3.5を用いてマルチターン日本語会話データセット(16K)を作りました
	- https://note.com/shi3zblog/n/nfc07c53d61a8?sub_rt=share_b
	- Wikipedia日本版データセット(izumi-lab/wikipedia-ja-20230720)とGPT-3.5-Turboでマルチターン会話データセットを作りました。
-  Google Colab で Japanese Wikipedia Conversation による Llama 2 のLoRAファインチューニングを試す
	- https://note.com/npaka/n/n723766f96cbc?sub_rt=share_sb
	- **<s> [INST]** 日本の首都は？ **[/INST]** 東京です。**</s><s> [INST]** その場所の観光名所を教えて。 **[/INST]** 東京ドームシティ、サンシャイン60（六万分一）があります。 **</s>**
- llamaindexからRAGのベンチマーク
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb
	- OpenAIのRAGが、llamaindexの5行のコードに劣っていると、、、
- LLM OS
	- https://x.com/karpathy/status/1723140519554105733?s=20
	- Specs:
		- LLM: OpenAI GPT-4 Turbo 256 core (batch size) processor @ 20Hz (tok/s)
		- RAM: 128Ktok
		- Filesystem: Ada002
- ChatGPTは、コピーライターやデザイナーの雇用を奪うとともに、単価も下げている
	- 米国の最新研究は、ChatGPTの立ち上げから数カ月で、主要なオンラインフリーランスのコピーライターやデザイナーの仕事の数が大幅に減少し、収入も急激に減ったと報じている
	- https://www.ft.com/content/b2928076-5c52-43e9-8872-08fda2aa2fcf
	- 「6桁稼ぐ人は30000ドルしか稼がない人の3倍ダメージを受ける」
- Pattern Language for Generative AI book!
	- https://x.com/IntuitMachine/status/1722931733866143754?s=20
- ニューラルネットは経験した言語を一般化する能力があるか（１０月２５日 Nature オンライン掲載論文） - Lab BRAINS
	- https://lab-brains.as-1.co.jp/enjoy-learn/2023/11/55788/
- Jochen Wulf and Juerg Meierhofer, "Towards a Taxonomy of Large Language Model based Business Model Transformations"
	- https://arxiv.org/abs/2311.05288
	- LLMを利用したビジネスモデルについて実際のケースをもとに調査報告が発表されました。
		- 「新しい顧客メリットの創造」、「新しい販売チャネルの開拓」、
		- 「ビジネスプロセス自動化の加速」、「情報リソース利用の改善」
-  LlamaIndex の マルチモーダルRAG のしくみ by npakaさん
	- https://note.com/npaka/n/n53e8aabed0f2?sub_rt=share_sb
	- 「GPT-4V API」の導入により、「RAG」の概念をテキスト/画像のハイブリッドに拡張し、さらに大量の(画像を含む) データコーパスから価値を引き出す
	- SimpleDirectoryReaderの画像拡張
	- **MultiModalVectorIndex**の導入
- RAGにおけるドキュメント検索精度向上について(概要編)
	- https://zenn.dev/sompojapan_dx/articles/eb755a18e893ce
	- 損害保険ジャパン株式会社 DX推進部
	- ドキュメントに手を加える
		- **ドキュメント整形/chunking**、**要約生成**、**質問文の拡張**、**Knowledge Graphの活用**
	- 検索モデルに手を加える
		- **検索モデルのfine-tune**、**Re-rankingモデルの活用**
-  PromptNER: Prompt Locating and Typing for Named Entity Recognition
	- https://arxiv.org/abs/2305.17104v1
- 「アナロジア」のジョージ・ダイソンがLLMについて語る
	- https://www.hayakawabooks.com/n/n6b8cf31a9472
	- 大規模言語モデルはいわゆる言語の地図とも言えるものであり、いろいろなAIは、その地図を辿って有用な目的地までデジタル方式のアルゴリズムでナビゲーションをしているだけです。
	- こうした地図はまだ市販の画像処理用チップGPUでシミュレーションされただけのものですが、いずれこうした（言語ばかりかイメージやありとあらゆる事象を重みづけする）巨大なモデル専用のアナログチップが利用されるようになり、徐々に浸透していき現行のシステムに代わっていくと思います。
- 「アナロジア」ジョージ・ダイソンより
	- 連続体仮設はデジタル・コンピューティングも、アナログ・コンピューティングもどちらも無限の力を持つが、それぞれがどれだけ進化しても発揮する力が異なることを示唆している(P292)
	- アナログ・コンピューティングでは複雑性はコードでなくアーキテクチャに宿る。
	- デジタル・コンピュータは硬直化してノイズをに対する耐性を失ってしまった、アナログ・コンピュータである
	- アナログ・コンピュータはノイズを受け入れるばかりか、＜略＞機能するために一定の背景ノイズを必要とさえしている。(P295)
- 人工知能の三つの法則からみるAIの次にくるもの（ダイソン）(P299)
	- 「アシュビーの必要多様性の法則」、実効的な制御システムは対象と同じ程度複雑でなければならない
	- 「複雑なシステムの特徴を規定するのは、それ自身の最も単純な動作の記述だ」（ノイマン）、
	- 「理解可能な単純なシステムは、知的な振る舞いをするには複雑さが足らず、知的な振る舞いができるくらい複雑などんなシステムでも、理解するには複雑すぎる」
	- →自ら思考する人工知能は、人間の知性を理解するまでは、マシンが超人的な知能を持つことを心配する必要はないともいえるが、理解をせずに何かを作っていけないという道理もない。

## 11/6

今週は、RinnaのYouri 7Bの発表(10/31)、Japanese Stable LM Beta 70Bの発表(11/2)、同日CyberAgentLM2-7B（CALM2 -7B）の公開(11/2)等、日本語LLMの発表・公開が相次ぐ。あっという間に4bit 量子化モデルも公開されて手元で試せるように。。。70Bもびっくりするが、特にCalm2は3万2000トークン（日本語で約5万字）に対応していて、RAG不要かも。ColabでもA100ならば動かせるらしい。ソフトバンクのLLM開発始動や、NTTの日本語対応言語モデルのtsuzumiの発表、牧野先生が、MM-core専任？になるとの話題もあり、日本でもLLMのインフラが今後そろってくるのは楽しみ。日本語事前学習済みモデルをSimCSEって、LLM本(大規模言語モデル入門)で紹介されていたやつ。説明可能AIによるペロブスカイト太陽電池開発って、AIに説明させて人間が次を考えるという、AIと人との協調の新しい未来の形。LLM評価のサーベイ論文、後で読もう。 TinyLLaMa、どこまで小さくできるか、こういうアプローチいいなあ、本当に1.1Bでどこまでいける？LLMを利用したFAQ検索の評価データセット作成の工夫とか、LangChainのアプリテンプレートの公開とか、実用面に近い開発も進展あり。npakaさんの、LangChain、LLamaIndexの紹介記事、コンパクトで最新の情報なのでお得。ちょうど日経新聞で紹介された、岩波新書の『言語哲学がはじまる』、フレーゲ、ラッセル、ヴィトゲンシュタイン、もし彼らが今生きていたらLLMをどう研究したのか。XのGrok-1は次週に続くだな。

- FP8-LM: Training FP8 Large Language Model
	- https://arxiv.org/abs/2310.18313
	- Microsoftの研究チームによる論文。
	-  FP8自動混合精度フレームワークで、性能低下を抑えつつ ・BF16よりも64%速く ・メモリ使用量を42%削減し GPT-175Bをトレーニングできた
- ControlLLM: Augment Language Models with Tools by Searching on Graphs
	- https://huggingface.co/papers/2310.17796
	- (1) a task decomposer that breaks down a complex task into clear subtasks with well-defined inputs and outputs; 
	- (2) a Thoughts-on-Graph (ToG) paradigm that searches the optimal solution path on a pre-built tool graph, which specifies the parameter and dependency relations among different tools; and
	-  (3) an execution engine with a rich toolbox that interprets the solution path and runs the tools efficiently on different computational devices.
- ハーバード大学とBCGの研究によるとGPT-4の活用で仕事の精度は40%向上し、スピードも25%早くなったとのこと。この結果を見てもAIの使い方は益々、知的差別化の重要な要素となる。知的さはもはやAIと切り離しが困難な状態。こうした変化についていくためにも最新のAIを使いこなせる努力をしてほしい。
	- https://x.com/gijigae/status/1718851299524096284?s=20
- ChatGPT のアプリ版に Retrieval Augmented Generation (RAG)機能が追加？
	- https://x.com/yi_ding/status/1719028284548382901?s=20
- シリコンバレー銀行の破綻を、シンプルに解析するnotebookが公開。スタンフォード大学Professor Ashwin Raoによる
	- https://colab.research.google.com/drive/15uxrAeCCL327kWH9N0X-ogKwf2zErjP5
- Microsoft うっかりgpt-3.5が20b相当だと漏らす、
	- CodeFusion: A Pre-trained Diffusion Model for Code Generation
	- https://arxiv.org/abs/2310.17680
	- Microsoft paper claims ChatGPT 3.5 has ~20 billion parameters
- BlokeニキがStability AI Japan のモデルを4bit量子化
	- https://huggingface.co/TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ
- rinnaはLlama 2の日本語継続事前学習モデル「Youri 7B」シリーズを公開しました。 
	- https://rinna.co.jp/news/2023/10/20231031.html
	- ①Youri 7B：日英40Bトークンで継続事前学習 
	- ②Youri 7B Instruction：高いベンチマークスコア 
	- ③Youri 7B Chat：複数ターンの対話に強い 
	- GPTQ 4bit 量子化モデルも公開しています。
-  Google Colab で Youri-7B を試す by npakaさん
	- https://note.com/npaka/n/nccadcbcfe37e?sub_rt=share_sb
	- 複数ターンの対話モデル (GPTQ版)である「rinna/youri-7b-chat-gptq」を使います
- 多様な日本語事前学習済みモデルをSimCSEで文埋め込みモデルにfine-tuning
	- https://arxiv.org/abs/2310.19349
	- かなりいい感じの文埋め込みモデルができたと思うので、ぜひお使いください...！！
	- https://github.com/hppRC/simple-simcse-ja
- Youri 7B InstructionのGPTQモデルつかえば、GPUメモリ8GBでもローカルでLLM翻訳ができそうな気配
	- https://x.com/kis/status/1719284609761108462?s=20
- ソフトバンク、 国産大規模言語モデル（LLM）の開発を本格開始
	- https://www.softbank.jp/corp/news/press/sbkk/2023/20231031_01/
	- 2024年内に3,500億パラメーターの国産LLMの構築を目指します
-  Evaluating Large Language Models: A Comprehensive Survey
	- https://arxiv.org/abs/2310.19736
	- A comprehensive survey (100+ pages) on evaluating LLMs. 
	- ■「知識と能力」の評価 
		- ① タスク中心の評価から能力中心の評価へと移行している 
		- ② 評価ベンチマークはますます拡張されている
		- ③ ダウンストリームタスク間の区別があいまい 
		- ④ モデルの能力を総合的に評価する新しいアプローチが必要 
	- ■アライメント（ガイドライン）の評価 
		- ① 人間の価値観との一致を評価する研究が増えている 
		- ② 倫理的な面も含めたモデルの進歩と応用が目指されている 
	- ■安全性の評価 
		- ① LLMの発展によるリスクに厳格な評価が必要 
		- ② 例えばバイアスの増幅、誤情報の拡散、プライバシーの侵害など 
		- ③ リスク評価と、対処アプローチが求められている 
	- ■特化型LLMの評価 
		- ① 特定ドメインやタスクに特化したLLMも存在 
		- ② 特化型モデルの評価には専門的アプローチが必要 
		- ③ 高度な知識や専門的な推論能力を持つモデルが期待されている
- LanChainから、様々なタスクにアプリテンプレが公開
	- https://blog.langchain.dev/langserve-hub/
	- LangChain Templates offers a collection of easily deployable reference architectures that anyone can use.
	- https://github.com/langchain-ai/langchain/tree/master/templates
- LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery
	- https://huggingface.co/papers/2310.18356
	- LoRAShear meticulously studies and proposes a dynamic fine-tuning schemes with dynamic data adaptors to effectively narrow down the performance gap to the full models.
- gguf版、japanese-stablelm-instruct-gamma-7b　実用 API サーバ・クライアント例
	- https://note.com/ai_meg/n/n0c449a877c6f?sub_rt=share_pb
	- 会話ログ、requestボディ-簡略化のためのデフォルト設定。llm()への生成時パラメータ追加など。
- Youri 7BをFastChatでChatGPT互換APIサーバとして動かして遊ぶ
	- https://qiita.com/takaaki_inada/items/fcb63da369b5bfd8a3cf?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- youri-7b-chatをfastchatでChatGPT互換APIでホストしてChatVRMでサクッと遊ぼう。prompt engineeringが効くのでsystem prompt設定画面で語尾やキャラクター設定できます
- Google Colab で Japanese Stable LM Beta 7B を試す by npakaさん
	- https://note.com/npaka/n/n49387d8a8af4?sub_rt=share_sb
	- 語彙拡張済み指示モデル「stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b 」を使います
- Generative AI for everyone	by Andrew Ng先生
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- Google Colabに、API keyを登録できる新機能が公開
	- https://x.com/GoogleColab/status/1719798406195867814?s=20
- 説明可能AIによるペロブスカイト太陽電池開発
	-  Discovering Process Dynamics for Scalable Perovskite Solar Cell Manufacturing with Explainable AI
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202307160
	- 成膜過程の動画やスペクトルデータからNNにより変換効率を予測、それに基づき解釈する手法を適用することで、プロセスと特性の新しい洞察につながったそうです。
- Efficient LLM inference on CPUs! 
	- https://huggingface.co/papers/2311.00502
	- NeurIPS'23の論文
	- Compatible with GGML yet better performance up to 1.5x over llama.cpp!
	- https://github.com/intel/intel-extension-for-transformers
- The Computational Lens: from Quantum Physics to Neuroscience
	- 計算機的な視点を用いて、量子物理学から神経科学に至るまでの分野を研究したハーバード大学の博士論文
	- https://arxiv.org/abs/2310.20539
- Japanese TinyLLaMa 1.1 B, llama.cpp で wasm でブラウザでも動く
	- https://github.com/lighttransport/japanese-normalizer-cpp
	- https://x.com/syoyo/status/1719646103891845438?s=20
-  LLMを利用したFAQ検索の評価データセットの作成〜その２〜
	- https://www.ai-shift.co.jp/techblog/3761
	- 「1.  FAQの回答内容から質問内容を抽出」をベースに、生成時のpromptの工夫について取り組んだ
- calm2で議事録をまとめてみました。AI時代の知的財産権検討会（第１回）
	- https://x.com/alfredplpl/status/1720005676829970472?s=20
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/kaisai/index.html
	- 主張1: AIによって生成されたコンテンツも含まれるべきである。 
	- 主張2: AIによって生成されたコンテンツは、人間によって創作されたコンテンツと同等に保護されるべきである。 
	- 主張3: 著作権を侵害する行為には、AIによって生成されたコンテンツも含まれるべきである。 
	- 主張4: 収益還元法については、AIによって生成されたコンテンツも適用範囲に含まれるべきである。
-  Google Colab で CALM2 を試す by npakaさん
	- https://note.com/npaka/n/n443e3ea8d0b8?sub_rt=share_sb
	- チャットモデル「cyberagent/calm2-7b-chat」を使います。
- CALM2-7B-chatのSpaceを作りました
	- https://huggingface.co/spaces/hayas/CALM2-7B-chat
- llamaとllama2の違い by NTT 西田さん
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
- 日本語DeBERTaV2モデルを公開しました！
	- 形態素解析器の事前の単語分割なしで使えるbase, smallモデルになっています
	- https://huggingface.co/izumi-lab/deberta-v2-base-japanese
- なんと、japanese-stablelm-instruct-beta-70B-GGUF
	- TheBloke/japanese-stablelm-instruct-beta-70B-GGUF
	- ggufのくせに40Gもあるよ、まったく
- OpenChat3.5
	- https://huggingface.co/openchat/openchat_3.5
	- gpt-3.5に迫る？？
- マルチモーダルのKOSMOS-2を取り込んだtransformerの更新！ by huggingface
	- KOSMOSのでもはこちら
		- https://huggingface.co/spaces/ydshieh/Kosmos-2
- Text generation web UIをつかって、cyberagent_calm2-7b-chat
	- https://x.com/StelsRay/status/1720137767857029444?s=20
	- モデルのLoad時にuse_fastがONじゃないと動かない点が罠だった！
-  LangChain クイックスタートガイド - Python版　 by npakaさん
	- https://note.com/npaka/n/n0fd7bd3ed27b?sub_rt=share_sb
	- 11/4版なので、整理されているし、「**LCEL**」(LangChain Expression Language)なんかよく分かった
- Idempotent Generative Network
	- https://assafshocher.github.io/IGN/
	- 拡散モデルではない新しい生成モデルがGoogleとUC Berkeleyから出たようだ。ノイズ除去というよりか分布を1stepで変換できるモデルことを仮定するらしい
- CALM2のGPTQ版が正常動作するようになりました。VRAMが少ない方は是非お使いください。
	- https://huggingface.co/mmnga/cyberagent-calm2-7b-chat-GPTQ-calib-ja-1k
-  CALM2で長い文章をまるごと取り扱う
	- https://note.com/alfredplpl/n/n5ed2ea2b78ec?sub_rt=share_sb
- 『責任あるAI: 「AI倫理」戦略ハンドブック』
	- https://x.com/abenben/status/1720750416361877680?s=20
- 【Calm2-7b】サイバーエージェントの最新LLMが優秀すぎたので、ChatGPTと比較レビューしてみた
	- https://weel.co.jp/media/cyberagentlm2-7b
-  Othello is Solved
	- https://arxiv.org/abs/2310.19387
	- PFNから、弱問題として解けたという話、双方最善手の結果は引き分け
-  LlamaIndex v0.8 クイックスタートガイド - Python版
	- https://note.com/npaka/n/nd449d5190431?sub_rt=share_b
	- 「LlamaIndex」は、プライベートやドメイン固有の知識を必要とする専門知識を必要とする質問応答チャットボットを簡単に作成できるライブラリです。
- シンガポールの首相は、C++で数独ソルバーを公開している	
	- https://t.co/rWig2ugILa
- CALM2-7Bをベンチマークする(11/5追記)
	- https://note.com/shi3zblog/n/n8b9ff5ea62bf?sub_rt=share_sb
- 今の高校では『情報Ⅰ』という科目ができて、ITパスポート相当のことを学んでいる→”高卒相当”のレベルが上がっているという話
	- https://togetter.com/li/2253207
- ＢＸストラテジー　実践行動経済学2.0 人を動かす心のツボ
	- https://www.amazon.co.jp/dp/4296115758?ref_=cm_sw_r_cp_ud_dp_BM2H3QZ9AHNCYW8F2ZY7
	- 企業経営の現場でどのように行動変容を促せばよいのかという知見が体系的に整理されており、法則や理論を寄せ集めたこれまでの事例集的な行動経済学本とは一線を画す良書でした。
- Xから、Grok発表, Elon’s new LLM.
	- https://x.com/xai/status/1721027348970238035?s=20
	- 330億パラメータGrok-0（LLaMA 2 (70B) の機能に近づき、トレーニングリソースの半分しか使用しない）を元にGrok-1を開発。
	- Grok-1 は GPT3.5や Inflection-1を標準的なベンチマークで超える。
- CALM2-7Bの性能を他の日本語LLMと比較してみた
	- https://note.com/it_navi/n/n35e5fac2b3d3?sub_rt=share_pb
	- CALM2-7B-Chatは、一度に**3万2000トークン（日本語で約5万字）**の長文の入出力に対応
	- **CALM2-7B-Chat**の回答を**ELYZA-japanese-Llama-2-7b-instruct**及び**Youri-7B-chat**の回答と比較
	- 論理的思考力については、**3種類の日本語モデルの回答は五十歩百歩**で大差ありません。ChatGPT（GPT-3.5）の性能とは、まだ相当差があるようです
- 『言語哲学がはじまる』野矢茂樹著
	- https://www.iwanami.co.jp/book/b633363.html
	- 日経の書評(11/4朝刊)掲載
	- 言葉とは何か。この問いにフレーゲ、ラッセル、ウィトゲンシュタインはどう挑んだのか。とびきりたのしい言語哲学の説き語り
	- 単語単独で意味を持つのか、文章の中の関係性として意味を持つのか、LLMは何を見ている？
- 牧野先生、PFN開発のMN-core開発に注力
	- https://jun-makino.sakura.ne.jp/articles/future_sc/note161.html
	- 神戸大とPFNのクロスアポイントメントだそうだ、
	- 「今後は社員として直接MN-Core の 開発に関わる」、「普及といったことを含めてMn-Core の 開発が本格化している」

## 10/30

新しいLLMがどんどん発表される。「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」、7BのLLMの覇者は、Mistral 7Bという話題もあったが、ReActをこなせる7bは、Zephyr-7b-betaということらしい、日本語はどうか？OSSのLLMで構造的な出力(Pydantic)を出すにはファインチューニングが有効らしい。text-to-SQLもファインチューニングが有効とのこと。心の理論(TOM)も、心理学のVoE理論の応用とかがあった。LLM の ベンチマーク、いろいろ紹介されるが、自動評価の結果がレーダーチャートで可視化されるMT-Benchが良いかも。既存の概念を組み合わせるsystematic compositionalityの能力をニューラルネットが持つことができるってのは、これはメタファー理論による認知の仕組みの解明が一歩現実に近づいたのか。Prompt によるLLMへの指示を超えるという、LLM programはは、分割統治というか、アンサンブルというかそういう感じ。MicrosoftのAgent Frameworkって前からあったような気もするが、なぜ注目？Hinton先生とLecum先生の議論がLLMの次を見据えた議論で面白い。限界は、ひょんなことから超えられてゆくという歴史もあるよな。FastChatで様々なLLMを試せて評価の幅が広がる、M-BenchもFastChat利用を想定しているのか。

- 7bのフルファインチューニングがcolabで動く？VRAM 32G程度で行けると
	- https://x.com/Sakkusakumura/status/1716158933319246289?s=20
- Character-LLM: A Trainable Agent for Role-Playing
	- https://aiboom.net/archives/57223
	- 特定の人物、例えばベートーヴェンやクレオパトラなどの行動や感情を模倣させるよう訓練する新しいフレームワーク『Character-LLM（キャラクターLLM）』
	- 訓練されたLLMは、特定の人物としての行動や感情を効果的に模倣できることが確認されました。
-  Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts
	- https://cxh0519.github.io/projects/Progressive3D/?ref=aiartweekly
	- Progressive3D brings region specific object manipulation through text with a DALL-E 3 like level of prompt understanding to the table.
	- ３Dモデルに対して、様々な加工を言語で行う
- Courtland Leer et al., "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models"
	- https://arxiv.org/abs/2310.06983
	- 「心の理論（Theory of Mind）」をメタ認知能力をつかって向上できる。
	- 心理学における「Violation of Expectation（期待違反）：VoE」理論を適用
- llamaindexがつかう、すべてのプロンプトを表示・カスタマイズできるI/Fが公開
	-  Accessing/Customizing Prompts within Higher-Level Modules
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompt_mixin.ipynb
- LangChainから、アドバンスなRAGでもある、"Query Transformation"
	- https://blog.langchain.dev/query-transformations/
	- 質問のほうを変換するとな？
- llamaindexで、HuggingFaceのLLMを活用するライブラリが拡張された(会話、テキスト生成、など）
	- you can now plug any `conversational`, `text_generation`, `feature_extraction` endpoints 
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/huggingface.ipynb
- Finetuning LLaMa + Text-to-SQL
	- https://github.com/run-llama/modal_finetune_sql
	- how to fine-tune Llama2 for better text-to-SQL + easily plug into your LLM app, ordered from easy to hard:
	- text-to-SQLで最も性能が良いのは、GPT-4/3.5でも、llamaでもファインチューニングすればどうにかなる。このファインチューニングの手法の様々を紹介、
- State of Open Source AI Book - 2023 Edition
	- https://book.premai.io/state-of-open-source-ai/
	- 当然本自身もOpenSoruce
	- https://github.com/premAI-io/state-of-open-source-ai
-  ComfyUI-LCMによるVid2Vidの高速変換を試す(Latent Consistency Models)
	- https://note.com/bakushu/n/nec4cee4f4f37
	- Latent Consistency Models（LCM）は、最小限のステップ数で迅速に推論できる新たな画像生成モデル
	- Google Colabの標準GPU（VRAM 16GB）で試したところ、512x512サイズの120フレームの動画変換で1分弱。1024x1024サイズの120フレームの動画変換だと12-13分ほどでした。
-  AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation
	- https://arxiv.org/abs/2308.08155
	- https://microsoft.github.io/autogen/
	- マイクロソフト謹製のAgentフレームワーク、前からあったような気もするが。
- Top AI Shops Fail Transparency Test
	- https://spectrum.ieee.org/ai-ethics#toggle-gdpr
	- Stanford transparency index rates Meta, OpenAI, and others on 100 indicators
	- The highest total score goes to Meta’s Llama 2, with 54 out of 100.
-  llm-jpをColabで試す
	- https://note.com/alexweberk/n/n6b26b324904c?sub_rt=share_pw
	- 「jaster を含むものは回答がそっけない」らしいので、それを除いたテスト
	- 流石日本語特化のモデルだけあって日本語は自然な形で生成できました。日本に関する基本的な知識も備えているのは嬉しい
-  LLM の ベンチマーク まとめ by npakaさん
	- https://note.com/npaka/n/ndec10f78fe2f
	- 人間を評価者としたベンチマーク、 GPT-4を評価者としたベンチマーク、QAデータセットによるベンチマーク、コード生成のベンチマーク、埋め込みのベンチマーク、 ロールプレイのベンチマーク
	- 現状で自動評価可能な最良のアプローチはGPT-4を評価者とする方法。ただしコストなど課題がある
- MiniGPT-V
	- https://note.com/ai_meg/n/n748acc8e824b
	- MiniGPT-4のAPIを実装する。　プログラムでマルチモーダルを自由に操作する。
-  Google Colab で Japanese Stable LM Gamma 7B を試す by npakaさん
	- https://note.com/npaka/n/n4f2d6e6c11f7?sub_rt=share_b
- 日本語大規模言語モデル「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」
	- https://ja.stability.ai/blog/japanese-stable-lm-3b-4e1tjapanese-stable-lm-gamma-7b
	- 約30億と70億のパラメータを持つこれらのモデルは、日本語タスクの性能評価でトップクラス
	- 3Bと7Bのサイズでそれぞれ圧倒的性能を誇る英語LLM「Stable LM 3B-4E1T」「Mistral-7B-v0.1」に継続事前学習を適用することでサクッとめちゃツヨ日本語LLM
-  Japanese research is no longer world class — here’s why
	- https://www.nature.com/articles/d41586-023-03290-1?error=cookies_not_supported&code=dd59d16e-8d54-49a4-95a3-8fcded36917f&utm_medium=Social&utm_campaign=nature&utm_source=Twitter#Echobox=1698226936
	- nature記事より
	- **資金不足と時間不足**、**若手研究者の不満と減少**　が指摘されている。
-  Branch-Solve-Merge Improves Large Language Model Evaluation and Generation
	- https://arxiv.org/abs/2310.15123
	- Promptを超えた？LLM自身をアルゴリズムの一部に埋め込んで使うような、LLM programと呼ばれるような手法
- Large Language Model Programs
	- https://arxiv.org/pdf/2305.05364.pdf
	- LLMをアルゴリズムに埋め込むことをLLM Programとと呼ぶらしい、分割統治なんかそうなんだけど、メタなLLMみたいな感じ
-  LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions
	- https://arxiv.org/abs/2310.14029v1
	- 結晶構造をテキスト化して言語モデルで学習、そのエンコーダを使って物性予測を行うと従来のSOTAであるGNNモデルより高精度な予測
-  LangChain の Step-back Prompting を試す by npakaさん
	- https://note.com/npaka/n/n55f276ad2988?sub_rt=share_sb
	- (1) ユーザーの元の質問に基づいて、ステップバック質問を生成  
	- (2) 元の質問とステップバック質問の両方を情報収集  
	- (3) 取得した両方の情報に基づいて回答を生成
- mmnga/japanese-stablelm-instruct-gamma-7b-gguf
	- stabilityAIさんが公開されているjapanese-stablelm-instruct-gamma-7bのgguf
	- Mistral-7bの日本語版で、AIのべりすとさんから提供された高品質なデータが入っている
- フィールズ賞受賞者のテレンス・タオさんが、証明支援系Leanを使うことで自分の論文の中のバグ（ミス）に気づいたという話
	- https://mathstodon.xyz/@tao/111287749336059662
	- 定理証明系が実数学者のためになっているのか。。。
-  KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval
	- https://huggingface.co/papers/2310.15511
	-  (e.g., 'a list of ice cream shops in San Diego')
-  LLMのプロンプト技術まとめ
	- https://qiita.com/fuyu_quant/items/157086987bd1b4e52e80
-  Zephyr: Direct Distillation of LM Alignment
	- https://arxiv.org/abs/2310.16944
	- なんかすごい性能らしい。
-  Human-like systematic generalization through a meta-learning neural network
	- https://www.nature.com/articles/s41586-023-06668-3
	- 既存の概念を組み合わせるsystematic compositionalityの能力を、メタ学習を施したニューラルネットで実現。35年前のFodor＆Pylyshynの「ニューラルネットはcompositionalityを持てない」との主張への応答として書いている
-  MT-Bench の使い方 by npakaさん
	- https://note.com/npaka/n/na28f31e96599?sub_rt=share_b
	- 「[**MT-Bench**](https://chat.lmsys.org/?leaderboard)」は、80の高品質でマルチターンの質問を含む、慎重にキュレーションされたLLMのベンチマークです。
	- レーダーチャートででるのがよい。
-  7BのLLMの覇者は、Mistral 7B ？？
	- https://www.promptingguide.ai/models/mistral-7b
- Getting started  with Llama by Meta
	- Meta謹製のLlmaガイド
	- https://ai.meta.com/llama/get-started/
	- Yann LeCun先生のおすすめでもある。
- bakLLaVA vision AI can read xrays with only 6Gb of RAM
	- https://github.com/SkunkworksAI/BakLLaVA
	- OSSのLLMでがん画像検診ができる？
- Zephyr-7b-betaって無敵かも
	- https://colab.research.google.com/drive/1UoPcoiA5EOBghxWKWduQhChliMHxla7U?usp=sharing
	- found it’s the only 7B LLM that can handle ReAct agent tasks over data
	- つまり、dataに対して、ReActするAgentを実装できる唯一の7B LLMということらしい
	- Jelly Liuさん(llamaindex作者)も激賞
	- https://x.com/jerryjliu0/status/1718054817640390840?s=20
-  Evaluating RAG pipelines with Ragas + LangSmith
	- https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/
	- RAGの性能評価をRagasとLangSmithで行う方法を紹介した記事
	- RagasはLLMによるRAGの自動評価を支援するOSS、試したけどお金かかるんだよな。
- llama2 7bをファインチューニングすることで、出力を特定フォーマットにすることができる
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/gradient/gradient_structured.ipynb
	- structured Pydantic objectsを出力する
- 帝人の統合報告書2023に掲載されている特許情報分析。ポートフォリオの変化について、テキストマイニングによる全体俯瞰と特許価値評価の2つのアプローチで可視化
	- https://ssl4.eir-parts.net/doc/3401/ir_material_for_fiscal_ym1/141477/00.pdf
- Hinton先生の、新しいLLMの開発（たぶんOpenAI)に対する危惧に対して、Lecum先生は、どうせ今のAuto-Regressive LLMの延長線上の開発なので、限界は自明い。真に必要なAIは、、と反論。
	- https://x.com/ylecun/status/1718263303485501784?s=20
	- Objective-Driven AI architecturesが必要とのこと
- Advanced Prompt Engineering for RAG by llamaindex
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompts_rag.ipynb
	- 基本的なRAGから、few-shot追加したり、context変換したりという話題
- Stability AI の Japanese MT-Bench を試した
	- https://x.com/npaka123/status/1718403656725483961?s=20
- Demystifying Advanced RAG Pipelines
	- https://github.com/pchunduri6/rag-demystified
-  Chatting With Your Data Ultimate Guide
	- https://medium.com/aimonks/chatting-with-your-data-ultimate-guide-a4e909591436
-  MT-Bench による日本語LLMの評価 by npakaさん
	- https://note.com/npaka/n/n0530f6f9123f?sub_rt=share_sb
	- 「Stability AI」が提供する**「Japanese MT-Bench」の質問ファイル**と**参照回答ファイル**を使う
	- 評価するモデルは、FastChatが対応している必要があります。

## 10/23

今週は、NIIからllm-jp-13b-v1.0が公開されたのが話題でした、さっそくcolabで使った例が公開されたり、4bit量子化版がhuggingfaceで公開されたりと、盛り上がってます。関係者の努力とABCIの活躍に頭が下がります。LLM活用アプリの性能を考えるときに、RAGでもそうなんだけど、LLMとembeddingの組み合わせをちゃんと評価するってのが最初にあるべきなのかも。使ったことないけどもReplicateはそこんところうまくついたサービス展開といえる。LLMをソフトウエアエンジニアリングで活用できるという論文が話題に。OpenAI、限りなくAGIに近いとうわさのArrakisの開発断念？映画Dune２(Arrakisという星が部隊）の公開も春にずれ込んだから、似たような運命をたどるのか？マッキンゼーのレポート、生成AIにより、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しというのは驚いた、つまり我々は25年先の技術を今見ていることになる、そりゃ（多くの人にはLLMの凄さが）分らんわな。スタンフォード大の「科学論文の査読」に、大規模言語モデル（LLM）が有用であるという論文、これは朗報だ（誰得？）。「kaggle LLMコンペ　上位解法のまとめ」はこれはLLMプラクティショナーには必読だ。ちゃんとコンテキストを適切に与えることが重要。あたりまえだけど、それを行うのは難し。「世界モデル」に対するOpenAI共同設立者のIlya Sutskever氏の対談、大規模深層学習モデルは言葉を生成する何等かの表現（つまり世界モデル）を学習し、これから漏れ出るものがテキストであると言っている（ナウシカの「墓所の主」みたいなものか）。LLMの因果推論能力のベンチーマーク、fine-tuningすると性能はあがるが、少し表現を変えると性能が爆下がりって！、それがLLMなのよ！最新の言語理論である「ジェスチャーゲーム」で人間の言語能力が身についたとすると、LLMが示すテキスト生成能力は何？？Ilya Sutskever氏の対談の話と真っ向から対立する感じ。「言語ゲーム」といえばヴィトゲンシュタイン、ウィトゲンシュタイン研究を専門とする大谷先生の対話記事によると。LLMと言語ゲームって似たところがあるそうだ。なんか、楽しくなってきた。

- Ilya Sutskever氏LLMと世界モデルについて語る with Jensen Huang, CEO of Nvidia:
	- https://twitter.com/i/status/1713368556618887670
	- OpenAIの共同設立者であるIlya Sutskever氏とNvidiaのensen Huang社長との対談より
	- （巨大な）ニューラルネットが学んでいるのは、テキストを生成する「何か」に対する表現を学んでいる。その「何か」とは世界モデルであり、それが射影されたものが生成されたテキストなのである。
- Jonas Belouadi et al., "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"
	- https://arxiv.org/abs/2310.00367
	- LLMを活用し人間のように科学的な図を生成するツール『AutomaTikZ』
	- テキストから科学的なベクターグラフィックスを生成する 
	- LLaMAをDaTikZデータセットで微調整
-  Can Large Language Models Infer Causation from Correlation?
	- https://arxiv.org/abs/2306.05836
	- https://ai-scholar.tech/articles/large-language-models/llm_causal_inference_skill
	-  LLMに因果推論能力はあるか？
	- 大規模言語モデルの因果推論能力をテストするベンチマークデータセットを提案  
	- 17の既存の大規模言語モデルを評価  
	- 現状のモデルは因果推論能力が低いことがわかった
	- fine-tuningにより性能向上が見られる一方で，少し表現を変えただけで性能が下がる現象も見られる
- Yijun Tian et al., "Graph Neural Prompting with Large Language Models"
	- https://arxiv.org/abs/2309.15427
	- LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』
	- GNPは、LLMに有益な知識を効果的にエンコードし、パフォーマンスを大幅に向上させることができる
- 大規模言語モデルがどのように動いてるかを視覚的に説明するインフォグラフィックが素晴らしいと
	- https://ig.ft.com/generative-ai/
	- Fanatical Timesのインフォグラフィック
- Large Language Models for Software Engineering: Survey and Open Problems
	- https://arxiv.org/abs/2310.03533
	- LLMをソフトウエアエンジニアリング(SE)にどうやって適用するか？
	- 要求エンジニアリング/デザイン、コード生成、テスト、運用/デプロイ、ドキュメント生成。またリサーチ領域での活用なども
	- 伝統的なSEとLLMを融合したはハイブリッドにより信頼ある効率的なLLMベースのSEが実現できた
- JapaneseEmbeddingEval　日本語におけるembeddingの評価
	-  https://github.com/oshizo/JapaneseEmbeddingEval
	- multilingual-e5っていい線いってるのか。。
- PaLI-3 Vision Language Models: Smaller, Faster, Stronger
	- https://huggingface.co/papers/2310.09199
	- Googleによる、高性能で小さいvision language model (VLM)
- マッキンゼーから発表されたAI動向に関するレポートがなかなか衝撃的
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-AI-the-next-productivity-frontier#introduction
	- 生成AI（というかChatGPTに代表されるLLM)の登場により、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しになった
		- 2017年の予測：2050年 ・2023年の予測：2024〜2025年 
- Xinyun Chen et al, "Teaching Large Language Models to Self-Debug"
	- https://arxiv.org/abs/2304.05128
	- GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』
	- LLMに自己デバッグの能力を教えることで、コード生成の性能が向上する
- ChatGPTを用いてコーディングを学ぶ方法について（慶応義塾大学）
	- https://speakerdeck.com/keio_smilab/keio-univ-intro-to-ml-02-coding
	- なんと、学生向けに、ChatGPTを用いてPythonなどのコーディングを学ぶという授業が、、
	- ChatGPTネイティブな学生は、ChatGPTでコーディングを学ぶのか。。
- Andrew Ng先生から、deeplearning.aiの「生成AI」の講義の宣伝
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- OpenAI、次世代LLMである、Arrakisの開発を断念？
	-  OpenAI Dropped Work on New ‘Arrakis’ AI Model in Rare Setback
	- 限りなくAGIに近いとうわさされる次世代のLLM、
	- どううも開発中（学習中）の性能評価で思ったほど性能が出なかったため。
	- https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback
- llamaindexのLiuさんより、“Evaluation Driven Development” (EDD)の提案
	- https://x.com/jerryjliu0/status/1713936561480610104?s=20
	- まずは、LLM＋Embeddingの組み合わせをちゃんと評価するところから始めようみたいな。
- Replicateを利用すると、任意のLLMとembeddingの組み合わせを簡単に評価できる
	- https://replicate.com/explore
	- つまりhuggingfaceのモデルをダウンロードして動かす手間を、少し省くサービスを提供、
	- ナイスだな。
- NIIから、LLM-jp-13B が公開される
	- LLM-jp （LLM 勉強会）は、日本語と英語を中心に事前学習した130億パラメータの大規模言語モデルをオープンなライセンスで公開
	- https://llm-jp.nii.ac.jp/release/
	- インストラクションデータでチューニングしたモデルや訓練・チューニングに用いたソフトウェアも公開
- データでできることのレベル感を理解する（デジタル庁の人のスライドより）
	- https://speakerdeck.com/hik0107/data-design-and-government?slide=10
	- 現状の把握(lv.1)、分解と差異の把握(Lv.2)、原因の把握(Lv.3)、対策の把握(Lv4)
-  Google Colab で LLM-jp-13B を試す by npakaさん
	- https://note.com/npaka/n/n60b0abf54ed5?sub_rt=share_sb
	- T4 ハイメモリで動作確認
	- 早速試されている
- BEYOND MEMORIZATION: VIOLATING PRIVACY VIA INFERENCE WITH LARGE LANGUAGE MODELS
	- https://arxiv.org/pdf/2310.07298v1.pdf
	- Redditの匿名ポストのテキストから、GPT-4はその人のプロファイル（収入、性別、住所）を85%の正確さで、かつ人間の1%のコストで当てた。。
	- A paper that really illustrates both the unexpected power, and unexpected risks, that come from LLMs.
-  InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
	- https://arxiv.org/abs/2310.07713
	- pre-train LLMs with Retrieval Augmentation
-  An Emulator for Fine-Tuning Large Language Models using Small Language Models
	- https://huggingface.co/papers/2310.12962
	- Emulator for Fine-Tuning(EFT)は、大規模な事前学習済みモデルを小規模な微調整済みモデルとアンサンブルすることで、大規模な事前学習済みモデルを微調整した結果をエミュレートするという、アップスケーリングが可能になった
-  Can large language models provide useful feedback on research papers? A large-scale empirical analysis
	- https://arxiv.org/abs/2310.01783
	- 「科学論文の査読」に、大規模言語モデル（LLM）が有用な可能性がある
	- 米スタンフォード大らが検証　参加者の80％以上「AI査読は有益」
	- https://www.itmedia.co.jp/news/articles/2310/19/news072.html
	- Nature系列のジャーナルにおけるフィードバックの結果、GPT-4が提供したコメントの57.55％は、全体の査読者の中で少なくとも1人の人間の査読者が記載していた
- A quantized version of the mistral that is instruction following over 32k tokens.
	- https://huggingface.co/TheBloke/MistralLite-7B-AWQ
	- mistralって性能がよいと先週評判になってたやつの、4bit量子化版が公開？
- llm-jp-13b-v1.0も早速GPTQ版が公開される
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-4bit-g128-GPTQ-calib-ja-1k
	- llm-jp-13b-v1.0を、 日本語のキャリブレーションセットで生成したGPTQモデル
-  言語はこうして生まれる―「即興する脳」とジェスチャーゲーム―
	- https://www.shinchosha.co.jp/book/507311/
	- 言語の生得性を否定し、文化進化や語用論的な観点から言語獲得を論じています
	- 歴史：ノーム・チョムスキーは「普遍文法」という概念を導入し、「人間の遺伝的青写真には、言語を支配する抽象的な数学的原理が内包」しているといった
	- 歴史：心理学者スティーブン・ピンカーがさらに『言語を生みだす本能』（NHKブックス）へと発展させる
	- 主張：「ジェスチャーゲーム」。言語は遺伝的に決定されたものなどではなく、身振り手振り、発声、あるいはその両方で自分の意思を双方向的に伝え合うジェスチャーゲームのようなものが起源なのではないかという斬新なアイデアだ。そこには普遍文法が入り込む余地などない。
- LLM（大規模言語モデル）は「言語ゲーム」的か  東京女子大学現代教養学部准教授・大谷弘氏に聞く（１）
	- [IT批評の記事](https://it-hihyou.com/recommended/llm%EF%BC%88%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%89%E3%81%AF%E3%80%8C%E8%A8%80%E8%AA%9E%E3%82%B2%E3%83%BC%E3%83%A0%E3%80%8D%E7%9A%84%E3%81%8B-%E2%80%95/)より
	- LLMって、パターンから学び、その背後には人間があるから、ヴィトゲンシュタインのいう「言語ゲーム」に似ている、らしい。記号接地してないという批判にも、学習データの背後の人間のあたりで接地しているのかもともいう。
- 多様体上の最適化理論
	- https://www.amazon.co.jp/exec/obidos/ASIN/4274231186?&linkCode=sl1&tag=mathlang09-22&linkId=bd145734052442298eb01413d823ca91&language=ja_JP&ref_=as_li_ss_tl
	- 多様体上の最適化理論について、基礎となる数理から応用例までを解説
-  Introducing CliffordLayers: Neural Network layers inspired by Clifford / Geometric Algebras.
	- https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/articles/introducing-cliffordlayers-neural-network-layers-inspired-by-clifford-geometric-algebras/
	- MS研究所から、クリフォード代数にインスパイアされた新しいNNレイヤの発明
-  OpenAgents: An Open Platform for Language Agents in the Wild
	- https://arxiv.org/abs/2310.10634v1
- llamaindexより、Unifying Text-to-SQL and RAG with our SQLRetrieve
	- https://docs.llamaindex.ai/en/latest/examples/index_structs/struct_indices/SQLIndexDemo.html
	- SQLデータベースに対して、RAGを行うRetriverについて、動いたぞ、役に立つぞ。
- kaggle LLMコンペ　上位解法まとめ
	- https://zenn.dev/yume_neko/articles/7347ba6b081e93
	- 科学分野の5択問題を解くLLMの精度を規則コンペのべスプラ
	- 今回のコンペで上位に行くにはRetrievalが最もキーだったように思います。やはり正解情報を直接参照できるので、contextをより良くすることが重要だったのではないかと思います。
- llama2のpretrainingを試す
	
<!--stackedit_data:
eyJoaXN0b3J5IjpbOTY2ODQ0ODYsLTU3Mjg5MDY0MSw5MzAyMj
k5MDgsLTU3MTM0NTgwMCw5Mzk3MDg4MjAsLTIxMzYwMDYyNSwx
OTE0MzgwNjAsLTEwMDg5NDEyMjYsNTk4MDg1MjI0LDExMTY2MD
c0OTYsNTMyMzc0NzI1LDgyNjIyNTM2LC0yMDQ0NjEzMzE5LDIz
NTc5MjY0NCwtMjAyNzM2NjQ0NCwxNjE1ODIwNDU5LDk1ODIxMz
A5NCw3NjEwOTE0NCwtMTQ5NjU1MTc0MiwtMjA2NjAzMTc3NF19

-->