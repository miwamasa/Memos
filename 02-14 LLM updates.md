# ã²ãŸã™ã‚‰LLMé–¢é€£æƒ…å ±ã‚’è¿½ã†ã€
ã“ã‚Œã¯ã€å€‹äººã®twitter bookmarkã‚’æ¯é€±ãŠã•ã‚‰ã„ã—ã¦ã„ã‚‹ã€‚

## 24/7/29

- æ—¥æœ¬ã®ä¼æ¥­æ´»å‹•ã¯ã€åˆç­‰ãƒ»ä¸­ç­‰æ•™è‚²ã¾ã§ã®çŸ¥è­˜ã§æˆã‚Šç«‹ã£ã¦ã„ã‚‹ã®ã«å¯¾ã—ã¦ã€ã‚¢ãƒ¡ãƒªã‚«ã®ä¼æ¥­æ´»å‹•ã¯ã€å¤§å­¦é™¢æ•™è‚²ã«åŸºã¥ã„ã¦æˆã‚Šç«‹ã£ã¦ã„ã‚‹
	- https://x.com/yukionoguchi10/status/1814670633277792779
- MITãƒ€ãƒ­ãƒ³ãƒ»ã‚¢ã‚»ãƒ¢ã‚°ãƒ«æ•™æˆ
	- https://x.com/kiyoshi_shin/status/1813799795221471701
	- å…ƒè«–æ–‡ã‚‚ã‚ã£ãŸã€‚ç™ºè¡¨ã¯ä»Šå¹´4æœˆ
		- https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf
		- AIã®ç™»å ´ã¯ã€æ–°å¸‚å ´ã‚’ä½œã‚Šå‡ºã™ã®ã§ã¯ãªãã€æ—¢å­˜å¸‚å ´ã®åŠ¹ç‡åŒ–ã«å‘ã‹ã†ã®ã§ã€å¸‚å ´è¦æ¨¡å…¨ä½“ãŒåºƒãŒã‚‹ã‚ã‘ã§ã¯ãªã„ã®ã§ã€çµŒæ¸ˆæˆé•·ãŒèµ·ãã‚‹ã¨ã„ã†ç‚¹ã«ã¯æ‡ç–‘çš„ã€‚
		- AIã®ãƒŸã‚¯ãƒ­çµŒæ¸ˆåŠ¹æœãŒã‚¿ã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã§ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼ˆã¾ãŸã¯ç”Ÿç”£æ€§å‘ä¸Šï¼‰ã«ã‚ˆã£ã¦ã‚‚ãŸã‚‰ã•ã‚Œã‚‹å ´åˆã€ãã®ãƒã‚¯ãƒ­çµŒæ¸ˆã¸ã®å½±éŸ¿ã¯ãƒãƒ«ãƒ†ãƒ³ã®å®šç†ã®ä¸€ç¨®ã«ã‚ˆã£ã¦ç¤ºã•ã‚Œã‚‹ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚ã¤ã¾ã‚Šã€GDPã¨ç·ç”Ÿç”£æ€§ã®å‘ä¸Šã¯ã€AIã®å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¿ã‚¹ã‚¯ã®å‰²åˆã¨ã‚¿ã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã§ã®å¹³å‡ã‚³ã‚¹ãƒˆå‰Šæ¸›ã«ã‚ˆã£ã¦æ¨å®šã§ãã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚
		- æ—¢å­˜ã®æ¨å®šå€¤ã‚’ç”¨ã„ã¦ã€ä»Šå¾Œ10å¹´é–“ã®ç·è¦ç´ ç”Ÿç”£æ€§ï¼ˆTFPï¼‰ã¸ã®å½±éŸ¿ã¯0.71ï¼…ã‚’è¶…ãˆãªã„ã¨è«–æ–‡ã¯çµè«–ã¥ã‘ã¦ã„ã¾ã™ã€‚
		- ã•ã‚‰ã«ã€åˆæœŸã®è¨¼æ‹ ã¯ã€Œå­¦ç¿’ã—ã‚„ã™ã„ã€ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã®ã‚‚ã®ã§ã‚ã‚‹ãŸã‚ã€ã“ã®æ¨å®šå€¤ã¯èª‡å¼µã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨ä¸»å¼µã—ã¦ã„ã¾ã™ã€‚
		- å°†æ¥ã®å½±éŸ¿ã®ä¸€éƒ¨ã¯ã€ã€Œå­¦ç¿’ã—ã«ãã„ã€ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã‚‚ãŸã‚‰ã•ã‚Œã‚‹ãŸã‚ã€TFPã®å¢—åŠ ã¯ã•ã‚‰ã«æ§ãˆã‚ã«ãªã‚‹ã¨äºˆæƒ³ã•ã‚Œã¾ã™ã€‚
		- AIãŒç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ä½ã‚¹ã‚­ãƒ«åŠ´åƒè€…ã®ç”Ÿç”£æ€§ã‚’å‘ä¸Šã•ã›ãŸã¨ã—ã¦ã‚‚ï¼ˆå½¼ã‚‰ã«æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿã¿å‡ºã™ã“ã¨ãªãï¼‰ã€ä¸å¹³ç­‰ã‚’æ¸›å°‘ã•ã›ã‚‹ã©ã“ã‚ã‹å¢—åŠ ã•ã›ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’ç†è«–çš„ã«ç¤ºã—ã¦ã„ã¾ã™ã€‚
		- AIã«ã‚ˆã£ã¦ç”Ÿã¿å‡ºã•ã‚Œã‚‹æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã®ä¸­ã«ã¯ã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ“ä½œã®ãŸã‚ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ è¨­è¨ˆãªã©ã€ç¤¾ä¼šçš„ã«è² ã®ä¾¡å€¤ã‚’æŒã¤ã‚‚ã®ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ã¨æŒ‡æ‘˜ã—ã¦ã„ã¾ã™
-  Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies
	- https://arxiv.org/abs/2407.13623
	- èªå½™æ•°ã‚‚è€ƒæ…®ã«å…¥ã‚ŒãŸã‚¹ã‚±ãƒ¼ãƒ«å‰‡ã‚’å°å‡ºã€‚ç•°ãªã‚‹èªå½™æ•°é–“ã§æ¯”è¼ƒã™ã‚‹ãŸã‚Unigramåˆ†ã‚’å¼•ã„ãŸæå¤±ã§è©•ä¾¡ã€‚éèªå½™åŸ‹ã‚è¾¼ã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®0.83ä¹—ã«æ¯”ä¾‹ã™ã‚‹ãƒšãƒ¼ã‚¹ã§èªå½™ã‚’å¢—ã‚„ã™ã¨è‰¯ã„ã€‚å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå¢—ãˆã‚‹ã»ã©æœ€é©ãªèªå½™æ•°ã¯å¢—åŠ ã™ã‚‹ã€‚æ—¢å­˜LLMã®èªå½™æ•°ã¯æœ€é©ã‚ˆã‚Šã‚‚æ•°å€å°‘ãªã„ã€‚
- Sakana AIã¯ã€æ—¥æœ¬ã®ç¾ã‚’å­¦ã‚“ã AIã¨ã—ã¦ã€æµ®ä¸–çµµé¢¨ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«Evo-Ukiyoeã¨ã€æµ®ä¸–çµµã‚«ãƒ©ãƒ¼åŒ–ãƒ¢ãƒ‡ãƒ«Evo-Nishikieã‚’å…¬é–‹ã—ã¾ã™ã€‚
	- https://x.com/SakanaAILabs/status/1815192991453401092
- NVIDIA proposes ChatQA 2, a Llama3-based model for enhanced long-context understanding and RAG capabilities.
	- https://x.com/omarsar0/status/1815219911276580951
	- The idea is to bridge the gap between open-access and leading proprietary models like GPT-4-Turbo.
	- Results demonstrate that the Llama3-ChatQA-2-70B model achieves accuracy comparable to GPT-4-Turbo2024-0409 on many long-context understanding tasks and surpasses it on the RAG benchmark.
-  ãƒ‡ãƒ¼ã‚¿ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã¨ç”ŸæˆAI
	- https://qiita.com/moritata9/items/f1f8538b559a007217af
	- ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¤ã‘ã‚‹éš›ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚’è‡ªç„¶è¨€èªã§è¡Œã†ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ãŒå¤šã„ã­ã€‚
	- ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¯LLMãŒå¾—æ„ãªé ˜åŸŸã ã‹ã‚‰ã€è‡ªç„¶è¨€èªã§SQLã‚’æ›¸ã„ã¦ã‚‚ã‚‰ã†ã“ã¨ã¯ã„ã„ä½¿ã„æ–¹ã ã­ã€‚
	- ãŸã ã€å“è³ªæ‹…ä¿ãŒä»•åˆ‡ã‚Œã‚‹ã‹ã©ã†ã‹ã¯ã¾ã ã‚ã‹ã‚‰ãªã„ã‹ã‚‰ã€SQLç”Ÿæˆã‚’ã—ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒã‚§ãƒƒã‚¯ã§ãã‚‹ä»•çµ„ã¿ã«ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã­ã€‚
	- åŠ¹ç‡åŒ–ã•ã‚Œã‚‹å´ã§ã¯ãªãã¦ã€åŠ¹ç‡åŒ–ã™ã‚‹å´ã«ãªã‚‹ã“ã¨ãŒå¤§äº‹ã ã­ã€‚
- Unslothã§Llamaã®QLoRA finetuningè©¦ã—ã¦ã¿ã¾ã—ãŸãŒæœ€é«˜ã§ã™ã­
	- https://x.com/arumaekawa/status/1814995731972755787
- Transformer Dissection: A Unified Understanding of Transformerâ€™s Attention via the Lens of Kernel
	- https://arxiv.org/pdf/1908.11775
	- https://x.com/myamada0/status/1814793268074586460
	- Transformerã¯ã‚«ãƒ¼ãƒãƒ«æ³•ä½¿ã£ã¦æ—©ããªã‚‹è«–æ–‡èª­ã‚“ã§ã€ã‚«ãƒ¼ãƒãƒ«æ³•ã“ã‚“ãªä½¿ã„æ–¹ã‚ã£ãŸã‹ã€é¢ç™½ã„ï¼ï¼ï¼ã£ã¦æ€ã£ãŸã‘ã©ã€å…±è‘—è«–æ–‡æ›¸ã„ã¦ãŸã®æ€ã„å‡ºã—ãŸã€‚(å¼•ç”¨ã•ã‚Œã¦ãŸ)
-  Mixture of LoRA Experts
	- https://arxiv.org/abs/2404.13628
	- è¤‡æ•°ã®LoRAã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã«ã‚ãŸã‚Šã€ãŸã è¶³ã—åˆã‚ã›ãŸã‚Šã¨ã„ã£ãŸæ–¹æ³•ã ã¨å„LoRAã®æ€§è³ªãŒå¤±ã‚ã‚Œã‚‹èª²é¡ŒãŒã‚ã£ãŸã€‚æœ¬ç ”ç©¶ã§ã¯LoRAã®å„å±¤ã”ã¨ã«Gating Functionã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€ä½ã‚³ã‚¹ãƒˆã§è¤‡æ•°ã®LoRAã®æ€§è³ªã‚’å¼•ãç¶™ãæ‰‹æ³•ã‚’ææ¡ˆã€‚V&Lã‚„NLPã«ãŠã„ã¦ã€æ—¢å­˜æ‰‹æ³•ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã¨ãªã£ãŸ
- Anthropic CEOã¯ã€äººé¡ã«è„…å¨ã‚’ä¸ãˆã‚‹AI(ASL-4æ°´æº–)ã®åˆ°æ¥ã¯ã€2025å¹´ã‹ã‚‰2028å¹´ã¨äºˆæƒ³
	- https://x.com/0317_hiroya/status/1815237370935136299
- DCLM 7B is based on OpenELM, trained on 2.5T tokens with 63.72 MMLU.
	- https://x.com/AlphaSignalAI/status/1815425975926006036
	- Apple just released a 7B model that beats Mistral 7B.
- ã€ŒHow is Mem0 different from RAG?ã€
	- https://x.com/Harappa80/status/1815358200826462272
	-  AIã¨ã®å¯¾è©±ã‚’é•·æœŸè¨˜éŒ²ã—ã¦LLMã®å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã™ã‚‹ã€ŒMem0ã€
- IMO questions only need high school level math knowledge and first one is the easiest so best humans can solve it in <60 mins
	- https://x.com/sytelus/status/1815203516941766757
- ã‚«ãƒ¼ãƒãƒ«æ³•ã¨Transformerã®è«–æ–‡ã¨ã‹æœ¬å½“ã«èƒ¸ç†±
	- https://x.com/m0chi_kokeshi/status/1815015579453133180
- Mistral-Nemo-Instruct-2407ã®ggufã‚ã‚Šã¾ã™
	- https://huggingface.co/mmnga/Mistral-Nemo-Instruct-2407-gguf
	- imatrixã®ãƒ‡ãƒ¼ã‚¿ã¯TFMC/imatrix-dataset-for-japanese-llmã‚’ä½¿ç”¨ã—ã¦ä½œæˆã—ã¾ã—ãŸ
- Llama 3.1 70B seems like the most interesting model launching tomorrow. HumanEval jumped from 39% to 79% between llama 3 and 3.1 70B
	- https://x.com/phill__1/status/1815426904289312788
-  æ·±æ´¥å¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¶…ãˆã‚‹ã€ãƒ­ãƒ³ã‚° ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ™‚ä»£ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯æŒ‡å—
	- https://note.com/google_gemini/n/nbbe40969c653?sub_rt=share_h
	- ã“ã‚Œã‹ã‚‰å¿…è¦ãªã®ã¯ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æš—è¨˜ã€ã§ã¯ãªã„
	- è€ƒãˆæ–¹ã¨ã—ã¦ã¯å¤§ãã 2 ç¨®é¡ã‚ã‚Šã¾ã™ã€‚ã²ã¨ã¤ãŒã€å•é¡Œã®é©æ­£ãªãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œã‚‹ã“ã¨ã€‚
	- ã‚‚ã†ã²ã¨ã¤ãŒã€å•é¡Œã‚’ç°¡å˜ã«è§£æ±ºã§ãã‚‹ã§ã‚ã‚ã†æ–¹æ³•ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã™ã€‚
	- ãƒ­ãƒ³ã‚° ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ´»ç”¨æ³•ã¨ã„ã†ã¨å¤§é‡ã®æƒ…å ±ã®è¦ç´„ã¨è¨€ã‚ã‚ŒãŒã¡ã§ãã‚Œã‚‚ã‚‚ã¡ã‚ã‚“ãªã®ã§ã™ãŒã€ã§ã‚‚ãã‚Œã ã‘ã§ãªãã€ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã€å¯¾è©±å±¥æ­´ã®åˆ†æã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãªã©ã€å¹…åºƒã„æ´»ç”¨ãŒå¯èƒ½ã§ã™ã€‚åƒ•çš„ã«ã¯ç‰¹ã«åˆ†æåŠ›ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€æ–°ãŸãªä¾¡å€¤ã‚’ç”Ÿã¿å‡ºã™ã“ã¨ãŒã§ãã‚‹ã¨è€ƒãˆã¦ã„ã‚‹ã‚“ã§ã™ã€‚
- LazyLLM:Dynamic Token Pruning for Efficient Long Context LLM Inference
	- https://huggingface.co/papers/2407.14057
	- Apple presents LazyLLM
- è‘—è€…ã‚‰ã®å®Ÿè£…ã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ãªKANã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹
	- https://github.com/Blealtan/efficient-kan
	-  An Efficient Implementation of Kolmogorov-Arnold Network
- Advanced RAG service
	- https://techcommunity.microsoft.com/t5/modern-work-app-consult-blog/exploring-the-advanced-rag-retrieval-augmented-generation/ba-p/4197836
	- è©±é¡Œã®Microsoft Researchã®GraphRAGã‚’ã¯ã˜ã‚ã€æ§˜ã€…ãªRAGã®æ§‹æˆæŠ€è¡“ã‚’ç°¡æ˜“ãªWebã‚¢ãƒ—ãƒªä¸Šã§ç°¡å˜ã«è©¦ã›ã‚‹Advanced RAG AI Serviceã€‚
- With our new InteractiveSheet feature you can create and edit Google Sheets from a Colab notebook!
	- https://x.com/GoogleColab/status/1815500302277394779
- Googleã€ã‚¢ãƒ—ãƒªå®Ÿè¡Œæ™‚ã«ç”ŸæˆAIãŒé©åˆ‡ãªUIã‚’æ§‹æˆã—å‹•çš„ç”Ÿæˆã™ã‚‹ã€ŒAI Generated UIã€ç™ºè¡¨
	- https://x.com/publickey/status/1815596621586891029
- MacStudioã§ã•ãˆãƒ­ãƒ¼ã‚«ãƒ«LLMã®é›»æ°—ä»£ã¨GPT-4ominiã®APIã‚³ã‚¹ãƒˆãŒãƒˆãƒ³ãƒˆãƒ³ã ã¨ã—ãŸã‚‰GPUã§ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMãªã‚“ã¦å®Œå…¨æ•—åŒ—ç¢ºå®šã˜ã‚ƒãªã„ã§ã™ã‹ï½ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1815620439940727067
- Build a mixture of agents with llama_index and ollama
	- https://x.com/jerryjliu0/status/1815534962785071442
- LLMã«ã‚ˆã£ã¦å°‚é–€çš„ãªå¿ƒç†ãƒ†ã‚¹ãƒˆã‚’RPGé¢¨ãªã©ã®ã‚²ãƒ¼ãƒ ã«å¤‰æ›ã—ã€æ¥½ã—ã¾ã›ãªãŒã‚‰æ¸¬å®šã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒæ¤œè¨¼ã•ã‚Œã¾ã—ãŸã€‚
	- https://arxiv.org/abs/2402.12326
	- LLM Agents for Psychology: A Study on Gamified Assessments
- å¯ã‚‹å‰ã«é ‘å¼µã£ãŸLLama 3.1æ°—ã«ãªã‚‹éƒ¨åˆ†ã¾ã¨ã‚
	- https://x.com/webbigdata/status/1815784455413612734
	- LLama 3.1 8Bã¯ã»ã¨ã‚“ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§Gemma 2 9Bã‚’ä¸Šå›ã‚‹
	-  LLama 3.1 70Bã¯ã»ã¨ã‚“ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT-3.5 turboã‚’ä¸Šå›ã‚‹ 
	- LLama 3.1 405Bã¯ã»ã¨ã‚“ã©ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§GPT-4ã‚’ä¸Šå›ã‚‹ 
	- LLama 3.1 405Bã¯GPT-4 Omniã€Claude 3.5 sonnetã¨ã»ã¼äº’è§’
-  The Llama 3 Herd of Models
	- https://ai.meta.com/research/publications/the-llama-3-herd-of-models/
- Tool calling with Ollama by LangChin
	- https://x.com/LangChainAI/status/1815860475441393845
	- https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/chat/ollama.ipynb
-  Towards Causal Foundation Model: on Duality between Causal Inference and Attention
	- https://arxiv.org/abs/2310.00809
	- æœ¬å½“ãªã‚‰å‡„ã„ã€‚
	- his is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention,
- Metaã¯å…ˆé™£ã‚’åˆ‡ã£ã¦æ˜ç¢ºã«ã€ŒEUã‚’ãƒãƒ–ã‚‹ã€æ–¹å‘ã«èˆµã‚’åˆ‡ã‚Š,ä»–æ©Ÿé–¢ã‚‚ç¶šããã†ã§ã™
	- https://x.com/ImAI_Eruel/status/1815935567680659803
	- EUã¯å³ã—ã„AIè¦åˆ¶ã‚’ã—ã‚ˆã†ã¨å‹•ã„ã¦ãŠã‚Šï¼ŒEUåœå¤–ã®ç”ŸæˆAIé–‹ç™ºãŒã€ŒEUã«åˆã‚ã›ã‚‹ã€ã®ã‹ã€ŒEUã‚’ãƒãƒ–ã‚‹ã€ã®ã‹å‹•å‘ãŒæ³¨è¦–ã•ã‚Œã¦ã„ãŸ
	- ä»Šæ—¥ã®Llama3.1ã§ã™ãŒï¼Œè«–æ–‡ï¼ˆhttps://ai.meta.com/research/publications/the-llama-3-herd-of-models/ï¼‰ã‚’è¦‹ã¦ã¿ã‚‹ã¨ï¼Œç·è¨ˆç®—é‡ãŒ3.8x10^25 ã§ï¼ŒEUãŒå®šã‚ãŸè¦åˆ¶å¯¾è±¡ã€Œsystemic riskã€ã®åŸºæº–ã§ã‚ã‚‹1.0x10^25ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼ã“ã‚Œã‚’è¶…ãˆã‚‹ã¨EUå†…ã§è‰²ã€…ã¨å„ä»‹ãªæ‰±ã„ã‚’å—ã‘ã‚‹ã¯ãšãªã®ã§ã™ãŒï¼ŒLeCunè‡ªèº«ã¯ã“ã®è©±é¡Œã«é–¢ã—ã¦ã€ŒEUã¯è‡ªã‚‰æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„ã‚ˆã†ã«é¦–ã‚’çµã‚ã¦ã„ã‚‹ã€ã¨ã„ã†ãƒ„ã‚¤ãƒ¼ãƒˆã‚‚RTã—ã¦ãŠã‚Šï¼Œæ„å›³çš„ã«è¸ã¿è¶Šãˆã¦ã„ã‚‹æ„Ÿã˜ã§ã™
- Fine-tuning gpt-4o-mini is *free* for up to 2M tok/day??
	- https://x.com/moyix/status/1815840634013639086
- Llama-3.1-8B-Instructã«ã€Llama3æ™‚ä»£ã®Swallowãƒ–ãƒ©ãƒ³ãƒå·®åˆ†ã‚’ãƒãƒ¼ã‚¸ã—æ—¥æœ¬èªåœã®çŸ¥è­˜ã‚’å­¦ç¿’ã•ã›ã‚‹å®Ÿé¨“
	- https://huggingface.co/aixsatoshi/Meta-Llama-3.1-8B-Instruct-plus-Swallow
- GPT-4o miniãŒ200ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã ã¨ç„¡æ–™ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã¨ã®ã“ã¨ğŸ‘ã€‚æ—©é€Ÿã€Govbotã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ä¸­â†“ğŸ˜‡ã€‚RAGã¨ã®ç²¾åº¦ã‚’æ¯”è¼ƒã—ã¦ã¿ãŸã„ã€‚ç”¨é€”ã«åˆã‚ã›ãŸãƒ¢ãƒ‡ãƒ«ãŒã“ã‚Œã»ã©ç°¡å˜ã«ä½œã‚Œã‚‹ã®ãŒãƒ›ãƒ³ãƒˆã™ã”ã„ã€‚ã—ã‹ã‚‚ã€ç„¡æ–™ï¼
	- https://x.com/gijigae/status/1815966274511348157
- I made the closed-source vs. open-weight models figure for this moment.
	- https://x.com/maximelabonne/status/1816008591934922915
	-  **é–‰æºãƒ¢ãƒ‡ãƒ«ã¨ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å·®ã®ç¸®å°:** 2022å¹´é ƒã‹ã‚‰ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚¦ã‚§ã‚¤ãƒˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒæ€¥é€Ÿã«å‘ä¸Šã—ã¦ãŠã‚Šã€é–‰æºãƒ¢ãƒ‡ãƒ«ã¨ã®å·®ãŒç¸®å°ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ç‰¹ã«ã€Llama 3.1 405Bã®ç™»å ´ã«ã‚ˆã‚Šã€åˆã‚ã¦é–‰æºãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ãŒå®Ÿç¾ã•ã‚Œã¾ã—ãŸã€‚
	-   **ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¨æ€§èƒ½ã®é–¢ä¿‚:** ä¸€èˆ¬çš„ã«ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¢—ãˆã‚‹ã»ã©æ€§èƒ½ãŒå‘ä¸Šã™ã‚‹å‚¾å‘ãŒè¦‹ã‚‰ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€å¿…ãšã—ã‚‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ãŒå¤šã„ãƒ¢ãƒ‡ãƒ«ãŒå¸¸ã«é«˜ã„æ€§èƒ½ã‚’ç¤ºã™ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚
	- **ãƒ¢ãƒ‡ãƒ«ã®é€²åŒ–ã®ã‚¹ãƒ”ãƒ¼ãƒ‰:** è‡ªç„¶è¨€èªå‡¦ç†ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã¯éå¸¸ã«é€Ÿãã€æ•°ãƒ¶æœˆã”ã¨ã«æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ãŒç™»å ´ã—ã€
- æ©Ÿæ¢°å­¦ç¿’ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³ã®è«–æ–‡ã€‚by æ¨ªå±±ã•ã‚“
	-  Deep learning density functional theory Hamiltonian in real space
	- https://arxiv.org/abs/2407.14379
	- å¾“æ¥ã®æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹ãƒãƒŸãƒ«ãƒˆãƒ‹ã‚¢ãƒ³äºˆæ¸¬ã¯åŸºåº•é–¢æ•°ã®é¸æŠãŒçµæœã«å¤§ããå½±éŸ¿ã—ãŸã®ã«å¯¾ã—ã€å®Ÿç©ºé–“ã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç›´æ¥äºˆæ¸¬ã™ã‚‹ã“ã¨ã§åŸºåº•é–¢æ•°ã«ä¾å­˜ã›ãšæ­£ç¢ºã«é›»å­çŠ¶æ…‹ã‚’äºˆæ¸¬ã§ããŸãã†ã§ã™ã€‚
- llama3.1ã‚’æ—¥æœ¬èªå¯¾å¿œã•ã›ãŸLlama3.1-ArrowSE-v0.4ã‚’å…¬é–‹ã—ã¾ã™ã€‚ã—ã£ã‹ã‚Šæ—¥æœ¬èªã§å¿œç­”ã—ã¾ã™ã€‚
	- https://huggingface.co/DataPilot/Llama3.1-ArrowSE-v0.4
- Fully local agents with Llama3.1
	- https://x.com/LangChainAI/status/1816150605318304166
- Mistral large2ã€123Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§æ—¥æœ¬èªã«æ­£å¼å¯¾å¿œ
	- https://x.com/AiXsatoshi/status/1816135011294404767
- Mistralã‹ã‚‰ã¾ãŸã—ã¦ã‚‚æ–°ãƒ¢ãƒ‡ãƒ«æŠ•ä¸‹ï¼ï¼Mistral-Large2ï¼ï¼å‰ã®Mistral-Largeã¯ã‚¯ãƒ­ãƒ¼ã‚ºãƒ¢ãƒ‡ãƒ«ã ã£ãŸã®ã«ä»Šå›ã¯ã‚ªãƒ¼ãƒ—ãƒ³å…¬é–‹ï¼ï¼ãƒ‘ãƒ©æ•°ã¯123Bï¼ï¼405Bã»ã©ã˜ã‚ƒãªã„ã‘ã©ã§ã‹ã„ã€‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·128kï¼å¤šè¨€èªå¯¾å¿œã§æ—¥æœ¬èªã‚‚ã‚¤ãƒ³ï¼ï¼MT-Benchã§8.63ã§Sonnet3.5ã‚„GPT-4oä¸¦ã¿ã‚‰ã—ã„ï¼ï¼ã€€ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1816154383211770096
- ç‰¹è¨±ç•ªå·ã‚’å…¥ã‚Œã‚‹ã¨AIãŒè‡ªå‹•çš„ã«ç‰¹è¨±ã«åŸºã¥ãã‚¢ã‚¤ãƒ‡ã‚£ã‚¢ã‚’è€ƒãˆã¦ãã‚Œã‚‹
	- https://chizaizukan.com/property/ideaflow/
- ãƒ™ã‚¤ã‚ºçµ±è¨ˆå…¥é–€ã€€by æ¸¡è¾ºæ¾„å¤«
	- https://warp.ndl.go.jp/info:ndljp/pid/12364128/watanabe-www.math.dis.titech.ac.jp/users/swatanab/joho-gakushu6.html
	- ã‚‚ã†ä¸»ç¾©ã‚‚è«–äº‰ã‚‚ã„ã‚Šã¾ã›ã‚“
	- ç¾ä»£ã®çµ±è¨ˆå­¦ã«ãŠã„ã¦ã€Œä¸»ç¾©ã€ãŒç„¡æ„å‘³ã§ã‚ã‚‹ã“ã¨ã¯ã€ã‚ã‹ã£ã¦ã„ã‚‹äººã¯ã¿ãªã‚ã‹ã£ã¦ã„ã‚‹ãŒã€ã€Œå°å…¥æœ¬ã€ã€Œï¼³ï¼®ï¼³ä¸Šã€ã€Œã¾ãŸèãã€ã«ã¯ã€Œãƒ™ã‚¤ã‚ºä¸»ç¾©ã€ã€ã€Œé »åº¦ä¸»ç¾©ã€ã¨ã„ã†è¨€è‘‰ã‚„è«–äº‰ã‚’ã‚ãŠã‚‹èª¬æ˜ãŒæ›¸ã‹ã‚Œã¦ã„ã‚‹å ´åˆãŒå¤šãã€ã“ã‚Œã‚’èª­ã‚“ã ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œã©ã¡ã‚‰ãŒæ­£ã—ã„ã‹ã€ã¨ã„ã†å•ã„ã‹ã‘ã‚’å§‹ã‚ã¦ã—ã¾ã„ã‚„ã™ã„ã€‚
- Llama 3.1 performing multi-step planning, reasoning, and tool calling. This is without an agent framework!
	- https://x.com/tom_doerr/status/1816118804541329533
-  Improving Model Safety Behavior with Rule-Based Rewards
	- https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards/
	- Weâ€™ve developed Rule-Based Rewards (RBRs) to align AI behavior safely by OpenAI
- OpenAIã®RBRã®è¨˜äº‹ã€Sonnetã«èª­ã‚“ã§ã‚‚ã‚ã†ãŸ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1816165449136267352
	- OpenAIã¯ä»Šã¾ã§LLMé–‹ç™ºã®ä»•ä¸Šã’ã«RLHFã§å¤§é‡ã®äººé–“ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã§èª¿æ•™ã—ã¦ã„ãŸã‘ã©ã€ã‚¤ãƒã‚¤ãƒå¤§å‹¢ã§RLHFã™ã‚‹ã®ã„ã„åŠ æ¸›ãƒ€ãƒ«ããªã£ã¦ããŸã®ã§ã€Œã›ã‚„ï¼AIã«AIã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚„ã‚‰ã›ãŸã‚ï¼ã€ã¨æ€ã£ãŸã€‚ãã‚“ã§è©•ä¾¡AIã«ãƒ«ãƒ¼ãƒ«ã‚’ä¸ãˆã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã•ã›ãŸã‚‰ã„ã„æ„Ÿã˜ã®çµæœã ã£ãŸã€‚
- OpenAIãŒä»Šå¹´åº¦7700å„„å††ã®æå¤±ã€å¢—è³‡ã—ãªã„ã¨è³‡é‡‘ãŒå‘ã“ã†12ãƒ¶æœˆã§å°½ãã‚‹å¯èƒ½æ€§ã‚ã‚Š
	- https://x.com/Haruki_Sonehara/status/1816230832849465415
	- ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã§1å…†å††ã»ã©ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚Šã€äººæã®ç¶­æŒç¢ºä¿ã«2000å„„å††ã€‚
-  Llama3.1-405Bã‚’ç¶™ä¹‹åŠ©ã§å‹•ã‹ã™ by shi3zã•ã‚“
	- https://www.free-ai.ltd/post/llama3-1-405b
	- å‹•ã„ãŸ Meta-Llama-3.1-405B running on A100x8
	- ä»®ã«FP8(8ãƒ“ãƒƒãƒˆæµ®å‹•å°æ•°ç‚¹æ•°)ãƒ¢ãƒ‡ãƒ«ã§ã‚ã£ãŸã¨ã—ã¦ã‚‚FP8ã«å¯¾å¿œã—ã¦ã„ãªã„Ampareä¸–ä»£ã®A100 80GBx8ã—ã‹æŒã£ã¦ãªã„å½“ç¤¾ã®ç¤¾é•·ã€ç¶™ä¹‹åŠ©(AIã‚¹ãƒ¼ãƒ‘ãƒ¼ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿)ã§ã¯å‹•ã‹ã›ãã†ã‚‚ãªã„ã¨è«¦ã‚ã¦ã„ã¾ã—ãŸ
	- vllmã§ã¯A100ã§FP8ã‚’ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹æ©Ÿèƒ½ãŒå‚™ã‚ã£ã¦ã„ã‚‹ã®ã§ã€A100x8ã§ã‚‚Llama-3.1-405BãŒå‹•ä½œã™ã‚‹ã¨ã®ã“ã¨!!ãƒã‚¸ã‹ã‚ˆ!
	- 

## 24/7/22

ä»Šé€±ã‚‚ã„ã‚ã„ã‚ã‚ã‚Šã¾ã—ãŸã€GPT-4o miniã®ç™ºè¡¨ã®ã»ã‹ã«AIæ•°å­¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯é–¢é€£ãŒç›®ç«‹ã¡ã¾ã—ãŸã€‚OpenAIã‹ã‚‰å‡ºãŸGPT-4o miniã€GPT-4ã‚ˆã‚Šã‚‚è³¢ãã€GPT-4oã‚ˆã‚Šç´„30å€ã‚‚å®‰ã„ã¨ã„ã†ã“ã¨ã§ã™ãŒã€èªå½™æ•°128Kã®Tekkenãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æ¡ç”¨ã§æ—¥æœ¬èªã¸ã®åŠ¹æœã‚‚æœŸå¾…ã•ã‚Œã‚‹ã¨ã®ã“ã¨ã€é‡å­åŒ–ã‚’æƒ³å®šã—ãŸå­¦ç¿’ã£ã¦ã©ã†ã„ã†ã“ã¨ï¼Ÿã€‚OpenAIã®ã€ŒProver-Verifier Gamesã€ã¯å¼·ã„AIã®å‡ºåŠ›ãŒäººé–“ãŒç†è§£ã™ã‚‹ãŸã‚ã«å¼±ã„AIã«èª¬æ˜ã•ã›ã‚‹ã¨ã„ã†è«–æ–‡ã€‚ã¾ã‚ã€LLMã«å¯¾ã—ã¦ã€Œå¿ƒã®ç†è«–ã€ã‚’å®Ÿè£…ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å„ªç§€æ€§ã¨ã‹ã€Claudeã«ã‚‚è€ƒãˆã‚‹æ™‚é–“ã‚’ã‚ã’ã‚‹ã¨è‰¯ã„ã¨ã„ã†<thinking>ã‚¿ã‚°ã®è©±ã¨ã‹ã€LLMã®æ·±å±¤ã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã¯ã‚‚ã¯ã‚„äººã«ã¯ã‚ã‹ã‚‰ãªã„ã®ã‹ã€‚OpenAIã®æœ€è¿‘ã®æ´»å‹•ã¯ã€Anthropicã‚‚ãã†ã ã‘ã©ã€LLMã‚’å–ã‚Šæ‰±ã†LLMã¨ã„ã†ãƒ¡ã‚¿ãªæ´»å‹•ãŒå¢—ãˆã¦ããŸæ„Ÿã˜ã€‚Mistralã‹ã‚‰ã¯ã€mambaã‚’æ¡ç”¨ã—ãŸcodestral-mambaã‚’ãƒªãƒªãƒ¼ã‚¹ã€HumanEvalã®Pythonã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ†ã‚¹ãƒˆã§äººé–“ã®75%ã‚’é”ã—ãŸã ã¨ã€‚åŒæ™‚ã«æ•°å­¦ãƒ¢ãƒ‡ãƒ«Mathtraã‚’ãƒªãƒªãƒ¼ã‚¹ã€OSSã§æ•°å­¦ãƒ¢ãƒ‡ãƒ«ã‚’ã¨ã„ã†ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ Numinaã¨é–¢é€£ã—ã¦ã„ã‚‹ã€‚AI-MOãŒãƒªãƒªãƒ¼ã‚¹ã—ãŸNuminaMath-7B-TIRã¯ã€AIæ•°å­¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ã§å„ªå‹ã—ãŸã‚‚ã®ã€ãƒ‡ãƒ¢ã‚‚ã‚ã‚‹ãŒã€é‡å­åŒ–ç‰ˆã¯llmcppã§ã‚‚å‹•ãã‚‰ã—ã„ã€‚Kaggleã«ã¯æ•°å­¦ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã®æ•´å‚™ã®è¨˜äº‹ãŒLLMæ´»ç”¨ã®ãŠæ‰‹æœ¬ã®ã‚ˆã†ãªæ„Ÿã˜ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰ã¯ã€ã‚¨ã‚¯ã‚»ãƒ«ã‚’å¯¾è±¡ã¨ã—ãŸLLMã§ã‚ã‚‹ã€ã€ŒSpreadsheetLLMã€ã€ã‚·ãƒ¼ãƒˆã‚³ãƒ³ãƒ—ãƒ¬ãƒƒã‚µãƒ¼ã£ã¦ã®ãŒè‚ã®æŠ€è¡“ã ã£ãŸã®ã‹ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã®Q-Sparseã€Mistral7Bãƒ™ãƒ¼ã‚¹ã§è©¦ã—ãŸã‚‰ã€æ´»æ€§åŒ–ãƒ‘ãƒ©æ•°ã‚’2.8Bãã‚‰ã„ã¾ã§åˆ‡ã‚Šè©°ã‚ã¦ã‚‚ã‚ã‚“ã¾ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢ä¸‹ãŒã‚‰ãªã„ã¨ã®ã“ã¨ã€ã“ã‚Œã¯ã™ã”ã„ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã§GraphRAGã‚’å®Ÿè£…ã™ã‚‹ä¾‹ãªã©ã‚‚å‡ºã¦ãã¦ã€GraphRAGã®ãƒ–ãƒ¼ãƒ ã‚‚ç¶šãã€‚ææ–™ç³»ãƒ»åŒ–å­¦ç³»ã ã¨ã€åå¿œäºˆæ¸¬ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€å°‚é–€å®¶ãŒé¸å®šã—ãŸç´ åå¿œãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ©ãƒ•ãƒ»æ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã™ã‚‹ã“ã§ã€ä¸­é–“ä½“ã‚„å‰¯ç”Ÿæˆç‰©ã‚‚äºˆæ¸¬ã§ãã‚‹ã¨ã‹ã€ By My Eyesè«–æ–‡ã®ã‚ˆã†ã«å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã‚’MLLMã«é¸ã°ã›ã¦ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã‚’äºŒæ¬¡å…ƒç”»åƒåŒ–ã—ã¦ã‹ã‚‰MLLMã§äºˆæ¸¬ã™ã‚‹ã¨ã‹ã€ã‚‚ã¯ã‚„ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ©Ÿèƒ½ã‚’ä½¿ãˆã°ä¸‹æ‰‹ãªäººé–“ã«ã‚ˆã‚‹å‰å‡¦ç†ãŒä¸è¦ãªã®ã‹ï¼Ÿãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰ã¯ã€æ±ç”¨æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã€æ–°ã—ã„æ©Ÿèƒ½æ€§ææ–™ã®æ¢ç´¢ã‚„ã€åœ°çƒå†…éƒ¨ã§ã®å…ƒç´ ã®åˆ†å¸ƒäºˆæ¸¬ã€åŠ¹ç‡çš„ãªåŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆãªã©ãŒæœŸå¾…ã§ãã‚‹ã€‚ãã‚Œã«ã—ã¦ã‚‚ã€Googleã®ã€Œè‡ªå·±è¤‡è£½ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã®è«–æ–‡ã€ã€ŒBrainfuck Familyã€ï¼ˆBFFï¼‰ã¨å‘¼ã°ã‚Œã‚‹è¨€èªç’°å¢ƒã¨ã„ã†ã®ã¯ã€å‰µç™ºã¨ã„ã†ã‹è¨ˆç®—æ©Ÿç§‘å­¦ä¸–ç•Œã®å‰µç”Ÿã®å†ç¾ã‚’ç‹™ã£ã¦ã„ã‚‹ã®ã‹ã€‚ã„ã‚‚ã™æ°ã®ã€ŒLLMã®ç¾åœ¨ã€ã‚„ã€éˆ´æœ¨å¤§æ…ˆå…ˆç”Ÿã®ã€Œæ·±å±¤å­¦ç¿’ã®æ•°ç† ã€ã‚’èª­ã‚ã°ã€æœ€æ–°ã®LLMã®ç†è«–çš„å‹•å‘ã«è¿½ã„ã¤ã‘ãã†ã€‚BCGã®ã€ã€Œãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµŒå–¶å‚è¬€ã€ã€ã“ã‚Œã‚’ï¼¬ï¼¬ï¼­ã«æ•™ãˆã‚‹ã¨ã€ã„ã‚„ã‚³ãƒ³ã‚µãƒ«ï¼¬ï¼¬ï¼­ãŒçˆ†èª•ã—ãã†ã ã€‚è¨€èªè³‡æºã¨ã„ã†ã‹ã€æ—¥æœ¬èªã«ã‚ˆã‚‹æŠ€è¡“çŸ¥è­˜ãŒå…¬å…±è²¡ã¨ãªã‚Šæ—¥æœ¬ã®ç™ºå±•ã‚’æ”¯ãˆãŸã¨ã„ã†è«–æ–‡ã€ãƒ¬ã‚¢ãªè‰¯è³ªãªçŸ¥è­˜ãŒãã“ã«ã‚ã‚‹ã‹ã‚‰ã¨ã„ã†ç†ç”±ãªã‚‰ã°ã€ä»Šã®ãƒãƒ«ãƒè¨€èªã®ä¸–ç•Œã§ã¯æ–°ã—ã„æ–¹å‘æ€§ã‚’è¦‹ã¤ã‘ãªã‘ã‚Œã°ã€ä¸–ç•Œã«åŸ‹ã‚‚ã‚Œã¦ã—ã¾ã†æ°—ãŒã™ã‚‹ã€‚MITã®ã‚¢ã‚»ãƒ¢ã‚°ãƒ«å…ˆç”Ÿã«ã‚ˆã‚‹ã€AIãŒåŠ´åƒè€…ã®ç”Ÿç”£æ€§ã«å¯¾ã—ã¦ã€Œã‚ãšã‹ã€ãªæ”¹å–„åŠ¹æœã—ã‹ã‚‚ãŸã‚‰ã•ãšã€ä»Šå¾Œ10å¹´é–“ã®ç±³å›½ã®çµŒæ¸ˆæˆé•·ã¸ã®å¯„ä¸ç‡ã¯1ï¼…æœªæº€ã ã¨äºˆæ¸¬ã£ã¦ã®ã¯ã€ä¸–ã®ä¸­ã®å¤§å‹¢ã®äºˆæ¸¬ã®é€†å¼µã‚Šã§èˆˆå‘³æ·±ã„ã€‚ELYZA-tasks-100ã‚’äººé–“ãŒè§£ãã¨ä½•ç‚¹å–ã‚Œã‚‹ã®ã‹ã¨ã„ã†è¨˜äº‹ã‚‚é¢ç™½ã‹ã£ãŸã€ã“ã†ã„ã†åœ°ã«ç€ã„ãŸæ´»å‹•ãŒã§ãã‚‹äººãŒå¼·ã„ã­ã€å•é¡ŒãŒäººç”¨ã«ã„ã¾ã„ã¡ã¨ã„ã†æ„Ÿã˜ã‚‚ã™ã‚‹ãŒã€ã“ã‚Œã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®æ¡ç”¨è©¦é¨“ã«ã—ãŸã‚‰ã©ã†ã‹ã€‚ã€‚

-  Common 7B Language Models Already Possess Strong Math Capabilities
	- https://arxiv.org/abs/2403.04706
	- his paper employs this straightforward approach achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B models, surpassing previous models by 14.2% and 20.8%, respectively.
	- 7Bã‚¯ãƒ©ã‚¹ã§æ•°å­¦çš„ãªèƒ½åŠ›70ãƒ‘ãƒ¼è¶Šãˆã€‚è¦‹ãŸã“ã¨ãªã„ãƒ¬ãƒ™ãƒ«ã€‚
-  ãƒãƒªã‚ªã‚«ãƒ¼ãƒˆã®ERå›³ã«ã¤ã„ã¦è€ƒãˆã‚‹
	- https://qiita.com/assu_ming/items/9d80320e6f778d83c61f
	-  1.æœ€çµ‚çš„ã«å‡ºã—ãŸã„ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’è€ƒãˆã‚‹
	- 2.ã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã‹åˆ—æŒ™ã™ã‚‹
	- 3.æ™‚ç³»åˆ—ã§ä¸¦ã¹ã‚‹
	- 4.ãƒ‡ãƒ¼ã‚¿ã®ã‹ãŸã¾ã‚Šæ¯ã«åˆ†é¡ã—ã¦ã¿ã‚‹
	- 5.ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åŒå£«ã®é–¢ä¿‚æ€§ã‚’ç·šã§ã¤ãªã
	- 6.ãã‚Œã‚‰ã—ã„ã‚«ãƒƒã‚³ã‚¤ã‚¤é …ç›®åã‚’ä»˜ã‘ã¦ã‚ã’ã‚‹ï¼ˆè‹±èªï¼‰
	- 7.å›³ã«è½ã¨ã—è¾¼ã‚€
- Incredible things are happening on my bag of legumes
	- https://x.com/stackofbears/status/1811837627357622398
- Kaggle ã®AIæ•°å­¦ã‚ªãƒªãƒ³ãƒ”ãƒƒã‚¯ã‚³ãƒ³ãƒšã®first solutioné¢ç™½ã‹ã£ãŸã€‚
	- https://x.com/corochann/status/1812447716410281986
	- æ•°å­¦ã®å•é¡Œã‚’è§£ãLLMã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆã‚’ã™ã‚‹ãŸã‚ã«TIR (Tool Integrated Reasoning)ã§Code execution feedbackã‚’ã„ã‚ŒãŸã‚Šã€Self-Consistencyã¨ã—ã¦è¤‡æ•°ç”Ÿæˆã•ã›ãŸçµæœã®Majority votingã¨ã£ãŸã‚Šã—ã¦ã„ã‚‹
	- https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/519303
- ColPali: Efficient Document Retrieval with Vision Language Models
	- https://arxiv.org/pdf/2407.01449
	- Repurposing PaliGemma as multimodal multi-vector encoder
	- ColPali, a ColBERT-inspired multimodal multi-vector encoder using PaliGemma as a basis for document retrieval.
- a knowledge graph agent into the ğŸ« CAMEL framework.
	- https://x.com/CamelAIOrg/status/1812168079712895059
- Camel AIã®KnowlegeGraphã‚’æŠ½å‡ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
	- https://x.com/guohao_li/status/1812406721547256100
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã§GraphRAGã‚’å®Ÿè£…ã—ã¦ã€Œã‚¯ãƒªã‚¹ãƒã‚¹ã‚­ãƒ£ãƒ­ãƒ«ã€ã‚’åˆ†æã—ã¦ã¿ãŸ
	- https://hamaruki.com/analyzing-christmas-carol-with-local-llm-graphrag-2/
- llama3 8B (not quantized) running on an heterogeneous home cluster made of:
	- https://x.com/evilsocket/status/1812110504531259900
-  Context Embeddings for Efficient Answer Generation in RAG
	- https://arxiv.org/abs/2407.09252
	- Speeds up generation time while improving answer quality by compressing multiple contexts into a small number of embeddings, offering flexible compression rates.
- LLMã®ç¾åœ¨ by ã„ã‚‚ã™
	- https://speakerdeck.com/pfn/llmnoxian-zai
	- ç”ŸæˆAIã«é–¢ã‚ã‚‹ãªã‚‰æ•™é¤Šã¨ã—ã¦èª­ã‚“ã§ãŠããŸã„è³‡æ–™ã€‚ ã“ã®è³‡æ–™ã‹ã‚‰ã‚ã‹ã‚‹ã“ã¨ã¨ã—ã¦ã¯ã€ 
		- é•·ã„ã‚¹ãƒ‘ãƒ³ã§è¦‹ãŸç¾åœ¨ã®ç”ŸæˆAIãƒ–ãƒ¼ãƒ ã®ç«‹ã¡ä½ç½® 
		- äº‹å‰å­¦ç¿’ã‹ã‚‰fine tuning,æ¨è«–ã®ä»•çµ„ã¿ãªã© 
		- é–‹ç™ºã«ãŠã‘ã‚‹èª²é¡Œãªã© LLMã«é–¢ã™ã‚‹ä¸€æ­©è¸ã¿è¾¼ã‚“ã å†…å®¹ã‚’ä½“ç³»çš„ã«ç†è§£ã§ãã¾ã™ï¼ 
	- Gæ¤œå®šã§ã‚‚ç”ŸæˆAIå‘¨ã‚Šã®å‡ºé¡Œã¯å¢—ãˆã¦ãã¦ã„ã‚‹ã—ã€ã“ã“ã¾ã§ã¾ã¨ã¾ã£ãŸè³‡æ–™ãŒç„¡æ–™ã§è¦‹ã‚Œã‚‹ã®ã¯ã‚ã‚ŠãŒãŸã„ã€‚
	- https://x.com/blue_statistics/status/1812785366925218181
- BCGã®å…ƒæ—¥æœ¬ä»£è¡¨ã®æ‰ç”°ã•ã‚“ã®ã€Œãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµŒå–¶å‚è¬€ã€
	- https://x.com/akino2425/status/1812627073913217357
	- è§£ãã¹ãèª²é¡Œã€€è«–ç‚¹è¨­å®šã®ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
		- 1. è§£ãã¹ãèª²é¡Œã¯è‡ªç¤¾ã®ã‚‚ã®ã‹ï¼Ÿ
			- ã©ã®ä¼æ¥­ã«ç½®ãæ›ãˆã¦ã‚‚åŒã˜ã‚ˆã†ãªèª²é¡Œè¨­å®šã«ãªã£ã¦ã„ãªã„ã‹ï¼Ÿ
		- 2. ãã‚ŒãŒè§£ã‘ãŸã‚‰æ¬¡ã«é€²ã‚€ã¹ãã€Œæ¬¡ã®èª²é¡Œã€ã¯è¦‹ãˆã¦ã„ã‚‹ã‹ï¼Ÿ
			- è‡ªç¤¾ã«ã¨ã£ã¦æ„å‘³ã®ã‚ã‚‹å¤§ããªå¢ƒå¤‰ã‚’æ„è­˜ã§ãã¦ã„ã‚‹ã‹ï¼Ÿ
		- 3. ãã“ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹ã‚‚ã®ãŒè¦‹ãˆã¦ã„ã‚‹ã‹ï¼Ÿ
			- ä½•ã‹ã‚’å†…åŒ…ã™ã‚‹ã€ã¯ã¦äº‰ä¸Šã®è¦³ç‚¹ãŒèŠ½å¹ãã®ã‹ï¼Ÿ
		- 4. Aã‹Bã‹ã®ç©¶æ¥µã®é¸æŠã‚’è¿«ã‚‹ã‚‚ã®ã§ã¯ãªã„ã‹ï¼Ÿ
			- ã‚ã‚‹ã„ã¯æ–°ãŸãªå±€é¢ã‚’åˆ‡ã‚Šé–‹ãã‚‚ã®ã‹ï¼Ÿ
		- 5. ã€Œã“ã®å•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã«ã“ã‚“ãªã“ã¨ãŒã§ãã¾ã™ã‚ˆã€ã¨è‡ªä¿¡ã‚’æŒã£ã¦è¨€ãˆã‚‹å…·ä½“æ€§ã‚’æŒã£ã¦ã„ã‚‹ã‹ï¼Ÿ
		- 6. å…·ä½“æ€§ãŒãªãã¦ã‚‚ã‚ˆã„ã®ã§ã€Œä¾‹ãˆã°ã€ã®ä»®èª¬ã‚’æç¤ºã§ãã‚‹ã‹ï¼Ÿ
		- 7. ãã‚ŒãŒçœŸã®èª²é¡Œã®è¨­å®šã¨è¨€ãˆã‚‹ã‹ï¼Ÿ
			- çœŸã®èª²é¡Œã¯ã€å•é¡Œç‚¹ã¨äº‹è±¡ã«æ˜ç¢ºãªå› æœé–¢ä¿‚ãŒã‚ã‚‹ã®ãŒã€çœŸã®å•é¡Œ
		- 8. ãã®åˆ¤æ–­ãŒä»Šã§ãã‚‹ã‹ï¼Ÿä»Šã€è§£ã‘ã‚‹èª²é¡Œã‹ï¼Ÿ
		- 9. è§£ãã¹ãè«–ç‚¹ã®ä»®è¨­ã¯åˆæœŸã«ä½œã‚‹ãŒã€ãã®ä»®è¨­ã‚‚å«ã‚ã¦ã€é€²åŒ–ã—ã¦ã„ã‚‹ã‹ï¼Ÿ
			- è«–ç‚¹è‡ªä½“ã‚‚å¤‰ã‚ã£ã¦ãã‚‹ã€‚ã‚ãã¾ã§è§£ãã¹ãç‚¹ã¯é€²åŒ–ã™ã‚‹
		- 10.ãã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµŒã¦æ·±ã‚ã¦ã„ãã‚‚ã®ã‹ï¼Ÿ
			- ä¸€ã¤ã®äº‹è±¡ã ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ã€åºƒã„è¦‹é€šã—ã‚’æŒã£ã¦ã„ã‚‹ã‹ï¼Ÿ
- BCGã®ãƒ¬ãƒãƒ¼ãƒˆã§ã¯ã€ä¸–ç•Œã®åœ°æ”¿å­¦çš„ãªç§©åºã®å¤‰åŒ–ã«ã‚ˆã£ã¦è²¿æ˜“æ´»å‹•ãŒã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’å—ã‘ã‚‹ã®ã‹ãŒã€ã‚¹ãƒƒã‚­ãƒªæ•´ç†ã•ã‚Œã¦ã„ã‚‹
	- https://x.com/Collie_Collie_/status/1812155080268984486
	- ä¾‹ãˆã°ã€ASEANãŒæ–°ãŸãªè¼¸å‡ºã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¨ã—ã¦æµ®ä¸Šã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚
	- https://www.bcg.com/ja-jp/publications/2024/jobs-national-security-and-the-future-of-trade
- AI Math Olympiad Winner - Running on Mac! 100% local
	- https://x.com/reach_vb/status/1812916171902976256
		- llama-cli
		- NuminaMath-7B-TIR-Q8_0-GGUF
		- "For how many values of the constant $ k $ will the polynomial $ x^{2}+kx+36$ have two distinct integer roots?"
- Deploy llama-agents running entirely self-hosted agents using arcee_ai, MistralAI and ollama!
	- https://x.com/llama_index/status/1812884178616406422
- CEEâ€™s new online graduate certificate, civil engineers can learn how to merge AI with digital twins to improve the predictive capabilities of their organization.
	- https://www.cmu.edu/online/aie-dta/rfi/index.html?utm_source=cee&utm_medium=social&utm_campaign=none&utm_content=fa24
-  Codification, Technology Absorption, and the Globalization of the Industrial Revolution
	- https://www.nber.org/papers/w32667
	- å¤–å›½ã‹ã‚‰ã®æŠ€è¡“çš„ãªçŸ¥è­˜ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦å…¬å…±è²¡ã¨ã—ã¦æ™®åŠã•ã›ãŸã“ã¨ãŒæ˜æ²»æ™‚ä»£ã®è¥¿æ¬§ã¸ã®ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ã«ã¤ãªãŒã£ãŸå¿…è¦æ¡ä»¶ã ã£ãŸã€‚æ˜æ²»ã®æ—¥æœ¬ãŒãªã‚“ã§ã†ã¾ãè¡Œã£ãŸã®ã‹ã®è¦å› ã‚’èª¬æ˜ã™ã‚‹ä¸€ã¤ã€‚
- ãƒã‚¹ãƒˆã‚·ãƒ³ã‚®ãƒ¥ãƒ©ãƒªãƒ†ã‚£å…±ç”Ÿå­¦ã®æ´»å‹•ã‚’æ‹¡å¤§ä¸­ã§ã™ã€‚ by å±±å·ã•ã‚“
	- https://x.com/hymkw/status/1812857636708294778
- BM42ãŒç¾ã‚Œã¦BM25ã‹ã‚‰æ–°æ™‚ä»£ã«ç§»è¡Œã™ã‚‹é›°å›²æ°—å‡ºãŸç›´å¾Œã«BM25Sã¨ã‹ã„ã†äºœç¨®å‡ºã¦ãã¦ã‚‹ã—ã€ãã‚‚ãã‚‚BM42ã®æ€§èƒ½ã‚‚æ–°æ™‚ä»£ã¨è¨€ãˆã‚‹ã‹æ€ªã—ã„ã—ã‚«ã‚ªã‚¹
	- https://x.com/goto_yuta_/status/1812861309534564516
- We've doubled the max output token limit for Claude 3.5 Sonnet from 4096 to 8192 in the Anthropic API.
	- https://x.com/alexalbert__/status/1812921642143900036
- Claude Sonnet 3.5 Coding System Prompt.
	- https://x.com/rohanpaul_ai/status/1812973162906460460
- Agentic RAG, explained visually
	- https://x.com/jerryjliu0/status/1812991904268849343
	- Check out nicolaygerold's full thread + diagrams below on agentic RAG + multi-agent architecture concepts, which we talked about during our aiDotEngineer talk ğŸ‘‡
	- https://www.youtube.com/watch?v=zeAyuLc_f3Q
- ELYZA-tasks-100ã‚’äººé–“ãŒè§£ãã¨ä½•ç‚¹å–ã‚Œã‚‹ã®ã‹ï¼Ÿ
	- https://zenn.dev/yuki127/articles/2496cd8383c84c
	- æ—¥æœ¬èªLLMè©•ä¾¡ã§ã‚ˆãç”¨ã„ã‚‰ã‚Œã‚‹elyza/ELYZA-tasks-100ã‚’äººé–“ãŒè§£ã„ãŸã‚‰ä½•ç‚¹å–ã‚Œã‚‹ã®ã‹ã‚’æ¤œè¨¼ã™ã‚‹
	- 2024/7/16æ™‚ç‚¹ã§æ—¥æœ¬èªæ€§èƒ½ãŒæœ€ã‚‚é«˜ã„LLMã®ä¸€ã¤ã¨ã•ã‚Œã‚‹Claude 3.5 Sonnetã¨ç‚¹æ•°ã‚’æ¯”è¼ƒã™ã‚‹
	- è§£ãã«ã‚ãŸã£ã¦é›£ã—ã‹ã£ãŸå•é¡Œã‚„ã€LLMã®ç«‹å ´ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ã©ã†ã‚ã£ã¦ã»ã—ã„ã‹ã‚’è§£èª¬ã™ã‚‹
	- Sonnet3.5ã¯ã€**4.42ç‚¹(+0.02 / -0.02)**
	- ãƒ¬ãƒãƒ¼ã‚¿ãƒ¼ã¯ã€**3.69ç‚¹(+0.03 / -0.03)**
- æ·±å±¤å­¦ç¿’ã®æ•°ç† by éˆ´æœ¨å¤§æ…ˆ
	- https://ibis.t.u-tokyo.ac.jp/suzuki/lecture/2023/TohokuUniv/%E6%9D%B1%E5%8C%97%E5%A4%A7%E5%AD%A62023.pdf
		- æ·±ã•ã«å¯¾ã—ã¦æŒ‡æ•°é–¢æ•°çš„ã«â€œè¡¨ç¾åŠ›â€ãŒä¸ŠãŒã‚‹
		- ç·šå½¢ãƒ¢ãƒ‡ãƒ«â†’ã‚«ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«â†’æ·±å±¤ãƒ¢ãƒ‡ãƒ«
		- è¨“ç·´èª¤å·®ã¨æ±åŒ–èª¤å·®
		- æ·±å±¤å­¦ç¿’ã¯ãªãœã†ã¾ãã„ãã®ã‹ï¼Ÿ [ä¸–ç•Œçš„èª²é¡Œ]
		- æ•°å­¦ã«ã‚ˆã‚‹æ·±å±¤å­¦ç¿’ã®åŸç†ç©¶æ˜
		  - ã€Œè¡¨ç¾èƒ½åŠ›ã€ã€ã€Œæ±åŒ–èƒ½åŠ›ã€ã€ã€Œæœ€é©åŒ–ã€
	  - **å­¦ç¿’**
		  - ã‚«ãƒ¼ãƒãƒ«æ³•ã€ã‚¹ãƒ‘ãƒ¼ã‚¹æ¨å®šã€ãƒ†ãƒ³ã‚½ãƒ«åˆ†è§£ã€ç‰¹å¾´æŠ½å‡º
	  - **æ·±å±¤å­¦ç¿’ã®ç†è«–**
	  - **æ•°å­¦**
		  -  Besovç©ºé–“ã€é€£ç¶šæ–¹ç¨‹å¼ã€é–¢æ•°è¿‘ä¼¼ç†è«–ã€ç¢ºç‡é›†ä¸­ä¸ç­‰å¼ã€Wassersteinå¹¾ä½•ã€ç¢ºç‡éç¨‹
	  - ç†è«–ã«ã‚ˆã‚Šæ·±å±¤å­¦ç¿’ã‚’"è¬ã®æŠ€è¡“"ã‹ã‚‰"åˆ¶å¾¡å¯èƒ½ãªæŠ€è¡“"ã¸  
	  - æ·±å±¤å­¦ç¿’ã‚’è¶…ãˆã‚‹æ–¹æ³•è«–ã®æ§‹ç¯‰ã¸
	- Deep Learningã«ã¤ã„ã¦æ·±ãç†è§£ã—ãŸã„äººã¯ã€æ±åŒ—å¤§å­¦ã®é›†ä¸­è¬›ç¾©ã€Œæ·±å±¤å­¦ç¿’ã®æ•°ç†ã€ã‚’èª­ã‚“ã æ–¹ãŒã„ã„ã§ã™ã€‚
	- æ·±å±¤å­¦ç¿’ã®ã€Œã‚ˆãã‚ã‹ã‚‰ãªã„ã‘ã©ã€ç²¾åº¦ãŒã‚ˆã„ã€ã¨ã„ã†èªè­˜ã‚’è¶…ãˆã€ä¸€æ­©æ·±ã„ç†è§£ãŒã§ãã‚‹ã‚ˆã†ã«ã€åŸç†ã‚’è§£æ˜ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹è³‡æ–™ã§ã™ã€‚
	- ç‰¹ã«ã€Œæ·±å±¤å­¦ç¿’ã®è§£é‡ˆå¯èƒ½æ€§ã€ã¯ã€ãƒ“ã‚¸ãƒã‚¹ã‚µã‚¤ãƒ‰ã§ã‚‚å¿…è¦‹ã§ã™ã€‚
- MatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures
	- https://arxiv.org/abs/2405.04967
	- æ±ç”¨æ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
	- Microsoftã•ã‚“ã¯1700ä¸‡ãƒ‡ãƒ¼ã‚¿ã§M3GNetã‚’è¨“ç·´ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã‚’ç”¨ã„ã¦æœ‰é™æ¸©åº¦ãƒ»åœ§åŠ›ä¸‹ã®è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ­£ç¢ºã«äºˆæ¸¬ã§ããŸãã†ã§ã™ã€‚
	- åºƒç¯„ãªå…ƒç´ ãƒ»æ¸©åº¦ãƒ»åœ§åŠ›æ¡ä»¶ã«å¯¾å¿œã§ãã‚‹æ±ç”¨çš„ãªãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ãŸã“ã¨ã§ã™ã€‚
	- æ–°ã—ã„æ©Ÿèƒ½æ€§ææ–™ã®æ¢ç´¢ã‚„ã€åœ°çƒå†…éƒ¨ã§ã®å…ƒç´ ã®åˆ†å¸ƒäºˆæ¸¬ã€åŠ¹ç‡çš„ãªåŒ–å­¦ãƒ—ãƒ­ã‚»ã‚¹ã®è¨­è¨ˆãªã©
- OllamaãŒOpenAIã®APIäº’æ›ã®ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’ã‚µãƒãƒ¼ãƒˆã ã£ã¦
	- https://x.com/umiyuki_ai/status/1813096846656430429
- MistralãŒã€æ•°å­¦ãƒ¢ãƒ‡ãƒ«ã¨ã€Mambaã®ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã€€by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://x.com/AiXsatoshi/status/1813315144254115987
	- https://mistral.ai/news/codestral-mamba/
	- https://mistral.ai/news/mathstral/
- ollama runs mathtral
	- https://ollama.com/library/mathstral
- 9.11 > 9.9? Someone suspected this is learned from version numbers. Here's some concrete proof.
	- https://x.com/liujc1998/status/1813244909501182310
- An underrated capability of sonnet-3.5 is that itâ€™s really good at chart understanding from llamaindex
	- https://x.com/llama_index/status/1813249175817232782
	- compared to gpt-4o itâ€™s much better at inferring chart values into a structured table.
	- Thanks to our brand-new LlamaParse release ğŸ’« you can easily use SOTA multimodal models like
- Math Olympiad Solver
	- https://huggingface.co/spaces/AI-MO/math-olympiad-solver
	- Demo of the [Numina-Math-7B-TIR](https://huggingface.co/AI-MO/NuminaMath-7B-TIR). Example data are drawn randomly from AMC12, year 2022-2023.
- InternVL2-Llama3-76B
	- https://huggingface.co/OpenGVLab/InternVL2-Llama3-76B
- Codestral Mamba 7B is a Code LLM based on the Mamba2 architecture. Released under Apache 2.0 and achieves 75% on HumanEval for Python Coding.
	- https://x.com/_philschmid/status/1813222276617412943
	- https://mistral.ai/news/codestral-mamba/
- By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting
	- https://x.com/sei_shinagawa/status/1813189318392885311
	- ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã‚’MLLMã§å‡¦ç†ã™ã‚‹æ–¹æ³•ã¨ã—ã¦ã€å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã‚’MLLMã«é¸ã°ã›ã¦ã‚»ãƒ³ã‚µãƒ‡ãƒ¼ã‚¿ã‚’äºŒæ¬¡å…ƒç”»åƒåŒ–ã—ã¦ã‹ã‚‰MLLMã§äºˆæ¸¬ã™ã‚‹ã€‚ã™ã¹ã¦ã‚’ç”»åƒã«ã—ã¦ã‚„ã‚‹ãœã¨ã„ã†æ„æ¬²ä½œå†ã³ã ãƒ»ãƒ»
-  Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction
	- https://arxiv.org/abs/2406.19108
	- Googleã®ç ”ç©¶è€…ã‚‰ãŒã€Œè‡ªå·±è¤‡è£½ã™ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã®è‡ªç„¶ç™ºç”Ÿã‚’ç¢ºèª
	- ã“ã®ç ”ç©¶ã®ä¸­å¿ƒã¨ãªã£ãŸã®ã¯ã€ã€ŒBrainfuckã€ï¼ˆBFï¼‰ã¨ã„ã†æ¥µã‚ã¦å˜ç´”ãªè¨€èªã‚’æ‹¡å¼µã—ãŸã€ŒBrainfuck Familyã€ï¼ˆBFFï¼‰ã¨å‘¼ã°ã‚Œã‚‹è¨€èªç’°å¢ƒã§ã‚ã‚‹ã€‚
	- BFFã§ã¯ã€_**64ãƒã‚¤ãƒˆã®é•·ã•ã‚’æŒã¤131,072å€‹ã®ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã£ã¦ã€ã€ŒåŸå§‹ã‚¹ãƒ¼ãƒ—ã€ï¼ˆPrimordial-soupï¼‰ã¨å‘¼ã°ã‚Œã‚‹ç’°å¢ƒã‚’å½¢æˆã™ã‚‹**_ã€‚
	- è¨€èªBrainfuckã‚„Z80ã®åŸå§‹ã‚¹ãƒ¼ãƒ—ç’°å¢ƒã‚’æ§‹ç¯‰ã€‚2ã®17ä¹—ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒç›¸äº’ä½œç”¨ã—è‡ªå·±ä¿®æ­£ã™ã‚‹ã ã‘ã§è‡ªå·±è¤‡è£½ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå‡ºç¾ã€‚ã“ã‚Œã‚‰ãŒç’°å¢ƒã‚’æ”¯é…ã—ç«¶äº‰ã—å…±ç”Ÿã™ã‚‹ç”Ÿå‘½ã«ä¼¼ãŸæŒ¯ã‚‹èˆã„ã‚’è¦‹ã›ãŸ
-  MicrosoftãŒã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ç†è§£ã§ãã‚‹è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒSpreadsheetLLMã€ã‚’ç™ºè¡¨ã€Excelã®ä»•äº‹ã‚‚AIãŒã“ãªã™æ™‚ä»£ã«
	- https://gigazine.net/news/20240716-microsofts-ai-spreadsheetllm/
- Google accidentally updated their website with Gemini 2.0 and Bing indexing caught it
	- https://x.com/phill__1/status/1813307823570157899
-  Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models
	- https://www.arxiv.org/abs/2407.07086
	- LLMã«å¯¾ã—ã¦ã€Œå¿ƒã®ç†è«–ã€ã‚’å®Ÿè£…ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ãã†ã§ãªã„LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚„å¼·åŒ–å­¦ç¿’ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨æ¯”ã¹ã¦æ§˜ã€…ãªç«¶äº‰ã§å„ªä½ã«ç«‹ã¤ã“ã¨ã‚’ç¤ºã™å®Ÿé¨“çµæœãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚
- Anthropic APIã®Claude 3.5 Sonnetã®æœ€å¤§å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒ4096ã‹ã‚‰8192ã«å€å¢—ã€‚
	- https://x.com/masahirochaen/status/1813333555185164637
	- GPT-4oã‚‚4Kç¨‹åº¦ãªã®ã§2å€ã« 8Kã ã¨Gemini 1.5 Proãƒ¬ãƒ™ãƒ«
-  Prover-Verifier Games improve legibility of language model outputs by OpenAI
	- https://openai.com/index/prover-verifier-games-improve-legibility/
	- We trained advanced language models to generate text that weaker models can easily verify, and found it also made these texts easier for human evaluation. 
	- This research could help AI systems be more verifiable and trustworthy in the real world.
	- OpenAIãŒä½œã£ã¦ã‚‹AIãŒè³¢ããªã‚Šã™ãã¦ã¦ã€AIãŒã„ãã‚‰æ­£ç¢ºãªå›ç­”ã—ã¦ã‚‚äººé–“ã¯ã‚¢ãƒ›ã ã‹ã‚‰å†…å®¹ã‚’ç†è§£ã§ããªã„ã®ãŒã‚‚ã¯ã‚„å•é¡Œã«ãªã£ã¦ã‚‹ã‚‰ã—ã„ã€‚by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1813635128570311037
	- ãã“ã§ã€ã—ã‚‡ã†ãŒã­ãˆã‹ã‚‰äººé–“ã®ä»£ã‚ã‚Šã«ã‚¢ãƒ›ãªAIã‚’ç”¨æ„ã—ã¦ã€ã¤ã‚ˆã¤ã‚ˆAIã«ã‚¢ãƒ›AIã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†ã«èª¬æ˜ã—ã‚ï¼ã£ã¦è¨“ç·´ã‚’ã•ã›ãŸã‚‰ã—ã„ã€‚
	- çµæœã€äººé–“ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼ã ã£ã¦ã•ã€‚
- AIã¯ç”Ÿç”£æ€§ã‚’å¤§ããé«˜ã‚ãªã„ è­°è«–ã‚’å‘¼ã¶MITæ•™æˆã®æ‚²è¦³è«–
	- https://www.asahi.com/articles/ASS7J33L5S7JUHMC003M.html
	- ã‚¢ã‚»ãƒ¢ã‚°ãƒ«æ•™æˆã¯ã“ã†çµè«–ã¥ã‘ã‚‹ã€‚AIã¯åŠ´åƒè€…ã®ç”Ÿç”£æ€§ã«å¯¾ã—ã¦ã€Œã‚ãšã‹ã€ãªæ”¹å–„åŠ¹æœã—ã‹ã‚‚ãŸã‚‰ã•ãšã€ä»Šå¾Œ10å¹´é–“ã®ç±³å›½ã®çµŒæ¸ˆæˆé•·ã¸ã®å¯„ä¸ç‡ã¯1ï¼…æœªæº€ã—ã‹ãªã„ã€ã¨ã€‚
- very glad President Trump is safe!ã€€by Sam Altman
	- https://x.com/sama/status/1812325941647233057
-  Reproducing Reaction Mechanisms with Machine Learning Models Trained on a Large-Scale Mechanistic Dataset
	- https://onlinelibrary.wiley.com/doi/10.1002/anie.202411296
	- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹åå¿œäºˆæ¸¬ã®è«–æ–‡ by æ¨ªå±±ã•ã‚“
	- https://x.com/yoko_materialDX/status/1813891469880459534
	- å¾“æ¥ã¯ä¸»ç”Ÿæˆç‰©ã—ã‹äºˆæ¸¬ã—ãªã‹ã£ãŸã®ã«å¯¾ã—ã€å°‚é–€å®¶ãŒé¸å®šã—ãŸç´ åå¿œãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ©ãƒ•ãƒ»æ–‡å­—åˆ—ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã™ã‚‹ã“ã§ã€ä¸­é–“ä½“ã‚„å‰¯ç”Ÿæˆç‰©ã‚‚äºˆæ¸¬ã§ããŸãã†ã§ã™ã€‚
	- ç¾çŠ¶ã®èª²é¡Œã¯èª¤å·®è“„ç©ã¨ä¿å­˜å‰‡ã‚’ç ´ã£ã¦ã—ã¾ã†ã“ã¨ã‚‰ã—ã„ã€‚ãªã‚‹ã»ã©ã€‚
-  Taming the chaos gently: a Predictive Alignment learning rule in recurrent neural networks
	- https://www.biorxiv.org/content/10.1101/2024.07.14.603423v1
	- How can a biologically plausible synaptic plasticity rule tame the chaos in recurrent neural networks?
- new GPT-4o mini release!
	- https://x.com/OpenAI/status/1813991706083340798
	- Introducing GPT-4o mini! Itâ€™s our most intelligent and affordable small model, available today in the API. GPT-4o mini is significantly smarter and cheaper than GPT-3.5 Turbo.
	- GPT-4o mini's early version "upcoming-gpt-mini" was tested in Arena in the past week. by lmsysorg
		- https://x.com/lmsysorg/status/1813999088758673875
- MistralãŒNVidiaã¨å¼·åŠ›ã‚¿ãƒƒã‚°ã‚’çµ„ã‚“ã§12Bãƒ‘ãƒ©ã®Mistral-Nemoã‚’ã‚ªãƒ¼ãƒ—ãƒ³ãƒªãƒªãƒ¼ã‚¹ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1813961423653077246
	- ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦128kï¼
	- é‡å­åŒ–èªè­˜ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æãªã†ã“ã¨ãªã FP8 æ¨è«–ã§ãã‚‹ï¼
	- ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢ã¯MMLUä»¥å¤–ã¯Gemma2-9Bã‚’åœ§å€’ï¼Tekkenãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã§æ—¥æœ¬èªã®ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡çˆ†ä¸ŠãŒã‚Šï¼
- GPT-4o miniã¯ã€GPT-4ã‚ˆã‚Šã‚‚è³¢ãã€GPT-4oã‚ˆã‚Šç´„30å€ã‚‚å®‰ã„ã€é©å‘½çš„ãªAIãƒ¢ãƒ‡ãƒ«ã§ã™
	- https://x.com/ctgptlb/status/1813998168931192843
- 128ké•·æ–‡å¯¾å¿œã€12Bãƒ¢ãƒ‡ãƒ«Mistral NeMo Apache 2.0ã§ãƒªãƒªãƒ¼ã‚¹ï¼ã€€ by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://x.com/AiXsatoshi/status/1814012421889216576
	- èªå½™æ•°128Kã®Tekkenãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§ã€å¤šè¨€èªã€ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ä¼šè©±ã«å¼·ã„ Gemma 2 9BãŠã‚ˆã³Llama 3 8Bã¨æ¯”è¼ƒã—ã¦é«˜ã„ç²¾åº¦ FP8æ¨è«–ã§æ€§èƒ½ä½ä¸‹ã—ãªã„ã‚ˆã†å­¦ç¿’ã—ã¦ã„ã‚‹
	- æ—¥æœ¬èª1.56å€åœ§ç¸®ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶
	- https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407
-  Codification, Technology Absorption, and the Globalization of the Industrial Revolution
	- https://x.com/nberpubs/status/1813589839951868033
	- Japanâ€™s massive public investments in codifying technical knowledge explain why it was unique among non-Western countries in industrializing in the 19th and early 20th centuries,
	- ç¾åœ¨ã€ä¸–ç•Œã«ã¯4ç¨®é¡ã®é«˜æ‰€å¾—å›½ã—ã‹ãªã„ã€‚1) è‹±èªåœã€2) ã‚¤ã‚®ãƒªã‚¹ã«è¿‘ã„å›½ã€3) è³‡æºã«æµã¾ã‚ŒãŸå›½ã€ãã—ã¦4) æ—¥æœ¬ã¨ãã®æ—§æ¤æ°‘åœ°ã§ã‚ã‚‹ã€‚ã€ 1ã€œ3ã¾ã§ã¯ã‚ˆãç ”ç©¶ã•ã‚Œã¦ã„ã‚‹ãŒã€ãªãœ4ãªã®ã‹ï¼Ÿ
	- ç”£æ¥­é©å‘½ãŒãªãœæ—¥æœ¬ã«æœ€åˆã«åºƒãŒã‚Šã€ä»–ã®éè¥¿æ´‹è«¸å›½ã«ã¯åºƒãŒã‚‰ãªã‹ã£ãŸã®ã‹ã«é–¢ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ã®ç ”ç©¶ã€‚
-  GPT-4o mini ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/nd985687d6cb1?sub_rt=share_h
	- ã€ŒGPT-4o miniã€ã¯ã€ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã‚’ã‚ˆã‚Šæ‰‹é ƒãªä¾¡æ ¼ã«ã™ã‚‹ã“ã¨ã§ã€AIã§æ§‹ç¯‰ã•ã‚Œã‚‹ã‚¢ãƒ—ãƒªã®ç¯„å›²ã‚’å¤§å¹…ã«æ‹¡å¤§ã™ã‚‹ã¨æœŸå¾…ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
	- 2. å„ªã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ã¨ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ¨è«–ã‚’å‚™ãˆãŸå°å‹ãƒ¢ãƒ‡ãƒ«
	- 3. çµ„ã¿è¾¼ã¿ã®å®‰å…¨å¯¾ç­–
	- ChatGPTã§ã¯ã€Freeã€Plusã€Team ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€GPT-3.5 ã®ä»£ã‚ã‚Šã«ã€æœ¬æ—¥ã‚ˆã‚Šã€ŒGPT-4o miniã€ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚
-  Q-Sparse: All Large Language Models can be Fully Sparsely-Activated
	- https://arxiv.org/abs/2407.10969
	- Microsoft Research is excited to introduce Q-Sparse: a breakthrough in training fully sparsely-activated LLMs. Q-Sparse supports both full-precision and 1-bit LLMs. Its synergy with BitNet b1.58 advances LLM efficiency, including cost and energy use.
	- LLMã‚’ã‚¹ãƒ‘ãƒ¼ã‚¹åŒ–ã•ã›ã¦æ¨è«–æ™‚ã«ä½¿ã†ãƒ‘ãƒ©æ•°æ¸›ã‚‰ã›ã¦å‡¦ç†åŠ¹ç‡çˆ†ä¸ŠãŒã‚‹ã‚‰ã—ã„ï¼Mistral7Bãƒ™ãƒ¼ã‚¹ã§è©¦ã—ãŸã‚‰ã€æ´»æ€§åŒ–ãƒ‘ãƒ©æ•°ã‚’2.8Bãã‚‰ã„ã¾ã§åˆ‡ã‚Šè©°ã‚ã¦ã‚‚ã‚ã‚“ã¾ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢ä¸‹ãŒã‚‰ãªã„ã‚‰ã—ã„ã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1813974577187537074
- æ—©ç¨²ç”°å¤§å­¦å†…ã®Wi-FiçµŒç”±ã§chatGPTã‚„DeepLãŒä½¿ãˆãªããªã‚Šã¾ã—ãŸã€‚
	- https://x.com/aisa_rizapuro/status/1813900610946957600
	- ãƒ†ã‚¹ãƒˆæœŸé–“é™å®šã®åˆ¶é™ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ä»Šã“ã®æ™‚ä»£ã«ç”ŸæˆAIãƒ„ãƒ¼ãƒ«ã‚’ç¦æ­¢ã™ã‚‹ã®ã¯ã„ã‹ãŒãªã‚‚ã®ã‹ã¨æ€ã„ã¾ã™
	- ä¸€æ–¹ã§chatGPTã‚’æ¨å¥¨ã™ã‚‹å…ˆç”Ÿã‚‚ã„ã‚‰ã£ã—ã‚ƒã‚‹ã®ã§æ•™æˆä¼šã®ä¸­ã§ã‚‚æ„è¦‹ãŒå‰²ã‚Œã¦ãã†ã§ã™â€¦
- æ·±å±¤NNã‚‚Transformerã‚‚çµå±€ã¯ã‚«ãƒ¼ãƒãƒ«æ³•ãªã®ã§ã™ï¼ã™ã¹ã¦ã¯ã‚«ãƒ¼ãƒãƒ«æ³•ã®ãŸã‚ã«ã‚ã‚‹ã®ã§ã™
	- https://x.com/btreetaiji/status/1814319983150932222
- Claudeã«ã‚‚è€ƒãˆã‚‹æ™‚é–“ã‚’ã‚ã’ã‚‹ã¨è‰¯ã„ã‚“ã â€¦
	- https://x.com/shiranui_it/status/1814580977576124535
	- <thinking></thinking>å†…ã§è€ƒãˆã¦ãã ã•ã„ã€‚ã€‚
- 


## 24/7/14

å…ˆé€±å…¬é–‹ã•ã‚ŒãŸã€GraphRAGé–¢é€£ã®ã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«å…¬è¡¨ã‚„è©•ä¾¡ãŒã™ã™ã‚“ã§ã„ã¾ã™ã€‚RAGã¨QFS(Query-Focused Summarization)ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’ã†ã‚ã‚‹ä¸€æ‰‹æ³•ã§ã‚ã‚‹ã¨ã„ã†ã®ã¯ãªã‚“ã‹ç´å¾—ã€‚Gemma-2:9bã§ã‚‚GraphRAGãŒå‹•ãã¨ã„ã†å ±å‘Šã‚‚ã€‚Gemma2ã¯ã€tokenizerã«ä¸å…·åˆãŒã‚ã‚‹ã‚‰ã—ã„ãŒã€AUTOMATIC1111ã•ã‚“ãŒå‹•ã„ã¦ã„ã‚‹ãªã‚‰ã€æ²»ã‚‹ã®ã¯æ™‚é–“ã®å•é¡Œã€‚ã•ã¦RAGã®å¯¾æŠ—é¦¬ï¼Ÿã¨ã—ã¦ã™ãã«è©±é¡Œã«ãªã‚‹ã®ã¯ã€ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰ã¯ï¼‘Mãƒˆãƒ¼ã‚¯ãƒ³å‡¦ç†ã‚’ï¼‘ï¼å€ã¨ã†ãŸã†MInference 1.0ãŒç™»å ´ã€Dynamic Sparse Attentionã£ã¦æŠ€è¡“ã‚’ä½¿ã†ã®ã­ã€ãƒ‡ãƒ¢ã‚µã‚¤ãƒˆã§ç„¡åŒã¶ã‚Šã‚’è©¦ã—ã¦ã¿ã‚‹ã®ã‚‚ã‚ˆã„ã‹ã‚‚ã€‚Interface 8æœˆå·ç‰¹é›†ã¯ã€Œç”ŸæˆAIã€ã€LoRaã‚’æ‰‹ã‚’å‹•ã‹ã—ã¦ç†è§£ãŒé€²ã‚€ã‹ã‚‚ã€‚NVIDIAã‹ã‚‰ã¯ã€RankRAGãŒç™»å ´ã€context rankingã¨ã„ã†ä»•æ›ã‘ã‚’LLMã«åŸ‹ã‚è¾¼ã‚“ã ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€‚NVIDIAçš„ã«ã¯ãƒ­ãƒ¼ã‚«ãƒ«ãªçŸ¥è­˜ã‚’é«˜ç²¾åº¦ã§ä½¿ãˆã‚‹ã‹ã‚‰ã€ã‚ªãƒ³ãƒ—ãƒ¬ã§GPUã©ã‚“ã©ã‚“è²·ã£ã¦ã­ã¨ã„ã†ã“ã¨ã‹ã€‚Unslothã‹ã‚‰ã¯Gemma-2:9bã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é€Ÿåº¦ãŒï¼’å€ã«ãªã£ãŸã¨ã€ã€colabã§ã‚‚è©¦ã›ã‚‹ã®ã‹ï¼Ÿã€‚Transformerã®æ¬¡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ï¼‘ã¤ã ã¨ã•ã‚Œã‚‹ã€Mamba-based Language Modelsã®å®šé‡çš„ãªè©•ä¾¡ãŒå‡ºã¦ããŸã€ç›¸å½“æœŸå¾…ãŒã‚‚ã¦ãã†ã€‚å…ˆé€±ã®è‡ªç„¶ãªä¼šè©±ãŒã§ãã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Moshiã‚‚ã™ã”ã‹ã£ãŸã®ã ã‘ã©ã€TerifAI (terrify) ã£ã¦ã®ã‚‚ã€è‡ªåˆ†å£°ã‚’ã¾ã­ã‚‹ã“ã¨ãŒã§ãã‚‹ãªã‚“ã¦ã€ã‚‚ã†ã‚ªãƒ¬ã‚ªãƒ¬è©æ¬ºLLMã®ç™»å ´ã¯æ™‚é–“ã®å•é¡Œã€æœ€åˆã«ã€Œã‚ªãƒ¬ã‚ªãƒ¬ã ã‘ã©ã€ã€ã€ã¨ç™ºã™ã‚‹è¦åˆ¶ãŒå¿…è¦ã€‚Artifactsã§å¿«é€²æ’ƒã®Claudeã€ä»Šåº¦ã¯ä½œã£ãŸArtifctsã®ãƒ©ã‚¤ãƒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«URLå…¬é–‹æ©Ÿèƒ½ãŒæ­è¼‰ã£ã¦ã€ã“ã‚Œã¯ã™ã”ã™ãã§ã—ã‚‡ã†ã€ã©ã†ã„ã†ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ãŒã§ãã‚‹ã‚“ã ã‚ã†ã‹ï¼Ÿã€‚AnthoropicãŒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è‡ªå‹•ç”Ÿæˆã‚„è©•ä¾¡æ©Ÿèƒ½ã‚’å‚™ãˆã¦ã€ï¼‘ä¸–ç´€åˆ†ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ­´å²ã‚’ãŠãã‚‰ã1å¹´ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ã¨ã„ã†è©±ã‚‚ç´å¾—ãªå‹•ãã€‚ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã¨ãƒãƒ•ã‚£ãƒ³ãƒˆãƒ³æ°ã«ã‚ˆã‚‹Thrive AI Healthã€è¡Œå‹•ã‚’å¤‰ãˆã‚‹ã“ã¨ã«ã‚ˆã‚Šå¥åº·ã«ãªã‚‹ã¨ã„ã†ã®ã¯ã€ãªã‚“ã‹è€³ãŒç—›ã„ãŒã€æœŸå¾…ã§ããã†ã€‚Ollama 0.2ã€gemma-2å¯¾å¿œã®ãƒã‚°ã¨ã‹ã‚‚æ²»ã£ãŸã¿ãŸã„ã ã©ã€è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸¦åˆ—ã«å‹•ä½œå¯èƒ½ã¨ã®ã“ã¨ã€ã“ã‚Œã£ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¨LlamaGuardã®ã‚ˆã†ãªLLMã«ã‚ˆã‚‹ã‚»ãƒ¼ãƒ•ã‚¬ãƒ¼ãƒ‰å®Ÿè£…ã‚’åŒæ™‚ã«å‹•ã‹ã™ã“ã¨ãŒã§ãã‚‹ã¨ã„ã†ã“ã¨ã€‚ç†è«–é¢ã§ã¯ã€å¼·åŒ–å­¦ç¿’ã®æ¦‚å¿µã‚’å–ã‚Šå…¥ã‚ŒãŸQ*ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€ã¾ãŸã¾ãŸè©±é¡Œã«ãªã‚‹ã€‚LLMã®å¤šæ®µæ¨è«–ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€A-starã‚µãƒ¼ãƒã§æ¢ç´¢ã™ã‚‹ã£ã¦ã©ã‚Œã ã‘è¨ˆç®—ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã®ã‹ã€‚å²¡é‡åŸã•ã‚“ã®ã€éå¹³è¡¡ç†±åŠ›å­¦ã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ¥ç‚¹ã®è«–æ–‡ã®ç´¹ä»‹ã€å¤§å­¦ç”Ÿï¼ˆï¼“å¹´ç”Ÿï¼‰ã¨ã®å…±è‘—ã¨ã„ã†ã®ãŒã€é©šãã ã€‚MoEã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å°ã•ãæ•°ã‚’å¢—ã‚„ã™ã»ã©æ€§èƒ½ãŒæ”¹å–„ã•ã‚Œã‚‹ã®ã‹ã€ãã‚Œã«ã—ã¦ã‚‚100ä¸‡ã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã£ã¦ã©ã†ã‚„ã£ã¦ä½œã‚‹ã®ï¼Ÿã€‚Llamaindexã‹ã‚‰ã¯ã€llama-agentsã‚’ç™ºè¡¨ã€ãã†ã„ãˆã°ã€ClaudeãŒï¼•æœˆã«ç™ºè¡¨ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã€ŒTool Useã€ã£ã¦è‡ªå¾‹çš„ã«å‹•ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å‚™ãˆãŸã¨ã„ã†è©±ã‚‚ä»Šé€±ã‚ã£ãŸã€‚DeepMindã®ãƒã‚µãƒ“ã‚¹æ°ã€ã€Œç¾æ™‚ç‚¹ã§ã®æ±ç”¨AIã¯çŒ«ç¨‹åº¦ã®IQã—ã‹ãªã„ã€ã¨ã€æ­©èª¿ã‚’ã‚ã‚ã›ã‚‹ã‚ˆã†ã«OpenAIã‹ã‚‰ã¯ã€ã€ŒAIãŒäººé–“ã®çŸ¥èƒ½ã«ã©ã‚Œã ã‘è¿‘ã¥ã„ãŸã‹ã€ã‚’è©•ä¾¡ã™ã‚‹ï¼•æ®µéšã®ãƒ¬ãƒ™ãƒ«ã®åŸºæº–ã‚’å…¬é–‹ã€ç¾åœ¨ã®AIã¯ãƒ¬ãƒ™ãƒ«1ã§ã‚‚ã†ã™ãã€ŒReasonersã€ã¨å‘¼ã¶ç¬¬2ãƒ¬ãƒ™ãƒ«ã«åˆ°é”ã§ããã†ã¨ã®ã“ã¨ã€‚çŒ«ã§ã‚‚ååˆ†ãªæ°—ã‚‚ã™ã‚‹ãŒã€‚ã€‚åœ°å‘³ã§ã™ãŒæ–°åˆŠã€ŒPythonã§å­¦ã¶å®Ÿé¨“è¨ˆç”»æ³•å…¥é–€ã€ã€ã¿ãªã•ã‚“ã‚¿ã‚¤ãƒˆãƒ«ã¯æ§ãˆã‚ã§ã™ãŒã€ã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã‚„ã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®æœ¬ã§ã™ã‚ˆã€‚

- GraphRAG: How to Develop AI That Thinks Like a Librarian
	- https://x.com/IntuitMachine/status/1809903707535868260
	-  Graph RAG is an innovative approach that bridges the gap between retrieval-augmented generation (RAG) and query-focused summarization (QFS) methods, addressing the limitations of existing techniques in handling global questions about extensive document collections.
- Gemma2ã®tokenizerã«ã¾ã ä¸å…·åˆãŒã‚ã‚‹ã¨issuesãŒæ–°ã—ãç™»éŒ²ã•ã‚Œã¦ã„ãŸã®ã§è¦‹ã¦ã¿ãŸã‚‰ã¾ã•ã‹ã®AUTOMATIC1111
	- https://x.com/webbigdata/status/1810143355013390779
	- ç”»åƒç”ŸæˆAIã§æœ‰åãªãƒ„ãƒ¼ãƒ«stable-diffusion-webuiã®ä½œè€…ã®äººã§ã™ã€‚ãƒ„ãƒ¼ãƒ«åç§°ãŒä¸€èˆ¬çš„ã™ãã‚‹ã®ã§ã€AUTOã¨ã‹AUTOMATICã¨ã‹ä½œè€…åã§å‘¼ã‚“ã§ã‚‹äººãŒå¤šã„ãƒ„ãƒ¼ãƒ«ã§ã™
- BM25S: Orders of magnitude faster lexical search via eager sparse scoring
	- https://x.com/_reachsumit/status/1810157881536430178
	- Introduces a fast Python implementation of BM25 that pre-computes scores during indexing using sparse matrices to achieve significant speed improvements
- MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention
	- https://x.com/schroneko/status/1810212258003480757
	- https://hqjiang.com/minference.html
	- Microsoft ã® Long-Context LLM ã®æ¨è«–é«˜é€ŸåŒ–æ‰‹æ³•
	- Dynamic Sparse Attention ã‚’ç”¨ã„ã¦ç²¾åº¦ç¶­æŒï¼†é«˜é€ŸåŒ– 
	- A100 ä¸€å° x 1M tokens ã®å‡¦ç†ã§ 10 å€ 
	- æ—¢å­˜ã® LLM ã«ãã®ã¾ã¾é©ç”¨ã§ãã¦è¿½åŠ ã®å­¦ç¿’ã¯ä¸è¦ 
	- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚„ encoder-decoder ã«ã‚‚ä½¿ãˆã‚‹ã£ã½ã„
- ã€Interface 8æœˆå·ç‰¹é›†ã€Œç”ŸæˆAIã€ã¡ã‚‡ã£ã¨è¨˜äº‹ç´¹ä»‹ã€‘
	- https://x.com/If_CQ/status/1810282808587538468
	- ç¬¬4éƒ¨2ç« ã¯ã€Œãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è‡ªåˆ†ç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã§ã™ï¼ã€ŒLoRAã€ãŒå°ã‚³ã‚¹ãƒˆã§å­¦ç¿’ã§ãã‚‹ä»•çµ„ã¿ã‚’è§£èª¬ã—ï¼Œå®Ÿéš›ã«è©¦ã—ã¾ã™
- Google Cloud TPUs made available to Hugging Face users
	- https://huggingface.co/blog/tpu-inference-endpoints-spaces
	- > Google Cloud TPUs available on Spaces and Inference Endpoints > 3 options: 16GB to 128GB TPU memory (1x1, 2x2, 2x4 v5e TPU) > Use Spaces for ML demos or dev mode for easy training
-  RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs
	- https://arxiv.org/abs/2407.02485
	- Llama3-RankRAG from nvidia significantly outperforms GPT-4 models on 9 knowledge-intensive benchmarks
	- The secret is a novel instruction fine-tuning framework, named RankRAG
	- Llama3-RankRAG-8B and Llama3-RankRAG-70B outperforms Llama3-ChatQA-1.5-8B and Llama3-ChatQA-1.5-70B by a margin, respectively.
	- The problem with traditional RAG was that LLM typically utilize the top-k contexts from a retriever.
	- RankRAG instruction-tunes a single LLM for dual purposes: context ranking and answer generation in RAG. This unified approach allows the model to excel at both tasks simultaneously. The process incorporates a small fraction of ranking data (about 50k examples) alongside other task-specific datasets. Yields superior ranking performance compared to models trained on much larger ranking datasets.
-  Learning to (Learn at Test Time): RNNs with Expressive Hidden States
	- https://arxiv.org/abs/2407.04620
	- https://x.com/xiaolonw/status/1810387662060269668
	- we have been developing a new LLM architecture, with linear complexity and expressive hidden states, for long-context modeling. The following plots show our model trained from Books scale better (from 125M to 1.3B) than Mamba and Transformer, and our 1.3B model works better and better with longer context.
-  Intent-based Prompt Calibration: Enhancing Prompt Optimization
	- https://x.com/IntuitMachine/status/1810258617473356140
	- IPC works by iteratively refining prompts through the generation of synthetic, challenging boundary cases. This process eliminates the need for large pre-existing benchmarks, 
- MInference by Microsoft is released
	- https://github.com/microsoft/MInference
	- Milliontokens Inference achieves a 10x speedup for pre-filling and maintains accuracy with 1M tokens
	- https://huggingface.co/spaces/microsoft/MInference
- å…ˆæœˆã‹ã‚‰ã“ã‚Œã¯Q*ã‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã‚ˆã†ãªæ¢ç´¢æ‰‹æ³•+LLMã®è«–æ–‡ãŒãƒªãƒªãƒ¼ã‚¹ã•ã‚Œã¦ã„ã‚‹ã€‚
	- https://x.com/bioshok3/status/1810302795402408116
	- ä¾‹ãˆã°ä»¥ä¸‹ã¯ãƒ¢ãƒ³ãƒ†ã‚«ãƒ«ãƒ­æ³•ã§GPT-4ãƒ¬ãƒ™ãƒ«ä»˜è¿‘ã«æ•°å­¦é–¢é€£ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§llama3 8bã§åˆ°é”
	- Q*ã¨ã„ã†è«–æ–‡ã‚‚å‡ºã¦ã„ã‚‹
		- https://arxiv.org/abs/2406.14283
		- ã“ã‚Œã¯LLMã®å¤šæ®µæ¨è«–ã‚’ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã§ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã€A-starã‚µãƒ¼ãƒã§æ¢ç´¢ã™ã‚‹ã¨ã„ã†ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚å…·ä½“çš„ã«ã¯ã€ãƒãƒ«ã‚³ãƒ•æ±ºå®šéç¨‹ã®è¡Œå‹•ä¾¡å€¤é–¢æ•°ï¼ˆQå­¦ç¿’ã§ç”¨ã„ã‚‰ã‚Œã‚‹é–¢æ•°ï¼‰ã®æœ€å¤§å€¤ã‚’ã€A-starã‚µãƒ¼ãƒã®ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ã‚¯ã‚¹é–¢æ•°ã¨ã—ã¦æ¡ç”¨ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã€‚
-  Issue 17: Moshi Challenges OpenAI, Compare LLM pricing and better understand long context LLMs  -  July 7, 2024
	- https://www.philschmid.de/cloud-attention/issue-17
- 6-part video series on Property Graphs in LlamaIndex using mistralai, neo4j and ollama
	- https://x.com/llama_index/status/1810410943215710510
	- https://www.youtube.com/playlist?list=PLTZkGHtR085ZYstpcTFWqP27D-SPZe6EZ
		- Whatâ€™s a property graph and why is it useful?
		- How to build a property graph in LlamaIndex
		- Building graph data extractors and retrievers
		- Using Neo4j with LlamaIndex
		- Using Ollama with pre-defined schemas
		- Building custom retrievers
-  An Empirical Study of Mamba-based Language Models
	- https://x.com/rohanpaul_ai/status/1810340344158167066
	- 8B-parameter Mamba-2-Hybrid exceeds the 8B-parameter Transformer on all 12 standard tasks we evaluated
- æ—¥æœ¬æ°—è±¡å”ä¼šãŒäºˆæ¸¬èª¤å·®ã‚’æœ€å¤§40ï¼…æ”¹å–„ã€çµŒæ¸ˆåŠ¹æœ1800å„„å††ã®å•†å“éœ€è¦äºˆæ¸¬ã«é©ç”¨
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09502/?n_cid=nbpnxt_twbn
	- ç”ŸæˆAIã§å¤©æ°—å›³ã‚’ç”»åƒã¨ã—ã¦ã€œã¿ãŸã„ãªè©±ã§ã¯ãªãã€èª¬æ˜å¤‰æ•°ã«å…¥ã‚Œã‚‹æµ·åŸŸã‚’æ‹¡å¤§â†’LASSOå›å¸°ã§å¤šé‡å…±ç·šæ€§ã‚’æŠ¼ã•ãˆã¦ç²¾åº¦å‘ä¸Šã—ã¦ã‚‹ã®ã€L1æ­£å‰‡åŒ–æ¨ã—ã¨ã—ã¦ã¯ã‚°ãƒƒã¨æ¥ã‚‹ã€‚
- Introducing TerifAI (terrify) - the ai that steals your voice
	- https://x.com/amanmibra/status/1810498609613553741
	- It's an educational experience that shows why AI has become a catalyst to voice phishing
- PaintsUndo: A Base Model of Drawing Behaviors in Digital Paintings
	- https://lllyasviel.github.io/pages/paints_undo/
	- é™æ­¢ç”»åƒã‚’å…¥åŠ›ã—ã¦ã€ãã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã®æç”»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡ºåŠ›ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï½— lllyasvielã•ã‚“ã¾ãŸé¢ç™½ã„ã®è€ƒãˆã‚‹ã­ï¼
	- https://x.com/forasteran/status/1810595599173226582
- Alpaca + Gemma2 9b Unsloth 2x faster finetuning.ipynb
	- https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing
	- Fixed some bugs for DPO, saving to GGUF, Ollama auto modelfile creation, enabled RoPE scaling for Gemma-2, so >8192 context lengths now work & more!
-  Speed-accuracy trade-off for the diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport
	- https://arxiv.org/abs/2407.04495
	- æ± ç”°ã•ã‚“ã€å®‡ç”°ã•ã‚“ã€ä¼Šè—¤å…ˆç”Ÿã¨ã®å…±è‘—ã§ã™ã€‚éå¹³è¡¡ç†±åŠ›å­¦ã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®æ¥ç‚¹ã‚’ã¾ã¨ã‚ã‚‹ã¨å…±ã«ã€ãã®çŸ¥è¦‹ã«åŸºã¥ãã€ç”Ÿæˆå“è³ªã¨æ‹¡æ•£éç¨‹ã«ãŠã‘ã‚‹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ç”Ÿæˆç‡ã‚„æœ€é©è¼¸é€ã¨ã®é–¢ä¿‚ã€æ—¢å­˜æ‰‹æ³•ã®å¦¥å½“æ€§ã‚’ç¤ºã—ã¾ã—ãŸã€‚ä¼Šè—¤å…ˆç”Ÿã®ã‚¹ãƒ¬ãƒƒãƒ‰ã«çµŒç·¯ã‚„ã¾ã¨ã‚ãŒã‚ã‚Šã¾ã™ã€‚æ§˜ã€…ãªç™ºå±•ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã¨æ€ã„ã¾ã™
- TTT could model long sequences with linear time complexity. It's a drop-in upgrade for any sequence modeling operators like self-attention.
	- https://x.com/Jerry_XU_Jiarui/status/1810401509366181968
	- It has been super fun to work on TTT with the amazing team!
	- https://github.com/test-time-training/ttt-lm-jax
- (*AMERICAN*) Football Analytics with Python and R â€” Learning DataScience Through the Lens of Sports: 
	- https://www.amazon.com/gp/product/1492099627?&linkCode=sl1&tag=kirkdborne-20&linkId=114a75558fca86195c93513bf81a439d&language=en_US&ref_=as_li_ss_tl
- Sam Altman and Arianna Huffington launch AI health company
	- https://x.com/HealthcareAIGuy/status/1810480678473232769
	- The company is building an AI health coach to drive personalized behavior change to improve health outcomes.
- Ollama 0.2 can now
	- https://x.com/jmorgan/status/1810486878799560765
	- * Run different models side-by-side 
	- * Process multiple requests in parallel
-  RAGã®æ¬¡ã€ŒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã®å¨åŠ›ã€ã‚¢ãƒ³ã‚½ãƒ­ãƒ”ãƒƒã‚¯ç¤¾å“¡ãŒå›½å†…AWSãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åŠ›èª¬
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09497/
	- Voæ°ãŒãƒ—ãƒ¬ã‚¼ãƒ³ã§å¼·èª¿ã—ãŸã®ãŒã€2024å¹´5æœˆ31æ—¥ã«ã‚¢ãƒ³ã‚½ãƒ­ãƒ”ãƒƒã‚¯ãŒç™ºè¡¨ã—ãŸã‚µãƒ¼ãƒ“ã‚¹ã€ŒTool Useã€ã®æ´»ç”¨æ–¹æ³•ã ã€‚Tool Useã¯ã€AIãŒäººã®ä»£ã‚ã‚Šã¨ãªã£ã¦è‡ªå¾‹çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã€ŒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚‹ã€‚
-  Language-Guided World Models: A Model-Based Approach to AI Control
	- https://arxiv.org/abs/2402.01695
	- Our paper is perhaps the first to demonstrate compositional generalization with concepts that involve interactions among multiple entities.
- GPT-4o Capabilities
	- https://x.com/InterestingSTEM/status/1810387007312429094
- ã“ã‚Œãªï¼æ—¥æœ¬ã¯æ¤œç´¢æŠ€è¡“ã«ã¤ã„ã¦ï¼Œè‘—ä½œæ¨©æ³•ã¨ã¯é–¢ä¿‚ãªãï¼Œæ­£ã€…å ‚ã€…ã¨å®Œå…¨ã«æŠ€è¡“åŠ›ã§Googleã«è² ã‘ãŸã®
	- https://x.com/yutakashino/status/1810190400487121282
	- ï¼å›½å†…ã§ã¯å½“åˆã€æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ãŒãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã—ã€ä¸€æ™‚çš„ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ä¿å­˜ã™ã‚‹è¡Œç‚ºãŒã€Œè‘—ä½œæ¨©æ³•é•åã§ã¯ãªã„ã‹ã¨ã®è­°è«–ãŒã‚ã£ãŸã€ã¨æ¾å°¾æ•™æˆã¯æŒ¯ã‚Šè¿”ã‚‹ã€‚ 
	- â†‘ æ¾å°¾å…ˆç”Ÿå˜˜ã¯ã‚ˆããªã„ æ–‡åŒ–åºè³‡æ–™èª­ã‚€ã¨ãã‚“ãªè­°è«–èµ·ã“ã£ã¦ãªã„
- Today Sam Altman and I published a piece in TIME sharing our vision for how AI-driven personalized behavior change can transform healthcare and announcing the launch of Thrive AI Health
	- https://x.com/ariannahuff/status/1810273407944040897
	- https://time.com/6994739/ai-behavior-change-health-care/
	- With AI-driven personalized behavior change, we have the chance to finally reverse the trend lines on chronic diseases like diabetes and cardiovascular diseases, which are directly related to daily behaviors but not distributed equally across demographics.
- æ–°ã‚µãƒ¼ãƒ“ã‚¹ã€ŒDataplex Catalogã€ãŒå…¬é–‹
	- https://x.com/y_sugi_it/status/1810446290330976501
	- Google Cloudä¸Šã®å„ç¨®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€‚å¾“æ¥ã®ã€ŒData Catalogã€ã‚ˆã‚ŠDataplexã¨ã®çµ±åˆãŒå¼·åŒ–ã€‚Aspectã¨ã„ã†è¨­å®šå€¤ã«ã‚ˆã‚Šãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä»˜ä¸ãƒ»ç®¡ç†ã€‚é †æ¬¡ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®ãŸã‚å¾ã€…ã«ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹
-  Mixture of A Million Experts
	- https://arxiv.org/abs/2407.04153
	- MoEã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã‚’å°ã•ãæ•°ã‚’å¢—ã‚„ã™ã»ã©æ€§èƒ½ãŒæ”¹å–„ã•ã‚Œã‚‹ã€‚PEERã¯å„ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒéš ã‚Œå±¤ã«1ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã—ã‹æŒãŸãªã„ã»ã©å°ã•ãã—ã€ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæ•°ã‚’100ä¸‡ã¾ã§å¢—ã‚„ã™ã€‚ã‚­ãƒ¼ã‚’éƒ¨åˆ†ã‚­ãƒ¼ã®ç©ã®å½¢ã§è¡¨ã—TopKã‚’åŠ¹ç‡çš„ã«æ¢ç´¢ã§ãã‚‹ã‚ˆã†ã«ã—ã€å¾“æ¥MoEã‚ˆã‚Šã•ã‚‰ã«æ€§èƒ½ã‚’æ”¹å–„ by å²¡é‡åŸã•ã‚“
-  MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases
	- https://arxiv.org/abs/2402.14905
	- MobileLLMã¯125/350Mã®ãƒ¢ãƒ‡ãƒ«ã€‚æºå¸¯å‘ã‘ã§ã¯æ€§èƒ½ã€ãƒãƒƒãƒ†ãƒªãƒ¼æ¶ˆè²»é‡ã®è¦³ç‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å°ã•ãã™ã‚‹ã®ãŒé‡è¦ã€‚1Bä»¥ä¸‹ãŒæœ‰åŠ¹ 1) å¹…ã‚ˆã‚Šæ·±ã•ãŒé‡è¦ã€‚å¾“æ¥ã®12å±¤ã‚ˆã‚Š30~42å±¤ã¾ã§å¢—ã‚„ã™ 2) åŸ‹ã‚è¾¼ã¿å±¤ã¯å…±æœ‰ 3) ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…±æœ‰ã—ãŸå±¤ã‚’2å›ãšã¤ç¹°ã‚Šè¿”ã™ã€‚ãƒ¡ãƒ¢ãƒªè»¢é€é‡ã‚‚æŠ‘ãˆã‚‰ã‚Œã‚‹ã€‚by å²¡é‡åŸã•ã‚“
- Claudeã®ãƒ©ã‚¤ãƒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ã€ŒArtifactsã€ã«URLå…¬é–‹æ©Ÿèƒ½ãŒæ­è¼‰
	- https://x.com/masahirochaen/status/1810722296501596237
- ç”ŸæˆAIã«ã‚ˆã‚‹MOFã®é€†è¨­è¨ˆã®è«–æ–‡ã€‚by æ¨ªå±±ã•ã‚“
	- https://chemrxiv.org/engage/chemrxiv/article-details/668775805101a2ffa871a56c
	- 3Dãƒ¢ãƒ‡ãƒªãƒ³ã‚°æŠ€è¡“ã‚’å¿œç”¨ã—ç¬¦å·ä»˜ãè·é›¢é–¢æ•°ã‚’å…¥åŠ›è¡¨ç¾ã¨ã—ãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã€ç‰©æ€§ã‚„ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ¡ä»¶ã‚’æº€ãŸã™MOFæ§‹é€ ã‚’æ­£ç¢ºã«ç”Ÿæˆã§ããŸãã†ã§ã™ã€‚
-  GraphRAGã‚·ã‚¹ãƒ†ãƒ ã®ä½¿ã„æ–¹ï¼šåˆå¿ƒè€…å‘ã‘å®Œå…¨ã‚¬ã‚¤ãƒ‰
	- https://hamaruki.com/graphrag-beginners-guide/
- æœ‰è­˜è€…å–æã®ç”³ã—è¾¼ã¿ãŒã€ç›®æ’ƒè€…å–æã¨åŒã˜æ‰‹æ³•ã«ãªã£ã¦ããŸã¨ã‹ã€ä¸–ã‚‚æœ«ã€‚
	- https://x.com/HiromitsuTakagi/status/1810550259866910838
	- ãƒ†ãƒ¬æœã€ã²ã‚ã¿ã¡ã‚…å…ˆç”Ÿã«å–æDMé€ã‚‹ã€‚ã€‚ã€‚
- Claudeã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã¨ä½ç½®ä»˜ã‘ã€çŒ›çƒˆãªé€Ÿåº¦ã§ï¼‘ä¸–ç´€åˆ†ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®æ­´å²ã‚’ãŠãã‚‰ã1å¹´ã§ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã‚ˆã†ã¨è€ƒãˆã¦ã„ã‚‹ã€‚
	- https://x.com/ai_syacho/status/1810835403940995383
-  Evaluate prompts in the developer console
	- https://www.anthropic.com/news/evaluate-prompts
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®ãŸã‚ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«
	- https://zenn.dev/tsurubee/articles/00446669b6c83a
	- ã¾ãšã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦å–ã‚Šæ‰±ã†Propmtingã¯ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ãªãäº‹å‰å­¦ç¿’ã—ãŸLLMã®èƒ½åŠ›ã‚’æ´»ç”¨ã§ãã‚‹ã€‚
	- å˜ç´”ãªå­£ç¯€çš„ãªå‘¨æœŸã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŒã¤ã‚ˆã†ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã§ã¯Propmtingã«ã‚ˆã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æœ‰åŠ¹ã§ã‚ã‚‹ãŒã€ã‚ˆã‚Šè¤‡é›‘ãªæ™‚ç³»åˆ—æ€§ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ã§ã¯ååˆ†ãªæ€§èƒ½ãŒæœŸå¾…ã§ããªã„ã‹ã‚‚ã—ã‚Œãªã„
	- ãã®ãŸã‚ã€ååˆ†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã§ãã‚‹å ´åˆã¯ã€Quantizationã¾ãŸã¯Aligningãƒ™ãƒ¼ã‚¹ã®æ–¹æ³•ãŒã‚ˆã‚Šæœ‰åŠ¹ã«ãªã‚‹ã ã‚ã†
	- Aligningã¯ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨è¨€èªç©ºé–“ã®ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã‚’æ•´åˆã•ã›ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã‚ã‚‹ã®ã§ã€æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã¨è¨€èªãŒãƒšã‚¢ã¨ãªã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸã‚¿ã‚¹ã‚¯ã®æœ‰åŠ›ãªé¸æŠè‚¢ã«ãªã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚ä¾‹ãˆã°ã€å¿ƒé›»å›³ã‚·ã‚°ãƒŠãƒ«ã¨ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã®äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¯¾è±¡è€…ã®è¨ºæ–­ã‚«ãƒ†ã‚´ãƒªã‚’åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’è§£ã„ãŸETPã‚„ã€å¯¾è©±ä¸­ã®è„³æ³¢ã¨è‡ªç„¶è¨€èªã®äºŒã¤ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ„Ÿæƒ…äºˆæ¸¬ã‚„é–¢ä¿‚æ¤œå‡ºã®ã‚¿ã‚¹ã‚¯ã‚’è§£ã„ãŸMTAMãŒãã®ä¾‹ã§ã‚ã‚‹ã€‚
- å¤©æ°—äºˆå ±ã§LassoãŒä½¿ã‚ã‚ŒãŸã‚“ã§ã™ã‹ï¼Ÿ æœ¬å½“ãªã‚‰ã‚„ã‚„ã³ã£ãã‚Š
	- https://x.com/Idesan/status/1810903568100077906
- å¤šé‡å…±ç·šæ€§ã®ã‚ã‚‹ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦ã¯ã€Lassoã‚’ã‚„ã‚‹ã¨æ±åŒ–æ€§èƒ½ã¯ä¸ŠãŒã£ã¦ã‚‚å¿…ãšã—ã‚‚ã€Œæœ¬æ¥å‰Šã‚‰ã‚Œã‚‹ã¹ãå¤‰æ•°ã€ãŒå‰Šã‚‰ã‚Œã‚‹ã‚ã‘ã§ã¯ãªã„ã¨ã•ã‚Œã¦ã„ã¦ã€
	- https://x.com/TJO_datasci/status/1810852746406604931
- Artifacts made with Claude can now be published and shared.
	- https://x.com/AnthropicAI/status/1810698780263563325
- Open source AI model for semiconductor design.
	- https://x.com/pentagoniac/status/1810768232401473680
	- Industryâ€™s first-ever open-source Semiconductor domain-specific model â€œSemiKongâ€, being announced atã€€SEMICONWest by me (!)
- gemini 1.5 pro ã® jsonãƒ¢ãƒ¼ãƒ‰ã€ã‚ã¡ã‚ƒä¾¿åˆ©ã€‚jsonã§ã‚ã‚‹ã“ã¨ã ã‘ã§ãªãã€ä»»æ„ã®ã‚¹ã‚­ãƒ¼ãƒã‚’æŒ‡å®šã§ãã‚‹ã€‚
	- https://developers.googleblog.com/en/gemini-15-pro-now-available-in-180-countries-with-native-audio-understanding-system-instructions-json-mode-and-more/
- æ‰¹åˆ¤å®¶ã‚²ã‚¤ãƒªãƒ¼ãƒãƒ¼ã‚«ã‚¹æ°ã¯ã€2016å¹´ã«WSCã§é™ç•Œèª¬ã‚’ä¸»å¼µã—ãŸãŒå¾Œã«ç ”ç©¶è€…ãŸã¡ã«ã‚ˆã£ã¦çªç ´ã•ã‚Œã€2018å¹´ã«æ·±å±¤å­¦ç¿’ã®é™ç•Œèª¬ã‚’ä¸»å¼µã—ã¦AIã®å†¬æ™‚ä»£ã‚’äºˆæƒ³ã—ãŸãŒå¤–ã‚Œã¦ã€2022å¹´ã«ã¯æ·±å±¤å­¦ç¿’ã¯å£ã«ã¶ã¤ã‹ã£ã¦ã„ã‚‹ã¨è¨€ã£ã¦ã‹ã‚‰ä»Šå›ã®ç”ŸæˆAIãƒ–ãƒ¼ãƒ ãŒãã¦GPT-4ãŒç™»å ´ã€‚ãã®å¾Œã‚‚ç™ºå±•ãŒç¶™ç¶šä¸­
	- https://x.com/jaguring1/status/1810993416991559893
- a16zãŒGPU(H100)2ä¸‡å€‹è²·ã„å ã‚ã¦å®‰ãæŠ•è³‡å…ˆã«ä½¿ã‚ã›ã¦ã‚‹ã¨ã‹ã€‚VCã®åŸŸã‚’è¶…ãˆãŸãƒ‘ãƒ¯ãƒ¼ãƒ—ãƒ¬ã‚¤ã‚„
	- https://x.com/kubotamas/status/1810985069131223355
- Bedrockã«ãƒãƒãƒ¼ã‚¸ãƒ‰Difyæ¥ãŸã‚„ã‚“ã“ã‚Œ
	- https://x.com/minorun365/status/1811041517479547097
- Notionã¯Notionã‚’ã©ã†ä½¿ã£ã¦ã„ã‚‹ã‹
	- https://notion.notion.site/Notion-Notion-15c4497a18e54de7a7ca696bc8fe688a#65c847c6692f45898edc17912667d4db
- Last week we launched llama-agents, a brand new multi-agent deployment framework,
	- https://x.com/llama_index/status/1811147950388916420
	- @MervinPraison has a great walkthrough of how to use lllama-agents on YouTube, 
	- https://www.youtube.com/watch?v=nEQCpSd5mx8
- Microsoft ã®GraphRAGãŒgemma2:9bã§å‹•ããã†ãªæ„Ÿã˜ï¼ï¼
	- https://x.com/hAru_mAki_ch/status/1811039029305233825
- ã‚ã¾ã‚Šè©±é¡Œã«ãªã£ã¦ã„ãªã„ãŒã€Claudeã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è©•ä¾¡æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚ŒãŸã®ãŒå€‹äººçš„ã«è¶…åŠ©ã‹ã‚‹ã€‚
	- https://x.com/masahirochaen/status/1811311003084394517
	- ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚è‡ªå‹•ã§ç”Ÿæˆå¯èƒ½ã§ã€ç”Ÿæˆçµæœã®è©•ä¾¡ç‚¹ã®å…¥åŠ›ã‚‚å¯èƒ½ã€‚
-  æœ€é©è¼¸é€å…¥é–€
	- https://speakerdeck.com/joisino/zui-shi-shu-song-ru-men
	- é©è¼¸é€ã¨KLãƒ€ã‚¤ãƒãƒ¼ã‚¸ã‚§ãƒ³ã‚¹ã®é•ã„ã®èª¬æ˜ãŒåˆ†ã‹ã‚Šã‚„ã™ã‹ã£ãŸã§ã™ï¼
- DifySandbox ãŒã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã«ãªã‚Šã¾ã—ãŸï¼
	- https://x.com/DifyJapan/status/1811260209438101754
	- DifySandbox ã¯ã€Dify ã«ãŠã‘ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ä¸­æ ¸ã®ä¸€ã¤ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ›¸ã„ãŸã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œç’°å¢ƒã¨ã—ã¦æ©Ÿèƒ½ã—ã€æ‚ªæ„ã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’ç¢ºä¿ã—ã¾ã™
- Magpieã®æ‰‹æ³•ã‚’ç”¨ã„ã¦æ§˜ã€…ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ä½œæˆã—ãŸæ—¥æœ¬èª29647ä»¶ã€è‹±èª39560ä»¶ã€åˆè¨ˆç´„69207ä»¶ã®ã‚³ãƒ¼ãƒ‰SFTç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- https://x.com/Aratako_LM/status/1811418924472492470
	- https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k
- We made a step-by-step tutorial on how to finetune Llama-3 with Google Colab & deploy it to Ollama
	- https://x.com/UnslothAI/status/1811447913962438994
	- https://docs.unsloth.ai/tutorials/how-to-finetune-llama-3-and-export-to-ollama
	- https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing
- çµ±è¨ˆçš„ãƒªãƒ†ãƒ©ã‚·ãƒ¼ã®å‹•å‘ã¨èª²é¡Œâ€•æ¦‚å¿µã¨å­¦ç¿’æŒ‡å°ã«ç€ç›®ã—ã¦â€•
	- https://www.jstage.jst.go.jp/article/jssej/48/2/48_133/_article/-char/ja/
	- ã“ã‚Œã¾ã§ã®å®Ÿè·µç ”ç©¶ã‚’æ¦‚è¦³ã™ã‚‹ã¨ï¼Œå­¦ç¿’æŒ‡å°ã®æ–¹æ³•ã®ç‰¹å¾´ã¨ã—ã¦ä»¥ä¸‹ 5 ç‚¹ãŒæŒ™ã’ã‚‰ã‚Œã‚‹
	- 1 ç‚¹ç›®ã¯ï¼Œã€Œå®Ÿéš›ã«ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰ç™ºä¿¡ã•ã‚ŒãŸçµ±è¨ˆæƒ…å ±ã‚’é¡Œæã®ä¸­å¿ƒã¨ã—ã¦ã„ã‚‹ã“ã¨ã€
	- 2 ç‚¹ç›®ã¯ï¼Œã€Œçµ±è¨ˆæƒ…å ±ã®å†…å®¹ã«å¯¾ã—ã¦å•ã„ã‚’æŒã¤ã‚ˆã†ã«ï¼Œå•ã„ã®ä¾‹ã‚’ç¤ºã™ã“ã¨ã€
	- 3 ç‚¹ç›®ã¯ï¼Œã€Œçµ±è¨ˆæƒ…å ±ã®å†…å®¹ã‚’å­¦ç¿’è€…åŒå£«ã§è­°è«–ã™ã‚‹æ´»å‹•ã‚’å–ã‚Šå…¥ã‚Œã‚‹ã“ã¨ã€
	- 4 ç‚¹ç›®ã¯ï¼Œã€ŒçŸ¥è­˜ã®ç¿’å¾—ã‚„æ´»ç”¨ã‚’æ„å›³ã—ãŸå€‹äººã®æ´»å‹•ãŒå±•é–‹ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€
	- 5 ç‚¹ç›®ã¯ï¼Œã€Œçµ±è¨ˆæƒ…å ±ã‚’é©åˆ‡ã«è§£é‡ˆã™ã‚‹ãŸã‚ã®èª­ã¿æ–¹ã®ç¿’å¾—ã‚’æ„å›³ã—ãŸå€‹äººã®æ´»å‹•ãŒå±•é–‹ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€
- Temporal distances (expected number of time steps between states) in stochastic MDPs in general lack metric structure.
	- https://x.com/svlevine/status/1811253559603888439
	- we propose this metric. Intuitively, the difference between state s and goal g is given by log of probability ratio between reaching g from g (self-loop) and reaching g from s.
	- https://arxiv.org/abs/2406.17098v1
- ã€Œç¾æ™‚ç‚¹ã§ã®æ±ç”¨AIã¯çŒ«ç¨‹åº¦ã®IQã—ã‹ãªã„ã€ã¨Google DeepMindã®ãƒ‡ãƒŸã‚¹ãƒ»ãƒã‚µãƒ“ã‚¹CEOãŒä¸»å¼µ
	- https://x.com/gigazine/status/1811143437975970124
	- è‡ªèº«ã®ç ”ç©¶ã¯AIã§ã¯ãªãAGI(æ±ç”¨äººå·¥çŸ¥èƒ½)ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã“ã¨ã‚’å¼·èª¿ã€‚ãã®ä¸Šã§ã€ãƒã‚µãƒ“ã‚¹CEOã¯ã€Œç¾ä»£ã®AIã¯äººé–“ã¨è¦‹é–“é•ã†ã»ã©ã®æ–‡ç« ã‚’æ›¸ã„ãŸã‚Šã€çµµã‚’æã„ãŸã‚Šã€éŸ³æ¥½ã‚’ä½œæ›²ã—ãŸã‚Šã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€AGIã¨ã—ã¦ã¯æ™®é€šã®é£¼ã„çŒ«ã®æ–¹ãŒã¯ã‚‹ã‹ã«é«˜ã„çŸ¥èƒ½ã‚’ã‚‚ã£ã¦ã„ã¾ã™ã€ã¨è¿°ã¹ã¾ã—ãŸã€‚
- OpenAIã¯ç«æ›œå…¨ä½“ä¼šè­°ã§AIé€²æ—ã‚’ãƒ¬ãƒ™ãƒ«åˆ†ã‘ã€‚ãƒ¬ãƒ™ãƒ«1ãŒç¾åœ¨ã§ã‚‚ã†ã™ãã€ŒReasonersã€ã¨å‘¼ã¶ç¬¬2ãƒ¬ãƒ™ãƒ«ã«ã‚‚ã†ã™ãåˆ°é”ã™ã‚‹ã¨ã“ã‚ã ã¨èªã£ãŸã¨åºƒå ±æ‹…å½“è€…ã¯è¿°ã¹ã¦ã„ã‚‹ã€‚
	- https://x.com/StockMKTNewz/status/1811488448001294720
	- Reasonersã¨ã¯ã€ãƒ„ãƒ¼ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„åšå£«ãƒ¬ãƒ™ãƒ«ã®æ•™è‚²ã‚’å—ã‘ãŸäººé–“ã¨åŒæ§˜ã«åŸºæœ¬çš„ãªå•é¡Œè§£æ±ºã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã§ãã‚‹ã‚·ã‚¹ãƒ†ãƒ 
- ãƒ‘ãƒ¼ãƒ—ãƒ¬ã®å…¬å¼æ—¥æœ¬ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§ã™ï¼æ—¥æœ¬ã®çš†ã•ã‚“ã¨ç¹‹ãŒã‚‹ã“ã¨ã‚’æ¥½ã—ã¿ã«ã—ã¦ã„ã¾ã™ã€‚
	- https://x.com/perplexity_jp/status/1811555477588738436
- OpenAIãŒã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ãŒäººé–“ã®çŸ¥èƒ½ã«ã©ã‚Œã ã‘è¿‘ã¥ã„ãŸã‹ã€ã‚’è©•ä¾¡ã™ã‚‹åŸºæº–ã‚’ä½œæˆ
	- https://gigazine.net/news/20240712-openai-super-intelligent-ai-scale/?utm_source=x&utm_medium=sns&utm_campaign=x_post&utm_content=20240712-openai-super-intelligent-ai-scale
	- OpenAIã¯è¨˜äº‹ä½œæˆæ™‚ç‚¹ã§ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ãƒ¬ãƒ™ãƒ«1ã§ã‚ã‚Šã€ãƒ¬ãƒ™ãƒ«2ã«è¿‘ã¥ã„ã¦ã„ã‚‹ã¨ã—ã¦ã„ã¾ã™ã€‚OpenAIã«ã‚ˆã‚Œã°ã€
	- ãƒ¬ãƒ™ãƒ«2ã¯åšå£«ãƒ¬ãƒ™ãƒ«ã®æ•™è‚²ã‚’å—ã‘ãŸäººé–“ã¨åŒç­‰ã®åŸºæœ¬çš„ãªå•é¡Œè§£æ±ºèƒ½åŠ›ã‚’æŒã¤ã‚·ã‚¹ãƒ†ãƒ ã¨è©•ä¾¡ã•ã‚Œã‚‹ãã†ã§ã™ã€‚ã¾ãŸã€
	- ãƒ¬ãƒ™ãƒ«3ã¯ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»£ã‚ã£ã¦è¡Œå‹•ã§ãã‚‹ã€ã€
	- ãƒ¬ãƒ™ãƒ«4ã¯ã€Œæ–°ã—ã„ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿã¿å‡ºã›ã‚‹ã€ã€
	- æœ€é«˜æ®µéšã®ãƒ¬ãƒ™ãƒ«5ã¯ã€Œçµ„ç¹”å…¨ä½“ã®ä»•äº‹ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã€ãƒ¬ãƒ™ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹ãã†ã§ã™ã€‚
- Mixture of Agents on Groq
	- https://x.com/KapadiaSoami/status/1811657156082712605
	- Introducing a fully configurable, Mixture-of-Agents framework powered by GroqInc using LangChainAI
- Pythonã§å­¦ã¶å®Ÿé¨“è¨ˆç”»æ³•å…¥é–€
	- https://x.com/mimikousi/status/1812071977441513954
	- æ›¸ç±åã‹ã‚‰ã¯æƒ³åƒã§ããªã„ãŒã€ã€Œã‚¬ã‚¦ã‚¹éç¨‹å›å¸°ã€ã®è§£èª¬ã‚‚ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚‚æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ã€‚ å‚è€ƒã«ã—ãªãŒã‚‰ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã¿ãŸã‚‰ã€ã‹ãªã‚Šç°¡å˜ã«å®Ÿè£…ã§ããŸã€‚ å–ã‚Šæ€¥ãã€GtiHubã«ã‚¢ãƒƒãƒ—ã—ãŸã‘ã©ã€æ™‚é–“ãŒã§ããŸã‚‰ãƒ–ãƒ­ã‚°ã§è§£èª¬è¨˜äº‹ã‚’æ›¸ããŸã„ãªã€‚
	- https://github.com/mimikousi/regression_model/blob/main/gpr_regression.ipynb
- ã€æœ€å°¤æ¨å®šã«ã‚ˆã‚‹å›å¸°ç›´ç·š vs ãƒ™ã‚¤ã‚ºæ¨è«–ã«ã‚ˆã‚‹å›å¸°ç›´ç·šã€‘
	- https://x.com/DS_school_1/status/1812280249763455444
	- æœ€å°¤æ¨å®šæ³•ã¯æœ€ã‚‚ç¢ºã‹ã‚‰ã—ã„ï¼‘ã¤ã®å›å¸°ç›´ç·šã‚’ç®—å‡ºã§ãã€ãƒ™ã‚¤ã‚ºæ¨è«–ã¯ä¿¡é ¼ã§ãã‚‹å¹…ã‚’æŒã£ãŸå›å¸°ç›´ç·šã‚’ç®—å‡ºã§ãã‚‹ç‰¹å¾´ãŒã‚ã‚‹ã­ğŸ‘é¢ç™½ã„ï¼ï¼
- `statsmodels`ã¨`sklearn`ã§ã®ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®æŒ™å‹•ã®é•ã„ã«ã¤ã„ã¦
	- https://zenn.dev/0_u0/articles/6a43ff43b02399
	- `sklearn.linear_model.LogisticRegression`ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æ­£å‰‡åŒ–(L2=1)ãŒã¤ã„ã¦ã„ã‚‹
	- `statsmodels.api.Logit`ã¯æ­£å‰‡åŒ–ãŒã¤ã„ã¦ã„ãªã„
	- `sklearn`ã¯æ©Ÿæ¢°å­¦ç¿’ã®é ˜åŸŸã§åºƒãä½¿ã‚ã‚Œã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®1ã¤ã§ã‚ã‚‹ã‹ã‚‰ã€çµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’ã“ã‚Œã‚’ä½¿ã£ã¦å®Ÿæ–½ã™ã‚‹å ´é¢ã‚‚å¤šã„ã ã‚ã†ãŒã€æ­£å‰‡åŒ–é …ã«ã¤ã„ã¦ã¯æ°—ã‚’ã¤ã‘ãŸæ–¹ãŒè‰¯ã„ã€‚
- Statistics for Mathematicians by Victor M. Panaretos
	- https://x.com/probnstat/status/1811833201612014073
	- Presents a rigorous yet elementary introduction to the main concepts and methods of statistical inference
	- Targets students of mathematics taking their first course in statistics
 

	- 


## 24/7/8

å…ˆé€±ãã‚‰æ˜Ÿã®ã‚ˆã†ã«ç™»å ´ã—ãŸgemma-2ã®è©•ä¾¡ã€DeepMindè‡ªèº«ã«ã‚ˆã‚‹gemma-2è«–æ–‡ã§ã¯ã€2å€ä»¥ä¸Šå¤§ããªã‚µã‚¤ã‚ºã®Llama 3ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã¨GPT-4oã«ç›¸å½“ã™ã‚‹å®‰å…¨æ€§ã¨ã„ã£ã¦ã„ã‚‹ãŒã€ ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã€çŸ¥è­˜è’¸ç•™ã€ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ”ãƒ³ã‚°ã«ã‚ˆã‚‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®‰å®šæ€§ã€WARPã¨å‘¼ã°ã‚Œã‚‹æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ³ã‚°æŠ€è¡“ãªã©ãŒã¦ã‚“ã“ç››ã‚Šã®æ¨¡æ§˜ã€9Bã¨27Bã§ã¯ä½œã‚Šæ–¹ã‚‚å¤‰ãˆã¦ããŸã€‚gemma-2-27b-itã®Elyzaãƒ™ãƒ³ãƒã®çµæœã‚‚ã„ã„ã—ã€gemma-2-27b-itã®æ—¥æœ¬èªimatrixé‡å­åŒ–ggufã‚‚ä¸ŠãŒã£ã¦ã‚‹ã€‚SPPOã£ã¦ã®ã¯ã€LLMã®æœ€é©åŒ–ã‚’äºŒäººå¯¾æˆ¦å‹ã®å®šæ•°å’Œã‚²ãƒ¼ãƒ ã¨ã—ã¦å®šå¼åŒ–ã—ã€ãã®å‡è¡¡ç‚¹ã‚’è¿‘ä¼¼çš„ã«æ±‚ã‚ã‚‹è‡ªå·±å¯¾æˆ¦å‹ã®é¸å¥½æœ€é©åŒ–æ‰‹æ³•ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§äººé–“ã®é¸å¥½ã‚’æ­£ç¢ºã«åæ˜ ã™ã‚‹å­¦ç¿’ã¨æœ€é©åŒ–æ‰‹æ³•ã ãã†ã§ã€ã¤ã¾ã‚Šalignmentã¨ã‚‚ç›¸æ€§ãŒè‰¯ã„ãã†ãªã‚“ã§ã™ãŒã€Gemma-2ã«SPPOã‚’é©ç”¨ã—ãŸGemma2-9B-it-SPPO-Iter3ãªã‚“ã‹ãŒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§é«˜å¾—ç‚¹ã‚’ãƒãƒ¼ã‚¯ã—ãŸã¨ã®å ±å‘Šã‚‚ã‚ã‚Šã€æ€§èƒ½ã«ã‚‚åŠ¹ãã¿ãŸã„ã ã€‚gemma-2ã€æ–°ä¸–ä»£ã®LLMã®ãŠæ‰‹æœ¬ã¿ãŸã„ãªæ§‹æˆã§ã€æ¬¡ã®Geminiã¸ã®ã‚¤ãƒ³ãƒˆãƒ­ã¨ã—ã¦ã¯æº€ç‚¹ã€‚ã¾ã‚ã€ã¨ã„ã£ã¦ã‚‚ã€ã†ã¿ã‚†ãã•ã‚“ã®å ±å‘Šã®ã‚ˆã†ã«ã€Sonnet3.5ã‚’Shaberi3ãƒ™ãƒ³ãƒã§è©•ä¾¡ã—ãŸã‚‰8.39ã¨ã„ã†ã‚ˆã†ã«ã€ä¾ç„¶æ¨ªç¶±ã¯Sonnet3.5ã‹ã€‚ä»Šé€±ã‚‚Claudeã®Artifactsæ©Ÿèƒ½ã§ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆä½œã£ãŸä¾‹ãŒå ±å‘Šã•ã‚Œã€ã‚ãã‚ããŒæ­¢ã¾ã‚‰ãªã„ã€‚Artifactsã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚è¦‹ã¤ã‹ã‚Šã€function callingã®ãŠæ‰‹æœ¬ã®ã‚ˆã†ã ã¨ã„ã†ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹Claude ã® "Generate a prompt" ã«ä»£è¡¨ã•ã‚Œã‚‹ã‚ˆã†ã«ã€LLMã‚’dogfoodã¨ã—ã¦è‡ªã‚‰ä½¿ã„ã“ãªã—ã€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ é€Ÿã•ã›ã¦ã„ã‚‹ã®ã¯ã€Anthropicã¨OpenAIã§ã€ãã®ä»–Googleãªã©ãŒé€²ã‚ã‚‹LLMã®é€²åŒ–ã¯ã€ç€å®Ÿãªã‚“ã ã‘ã©ã€æƒ³åƒå¯èƒ½ãªç¯„å›²ã‹ãªã‚ã€‚Llama3-Swallow-8Bã¨ã‹ã€CALM3-22B-Chatã¨ã‹ã€æ—¥æœ¬ã®LLMã‚‚å¥é—˜ã—ã¦ã¾ã™ãŒã€ã¡ã‚‡ã£ã¨å³ã—ã„ã€‚Runwayã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å‹•ç”»ã€ç”»åƒã‹ã‚‰å‹•ç”»ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹Gen-3ãŒè©±é¡Œã«ãªã£ãŸã€äººã®é¡”ã£ã¦å‹•ãã¨ä¸è‡ªç„¶ã•ãŒã‚ã‹ã‚‹ã¯ãšãªã®ã«ã€Gen-3ã®ç”Ÿæˆã™ã‚‹å‹•ç”»ã§ã¯ã€ã‚‚ã¯ã‚„è­˜åˆ¥ä¸èƒ½ã€ä¸æ°—å‘³ã®å£ã‚’è¶ŠãˆãŸã‹ã€‚ãƒ¡ã‚¿ã‚‚äººçŸ¥ã‚Œãšã€ŒMeta 3D Genã€ã‚’ç™ºè¡¨ã€è©•ä¾¡ã‚’å¾…ã¨ã†ã€‚éå–¶åˆ©å›£ä½“KyutaiãŒçªç„¶ç™ºè¡¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ¼ãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã€ŒMoshiã€ã€è‡ªç„¶ãªå¯¾è©±ãŒgpt-4oã¨ãã‚“è‰²ãªã„ã‚“ã ã‘ã©ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ã•ã‚Œã‚‹ã¨ã€è©æ¬ºLLMãŒèª°ã§ã‚‚ä½œã‚Œã¡ã‚ƒã†ã€ã¡ã‚‡ã£ã¨ä¸å®‰ã ã€‚RAGé–¢é€£ã§ã¯ã€å…ˆé€±è©±é¡Œã¨ãªã£ãŸMicrosoftã®GraphRAGè«–æ–‡ã€ç™ºè¡¨ã—ãŸã°ã‹ã‚Šãªã®ã«å®Ÿè£…ãŒgithubã«å…¬é–‹ã€ã“ã£ã¡ã‚‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¦‹æœ¬ã®ã‚ˆã†ãªå†…å®¹ã€ollama/gemma-2ã§ã‚‚å‹•ãæ¨¡æ§˜ã€‚RAG surveyè«–æ–‡ã€"Naive RAG", "Advanced RAG", "Modular RAG"ã¨ã„ã†æ­´å²çš„ãªè¦–ç‚¹ã‹ã‚‰ã€ç´°ã‹ã„æŠ€è¡“ã¾ã§å¾¹åº•çš„ã«ç¶²ç¾…ã€ã„ã‚„ã“ã‚“ãªæ‰‹æ³•ãŒã‚ã‚‹ã®ã‹ã¨å¤§å¤‰å‚è€ƒã«ãªã‚‹ã€‚TJOã•ã‚“ã‚‚çµ¶è³›ã€ã¨ã„ã†ã‹å¾Œå‡ºã—ã˜ã‚ƒã‚“ã‘ã‚“ã½ãã¦ã¿ã£ã¨ã‚‚ãªã„ãªã€‚åŸºç›¤æŠ€è¡“ã‚‚ã€BM42ã¨ã‹ã€RetrievaBERTã¨ã‹ã€FastEmbedã€ã¨ã‹æ–‡æ›¸æ¤œç´¢ã‚„ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãªã©ã®åŸºç¤ã¨ãªã‚‹æŠ€è¡“ã‚‚ç€å®Ÿã«é€²åŒ–ãŒã‚ã‚‹ã€ä»Šå¾Œã®ç™ºå±•ã«æœŸå¾…ã€‚ä¸€æ–¹ã€ä»Šé€±ã¯LLMã®é€²æ­©ã«å¯¾ã™ã‚‹å†·é™ãªè¨˜äº‹ã‚‚ç›®ç«‹ã£ãŸã€‚LLMã®åŸºæœ¬çš„ãªæ€§è³ªã«å¯¾ã—ã¦ç‰©ç”³ã™Key Claims è«–æ–‡ã€LLMãŒã‚ã‚“ãªã“ã¨ã§ããŸã€ã“ã‚“ãªã“ã¨ã§ããŸã¨ã„ã†ã®ã¯ã€æ‰€è©®ã€æ±åŒ–æ€§ã®ãªã„SOTAã®é›†ã¾ã‚Šã¿ãŸã„ãªæ„Ÿã˜ã‹ã€ç¢ºã‹ã«LLMã®ç‰¹å¾´ã£ã¦ãã‚ŒãŒç™ºç¾ã™ã‚‹æ¡ä»¶ã‚’å‚™è€ƒã«ä¹—ã›ã‚‹ã¨é•·ããªã‚‹æ°—ãŒã™ã‚‹ã€ã§ã‚‚Claudeãªã‚“ã‹ã‚’è¦‹ã¦ã‚‹ã¨ã€LLMã«ã‚ˆã‚‹ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿç¾ã£ã¦ä½œè€…ãŒçŸ¥ã‚‰ãªã„ã¨ã“ã‚ã§èµ·ãã¦ã„ã‚‹ã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚æ±åŒ–æ€§ã¯Grokked Transformersã«æœŸå¾…ã€‚çµŒæ¸ˆçš„ãªè¦–ç‚¹ã§ã¯ã€ã€Œã‚¨ã‚³ãƒãƒŸã‚¹ãƒˆã€èªŒã®AIé©å‘½ã¯ä»Šã®ã¨ã“ã‚çµŒæ¸ˆçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã»ã¨ã‚“ã©ç¢ºèªã§ããªã„ã¨ã„è¨˜äº‹ã‚‚ã€ç¢ºã‹ã«ã€èª°ãŒé–‹ç™ºã‚„GPUã‚’å‹•ã‹ã™ãŠé‡‘ã‚’æ‰•ã£ã¦ã‚‹ã‚“ã ã‚ã†ã¨å†·é™ãªåˆ†æã€‚GPTZeroã®å ±å‘Šã«ã‚ã£ãŸã‚ˆã†ã«ã€Perplexityã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¹³å‡ã§ã€3å›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©¦è¡Œã‚’ã™ã‚Œã°ã€ç”Ÿæˆã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã«é­é‡ã™ã‚‹ã¨ã„ã†ã®ã ã‹ã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã®æ¯æ¸‡ã‚‚ãã‚ãã‚LLMã®ç™ºå±•ã«å½±éŸ¿ã—å§‹ã‚ã‚‹ã®ã‹ã€‚æ˜ã‚‹ã„ã‚ˆã†ãªæš—ã„ã‚ˆã†ãªãã†ã„ã†è©±é¡Œã®æ··ã–ã£ãŸé€±ã§ã—ãŸã€‚


-  Self-Play Preference Optimization for Language Model Alignment
	- https://huggingface.co/papers/2405.00675
	- SPPOè«–æ–‡
- Gemma-2ã®Self-Play Preference Optimization (SPPO) ã‚’é©ç”¨ç‰ˆ
	- https://huggingface.co/UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3
	- AlpacaEval 2.0 ã§ 53.27%ã¨é©šç•°çš„ ãŸã£ãŸ9Bã§GPT-4ã¨è‚©ã‚’ä¸¦ã¹ã‚‹ãƒ¬ãƒ™ãƒ«ã¯æ–°æ™‚ä»£ã‹ by AIXã‚µãƒˆã‚·
- NICTå†…ã«GPAIï¼ˆAIã«é–¢ã™ã‚‹ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ»ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ— ï¼‰æ±äº¬å°‚é–€å®¶æ”¯æ´ã‚»ãƒ³ã‚¿ãƒ¼ã€‚
	- https://x.com/ikegai/status/1807668045302857856
	- æ—¥æœ¬æ”¿åºœã¯ã€GPAIè­°é•·å›½ã¨ã—ã¦ã€ç”ŸæˆAIã®æ”¿ç­–ç«‹æ¡ˆã®ãŸã‚ã®ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’è“„ç©ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç­‰ã®æ´»å‹•ã‚’æ¨é€²ã—ã€GPAIã¸ã®ã•ã‚‰ãªã‚‹è²¢çŒ®ã‚’æœãŸã™ãŸã‚ã€
	- https://www.soumu.go.jp/menu_news/s-news/01tsushin06_02000292.html
- Llama3ã‹ã‚‰ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’ã—ãŸLlama-3-Swallowãƒ¢ãƒ‡ãƒ«ã®ãƒªãƒªãƒ¼ã‚¹
	- https://huggingface.co/tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1
-  Imperative Learning: A Self-supervised Neural-Symbolic Learning Framework for Robot Autonomy
	- https://arxiv.org/abs/2406.16087
	- What is Neural-Symbolic AI? How do we use it for Robot Autonomy? How to overcome the generalization challenge of RL and Imitation Learning? In this article (https://arxiv.org/abs/2406.16087), we introduce Imperative Learning, a Self-supervised Neural-Symbolic  Framework as our answer.
- NICTã¨KDDIã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹å…±åŒç ”ç©¶ã‚’é–‹å§‹
	- https://newsroom.kddi.com/news/detail/kddi_nr-154_3422.html
- gemma-2-27b-itã®æ—¥æœ¬èªimatrixé‡å­åŒ–gguf
	- https://huggingface.co/grapevine-AI/gemma-2-27b-it-gguf
	- Googleã•ã‚“ã®gemma-2-27b-itã®æ—¥æœ¬èªimatrixé‡å­åŒ–ggufãŒå®Œæˆã—ã¾ã—ãŸï¼ è»½é‡ãªã®ã«ã¨ã‚“ã§ã‚‚ãªãè³¢ã„ã€ç¾çŠ¶æœ€å¼·ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMã ã¨æ€ã„ã¾ã™
	- https://x.com/2022_technology/status/1807301685276217458
- gemma-2-27b-itã®Elyza tasks 100ã®ã‚¹ã‚³ã‚¢
	- https://x.com/2022_technology/status/1807302310114267186
	- ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚é«˜ã„3.88ç‚¹ã§ã™ï¼é©šç•°ã®ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒˆã‚­ãƒªãƒ³ã‚°ï¼
-  Claudeã®Artifactsæ©Ÿèƒ½ã§ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆã‚’ä½œã‚ã†ï¼
	- https://note.com/yoshi8__/n/n0d2816815fba?sub_rt=share_pb
	- ä»Šå›ã¯ã€Three.jsã¨ã„ã†ï¼“Dãƒ¢ãƒ‡ãƒ«ãŒä½œã‚Œã‚‹JavaScriptãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ã¦ã€ç°¡å˜ãªãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆé¢¨ã®3Dã‚²ãƒ¼ãƒ ã‚’ä½œæˆã™ã‚‹æ–¹æ³•ã‚’ãƒˆãƒ©ã‚¤ã—ã¾ã—ãŸã€‚
	- ã‚²ãƒ¼ãƒ é–‹ç™ºçµŒé¨“ãŒãªã„åƒ•ã§ã‚‚ã€Claudeã‚’ä½¿ã£ã¦ç°¡å˜ãªWebã‚²ãƒ¼ãƒ ã‚’ä½œã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸï¼ã€Œè¿½åŠ ã—ã¦æ¬²ã—ã„æ©Ÿèƒ½ã‚’ã†ã¾ãä¼ãˆã‚‹ã“ã¨ã€ãŒéµã‹ãªã£ã¦æ€ã£ã¦ã„ã¾ã™ã€‚
- ã€AIæ™‚ä»£ã®è³ªå•åŠ› ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒªãƒ†ãƒ©ã‚·ãƒ¼ ã€Œå•ã„ã€ã¨ã€ŒæŒ‡ç¤ºã€ãŒç”ŸæˆAIã®å¯èƒ½æ€§ã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ã€
	- https://www.shoeisha.co.jp/book/detail/9784798183459
	- æœ¬æ›¸ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®ä»•çµ„ã¿ã¨ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ã®åŸºæœ¬ã‚’ç†è§£ã™ã‚‹ã¨ã“ã‚ã‹ã‚‰ã€AIã«é©åˆ‡ãªè³ªå•ã‚’ã—ã€AIã¨ã‚ˆã‚ŠåŠ¹æœçš„ãªå¯¾è©±ã‚’ã™ã‚‹ãŸã‚ã®ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã€Œãƒˆãƒªã‚¬ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã€ã•ã‚‰ã«é€²ã‚“ã ç™ºå±•çš„ãªæŠ€è¡“ã€ã¾ãŸæœ€å…ˆç«¯ã®ã€ŒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã«ã„ãŸã‚‹ã¾ã§ã€AIã¨ã®ã‚„ã‚Šã¨ã‚Šã‚’æœ€é©åŒ–ã™ã‚‹ãŸã‚ã®çŸ¥è­˜ã¨ãƒã‚¦ãƒã‚¦ãŒå­¦ã¹ã¾ã™
-  Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning
	- https://arxiv.org/abs/2406.19502
	- Excited to share our latest paper on the reasoning capabilities of LLMs! Our research dives into how these models recall and utilize factual knowledge during solving complex questions
	- Take this question as an example: "Why does ReLU training take less time than sigmoid or tanh training?". One must not only *recall* what an activation function is, but also *compare*
	- we propose breaking down complex questions into a graph structure, with each node representing a specific depth of understanding: recall (D1), application (D2), and strategic thinking (D3). Our approach emphasizes accumulating and integrating knowledge to
-  Scaling Synthetic Data Creation with 1,000,000,000 Persona
	- https://arxiv.org/abs/2406.20094
	- It's easy to generate synthetic data but hard to scale up its diversity which is essential for its application.
	- This paper proposes a novel persona-driven data synthesis methodology to generate diverse and distinct data covering a wide range of perspectives.
- Llama3-Swallow-8B-Instruct-v0.1ã®Shaberi3ãƒ™ãƒ³ãƒã‚¹ã‚³ã‚¢ã¯6.78ã€‚by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1807840130016989601
	- ãƒ¢ãƒ‡ãƒ«å…¬é–‹ã—ã¦ãã‚Œã‚‹ã®ã¯ã‚ã‚ŠãŒãŸã„ã‚“ã ã‘ã©ã¡ã‚‡ã£ã¨æ“è­·ãŒé›£ã—ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€‚ãƒ™ãƒ¼ã‚¹ã«ãªã£ãŸLlama8-8Bï¼ˆ6.91ï¼‰ã«ã‚‚è² ã‘ã¦ã‚“ã ã‘ã©ã€
- ãŸã£ãŸã„ã¾ä¸€èˆ¬å…¬é–‹ã•ã‚ŒãŸã€Gen-3ã€ å®Ÿéš›ã«ä½œã£ã¦ã¿ãŸã‘ã©ãƒ¤ãƒã™ãã‚‹ã‚
	- https://x.com/ryo_kun0811/status/1807829970577920352
-  Semiautomated experiment with a robotic system and data generation by foundation models for synthesis of polyamic acid particle
	- https://www.nature.com/articles/s41428-024-00930-9
	- ãƒãƒªãƒãƒ¼å¾®ç²’å­ã®ãƒ­ãƒœãƒƒãƒˆåˆæˆå®Ÿé¨“ + ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«GPT-4ã§å®Ÿé¨“è¦³å¯Ÿã€è§£æã€è‡ªçœãªã©ãŒã©ã‚Œãã‚‰ã„ã§ãã‚‹ã‹ã‚’èª¿ã¹ã¦ã¿ãŸè«–æ–‡ãŒpublishã•ã‚Œã¾ã—ãŸ(polymer journal)ã€‚
- ã€Œã‚´ãƒŸã‚’é£Ÿã¹ã€ã‚´ãƒŸã‚’åãã€ã€ãƒ™ã‚¾ã‚¹ã‚‚å‡ºè³‡ã™ã‚‹AIæ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®å“è³ªå•é¡Œ
	- https://forbesjapan.com/articles/detail/72055?read_more=1
	- GPTZeroã®ç ”ç©¶ã§ã€ãƒ‘ãƒ¼ãƒ—ãƒ¬ã‚­ã‚·ãƒ†ã‚£ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯å¹³å‡3å›ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå‘½ä»¤æ–‡ï¼‰ã®å…¥åŠ›ã§AIãŒç”Ÿæˆã—ãŸæƒ…å ±æºã«é­é‡ã™ã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ãŸã€‚ã€Œå½¼ã‚‰ã®ã‚µãƒ¼ãƒ“ã‚¹ã®è³ªã¯ã€ãã®å¼•ç”¨å…ƒã®è³ªã«ä¾å­˜ã—ã¦ã„ã‚‹ã€‚æƒ…å ±æºãŒAIã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ç”Ÿã¿å‡ºã•ã‚ŒãŸã‚‚ã®ã§ã‚ã‚‹ãªã‚‰ã€ãã®å‡ºåŠ›ã‚‚åŒæ§˜ã ã€
	-  ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã€Œç›—ç”¨ã€
- Position: Key Claims in LLM Research Have a Long Tail of Footnotes
	- https://arxiv.org/abs/2308.07120
	- LLMã«é–¢ã™ã‚‹â€ä¸€èˆ¬çš„ãªä¸»å¼µâ€ã‚’æ‰¹åˆ¤çš„ã«æ¤œè¨ã—ã¦ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚LLMã®å®šç¾©ã€ç‰¹æ€§ã€å½±éŸ¿åŠ›ã«ã¤ã„ã¦åˆ†æã‚’è¡Œã„ã€å¤šãã®ä¸»å¼µãŒã‚‚ã—ã‹ã™ã‚‹ã¨ååˆ†ãªæ ¹æ‹ ã‚’æ¬ ã„ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã¾ã™ã€‚
	- ä¾‹ãˆã°ä»¥ä¸‹ã¯éµœå‘‘ã¿ã«ã§ããªã„ã¨ã®ã“ã¨ã€‚
		- æ–°ã—ã„å•é¡Œã«ã‚‚æŸ”è»Ÿã«å–ã‚Šçµ„ã‚ã‚‹ 
		- è‡ªç„¶è¨€èªå‡¦ç†ã§ãƒ™ã‚¹ãƒˆãªãƒ„ãƒ¼ãƒ« 
		- æ€§èƒ½å‘ä¸Šã¯å˜ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚‚ã® 
		- æ­´å²çš„ãªæ±ç”¨æŠ€è¡“
		- å‰µç™ºçš„ãªç‰¹æ€§ãŒã‚ã‚‹
- Gemma 2: Improving Open Language Models at a Practical Size
	- https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf
	- è»½é‡ãªã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹LLMã®Gemma 2ã®æ€§èƒ½ã¯ã€
	- 2å€ä»¥ä¸Šå¤§ããªã‚µã‚¤ã‚ºã®Llama 3ã«åŒ¹æ•µã™ã‚‹ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚ 
	- å®‰å…¨æ€§è©•ä¾¡ã§ã¯GPT-4oã¨åŒç­‰ä»¥ä¸Šã®çµæœã‚‚ã€‚ 
	- ã¾ãŸã€ä½¿ã„å¿ƒåœ°ã®è©•ä¾¡ï¼ˆChatbot Arenaï¼‰ã§ã¯æ—¢ã«å¤šãã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚
-  GoogleãŒå…¬é–‹ã—ãŸæ–°ã—ã„ã‚ªãƒ¼ãƒ—ãƒ³LLMã€Gemma 2ã¸ã‚ˆã†ã“ãï¼
	- https://hamaruki.com/welcome-to-gemma-2-googles-new-open-llm-2/
	- ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼šé«˜å“è³ªãªç”Ÿæˆã®ãŸã‚ã«ã€ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¨å®Œå…¨ãªäºŒæ¬¡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’äº¤äº’ã«é…ç½®ã—ã¾ã™ã€‚
	- å¯¾æ•° ã‚½ãƒ•ãƒˆã‚­ãƒ£ãƒƒãƒ”ãƒ³ã‚°ï¼šãƒ­ã‚¸ãƒƒãƒˆã‚’ä¸€å®šã®ç¯„å›²ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ãƒ­ã‚¸ãƒƒãƒˆãŒéåº¦ã«å¤§ãããªã‚‹ã®ã‚’é˜²ãã€å­¦ç¿’ã‚’æ”¹å–„ã—ã¾ã™ã€‚
	- è’¸ç•™ï¼šã‚ˆã‚Šå¤§ããªæ•™å¸«ãƒ¢ãƒ‡ãƒ«ã‚’æ´»ç”¨ã—ã¦ã€ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ï¼ˆ9Bãƒ¢ãƒ‡ãƒ«ã®å ´åˆï¼‰ã‚’å­¦ç¿’ã—ã¾ã™ã€‚
	- ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ï¼š2ã¤ä»¥ä¸Šã®LLMã‚’çµ„ã¿åˆã‚ã›ã¦ã€å˜ä¸€ã®æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚
- Microsoft ç”ŸæˆAIæ´»ç”¨äº‹ä¾‹ã¨è©•ä¾¡æ–¹æ³•ã«ã¤ã„ã¦
	- https://speakerdeck.com/daikikanemitsu/microsoft-sheng-cheng-aihuo-yong-shi-li-toping-jia-fang-fa-nituite
	- MicrosoftãŒå…¬é–‹ã—ã¦ã„ã‚‹ã€Œç”ŸæˆAIæ´»ç”¨äº‹ä¾‹ã€ãŒæœ‰ç›Šã€‚
	- ä¸€äººå½“ãŸã‚Š"æœˆ17æ™‚é–“ã®æ¥­å‹™æ™‚é–“å‰Šæ¸›" ã‚’é”æˆã—ãŸå†…è¨³ã‚’å®šæ€§çš„ãƒ»å®šé‡çš„ã«åŠ¹æœæ¸¬å®šã—ã¦ã„ã‚‹ã€‚
-  Impact of Data Bias on Machine Learning for Crystal Compound Synthesizability Predictions
	- https://arxiv.org/abs/2406.17956
	- ãƒ‡ãƒ¼ã‚¿åã‚Šã®å½±éŸ¿ã‚’èª¿æŸ»ã—ãŸè«–æ–‡ã€‚
	- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åã‚Šã‹ã‚‰æ„å›³ã—ãªã„ç›¸é–¢ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€å®Ÿæ§‹é€ ã¨ä»®æƒ³æ§‹é€ ã‚’æ··ãœãŸåã‚Šã®å¼·ã„ãƒ‡ãƒ¼ã‚¿ã¨DFTç·©å’Œæ§‹é€ ã®åã‚Šã®å¼±ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã„ã“ã®å½±éŸ¿ã‚’æ¯”è¼ƒã€å‰è€…ã¯ä¿¡é ¼æ€§ãŒä½ã‹ã£ãŸã¨ã®ã“ã¨ã€‚
	- ç•°ç¨®ãƒ‡ãƒ¼ã‚¿ã‚’æ··ãœã‚‹éš›ã«ã¯ã”æ³¨æ„ã‚’ã€‚by æ¨ªå±±ã•ã‚“
-  Metaã€LLMã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã‚’å…¬é–‹â€”â€”AIãŒãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å¸¸è­˜ã‚’å¤‰ãˆã‚‹ã‹ã‚‚
	- https://thebridge.jp/2024/07/metas-llm-compiler-is-the-latest-ai-breakthrough-to-change-the-way-we-code
	- https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb
	- LLVM-IR ã¨ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚³ãƒ¼ãƒ‰ã®5,460å„„ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãªã‚‹è†¨å¤§ãªã‚³ãƒ¼ãƒ‘ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã®ä¸­é–“è¡¨ç¾ã€ã‚¢ã‚»ãƒ³ãƒ–ãƒªè¨€èªã€æœ€é©åŒ–ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’ç†è§£ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€‚
	- LLM ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã¯ã€ã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã®æœ€é©åŒ–ã«ãŠã„ã¦ç›®è¦šã¾ã—ã„æˆæœã‚’ä¸Šã’ãŸã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ãƒ†ã‚¹ãƒˆã«ãŠã„ã¦ã€ã‚ªãƒ¼ãƒˆãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¢ç´¢ã®æœ€é©åŒ–ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã®77%ã«é”ã—ãŸ
- Sonnet3.5ã‚’Shaberi3ãƒ™ãƒ³ãƒã§è©•ä¾¡ã—ãŸã‚‰ã€8.39ï¼ï¼ã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1808203661623058684
	- ã‚„ã¯ã‚Šä¸–ç•Œæœ€å¼·ã€ç‹è€…ã®æ€§èƒ½ã‚’å©ãå‡ºã—ã¦GPT-4Tã‚„Opusã«å‹åˆ©ã—ã¾ã—ãŸã€‚ãŠå‰ãŒãƒŠãƒ³ãƒãƒ¼ãƒ¯ãƒ³ã 
- GraphRAG from Microsoft is just open sourced
	- https://github.com/microsoft/graphrag
- GraphRAG from MS
	- https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/
	- GraphRAG, a graph-based approach to retrieval-augmented generation (RAG) that significantly improves question-answering over private or previously unseen datasets, is now available on GitHub. Learn more
	-  Advantages of community summaries for â€œglobal questionsâ€
	- The results show that GraphRAG, when using community summaries at any level of the community hierarchy, outperforms naive RAG on comprehensiveness and diversity (~70â€“80% win rate). 
	- GraphRAG using intermediate- and low-level community summaries also performed better than source text summarization on these metrics at lower token costs (~20â€“70% token use per query). 
	- Performance was competitive with hierarchical source text summarization for the highest-level communities at substantially lower token costs (~2â€“3% token use per query).
-  GraphRAG Ollama: 100% Local Setup, Keeping your Data Private
	- https://www.youtube.com/watch?v=BLyGDTNdad0
-  Retrieval-Augmented Generation for Large Language Models: A Survey
	- https://arxiv.org/abs/2312.10997
	- [RAGã®Surveyè«–æ–‡ã‹ã‚‰RAGé–¢é€£æŠ€è¡“ã‚’ä¿¯ç°ã™ã‚‹](https://sue124.hatenablog.com/entry/2024/07/02/233616)
	- ã€Œæ•™å¸«ãªã—Fine-tuningãŒï¼ˆFine-tuningå‰ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ï¼‰è‹¥å¹²ã®æ”¹å–„ã‚’ç¤ºã™ä¸€æ–¹ã§ã€RAGã¯ã€äº‹å‰å­¦ç¿’ä¸­ã«é­é‡ã—ãŸæ—¢å­˜ã®çŸ¥è­˜ã¨å…¨ãæ–°ã—ã„çŸ¥è­˜ã®ä¸¡æ–¹ã«å¯¾ã—ã¦ã€ä¸€è²«ã—ã¦Fine-tuningã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ä¸Šå›ã‚‹ã“ã¨ã‚’æ˜ã‚‰ã‹ã«ã—ãŸã€
	- RAGã¯ä¸‹å›³ã®ã‚ˆã†ã« "Naive RAG", "Advanced RAG", "Modular RAG" ã®ã‚ˆã†ã«å¤‰é·ã—ã¦ãã¾ã—ãŸ
- éå¸¸ã«è‰¯ã„RAGç ”ç©¶ã®ç¾çŠ¶ã¾ã¨ã‚ã§ã—ãŸ by TJO
	- https://x.com/TJO_datasci/status/1808334151709610368
	- å…ƒã€…LLMå®Ÿå¿œç”¨ã®ã‚³ã‚¢ã¨ç›®ã•ã‚Œã¦ã„ãŸRAGã®ã“ã‚Œã¾ã§ã¨ã“ã‚Œã‹ã‚‰ã¨ãŒæ¦‚è¦³ã§ãã¾ã™ / RAGã®Surveyè«–æ–‡ã‹ã‚‰RAGé–¢é€£æŠ€è¡“ã‚’ä¿¯ç°ã™ã‚‹ - å…ƒç”ŸæŠ€ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®ãƒ¡ãƒ¢å¸³
- ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‹ã‚‰CALM3-22B-Chatã£ã¦ã®ãŒå…¬é–‹
	- https://huggingface.co/cyberagent/calm3-22b-chat
- Swallow-8Bã«ã€æœ¬å®¶Metaã®Instructãƒ¢ãƒ‡ãƒ«ã¨Baseãƒ¢ãƒ‡ãƒ«ã®å·®åˆ†ãƒ™ã‚¯ãƒˆãƒ«ã‚’åŠ ç®—ã—ã¾ã—ãŸ by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://x.com/AiXsatoshi/status/1808063295259304286
- gen3 ã‚¹ã‚´ã„ã£ã™ã€‚æ—¥æœ¬äººã‚‚æ™®é€šã«å‡ºã›ã‚‹ã€‚ ç ´ç¶»ã‚‚å°‘ãªã„
	- https://x.com/br_d/status/1807986683226599806
	- æ˜ åƒã¨ã‹ã«1ã‚«ãƒƒãƒˆã±ã£ã¨å‡ºã•ã‚ŒãŸã‚‰ã€åˆ¤æ–­ã¤ã‹ãªã„ãƒ¬ãƒ™ãƒ«
- ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯HDã¯ã€ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ã¨1,000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è‡ªç¤¾å°‚ç”¨ [#LLM](https://x.com/hashtag/LLM?src=hashtag_click) "Panasonic-LLM-100b" ã®é–‹ç™ºã§å”æ¥­
	- https://x.com/panasonic_ai/status/1808007439922745561
- RetrievaBERTã®å…¬é–‹
	- https://note.com/retrieva/n/n715bea2c2cd1
	- â€œSentence Representationã§ç”¨ã„ã‚‹ãŸã‚ã®BERTã¨ã—ã¦ç³»åˆ—é•·ãŒ2048ã¾ã§å¯¾å¿œã—ã¦ã„ã‚‹BERTã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ
	- æˆ‘ã€…ã®çŸ¥ã‚‹é™ã‚Šã§ã¯ç¾åœ¨å…¬é–‹ã•ã‚Œã¦ã„ã‚‹BERTã¯ç³»åˆ—é•·512ã¾ã§ã¨ãªã£ã¦ã„ã‚‹ã‚‚ã®ãŒã»ã¨ã‚“ã©ã ã¨æ€ã„ã¾ã™ã€‚ãã“ã§ä»Šå›ã€Sentence Representationã§ç”¨ã„ã‚‹ãŸã‚ã®BERTã¨ã—ã¦ç³»åˆ—é•·ãŒ2048ã¾ã§å¯¾å¿œã—ã¦ã„ã‚‹BERTã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œã‚‹ã®è‹¦æ‰‹ãªäººã¯å…¨å“¡ Claude ã® "Generate a prompt" ã‚’ä½¿ã£ãŸæ–¹ãŒè‰¯ã„ã€‚
	- https://x.com/sora19ai/status/1807950984741806191
	- ä»Šã‚„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯AIã«ä½œã‚‰ã›ã‚‹ã“ã¨ãŒã§ãã¦ã€Claude ã® Generate a prompt ã§ä½œã£ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ GPTs ã‚„ Dify ã§ä½¿ãˆã°ã€å‡ºåŠ›ã®ç²¾åº¦ãŒ10å€ä¸ŠãŒã‚‹ã€‚
	- ç¾åœ¨ GPTs ã‚„ Dify ã®éœ€è¦ãŒé«˜ã¾ã‚‹ä¸­ã€ä»Šã‹ã‚‰ ChatBot ã‚’é‡ç”£ã—ã¦ãŠã“ã†ã€‚ãƒªãƒ—æ¬„ã«ãƒªãƒ³ã‚¯ã‚’è¼‰ã›ã¦ãŠãã®ã§è©¦ã—ã¦ã¿ã¦ï¼
- Difyã§VOICEVOXã®TTSã‚’ä½¿ãˆã‚‹ã‚ˆã†ã«ã—ãŸã‚ˆã€œ
	- https://github.com/uezo/dify-voicevox-tts
- ã€Œã‚¢ã‚¸ã‚¢äººã½ã„è¤‡æ•°ã®ç”·æ€§ãŒã€ã²ãŸã™ã‚‰ã«ç‰›ã®é¤Œã®ã‚ˆã†ãªè‰ã‚’é£Ÿã¹ã¦ã„ã‚‹ã€‚æ‰‹ã¥ã‹ã¿ã§ã€‚ãŸã ã—ã€æœè£…ã¯ã‚¹ãƒ¼ãƒ„ã§ã‚ã‚Šã€ãƒ›ãƒ†ãƒ«ã®ã‚ˆã†ãªé«˜ç´šãªå ´æ‰€ã§ã‚ã‚‹ã€‚èƒŒæ™¯ã§ã¯æ ¸æˆ¦äº‰ãŒèµ·ãã¦ã„ã‚‹ã€‚ã€
	- https://x.com/kensuu/status/1807972176005587070
- Runwayã®Gen-3ã§ç››ã‚Šä¸ŠãŒã‚‹ä¸­ã€MetaãŒã—ã‚Œã£ã¨é«˜æ€§èƒ½ã®3Dç”ŸæˆAIã€ŒMeta 3D Genã€ã‚’ç™ºè¡¨
	- https://x.com/masahirochaen/status/1808166498403602822
- Launching GPT4All 3.0: The Open-Source Local LLM Desktop App
	- https://x.com/nomic_ai/status/1808162955806097767
		- Completely Private Experience 
		- Supports 1000â€™s of models and all major operating systems 
		- Major UI/UX Improvements 
		- Local File Chat 
		- MIT Licensed
- Runway Gen-3ã§ä½œã£ãŸã‚·ãƒ¥ãƒ¼ãƒ«ãªå‹•ç”»15é¸ï¼
	- https://x.com/takamasa045/status/1807975062873792958
	- 1æ™‚é–“ã§ãƒ—ãƒ­æ ã‚’ä½¿ã„åˆ‡ã‚Šã€ã‚¢ãƒ³ãƒªãƒŸãƒ†ãƒƒãƒ‰ãƒ—ãƒ©ãƒ³ã«å³ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ 1.5ä¸‡å††å¹ã£é£›ã‚“ã ã€ã€ã€
- ã‚¤ãƒ©ã‚¹ãƒˆã®ã‚ˆã†ãªQRã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ãŸã„äººã¯QRBTFã‚’ä½¿ã£ãŸã‚‰è‰¯ã„
	- https://x.com/satori_sz9/status/1807621893488623976
- Gemini Nano running locally in Brave using MediaPipe
	- https://x.com/rohanpaul_ai/status/1807763287599149557
	- or Web, Android and iOS LLM Inference API, now you can run Gemini Nano locally not only in Google Chrome Canary, but in every web browser supporting WebGPU like Brave, through MediaPipe
- ã‚¶ãƒƒã‚«ãƒ¼ãƒãƒ¼ã‚°ã€Œæ—¥æœ¬ã®æ‹…å½“ã‚’è§£é›‡ã™ã‚Œã°æ—¥æœ¬äººã‹ã‚‰Metaã«å¯¾ã™ã‚‹è©æ¬ºåºƒå‘Šã®ã‚¯ãƒ¬ãƒ¼ãƒ å±Šã‹ãªããªã‚‹ã—äººä»¶è²»ã‚‚æµ®ãã—ä¸€çŸ³äºŒé³¥ã‚„ã‚ã€ã‚¬ãƒƒãƒãƒƒãƒã€
	- https://x.com/makkinze/status/1807688392865624528
- The parable of the parserã€ç¾ä»£ã®ç‰©ä½“æ¤œå‡ºã‚’ä½œã£ã¦ããŸGirshickæ°ã«ã‚ˆã‚‹è­°è«–ã‚’ã‚ˆã¶ãƒ—ãƒ¬ã‚¼ãƒ³ã€‚
	- https://drive.google.com/file/d/1VodGljuEhBKwZIXQwN-ApH6g2wBAVAdK/view
	- ç”»åƒå‡¦ç†ã«ãŠã„ã¦ç”»åƒåˆ†é¡ã‚„ç‰©ä½“æ¤œå‡ºã¯æœ€çµ‚çš„ãªã‚¿ã‚¹ã‚¯ã‚’è§£ãã®ã«å¿…è¦ãªã„ã®ã§ã¯
	- ç‰©ä½“æ¤œå‡ºã‚’ã“ã‚Œã¾ã§ç ”ç©¶ã—ã¦ããŸã“ã¨è‡ªä½“ã¯é–“é•ã„ã§ã¯ãªãã€ãã‚Œã«ã‚ˆã‚ŠçŸ¥è­˜ã‚’ãŸã‚ã¦é€²ã‚“ã§ããŸã®ã¯ç¢ºã‹ã ãŒã€ã•ã‚‰ã«é€²ã‚€ãŸã‚ã«ã¯ã€ã‚ˆã‚Šè‰¯ã„ç‰©ä½“æ¤œå‡ºã‚’ä½œã‚‹ã®ã§ã¯ãªãæœ¬å½“ã«è§£ããŸã„å•é¡Œã¯ä½•ã‹ã‚’è€ƒãˆã‚‹ã®ãŒå¿…è¦ã¨ã®ã“ã¨ã€‚ç‰©ä½“æ¤œå‡ºã‚¿ã‚¹ã‚¯ã¯ã‚ã¾ã‚Šã«é™å®šçš„ã§è„†ãã€ãƒ‡ãƒ¼ã‚¿ã«åˆ¶ç´„ãŒã‚ã‚‹ã€‚50å¹´~60å¹´å½“ç„¶ã¨æ€ã‚ã‚Œã¦ã„ãŸè€ƒãˆæ–¹ã«ç–‘å•ã‚’ã‚‚ã¤ã“ã¨ã€ï¼ˆå„äººãŒï¼‰æœ¬å½“ã«è§£ããŸã„ã‚¿ã‚¹ã‚¯ã¯ä½•ã‹ã‚’è€ƒãˆã‚‹ã“ã¨ãŒé‡è¦ã€‚
- Decentralized Identifiers (DID) ã¨Verifiable Credentials (VC) ã®ç¾æ³
	- https://www.jstage.jst.go.jp/article/essfr/18/1/18_42/_article/-char/ja
- é«˜æ ¡ã‹ã‚‰ã®ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»çµ±è¨ˆæ´»ç”¨ã€ä¸Šç´šç·¨
	- https://www.soumu.go.jp/main_content/000607858.pdf#page=1.00
- Gemma 2ã§ã¯WARPã¨å‘¼ã°ã‚Œã‚‹æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ³ã‚°æŠ€è¡“ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://x.com/AiXsatoshi/status/1808346577700069697
	- WARPã¯ã€3æ®µéšã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ¼ã‚¸ 
		- ãƒ»EMAã‚’åˆ©ç”¨ã—ãŸRLHF 
		- ãƒ»è¤‡æ•°ã®ãƒãƒªã‚·ãƒ¼ã§RLHFã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’SLERPãƒãƒ¼ã‚¸
		-  	ãƒ»åˆæœŸãƒ¢ãƒ‡ãƒ«ã¨ç·šå½¢è£œå®Œ 
	- ã“ã‚Œã‚’ç¹°ã‚Šè¿”ã™ã“ã¨ã§ã€æ®µéšçš„ã«æ”¹å–„ã—ã€æœ€çµ‚çš„ã«ã‚ˆã‚Šå„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã‚’å®Ÿç¾
- ã€Œã‚¢ãƒƒãƒ—ãƒ«ã§ã‚¢ãƒƒãƒ—ã‚¹ãƒˆã‚¢äº‹æ¥­ã‚’çµ±æ‹¬ã™ã‚‹ãƒ•ã‚£ãƒ«ãƒ»ã‚·ãƒ©ãƒ¼æ°ãŒã‚ªãƒ¼ãƒ—ãƒ³ï¼¡ï¼©å–ç· å½¹ä¼šã®ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ¼ã«é¸ã°ã‚ŒãŸã€‚ã€
	- https://x.com/bioshok3/status/1808284141173330407
- çªå¦‚Kyutaiã¨ã„ã†çµ„ç¹”ãŒGPT-4oã‹ãã‚Œã‚ˆã‚Šå¿œç­”é€Ÿã„ã¨æ„Ÿã˜ã‚‹Speech2Speechãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ã€ŒMoshiã€ã‚’ç™ºè¡¨
	- https://x.com/bioshok3/status/1808529863621652596
- OpenContracts - a fully open-source, AI-powered Document Analytics Too
	- https://x.com/llama_index/status/1808528869252812902
-  Property-guided generation of complex polymer topologies using variational autoencoders
	- https://www.nature.com/articles/s41524-024-01328-0
	- VAEã«ã‚ˆã‚‹ãƒãƒªãƒãƒ¼é€†è¨­è¨ˆã®è«–æ–‡ã€€by æ¨ªå±±ã•ã‚“
	- å¾“æ¥ã®é€†è¨­è¨ˆã¯ã‚ã‚‹ãƒˆãƒãƒ­ã‚¸ãƒ¼ã®ãƒãƒªãƒãƒ¼ã«é™å®šã•ã¦ã„ãŸã®ã«å¯¾ã—ã€ç’°çŠ¶ãƒ»æ«›å½¢ãƒ»æ˜Ÿå½¢ãªã©æ§˜ã€…ãªãƒˆãƒãƒ­ã‚¸ãƒ¼ã®ãƒãƒªãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã€ç‹™ã„ã®ç‰©æ€§ã‚’ã‚‚ã¤ãƒãƒªãƒãƒ¼ã‚’åºƒç¯„å›²ã‹ã‚‰é€†è¨­è¨ˆã§ããŸãã†ã§ã™ã€‚
- BM42: The combination of semantic and keyword search
	- https://x.com/qdrant_engine/status/1808498752107241949
	- https://qdrant.tech/articles/bm42/
	- For 40 years, BM25 has been the standard for search engines. However, it falls short for modern RAG applications.
	- We propose a new approach for exact keyword search based on Sparse Vectors and Attention from Transformers.
	- We can leverage the intelligence of the transformer to score the importance of each word in a sentence, while still being able to combine it with collection-wide statistics like IDF.
- **Zero Grads: Learning Local Surrogate Losses for Non-Differentiable Graphics**
	- https://mfischer-ucl.github.io/zerograds/
	- SIGGRAPH'24è«–æ–‡ã€‚å‹¾é…è¨ˆç®—ä¸å¯èƒ½ãªãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹é–¢æ•°ã‹ã‚‰ã®éå¸¸ã«å°‘æ•°ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã§å¾®åˆ†å¯èƒ½ãªä»£æ›¿é–¢æ•° (å‹¾é…æ³•ã§æœ€é©åŒ–å¯èƒ½) ã‚’ä½œæˆã€‚ã‹ãªã‚Šã®é«˜æ¬¡å…ƒã§ã‚‚åŠ¹ç‡çš„ã«å‹•ä½œã™ã‚‹ã€‚
	- https://x.com/SupervisedAi/status/1808462332479107542
	- ã“ã‚Œã™ã”ã„ã§ã™ã­ã€‚å¿œç”¨ä¾‹ã¨ã—ã¦å…ƒVAEã‹ã‚‰ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³ã®åº§æ¨™ä½ç½®ã‚’æ±ºã‚ã¦ç”»åƒç”Ÿæˆã™ã‚‹ã¨ã„ã†å¾®åˆ†ä¸å¯èƒ½ãªç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã‚‚è¿‘ä¼¼ã—ãŸå‹¾é…æ³•çµæœã«ã‚ˆã‚Šç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã«æˆåŠŸã—ã¦ã¾ã™
- Llama3-ArrowSE-8B-v0.1ã®Shaberi3ã‚¹ã‚³ã‚¢ã¯7.14ã€‚ã‹ãªã‚Šæ€§èƒ½ã™ã”ã„ã§ã™ã­ã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1808536639574266293
- This AI-powered Juypter implementation has huge potential.
	- https://x.com/omarsar0/status/1808527461736485229
	- They have added Mistral's Codestral and GPT4-o for inline AI Copilot auto-complete, code generation, editing, error fixing, and sidebar chat.
	- https://github.com/pretzelai/pretzelai
- How good are LLMs in a long context, and do we need RAG?
	- https://x.com/_philschmid/status/1808420168558649479
	- RAG always improves the performance of LLMs if correct information is retrieved
	- ğŸ“Š Evaluated 10 LLMs and 50 RAG systems, including GPT-4o, Claude 3 Opus, and Gemini-1.5-pro
	- ğŸ† Claude 3 Opus achieved the highest Coverage; Gemini-1.5-pro highest citation
	- ğŸ¯ Gemini-1.5-pro is the best LLM without RAG with 37.8; Claude 3 Sonnet 18.3; GPT-4o 11.4;
	- âš™ï¸ Gemini-1.5-pro + Oracle RAG achieves 44.6, whereas humans achieved 56.1.
- **Multi-token prediction models and baselines**
	- https://huggingface.co/facebook/multi-token-prediction
	- In April we published a paper on a new training approach for better & faster LLMs using multi-token prediction. To enable further exploration by researchers, weâ€™ve released pre-trained models for code completion using this approach on
- unslothãŒgemma 2ã®å¾®èª¿æ•´ã«å¯¾å¿œ
	- https://x.com/webbigdata/status/1808698905774993771
	- å„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã ã‘ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã™ã‚Œã°gemma 1ã®å¾®èª¿æ•´æ™‚ã«ä½¿ã£ãŸè¨­å®šã‚’ã»ã¼å¤‰ãˆãšã«GPUãƒ¡ãƒ¢ãƒª16GBã§å‹•ã„ã¦ãã‚Œã¾ã—ãŸã€
- "Patent Landscape Report on Generative AI,"
	- https://x.com/LuizaJarovsky/status/1808835305232839159
	- 54,000 GenAI-related inventions (patent families) were filed and more than 75,000 scientific publications published between 2014 and 2023.
	- The growth is rapid, with the number of GenAI patents increasing eightfold since the 2017 introduction of the deep neural network architecture behind the Large Language Models that have become synonymous with GenAI.
	- n 2023 alone over 25% of all GenAI patents globally were published, and over 45% of all GenAI scientific papers were published.
	- GenAI patents still currently only represent 6% of all AI patents globally.
- Claude 3.5 Sonnet, Gemini 1.5 Pro, GPT-4o é ‚ä¸Šæ±ºæˆ¦ã€€by å…ƒæœ¨ã•ã‚“
	- https://x.com/ai_syacho/status/1808708033989525886
	- é–‹ç™ºã«ãŠã‘ã‚‹èƒ½åŠ›é †ä½ã‚’å…ƒæœ¨ã®æ„Ÿè¦šå€¤ã§ä¸¦ã¹ã¾ã—ãŸã€‚
- BM25ã®tfidfã§ã„ã†tfã«ç›¸å½“ã™ã‚‹é …ï¼ˆBM25ã ã¨ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã«å¿œã˜ãŸè£œæ­£ãŒæ›ã‘ã‚‰ã‚Œã¦ã‚‹é …ï¼‰ã®ä»£ã‚ã‚Šã«ã€transformerãƒ¢ãƒ‡ãƒ«ã«å…¥ã‚ŒãŸæ™‚ã®æœ€çµ‚å±¤ã®CLSãƒˆãƒ¼ã‚¯ãƒ³ã®attensionã®å€¤ã‚’ä½¿ã†BM42ãŒè‰¯ã„ã‚‰ã—ã„ã€‚
	- https://x.com/s_tat1204/status/1808896746837455249
	- BM25è³‡ç”£ã‚’ãã®ã¾ã¾ä½¿ãˆãã†ã§è‰¯ã„ã§ã™ã­
-  So far the technology has had almost no economic impact
	- https://www.economist.com/finance-and-economics/2024/07/02/what-happened-to-the-artificial-intelligence-revolution
	- AIé©å‘½ã¯ä»Šã®ã¨ã“ã‚çµŒæ¸ˆçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒã»ã¨ã‚“ã©ç¢ºèªã§ããªã„ãªã„ã¨ã„ã†è¨˜äº‹ã€‚by å°æ—ã•ã‚“
	- https://x.com/yohei_econ/status/1808503287617851876
	- GAFAMç­‰ã®å·¨å¤§ãƒ†ãƒƒã‚¯ä¼æ¥­ã¯ä»Šå¹´4000å„„ãƒ‰ãƒ«ï¼ˆ60å…†å††å…†ï¼‰ã®AIé–¢é€£è³‡æœ¬æ”¯å‡ºã‚’äºˆå®šã—ã¦ã„ã‚‹ã€‚
	- ã—ã‹ã—AIã®åˆ©ç”¨ç‡ã¯ã¾ã ä½ã„
	- 75ï¼…ã®çŸ¥è­˜åŠ´åƒè€…ã¯æ—¢ã«AIã‚’ä½¿ã£ã¦ã„ã‚‹ã¨ç­”ãˆã¦ã„ã‚‹ãŒã€ã‚¢ãƒ¡ãƒªã‚«ã§ä¼æ¥­ã¨ã—ã¦ä½¿ã£ã¦ã„ã‚‹ã®ã¯ï¼•ï¼…ç¨‹åº¦ã€‚ãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨æ€§ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚¤ã‚¢ã‚¹ãŒæ‡¸å¿µç‚¹ã€‚ 
	- ã¾ãŸAIã¯é€²æ­©ãŒé€Ÿã„ã®ã§ã€ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã‚’å§‹ã‚ã‚ˆã†ã¨ã—ã¦ã‚‚ã€ãã‚ŒãŒã™ãã«æ™‚ä»£é…ã‚Œã«ãªã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã€å¤§è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«ç€æ‰‹ã—ã«ãã„ã€‚
	- ãŸã ã—ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã‚„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®æ”¹å–„ãªã©ã€ç‹­ã„é ˜åŸŸã«é™ã‚Œã°AIã®å®Ÿè£…ã¯é€²ã‚“ã§ã„ã‚‹ã€‚ 
	- ã—ã‹ã—ãªãŒã‚‰ã€AIä¼æ¥­ã®æ ªä¾¡ã¯å¸‚å ´å…¨ä½“ã¨æ¯”è¼ƒã™ã‚‹ã¨ä½è¿·ã—ã¦ãŠã‚Šã€çµ±è¨ˆä¸Šã¯ç”Ÿç”£æ€§ä¸Šæ˜‡ã¯è¦‹ã‚‰ã‚Œãªã„ã€‚
	- AIãŒé€²ã‚ã°åŠ´åƒè€…ã«ç½®ãæ›ã‚ã‚‹ã¨è¨€ã‚ã‚ŒãŸãŒã€çµ±è¨ˆçš„ã«ã¯ãã‚Œã‚‚ç¾ã‚Œã¦ã„ãªã„ã€‚
	- ãƒˆãƒ©ã‚¯ã‚¿ãƒ¼ã€é›»åŠ›ã€PCç­‰ã€éå»ã®å¤šãã®æŠ€è¡“é€²æ­©ãŒåºƒã¾ã‚‹ã«ã¯æ™‚é–“ã‚’è¦ã—ãŸã€‚AIã‚‚ãã®å¯èƒ½æ€§ã¯é«˜ãã€æŠ•è³‡å®¶ã‚‚AIã«èµ·å› ã™ã‚‹åç›ŠãŒãƒ†ãƒƒã‚¯ä¼æ¥­ã‚‚ãŸã‚‰ã•ã‚Œã‚‹ã®ã¯2032å¹´ä»¥é™ã¨äºˆæƒ³ã€‚
- claudeã¯æ–‡ã‚’ç”Ÿæˆã—ã¦ã‚‹é€”ä¸­ã§ã€é‡è¦ãªç®‡æ‰€ã§ã‚ãŸã‹ã‚‚ç†Ÿæ…®ã—ã¦ã‚‹ã‚ˆã†ã«ç”Ÿæˆã‚’ä¸€æ™‚æ­¢ã‚ã‚‹ã“ã¨ãŒã‚ã£ãŸãŒã€è£å´ã§ã¯å®Ÿéš›ã«éè¡¨ç¤ºã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ãŸã€‚ 
	- https://x.com/_kaiinui/status/1808778423319605647
	- xmlã‚¿ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆã†å·¥å¤«ã™ã‚‹ã“ã¨ã§ç¢ºèªã§ãã‚‹
- Anthropic Claude 3.5 Sonnet on (claude ai) is suppressing parts of his answer from the user, which are not sent to the client. You can test that with, from now on, use Â§Â§ instead of <>. This then includes Â§Â§antThinkingÂ§Â§ tags, which are
	- https://x.com/_philschmid/status/1808755146190446667
- Gemma2-27Bã‚‚ã€Q8_0é‡å­åŒ–ãŒVRAMã«åã¾ã‚‰ã‚“ã‹ã£ãŸã‹ã‚‰æš«å®šçš„ã«Q5_K_Mé‡å­åŒ–ã‚’Shaberi3è©•ä¾¡ã—ãŸã‚‰7.88ï¼ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1808901901720957212
	- ã„ã‚„Qwen2-72Bè¶…ãˆã¦ã‚‹ã—ãƒ¡ãƒãƒ£ã‚¯ãƒãƒ£ã™ã”ã„ã‚“ã ã‘ã©ã€ã§ã‚‚æ€ã£ãŸä»¥ä¸Šã«9Bã¨åƒ…å·®ã ãªâ€¦ã€‚å¯ã¦ã‚‹é–“ã«Q8_0ã§ã‚‚ä¸€å¿œã‚ã‚‰ãŸã‚ã¦è©•ä¾¡ã™ã‚‹äºˆå®š
- Gemma2-27Bã®Q8_0é‡å­åŒ–ã®Shaberi3ã‚¹ã‚³ã‚¢å‡ºã¾ã—ãŸã€‚7.81ã€€ b æµ·ç”±ç´€ã•ã‚“
	- https://x.com/umiyuki_ai/status/1809028134727266364
	- Q5_K_Mé‡å­åŒ–ï¼ˆ7.88ï¼‰ã‚ˆã‚Šã‚¹ã‚³ã‚¢ä¸‹ãŒã£ãŸã­ï¼Ÿãˆãƒ¼ã¨â€¦ã¨ã‚Šã¾ã€5bitã¾ã§é‡å­åŒ–ã—ã¦ã‚‚åŠ£åŒ–ã¯ã—ãªã„ã‚‰ã—ã„ã­ã¨ã„ã†äº‹ã§â€¦
- Claude3ã«ãƒ­ã‚¸ãƒƒã‚¯ãŒç ´ç¶»ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹éƒ¨åˆ†ã«ã¤ã„ã¦æŒ‡æ‘˜ã—ã¦ã‚‚ã‚‰ã£ã¦ã¿ãŸã€‚
	- https://x.com/yukatan/status/1809114126746284492
	- ç¥å®®å¤–è‹‘å†é–‹ç™ºã‚ãã‚Šä¼Šè—¤å¿ å•†äº‹ãŒç•°ä¾‹ã®é•·æ–‡ã®å£°æ˜ã‚’ç™ºè¡¨
- Gemma2-9Bã®SPPOãƒ¢ãƒ‡ãƒ«ã€AlpacaEvalã§ã‚‚ãƒ¡ãƒãƒ£ã‚¯ãƒãƒ£å‹ç‡é«˜ãã¦GPT-4Tã«åŒ¹æ•µã—ã¦ã‚‹ãã‚‰ã„ã ã‹ã‚‰ã¾ã‚Shaberi3ãƒ™ãƒ³ãƒã§7.9å–ã‚Œã¦ã‚‚ãŠã‹ã—ããªã„ã‘ã©ç•°å¸¸ã™ãã‚‹ã€€ by ã†ã¿ã‚†ãã•ã‚“
	- https://tatsu-lab.github.io/alpaca_eval/
- AIâ€™s $600B Question
	- https://www.sequoiacap.com/article/ais-600b-question/
	- the tech industry needs $600B in AI revenue to justify the money spent on GPUs and data centers.
	- OpenAI is the biggest AI pure play and is at $3.4B annual run rate. This feels like a bubble unless products worth buying show up.
- Gemma2-9B-it-SPPO-Iter3ã‚’Shaberi3è©•ä¾¡ã—ãŸã‚‰ãªã‚“ã¨ã‚¹ã‚³ã‚¢7.90ï¼ï¼ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1809215562008179163
	- ã‚«ã‚¬ãƒŸã‚«ãƒŸã•ã‚“ã«è©¦ã—ã¦ã£ã¦è¨€ã‚ã‚ŒãŸ
	- 9Bç¨‹åº¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯çµ¶å¯¾è¾¿ã‚Šç€ã‘ãªã„ãƒã‚ºã®å¢ƒåœ°ã«åˆ°é”ã—ã¦ã—ã¾ã£ã¦ã‚‹ï¼ã‚¹ã‚³ã‚¢ä¸Šã¯Qwen2-72Bï¼ˆ7.76ï¼‰è¶…ãˆã€Gemma2-27Bï¼ˆ7.88ï¼‰è¶…ãˆï¼Gemini1.5Proï¼ˆ8.01ï¼‰ã®ãƒãƒ§ã‚¤ä¸‹ï¼æµçŸ³ã«ãŸã¾ã’ãŸ
-  éå…¬å¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªClaudiaã‚’ä½¿ã£ã¦ã€Claude3ã¨Function Callingã‚’Unityã§å‹•ã‹ã™
	- https://note.com/361yohen/n/nbc4957231fe1
- The Transformers architecture clearly explained
	- https://x.com/rfeers/status/1809150250688639209
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- Should you finetune your LLM or just give relevant examples in the prompt? How many examples should you give for best performance?? If you give more will it hurt perf?? Does order of the examples matter!?
	- Large performance jumps when going from providing very few(1-5) examples(few-shot in-context learning - ICL) to providing many(100s-1000s) examples(many-shot ICL)
	- Show that many-shot ICL can overcome pre-training biases, perform comparably to supervised fine-tuning, and learn non-NLP prediction tasks.
- CodeInterpreterå›å‹æ‰‹ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªè‡ªåˆ†ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ã‚‹
	- https://x.com/lemilemilemio/status/1809250242468188288
- GraphRAG Advanced: Avoid Overspending with These Tipsã€€by MervinPraison
	- https://x.com/MervinPraison/status/1809279522891604249
- ä»Šå¾Œæ•°ã‚«æœˆã§Assistants APIã®ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã«æ¥ã‚‹äºˆå®šã®æ©Ÿèƒ½ãŒæ›¸ã‹ã‚Œã¦ã‚‹ã˜ã‚ƒã‚“ï¼
	- https://x.com/super_bonochin/status/1809355949565702542
	- ãƒ™ã‚¯ãƒˆãƒ«ã ã‘ã§ãªããƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åˆ©ç”¨ã—ãŸãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆAzure AI searchä½¿ã£ã¦ã‚‹ã‚‚ã‚“ã­ï¼‰
	- ã„ã‚ã‚†ã‚‹ç”»åƒRAGï¼ˆå›³è¡¨ã®å†…å®¹ã‚‚ãµã¾ãˆãŸRAGï¼‰
	- csvã‚„jsonlç­‰ã®æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹ã‚¯ã‚¨ãƒª
-  Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/abs/2405.15071
	- They found that the critical factor isn't the amount of data, but the ratio (Ï•) of inferred facts to atomic facts. Figure 2(a) illustrates this beautifully - higher Ï• values correlate with faster generalization. This challenges a lot of conventional wisdom about data requirements in deep learning.
	- The best part? They showed their fully grokked transformer outperforming state-of-the-art models like GPT-4-Turbo and Gemini-1.5-Pro on a complex reasoning task with a large search space. We're talking near-perfect accuracy where the big models barely beat random guessing.
-  FastEmbed
	- https://github.com/qdrant/fastembed
	- Fast, Accurate, Lightweight Python library to make State of the Art Embedding
- What is a "cognitive architecture"?
	- https://blog.langchain.dev/what-is-a-cognitive-architecture/
- Human Prompt Engineer VS AI Prompt Engineer? Who wins?
	- https://x.com/learnprompting/status/1809301301760537021
	- DPSy performed 40% better on a novel classification benchmark.
- extracted the full ~5000 token claude3.5sonnet
	- https://x.com/rahulgs/status/1809313740275454352
	- this is a great template for function calling / tool use
	- https://gist.github.com/1rgs/b31a1de86df9b9f1b295647d4d29dd45
	- artifacts: seem to be a fully in-context abstraction, model not finetuned for it
- 

## 24/7/1

ä»Šé€±ã‚‚ã„ã‚ã„ã‚ã‚ã£ã¦ãƒ‘ãƒ³ã‚¯æ°—å‘³ã§ã™ãŒã€GUILDã®æ·±æ´¥ã•ã‚“ãŒã„ã†ã‚ˆã†ã«æ¯é€±ãƒªã‚»ãƒƒãƒˆã•ã‚Œã¦ã‚‚è¿½ãˆã‚‹ã®ãŒç¶šã‘ã‚‹ã‚³ãƒ„ã‹ã‚‚ã€‚ä»Šé€±ã‚‚Anthropicã‹ã‚‰ã€Artifactã‚’ä½œã£ãŸã®ã¯ã‚¤ãƒ³ã‚¹ã‚¿ã‚°ãƒ©ãƒ å…±åŒå‰µæ¥­è€…ãŒjoinã—ã¦ï¼’ã‹æœˆã§ä½œæˆã¨ã®ã“ã¨ã€æ—¥æœ¬ã¸ã®é€²å‡ºã‚‚ã€AWS summit Japanå±•ç¤ºä¼šã§æ—¥æœ¬èªå¼·åŒ–ã‚’ã‚¢ãƒ”ãƒ¼ãƒ«ã—ãŸã‚Šã€è‡ªæ°‘å…šAIæˆ¦ç•¥ä¼šè­°ã§ã‚‚ã€6ï½18ã‹æœˆã®é–“ã§å‡ºã¦ãã‚‹æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ãŒç”£æ¥­ã‚’å¤‰é©ã™ã‚‹ã€ã„ã¾æº–å‚™ã—ãªã„ã¨ï¼ˆå›½ã¨ã—ã¦ã€ä¼æ¥­ã¨ã—ã¦ï¼‰æ­»ã«ã¾ã£ã›ã¨è„…ã—ãŸã‚Šã¨å¤§å¿™ã—ã€‚ Claudeã®projectæ©Ÿèƒ½ã‚‚ç›¸å½“ã‚„ã°ã„ã‚‰ã—ã„ã€‚Googleã‚‚ã€Gemini 1.5 ã§ã€å‡ºåŠ›ã‚’ JSON ã«å›ºå®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ã‹ã€Google AI Studioã‚„Gemini APIã§ã‚³ãƒ¼ãƒ‰ãŒå®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã¨ã‹ã€Artifactã‚’ã ã„ã¶æ„è­˜ã—ã¦ããŸã‚ˆã†ã ã€‚æ—¥æœ¬ã®LLMé–‹ç™ºã§ã¯ã€KARAKURI-LMãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ãªã©ã‚‚ã‚ã‚Šã¾ã—ãŸãŒã€Llama-3-ELYZA-JPãŒãƒªãƒªãƒ¼ã‚¹ã€70Bãƒ¢ãƒ‡ãƒ«ã¯æ—¥æœ¬èªã®ç”Ÿæˆèƒ½åŠ›ã«ãŠã„ã¦ã€ŒGPT-4ã€è¶…ãˆã€8Bã¯GPT-3.5 turboã‚’ä¸Šå›ã‚‹æ€§èƒ½ã¨ã®ã“ã¨ã€‚Googleã‹ã‚‰ã¯Gemma-2ã®27B & 9BãŒãƒªãƒªãƒ¼ã‚¹ã€27Bã£ã¦Llama-3-70Bè¶Šãˆã¨ã‹ã€9Bã¯ Qwen-2-72Bä¸¦ã¿ã®æ€§èƒ½ã¨ã‹ã€æ€§èƒ½çˆ†ä¸ŠãŒã‚Šã®èƒŒå¾Œã«ä½•ã‚‰ã‹ã®ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼ãŒã‚ã‚‹ã€ ã—ã£ã‹ã‚Šæƒ…å ±è¿½ã£ãŸæ–¹ãŒè‰¯ã•ãã†ã€‚Gemini Nanoã®Chromeæ­è¼‰ã¯Canaryç‰ˆã‚’ä½¿ãˆã°ã ã‚Œã§ã‚‚22GBç©ºããƒ‡ã‚£ã‚¹ã‚¯ã•ãˆã‚ã‚Œã°!ä½¿ãˆã‚‹ã¨ã®ã“ã¨ã€‚LLMã®å®‰å…¨æ€§ã«é–¢ã—ã¦ã¯ã€Antropicã‹ã‚‰ã¯ã€ŒConstitutional AIã€ã€åŸç†åŸå‰‡ã‚’ä¸ãˆã‚‹ã“ã¨ã§ã€è‡ªå·±è©•ä¾¡ã¨èª¿æ•´ã‚’è¡Œã†æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¨ã®ã“ã¨ã€‚ä¸€æ–¹ã€OpenAIã¯CriticGPTã‚’ç™ºè¡¨ã€ChatGPTã®å‡ºåŠ›çµæœã®è©•ä¾¡ã¨ã„ã†è©±ã ã‹ã‚‰ã€åŒç¤¾ãŒå‡ºã—ãŸLLMã®æŒ¯ã‚‹èˆã„ã‚’è¦å®šã™ã‚‹ä»•æ§˜æ›¸Model Specã¨ã‚‚é–¢é€£ã™ã‚‹æ°—ã‚‚ã™ã‚‹ãŒã€"AIãŒäººé–“ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«è³¢ããªã£ã¦ã‚‚ã€æ­£ã—ã„è¡Œå‹•ã«å ±é…¬ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£è¦–"ã®ç¬¬ï¼‘æ®µã ãã†ã ã€çµå±€OpenAIã‚‚Anthropicã‚‚LLMã®èª¬æ˜æ€§ã¨ã‹å®‰å…¨ç¢ºä¿ã¨ã„ã†é¢ã§ã¯ä¼¼ãŸã‚ˆã†ãªå‹•ãã‚’ã€åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã€ã™ã‚‹ã‚“ã ãªã€‚ãƒ¡ã‚¿ã‹ã‚‰ã¯visonã¨textã‚’çµ±åˆã—ãŸåˆã®LLMã¨ã„ã†ã“ã¨ã§Chameleonã®ç´¹ä»‹è¨˜äº‹ã¨ã‹ã‚‚ã‚ã‚Šã¾ã—ãŸãŒã€ãªã‚“ã¦ã£ãŸã£ã¦Llamaãƒ™ãƒ¼ã‚¹ã®LLMã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã£ã¦ã®ã¯é©šã„ãŸã€ã‚³ãƒ¼ãƒ‰æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã‚’è¡Œãˆã‚‹ã‚‰ã—ã„ã€ç¶šå ±ã‚’æœŸå¾…ã€‚Microsoftã‹ã‚‰ã¯ã€visonåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã§ã€WebGPUã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«å‹•ãFlorence-2ãŒç™ºè¡¨ã€ã“ã‚Šã‚ƒã€ç›£è¦–ã‚«ãƒ¡ãƒ©ã«ãƒ­ãƒ¼ã‚«ãƒ«LLMè¼‰ã‚‹ã‚ãƒ¼ã€‚Microsoftã®GraphRAGã®è¨˜äº‹ã€graphã‚’ä½¿ã‚ãªã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¨ã®æ¯”è¼ƒãŒé¢ç™½ã„ã€è©¦ã—ã¦ã¿ãŸã„ã¨ã“ã‚ã€‚NVIDIAã®ãƒ•ã‚¡ãƒ³CEOã€10å¹´ã‚‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰ã§è¬›æ¼”ã‚’ã¤ã¥ã‘ãŸã®ã‹ã€è¬›æ¼”å†…å®¹ã‹ã‚‰ã®ãƒ“ã‚¸ãƒã‚¹ã®å¼·ã•ã‚’åˆ†æã—ãŸãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ãŒé¢ç™½ã„ã€"In tech, if you aren't reinventing yourself, you are slowly dying"ã¦ã®ãŒæŸ“ã¿ã‚‹ã€‚ã—ã‹ã—NVIDIAä¸€å¼·ã‚‚å®‰æ³°ã§ã¯ãªã„ã€ã€ŒNVIDIAæœ€æ–°GPUã®20å€é€Ÿã„ã€å²ä¸Šæœ€é€Ÿã‚’è¬³ã†AIãƒãƒƒãƒ—ã€ŒSohuã€ã¨ã„ã†ã®ã¯ã€Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã®ã¿ã«ç‰¹åŒ–ã—ãŸè¨­è¨ˆã¨ã„ã†ã®ã ã‹ã‚‰ã€æ—¥æœ¬ã®PFNã®Mï¼®-coreã«ã‚‚å‹æ©Ÿã‚ã‚Šã€‚AIã®æ°‘ä¸»åŒ–ã¨ã„ã†ã‹æ™®åŠã«é–¢é€£ã—ã¦ã€IBMã«ã‚ˆã‚‹ã€è£½é€ ç¾å ´ã§ç¶™ç¶šçš„ãªãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã‚’æ¨é€²ã™ã‚‹ã«ã¯ã€ã€Œæ¥­å‹™çŸ¥è¦‹ã«è©³ã—ã„äººã€ã‚‚å¿…è¦ã¨ã‹ã€ä¾¡æ ¼ã‚³ãƒ ã§Difyã‚’ç¾å ´ã«å±•é–‹ã™ã‚‹è©±ã‚‚å‚è€ƒã«ãªã‚‹ã€‚ã¾ã‚ã€ç”ŸæˆAIï¼ˆç‰¹ã«LLM)ãªã‚“ã¦ã€Œåšå­¦ã®è–„å­¦ã€ãªã‚“ã¦å‰ã¶ã‚‹ã®ã¯ã‚„ã‚ãŸã»ã†ãŒè‰¯ã„ã§ã™ãŒã€‚ã€Œå·¨å¤§ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®LLMã¯RAGã‚’ä¸è¦ã«ã™ã‚‹ã®ã‹ï¼Ÿã€ã¨ã„ã†DeepMindã®è«–æ–‡ã€RAGä¸è¦è«–äº‰ã«ã¨ã©ã‚ã‹ã€ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®LLMã£ã¦ãªã‚“ã‚‰ã‹ã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã‚’èµ·ã“ã—ãã†ãªäºˆæ„Ÿã€‚ææ–™ç³»ã§ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ´»ç”¨ã‚„äº¤å·®ã¨çªç„¶å¤‰ç•°ã‚’åŒ–å­¦çŸ¥è­˜ã§å¾®èª¿æ•´ã—ãŸLLMã§åˆ†å­è¨­è¨ˆãªã©ã€ææ–™ã‚„åŒ–å­¦ç³»ã§ã®LLMã®æ´»ç”¨ã£ã¦ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã„ã¤ã‚‚é¢ç™½ã„ã€‚æ‚£è€…ã®æŒ¯ã‚‹èˆã„ã‚’LLMã§æ¨¡æ“¬ã—ã¦åŒ»è€…ã®è¨“ç·´ã«ä½¿ã†ã¨ã„ã†PATIENT-Î¨ã‚‚é¢ç™½ã„LLMã®å¿œç”¨ã ã€‚å²¡é‡åŸã•ã‚“ãŒç´¹ä»‹ã—ãŸã€è¨€èªã¯æ€è€ƒã‚ˆã‚Šã‚‚ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é“å…·ã§ã‚ã‚‹ã¨ã„ã†ä¸»å¼µã®Natureè«–æ–‡ã€è¨€èªãŒæ€è€ƒã‚’å½¢ä½œã‚‹ã¨ã„ã†è€ƒãˆæ–¹ã¨çœŸé€†ãªã‚“ã ã‘ã©ã€LLMã£ã¦ã©ã†é ‘å¼µã£ã¦ã‚‚ã—ã‚‡ã›ã‚“ã¯æ©Ÿæ¢°äººå½¢(Anthropic)ã¨ã„ã†ã“ã¨ãªã®ã‹ã€‚ã¨ã„ã†ã¨ã“ã‚ã§ã€Anthropicã«å§‹ã¾ã‚ŠAnthropicã§çµ‚ã‚ã£ã¦ã€ãŠå¾ŒãŒã‚ˆã‚ã—ã„ã‚ˆã†ã§ã€‚

- å°ç”ºå…ˆç”Ÿã®ã€ã€Œè¨€èªç³»AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®é€²ã‚æ–¹ã€ãŒã‚ˆã„ã‚‰ã—ã„
	- https://x.com/mr_bay_area/status/1804689914291957983
- Questions at academic conferences
	- https://x.com/jayvanbavel/status/1801961592654815489
-  LLMatDesign: Autonomous Materials Discovery with Large Language Models
	- https://arxiv.org/abs/2406.13163
	- LLMã«ã‚ˆã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è«–æ–‡
	- ãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—ã®è¨ˆç®—ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨LLMã‹ã‚‰AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã€‚ã€Œãƒãƒ³ãƒ‰ã‚®ãƒ£ãƒƒãƒ—1.4eVã®ææ–™ã¯ï¼Ÿã€ã ã‘ã§ãªãã€ŒBaã‚’ä½¿ç”¨ã—ãªã„ã§æŒ‡å®šã®ææ–™ã‚’1.4eVã«ãªã‚‹ã‚ˆã†æ”¹è‰¯ã—ã¦ã€ãªã©ã®æŒ‡ç¤ºã‚‚ã†ã¾ãã„ãã‚ˆã†ã§ã™ã€‚
- Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?
	- https://arxiv.org/abs/2406.13121
	- Google DeepMindã«ã‚ˆã‚‹å ±å‘Šã€‚
	- ã€Œå·¨å¤§ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®LLMã¯RAGã‚’ä¸è¦ã«ã™ã‚‹ã®ã‹ï¼Ÿã€ã¨ã„ã£ãŸè­°è«–ãŒæ´»ç™ºåŒ–ã™ã‚‹ä¸­ã€Geminiã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ¿å…¥ã—ã¦RAGã¨æ€§èƒ½ã‚’æ¯”è¼ƒã™ã‚‹å®Ÿé¨“ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚
	- ãã®çµæœã€ã‚„ã¯ã‚Šãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆLLMã¯ä¸€å®šã®ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆã‚’ã‚‚ãŸã‚‰ã™å¯èƒ½æ€§ã‚’ç¤ºå”†ã—ã¦ã„ã¾ã™ã€‚ 
	- ã•ã‚‰ã«RAGã ã‘ã§ãªãText to SQLã‚¿ã‚¹ã‚¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚‚èª¿æŸ»ã•ã‚Œã¦ã„ã¾ã™ã€‚
- This is fast. Chrome running Gemini locally on my laptop. 2 lines of code.
	- https://x.com/mortenjust/status/1805190952358650251
-  Claudeâ€™s Constitution
	- https://www.anthropic.com/news/claudes-constitution
	- Anthropic Constitutional AI ï¼ˆæ†²æ³•çš„AIï¼‰ã‚’å°å…¥ã€€by   AIğ•ã‚µãƒˆã‚·ã•ã‚“
		- https://x.com/AiXsatoshi/status/1804999143586402460
		- ã€ŒConstitutional AIã€ã¯ã€AIãƒ¢ãƒ‡ãƒ«ãŒè‡ªå·±è©•ä¾¡ã¨èª¿æ•´ã‚’è¡Œã†æ–°ã—ã„ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•
		- å›½é€£ã®ä¸–ç•Œäººæ¨©å®£è¨€ãªã©ã«åŸºã¥ãåŸå‰‡ã‚’å‚ç…§ã€äººé–“ã®ä»‹å…¥ã‚’æ¸›ã‚‰ã™ã“ã¨ã§æœ‰å®³ãªå‡ºåŠ›ã‚’é¿ã‘ã‚‹AIã‚’æ§‹ç¯‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ã¨ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§ãŒå‘ä¸Šã™ã‚‹
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹Instruction Tuningãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸã€‚by ã¯ã¡ã•ã‚“
	- https://x.com/CurveWeb/status/1805232501323112599
	- Timeseries-PILEã€Phi-3-mini-4k-instructã‚’ä½¿ã£ã¦ã„ã‚‹ã®ã§MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã§ã™ã€‚ ã¨ã‚Šã‚ãˆãšsingle turnã§160K recordsã‚ã‚Šã¾ã™ã€‚multi turnã‚‚ä½œæˆä¸­ã§ã™ã€‚
	- https://huggingface.co/datasets/HachiML/Timeseries-QA
- ã‚¤ãƒ³ã‚¹ã‚¿ã®å…±åŒå‰µæ¥­è€…ãŒClaudeãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒ¼ãƒ ã‚’ç‡ã„ãŸçµæœã€ArtifactãŒèª•ç”Ÿã€‚ãã®é–“ã‚ãšã‹2ãƒ¶æœˆ
	- https://x.com/Haruki_Sonehara/status/1805111108748886440
	- ãƒãƒ£ãƒƒãƒˆUIã¯è‡ªç”±ã™ãã‚‹åˆ†ä½¿ã„æ‰‹ã®è² è·ãŒé«˜ã„ã€‚è‰¯ã„è³ªå•ãŒã§ãã‚‹äººã¯ã„ã„ãŒã€ä¸–ã®ä¸­ãã†å¤šããªã„ã€‚ 
	- Anthropicã¯ãã®ã“ã¨ã«æ°—ã¥ã„ã¦ã€ã‚¤ãƒ³ã‚¹ã‚¿ã®å…±åŒå‰µæ¥­è€…ã‚’CPOã¨ã—ã¦ãƒ˜ãƒƒãƒ‰ãƒãƒ³ãƒˆã—ãŸã€‚ 
	- ãƒãƒ£ãƒƒãƒˆã¨ã¯é•ã†åˆ‡ã‚Šå£ã®LLMãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãŒã‚‚ã£ã¨å¢—ãˆã‚‹ã€‚ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®çš†ã•ã‚“æœªæ¥ã‚’ä½œã‚‹å‡ºç•ªã§ã™ï¼
-  ä¸‰è±é›»æ©ŸãŒClaude 3æ´»ç”¨ã§ã€Œå·¥æ•°4å‰²æ¸›ã€ã€ä»•æ§˜æ›¸ã®å›³è¡¨è§£æã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãŒå¨åŠ›
	- https://xtech.nikkei.com/atcl/nxt/column/18/02875/062000004/
	- ã™ã”ã„ã­ã€å®Ÿéš›ã©ã†ãªã®ã‹æ°—ã«ãªã‚‹ / â€œä¸‰è±é›»æ©ŸãŒClaude 3æ´»ç”¨ã§ã€Œå·¥æ•°4å‰²æ¸›ã€ã€ä»•æ§˜æ›¸ã®å›³è¡¨è§£æã«ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãŒå¨åŠ›â€
- ã€ŒNVIDIAæœ€æ–°GPUã®20å€é€Ÿã„ã€å²ä¸Šæœ€é€Ÿã‚’è¬³ã†AIãƒãƒƒãƒ—ã€ŒSohuã€
	- https://ascii.jp/elem/000/004/206/4206328/
	- **Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã®ã¿ã«ç‰¹åŒ–ã—ãŸè¨­è¨ˆã‚’æ¡ç”¨ã—ãŸ**ã“ã¨ã ã€‚ã“ã®å°‚é–€åŒ–ã«ã‚ˆã‚Šã€Sohuã¯æ±ç”¨GPUã¨æ¯”ã¹ã¦å¤§å¹…ãªæ€§èƒ½å‘ä¸Šã‚’å®Ÿç¾
	- 8å°ã®Sohuã‚µãƒ¼ãƒãƒ¼ï¼‘å°ã§160å°ã®H100ã‚’ãƒªãƒ—ãƒ¬ã‚¤ã‚¹ã§ãã‚‹ã‚“ã ã£ã¦ï¼ï¼Sohux8ã‚µãƒ¼ãƒãƒ¼ã¯Llama-70Bã‚’50ä¸‡tpsã§è¶…çˆ†é€Ÿå‡¦ç†ï¼B200x8ã®10å€ã®é€Ÿåº¦ï¼ã—ã‹ã‚‚B200ã‚ˆã‚Šå®‰ã„
- Anthropicã¯æ—¥æœ¬æ”¿åºœã¸6-18ãƒ¶æœˆä½å†…ã€ã¤ã¾ã‚Š2024å¹´æœ«ã‹ã‚‰2025å¹´æœ«ã¾ã§ã«æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ãŒç”£æ¥­ã‚’æ€¥é€Ÿã«å¤‰é©ã™ã‚‹ã¨äºˆæƒ³ã—ã¦ã„ã‚‹ã¨ãƒ—ãƒ¬ã‚¼ãƒ³ã€‚
	- ã“ã‚Œã¯å¤§ããªã“ã¨ã€‚æ”¿åºœã¸è¨€ã†ã¨ã„ã†ã“ã¨ã¯ç›¸å½“è‡ªä¿¡ãŒã‚ã‚‹è¨¼æ‹ ã ã¨æ„Ÿã˜ã‚‹ã€‚
	- https://x.com/bioshok3/status/1805649281938018318
	- è‡ªæ°‘å…šAIã®é€²åŒ–ã¨å®Ÿè£…ã«é–¢ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ãƒ ã« anthoropicã®ãƒ—ãƒ¬ã‚¼ãƒ³
		- https://note.com/komori_takuo/n/n8433de4720a0
		- ç§ãŸã¡ã¯ã€6ï½18 ãƒ¶æœˆ ä»¥å†…ã«æœ€å…ˆç«¯ã®ãƒ¢ãƒ‡ãƒ«ãŒ æ–°ã—ã„èƒ½åŠ›ã§ç”£æ¥­ã‚’ æ€¥é€Ÿã«å¤‰é©ã™ã‚‹ã¨ äºˆæƒ³ã—ã¦ã„ã¾ã™
		- ç§ãŸã¡ã®ãŠå®¢æ§˜ã¯ã€ å°†æ¥ã®ç”»æœŸçš„ãªé€²æ­©ã« å‚™ãˆã¦æœ€å¤§é™ã®æº–å‚™ã‚’ ã™ã‚‹ãŸã‚ã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ ã‚’æ€¥é€Ÿã«æ§‹ç¯‰ã—ã¦ã„ã¾ã™
		- æ–°ã—ã„ç”»æœŸçš„ãªé€²æ­©ã‚’å¾…ã¡ ç«‹ã¡æ­¢ã¾ã£ã¦ã„ã‚‹ä¼æ¥­ã¯ã€ ã™ã§ã« 4ï½8 ãƒ¶æœˆé…ã‚Œã¦ ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- Claudeã®projectæ©Ÿèƒ½ã‚„ã°ã„ã€‚
	- https://x.com/onokoro48/status/1805810323473203366
	- ã¯ã˜ã‚ã¦æ•™è‚²ã«ä½¿ãˆãã†ã€‚ æ•™ç§‘æ›¸ã‚’èª­ã¿è¾¼ã¾ã›ã¦ãŠã„ã¦ã€ ãƒãƒ³å‡ºã—ã§å•é¡Œæ¼”ç¿’ãƒã‚·ãƒ³ãŒã§ããŸã€‚ å‹æ‰‹ã«Artifactsã¨é€£å‹•ã—ã¦ã‚‹ã—ã€‚
- Meta Chameleon: a new mixed-modal research model from Meta FAIR.
	- https://x.com/AIatMeta/status/1805705668567220261
	- The 7B & 34B safety tuned models weâ€™ve released can take any combination of text and images as input and produce text outputs using a new early fusion approach.
	- While some LLMs have separate image and text encoders or decoders, **Chameleon is one of the first publicly released approaches using a single unified architecture.**
	- https://arxiv.org/abs/2405.09818
- GPT-4oãƒœã‚¤ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®ã‚¢ãƒ«ãƒ•ã‚¡ç‰ˆãƒ­ãƒ¼ãƒ³ãƒã€å»¶æœŸãŒç¢ºå®š
	- https://x.com/ctgptlb/status/1805734395833467342
-  KARAKURI-LMãƒ¢ãƒ‡ãƒ«ï¼ˆkarakuri-lm-8x7b-instruct-v0.1-Q4_K_M.ggufï¼‰ã®ELYZA-tasks-100ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
	- https://hamaruki.com/llama-cpp-wandb-karakuri-lm-elyza-tasks-performance/
- ã‚·ãƒ¼ã‚ºãƒ³ãŒæ•°ãƒ¶æœˆã”ã¨ã«ãƒªã‚»ãƒƒãƒˆã•ã‚Œã€å‰ä¾‹ãŒå…¨éƒ¨ãªããªã‚‹ç’°å¢ƒå¤§å¥½ãã€€ by æ·±æ´¥ã•ã‚“
	- https://x.com/fladdict/status/1805421726001774745
-  PATIENT-Î¨: Using Large Language Models to Simulate Patients for Training Mental Health Professionals
	- https://arxiv.org/abs/2405.19660
	- We introduce Patient-Î¨ğŸ¤–, where we integrate cognitive modeling with LLMs to simulate patients for training mental health professionals.
- Claude 3.5 Sonnetã®Breaking News from Chatbot Arena
	- https://x.com/lmsysorg/status/1805329822748655837
	- Claude 3.5 Sonnet has just made a huge leap, securing the #1 spot in Coding Arena, Hard Prompts Arena, and #2 in the Overall leaderboard.
-  ELYZAã€GPT-4ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã®æ—¥æœ¬èªLLMã‚’é–‹ç™º
	- https://www.watch.impress.co.jp/docs/news/1603370.html
	- ã€ŒLlama 3ã€ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸ700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã€ŒLlama-3-ELYZA-JP-70Bã€ã¨80å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã€ŒLlama-3-ELYZA-JP-8Bã€ã‚’é–‹ç™ºã—ã€æ€§èƒ½ã‚’å…¬é–‹ã—ãŸã€‚70Bãƒ¢ãƒ‡ãƒ«ã¯ã€æ—¥æœ¬èªã®ç”Ÿæˆèƒ½åŠ›ã«ãŠã„ã¦ã€ŒGPT-4ã€è¶…ãˆã‚’é”æˆã—ãŸã¨ã„ã†ã€‚
	- 8Bãƒ¢ãƒ‡ãƒ«ã¯ã€Metaã®Llama-3-8Bã‚’ãƒ™ãƒ¼ã‚¹ã«äº‹å¾Œå­¦ç¿’(æ—¥æœ¬èªè¿½åŠ äº‹å‰å­¦ç¿’ãƒ»æŒ‡ç¤ºå­¦ç¿’)ã‚’å®Ÿæ–½ã€‚ã€ŒGPT-3.5 turboã‚’ä¸Šå›ã‚‹æ€§èƒ½
- ã€ŒGPT-4ã€ã‚’ä¸Šå›ã‚‹æ—¥æœ¬èªæ€§èƒ½ã®LLMã€ŒLlama-3-ELYZA-JPã€ã‚’é–‹ç™ºã—ã¾ã—ãŸ
	- https://note.com/elyza/n/n360b6084fdbd
	- 70Bãƒ‡ãƒ¢
		- https://elyza.ai/lp/elyza-llm-for-jp
	- 8Bãƒ¢ãƒ‡ãƒ«
		- https://huggingface.co/collections/elyza/llama-3-elyza-jp-667a311d51c8952e07778ecc
- Meeting Information Seeking Dialogs dataset (MISeD)
	- https://x.com/GoogleAI/status/1805654929182199832
	- https://research.google/blog/efficient-data-generation-for-source-grounded-information-seeking-dialogs-a-use-case-for-meeting-transcripts/
- Microsoft presents EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees
	- https://arxiv.org/abs/2406.16858
	- 20%-40% faster than EAGLE-1 (i.e. 3.05x - 4.26x faster than the baseline) - Ensures that the distribution of the generated text remains unchanged
- claude 3.5 makes my graphs from excel screenshots.
	- https://x.com/RubenHssd/status/1805609472582144201
	- You just turn on "Artifacts", and prompt it to stick to your brand color. Here's how:
- Florence-2, the new vision foundation model by Microsoft, can now run 100% locally in your browser on WebGPU, thanks to Transformers.js!
	- https://huggingface.co/spaces/Xenova/florence2-webgpu
	- Once loaded, the model (340 MB) will be cached and reused when you revisit the page.
- NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF
	- https://x.com/laniusdev/status/1805658195450380557
	- Boys, I think I've found a locally run model that can replace ChatGPT for me. It's sooo fast and passed my esoteric coding suggestion capability test.
- How LLMs work, explained with visuals:
	- https://x.com/akshay_pachaar/status/1805586547527631181
- Self-Play models finally got released! | SPPO Llama-3-8B finetune performs extremely strong strong on AlpacaEval 2.0
	- https://www.reddit.com/r/LocalLLaMA/comments/1doxvdi/selfplay_models_finally_got_released_sppo/?onetap_auto=true&one_tap=true
	- SPPOè«–æ–‡ã§ã€ŒSPPOã—ãŸLlama-3-8Bã®å‹ç‡ãŒGPT-4è¶…ãˆï¼ã€ã¨ã‹ä¸»å¼µã—ã¦ã¦ã€Œã‚¦ã‚½ä»˜ã‘ï¼ã ã£ãŸã‚‰ãƒ¢ãƒ‡ãƒ«å‡ºã›ã‚„ï¼ã€ã¿ãŸã„ãªè©±ã ã£ãŸã®ãŒã¤ã„ã«ãƒ¢ãƒ‡ãƒ«ãŒãŠå‡ºã—ã•ã‚ŒãŸã‚‰ã—ã„
- äººã«ã¨ã£ã¦è¨€èªã¯æ€è€ƒã‚ˆã‚Šã‚‚ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é“å…·ã§ã‚ã‚‹ã¨ã„ã†ä¸»å¼µã€€by å²¡é‡åŸã•ã‚“
	- https://www.nature.com/articles/s41586-024-07522-w
	- å¤±èªç—‡ã‚„è¨€èªã‚’ç²å¾—ã—ã¦ã„ãªã„å ´åˆã§ã‚‚æ€è€ƒèƒ½åŠ›ã¯ç²å¾—ã§ãã€é€†ã«è¨€èªèƒ½åŠ›ãŒå®Œå…¨ã«ã‚ã£ã¦ã‚‚æ€è€ƒèƒ½åŠ›ã«å•é¡ŒãŒã‚ã‚‹å ´åˆãŒã‚ã‚Šã€è¨€èªã¯æ€è€ƒã«ã¨ã£ã¦ååˆ†æ¡ä»¶ã§ã‚‚å¿…è¦æ¡ä»¶ã§ã‚‚ãªã„ã€‚ 
	- è¨€èªã¯å˜ãªã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã§ã‚ã‚Šã€å­¦ç¿’å¯èƒ½ã«ã§ãã‚‹ã‚ˆã†ã«å˜ç´”ã§ã‚ã‚‹ã“ã¨ã¨ã€å¤šãã®æƒ…å ±ã‚’åŠ¹ç‡çš„ã«ä¼ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã§é€²åŒ–ã—ã¦ããŸã€‚
	- æ§˜ã€…ãªè¨€èªå‡¦ç†ã€æ€è€ƒå‡¦ç†ã®è„³å†…æ´»å‹•ã‚’ã¿ã¦ã‚‚è¨€èªã¨æ€è€ƒã¯è„³å†…ã§åˆ¥ã€…ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å‡¦ç†ã•ã‚Œã¦ã„ã‚‹ã€‚LLMã‹ã‚‰ã‚‚è¨€èªèƒ½åŠ›ã‚’ãŸã¨ãˆç²å¾—ã§ããŸã¨ã—ã¦ã‚‚æ€è€ƒèƒ½åŠ›ã®æ”¹å–„ã«ã¯å¿…ãšã—ã‚‚ç¹‹ãŒã‚‰ãªã„ã¨ã„ã†ç¤ºå”†ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã€‚
	- äººã§ç‰¹ã«ç™ºé”ã—ãŸé€£åˆçš®è³ªã¯è¨€èªé ˜åŸŸã‚‚å«ã‚€ãŒãã‚Œä»¥å¤–ã®æ€è€ƒèƒ½åŠ›ï¼ˆä¾‹ãˆã°multiple demand networkï¼‰ã‚‚åŒæ™‚ã«ç™ºé”ã—ã¦ãŠã‚Šã€è¨€èªã‹ä½•ã‹ç”±æ¥ã§ã¨ã„ã†ã‚ˆã‚Šã€ã“ã‚Œã‚‰ãŒåŒæ™‚ä¸¦åˆ—ã§ç™ºé”ã—ãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹
-  Efficient Evolutionary Search Over Chemical Space with Large Language Models
	- https://arxiv.org/abs/2406.16976
	- LLMã«ã‚ˆã‚‹æœ€é©åŒ–ã®è«–æ–‡ã€‚ã€€by æ¨ªå±±ã•ã‚“
	- éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ãŠã‘ã‚‹äº¤å·®ã¨çªç„¶å¤‰ç•°ã‚’åŒ–å­¦çŸ¥è­˜ã§å¾®èª¿æ•´ã—ãŸLLMã§åˆ†å­è¨­è¨ˆã‚’è¡Œã†ã¨ã€å¾“æ¥ã‚ˆã‚Šæ—©ãæœ€é©è§£ã«ãŸã©ã‚Šç€ãã“ã¨ãŒåˆ†ã‹ã£ãŸãã†ã§ã™ã€‚ãƒ©ãƒ³ãƒ€ãƒ ã§ãªãåŒ–å­¦ã‚’è€ƒæ…®ã—æœ€é©åŒ–æ“ä½œãŒã§ãã‚‹ç‚¹ãŒãƒã‚¤ãƒ³ãƒˆã€‚
	- LLMã®ä½¿ã„æ–¹ãŒã†ã¾ã„ã€‚
- Gemini Nanoã€åŠã³WebGUIã€éå°è©•ä¾¡ã—ã¦ã¾ã—ãŸ
	- https://x.com/webbigdata/status/1806222156852052478
	- Chromeã®Canaryç‰ˆã¨è¨€ã£ã¦ã€æ¯æ™©ã®ã‚ˆã†ã«æ›´æ–°ã•ã‚Œã‚‹Î±ç‰ˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã¡ã‚‡ã£ã¨ã—ãŸè¨­å®šã‚’ã™ã‚Œã°å³ä½¿ãˆã¾ã—ãŸ
	- æ³¨æ„ç‚¹ã¯å°‘ãªãã¨ã‚‚å¿…è¦æ¡ä»¶ã¨ã—ã¦ãƒ‡ã‚£ã‚¹ã‚¯ã«22GBã®ç©ºãå®¹é‡ãŒå¿…è¦ã¨ã®äº‹ã§ã™ã€‚ç¾æ™‚ç‚¹ã§ã¯å®Ÿéš›ã«ã¯ãã“ã¾ã§å æœ‰ã•ã‚Œã¾ã›ã‚“ãŒã€å°†æ¥çš„ã«ã‚‚ã†å°‘ã—å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚’è¦‹æ®ãˆã¦ã„ã‚‹ã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“
- Gemini 1.5 ã§ã€å‡ºåŠ›ã‚’ JSON ã«å›ºå®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output
	- ä»Šã¾ã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­ã§æŒ‡å®šã™ã‚‹ã‚ˆã†ãªæ‰‹æ³•ã¨ã¯é•ã„ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä¸­ã§æŒ‡å®šã‚’ã—ã¦æŠ•ã’ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šå‡ºåŠ›ãŒç¢ºå®Ÿã«æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ãªã‚‹ã€‚ "responseMimeType": "application/json"
- OpenAIãŒæ–°å‹ã®GPTã€ŒCriticGPTã€ã‚’å…¬é–‹ã—ã¾ã—ãŸ by ä»Šäº•ã•ã‚“
	- https://x.com/ImAI_Eruel/status/1806376950455554092
	- ChatGPTä»¥æ¥åˆã®ãƒŠãƒ³ãƒãƒ¼ã‚·ãƒªãƒ¼ã‚ºã§ã¯ãªã„å¤‰åŒ–çƒãªGPTã®ç™ºè¡¨ã§ï¼ŒLLMã®å¼·åŒ–å­¦ç¿’ã«åˆ©ç”¨ã™ã‚‹GPTã®ã‚ˆã†ã§ã™ï¼
	-  Finding GPT-4â€™s mistakes with GPT-4
	- https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/
- AIãŒäººé–“ã‚ˆã‚Šã‚‚ã¯ã‚‹ã‹ã«è³¢ããªã£ã¦ã‚‚ã€æ­£ã—ã„è¡Œå‹•ã«å ±é…¬ã‚’ä¸ãˆã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªç›£è¦–ãŒä»Šå¾Œå¿…è¦ã«ãªã‚‹ã€‚
	- https://x.com/bioshok3/status/1806378837334503786
	- OpenAIã¯ä»Šå›ãã®ä¸€æ­©ã¨ãªã‚‹GPT-4ãƒ™ãƒ¼ã‚¹ã®CriticGPTã‚’é–‹ç™ºã€‚ ChatGPTã®ã‚³ãƒ¼ãƒ‰å‡ºåŠ›ã®ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡ºã§ãã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã¦ã„ã‚‹ã€‚
- è£½é€ ç¾å ´ã§ç¶™ç¶šçš„ãªãƒ‡ãƒ¼ã‚¿æ´»ç”¨ã‚’æ¨é€²ã™ã‚‹ãŸã‚ã«å¿…è¦ãªã“ã¨
	- https://x.com/Nurruttan/status/1806098781542437239
	- æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¤‰ãˆã‚‹ãŸã‚ã«ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚’æ´»ç”¨ã—ã‚ˆã†ã¨ã™ã‚‹å–ã‚Šçµ„ã¿ã¯å¤šã€…ã‚ã‚‹ã‚ˆã€‚ 
	- ãã®ãŸã‚ã«å¿…è¦ãªã®ã¯ã€Œãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹åŠ›ã€ã ã‘ã§ãªãã¦ã€ã€Œæ¥­å‹™çŸ¥è¦‹ã«è©³ã—ã„äººã€ã‚‚å¿…ãšå¿…è¦ã«ãªã‚‹ã‚ˆã€‚ 
	- å®Ÿéš›ã«ã©ã®ã‚ˆã†ã«æ¥­å‹™ã‚’å¤‰ãˆã‚‹ã‹ï¼Ÿãã“ã«ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚’ã©ã†ä½¿ã†ã‹ï¼Ÿã‚’ã‚»ãƒƒãƒˆã§è€ƒãˆã‚‹ã“ã¨ãŒå¿…è¦ã ã‹ã‚‰ã­ã€‚
- Google AI Studioã§ã‚³ãƒ¼ãƒ‰ãŒå®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹
	- https://x.com/YoheiN2023/status/1806238104979644481
	- å³ä¸‹ã®Code executionã®ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã‚‹ã¨è©¦ã›ã¾ã™ã€‚å…¨ç„¶æ°—ã¥ã‹ãªã‹ã£ãŸâ€¦
- Gemma-2 27B & 9B release! by lmsys.org
	- https://x.com/lmsysorg/status/1806369224895647757
	- Gemma-2 was tested in the Arena under the codename "*late-june-chatbots" and now out of stealth. Its early result matches the best open models (Llama-3-70B, Nemotron-340B) with only 27B parameters!
	- Impressively, Gemma-2-9B is ranked as high as Qwen-2-72B. The rate of improvement is fast.
- Google AI Studio ã§ Gemma 2 ã‚’ãŠè©¦ã—ä¸­ã€‚
	- https://aistudio.google.com/app/prompts/new_chat
- ã¨ã“ã‚ã¦ã‚“ã•ã‚“ã€çµŒç”£çœã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã€‚
	- https://www.meti.go.jp/shingikai/mono_info_service/digital_jinzai/021.html
	- https://x.com/tokoroten/status/1806576954692530385
-  Gemini API ã® Code Execution by ã†ã¿ã‚†ãã•ã‚“
	- https://note.com/npaka/n/n7fff64088a9e?sub_rt=share_h
	- ã€Œ**Code Execution**ã€ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒPythonã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ã€ŒGoogle AI Studioã€ã‚„ã€ŒGemini APIã€ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚
	- ä»®æƒ³ãƒã‚·ãƒ³ä¸Šã§NumPyã‚„SimPyãªã©ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã§ãã¾ã™ãŒã€è¿½åŠ ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œã¯ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã§æœ‰åŠ¹åŒ–ã§ãã€ãƒãƒ£ãƒƒãƒˆã§ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ã€‚å®Ÿè¡Œç’°å¢ƒã«ã¯30ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãªã©ã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚
- ãƒ¡ã‚¿ãŒLlamaãƒ™ãƒ¼ã‚¹ã®LLMã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã‚’ã‚ªãƒ¼ãƒ—ãƒ³ãƒªãƒªãƒ¼ã‚¹ã€‚
	- https://x.com/umiyuki_ai/status/1806380265041973349
	- ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ã¨æœ€é©åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¦ãã‚Œã‚‹ã¨ã‹ã€‚ã‚ã¨ãƒã‚¤ãƒŠãƒªã‹ã‚‰é€†ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã§ãã‚‹ï¼ˆç²¾åº¦45%ï¼‰ã¨ã‹ã€‚
	- https://prompthub.info/21476/
	- Meta Large Language Model Compilerã‚’å°å…¥ã—ã€ã‚³ãƒ¼ãƒ‰æœ€é©åŒ–ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã€‚
	- LLVMä¸­é–“è¡¨ç¾ï¼ˆIRï¼‰ã¨ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚³ãƒ¼ãƒ‰ã®5460å„„ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è©³ç´°ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã¦ãŠã‚Šã€ã‚³ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºæœ€é©åŒ–ã‚„ã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚³ãƒ¼ãƒ‰ã®æ­£ç¢ºãªå¤‰æ›ã‚’å®Ÿè¡Œã€‚
	- ä¼çµ±çš„ãªè‡ªå‹•ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã®77%ã®æœ€é©åŒ–æ½œåœ¨èƒ½åŠ›ã‚’é”æˆã—ã€ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã§Code Llamaã‚„GPT-4 Turboã‚ˆã‚Šã‚‚å„ªã‚ŒãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚
- Gemma 2 is officially here!
	- https://blog.google/technology/developers/google-gemma-2/
- gemman2 demo on HF
	- https://huggingface.co/spaces/huggingface-projects/gemma-2-9b-it
	- Community is most welcome to do the vibe evals themselves at:
- Google's Gemma 2 models are here! Available in 2 sizes: by ollama
	- https://x.com/ollama/status/1806342805905616983
- AISI Japanã®ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ãŒå®Œæˆã—ã¦ã„ã‚‹
	- https://aisi.go.jp/international/
- MicrosoftãŒææ¡ˆã—ã¦ã„ã‚‹GraphRAG
	- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/
	- https://x.com/A7_data/status/1806231239147364485
	- LLMã§ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•ä½œæˆ 
	- è¤‡é›‘ãªè³ªå•ã«ã‚‚å¯¾å¿œå¯èƒ½ 
	- ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚ˆã‚Šä¸€è²«ã—ã¦è‰¯ã„æ€§èƒ½ã‚’ç™ºæ®
- Buried in 10 years of Jensen Huang's Stanford talks are the secrets to building the most valuable tech company in the world.
	- https://x.com/JasonShen/status/1806357605343691053
	- In tech, if you aren't reinventing yourself, you are slowly dying
- Colab Pro and Pro+ now support Workspace organizations!
	- https://x.com/GoogleColab/status/1806099465604046928
- Dive into llama-agents with this notebook showing how to build an agentic RAG service!
	- https://github.com/run-llama/llama-agents/blob/main/examples/agentic_rag_toolservice.ipynb
- ã„ã‚ˆã„ã‚ˆLangChainã‚‚ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒä½œã‚Œã‚‹LangGraphã‚’ç™ºè¡¨â†“
	- https://x.com/gijigae/status/1806701809269866990
	- LangChainã¨æ±ºåˆ¥ã—ç‹¬è‡ªã®é“ã‚’é¸ã‚“ã Difyã®åˆ¤æ–­ã¯æ­£ã—ã‹ã£ãŸã¨æ€ã†ã€‚DifyãŒç›®æŒ‡ã—ã¦ã‚‹ä¸–ç•Œã¯è¡¨ã«å‡ºã¦ã‚‹ã“ã¨ã‚ˆã‚Šãšãƒ¼ã£ã¨å¤§ãã„ã€‚
- ã‚«ã‚«ã‚¯ã‚³ãƒ ãŒå…¬é–‹ã—ã¦ã„ã‚‹ã€ŒDifyã®å°å…¥äº‹ä¾‹ç´¹ä»‹ã€è³‡æ–™ãŒæœ‰ç›Š
	- https://speakerdeck.com/tokita_kakaku/quan-she-de-nasheng-cheng-aihuo-yong-puratutohuomutositeno-difynodao-ru-shi-li-shao-jie
	- å…¨ç¤¾å°å…¥ã«è‡³ã‚‹ã¾ã§ã®æ´»ç”¨ãƒ•ã‚§ã‚¤ã‚ºã”ã¨ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚„ä¼æ¥­ç›®ç·šã®èª²é¡Œã€å®Ÿéš›ã«ä½œæˆã—ãŸã‚¢ãƒ—ãƒªã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¾ã§æ²è¼‰ã—ã¦ãŠã‚Šå°‘ã—ã§ã‚‚æ´»ç”¨ã«èˆˆå‘³ãŒã‚ã‚‹äººã¯éå¸¸ã«å‹‰å¼·ã«ãªã‚‹
- ã¿ã‚“ãªåœ°ç„ã§æ—¥æœ¬ã¯æ„å¤–ã«ã¾ã—ãªåœ°ç„
	- https://x.com/narita_yusuke/status/1803050919304781958
	- ã“ã“5å¹´å¼±ã®G7è«¸å›½ã‚’æ¯”ã¹ã¦ã¿ã‚‹ 
	- 1) æ—¥æœ¬ã¯ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ãŒåœ§å€’çš„ã«ä½ã„ 
	- 2) å®Ÿè³ªGDPæˆé•·ç‡ã¯çœŸã‚“ä¸­ãã‚‰ã„ã€‚ãƒ‰ã‚¤ãƒ„ãƒ»ã‚¤ã‚®ãƒªã‚¹ãƒ»ãƒ•ãƒ©ãƒ³ã‚¹ã‚ˆã‚Šä¸Š
- ã‚½ãƒ•ãƒˆé–‹ç™ºè€…ã®æ±‚äººãŒã‚¢ãƒ¡ãƒªã‚«ã§æ¿€æ¸›ã€‚
	- https://x.com/hiyori13/status/1806698946531872982
	- ã‚‚ã¡ã‚ã‚“GPTãŒç†ç”±ã€‚äºˆæƒ³é€šã‚Šãªã‚“ã ã‘ã©ã€æ—¥æœ¬ã§ã‚‚ã‚‚ã†ã™ãã“ã†ãªã‚‹ã¯ãšã€‚ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¯GPTã‚’ä½¿ã„ã“ãªã—ã¦ã€Œè‡ªåˆ†ãŒå­¦ç¿’ã‚’ã—ã¦ã„ãªã„è¨€èªã€ã‚’ä½¿ã„ã“ãªã™ã‚¹ã‚­ãƒ«ã‚’è¦šãˆãŸã»ã†ãŒã„ã„ã€‚ã“ã£ã¡ãŒä»Šå¾Œé‡è¦ã€‚ãã—ã¦ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼è¨€èªã¯ã“ã‚Œã‹ã‚‰ã©ã‚“ã©ã‚“æ¸›ã£ã¦ã„ãã¯ãšã€‚
- Ollamaãƒ™ãƒ¼ã‚¹ã§GraphRAGã§ããŸï¼
	- https://x.com/hAru_mAki_ch/status/1807092967574028398
-  Ollama Embeddings å®Œå…¨ã‚¬ã‚¤ãƒ‰ API ä¸è¦ã®ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿç¾ã™ã‚‹ é«˜æ€§èƒ½ãƒ†ã‚­ã‚¹ãƒˆè§£æ
	- https://hamaruki.com/ollama-embeddings/
	- langchainã®embeddingsã£ã¦ã€Œgpt4allã€ã¨ã€Œollamaã€ã«å¯¾å¿œã—ã¦ãŸã€‚ã€‚ã€‚
- ollamaã®Gemma2ã‚’ä½¿ã£ã¦ã€Œå‘ªè¡“å»»æˆ¦ã€ã®wikipediaæƒ…å ±ã‚’Neo4Jã«å…¥ã‚Œã¦ã¿ãŸï¼çµæ§‹ã„ã„æ„Ÿã˜ã«å…¥ã£ã¦ã‚‹ã¨æ€ã†ï¼ï¼
	- https://x.com/hAru_mAki_ch/status/1807318938675814506
- Googleã•ã‚“ã®gemma-2-27b-itã®æ—¥æœ¬èªimatrixé‡å­åŒ–ggufãŒå®Œæˆã—ã¾ã—ãŸï¼
	- https://huggingface.co/grapevine-AI/gemma-2-27b-it-gguf
	- è»½é‡ãªã®ã«ã¨ã‚“ã§ã‚‚ãªãè³¢ã„ã€ç¾çŠ¶æœ€å¼·ã®ãƒ­ãƒ¼ã‚«ãƒ«LLMã ã¨æ€ã„ã¾ã™
- Perplexity APIã«ã¯ã„ãã¤ã‹ã®LLMãŒã‚ã£ã¦ã€æ¤œç´¢ï¼‹LLMã‚’ä½“é¨“ã™ã‚‹ãªã‚‰ã€Œllama-3-sonar-large-32k-onlineã€ãŒã‚ªã‚¹ã‚¹ãƒ¡ã€‚
	- https://x.com/gijigae/status/1807355566169432125
- Gemma-2ãŒç´ æ™´ã‚‰ã—ã„æ€§èƒ½ã¨ãªã£ã¦ã‚‹ ãªã‚“ã‚‰ã‹ã®æœ€è¿‘ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ãŒé–¢ã‚ã£ã¦ã‚‹ã‹ï¼Ÿ ã—ã£ã‹ã‚Šæƒ…å ±è¿½ã£ãŸæ–¹ãŒè‰¯ã•ãã†ã€€ by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://x.com/AiXsatoshi/status/1807563542125826120
- TJOã•ã‚“ã€ç”ŸæˆAIï¼ˆç‰¹ã«LLMï¼‰ã®å®Ÿå‹™å¿œç”¨ç³»ãƒˆãƒ¬ãƒ³ãƒ‰ãŒäº‹å‰ã®äºˆæƒ³é€šã‚Šã€ŒRAGç³»ã‚µãƒ¼ãƒ“ã‚¹ã€ã«åæ–‚ã—ã¤ã¤ã‚ã‚‹æ„ŸãŒã‚ã‚‹ã¨ã€å¾Œå‡ºã—ã˜ã‚ƒã‚“ã‘ã‚“
	- https://x.com/TJO_datasci/status/1807603353884807272
	- ã‚„ã¯ã‚Šã©ã‚Œã»ã©åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’å……å®Ÿã•ã›ã¦ã‚‚ã€Œåšå­¦ã®è–„å­¦ã€ã«ãªã‚ŠãŒã¡ã§ã€
	- ä¸€æ–¹å®Ÿå‹™ä¸Šã¯ã€Œæ¥­å‹™ãƒ‰ãƒ¡ã‚¤ãƒ³ã®çŸ¥è­˜ã‚’ã‚‚ã¨ã«ç¢ºå®Ÿã«ç–‘å•ã«ç­”ãˆã‚‰ã‚Œã‚‹ã€ã“ã¨ã®æ–¹ãŒé‡è¦ã€‚
	- ãã—ã¦ãã‚Œã¯RAGçš„ãªã‚‚ã®ã§å®Ÿç¾å¯èƒ½ã‹ã¨

## 24/6/24

ä»Šé€±ã¯ã™ã¹ã¦ã‚’å¹ã£é£›ã°ã—ã¦ã€AnthropicãŒçªç„¶ç™ºè¡¨ã—ãŸClaude 3.5 Sonnetã§ã—ã‚‡ã†ã€‚Claude 3 Opusã®2å€ã®é€Ÿåº¦ã§ã“ã‚Œã¾ã§ã®5åˆ†ã®1ã®ã‚³ã‚¹ãƒˆã¨ã„ã†ã®ã‚‚ã™ã”ã„ã®ã§ã™ãŒã€æ–°ã—ã„ã‚¢ãƒ—ãƒªé–‹ç™ºç’°å¢ƒArtifactsã‚’ä½¿ã£ã¦ã€äººé–“ã¨å¯¾è©±ã—ãªãŒã‚‰ã‚ã£ã¨ã„ã†é–“ã«ã€ ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ ã€webUIç”Ÿæˆ ã€ã‚¹ãƒãƒ›UIç”Ÿæˆ ã€ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã€ç°¡æ˜“ã‚²ãƒ¼ãƒ ç”Ÿæˆã€ã»ã¼å®Œãºããªã‚·ãƒ•ãƒˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆã€WebGLã‚’ã¤ã‹ãŸã£ãŸå¯è¦–åŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ç”Ÿæˆã€æ§˜ã€…ãªäº‹ä¾‹ãŒç™ºè¡¨ã•ã‚ŒãŠç¥­ã‚ŠçŠ¶æ…‹ã«ã€‚ç„¡æ–™ã§Artiffactsã¯è©¦ã›ã¦ã€ä¾‹ãˆã°ã€ã“ã®æ–‡ç« ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½œã£ãŸã‚Šã€LLMã«é–¢ã™ã‚‹çŸ¥è­˜ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã—ãŸã‚Šã¨ã‹ã€ç©ºã‹ã‚‰é™ã£ã¦ãã‚‹ãƒˆãƒ”ãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’æ‰“ã¡è½ã¨ã™ã‚²ãƒ¼ãƒ ã•ãˆã§ãã‚‹ã€‚ç”Ÿç”£æ€§å‘ä¸Šã¨ã‹æ”¹å–„ã¨ã‹ã€ã‚‚ã†å…¨éƒ¨ã€Claude 3.5 Sonnetã§ä¸Šæ›¸ãã•ã‚Œã‚‹æ„Ÿã˜ã€é€†ã«ã€ã“ã‚ŒãŒä½¿ã„ã“ãªã›ã‚‹äººæã—ã‹æ®‹ã‚‰ãªã„ã€‚ã§ã‚‚ã“ã‚ŒSonnetãªã‚“ã§ã™ã‚ˆã€Opusã£ã¦ã©ã†ãªã‚‹ã‚“ã§ã—ã‚‡ã†ã‹ã€‚Googleã‹ã‚‰ã¯ã€æ‚£è€…ã¨ã®ã‚„ã‚Šå–ã‚Šã§äººé–“ã®åŒ»å¸«ã‚’è¶…ãˆã‚‹ã¨ã„ã†AMIE(Articulate Medical Intelligence Explorer )ã®ç™ºè¡¨ã‚„ã€é«˜ç²¾åº¦å¤©æ°—äºˆå ±ã€ŒãƒŠã‚¦ã‚­ãƒ£ã‚¹ãƒˆã€ã‚’æ—¥æœ¬ã§ã‚¦ã‚§ã‚¶ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã¦æä¾›ã¨ã‹ã€Gemini1.5Proã¨Gemini1.5Flashã®APIã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã®ãƒªãƒªãƒ¼ã‚¹ç­‰ãŒã‚ã‚Šã¾ã—ãŸã€‚Geminiã®å…¬å¼ noteã‚·ãƒªãƒ¼ã‚ºé–‹å§‹ã¨ã‹ã€ç€å®Ÿã«ã™ãé‡ã‚‚åºƒã‚ã¦ã¦å¥½æ„ŸãŒæŒã¦ã‚‹ã€‚å‚˜ä¸‹ã®DeepMindã‹ã‚‰video-to-audio (V2A)ãŒç™ºè¡¨ã•ã‚Œã€å…ˆé€±ã®Luma AIã¨åˆã‚ã›ã‚Œã°ã€ã‚·ãƒ§ãƒ¼ãƒˆãƒ•ã‚£ãƒ«ãƒ ã¯ä½œã‚Œãã†ãªå‹¢ã„ã€‚ã•ã¦ã€Metaã‹ã‚‰ã¯ã€ãƒŸãƒƒã‚¯ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ãªChameleonã‚„ã€éŸ³å£°ãŒAIè£½ã‹ã©ã†ã‹ã‚’è¦‹ç ´ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãªã©ã®è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã®ç™ºè¡¨ã€ã©ã®ã‚ˆã†ãªè©•ä¾¡ã‚„æ–¹å‘æ€§ã«ãªã‚‹ã®ã‹æ¥é€±ä»¥é™æœŸå¾…ã€‚å…ˆé€±è©±é¡Œã¨ãªã£ãŸã€Nemotron-4-340B-Instructã€è©•ä¾¡ãªã©ãŒã¼ã¡ã¼ã¡ã€ã†ã¿ã‚†ãã•ã‚“ãŒShaberi3ãƒ™ãƒ³ãƒã«ã‹ã‘ã¦ã¿ãŸã‚‰ã€å¹³å‡ã‚¹ã‚³ã‚¢8.05ã§ã€Gemini1.5Proï¼ˆ8.01ï¼‰ä»¥ä¸Šã€GPT-4oï¼ˆ8.16ï¼‰ä»¥ä¸‹ã¨ã®ã“ã¨ã€‚ã¾ãŸãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ã¨98%ã®äº‹å¾Œå­¦ç¿’ã®ãƒ‡ãƒ¼ã‚¿ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ã¤ã‹ã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€ã•ã™ãŒåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹ã®ãŒå¾—æ„ãªNemotronã®é¢ç›®èºå¦‚ã€ã„ã‚„ã€ãã®ãƒ‡ãƒ¢ã ã£ãŸã®ã‹ã‚‚ã€‚ç„¡æ–™ã®Playgroundã§åˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒã‚³ãƒä½œã‚‹ã¨ã„ã†æ‰‹ã‚‚ã‚ã‚Šãã†ã ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã¯ã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ä½¿ãˆã‚‹ã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ãŒã€è£½ä½œè²»75ä¸‡å††ã¨ã„ã†ã“ã¨ã§è©±é¡Œã«ãªã‚Šã¾ã—ãŸãŒã€ãªã‚“ã¨ã„ã£ã¦ã‚‚ã€Chrome ã§å‹•ã Gemini Nanoã€Chromeé–‹ç™ºç‰ˆã§ã¯åˆ©ç”¨å¯èƒ½ã«ãªã£ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€ã•ã£ããnpakaã•ã‚“ãŒå‹•ä½œäº‹ä¾‹ã‚’ç´¹ä»‹ã€‚ãƒ–ãƒ©ã‚¦ã‚¶çµ„ã¿è¾¼ã¿ã§ã£ã›ã€javascriptã‹ã‚‰ãŸãŸã‘ã‚‹ã‚“ã§ã£ã›ã€‚shi3zã•ã‚“ã®è§£èª¬ã«ã‚ˆã‚‹ã¨ã€KARAKURIãŒä½äºˆç®—ã§LLMã‚’ä½œã‚ŒãŸã‹ã‚‰ãã‚Šã¯ã€AWS Trainiumã®åˆ©ç”¨ã¨ã®ã“ã¨ã§ã€ã¾ãŸã€å…ˆé€±ç´¹ä»‹ã®ã‚ã£ãŸã€MoA(Mixture of Agent)ã‚„ã€LLMã®ãƒãƒ¼ã‚¸æŠ€è¡“ã«ã‚ˆã‚Šã€æ‰‹è»½ã«èª°ã§ã‚‚é«˜æ€§èƒ½ãªLLMã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€ç¢ºå¤‰ã®æ™‚ä»£ããŸã‚‹ã¨ã„ã†è¨˜äº‹ã¯ã—ã³ã‚Œã‚‹ã€ãã†ã‹ã€ãƒ‡ãƒ¼ã‚¿ã¯Nemotronã§åˆæˆã•ã‚Œã‚Œã°ã‚ˆã„ã®ã‹ã€ã©ã‚“ãªLLMãŒshi3zã•ã‚“ã®GPUãƒã‚·ãƒ³ã‹ã‚‰å‡ºã¦ãã‚‹ã®ã‹æ¥½ã—ã¿ã§ã™ã€‚ç†è«–é¢ã§ã¯ã€LLMãŒäº‹å‰å­¦ç¿’æ™‚ã«äº‹å®Ÿçš„çŸ¥è­˜ã‚’ç²å¾—ã™ã‚‹æ§˜å­ã®åˆ†æè«–æ–‡ã‚„ã€Transformer ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‹å§‹ã¾ã£ã¦æœ€çµ‚çš„ãªè¡¨ç¾å‹ã«è¿‘ã„ç¾è±¡æŒ™å‹•ã¾ã§ã¤ãªãŒã‚‹æ§˜å­ã‚’ã»ã¼æ˜ã‚‰ã‹ã¨ã™ã‚‹è§£èª¬è¨˜äº‹ã¨ã‹ã€LLMã®æŒ¯ã‚‹èˆã„ã®ç†è«–çš„ãªè§£æã‚‚ç€å®Ÿã«ã™ã™ã‚“ã§ã„ã¾ã™ã€èª¬æ˜æ€§ã®å‘ä¸Šã«æœŸå¾…ã€‚å¿œç”¨é¢ã®RAGã‚‚å¿˜ã‚Œã¦ã¾ã›ã‚“ã‚ˆã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¨ã®çµ±åˆã¨ã‹ã€ã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ã£ã¦RAGã«å¯¾å¿œã¨æ˜ç¤ºã—ã¦ã‚ã£ãŸã‚Šã¨ã€ä»Šé€±ã‚‚ã„ã‚ã„ã‚ã‚ã‚Šã¾ã—ãŸãŒã€ã“ã“ã¯åŸºæœ¬æˆ»ã£ã¦ã€ LangChain ã§ RAGã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãªã‚“ã‹ã‚„ã‚‰ã›ã¦ã¿ã¦ã€æ­£æ°—ã‚’å–ã‚Šæˆ»ã—ã¾ã—ã‚‡ã†ã€‚ã•ã¦ã€Claude 3.5 Sonnetã®èƒ½åŠ›ã‚’è¦‹ã¦ã‚‹ã¨ã€ã€Œã¾ã LLMã§é©šã‘ã‚‹ã‚“ã ã€ã¨ã„ã†(ãƒ¡ã‚¿ãªï¼‰é©šãã‹ã‚‰ã€ãã‚Œã£ã¦ã€äººã£ã¦ãã‚“ãªã«æ²¢å±±ã„ã‚‰ãªã„ã‹ã‚‚ã€ã¨ã„ã†ã®ãŒç¢ºä¿¡ã«ãªã‚Šã¤ã¤ã‚ã‚Šã¾ã™ã€‚BBCã§ç´¹ä»‹ã•ã‚ŒãŸã€60äººã„ãŸãƒ©ã‚¤ã‚¿ãƒ¼ã¨ç·¨é›†è€…ãŒè·ã‚’å¤±ã„ã€ChatGPTã®å‡ºåŠ›ã‚’æ‰‹ç›´ã—ã™ã‚‹ä¸€äººã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã«ç½®ãæ›ãˆã‚‰ã‚ŒãŸã¨ã„ã†è©±é¡Œã‚‚ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚ã‚Šã¾ã—ãŸãŒã€Claude 3.5 Sonnetã‚„GPT-4oç´šãªã‚‰ãã†ãªã‚‹ã‹ã‚‚ã€‚ã„ã‚„ã€ãƒãƒ¼ã‚¸ãƒ‹ã‚¢å¤§å­¦ã®å…ˆç”Ÿã®ã„ã†ã€Œç”Ÿç”£çš„ã«æ„šã‹ã«ãªã‚‹ã€ã£ã¦ã®ã¯ã€LLMã«ã¯ã¾ã ç„¡ç†ã‹ãªã€ã¨ä¿¡ã˜ãŸã„ã¨ã“ã‚ã§ã™ã€‚

- ã„ã¤ã®é–“ã«ã‹Stable DiffusionãŒDiffusion Modelã§ã¯ãªããªã£ã¦ã„ã‚‹ï¼ï¼Ÿï¼ˆãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ãŒDiffusion Transformerã ã‹ã‚‰ã‚»ãƒ¼ãƒ•ï¼Ÿï¼‰
	- https://x.com/shion_honda/status/1802386378874835056
- WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild
	- https://arxiv.org/abs/2406.04770
	- 100ä¸‡ä»¶ã«ãŠã‚ˆã¶äººé–“ã¨LLMã®ä¼šè©±å±¥æ­´ã‚’ã‚‚ã¨ã«ä½œæˆã—ãŸã€ç¾å®Ÿãƒ‹ãƒ¼ã‚ºã«å‰‡ã™ã‚‹1,024ã®ã‚¿ã‚¹ã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹æ‰‹æ³•ã€WildBenchã€ãŒå…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- ã€Œäººé–“ãŒå®Ÿéš›ã«æŠ•ã’ã‚‹ã‚¿ã‚¤ãƒ—ã®ã‚¿ã‚¹ã‚¯ã€ã«ãŠã‘ã‚‹40ç¨®é¡ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¯èˆˆå‘³æ·±ã„ã‚‚ã®ã¨ãªã£ã¦ã„ã¾ã™ã€‚
- DeepSeek-Coder-V2
	- https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct
	- 236B Mixture-of-Expertsï¼ˆMoEï¼‰ 6T tokensã®äº‹å‰å­¦ç¿’ ã‚µãƒãƒ¼ãƒˆã™ã‚‹è¨€èªã¯338 ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·ã‚‚16Kã‹ã‚‰128Kã«
	- æ¨™æº–çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã§ã€GPT4-Turboã€Claude 3 Opusã€Gemini 1.5 Proãªã©2ã‚’ä¸Šå›ã‚‹æ€§èƒ½
-  AI took their jobs. Now they get paid to make it sound human
	- https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human
	- 60äººã„ãŸãƒ©ã‚¤ã‚¿ãƒ¼ã¨ç·¨é›†è€…ãŒè·ã‚’å¤±ã„ã€ChatGPTã®å‡ºåŠ›ã‚’æ‰‹ç›´ã—ã™ã‚‹ä¸€äººã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã«ç½®ãæ›ãˆã‚‰ã‚ŒãŸã¨ã„ã†è©±é¡Œ
	- AIã®å‡ºåŠ›ã‚’äººé–“ã£ã½ãã™ã‚‹ãŸã‚ã«å°‘æ•°ã®äººé–“ãŒé›‡ã‚ã‚Œã‚‹æµã‚ŒãŒã‚‚ã†åŠ é€Ÿã—ã¦ã„ã‚‹
- The importance of stupidity in scientific research
	- https://web.stanford.edu/~fukamit/schwartz-2008.pdf
	- ã€Œæ„šã‹ã•ã€ã¯ã€ç§‘å­¦è€…ãŒé‡è¦ãªè³ªå•ã‚’ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã™å…†å€™ã§ã‚ã‚‹ã¨ã•ã‚Œã¦ã„ã¾ã™ã€‚è‘—è€…ã¯ã€å­¦ç”ŸãŒã€Œç”Ÿç”£çš„ã«æ„šã‹ã«ãªã‚‹ã€æ–¹æ³•ã‚’æ•™ãˆã‚‹ãŸã‚ã®ææ¡ˆã§è«–æ–‡ã‚’ç· ã‚ããã£ã¦ã„ã¾ã™ã€‚
- Nemotron 340B Technical Report
	- https://x.com/_philschmid/status/1802617332893729029
	- Implementation
		- Pretraining: 2-phase pretraining, first trained on 8T and then continued on 1T higher quality tokens and Instruction data with a steeper slope of learning rate decay. 
		- Fine-tuning: First fine-tuned on 800K coding samples, followed by 200K diverse task samples. 
		- RLHF: Applied Direct Preference Optimization (DPO) followed by Reward-aware Preference Optimization (RPO) on multiple iterations.
	- Insights
		- 98% of data used in post-training was synthetically generated
		- Pretraining data: English data (70%), Multilingual data (15%), Source code (15%).
		- Trained on 6144 H100 GPUs with 8-way TP, 12-way PP with interleaving and DP to achieve ~42% MFU
		- Only used 20k Human annotated data mostly for Reward Modeling
		- Detailed Synthetic Data pipeline instruction including all prompts to generate data
- DeepMindã€€ã‹ã‚‰video-to-audio (V2A) generative technology. 
	- https://x.com/GoogleDeepMind/status/1802733643992850760
	- It can add sound to silent clips that match the acoustics of the scene, accompany on-screen action, and more.
- How Do Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://arxiv.org/abs/2406.11813
	- Reveals several important insights into the dynamics of factual knowledge acquisition during pretraining
- Nemotron-4-340B-Instructã®APIã‚’ã•ã£ããShaberi3ãƒ™ãƒ³ãƒã«ã‹ã‘ã¦ã¿ãŸã‚‰ã€å¹³å‡ã‚¹ã‚³ã‚¢8.05ï¼Gemini1.5Proï¼ˆ8.01ï¼‰ä»¥ä¸Šã€GPT-4oï¼ˆ8.16ï¼‰ä»¥ä¸‹ï¼ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1803112240935260328
- Building Advanced RAG with Knowledge Graphs
	- https://x.com/llama_index/status/1803082001538535703
	- This 60 minute webinar is a must-watch if youâ€™re looking to apply the latest techniques combining LLMs with knowledge graphs.
-  Creativity Has Left the Chat: The Price of Debiasing Language Models
	- https://arxiv.org/abs/2406.05587
	- ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã•ã‚Œã‚‹ã¨å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯å‰µé€ æ€§ã‚’å¤±ã† RLHF ãªã©ã®æœ‰å®³ãªç”Ÿæˆã‚’é˜²ããŸã‚ã®ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆæŠ€è¡“ã«ã‚ˆã£ã¦ã€LLM ã®å‰µé€ æ€§(å¤šæ§˜æ€§)ãŒæ¸›å°‘ã™ã‚‹ã€‚ä¾‹ãˆã°ç”Ÿæˆæ–‡ã‚’ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æã™ã‚‹ã¨ã€ã‚¢ãƒ©ã‚¤ãƒ³ãƒ¡ãƒ³ãƒˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§ã¯æ˜ç¢ºãªã‚¯ãƒ©ã‚¹ã‚¿å½¢æˆã•ã‚Œåã‚ŠãŒã‚ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹
- I have lots of thoughts on "agents"!
	- https://x.com/hwchase17/status/1803089961245348125
	- spotify ã§ã®é…ä¿¡ä»˜ã
- today at Meta FAIR weâ€™re announcing four new publicly available AI models
	- https://x.com/AIatMeta/status/1803107817345393136
	- Meta Chameleon
		- 7B & 34B language models that support mixed-modal input and text-only outputs.
		- ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒã‚’å…¥åŠ›ã™ã‚‹ã¨ãƒ†ã‚­ã‚¹ãƒˆã‚„ç”»åƒã‚’å‡ºåŠ›ã§ãã‚‹ãƒ¢ãƒ‡ãƒ«ï¼
	- Meta Multi-Token Prediction
		- Pretrained Language Models for code completion using Multi-Token Prediction.
		- ãƒãƒ«ãƒãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬ã®7Bãƒ¢ãƒ‡ãƒ«ï¼æ™®é€šã®LLMã¯1ãƒˆãƒ¼ã‚¯ãƒ³ãšã¤ã—ã‹å‡ºåŠ›ã§ããªã„ã‘ã©ã€ã“ã‚Œã¯è¤‡æ•°ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã¾ã¨ã‚ã¦å‡ºåŠ›ã§ãã¦é€Ÿã„
	- Meta JASCO
		- Generative text-to-music models capable of accepting various conditioning inputs for greater controllability. Paper available today with a pretrained model coming soon.
		- ã“ã‚Œã¯ã‚³ãƒ¼ãƒ‰ã‚„ã‚‰ãƒ“ãƒ¼ãƒˆã‚’æŒ‡å®šã—ã¦éŸ³æ¥½ç”Ÿæˆã§ãã‚‹ã‚‰ã—ã„
	- Meta AudioSeal
	-  	An audio watermarking model that we believe is the first designed specifically for the localized detection of AI-generated speech, available under a commercial license.
	- éŸ³å£°ãŒAIè£½ã‹ã©ã†ã‹ã‚’è¦‹ç ´ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«
- Firefunction-v2
	- https://x.com/LangChainAI/status/1803083016715289045
	- Llama 3 fine-tuned for tool calling / agents
- ç›´æ„Ÿçš„ã«ç†è§£ã™ã‚‹Conformal Prediction
	- https://speakerdeck.com/masatoto/zhi-gan-de-nili-jie-suruconformal-prediction
	- åˆ†é¡å•é¡Œã«ãŠã‘ã‚‹ç¢ºä¿¡åº¦ã®é«˜ã„çµæœã ã‘ã‚’è¿”ã™ã®ã§ã¯ãªãï¼Œäºˆæ¸¬é›†åˆã‚’è¿”ã™æ–¹æ³•.äºˆæ¸¬é›†åˆã«çœŸã®çµæœãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºç‡çš„ã«ä¿è¨¼.
- What is a Mixture-of-Experts (MoE)
	- https://x.com/akshay_pachaar/status/1803043120654983424
	- A Mixture of Experts (MoE) is a machine learning framework that resembles a team of specialists, each adept at handling different aspects of a complex task.
	- It's like dividing a large problem into smaller, more manageable parts and assigning each part to a different expert.
- åˆæˆãƒ‡ãƒ¼ã‚¿ä½œã‚Šæ”¾é¡Œã§ãŠãªã˜ã¿ã®Nemotronã€APIã¨ã‹ã‚ã‚‹ã®ã­
	- https://x.com/umiyuki_ai/status/1803078912051986714
	- ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚Œã°ç„¡æ–™ã§1000å›ã¾ã§å©ã‘ã‚‹ã‚‰ã—ã„ã€‚èª²é‡‘ã¨ã‹ã¯ã¾ã ç„¡ã„ã½ã„ã€‚èª²é‡‘ã—ã¦ã§ã‚‚å©ããŸã„äººå¤šãã†ã ã‘ã©ã€‚Playgroundã§ãƒãƒ£ãƒƒãƒˆã™ã‚‹ã ã‘ãªã‚‰ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ¸›ã‚‰ãªã„ã£ã½ã„ã‹ã‚‰é ‘å¼µã‚Œã°åˆæˆãƒ‡ãƒ¼ã‚¿åé›†ã§ãã‚‹ã‹ã‚‚
- Gemini1.5Proã¨Gemini1.5Flashã®APIã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ãŒãƒªãƒªãƒ¼ã‚¹
	- https://x.com/umiyuki_ai/status/1803127902533460149
	- https://ai.google.dev/gemini-api/docs/caching?lang=python&hl=ja
	- è¦ã™ã‚‹ã«KVã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜ã—ãŸã‚Šãƒ­ãƒ¼ãƒ‰ã—ãŸã‚Šã™ã‚‹æ©Ÿèƒ½ã€‚APIç„¡æ–™æ ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚‚Flashã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ€å¤§100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³æ´»ç”¨å¯èƒ½ï¼32kä»¥ä¸Šã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒä½¿ç”¨ã§ãã‚‹
- How Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://x.com/hoyeon_chang/status/1802952064726622671
	- è‘—è€…ã®ãƒ„ã‚¤ãƒ¼ãƒˆã€Iâ€™m thrilled to announce the release of my new paper!
	- This research explores how LLMs acquire and retain factual knowledge during pretraining. Here are some key insights:
	- LLMãŒäº‹å‰å­¦ç¿’æ™‚ã«äº‹å®Ÿçš„çŸ¥è­˜ã‚’ç²å¾—ã™ã‚‹æ§˜å­ã‚’ã€äº‹å®Ÿã®å¯¾æ•°å°¤åº¦ã§è©•ä¾¡ã—ãŸå ´åˆã€çŸ¥è­˜ã«è§¦ã‚Œã‚‹ãŸã³å°‘ã—ã ã‘ä¸Šæ˜‡ã—ç·©ã‚„ã‹ã«ä¸‹ãŒã‚Šå…ƒã«æˆ»ã‚‹ã€‚å¿˜ã‚Œã‚‹ã‚ˆã‚Šå…ˆã«ã¾ãŸçŸ¥è­˜ã«è§¦ã‚Œã‚‹ã“ã¨ã‚’ç¹°ã‚Šè¿”ã—é–¾å€¤ã«é”ã™ã‚‹ã¨å›ç­”ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚by å²¡é‡åŸã•ã‚“
-  Google ã® AI ã€ŒGeminiã€ã€å…¬å¼ note ã¯ã˜ã‚ã¾ã™
	- https://note.com/google_gemini/n/nc53d2b6f4a08
	- æ–°æ©Ÿèƒ½ã®ç´¹ä»‹ã‚„ã‚¤ãƒ™ãƒ³ãƒˆ ãƒ¬ãƒãƒ¼ãƒˆã€é–‹ç™ºè€…ã®è©±ãªã©ã€Gemini ã«ã¾ã¤ã‚ã‚‹ã•ã¾ã–ã¾ãªæƒ…å ±ã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚
- ã€ŒChatGPTã£ã¦ã€è‡ªåˆ†ã®ã€Œå¢ƒç•Œã€ã‚’æŒã£ã¦ã„ã¾ã›ã‚“ã‚ˆã­ã€‚
	- https://x.com/ShigeruTaguchi/status/1803044441680412775
	- ã ã‹ã‚‰ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–ã‚’æŒã¦ãªã„ã¨ã„ã†ã‹ã€‚â€¦â€¦èº«ä½“æ€§ã£ã¦ã€ãŸã—ã‹ã«å˜ã«ç‰©ç†çš„ãªè‚‰ä½“ã‚’æŒã¤ã¨ã„ã†ã“ã¨ã ã‘ã§ã¯ãªã„ã‘ã‚Œã©ã€è‡ªåˆ†ã«å›ºæœ‰ã®å¢ƒç•Œã‚’æŒã£ã¦ã„ã¦ã€ãã“ã‹ã‚‰ã—ã‹ç™ºç”Ÿã—ãªã„ãƒ‘ãƒ¼ã‚¹ãƒšã‚¯ãƒ†ã‚£ãƒ–ã‚’æŒã¤ã¨ã„ã†ã®ã¯å¤§äº‹ã ã¨æ€ã†ã‚“ã§ã™ã€‚
- Gemini ã«ã¤ã„ã¦å…¨éƒ¨è§£èª¬ï¼ ä½¿ã„æ–¹ã‚„ãƒ¢ãƒ‡ãƒ«ã€ãƒ—ãƒ©ãƒ³ã¾ã§
	- https://note.com/google_gemini/n/ncd7557d98d07?sub_rt=share_b
-  OpenAIã¨GoogleãŒç«èŠ±ã€€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆâ€¦ç”ŸæˆAIã®ä»Š by ä»Šäº•ã•ã‚“
	- https://xtrend.nikkei.com/atcl/contents/casestudy/00012/01473/?n_cid=nbpnxr_twed_cms
	- çµè«–ã ã‘è¨€ã†ã¨ã€Œé•·æœŸçš„ã«ã¯Googleæœ‰åˆ©ã€ã§ã™ã€‚
-  LangChain ã§ RAGã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n6782314fb471?sub_rt=share_h
	- ã€ŒRAGã€ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã¯ã€è¤‡æ•°ã®æ¤œç´¢æ–¹æ³•ã‚’çµ„ã¿åˆã‚ã›ã‚‹æ‰‹æ³•ã§ã€ä¸»ã«ã€Œãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã€ã¨ã€Œã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã€ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ã„ã¾ã™
-  Fine Tuning MistralAI models using Finetuning API
	- https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/mistralai_fine_tuning.ipynb
-  LLM ã®ä»•çµ„ã¿ã‚’æŠ¼ã•ãˆã‚Œã°ã•ã‚‰ã«ç”Ÿæˆ AI ã‚’æ´»ç”¨ã§ãã‚‹
	- https://note.com/google_gemini/n/n51d9f3b97470?sub_rt=share_b
	- è¨€èªãƒ¢ãƒ‡ãƒ«ãŒè¡Œãªã£ã¦ã„ã‚‹ã“ã¨ã¯ã€Œæ–‡è„ˆã‚’è¸ã¾ãˆã¦æ–‡ã®ç¶šãã‚’äºˆæ¸¬ã€ã™ã‚‹ã“ã¨
	- LLM ã®ä»•çµ„ã¿ã‚’è¸ã¾ãˆã‚‹ã¨ã€ç”Ÿæˆ AI ã®ç‰¹å¾´ãŒã‚ˆã‚Šç†è§£ã§ãã‚‹
	- ã‚ˆã‚Šé•·ã„æ–‡è„ˆã‚’è¸ã¾ãˆã¦ã€Œæ–‡ã®ç¶šãã‚’äºˆæ¸¬ã€ã§ãã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé€²åŒ–ã—ã¦ã„ã
	- ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã„ã“ãªã™ï¼
- Ilya SutskeverãŒå®‰å…¨ãªè¶…çŸ¥èƒ½ã‚’ç›®æ¨™ã¨ã™ã‚‹Safe Superintelligence Inc.è¨­ç«‹!
	- https://x.com/bioshok3/status/1803475573030920310
- ã‚°ãƒ¼ã‚°ãƒ«ã€12æ™‚é–“å…ˆã¾ã§5åˆ†åˆ»ã¿ã§é™é›¨äºˆæ¸¬ã™ã‚‹ã€ŒGoogle ãƒŠã‚¦ã‚­ãƒ£ã‚¹ãƒˆã€
	- https://www.watch.impress.co.jp/docs/news/1601121.html
	- Google ãƒŠã‚¦ã‚­ãƒ£ã‚¹ãƒˆã§ã¯ã€6æ™‚é–“å…ˆã¾ã§ã®é™é›¨äºˆæ¸¬ã‚’Google æ¤œç´¢ã®çµæœã«è¡¨ç¤ºã—ã€ã•ã‚‰ã«12æ™‚é–“å…ˆã¾ã§ã®äºˆæ¸¬ã‚’æ–‡å­—æƒ…å ±ã§è¡¨ç¤ºã€‚5åˆ†å˜ä½ã®è©³ç´°ãªé›¨é‡äºˆæ¸¬ãŒå¯èƒ½ã¨ãªã‚‹ã€‚é›¨ã ã‘ã§ãªãé›ªã®äºˆæ¸¬ã‚‚è¡Œãªã†ã€‚
	- é«˜ç²¾åº¦å¤©æ°—äºˆå ±ã€ŒãƒŠã‚¦ã‚­ãƒ£ã‚¹ãƒˆã€æ—¥æœ¬ã§æä¾›ã€€ã‚¦ã‚§ã‚¶ãƒ¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸAIæ¡ç”¨
- Google researchers developed the Articulate Medical Intelligence Explorer (AMIE),
	- https://www.deeplearning.ai/the-batch/amie-a-chatbot-that-outperforms-doctors-in-diagnostic-conversations/?utm_campaign=The%20Batch&utm_content=297333022&utm_medium=social&utm_source=twitter&hss_channel=tw-992153930095251456
	- AMIE, a chatbot that outperforms doctors in diagnostic conversations
- Kolmogorov Arnold Networkâ€ is one of the best innovations of 2024
	- https://x.com/predict_addict/status/1803323909233668281
	- â€œKolmogorovâ€“Arnold-Informed neural network: A physics-informed deep learning framework for solving PDEs based on Kolmogorovâ€“Arnold Networksâ€
- Chrome ã§ Gemini Nano ã‚’ä½¿ç”¨ã™ã‚‹
	- https://developer.chrome.com/docs/ai?hl=ja
- Transformerã®æ¬¡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦æœŸå¾…ã•ã‚Œã¦ã„ã‚‹Mambaã‚’ä½¿ã£ãŸéŸ³å£°åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã€Audio-Mambaã®Fine-Tuningã‚’è©¦ã—ã¦ã¿ã¾ã—ãŸ
	- https://x.com/AIShift_PR/status/1803349519532531817
-  A Primer on the Inner Workings of Transformer-based Language Models
	- https://arxiv.org/abs/2405.00208
	- Section 2â†’5ã«é€²ã‚€ã«ã¤ã‚Œã¦Transformerã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå†…ã®å±€æ‰€çš„ãªæŒ™å‹•ã‹ã‚‰å§‹ã¾ã£ã¦ã‚ˆã‚Šæœ€çµ‚çš„ãªè¡¨ç¾å‹ã«è¿‘ã„ç¾è±¡ã®èª¬æ˜ã¾ã§ï¼Œã“ã‚Œã¾ã§ã®å¤§é‡ã®çŸ¥è¦‹ãŒã¾ã¨ã¾ã£ã¦ã„ã¾ã™
	- Transformer ã®æŒ™å‹•ã¯ã»ã¼æ˜ã‚‰ã‹ã«ãªã£ã¦ã‚‹ã¨æ€ã£ã¦ã„ã¦ã€ã¾ã æ˜ã‚‰ã‹ã«ãªã£ã¦ãªã„ã“ã¨ã¯ãƒ¢ãƒ‡ãƒ«ã¨ã„ã†ã‚ˆã‚Šè¨€èªã®æ€§è³ªãŒåŸå› ãªæ°—ãŒã™ã‚‹ï¼ˆç´ äººã®å‹˜ï¼‰
- ããŸã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ï¼ï¼
	- https://x.com/lemilemilemio/status/1803607874079432959
	- Anthropicç¤¾ã¯çªå¦‚ã¨ã—ã¦"Claude 3.5 Sonnet"ã‚’ãƒªãƒªãƒ¼ã‚¹
- å›½ç”£LLMåˆã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ä½¿ãˆã‚‹ã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ã‚’ä¸€èˆ¬å…¬é–‹
	- https://prtimes.jp/main/html/rd/p/000000089.000025663.html
	- Function callingã¨RAGã«å¯¾å¿œã—ãŸã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ã‚’å…¬é–‹ã„ãŸã—ã¾ã™
	- æœ¬å¯¾å¿œã«ã‚ˆã‚Šã€ã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ã¯æ§˜ã€…ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’äººé–“ã«ä»£ã‚ã£ã¦æ“ä½œã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆâ€»2 ã¨ã—ã¦ã®æ´»ç”¨ãŒå¯èƒ½ã§ã™
- Anthropicç¤¾ã¯çªå¦‚ã¨ã—ã¦"Claude 3.5 Sonnet"ã‚’ãƒªãƒªãƒ¼ã‚¹
	- https://x.com/ctgptlb/status/1803822932831166712
	- ç¾çŠ¶æœ€å¼·ã ã£ãŸGPT-4oã®æ€§èƒ½ã‚’ä¸Šå›ã‚‹ä¸Šã«ã€Claude 3 Opusã®2å€ã®é€Ÿåº¦ã§ã“ã‚Œã¾ã§ã®5åˆ†ã®1ã®ã‚³ã‚¹ãƒˆã«
	- ã¾ãŸæ–°ã—ãã€"Artifacts"ã¨ã„ã†æ–°æ©Ÿèƒ½ãŒç™»å ´ã€‚Xã§æ—©é€ŸArtifactsæ©Ÿèƒ½ã®ã™ã”ã„äº‹ä¾‹ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™
- Claude3.5Sonnetã€€ä¸éƒ½åˆæ—¥ã€ä¼‘æ—¥æ‹…å½“æ•°ã®å…¬å¹³æ€§ã€å½“ç›´æ—¥ã®é–“éš”ãªã©ã‚’è€ƒæ…®ã—ã¦ã»ã¼å®Œç’§ãªã‚·ãƒ•ãƒˆã‚’çµ„ã‚“ã§ãã‚Œã¾ã™
	- https://x.com/genkAIjokyo/status/1803905958776836356
	- ã¤ã„ã«...äººé–“ãŒå½“ç›´è¡¨ã€å¾…æ©Ÿè¡¨ã€ã‚·ãƒ•ãƒˆã®ä½œæˆã‹ã‚‰è§£æ”¾ã•ã‚Œã‚‹æ—¥ãŒï¼
	- ã“ã®ã‚¿ã‚¹ã‚¯ã¯GPT4oã€Claude3Opusã§ã‚‚å°‘ã—ä¿®æ­£å¿…è¦ã ã£ãŸã®ã§Claude3.5Sonnetã‹ãªã‚Šå„ªç§€...
- Claude 3.5 sonnetã¨Artifactã§å‡ºæ¥ã‚‹ã“ã¨ã€‚by å…ƒæœ¨ã•ã‚“
	- https://x.com/ai_syacho/status/1803822100186058831
	- 1. ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ 
	- 2. webUIç”Ÿæˆ 
	- 3. ã‚¹ãƒãƒ›UIç”Ÿæˆ 
	- 4. ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ 
	- 5. ç°¡æ˜“ã‚²ãƒ¼ãƒ ç”Ÿæˆ
-  Evaluating the World Model Implicit in a Generative Model
	- https://arxiv.org/abs/2406.03689
	- New paper: How can you tell if a transformer has the right world model?
	- We trained a transformer to predict directions for NYC taxi rides. The model was good. It could find shortest paths between new points
	- The map let us visually inspect the incoherent world model. But how should we evaluate world models in non-map settings?
- å›½ç”£LLMåˆã€AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ä½¿ãˆã‚‹ã€ŒKARAKURI LM 8x7B Instruct v0.1ã€ã‚’ä¸€èˆ¬å…¬é–‹
	- https://karakuri.ai/seminar/news/karakuri-lm-8x7b-instruct-v0-1/
	- æœ¬ãƒ¢ãƒ‡ãƒ«ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ã‚¹ãƒˆã‚’æœ€å¤§50%å‰Šæ¸›ã§ãã‚‹ã¨ã„ã‚ã‚Œã¦ã„ã‚‹AWS Trainiumã‚’æ´»ç”¨ã—ã¦ãŠã‚Šã€é–‹ç™ºè²»ç”¨ã¯75ä¸‡å††ã§ã™ã€‚
	- ãƒ‡ãƒ¢ï¼ˆæœŸé–“é™å®šï¼‰
		- https://lm.karakuri.cc/
-  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention
	- https://arxiv.org/abs/2404.07143
	- Infini-attentionã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®LLMsãŒç„¡é™ã«é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æ–°ã—ã„æ‰‹æ³•
	- å¾“æ¥ã®æ³¨æ„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒé•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹éš›ã«ç›´é¢ã™ã‚‹ãƒ¡ãƒ¢ãƒªã¨è¨ˆç®—è² è·ã®å•é¡Œã‚’è§£æ±º
- åŠ ç†±ã™ã‚‹LLMé–‹ç™ºç«¶äº‰ã«å†·ã‚„æ°´ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ã ã‘ã§GPT-4oè¶Šãˆã®äº‹å®Ÿ by shi3zã•ã‚“
	- https://wirelesswire.jp/2024/06/86709/
	- ã“ã®æœ€æ–°ã®LLNã¯ã€æ—¥æœ¬èªå‘ã‘ã‚ªãƒ¼ãƒ—ãƒ³LLMã¨ã—ã¦ã¯åˆã®ã€Œå‘½ä»¤å®Ÿè¡Œã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ–½ã•ã‚Œã¦ã„ã‚‹
	- Karakuriã¯ã“ã‚“ãªä½äºˆç®—ã§æ—¥æœ¬èªæœ€é«˜æ€§èƒ½ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆLLMã‚’ä½œã‚‹ã“ã¨ãŒã§ããŸã®ã‹ã€‚ãã‚Œã¯NVIDIAã®GPUã‚’ä½¿ã£ã¦ã„ãªã„ã‹ã‚‰ã ã€‚
	- äºŒé€±é–“ã»ã©å‰ã«ç™ºè¡¨ã•ã‚ŒãŸã€Œ[Mixture-of-Agents](https://arxiv.org/abs/2406.04692)(ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæˆ)ã€ã¨ã„ã†è«–æ–‡ãŒã‚ã‚‹ã€‚
	- ã™ã§ã«å…¬é–‹ã•ã‚Œã¦ã„ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³LLMã‚’8ã¤çµ„ã¿åˆã‚ã›ã¦ä½¿ã†ã ã‘ã§ã€GPT-4oå˜ä½“ã®æ€§èƒ½ã‚’ä¸Šå›ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã¨ãªã£ãŸã¨ä¸»å¼µã—ã¦ã„ã‚‹ã€‚
	- LLMã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã£ã¦GPT-4oã¨åŒç­‰ã®æ€§èƒ½ã ãŒè¨ˆç®—åŠ¹ç‡ã¯åœ§å€’çš„ã«é«˜ã„MoA-Liteã¨ã€GPT-4oã‚ˆã‚Šè¨ˆç®—é‡ã‚‚å°‘ãªãã•ã‚‰ã«é«˜æ€§èƒ½ãªMoAã®äºŒã¤ãŒææ¡ˆã•ã‚ŒãŸã€‚
	- ä¸–ç•Œä¸­ã®å¤§ä¼æ¥­ãŒä½•åƒå„„ã€ã²ã‚‡ã£ã¨ã—ãŸã‚‰åˆè¨ˆã—ã¦ä½•å…†å††ã¨ã„ã†é‡‘é¡ã‚’GPUã«æµªè²»ã—ã¦ã„ã‚‹é–“ã«ã€å¼·ã‹ãªäººãŸã¡ã¯æ—¢å­˜ã®æŠ€è¡“ã®æ‰‹è»½ãªçµ„ã¿åˆã‚ã›ã§å¤§ããªé€²æ­©ã‚’æˆã—é‚ã’ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã€‚
	- ç­†è€…(shi3zã•ã‚“)ã‚‚æ—©é€Ÿã€æ—¥æœ¬èªã®ã‚ªãƒ¼ãƒ—ãƒ³LLMã‚’Mixture-of-Agentsã§çµ„ã¿åˆã‚ã›ã‚’è©¦ã™ã¤ã‚‚ã‚Šã ã€‚  
	- ã“ã‚Œã¨DiscoPOPã‚’çµ„ã¿åˆã‚ã›ã¦ã€æ—¥æœ¬èªLLMã®æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’GPTã¾ãŸã¯LLMè‡ªèº«ã«è©•ä¾¡ã•ã›ã‚‹ã¨ã„ã†ã®ã‚‚é¢ç™½ã„ã€‚
-  Claude 3.5 Sonnet ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/n7c8e19914166
	- å¤§å­¦é™¢ãƒ¬ãƒ™ãƒ«ã®æ¨è«– (GPQA)ã€å­¦éƒ¨ãƒ¬ãƒ™ãƒ«ã®çŸ¥è­˜ (MMLU)ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°èƒ½åŠ› (HumanEval) ã«ãŠã„ã¦ã€æ–°ãŸãªæ¥­ç•ŒåŸºæº–ã‚’è¨­å®šã—ã¾ã—ãŸã€‚ãƒ‹ãƒ¥ã‚¢ãƒ³ã‚¹ã€ãƒ¦ãƒ¼ãƒ¢ã‚¢ã€è¤‡é›‘ãªæŒ‡ç¤ºã®æŠŠæ¡ã«ãŠã„ã¦é¡•è‘—ãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œã€è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§é«˜å“è³ªã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ›¸ãã“ã¨ã«å„ªã‚Œã¦ã„ã¾ã™
	- æŒ‡ç¤ºã«å¾“ã£ã¦[é©åˆ‡ãªãƒ„ãƒ¼ãƒ«ãŒæä¾›ã•ã‚Œã‚Œã°](https://www.anthropic.com/news/tool-use-ga)ã€é«˜åº¦ãªæ¨è«–æ©Ÿèƒ½ã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’ç‹¬è‡ªã«è¨˜è¿°ã€ç·¨é›†ã€å®Ÿè¡Œã§ãã¾ã™ã€‚ã‚³ãƒ¼ãƒ‰å¤‰æ›ã‚‚ç°¡å˜ã«å‡¦ç†ã§ãã‚‹ãŸã‚ã€ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ›´æ–°ã‚„ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç§»è¡Œã«ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚
	- ã€Œ**Artifacts**ã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒClaudeã¨ã‚„ã‚Šå–ã‚Šã™ã‚‹æ–¹æ³•ã‚’æ‹¡å¼µã™ã‚‹æ–°æ©Ÿèƒ½ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒClaudeã«ã‚³ãƒ¼ãƒ‰ã€ãƒ†ã‚­ã‚¹ãƒˆã€Webã‚µã‚¤ãƒˆãƒ‡ã‚¶ã‚¤ãƒ³ãªã©ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†ã«ä¾é ¼ã™ã‚‹ã¨ã€ã“ã‚Œã‚‰ã®ArtifactsãŒä¼šè©±ã®æ¨ªã«ã‚ã‚‹å°‚ç”¨ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
	- Anthropicã®ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ è©•ä¾¡ã§ã¯ã€ã€ŒClaude 3.5 Sonnetã€ã¯ASL-2ã®ã¾ã¾ã§ã‚ã‚‹ã¨çµè«–ä»˜ã‘ã‚‰ã‚Œã¾ã—ãŸã€‚
-  Claude 3.5 Sonnet ã®è©•ä¾¡ã«é–¢ã™ã‚‹å‚™å¿˜éŒ²
	- https://tech.algomatic.jp/entry/papers/anthropic-2024-claude35
	- è«–æ–‡ã«ã‚ã£ãŸã€æ§˜ã€…ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å…·ä½“çš„ãªæ€§èƒ½ã‚’ä¾‹ç¤ºã—ã¦ã„ã‚‹
	- Artifacts â€” a new way to use Claude
		- https://www.youtube.com/watch?v=rHqk0ZGb6qo&t=4s
- ã‚¤ãƒ³ãƒ‰ã®ç‰©ç†å­¦è€…ãŒã²ã‚‚ç†è«–ã®ç ”ç©¶ã‹ã‚‰å¶ç„¶ã€Œå††å‘¨ç‡ã€ã®æ–°ã—ã„å…¬å¼ã‚’ç™ºè¦‹
	- https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.132.221601
- VLSIã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ã§ã¯Mediatakã®LLMå‘ã‘ãƒ¢ãƒã‚¤ãƒ«ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ç™ºè¡¨ãŒè¿«åŠ›ã‚ã£ãŸ by ç«¹å†…ã•ã‚“
	- https://x.com/kentakeuchi2003/status/1804713977886425509
	- ã‚¨ãƒƒã‚¸AIã«ã‚‚LLMãŒæ¥ã‚‹ãã€ã¨ã„ã†ã‚ˆã‚Šã‚‚ã€ã‚‚ã†æ¥ã¦ã„ã‚‹ã¨ã„ã†æ„Ÿã˜ã€‚
- Claude 3.5 ä½¿ã£ãŸã‚‰ 5åˆ†ãã‚‰ã„ã§æŠ½è±¡è¨€èªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼Grimoã®ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ¢ãƒƒã‚¯å‡ºæ¥ã¦ã—ã¾ã£ãŸ
	- https://x.com/ai_syacho/status/1804400108664189260
- Claude able to produce simulated 3d physics using WebGL
	- https://x.com/Hamptonism/status/1804496837216227756
- Magpieã¨ã„ã†æ‰‹æ³•ã‚’Nemotron-4-340B-Instructã«é©ç”¨ã—ã€æ—¥æœ¬èªãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤ç”¨instructionã®åˆæˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¦ã¿ã¾ã—ãŸã€‚
	-	https://x.com/Aratako_LM/status/1804817272911138909
	-	ç‰¹ã«ãƒ•ã‚£ãƒ«ã‚¿ç­‰ã—ã¦ã„ãªã„ç”Ÿã®ãƒ‡ãƒ¼ã‚¿ã§ã™ãŒã€åˆæˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã¯ã‹ãªã‚Šè³ªãŒé«˜ãã†ã§ã™ã€‚ï¼ˆæµçŸ³Nemotron-4ï¼‰
-	Chrome ã® Gemini Nano ã‚’è©¦ã™ by npakaã•ã‚“
	-	https://note.com/npaka/n/n17176250330e?sub_rt=share_h
	-	ã€ŒChromeã€ã®ã€ŒGemini Nanoã€ã®æ—©æœŸã‚¢ã‚¯ã‚»ã‚¹ç‰ˆãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
	-	ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
	-	(1) ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã€Œè¡¨ç¤º â†’ é–‹ç™º/ç®¡ç† â†’ JavaScriptã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã€ã§ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‚’è¡¨ç¤ºã€‚
	-	(2)ã„ã‹ãŒã‚³ãƒ¼ãƒ‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸
		-	const canCreate = await  window.ai.canCreateTextSession();
		-	const session = await  window.ai.createTextSession(); 
		-	const result = await session.prompt("ã¾ã©ã‹â˜†ãƒã‚®ã‚«ã§ã¯èª°ãŒä¸€ç•ªã‹ã‚ã„ã„?");
		-	console.log(result);

## 6/17

ä»Šé€±ã¯ã€WWDCã§å§‹ã¾ã£ãŸã€‚ã‚¢ãƒƒãƒ—ãƒ«æœ¬ç¤¾ä¸Šç©ºã‹ã‚‰ãƒ‘ãƒ©ã‚·ãƒ¥ãƒ¼ãƒˆã§é™ã‚Šã‚‹ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ã‹ã‚‰ã€ã‚¯ãƒ¬ã‚¤ã‚°å‰¯ç¤¾é•·ã®è¬ã®é‹å‹•èƒ½åŠ›ã®ãƒ‡ãƒ¢ã€OpenAIã®ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ç›®æ’ƒæƒ…å ±ãŒAppleã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ã®ç¾åœ°ã‹ã‚‰å¤šæ•°ãªã©è©±é¡Œã«äº‹æ¬ ã‹ãªã„ã€‚Apple Intelligenceã¯Appleè£½å“ã«LLMãŒã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ„ã¿è¾¼ã¾ã‚Œã€UXã¨ã—ã¦ã®é›„ã®è²«éŒ²ã‚’ã€Ferret-UIè«–æ–‡ã‚‚ä½µã›ã¦è¦‹ã›ãŸã€‚Siriã‚‚ã€ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã¨ã¯ã„ãˆãªã„ã¾ã§ã‚‚ã€GPT-4oã«ã¤ãªãŒã‚‹ã€ä»Šå¹´æœ«ã«ã¯ãƒªãƒªãƒ¼ã‚¹ã€‚å®Ÿã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ãª3Bã®LLMã€ã‚»ã‚­ãƒ¥ã‚¢ãªã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒ(Mã‚·ãƒªãƒ¼ã‚ºãŒå‹•ãï¼‰ã§ã®LLMã¨ã„ã†ç‹¬è‡ªã®LLMãŒï¼µï¼¸ã‚’èµ·ç‚¹ã«ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«å±•é–‹ã•ã‚Œã¦ã„ã‚‹ã€é–‹ç™ºã«ã‚ãŸã‚ŠAIåŸå‰‡ã‚‚ç‹¬è‡ªã«ä½œã£ã¦ã„ã‚‹ã€‚Googleå¯ã¦ã¾ã—ãŸã‹ï¼Ÿã¨ã„ã†ã‚³ãƒ¡ãƒ³ãƒˆã‚‚ã‚ã£ãŸãŒã€Appleã‚‚ã€ã“ã®LLMã®æ´»ç”¨ã§ã¯ä»–ç¤¾ã¨åŒã˜ã‚ˆã†ãªå±•é–‹ã—ã‹ã§ãã¦ãŠã‚‰ãšã€çµå±€ã€é¡§å®¢ãŒä¸è¦ãªæŠ€è¡“ã‚’è²·ã†ã“ã¨ã«ãªã£ã¦ã„ã‚‹ã¨å³ã—ã„æ„è¦‹ã‚‚ã‚ã£ãŸã€‚ã•ã¦Googleã¯ã€Gemini 1.5 Flashã®è©•åˆ¤ã‚‚é«˜ãã€è­°äº‹éŒ²ä½œæˆã¯ç›¸å½“ã“ãªã›ãã†ã€Chromeã§ã€ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§Gemini NanoãŒå‹•ãã‚ˆã†ã«ãªã‚‹ã‚‰ã—ã„ã€RecurrentGemma-9bã‚‚ã€æ–°ã—ã„ãƒªã‚«ãƒ¬ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã¤é«˜æ€§èƒ½ãªè¨€èªå‡¦ç†ã‚’å®Ÿç¾ã—ãŸã¨ã„ã†ãŒã€ã©ã†ã‚„ã‚‰å‹•ä½œãŒå®‰å®šã—ã¦ãã¦ã„ã‚‹æ¨¡æ§˜ã€‚DeepMindã®ã€LLMã®çŸ¥è­˜ä¸è¶³ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚’ç¢ºã‹ã‚ã‚‹æ–¹æ³•ã¨ã„ã†ã®ã‚‚ã€é¢ç™½ã„ãŒã€äººé–“ã«ã‚‚é©ç”¨ã§ããã†ã ã€‚DreamMachineã‹ã‚‰å‡ºãŸLuma AIã¯ä¸æ°—å‘³ã‚’è¶…ãˆã¦ã„ã‚‹ã€ãƒ‡ãƒ¼ãƒˆä¸­ã«ã»ã‹ã®å­ã«æ°—ã‚’ãã‚‰ã•ã‚Œã‚‹ç”·ã®å­ã¨ã‹ã€å†™çœŸã‚’ã‚‚ã¨ã«å‹•ç”»ã‚’ã¤ãã‚‹ã¨ã„ã†ã“ã¨ã§ã€å¥¥ã•ã‚“ã®è‹¥ã„ã“ã‚ã®å†™çœŸã‹ã‚‰å‹•ç”»ã‚’ä½œã£ãŸã‚Šã¨ã€ã¾ã•ã«ä¸æ°—å‘³ãªæ„Ÿã˜ã€‚ã‚ã¾ã‚Šã«ã‚‚è‡ªç„¶ãªã®ã§ã€ã‚‚ã£ã¨ã‚‚å„ä»‹ãªã®ã¯ã€äººã®è¨˜æ†¶ã‚’ä¸Šæ›¸ãã—ã¦ã—ã¾ã†æã‚ŒãŒã‚ã‚‹ã¨ã„ã†ã“ã¨ã ãã†ã ã€‚äººã®èªçŸ¥ã¯å¼±ã„ã€‚NVIDIAã€æ ªã‚’ï¼‘ï¼åˆ†å‰²ã—ãŸã‚Šã€ã‚ªãƒ¼ãƒ–ãƒ³ã‹ã‚‰A100ã®ãƒœãƒ¼ãƒ‰ã‚’å‡ºã™ãƒ•ã‚¡ãƒ³CEOã®ãƒ“ãƒ‡ã‚ªãŒè©±é¡Œã«ãªã£ãŸã‚Šã€ãã®ãƒ•ã‚¡ãƒ³CEOã¯ç±³åé–€ã‚«ãƒ«ãƒ†ãƒƒã‚¯å¤§å­¦å’æ¥­å¼ã§ã‚¹ãƒ”ãƒ¼ãƒã¨ã€è©±é¡ŒãŒæº€è¼‰ã§ã™ãŒã€Nemotron-4-340Bã¨ã„ã†è¬ã®å·¨å¤§LLMã‚‚ãƒªãƒªãƒ¼ã‚¹ã€‚ã‚‚ã£ã¨ã‚‚ã€æ”»æ’ƒã«å¯¾ã™ã‚‹è„†å¼±æ€§ã«ã¤ã„ã¦ã¯ã¾ã£ãŸãç„¡é…æ…®ãªã“ã¨ã‚‚æ˜ã‚‰ã‹ã«ãªã£ãŸã€‚ä½•ã‚’ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã®ã‹NVIDIAã€‚é«˜æ©‹å…ˆç”Ÿã®ã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åŸºç¤ã¨å¿œç”¨ã€ã€ç´ æ™´ã‚‰ã—ã„è³‡æ–™ãŒã§ã¦ããŸã€LLMã‚’é¿ã‘ã¦ããŸäººã‚‚ã“ã‚Œã¯è¦‹ã‚‹ã¹ãã€‚MoEã®æ¬¡ã®MoAï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰ã£ã¦ã®ã‚‚ã‚ã£ãŸAlpacaEval 2.0 ã§GPT-4oã«å‹ã‚‹ã¨ã€‚ACL 2024ã‹ã‚‰LLMã¯ä¸–ç•Œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã«ãªã‚Šã†ã‚‹ã‹ï¼Ÿã¨ã„ã†è«–æ–‡ã‚‚è©±é¡Œã«ãªã£ãŸã€not reallyã‚‰ã—ã„ã€‚LLMã‚’ä½¿ã„ã“ãªã™ã®ã«å¿…è¦ãªã€è¨€èªåŒ–èƒ½åŠ›ã¯ã€å®Ÿã¯ãƒ¡ã‚¿è¨€èªèƒ½åŠ›ã§ã‚ã‚‹ã¨ã®èª¬ã€ã¾ã‚ã€æœ€æ–°ã®LLMã¯ãƒ¡ã‚¿èƒ½åŠ›ã‚’æŒã£ã¦ã‚‹ã‹ã‚‰ã€ä½¿ã†å´ã«ã‚‚ç›¸å¿œã®åŠ›é‡ãŒå¿…è¦ãªã®ã¯æ˜ã‚‰ã‹ã€‚ä»Šäº•å…ˆç”Ÿã‚‚å¤§åˆ‡ãªã®ã¯ãƒ¡ã‚¿èªçŸ¥èƒ½åŠ›ã¨ã‹è¨€ã£ã¦ãŸãªã€‚LLMãŒè‹¦æ‰‹ãªã€ã‚¢ãƒªã‚¹å•é¡Œã¨ã„ã†ã®ã‚‚è©±é¡Œã«ãªã£ãŸã€ã€Œã‚¢ãƒªã‚¹ã«ã¯Näººã®å…„å¼Ÿã¨Mäººã®å§‰å¦¹ãŒã„ã‚‹ã€‚ã‚¢ãƒªã‚¹ã®å…„ã«ã¯ä½•äººã®å§‰å¦¹ãŒã„ã‚‹ã‹ã€ã€è©¦ã—ã¦ã¿ã‚ˆã†ã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã€Personalized PageRank ã‚’çµ„ã¿åˆã‚ã›ãŸHippoRAGã€äººã®è„³å†…å‡¦ç†ã¨é¡ä¼¼ã—ã¦ã„ã‚‹ã¨ã„ã£ã¦ã‚‹ãŒã€ä»Šäº•å…ˆç”Ÿã®æ–°åˆŠã€ã€Œä½•å›èª¬æ˜ã—ã¦ã‚‚ä¼ã‚ã‚‰ãªã„ã€ã¯ãªãœèµ·ã“ã‚‹ã®ã‹ï¼Ÿã€ã‚’ã¿ã¦ã‚‚ã€éƒ½åˆã®è‰¯ã„è¨˜æ†¶ã«æ®‹ã£ãŸã‚ãšã‹ãªæƒ…å ±ã‹ã‚‰äººé–“ã‚‚ç­”ãˆã¦ã„ã‚‹æ°—ãŒã—ã¦ããŸã€‚ä»Šäº•å…ˆç”Ÿã«ã‚ˆã‚‹ã¨ã€ãƒ“ã‚¸ãƒã‚¹ã‚„æ¢æ±‚ã‚’çªãè©°ã‚ãŸäººãŒå¾—ã‚‰ã‚Œã‚‹ã€Œå„ªã‚ŒãŸç›´è¦³ã€ã¨ã„ã†ã®ã‚’ã€ï¼ˆé ¼ã‚Šã™ãã¦ï¼‰AIãŒå¥ªã†ã®ã§ã¯ã¨ã„ã†ã®ã¯é ­ã«æ®‹ã£ãŸã€‚Luminaã‚‚ãã†ã ãŒã€äººã®èªçŸ¥èƒ½åŠ›ã‚„è¨˜æ†¶ã®é ˜åŸŸã«ã€ãã‚Œã‚’ä½¿ã†ã“ã¨ã§é–“æ¥çš„ã«ã€AIã®å½±éŸ¿ãŒå‡ºã‚‹ã‚ˆã†ã«ãªã£ã¦ããŸã®ã¯ã€æã‚ã—ã„ã€‚

- MMed-Llama-3-8B
	- https://x.com/longislandtea3/status/1799013747178278939
	- ï¼’é€±é–“ã»ã©å‰ã«å‡ºãŸMMed-Llama-3-8B åŒ»ç™‚ç”¨ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯GPT-3.5ã‚’è»½ãè¶…ãˆã€GPT-4ã‚’åŒ¹æ•µã™ã‚‹ã¨è¨€ã£ã¦ã„ã‚‹
- Prometheus-2: An Open-Source Evaluator LM for Your RAG Application
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/prometheus2_cookbook/
	- Prometheus-2 shows a high degree of correlation and agreement with human evaluations, GPT-4, and Claude3, making it a dependable evaluator LM for RAG applications.
- Qwen2-72B-Instructã®ElyzaTasks100ã®å¹³å‡ã‚¹ã‚³ã‚¢ã€4.23ã§ã—ãŸ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1800023709958431166
	- ãƒãƒ£ã‚¯ãƒãƒ£ã™ã”ã„â€¦Gemini1.5Flashã®ãƒãƒ§ã‚¤ä¸‹ã€‚OpenAIã®é€²æ­©ãŒåœæ»æ„Ÿã‚ã‚‹ã®ã«å¯¾ã—ã¦ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã®é€²åŒ–ã¯ã™ã•ã¾ã˜ã„ã§ã™ã€‚
	- Qwen1.5ãŒå‡ºã¦ã‹ã‚‰4ãƒ¶æœˆã€Llama3ã‹ã‚‰2ãƒ¶æœˆã—ã‹çµŒã£ã¦ã¾ã›ã‚“ã€‚ã“ã‚“ãªäº‹æ…‹ã«ãªã‚‹ã¨ã¯
- MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark
	- https://arxiv.org/abs/2406.01574
	- ã‚‚ã¯ã‚„å®šç•ªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã€MMLUã€ã§ã¯LLMã®æ€§èƒ½è©•ä¾¡ã§å·®ãŒã¤ã‹ãªã„ã“ã¨ã‚’å—ã‘ã€ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ«ãƒ¼å¤§å­¦ãªã©ã®ç ”ç©¶è€…ã‚‰ã«ã‚ˆã‚Šã€MMLU-Proã€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚
	- ã™ã§ã«GPT-4oã€Claude 3ã€Llama-3ã€Phi-3ãªã©å¤šæ•°ã§å®Ÿé¨“ãŒè¡Œã‚ã‚Œã€å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´ã‚’æ‰ãˆã‚‹ã“ã¨ã«æˆåŠŸã—ã¦ã„ã¾ã™ã€‚
-  CRAG -- Comprehensive RAG Benchmark
	- https://arxiv.org/abs/2406.04744
	- Meta presents CRAG - Comprehensive RAG Benchmark
	- Presents a factual QA benchmark of 4,409 QA pairs and mock APIs to simulate web and Knowledge Graph (KG) search
- Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- LLMã®è¨ˆç®—ã‚³ã‚¹ãƒˆã‚’æ”¯é…ã™ã‚‹è¡Œåˆ—ç©ï¼ˆMatMulï¼‰ã‚’å®Œå…¨ã«æ’é™¤ã—ãªãŒã‚‰ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒã™ã‚‹æ–¹æ³•ãŒç™ºè¡¨ã•ã‚ŒãŸ 
	- ã¡ã‚‡ã£ã¨å‰ã«æ¥­ç•Œã®è©±é¡Œã‚’å¸­ã‘ã‚“ã—ãŸBitNet1.58bã®ä¸Šä½äº’æ›ã¨ã‚‚ã¨ã‚Œã‚‹ 
	- FPGAã§å®Ÿè£…ã—ã€åŠ¹æœã‚’ç¢ºèªã—ã¦ãŠã‚Šã€ã“ã‚Œã¯è„±GPUã®æµã‚ŒãŒæ¥ã‚‹ã‹ã‚‚ã—ã‚Œãªã„
- Appleãƒ‡ãƒã‚¤ã‚¹ã«ChatGPTãŒçµ±åˆã•ã‚Œã¾ã™ï¼
	- https://x.com/gizmodojapan/status/1800237589330526454
	- iPhone/Macç­‰ã‹ã‚‰ç„¡æ–™ã§ChatGPTã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆã‚‚ä¸è¦ï¼ˆæœ‰æ–™ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’æŒã£ã¦ã‚‹å ´åˆã¯ãã¡ã‚‰ã‚’ä½¿ãˆã‚‹ã‚ˆã†ï¼‰ã€‚
- ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã®æœ€è¿‘ã®é€²åŒ–ã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1800036264487591937
	- ï¼‘å¹´å‰ã®elyza-japanese-llama-2-7bã®é ƒã¯5æ­³å…ãƒ¬ãƒ™ãƒ«ã§ã€
	- åŠå¹´å‰ã®nekomata-14bã§å°å­¦ç”Ÿã€
	- 4ã‚«æœˆå‰ã®Qwen1.5ã§ä¸­å­¦ç”Ÿã€
	- 2ãƒ¶æœˆå‰ã®Llama3ã§é«˜æ ¡ç”Ÿã€
	- ç›´è¿‘ã®Qwen2ã§å¤§å­¦ç”Ÿã£ã¦æ„Ÿã˜ã‹ã‚‚ã—ã‚Œãªã„ã€‚ã‚°ãƒ©ãƒœè²·ã£ã¦ã‚‚ã‹ã¤ã¦ã¯5æ­³å…AIã—ã‹é›‡ç”¨ã§ããªã‹ã£ãŸã®ãŒä»Šã§ã¯åŒã˜ã‚°ãƒ©ãƒœã§å¤§å­¦ç”ŸAIãŒé›‡ç”¨ã§ãã¦ã—ã¾ã†ã¨ã„ã†ã‚³ã‚¹ãƒ‘ã®çˆ†ä¸ŠãŒã‚Šã€‚ãã—ã¦1å¹´å¾Œã¯ã©ã†ãªã£ã¦ã—ã¾ã†ã®ã‹ï¼Ÿé™¢ç”Ÿãƒ¬ãƒ™ãƒ«ï¼Ÿåšå£«ãƒ¬ãƒ™ãƒ«ï¼Ÿ
-  Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
	- https://arxiv.org/abs/2404.05719
	- Apple already published a paper on it that disclosed way more details than what we expect from Apple. 
	- It's called "Ferret-UI", a multimodal vision-language model that understands icons, widgets, and text on iOS mobile screen, and reasons about their spatial relationships and functional meanings.
- GraphRAGãµãƒ¼ã‚“ã£ã¦æ„Ÿã˜ã ã£ãŸã‘ã©ã€ã³ã£ãã‚Šã™ã‚‹ãã‚‰ã„ã‚ã‹ã‚Šã‚„ã™ã‹ã£ãŸ
	- https://x.com/__genzitsu__/status/1800074489897889998
- é–‹ç™ºç‰ˆã®Chromeã§ã€ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§Gemini Nanoã‚’å‹•ã‹ã›ã‚‹ã‚ˆã†ã«ãªã£ãŸ
	- https://x.com/kentaro/status/1799856400149221599
	- ãƒ–ãƒ©ã‚¦ã‚¶APIã ã‘ã§å®Œçµã™ã‚‹éŸ³å£°ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å®Ÿé¨“ã‚’ã—ã¦ã¿ã¾ã—ãŸã€‚ã“ã‚Œã¯å¤¢ãŒåºƒãŒã‚Šã¾ã™ã­ï¼ã‚¢ãƒ„ã„ï¼ï¼
	- https://codesandbox.io/p/sandbox/gemini-nano-chatbot-cdg59q?file=%2Findex.html
		-  LLM: Chromeä¸Šã§å‹•ä½œã™ã‚‹Gemini Nano 
		- éŸ³å£°èªè­˜+éŸ³å£°åˆæˆ: Web Speech API
- ã„ãŸï¼ˆã‚¢ãƒ«ãƒˆãƒãƒ³æ°ãŒã€WWDC2024ã«)
	- https://x.com/iskw226/status/1800202842428653817
- AppleãŒç™ºè¡¨ã—ãŸäººå·¥çŸ¥èƒ½ã€ŒApple Intelligenceã€ by GIZMODE
	- 1. æ–‡ç« ã®è‡ªå‹•ç·¨é›†ãƒ»æ ¡æ­£æ©Ÿèƒ½ 
	- 2. ãƒ¡ãƒ¢ãƒ»ãƒ•ãƒªãƒ¼ãƒœãƒ¼ãƒ‰ãƒ»Keynoteãªã©ã§ç”»åƒç”ŸæˆãŒå¯èƒ½ã« 
	- 3. Apple Intelligenceã¯ã€Œå®Ÿè¡Œã€ãŒã§ãã‚‹ã€‚ã€Œã“ã®é–“ã€é€ã‚‰ã‚Œã¦ããŸãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã‚’å†ç”Ÿã—ã¦ã€ã¨è¨€ãˆã°ã€è¦‹ã¤ã‘å‡ºã—ã¦å†ç”Ÿã™ã‚‹ã“ã¨ã‚ã¾ã§ã‚„ã£ã¦ãã‚Œã‚‹ã‚‰ã—ã„â€¦ï¼ 
	- 4. ãƒ¡ãƒ¼ãƒ«ã§é€ã‚‰ã‚Œã¦ããŸäºˆå®šã¯ã€è‡ªå‹•ã§ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã€‚äºˆå®šã®å ´æ‰€ã®åœ°å›³ãƒ‡ãƒ¼ã‚¿ãªã©ã‚‚è‡ªå‹•ã§æ·»ä»˜ã€‚
- LaVague
	- https://github.com/lavague-ai/LaVague
	- LaVague is an **open-source Large Action Model framework** to develop AI Web Agents.
- Weâ€™re partnering with Apple to integrate ChatGPT into iOS, iPadOS, and macOSâ€”coming later this year:
	- https://x.com/OpenAI/status/1800240380220473552
- ã‚¢ãƒƒãƒ—ãƒ«ãƒ»Googleãƒ»ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãƒ»OpenAIãŒã¿ã‚“ãªã“ã®æŠ€è¡“ã‚’åŒã˜ã“ã¨ã«ã—ã‹ä½¿ãˆã¦ã„ãªã„ã¨ã„ã†ç¾å®Ÿ
	- https://x.com/mehori/status/1800239908713283836
	- ãã—ã¦ãã®é™ç•Œã¯ã€ã§ãã‚‹ã“ã¨ã‹ã‚‰é€†ç®—ã—ã¦å¿…ãšã—ã‚‚å¿…è¦ã¨ã—ãªã„æ©Ÿèƒ½ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãŠã—ã¤ã‘ã‚‹ã“ã¨ã«ã¤ãªãŒã£ã¦ã„ã‚‹
- very happy to be partnering with apple to integrate chatgpt into their devices later this year! by Sam
	- https://x.com/sama/status/1800237314360127905
- æ—…è¡Œãƒ—ãƒ©ãƒ³ã«è¿·ã†äººã¯å…¨å“¡Geminiã‚’ä½¿ã£ãŸæ–¹ãŒè‰¯ã„ã€‚
	- https://x.com/SuguruKun_ai/status/1799695851968942167
- Appleã®äººå·¥çŸ¥èƒ½ï¼ˆç”ŸæˆAIï¼‰ã€ŒApple Intelligenceã€ã¯ã€ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ¼ã‚’ã‚µãƒ¼ãƒãƒ¼ã«é€ä¿¡ã›ãšã«å‡¦ç†ï¼‰ã‚’åŸºæœ¬ã¨ã™ã‚‹ãã†ã§ã™ã€‚
	- https://x.com/gizmodojapan/status/1800231580788736014
- Apple WWDC intro was so lit
	- https://x.com/ai_for_success/status/1800214745078968712
	- ã‚ã‚ã€ç©ºã‹ã‚‰ã€ã‚¹ã‚«ã‚¤ãƒ€ã‚¤ãƒ“ãƒ³ã‚°ã—ã¦ã€ã‚¢ãƒƒãƒ—ãƒ«æœ¬ç¤¾ã«é™ã‚Šã‚‹ã¨ã„ã†ç”»åƒã€ã“ã‚Œã¯æœ¬ç‰©ã‹ï¼Ÿï¼Ÿ
- Appleã«ã“ã“ã¾ã§AIã‚¹ãƒãƒ›çµ±åˆã§å…ˆã‚’è¶Šã•ã‚ŒãŸGoogleã£ã¦ä»Šã¾ã§ä½•ã—ã¦ãŸã®ï¼ŸãƒãƒŒã‚±ã§ã™ã‹ï¼Ÿã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1800236837665206563
-  Mixture-of-Agents Enhances Large Language Model Capabilities
	- https://huggingface.co/papers/2406.04692
	- With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction.
	- we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology.
	- our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni.
- è­°äº‹éŒ²å–ã£ã¦ã‚‹ãªã‚‰Gemini 1.5 Flashã¯ä½¿ã£ãŸæ–¹ãŒè‰¯ã„
	- https://x.com/keitowebai/status/1800006621780951533
	- éŒ²ç”»ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€Œè¦ç‚¹ã‚’ã¾ã¨ã‚ã¦ã€ã¨è¨€ã†ã ã‘ã§è¦ç´„å®Œäº†ã€‚ã“ã‚Œã§å ±å‘Šã¯3åˆ†ã§çµ‚ã‚ã‚‰ã›ã‚ˆã†ã‹ã€‚
- LLMã«å…¥åŠ›ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãã¨ãã«ã¯è¨€èªåŒ–èƒ½åŠ›ãŒå¿…è¦ã€ã¨ã„ã†ã®ã¯æ­£ã—ã„ã¨æ€ã†ã®ã ã‘ã©ã€ã˜ã‚ƒã‚è¨€èªåŒ–èƒ½åŠ›ã£ã¦ãªã‚“ã‚„ã­ã‚“ã€ã¨ã„ã†ã¨ãã«ã€ã€Œæ§‹é€ åŒ–ã•ã‚Œã¦ã„ã¦åˆ†ã‹ã‚Šã‚„ã™ãã€ç¶ºéº—ã§è«–ç†çš„ãªæ–‡ç« ã€ã€ã§ã¯ãªã„ã€ã¨ç§ã¯æ€ã£ã¦ã„ã‚‹ã€‚by mutaguchi
	- https://x.com/mutaguchi/status/1799899202803433571
	- å®Ÿã¯LLMãã‚“ã¯ã‹ã—ã“ãã¦ã€ã‹ã—ã“ããªã„ã®ã§ã€ãœã‚“ãœã‚“æ§‹é€ åŒ–ã•ã‚Œã¦ãªã„ã€è«–ç†ã‚‚ç ´ç¶»ã—ã¦ã„ã¦ã€æ–‡å­—ã‚‚é–“é•ã„ã ã‚‰ã‘ã§ã€è¨€èªã¨ã—ã¦ã‚‚æˆç«‹ã—ã¦ã„ãªã„ã‚ˆã†ãªãã¡ã‚‡ãã¡ã‚‡ãƒ†ã‚­ã‚¹ãƒˆã§ã‚‚ã€å‹æ‰‹ã«é›°å›²æ°—ã§è£œé–“ãƒ»ä¿®æ­£ã—ã¦èª­ã¿å–ã£ã¦ãã‚Œã‚‹ã€‚ãŸã ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã¯å‡ºåŠ›ã«å¿…è¦ãªæƒ…å ±ãŒéä¸è¶³ãªãæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã¯å¿…è¦ã¨ãªã‚‹ã€‚
	- ã¤ã¾ã‚Šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãã®ã«å¿…è¦ãªè¨€èªåŒ–èƒ½åŠ›ã¨ã„ã†ã®ã¯ã€LLMã®å‡ºåŠ›ï¼ˆå…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹è£œå®Œï¼‰ã‚’å¼•ãå‡ºã™ãŸã‚ã«å¿…è¦ãªæ–‡å­—åˆ—ã‚’ã€éä¸è¶³ãªãä»•è¾¼ã‚€èƒ½åŠ›ã§ã¯ã‚ã‚‹ã®ã ãŒã€å¿…ãšã—ã‚‚äººé–“ãŒè¦‹ã¦ã€Œã“ã®äººè¨€èªåŒ–èƒ½åŠ›é«˜ã„ãªã‚ã€ã¨è©•ä¾¡ã•ã‚Œã‚‹ã‚ˆã†ãªæ–‡ç« ã‚’æ›¸ãèƒ½åŠ›ãŒå¿…è¦ã¨ã•ã‚Œã¦ã„ã‚‹ã¨ã¯é™ã‚‰ãªã„ã€ã¨è€ƒãˆã¦ã„ã‚‹ã€‚
- (LLMã«å…¥åŠ›ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›¸ãã¨ãå¿…è¦ãªã®ã¯)ãƒ¡ã‚¿è¨€èªèƒ½åŠ›ã€è¨€èªã«å¯¾ã™ã‚‹ãƒ¡ã‚¿èªçŸ¥ã‹ãª
	- https://x.com/erukiti/status/1799945431864254487
	- ä¼šè©±ã¨ã‹è¨€èªåŒ–ãƒ¬ãƒ™ãƒ«ã§ã¯ãªãã€è¨€èªã‚’æ‰±ã†LLMã‚’hackã™ã‚‹ã‚ˆã†ã«ã€è¨€èªã‚’é–“æ¥çš„ã«æ‰±ã†èƒ½åŠ›ãŒå¿…é ˆã€‚è¦³å¯Ÿãƒ»æ°—ã¥ããƒ»åˆ¶å¾¡ãƒ»ã­ã˜ä¼ã›
	- 1. å¯¾è±¡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã¨ãƒœã‚­ãƒ£ãƒ–ãƒ©ãƒªãŒæ­»ã¬ã»ã©å¿…è¦ï¼ˆã“ã“ã¾ã§ã¯æ™®é€šã®è¨€èªèƒ½åŠ›ã€‚ç°¡å˜ã‚„ã­ã€ã‚„ã£ãŸï¼ï¼‰ 
	- 2. LLMãŒã©ã®ç¨‹åº¦ç†è§£ãŒå®šã¾ã£ã¦ã‚‹ã‹ã®è¦‹æ¥µã‚ãŒå¿…è¦ï¼ˆä¸€ç™ºã§æŒ‡å®šã§ãã‚‹ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚Œã°ã€èª¬æ˜æ–‡ãŒå¿…è¦ã€å®šç¾©ã‚’ä¸€é€šã‚Šæ¸¡ã™å¿…è¦ãªã©ã®ã‚±ãƒ¼ã‚¹ã‚‚ã‚ã‚‹ã€‚ã“ã“ã‚‰ã¸ã‚“ã¯ã‚‚ã†è¨€èªèƒ½åŠ›ã¨ã„ã†ã‚ˆã‚Šãƒ¡ã‚¿è¨€èªèƒ½åŠ›ï¼‰ 
	- 3. 2ã§è¦‹æ¥µã‚ãŸç¯„å›²å†…ã§æŒ‡ç¤ºã‚’ã©ã‚Œã ã‘æœ€ä½é™ã«è»½é‡åŒ–ã§ãã‚‹ã‹ï¼Ÿè¤‡é›‘ãªæŒ‡ç¤ºã¯ã€æŒ‡ç¤ºã‚’è§£é‡ˆã™ã‚‹ã¨ã“ã‚ã«LLMã®çŸ¥æ€§ã‚’ä½¿ã„ã™ãã¦ã€æŒ‡ç¤ºãã®ã‚‚ã®ã«è¿½å¾“ã§ããªããªã‚‹ã“ã¨ãŒã‚ã‚‹ã‹ã‚‰ã€æŒ‡ç¤ºã«å¾“ãˆã‚‹ã‚®ãƒªã‚®ãƒªæœ€å°é™ã‚’ç‹™ã†ã“ã¨ã«ãªã‚‹ï¼ˆãƒ¡ã‚¿è¨€èªèƒ½åŠ›ï¼‰ 
	- ã‚ã¨ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ã‚’LLMã§ç”Ÿæˆã™ã‚‹ãƒ¡ã‚¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„ãƒ¡ã‚¿ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¿ãŸã„ãªã®ã‚‚æ™®é€šã«å‡ºã¦ãã‚‹ã‹ã‚‰ã€ãã†ã„ã†æ„å‘³ã§ã‚‚ãƒ¡ã‚¿è¨€èªèƒ½åŠ›ãŒå¿…è¦ã ã¨æ€ã†
- If Apple integrates OpenAI at the OS level, then Apple devices will be banned at my companies. by maskã•ï½
	- https://x.com/elonmusk/status/1800265431078551973
- çµ±è¨ˆå­¦ã®æœ¬è³ªã®ä¸€ã¤ã¯ä»®å®šã«ã‚ã‚‹ã¨æ€ã†ã€‚ 
	- https://x.com/1kn29cgQJzRwtgd/status/1800005796585259435
	- ãã‚‚ãã‚‚çµ±è¨ˆå­¦é–¢ä¿‚ãªãã€ãƒ‡ãƒ¼ã‚¿ã‚’è§£é‡ˆã™ã‚‹éš›ã€äººé–“ã¯ä»®å®šã‚’ãŠãã€‚ é€šå¸¸ãã‚Œã¯æš—é»™ã®ä»®å®šã ãŒã€çµ±è¨ˆå­¦ã¯ãã‚Œã‚’æ˜ç¤ºã—ã€ãã®ä»®å®šã§ã‚ˆã„ã®ã‹ã‚„ä»®å®šãŒã‚ºãƒ¬ã‚‹ã“ã¨ã®å½±éŸ¿ã‚’è­°è«–ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚ ä»®å®šã‚’æ˜ç¤ºã—ã€è­°è«–ã®ä¿ä¸Šã«ã®ã›ã‚‹ã€‚ã“ã‚ŒãŒçµ±è¨ˆå­¦ã®åŠ¹èƒ½ã®ä¸€ã¤
- SEDDã¯é›¢æ•£ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã€‚by å²¡é‡åŸã•ã‚“
	- https://x.com/hillbig/status/1800303691364470800
	- é›¢æ•£ç‰ˆã®ã‚¹ã‚³ã‚¢ã§ã‚ã‚‹ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆã‚¹ã‚³ã‚¢ï¼ˆp(y)/p(x)ï¼‰ã‚’ãƒ‡ãƒã‚¤ã‚¸ãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æœ€å°åŒ–ã§æ±‚ã‚ã‚‹ã€‚ã‚¹ã‚³ã‚¢ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯ELBOã¨ã¿ãªã›å°¤åº¦ã®ä¸‹é™ã‚’ä¸ãˆã‚‰ã‚Œã‚‹ã€‚è¨€èªãƒ¢ãƒ‡ãƒ«ãªã©ã§åŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã€‚ä¸€è²«æ€§ã«å„ªã‚Œã‚‹
-  To Believe or Not to Believe Your LLMã€€by DeepMind
	- https://arxiv.org/abs/2406.02543
	- Google DeepMindã¯ã€ã‚ã‚‹å•é¡Œã«ãŠã‘ã‚‹LLMã®çŸ¥è­˜ä¸è¶³ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚’ç¢ºã‹ã‚ã‚‹æ–¹æ³•ã‚’è€ƒæ¡ˆã—ã¦ã„ã¾ã™ã€‚
	- åŒã˜è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ã®ãƒãƒ©ã¤ãã‚’è¦‹ã‚‹ã“ã¨ã§ã€è‡ªä¿¡ã‚’æŒã£ã¦æ­£ã—ã„å›ç­”ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€çŸ¥è­˜ä¸è¶³ã®ãŸã‚ã«é–“é•ã£ãŸå›ç­”ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’åˆ¤æ–­ã§ãã‚‹ã¨ã®ã“ã¨ã§ã™ã€‚
-  Appleã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ãƒ»ã‚µãƒ¼ãƒãƒ¼åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/ncd651c042e6a?sub_rt=share_h
	- ã€ŒApple Intelligenceã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¥å¸¸çš„ãªã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸè¤‡æ•°ã®é«˜æ€§èƒ½ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ç¾åœ¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ã«å³åº§ã«é©å¿œã§ãã¾ã™ã€‚
	- https://machinelearning.apple.com/research/introducing-apple-foundation-models
	- ã€Œ**ç´„3Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ã®è¨€èªãƒ¢ãƒ‡ãƒ«**ã€ã¨ã€Œ**Private Cloud Computeã§åˆ©ç”¨ã§ãã‚‹ã‚µãƒ¼ãƒãƒ¼ã®è¨€èªãƒ¢ãƒ‡ãƒ«**ã€ãŒã€ç‰¹æ®Šãªã‚¿ã‚¹ã‚¯ã‚’åŠ¹ç‡çš„ã€æ­£ç¢ºã€è²¬ä»»ã‚’æŒã£ã¦å®Ÿè¡Œã™ã‚‹ãŸã‚ã«ã©ã®ã‚ˆã†ã«æ§‹ç¯‰ãŠã‚ˆã³é©å¿œã•ã‚ŒãŸã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚
	- AIãƒ„ãƒ¼ãƒ«ã®é–‹ç™ºæ–¹æ³•ã¨ãã‚Œã‚’æ”¯ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¬ã‚¤ãƒ‰ã™ã‚‹è²¬ä»»ã‚ã‚‹AIåŸå‰‡ã‚’ä½œæˆã—ã¾ã—ãŸã€‚
-  Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/html/2406.02061v1
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
- Sam Altmanâ€™s blue backpack didnâ€™t show up today at Apple Park which is a notable shift for AI safety and preparedness.
	- https://x.com/RayFernando1337/status/1800366357902709184
	- ã©ã†ã‚‚ã€ã‚¢ãƒ«ãƒˆãƒãƒ³æ°ã®é’ã„ãƒãƒƒã‚¯ãƒ‘ãƒƒã‚¯ã«ã¯ã€ChtGPTã‚’æ­¢ã‚ã‚‹ã‚¹ã‚¤ãƒƒãƒãŒå…¥ã£ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚
- Appleã®ã‚¯ãƒ¬ã‚¤ã‚°å‰¯ç¤¾é•·ã€å°‹å¸¸ã§ãªã„é‹å‹•èƒ½åŠ›ã‚’è¦‹ã›ã‚‹ã€‚ã€‚
	https://x.com/durreadan01/status/1800453311382147219
- guide on finetuning an LLM to query knowledge graphs (through text-to-cypher).
	- https://github.com/neo4j-labs/text2cypher/blob/main/finetuning/unsloth-llama3/README.md#llamaindex
	- that allows you to directly use this LLM to generate cypher statements and retrieve knowledge graph entities as "chunks" for your Graph RAG pipeline!
- RecurrentGemma 9B 
	- https://huggingface.co/collections/google/recurrentgemma-release-66152cbdd2d6619cb1665b7a
	- This new model achieves performance comparable to the largest Gemma 1 model, but with significantly greater efficiency.
	- For example, on a single TPU-v4, it delivers 80x higher throughput when sampling 1k tokens from a 2k token prompt.
- Doing RAG? Vector search is *not* enough
	- https://techcommunity.microsoft.com/t5/microsoft-developer-community/doing-rag-vector-search-is-not-enough/ba-p/4161073
	- RAGã«ãŠã„ã¦ã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã ã‘ã˜ã‚ƒãªãå…¨æ–‡æ¤œç´¢ã‚‚åŠ ãˆãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã˜ã‚ƒãªã„ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‡ºãªã„ã“ã¨ã‚’è©¦ã—ã¦ã¿ãŸã€ã¨ã„ã†Microsoftæ–¹ã®è¨˜äº‹
	- RAG ï¼ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ã„ã†é¢¨æ½®ãŒã‚ã‚‹ãŒã€ãã†ã§ã¯ãªã„ã€ã¨
-  Llama for Scalable Image Generation a.k.a LlamaGen
	- https://github.com/FoundationVision/LlamaGen
	- æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹Transformerã«ã‚ˆã‚‹ç”»åƒç”Ÿæˆ
- Apple Intelligence ã®æ€§èƒ½ã®è‡ªç¤¾è©•ä¾¡ã®çµæœã€‚
	- https://x.com/overlast/status/1800746455159963737
	- ãƒ‡ãƒã‚¤ã‚¹å†…ãƒ¢ãƒ‡ãƒ«ã§ã¯7Bãƒ¢ãƒ‡ãƒ«ã®ä¸Šä½ã«ä½ç½®ã—ã¦ã„ã¦ã€ã‚µãƒ¼ãƒãƒ¼å†…ãƒ¢ãƒ‡ãƒ«ã§ã¯GPT-3.5 Turboã‚’å‡Œé§•ã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚ç²›ã€…ã¨æ€§èƒ½ã‚’ä¸Šã’ã¦ã„ã¦å‡„ã„ |
-  RecurrentGemma-9b: é©æ–°çš„ãªè‡ªç„¶è¨€èªå‡¦ç†ãƒ¢ãƒ‡ãƒ«ã®ç™»å ´
	- https://hamaruki.com/recurrentgemma-introducing-a-revolutionary-natural-language-processing-model/
	- RecurrentGemmaã¯ã€å¾“æ¥ã®Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æ–°ã—ã„ãƒªã‚«ãƒ¬ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã‹ã¤é«˜æ€§èƒ½ãªè¨€èªå‡¦ç†ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚
	- Colab notebook
	- https://colab.research.google.com/drive/1jDbbKhBs-A__QOtp7S6WxGxBH4J6gtuj?usp=sharing
-  Advancing personal health and wellness insights with AI
	- https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/
	- Today on the blog, read about the latest from our two new research papers on how AI, particularly fine-tuned Gemini models, can create personalized health experiences that cater to individualsâ€™ unique health journeys.
- LLM CLI tool are the cool things you can do with piping.
	- https://x.com/HamelHusain/status/1800741993276203043
- æœ€æ–°ã®LLMã®å¤šãã¯ã€Œã‚¢ãƒªã‚¹ã«ã¯Näººã®å…„å¼Ÿã¨Mäººã®å§‰å¦¹ãŒã„ã‚‹ã€‚ã‚¢ãƒªã‚¹ã®å…„ã«ã¯ä½•äººã®å§‰å¦¹ãŒã„ã‚‹ã‹ã€ã¨ã„ã†ç°¡å˜ãªæ¨è«–ã¨å¸¸è­˜ã‚’å¿…è¦ã¨ã™ã‚‹å•é¡ŒãŒè§£ã‘ãªã„ã“ã¨ã‚’æŒ‡æ‘˜ã€‚
	- https://x.com/shion_honda/status/1800895368458305643
- ã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®åŸºç¤ã¨å¿œç”¨ã€ã®è¬›ç¾©è³‡æ–™ã‚’å…¬é–‹ã—ã¾ã™ by å¤§é˜ªå¤§å­¦ã€€é«˜æ©‹å…ˆç”Ÿ
	- https://x.com/taka8hiroshi/status/1801177682450981251
	- æœ€å°¤æ¨å®šã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦ã€æ·±å±¤ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚„Transformerã‚’ä¸€é€šã‚Šç†è§£ã—ã‚ˆã†ã¨ã„ã†å†…å®¹ã§ã™ã€‚ãœã²ã”è¦§ãã ã•ã„
		- https://speakerdeck.com/takahashihiroshi/generative-models
- ã‚µã‚«ãƒŠAIãŒ1å¹´ã§ãƒ¦ãƒ‹ã‚³ãƒ¼ãƒ³ã€€æ—¥æœ¬æœ€é€Ÿï½¤200å„„å††è¿½åŠ èª¿é”
	- https://www.nikkei.com/article/DGXZQOUC144OB0U4A610C2000000/
- Oumuamua-7b-instruct-v2ã€Shaberi3ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§å¹³å‡ç‚¹7.25ã§ã™ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1801836418744127702
	- GPT3.5Tï¼ˆ7.16ï¼‰ã‚„Qwen2-7Bï¼ˆ7.23ï¼‰ã‚’è¶…ãˆã¦ã¾ã™ã€‚ãƒ¡ãƒƒãƒãƒ£å¼·ã„
- å·¨äººã‚ªãƒ¼ãƒ—ãƒ³LLMã§è©±é¡Œã® Nemotron-340B ãŠè©¦ã— by AIXã•ã¨ã—ã•ã‚“
	- https://x.com/AiXsatoshi/status/1801865161717760380
	- æ—¥æœ¬èªæ¨è«–ã€ç”Ÿæˆå¯èƒ½ã€ã‚ªãƒ¼ãƒ—ãƒ³LLMã¨ã—ã¦ã¯ã€çŸ¥è­˜ã¯éå¸¸ã«æ­£ç¢º
- RecurrentGemma 9Bã¯ã€Griffinã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ãŸGemmaãƒ¢ãƒ‡ãƒ«
	- https://x.com/webbigdata/status/1801928695764099084
	- Gemma 7Bã¯ç‰¹å®šã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ã‚¿ã‚¹ã‚¯(ç§‘å­¦ã€æ•°å­¦ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å•é¡Œ)ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ 
	- RecurrentGemma 9Bã¯ã€å¸¸è­˜æ¨è«–ã‚„ä¸€èˆ¬çŸ¥è­˜ã‚’å¿…è¦ã¨ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ ã¨è¨€ã†é•ã„ãŒã‚ã‚Šã¾ã™
	- RecurrentGemma 9Bã¯Hugging faceã®Transformesrã§å¾®èª¿æ•´ã‚µãƒãƒ¼ãƒˆã¯ã•ã‚Œã¦ã„ã¾ã™ãŒã€issuesè¦‹ã‚‹é™ã‚Šå±é™ºãªé¦™ã‚ŠãŒã™ã‚‹ã®ã§
-  HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models
	- https://arxiv.org/abs/2405.14831
	- çŸ¥è­˜ã‚°ãƒ©ãƒ•ã€Personalized PageRank ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’çµ„ã¿åˆã‚ã›ãŸRAGã®æ‰‹æ³•ã®ææ¡ˆã€‚äººé–“ã®è„³ã®è¨˜æ†¶ã®ä»•çµ„ã¿ã‚’æ¨¡å€£ã€‚
-  Nemotron-4 340B from NVIDA
	- https://research.nvidia.com/publication/2024-06_nemotron-4-340b
	- æ˜¨æ—¥ã«å‡ºãŸNemotron-4 340Bã‚‚ã€äººé–“ãŒ2ä¸‡ä»¶ã€æ®‹ã‚Š98%(98ä¸‡ä»¶?)ã¯åˆæˆãƒ‡ãƒ¼ã‚¿ã§alignmentã—ãŸæ¨¡æ§˜(?)
- ã‚µã‚¯ãƒƒã¨è«–æ–‡èª­ã‚€ãªã‚‰Googleã®NotebookLMã‚’ä½¿ã£ãŸã»ã†ãŒè‰¯ã„
	- https://x.com/tetumemo/status/1801889597871558864
- nvidia/Nemotron-4-340B-Instruct
	- https://huggingface.co/nvidia/Nemotron-4-340B-Instruct
	- https://x.com/webbigdata/status/1802173127767802234
		- ãƒ¢ãƒ‡ãƒ«ã¯å•†æ¥­çš„ã«åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ 
		- æ´¾ç”Ÿãƒ¢ãƒ‡ãƒ«ã¯è‡ªç”±ã«ä½œæˆãŠã‚ˆã³é…å¸ƒã§ãã¾ã™ã€‚ 
		- NVIDIA ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯æ´¾ç”Ÿãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”Ÿæˆã•ã‚ŒãŸå‡ºåŠ›ã«å¯¾ã™ã‚‹æ‰€æœ‰æ¨©ã‚’ä¸»å¼µã—ã¾ã›ã‚“ã€‚
-  An Empirical Study of Mamba-based Language Models
	- https://arxiv.org/abs/2406.07887
	- Mamba2ã¨Transformerã®æ¯”è¼ƒã€‚å­¦ç¿’é‡ãŒ1.1Ttokenã ã¨Transformerã®æ–¹ãŒç²¾åº¦ãŒè‰¯ã„ã€‚ä¸€æ–¹3.5Ttokenå­¦ç¿’ã™ã‚‹ã¨Mamba2ãŒè‰¯ããªã‚‹ã€‚
	- https://x.com/jnishi/status/1801842541639438494
	- ICLã®æ€§èƒ½ã¯Mamba2ã¯Transformerã«åŠã°ãªã„ãŒã€Mamba2ã¨MLPã¨self-attentionã‚’å°‘ã—ã§æ§‹æˆã—ãŸMamba2-Hybridã¯ICLæ€§èƒ½ã¯é«˜ã„ã€‚
- nitky/Oumuamua-7b-instruct-v2
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
-  LLMFlex
	- https://github.com/nath1295/LLMFlex
	- LLMFlexã€‚LangChainã‚ˆã‚Šã‚‚è‰²ã€…ã¨ç°¡å˜ã«ã—ã¤ã¤ã€StreamLitã§ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰UIã¾ã§ä»˜ã‘ã¦ãã‚Œã¡ã‚ƒã£ã¦ã‚‹ãƒ–ãƒ„ã€‚ã“ã†ã„ã†ã®ã‚ã‚ŠãŒãŸã„ã­ã€‚GPTQã‚„GGUFãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã€‚DuckDuckGoæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§RAGã¨ã‹ã‚‚ãƒ‘ãƒƒã¨ã§ãã‚‹
- Dream Machine by Luma AI is just 3 days old.
	- https://x.com/hey_madni/status/1801900554488291414
	- 1. Distracted boyfriend
	- 2. Disaster girl with firefighters
- Ninja-v1ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã€Ninja-V2-7Bã‚’ãƒªãƒªãƒ¼ã‚¹è‡´ã—ã¾ã™ã€‚
	- https://huggingface.co/Local-Novel-LLM-project/Ninja-V2-7B
	- ãƒ™ã‚¯ãƒˆãƒ«ãƒãƒ¼ã‚¸ç­‰ã®æŠ€è¡“ã‚’æ´»ç”¨ã—ä½œæˆã—ãŸMistralãƒ™ãƒ¼ã‚¹ã®70å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
	- Gemini pro 1.0è©•ä¾¡ã§ Elyza taskã§3.71 JP MT Benchã§8.24
- Flaxã‚’ä½¿ç”¨ã—ãŸRecurrentGemma2Bã‚°ãƒªãƒ•ã‚£ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«(Kaggleã€GoogleColabãƒãƒ¼ãƒˆä»˜)
	- https://x.com/hAru_mAki_ch/status/1802227933534429614
- Nemotron-4 340B is a huge release by NVIDIA!
	- https://x.com/omarsar0/status/1802024352851878296
	- The Nemotron-4 340B instruct model lets you generate high-quality data and then the reward model (also released) can filter out data on several attributes.
	- The results show that Nemotron-4 340B is a strong model. Check out those MMLU, GSM8K, and Arena Hard numbers.
- ãŸã¨ãˆã°Dream Machineã«æ˜”ã®å†™çœŸå…¥ã‚Œã¦å‹•ç”»ã«ã™ã‚‹ã¨ã€ãã‚Œã¯100%ã‚¦ã‚½ã®ãƒã‚ºãªã®ã«ã€ãªã‚“ã‹50%ãã‚‰ã„æœ¬å½“ã ã£ãŸã‚ˆã†ãªæ°—ãŒã—ã¦ãã‚‹ã¨ã„ã†ã‚ˆã†ãª
	- https://x.com/hirochuu8/status/1801986929183142369
- Exciting that our Mixture of Agents (MoA) tops the AlpacaEval leaderboard!
	- https://x.com/james_y_zou/status/1801656163936964919
- Ninja-V2-7Bã®Shaberi3ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ã¯6.80ã§ã—ãŸ
	- https://x.com/umiyuki_ai/status/1802027838524321839
- Can language models be used as world simulators? In our ACL 2024 paper, we show -- not really.
	- https://arxiv.org/pdf/2406.06485
	- GPT-4 is only ~60% accurate at simulating state changes based on common-sense tasks, like boiling water.
- nvidiaã®ãƒ•ã‚¡ãƒ³CEOã€Caltecã®å’æ¥­å¼ã§ã‚¹ãƒ”ãƒ¼ãƒ
	- https://x.com/shuki004/status/1801681153705054588
-  Lares smart home assistant: A toy AI agent demonstrating emergent behavior
	- https://interconnected.org/more/2024/lares/
	- This is a great little example of how simple agent-based systems can lead to emergent behavior, even with tiny AIs like Apple's on-device LLM.
	- Matt Webb built a demo AI smart home, when he asks it "turn on the light for my dog" the home figures out how.
- DreamMachineãŒå±é™ºãªã®ã¯ã€ç”Ÿæˆå‹•ç”»ã‚’è¦‹ãŸã‚‰ã€Œæœ¬äººã®è¨˜æ†¶ãŒä¸Šæ›¸ãã•ã‚Œã‚‹ã€ç‚¹ã ã¨æ€ã†
	- https://x.com/genmeisui/status/1801944958062239884
	- ä¾‹ãˆã°ç—´æ¼¢å†¤ç½ªã®äººã«ã€Œè§¦ã£ãŸç¬é–“ã®å‹•ç”»ãŒè¦‹ã¤ã‹ã£ãŸã€ã¨ç”Ÿæˆå‹•ç”»ã‚’è¦‹ã›ç¶šã‘ãŸã‚‰ã€ã€Œã‚„ã£ãŸã‹ã‚‚ã€ã¨æ€ã„è¾¼ã¾ã›ã‚‹ã“ã¨ã¯é›£ã—ããªã„
- äºˆæƒ³ã¯ã—ã¦ã„ãŸã‘ã©5äººç›®ãŒå‡ºã¦ããŸæ™‚ç‚¹ã§ãƒ€ãƒ¡ã ã£ãŸ [#DreamMachine](https://x.com/hashtag/DreamMachine?src=hashtag_click)
	- https://x.com/kizuki_jpn/status/1801950889747354076
-  Coupled Ocean-Atmosphere Dynamics in a Machine Learning Earth System Model
	- https://arxiv.org/abs/2406.08632
	- New Earth-2 nvidia preprint about AI forecasting for seasonal timescales including interactive ocean coupling. The generated El NiÃ±o looks realistic including its subsurface thermal structure. Internship project led by 
- GPT-4ãƒ¬ãƒ™ãƒ«ã®Nemotron-4-340Bç„¡èŒ¶è‹¦èŒ¶è„†å¼±
	- https://x.com/maksym_andr/status/1802011165670735946
	- leads to 100% attack success rate on 50 harmful requests from AdvBench using GPT-4 as a judge. There is no need to do any random search or random restarts, the model just complies directly.
- AIé©å‘½ã€ã™ã§ã«å¤±é€Ÿã—ã¦ã„ã‚‹
	- https://newspicks.com/news/10094191/body/
	- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ä¸è¶³ã§ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã®é ­æ‰“ã¡ãŒè¦‹ãˆã¦ãŠã‚Šã€é‹ç”¨ãŒé«˜ã‚³ã‚¹ãƒˆã«ã€‚ç¾æ™‚ç‚¹ã§ã¯AIã®åˆ©ç”¨ã‚·ãƒ¼ãƒ³ã‚‚é™å®šçš„ã®ãŸã‚ã€åç›Šæˆé•·ã‚‚ä¼¸ã³æ‚©ã‚€ã¨
- nitkyã•ã‚“ãŒã€æ–°ãŸãªãƒãƒ¼ã‚¸7Bãƒ¢ãƒ‡ãƒ« Oumuamua-7b-instruct-v2 ã‚’å‡ºã—ã¦ãã‚Œã¾ã—ãŸã€‚
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
	- ï¼—Bã‚µã‚¤ã‚ºãªãŒã‚‰ã€âŒ˜R+ä»¥ä¸Šã€GPT3.5æœªæº€ã¿ãŸã„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚‰ã—ã„ã§ã™ã€‚
- Oumuamua-7bã®ElyzaTasks100ã‚¹ã‚³ã‚¢ã¯3.85ã§ã—ãŸã€‚ç›¸å½“å¼·ã„ã§ã™ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1797191209976537102
- ã€ä½•å›èª¬æ˜ã—ã¦ã‚‚ä¼ã‚ã‚‰ãªã„ã¯ãªãœèµ·ã“ã‚‹ã®ã‹ï¼Ÿã€ï¼ˆä»Šäº•ã‚€ã¤ã¿ï¼‰
	- https://x.com/JunkudoT/status/1791361304655241449
	- äººé–“ã¯èãé€ƒã—ã€éƒ½åˆã‚ˆãè§£é‡ˆã—ã€å¿˜ã‚Œã‚‹ã€‚ãã‚“ãªäººé–“åŒå£«ãŒãã‚Œã§ã‚‚ä¼ãˆåˆã†ã“ã¨ã¯å¯èƒ½ãªã®ã‹ï¼Ÿç†è§£ã—åˆã†ã“ã¨ãŒé›£ã—ã„ä¸–ã®ä¸­ã§ã€Œä¼ãˆã‚ã‹ã‚Šåˆã†ã€ã“ã¨ã«æ¢æ±‚ã™ã‚‹ã‚ãªãŸã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ä¸€å†Šã§ã™ã€‚


## 6/10

ä»Šé€±ã¯NotebookLMãŒã™ã”ã‹ã£ãŸã€‚LLMã®èºé€²ã«ã‚„ã‚‰ã‚Œã±ãªã—ã§ã‚ã‚‹ãŒã€LLMæ´»ç”¨ã§å¸Œæœ›ã‚’æŒã¦ã‚‹äº‹ä¾‹ã‚‚ã€‚ç†è«–é¢ã§ã¯ã€Transformerã®æ¬¡ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ä¸‹é¦¬è©•ã®é«˜ã„Mambaã§ã‚ã‚‹ãŒã€CMUã«ã‚ˆã‚‹Mamba-2ã®ææ¡ˆã§ã¯æ–°ã—ãå°å…¥ã•ã‚ŒãŸçŠ¶æ…‹ç©ºé–“åŒå¯¾æ€§(SSD)ã«ã‚ˆã£ã¦ã€Transformerã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ãªãŒã‚‰ã€Transformerã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ãã†ã ã€‚å²¡é‡åŸã•ã‚“ã«ã‚ˆã‚‹ã¨transformerã¨SSMãŒçµ±ä¸€ã•ã‚ŒãŸã¨ã®ã“ã¨ã€‚LSTMã‚’æ”¹è‰¯ã—ã¦transformerä¸¦ã¿ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãŒã‚ã‚‹ã¨ã„ã†xLSTMã¨ã„ã†ã®ã‚‚æ°—ã«ãªã‚‹ã€‚OpenAIãŒGPT-4ã®å†…éƒ¨è¡¨ç¾åˆ†æã«æ´»ç”¨ã—ãŸ**k-Sparse Autoencoders**ã£ã¦ã€AnthropicãŒã¤ã„æœ€è¿‘ç™ºè¡¨ã—ãŸã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®åˆ©ç”¨ã¨åŒåˆ—ã‹ã€ãªãŠã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€è‡ªèº«ã¯ICLR 2014 ã§ç™ºè¡¨ã•ã‚ŒãŸã¨è‘—è€…ãŒãƒ„ã‚¤ãƒ¼ãƒˆã€‚ã•ã¦ã€æ–°ã—ã„LLMã®ç™ºè¡¨ã§ã¯ã€ã‚¢ãƒªãƒãƒãŒQwen2ã‚’ç™ºè¡¨ã€å…¨ä½“çš„ã«Llama3è¶…ãˆã¨ã‹ã€æœ€ä¸Šä½ãƒ¢ãƒ‡ãƒ«ä»¥å¤–ã¯Apacheãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã¨ã‹ã€ollamaãŒã•ã£ããå¯¾å¿œã¨ã‹ã€7B-instructã®ãŠè©¦ã—ã‚’huggingface spaceã«AIXã‚µãƒˆã‚·ã•ã‚“ãŒæä¾›ã¨ã‹ã€ã«ãã‚„ã‹ã ã€ã“ã‚Œã‹ã‚‰ã®è©•ä¾¡ãŒæ°—ã«ãªã‚‹ã€‚GLM4-9Bã£ã¦ æ™ºè°±AIã®ãƒ¢ãƒ‡ãƒ«ã‚‚ç›¸å½“æ€§èƒ½ãŒé«˜ã„ã‚‰ã—ã„ã€åŒæ–¹ã¨ã‚‚ä¸­è¯LLMã‚‰ã—ãæ—¥æœ¬èªå ªèƒ½ãªã®ã ãŒãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«ã¯æ³¨æ„ãŒå¿…è¦ã¨ã®ã“ã¨ã€‚Googleã®Gemini 1.5 Proã ã£ã¦æ—¥æœ¬èªæ€§èƒ½ã™ã”ã„ã€å¸ƒç•™å·ã•ã‚“ã®Google Gemini 1.5ã®æ–°åˆŠã‚‚ã§ã‚‹ã®ã§ã€æ˜¯éãŠè©¦ã—ã‚’ã€‚ Google AI Studioã§ç„¡æ–™ãŠè©¦ã—ã§ãã®ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ã¯æ˜ã‚‰ã‹ãªã‚ã‘ã§ã‚ã‚‹ãŒã€gpt-4oã«è©±é¡Œã‚’æŒã£ã¦ã„ã‹ã‚Œæ°—å‘³ã€‚ãã“ã§ã€ä¸€æ°—ã«æŒ½å›ã¨ã„ã†ã‚ã‘ã§ã¯ãªã„ãŒã€Gemini 1.5 Proã‚’ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚‚ã¤NotebookLMã®è©¦è¡ŒãŒé–‹å§‹ã€‚PDFã€ãƒ†ã‚­ã‚¹ãƒˆã€URLã‚’ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ç™»éŒ²ã™ã‚‹ã¨ã€ãã®ã‚½ãƒ¼ã‚¹ã«å¯¾ã—ã¦ã€æ¦‚è¦ã‚„FAQã€ã•ã‚‰ã«ã¯ãƒãƒ£ãƒƒãƒˆã«ã‚ˆã‚‹å¿œç­”ã¨æ ¹æ‹ ç®‡æ‰€ã®è¡¨ç¤ºãŒã§ãã‚‹ã¨ã„ã†ä»£ç‰©ã€‚ã„ã‚„ã€ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§RAGä½œã‚‹ã¿ãŸã„ãªè©±ã¯å…¨éƒ¨å¹ã£é£›ã¶ã‚ˆã†ãªè©±ã§ã¯ã‚ã‚‹ãŒã€ç”Ÿæˆã®éƒ¨åˆ†ã®æŠ½å‡ºã®éƒ¨åˆ†ã®ãƒãƒ©ãƒ³ã‚¹ãŒæ­£å‘³ã©ã‚Œãã‚‰ã„ã‹ã“ã‚Œã‹ã‚‰ã®è©•ä¾¡ãŒæ°—ã«ãªã‚‹ã€‚AIã«æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãã¦ã‚‚ã‚‰ã†ã¤ã„ã§ã«ãã‚Œã‚’Webè¨˜äº‹ã®ä½“è£ã§ã¾ã¨ã‚ã¦å…¬é–‹ã™ã‚‹Perplexity Pagesãªã‚“ã‹ã‚‚ã€ãã†ã ã‘ã©ã€å„ç¤¾ã¨ã‚‚ãƒãƒ£ãƒƒãƒˆã®æ¬¡ã®ã‚­ãƒ©ãƒ¼ã‚¢ãƒ—ãƒªã‚’æ¢ã—ã¦è©¦è¡Œã—ã¦ã„ã‚‹æ„Ÿã˜ã‹ãªãƒ¼ã€‚æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã¯ã“ã‚Œã‚‰ã®è©¦è¡Œã®çµæœã€ä½¿ã„ã“ãªã›ã‚‹äººã¯å°‘ãªã‹ã£ãŸã¨ã„ã†çµè«–ã«ãªã‚‹ã“ã¨ã€‚kobayashiã•ã‚“ã®ã€ã€ŒLLM ã‚’ä½¿ã„ã“ãªã›ã‚‹äºº ï¼ è¨€èªèƒ½åŠ›ãŒé«˜ã„äººã€ã¨ã„ã†ã®ã¯ã€ã“ã®ã‚ˆã†ãªèƒ½åŠ›ã‚’å¾—ã‚‹ã«ã¯ã€ãƒªã‚¹ã‚­ãƒ³ã‚°ã§ã¯è¿½ã„ã¤ã‘ãªã„ã¨ã„ã†èº«ã‚‚ãµãŸã‚‚ãªã„è©±ã€‚AIãƒªãƒ†ãƒ©ã‚·ãƒ¼ã¯ã„ã‹ã«è¨€èªèƒ½åŠ›ã‚’ä¸Šã’ã‚‹ã‹ã«ã‹ã‹ã£ã¦ã„ã‚‹ã€‚è¨€èªèƒ½åŠ›ãŒé«˜ã„äººã®ä¾‹ã¨ã¯ã€ä¾‹ãˆã°ã€ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆãŒæœ¬ç‰©ã‹å½ç‰©ã‹ã‚’è¦‹æŠœãï¼‘ï¼ã®è³ªå•ã¿ãŸã„ãªã‚„ã¤ãŒã§ãã‚‹äººã‹ã€‚ä¸€æ–¹NTTã®streamitã‚’ä½¿ã£ãŸAIã®æ°‘ä¸»åŒ–ã¨ã‹ã€æ¦‚å¿µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’ã¤ã‹ã£ãŸãƒ‡ãƒ¼ã‚¿ã®æ•´ç†ãªã©ã€ç¾å ´ã«ã¯ã¾ã åŠ›ãŒã‚ã£ã¦ã€ã“ã‚Œã‚’ç”ŸæˆAIã‚’ä½¿ã£ã¦ä¼šç¤¾ã®DXã«ã¤ãªã’ã‚‹ã£ã¦ã®ã‚‚ã€å¸Œæœ›ã‚’æŒã¦ã‚‹LLMæ´»ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãªæ„Ÿã˜ãŒã—ã¦ããŸã€‚ã“ã‚Œã‚‰ã«æ¯”ã¹ã¦AIã§ç”Ÿç”£æ€§ã‚’ä¸Šã’ã¦äººæ‰‹ä¸è¶³ã‚’è§£æ¶ˆã—ã€ä½™ã£ãŸäººå‘ã‘ã«è»¢è·ä¿ƒé€²ã¨ã„ã†ã€æ”¿åºœã®æˆé•·æˆ¦ç•¥ã®è–„ã£ãºã‚‰ã„ã“ã¨ã‚ˆã€‚æ”¾é€å¤§å­¦ã®æ•™ç§‘æ›¸ã€è‡ªç„¶è¨€èªå‡¦ç†ã€ã®æ”¹è¨‚ç‰ˆã¨ä¸‰è¨‚ç‰ˆã®æ¯”è¼ƒã€ã„ã‹ã«è¨€èªå‡¦ç†ã®åŸºæœ¬æ§‹æˆãŒtransformerã®ç™»å ´ã§å¤§ããæ›¸ãæ›ã‚ã£ãŸã‹ãŒç›®æ¬¡ã ã‘ã§ã‚‚ã‚ˆãã‚ã‹ã‚‹ã€‚ã—ã‹ã—ã€ã€ŒçŸ¥è­˜ã‚°ãƒ©ãƒ•ã£ã¦æœ€è¿‘èã‹ãªãªã„ãªã‚ã€ã¨ã¯ã€å°ç”ºå…ˆç”Ÿå†·ãŸã™ãã€‚GraphRAGã¨ã‹Property Graph Indexã¨ã‹ã€LLMå¿œç”¨ç•Œéšˆã§ã¯çŸ¥è­˜ã‚°ãƒ©ãƒ•ã¯ã¾ã ãƒ›ãƒƒãƒˆã ã—ã€Document Intelligenceã®ã‚ˆã†ã«ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’æŠ‘ãˆã‚‹æ‰‹æ®µã¨ã—ã¦ã®çŸ¥è­˜ã®é‡è¦ã•ã‚‚ã‚ã‹ã£ã¦ããŸã¨ã“ã‚ãªã‚“ã§ã™ã‘ã©ã€‚æœ€å¾Œã«ã€Hassabis ãŒã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼ã§è¨€åŠã—ãŸProject Astra(Goole I/O 2024ã§ãƒ‡ãƒ¢ã—ãŸã‚„ã¤ï¼‰ã€ã‚ã¨ï¼‘ã‹ã‚‰ï¼’å¹´ã§ãƒªãƒªãƒ¼ã‚¹ã€æ™®é€šã®äººãŒä½¿ãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã—ã¦ã‚²ãƒ¼ãƒ ãƒã‚§ãƒ³ã‚¸ãƒ£ãƒ¼ã«ãªã‚‹ã¨ã®ã“ã¨ã€‚

- Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality
	- https://arxiv.org/abs/2405.21060
	- ç¾åœ¨ç”ŸæˆAIã§ä¸»æµã®Transformerã®ã€Œæ¬¡ã€ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã—ã¦æœŸå¾…ã•ã‚Œã‚‹Mamba-2ã‚’ææ¡ˆ
	- **çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰** ã¯ã€æ§‹é€ åŒ–è¡Œåˆ— ã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€å¾“æ¥ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã¨å¯†æ¥ã«é–¢é€£ã—ã¦ã„ã‚‹ã“ã¨ãŒæ˜ã‚‰ã‹ã«ãªã‚Šã€
	- çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ï¼ˆSSMï¼‰ ã¨ ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ ã®å¤‰ç¨®ã¨ã®é–“ã®ç†è«–çš„ãªé–¢é€£æ€§ã‚’ç¤ºã™ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**çŠ¶æ…‹ç©ºé–“åŒå¯¾æ€§ï¼ˆSSDï¼‰**ã‚’ææ¡ˆ
	- ãã®çµæœã€ç·šå½¢æ™‚é–“è¨ˆç®— ã¨ äºŒæ¬¡æ™‚é–“è¨ˆç®— ã®ä¸¡æ–¹ã®å½¢å¼ã‚’æŒã¤ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚
	- ã“ã® çŠ¶æ…‹ç©ºé–“åŒå¯¾æ€§ï¼ˆSSDï¼‰ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€Mamba-2 ã¨å‘¼ã°ã‚Œã‚‹æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¨­è¨ˆã‚’å°ãã€è¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã«ãŠã„ã¦Transformerã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ãªãŒã‚‰ã€Transformerã‚ˆã‚Šã‚‚åŠ¹ç‡çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¾ã™ã€‚
	- Mamba2ã¯æ–°ã—ãå°å‡ºã•ã‚ŒãŸSSDã‚’ä½¿ã„ã€ç³»åˆ—é•·ã«å¯¾ã—ç·šå½¢ã®è¨ˆç®—é‡ã€ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã§åŠ¹ç‡çš„ã«å­¦ç¿’ã€æ¨è«–ã§ãã€Transformerã‚„Mambaã‚ˆã‚ŠPPLã‚„ä¸‹æµã‚¿ã‚¹ã‚¯ã§æ€§èƒ½ãŒé«˜ã„ã€‚SSMã¨TransformerãŒçµ±ä¸€çš„ãªæ çµ„ã¿ã§æ‰±ãˆã‚‹ã“ã¨ã‚‚ç¤ºã™ by å²¡é‡åŸã•ã‚“
- GPT-4 is 1.8T MoE, thanks Nvidia Presentation
	- https://x.com/literallydenis/status/1797531945926287497
- LLMã‚’æ´»ç”¨ã—ãŸå¤§è¦æ¨¡å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã¸ã®å–ã‚Šçµ„ã¿
	- https://engineering.mercari.com/blog/entry/20240411-large-scale-item-categoraization-using-llm/
	- GPTã‚’å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã«æ´»ç”¨ã—ãŸäº‹ä¾‹ã¨å·¥å¤«ã—ãŸãƒã‚¤ãƒ³ãƒˆãŒã¾ã¨ã¾ã£ã¦ã„ã‚‹ã‚ˆ
		- Embeddingãƒ¢ãƒ‡ãƒ«ã¯OSSã§ã‚‚å•é¡Œãªã—
		- GPT4ã¯ã‚³ã‚¹ãƒˆçš„ã«ä½¿ãˆãªã‹ã£ãŸ
		- max_tokensã¨Chain of Thought ã§ã®åŠ¹ç‡åŒ–
		- Numbaã¸ã®æ›¸ãæ›ãˆã‚‚GPTã‚’ä½¿ã£ã¦åŠ¹ç‡åŒ–
-  Hugging Faceã®ZeroGPUã§AIã®ãƒ‡ãƒ¢ã‚’ä½œã‚‹æ–¹æ³•: åˆç´šç·¨
	- https://qiita.com/alfredplpl/items/abb30283b578dc984d16
	- ZeroGPU ã¨ã¯ã€ãƒ‡ãƒ¢ã®åˆ©ç”¨è€…ãŒä½¿ã†ç¬é–“ã ã‘é«˜æ€§èƒ½ãªGPUãŒå€Ÿã‚Šã‚‰ã‚Œã‚‹ã¨ã„ã†ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚ç¾åœ¨ã¯A100 40GBãŒä¸€ç¬å€Ÿã‚Šã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã‚’å®Ÿç¾ã§ãã¦ã„ã‚‹ã®ã¯ä¸–ç•Œã§Hugging Faceã ã‘ã§ã—ã‚‡ã†ã€‚ãŠå€¤æ®µã¯æœˆé¡9ãƒ‰ãƒ«ï¼ˆç´„1500å††ï¼‰ã§ã™
	- Hugging Faceã®ZeroGPUã¯AIã®ãƒ‡ãƒ¢ã‚’ä½œã‚‹ã®ã«æœ€é©ã ã¨ã‚ã‹ã‚Šã¾ã—ãŸã€‚ã„ã‹ãŒã§ã—ãŸã§ã—ã‚‡ã†ã‹ã€‚ãœã²ã¿ãªã•ã‚“ã‚‚ãƒ‡ãƒ¢ã‚’ä½œã£ã¦ã¿ã¦ãã ã•ã„ã€‚ãªãŠã€ç§ã¯è²¬ä»»ã‚’æŒã¡ã¾ã›ã‚“ã€‚
- lmsys.org ã§Googleã®Gemini 1.5 Proï¼ˆ5/14ãƒ¢ãƒ‡ãƒ«ï¼‰ãŒæ—¥æœ¬èªã§ä¸–ç•Œä¸€ã«ãªã‚Šã¾ã—ãŸã€‚ï¼’ãƒ¶æœˆå‰ã®ãƒ¢ãƒ‡ãƒ« (4/9ãƒ¢ãƒ‡ãƒ«ï¼‰ã‚ˆã‚Šã‹ãªã‚Šæ”¹å–„ã•ã‚Œã¾ã—ãŸ
	- https://x.com/shanegJP/status/1797798176344453414
- Perplexity Pagesã€AIã«æƒ…å ±ã‚’ã¾ã¨ã‚ã¦ãã¦ã‚‚ã‚‰ã†ã¤ã„ã§ã«ãã‚Œã‚’Webè¨˜äº‹ã®ä½“è£ã§ã¾ã¨ã‚ã¦å…¬é–‹ã§ãã¡ã‚ƒã†ã®ã‹ã‚ã€‚
	- https://x.com/umiyuki_ai/status/1797871157850620270
- å¯Œå£«é€šã¯ã€ç‰¹åŒ–å‹ã®ç”ŸæˆAIæ··åˆæŠ€è¡“ã¨ãƒŠãƒ¬ãƒƒã‚¸ã‚°ãƒ©ãƒ•æ‹¡å¼µRAGã¨ã„ã†ãƒãƒ‹ã‚¢ãƒƒã‚¯ãªæ–¹å‘ã«é€²åŒ–ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸã€‚
	- https://x.com/AsamaKotaro/status/1797844740328804563
-  the benefits of Google Gemini's gigantic 1 million token context window in action!
	- https://x.com/llama_index/status/1798049438814081138
	- In this quick notebook, we show Gemini built into a LlamaIndex agent attempting to answer a multi-part question from a set of complicated, heterogeneous documents.
- å¯Œå£«é€šã®ç ”ç©¶æˆ¦ç•¥ç™ºè¡¨ä¼šã€æœ€é©åŒ–å•é¡Œã¨ç”ŸæˆAIã«ã‚ˆã‚‹åˆ¶ç´„æ¡ä»¶ã®ç”ŸæˆãŒç›¸æ€§ãŒè‰¯ã„ã¨ã„ã†ç™ºæƒ³
	- https://x.com/tokoroten/status/1797851927457546682
	- è­°äº‹éŒ²ã‚„ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‹ã‚‰åˆ¶ç´„æ¡ä»¶ã‚’èµ·ã“ã—ãŸã‚Šã€AIã¨ã®å¯¾è©±ã‚’é€šã˜ã¦åˆ¶ç´„æ¡ä»¶ã‚’èµ·ã“ã—ãŸã‚Š
- æ¦‚å¿µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å§‹ã‚ã‚‹çœŸã«ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ãªè£½é€ æ¥­DX
	- https://www.qunie.com/quriosity/231218_00/
	- æ¦‚å¿µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¯å€‹ã€…ã®æ¥­å‹™æ”¹é©ã‚„ãƒ¢ãƒ€ãƒŠã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã«ç€æ‰‹ã™ã‚‹å‰ã«ä½œæˆã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹ã€‚ç‰¹å®šã®æ¥­å‹™é ˜åŸŸã ã‘ã§ãªãã€è£½é€ æ¥­ã®ãƒãƒªãƒ¥ãƒ¼ãƒã‚§ãƒ¼ãƒ³å…¨ä½“ã‚’ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¡¨ç¾ã™ã‚‹ã€‚
	- è«–ç†ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ã‚ˆã†ãªå³å¯†ã•ã¯ä¸è¦ã§ã€é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸãƒ‡ãƒ¼ã‚¿ç¾¤ã¨ã€ãã®ã‚­ãƒ¼é …ç›®ï¼ˆå…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿é …ç›®ã¯ä¸è¦ï¼‰ã€ãƒ‡ãƒ¼ã‚¿ç¾¤ã®ã¤ãªãŒã‚Šã‚’ç¤ºã™ã€‚
	- ãƒãƒªãƒ¥ãƒ¼ãƒã‚§ãƒ¼ãƒ³å…¨ä½“ã‚’ä¿¯ç°ã—ãŸæ¦‚å¿µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã‹ã‚‰ã“ãã€ä¼æ¥­å…¨ä½“ã®æ”¹é©ã«ä¸€æœ¬ã®èŠ¯ãŒé€šã‚‹ã“ã¨ã«ãªã‚‹ã®ã ã€‚ã‚ã‚‹ãŠå®¢ã•ã¾ã¯ã€æ¦‚å¿µãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®ã“ã¨ã‚’â€œè‡ªç¤¾ã®æ†²æ³•â€ã¨è¡¨ç¾ã•ã‚Œã¦ã„ãŸãŒã€ã¾ã•ã«ãã®é€šã‚Šã§ã‚ã‚‹ã€‚
- ELYZAãŒã€å›½ç«‹ç ”ç©¶é–‹ç™ºæ³•äºº ç”£æ¥­æŠ€è¡“ç·åˆç ”ç©¶æ‰€ãŒå‹Ÿé›†ã—ãŸå¤§è¦æ¨¡ç”ŸæˆAIç ”ç©¶é–‹ç™ºæ”¯æ´ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«æ¡æŠã•ã‚Œã¾ã—ãŸã€‚
	- https://x.com/ELYZA_inc/status/1797780304717078689
-  è«–æ–‡è§£èª¬ã‚’GPT-4oã‚’ä½¿ã£ã¦è‡ªå‹•çš„ã«ç”Ÿæˆã—ã¦ã¿ã‚‹ by é€†ç€¬å·ã•ã‚“
	- https://qiita.com/sakasegawa/items/8e17ede26dd96e7e3280
	- PDFã‚’ç”»åƒã¨ã—ã¦å–ã‚Šæ‰±ã†ã¨å‡¦ç†ã¯é…ã„ãŒæ ¼æ®µã«å®‰ã„ï¼ï¼ 
	- è«–æ–‡ã®PDFã‚’ç”»åƒã¨ã—ã¦æ‰±ã„ã€GPT-4oã§è½åˆãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ã£ã¦è§£èª¬ã‚’ç”Ÿæˆã•ã›ã‚‹
	- è«–æ–‡ã®PDFã‹ã‚‰æ•°å¼ã‚„å›³è¡¨ã‚’æŠ½å‡ºã—ã€å€‹ã€…ã«è§£èª¬ã‚’ç”Ÿæˆ
- ã‚‚ã¯ã‚„AIã®æ€§èƒ½ã‚’äººé–“ãŒæ¸¬å®šã§ããªã„ by  karaage. [ã‹ã‚‰ã‚ã’]ã•ã‚“
	- https://karaage.hatenadiary.jp/entry/2024/06/04/073000
	- ãã‚‚ãã‚‚AIã®æ€§èƒ½ã‚’äººé–“ãŒæ¸¬å®šã™ã‚‹ã®ãŒé›£ã—ã„é ˜åŸŸã«æ¥ã¦ã„ã‚‹ãªã¨å®Ÿæ„Ÿã—ã¾ã—ãŸã€‚
- Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming
	- https://arxiv.org/abs/2406.00592
- LLM Basics - Why can't we use regular LoRA for pre-training LLMs
	- https://x.com/rohanpaul_ai/status/1797759219891937324
	- LoRA (Low-Rank Adaptation), targets a subset of a neural network's parameters, specifically focusing on the weight matrices of transformer models. It represents these large matrices as the product of smaller
- Why AI wont take your job just yet
	- https://medium.com/@starloba/why-ai-wont-take-your-job-just-yet-13e95cd05da8
	- æ±ç”¨çš„ãªã‚¿ã‚¹ã‚¯ã‚’AIã«è§£ã‹ã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã€äººé–“ã¯ã‚ˆã‚Šã‚¯ãƒªã‚¨ã‚¤ãƒ†ã‚£ãƒ–ãªå•é¡Œã«æ³¨åŠ›ã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã€‚ã‚ˆã‚Šæ­£ç¢ºã«è¨€ã†ãªã‚‰ã€å¼·åˆ¶çš„ã«æ³¨åŠ›ã—ãªã„ã¨ã„ã‘ãªã„çŠ¶æ³ã«è¿½ã„è¾¼ã¾ã‚Œã‚‹ã€‚
- Microsoft has built a weather forecasting model named 'Aurora
	- https://x.com/MSFTResearch/status/1797662278394827029
-  Heuristics on the high seas: Mathematical optimization for cargo ships
	- https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/
	- Today we present new solutions to the Liner Shipping Network Design and Scheduling Problem, released as part of our new Shipping Network Design API, with the goal of maximizing the efficiency of container shipping networks at world-wide scale
- Unslothã¯ã“ã®è«–æ–‡ã«å¯¾æŠ—ã—ã¦LoRAã§ã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã‚’å¾¹åº•çš„ã«æœ€é©åŒ–ã—ãŸçµæœã€ä»Šã¾ã§ã®LoRAå­¦ç¿’ã®ï¼’å€ã®åŠ¹ç‡ã§å­¦ç¿’ã§ãã¦ã€VRAMã‚‚åŠåˆ†ã§æ¸ˆã‚€
	- https://x.com/umiyuki_ai/status/1798221784334160262
	- 24GBã®VRAMã§Llama3-8Bã‚„Mistral-7BãŒLoRAç¶™ç¶šäº‹å‰å­¦ç¿’ã§ãã‚‹
- GLM4-9Bã ã£ã¦ã€‚26è¨€èªå¯¾å¿œã€‚GPT-4ã«åŒ¹æ•µã™ã‚‹é–¢æ•°å‘¼ã³å‡ºã—èƒ½åŠ›
	- https://x.com/umiyuki_ai/status/1798292824544420150
-  ä¸­å›½è£½LLMã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹å•é¡Œã¨å›½å®‰æ³•ã«ã¤ã„ã¦
	- https://note.com/willplion/n/n2710f60b381a
- ç¶™ç¶šäº‹å‰å­¦ç¿’(CPT: Continued Pre-Training)ã‚’QLoRAã§ã‚„ã‚ã†ã¨ã™ã‚‹è©¦ã¿
	- https://x.com/webbigdata/status/1798313713654776062
	- Colabç„¡æ–™ç‰ˆã§ã‚‚mistral-7b-v0.3ãªã‚‰ååˆ†å‹•ãã¾ã—ãŸ
	- llama3 8bã‚„gemma7bã§ã¯æœ‰æ–™ç‰ˆã®L4(24GB)ã§ã‚‚ãƒ¡ãƒ¢ãƒªä¸è¶³ã«ãªã£ã¦ã—ã¾ã„ã¾ã—ãŸãŒllama2ã¨ã„ã†æ‰‹ã‚‚ã‚ã‚Šã¾ã™
-  ä½è³€ã®ç¹”ç”°ç—…é™¢ãŒã‚ªãƒ³ãƒ—ãƒ¬GPUã‚µãƒ¼ãƒãƒ¼ã§LLMç¨¼åƒã€é›»å­ã‚«ãƒ«ãƒ†æƒ…å ±ã‚’ç”ŸæˆAIãŒè¦ç´„
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09236/
	- ã“ã‚Œã¾ã§åˆ©ç”¨ã—ã¦ããŸé›»å­ã‚«ãƒ«ãƒ†ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ªãƒ—ãƒ†ã‚£ãƒ ãŒæä¾›ã™ã‚‹ç”ŸæˆAIã€ŒOPTiM AIã€ã‚’çµ„ã¿åˆã‚ã›ã€çœ‹è­·å¸«ã®æ¥­å‹™åŠ¹ç‡ã‚’é«˜ã‚ã‚‹å®Ÿè¨¼ã«ä¹—ã‚Šå‡ºã—
	- ç±³NVIDIAã®RTX A2000ã‚’æ­è¼‰ã—ãŸGPUï¼ˆç”»åƒå‡¦ç†åŠå°ä½“ï¼‰ã‚µãƒ¼ãƒãƒ¼1å°ã‚’æ–°ãŸã«é™¢å†…ã«ç”¨æ„ã—ãŸã€‚LLMã®å­¦ç¿’ã‚„æ¨è«–ã«ç”¨ã„ã‚‹
- Introducing AI Agents in LangGraph!ã€€ by Deeplearning.ai
	- https://x.com/DeepLearningAI/status/1798376731188834780
	- In this course taught by hwchase17, LangChainAI CEO, and weiss_rotem, tavilyai CEO, youâ€™ll learn to use LangGraph to create controllable agents, and agentic search for agents to enhance their output.
- ChatGPTã§ãƒ¬ãƒ»ãƒŸã‚¼ãƒ©ãƒ–ãƒ«ã®äººç‰©ç›¸é–¢3Dãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
	- https://x.com/itnavi2022/status/1798320618695438647
- GLM4-9B-Chatã‚’ElyzaTasks100ã§è©•ä¾¡ã—ãŸ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1798328337699606704
	- ã‚¹ã‚³ã‚¢ã¯ãªã‚“ã¨3.92ï¼ï¼ã‚„ã¹ãˆï¼ï¼ï¼ï¼Gleipnir-7Bã®3.91ã‚ˆã‚Šå‹ã£ã¦ã‚‹ï¼ãƒ¡ãƒãƒ£ã‚¯ãƒãƒ£ã‹ã—ã“ã„ï¼ã“ã®ãƒ¢ãƒ‡ãƒ«ã€ã‚¹ãƒšãƒƒã‚¯ã ã‘ã®ã‚³ã‚±ã‚ªãƒ‰ã‚·ã˜ã‚ƒãªã„ï¼
- ReFT: Representation Finetuning for Language Models
	- https://x.com/rohanpaul_ai/status/1798026828017197256
	- 10x-50x more parameter-efficient than prior state-of-the-art PEFT methods.
- Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks
	- https://arxiv.org/abs/2406.02550
-  xLSTM: Extended Long Short-Term Memo	
	- https://arxiv.org/abs/2405.04517
	- LSTMï¼ˆLong Short-Term Memoryï¼‰ã‚’æ”¹è‰¯ã—ã€æ•°åå„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦Transformerä¸¦ã¿ã‹ãã‚Œä»¥ä¸Šã®æ‹¡å¼µæ€§ï¼ˆã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ¼ï¼‰ã‚’æŒãŸã›ãŸã¨ã„ã†ã€‚
-  In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter Optimization
	- https://arxiv.org/abs/2404.16795
	- ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã¯æ›´ã«é©æ–°çš„ã«!
	- ã“ã®è«–æ–‡ã§ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®PFNã‚’æ´»ç”¨ã—ãŸ"In-Context Freeze-Thaw BO"ã‚’ææ¡ˆ!
	- å¾“æ¥æ‰‹æ³•ã«æ¯”ã¹10ã€œ100å€é«˜é€Ÿã‹ã¤ç²¾åº¦è‰¯ãå­¦ç¿’æ›²ç·šã‚’äºˆæ¸¬ã§ãã‚‹ã¨ã„ã†é©šãã®çµæœ!
- ã€Google Gemini 1.5ï¼LlamaIndexï¼LangChain äººå·¥çŸ¥èƒ½ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å®Ÿè·µå…¥é–€ã€ã®å‡ºç‰ˆè¨˜å¿µã‚¤ãƒ™ãƒ³ãƒˆ
	- https://x.com/npaka123/status/1798557659693781217
	- 25å¹´é–“ã§æŠ€è¡“æ›¸49å†Šã€å¹´é–“300ä»¥ä¸Šã®æŠ€è¡“è¨˜äº‹ã‚’æ›¸ã„ã¦ã„ã‚‹è‘—è€…ãŒã€Google Geminiã®æœ€æ–°æŠ€è¡“æƒ…å ±ã«åŠ ãˆã¦ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã¨ãƒ­ãƒ¼ã‚«ãƒ«LLMã®æœªæ¥äºˆæƒ³ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
	- https://studyco.connpass.com/event/319990/
- Qwen2ãŒæ¥ãŸï¼0.5Bã€1.5Bã€7Bã€57B-A14Bã€72Bã®ï¼•ç¨®é¡
	- https://x.com/umiyuki_ai/status/1798762190729777185
	- 1.5ã‹ã‚‰æ€§èƒ½ãƒã‚­ãƒã‚­ã«ä¸Šã’ã¦ããŸï¼å…¨ä½“çš„ã«Llama3è¶…ãˆï¼
	- 72Bã¯ä»Šã¾ã§ã¨åŒã˜ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã ã‘ã©ã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯Apacheãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«å¤‰æ›´
- GoogleNotebookLM
	- https://notebooklm.google/
	- Gemini1.5Proã‚’ä½¿ã£ãŸRAGå°‚ç”¨ã®ãƒãƒ£ãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ã€‚
	- ç´„ï¼•ä¸‡å­—ã®æœ¬ã‚’å…¥åŠ›ã—ã¦è³ªå•ã—ã¦ã¿ãŸã®ã ã‘ã©ã€GPT-4oã§ã‚‚Claude3ã§ã‚‚å¾®å¦™ã ã£ãŸã®ã«ã€çµæ§‹ã„ã„æ„Ÿã˜ã®å›ç­”ã§ãƒ“ãƒƒã‚¯ãƒªã—ãŸã®ã ã€‚
- æ™‚ç³»åˆ—åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ ªä¾¡ãƒ‡ãƒ¼ã‚¿(å¤šå¤‰é‡)ã®é¡ä¼¼åº¦ç®—å‡ºã¨æ¤œç´¢
	- https://note.com/hatti8/n/n6c1a91a3b6ba?sub_rt=share_pb
	- æ™‚ç³»åˆ—åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€ ãƒ»å¤šå¤‰é‡ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿Embeddingä½œæˆ ãƒ»æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åŒå£«ã®é¡ä¼¼åº¦ã‚’ç®—å‡º ã¨ã„ã†ã®ã‚’è©¦ã—ã¦ã¿ã¾ã—ãŸã€‚
- Hello Qwen 2!ã€€by ollama
	- https://x.com/ollama/status/1798807013327241302
	- ollamaãŒ qwen2ã«å¯¾å¿œ
-  Extracting Concepts from GPT-4
	- https://openai.com/index/extracting-concepts-from-gpt-4/
	- OpenAIã¯å…ˆã»ã©LLMã®å‹•ãã‚’ç†è§£ã™ã‚‹ãŸã‚ã®ç ”ç©¶ã‚’å…±æœ‰ã€‚GPT-4ã®å†…éƒ¨è¡¨ç¾ã‚’1600ä¸‡ã®ç‰¹å¾´ã«åˆ†è§£ã™ã‚‹ã“ã¨ã«æˆåŠŸã—ãŸã“ã¨ã‚’ç™ºè¡¨ã€‚
- Googleã®AIã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚‹ã€ŒNotebookã€
	- https://x.com/kensuu/status/1798876734298935771
	- æœ¬ã®PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ - ã™ã‚‹ã¨ä¸­èº«ãŒå…¨éƒ¨å·¦å´ã«å‡ºã¦ãã‚‹
	- AIã«è‰²ã€…è³ªå•ãŒã§ãã‚‹ - ç­”ãˆã«å‡ºã¦ããŸéƒ¨åˆ†ã‚’å·¦å´ã§èª­ã‚ã‚‹ 
	- å›ç­”ã‚’ãƒ”ãƒ³ç•™ã‚ã™ã‚‹ã¨ãƒ¡ãƒ¢ã¨ã—ã¦ä¿å­˜ã§ãã‚‹ã€‚ãƒ¡ãƒ¢ã‚’è‡ªåˆ†ã§æ›¸ãã“ã¨ã‚‚ã§ãã‚‹
- Qwen2-7Bã‚’ã•ã£ããElyzaTasks100ã«ã‹ã‘ãŸã‚‰ã‚¹ã‚³ã‚¢4.01ï¼ï¼ï¼ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1798777448282378254
- Qwen 2 ã¿ã‚“ãªè§¦ã‚‰ã‚Œã¾ã—ãŸã‹ã­ï¼ŸæŒ‡ç¤ºæ€§èƒ½ã¨çŸ¥è­˜ãˆããªã„..ã€€by ã¬ã“ã¬ã“ã•ã‚“
	- https://x.com/i/bookmarks
	- 0.5B ã®æµ·å¤–ãƒ¢ãƒ‡ãƒ«ã§æ—¥æœ¬èªè©±ã›ã‚‹ãªã‚“ã¦èã„ã¦ã„ãªã„ã‚ˆ...
- Qwen2-7B-instructã®ãƒ‡ãƒ¢ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«è¨­ç½®ã—ã¾ã—ãŸ by AIXã‚µãƒˆã‚·ã•ã‚“
	- https://huggingface.co/spaces/aixsatoshi/Qwen-7B-instruct
- Recipes for open source / local agents w/ Llama 3
	- https://x.com/LangChainAI/status/1799109018163761588
	- https://github.com/meta-llama/llama-recipes/tree/main/recipes/use_cases/agents/langchain
- From simple to advanced Agents
	- https://x.com/jerryjliu0/status/1799107241695715773
	- Before you build a complex multi-agent systems, learn the core abstractions for building a single powerful assistant over your data: routing, memory, tool use, and sequential to DAG-based planning.
- It's finally possible: real-time in-browser speech recognition with OpenAI Whisper!
	- https://x.com/xenovacom/status/1799110540700078422
- Democratizing Data Across NTT docomo with Streamlit
	- https://x.com/pei0804/status/1798501802415210935
	- streamlitã‚’ä½¿ã£ãŸèª°ã§ã‚‚ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æ´å¯Ÿã‚’å¾—ã‚‰ã‚Œã‚‹ç’°å¢ƒã‚’ä½œã£ãŸè©±ã€‚ ã‚ã¡ã‚ƒãã¡ã‚ƒè‰¯ã™ãã¦æœ€é«˜ã ã£ãŸã€‚ã“ã“ã¾ã§ã‚„ã‚Šé‚ã’ã¦ã‚‹ã“ã¨ã«ã€æœ¬å½“ã«å°Šæ•¬ã—ã‹ãªã„ã€‚ã¡ãªã¿ã«ã€ä»Šå¾Œã®å±•æœ›ã‚‚è‰¯ã™ããŸã€‚
- ä½•ãŒå‡„ã„ã®ã‹ï¼Ÿæœ€æ–°ã®æŠ€è¡“GraphRAGã«ã¤ã„ã¦è§£èª¬ã—ã¦ã¿ãŸ
	- https://www.youtube.com/watch?v=PqAgkfg0MA0
- æ”¿åºœã®æˆé•·æˆ¦ç•¥ç™ºè¡¨ã•ã‚Œã¾ã—ãŸï¼
	- https://x.com/sirap_kuro/status/1799032255828140169
	- AIã§ç”Ÿç”£æ€§å‘ä¸Š/äººæ‰‹ä¸è¶³è§£æ±ºã€
	- ãã®ã‚ã¨ã«è¥²ã£ã¦ãã‚‹ä¸€èˆ¬ãƒ›ãƒ¯ã‚¤ãƒˆã‚«ãƒ©ãƒ¼ã®éœ€è¦æ¸›/å¤±æ¥­ãªã©ã«ã¯ã€è»¢è·ã‚’ä¿ƒã™ã“ã¨ã«ã‚ˆã£ã¦å¯¾å‡¦ã€‚
	- æ™®åŠã®è¶³ã‹ã›ã«ãªã‚‹å®‰å…¨/å®‰å¿ƒæ‡¸å¿µã«ã¤ã„ã¦ã¯ã€æ”¿åºœã§â€AIåˆ¶åº¦ç ”ç©¶ä¼šâ€ã‚’é–‹ãã€è­°è«–ã€‚
	- ã¾ãŸæ”¿åºœè‡ªèº«AIã‚’èª¿é”ã™ã‚‹ã€‚
- Demis Hassabis says he is most excited about DeepMind's work on Universal Multimodal AI Agents (Project Astra).
	- https://x.com/electrik_dreams/status/1799139945560363264
	- These agents, to be launched in 1-2 years, will serve as highly intelligent assistants for all general humans tasks, and "will be a pretty big game changer", he thinks.
- Introducing GraphRAG with LangChain and Neo4j
	- https://medium.com/microsoftazure/introducing-graphrag-with-langchain-and-neo4j-90446df17c1e
	- Great introduction to using Graphs - instead of pure vector DBs - to power RAG applications
	- The relationships that graphs provide can empower better retrieval which can yield better answers
- Graph RAG makes sense if you think about it as a superset of "standard" vector RAG:
	- https://x.com/jerryjliu0/status/1797057726994092492
- ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã¯æœ¬ç‰©ã¨å½ç‰©ãŒæ··åœ¨ã€€å®ŸåŠ›ã‚’è¦‹æŠœã10ã®è³ªå•
	- https://bookplus.nikkei.com/atcl/column/041500053/052900298/
- Safety Alignment Should Be Made More Than Just a Few Tokens Deep
	- https://xiangyuqi.com/shallow-vs-deep-alignment.github.io/
	- 1. Crrent LLM safety alignment is only a few tokens deep. 
	- 2. Deepening the safety alignment can make it more robust against multiple jailbreak attacks. 
	- 3. Protecting initial token positions can make the alignment more robust against fine-tuning attacks.
- LlamaIndex Introduces the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- In addition to the existing KnowledgeGraphIndex, LlamaIndex's new Property Graph Index enables:
- i heard people are rediscovering ReNet in its (almost) 10y anniversary
	- https://x.com/kchonyc/status/1799067177276014784
- Open-Endedness is Essential for Artificial Superhuman Intelligence
	- https://arxiv.org/pdf/2406.04268
	- "In this position paper, we argue that the ingredients are now in place to achieve open-endedness in AI systems with respect to a human observer. Furthermore, we claim that such open-endedness is an essential property of any artificial superhuman intelligence (ASI)."
-  An Easy Way to Comprehend How GraphRAG Works
	- https://towardsdatascience.com/an-easy-way-to-comprehend-how-graphrag-works-6d53f8b540d0
	- In a beginner-friendly explainer, Rendy Dalimunthe introduces GraphRAG, explains how it works, and outlines its benefits compared to traditional retrieval-augmented generation systems.
- OpenAI is using "k-Sparse Autoencoders" (my ICLR 2014 paper) to extract interpretable features from GPT-4,and showing that it outperforms other methods on sparsity-reconstruction frontier:
	- https://x.com/AliMakhzani/status/1799472688026517666
	-  k-Sparse Autoencoders
		- https://arxiv.org/abs/1312.5663
- æ”¾é€å¤§å­¦ã®æ•™ç§‘æ›¸ã€è‡ªç„¶è¨€èªå‡¦ç†ã€ã®æ”¹è¨‚ç‰ˆã¨ä¸‰è¨‚ç‰ˆã®æ¯”è¼ƒ
	- https://yudukikun5120.hatenadiary.jp/entry/2024/01/20/003314
	- å…¨ä½“çš„ã«ç³»åˆ—ãƒ»æ„å‘³è«–ãƒ»æ§‹æ–‡è«–ç­‰ã®åˆ†é‡ã”ã¨ã«åˆ†é›¢ã•ã‚Œã¦ã„ãŸå¤å…¸çš„æ‰‹æ³•ãŒã€å˜ä¸€ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çš„æ‰‹æ³•ã«åœ§å€’ã•ã‚Œã¦ã„ãã•ã¾ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã‚‹ã€‚
	- ã€Œä»Šæ—¥ã§ã¯ã€è¶…å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ã§å­¦ç¿’ã•ã‚Œã‚‹æ±ç”¨è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆ8ç« ï¼‰ãŒéå¸¸ã«å¼·åŠ›ã§ã‚ã‚Šã€è‡ªç„¶è¨€èªå‡¦ç†ã®è¦³ç‚¹ã§ã¯çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ç›¸å¯¾çš„ä¾¡å€¤ã¯æ¸›å°‘ã—ã¤ã¤ã‚ã‚‹ (p.44)ã€
	- ç¢ºã‹ã«ã‚‚ã†è‡ªç„¶è¨€èªå‡¦ç†ã§ã¯çŸ¥è­˜ã‚°ãƒ©ãƒ•ã£ã¦ãã‚“ãªè¨€ã‚ãªã„ã‹ãªã€‚ã€‚
		- https://x.com/mamoruk/status/1799070548863205470
- ã€ŒLLMã®å›ç­”çµæœã‚’è©•ä¾¡ã™ã‚‹ä»•çµ„ã¿ä½œã‚Šã€ã¯ã€ŒLLMã‹ã‚‰è‰¯ã„å›ç­”ã‚’å¼•ãå‡ºã™ã“ã¨ã€ã¨åŒã˜ãã‚‰ã„é‡è¦ã§ã™ã€‚
	- https://x.com/hiro_gamo/status/1799470543491694643
- æ·±å±¤å­¦ç¿’ã‚’å«ã‚€å¤šãã®å®Ÿå¿œç”¨ãƒ¢ãƒ‡ãƒ«ã§ã¯ï¼Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ä¸Šã§ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼ãƒ»ãƒ©ã‚ªè¨ˆé‡ãŒé€€åŒ–ã—ï¼ŒåŒå¯¾å¹³å¦æ§‹é€ ãŒå®šç¾©ã§ããªããªã‚‹ï¼ã™ãªã‚ã¡æƒ…å ±å¹¾ä½•ãŒå±•é–‹ã§ããªããªã‚‹
	- https://x.com/hayashiyus/status/1799457123103072282
	- ã™ãªã‚ã¡æƒ…å ±å¹¾ä½•ãŒå±•é–‹ã§ããªããªã‚‹ï¼åŒå¯¾å¹³å¦æ§‹é€ ã‚’ä¸€èˆ¬åŒ–ã—ãŸæ¦‚ã‚³ãƒ€ãƒƒãƒæ§‹é€ ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã“ã®èª²é¡Œã‚’å…‹æœã—ãŸè«–æ–‡
- Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/pdf/2406.02061
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
	- The AIW problem is a concise natural language task that asks: "Alice has N brothers and she also has M sisters. How many sisters does Alice's brother have?" While easily solvable by humans using common sense reasoning (the correct answer is M+1), most tested LLMs, including GPT-3.5/4, Claude, Gemini, LLaMA, Mistral, and others, show a severe collapse in performance, often providing nonsensical answers and reasoning.
- ã‚¢ãƒªã‚¹å•é¡Œã«ã‚ˆã‚‹æ—¥æœ¬èªæ¨è«–èƒ½åŠ›ã®æ¯”è¼ƒ
	- https://note.com/willplion/n/n5842538dd13d
	- ã€Œå¥³ã®å­ã®ã‚¢ãƒªã‚¹ã«ã¯4äººã®å…„å¼Ÿã¨1äººã®å§‰å¦¹ãŒã„ã¾ã™ã€‚ã‚¢ãƒªã‚¹ã®å…„å¼Ÿã«ã¯ä½•äººã®å§‰å¦¹ãŒã„ã¾ã™ã‹ï¼Ÿã€ã¨ã—ã€LLMãŒã‚¢ãƒªã‚¹ã®æ€§åˆ¥ãŒã‚ã‹ã‚‰ãªã„ç‚ºç­”ãˆã‚‰ã‚Œã¾ã›ã‚“ã¨ã‹è¨€ã„å‡ºã™ã“ã¨ãŒãªã„ã‚ˆã†ã«èª¿æ•´ã—ãŸã€‚
	- ã»ã¨ã‚“ã©ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ä¸Šä½ãƒ¢ãƒ‡ãƒ«ã«ãŠã„ã¦ã¯ã€ã‚¢ãƒªã‚¹å•é¡Œã«é–¢ã—ã¦ã¯å›ç­”ãŒã§ãã‚‹ã“ã¨ãŒã‚ã‹ã£ãŸã€‚ç‰¹ã«æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Œã°ç­”ãˆã‚‰ã‚Œã¦å½“ãŸã‚Šå‰ã¨ã„ã£ãŸçŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹ã€‚
- ã€ä»Šã®ç”ŸæˆAIã®æœ¬è³ªçš„ãªé›£ã—ã•ã¯ã€Œä½•ã‚’AIã«ç”Ÿæˆã•ã›ã‚‹ã—ã¦ã‚‚ã€å…¨ã¦é©ç¢ºãªè¨€è‘‰ã‚’ä½¿ã£ã¦AIã«æŒ‡ç¤ºã‚’ä¸ãˆãŸã»ã†ãŒçµæœãŒè‰¯ã„ã€ã¨ã„ã†ã“ã¨ã€
	- https://x.com/izutorishima/status/1799568010950348942
	- ã€ŒLLM ã‚’ä½¿ã„ã“ãªã›ã‚‹äºº ï¼ è¨€èªèƒ½åŠ›ãŒé«˜ã„äººã€ã¨è¨€ã„åˆ‡ã‚Œã‚‹ãã‚‰ã„ã«ã¯ ChatGPT ã‚’ä½¿ã„ã“ãªã›ã¦ã‚‹äººãŒå°‘ãªã„æœ€å¤§ã®ç†ç”±
	- ã“ã®ä½¿ã†äººã®è¨€èªãƒªãƒ†ãƒ©ã‚·ãƒ¼ã«ç›¸å½“ä¾å­˜ã™ã‚‹ã¨ã„ã†ä»•æ§˜ã¯ã€æŠ€è¡“é¢ã§ã¯ãªã‹ãªã‹å€‹ã€…äººã®å·®ã‚’åŸ‹ã‚ã‚‹ã“ã¨ã¯ã§ããªã„ã‚“ã˜ã‚ƒãªã„ã‹ã¨ã„ã†æ‡¸å¿µãŒã‚ã‚‹ã€‚ä½•æ•…ãªã‚‰ã€ã©ã‚“ãªã«AIãŒé ‘å¼µã£ã¦ã‚‚ã€ãã®AIãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹äººé–“ã®è¨€èªèƒ½åŠ›ã®å¼•ãä¸Šã’ã«ã¯é™ç•ŒãŒã‚ã‚‹ã‹ã‚‰ã€‚
	- ã“ã®è¨€èªèƒ½åŠ›ã®è‚²æˆã¨å¼·åŒ–ã¨ã„ã†èª²é¡Œã¯ã€æœ¬æ¥ã¯å¤§å­¦æ•™è‚²ä»¥ä¸Šã®ãƒ¬ãƒ™ãƒ«ã§è¡Œã‚ã‚Œã‚‹éç¨‹ã§ã€è‡ªåˆ†ã®çµŒé¨“ã§ã¯å¤§å­¦é™¢ã®ç ”ç©¶å®¤ãªã©ã§æ—¥ã€…å©ã‹ã‚Œã‚‹ã“ã¨ã«ã‚ˆã£ã¦ç£¨ã‹ã‚Œã‚‹ç¨®é¡ã®ã‚‚ã®ã ã¨æ€ã£ã¦ã„ã‚‹ã€‚ãã†ã„ã†ç‚¹ã§ã¯ã€ä¾‹ãˆå¤§å’ã®å­¦æ­´ã‚’æŒã£ã¦ã„ã‚‹ã¨ã—ã¦ã‚‚ã€æœ¬æ°—ã§AIã‚’æœ¬è³ªçš„ã«ä½¿ã„ã“ãªã›ã‚‹ã‚ˆã†ã«ãªã‚‹ã‚ˆã†ã«å†æ•™è‚²ã™ã‚‹ãŸã‚ã«ã¯ã€ã„ã‚ã‚†ã‚‹ã€Œç¤¾ä¼šäººã®ãƒªã‚¹ã‚­ãƒªãƒ³ã‚°ã€ã©ã“ã‚ã§ã¯ãªã„ãƒ¬ãƒ™ãƒ«ã®å†æ•™è‚²ãŒæœ¬å½“ã¯å¿…è¦ãªã®ã ã‚ã†ã€‚
	- https://x.com/nyaa_toraneko/status/1799302550841364919
- Azureã®ã‚µãƒ¼ãƒ“ã‚¹ã§GPT-4oã‚’å¼·åŒ–ã™ã‚‹ã¨æœ€å¼·ã ã¨ã„ã†ã®ãŒåˆ†ã‹ã£ã¦ã‚‚ã‚‰ãˆã‚‹ã¨æ€ã†ã€‚
	- https://x.com/super_bonochin/status/1799452550665773447
	- GPT-4oã¯ã€æ—¥æœ¬èªOCRå‘¨ã‚ŠãŒå¼·åŒ–ã•ã‚ŒãŸã¨ã¯ã„ãˆã€ç‰¹ã«æ‰‹æ›¸ãã¨ã‹ã ã¨ã¾ã ã¾ã ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ°—å‘³ã€‚ ãƒ¯ã‚¤ã®ã‚¢ãƒ—ãƒªã§ã¯GPT-4oã«ã‚ˆã‚‹ç”»åƒèªè­˜ã«ã€Document Intelligenceã«ã‚ˆã£ã¦æ§‹é€ åŒ–ã—ãŸæƒ…å ±ã‚’ä»˜åŠ ã™ã‚‹ã“ã¨ã§ã€ç²¾åº¦ã‚’é£›èºçš„ã«ä¸Šã’ã‚‹ã“ã¨ã«æˆåŠŸã—ã¦ã„ã‚‹ã®ã ï½—
		- https://x.com/super_bonochin/status/1799445107579695606
- NotebookLMã€ã‚„ã£ã¨ã‚³ãƒ³ã‚»ãƒ—ãƒˆãŒã‚ã‹ã£ãŸã®ã§ã™ãŒ
	- https://x.com/0317_hiroya/status/1799617523148796068
	- ã€AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ + RAGã€‘ 
		- AIãŒä¸»ã§ã€æƒ…å ±æºãŒå¾“ 
		- æƒ…å ±æºã‚’ä½¿ã†ã‚ˆã†ã«ãªã‚‹ã‘ã©ã€AIãŒå­¦ç¿’ã—ãŸå†…å®¹ã¨åˆã‚ã›ã¦ã€å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ 
	- ã€NotebookLMã€‘ 
		- æƒ…å ±æºãŒä¸»ã§ã€AIãŒå¾“
		- ãƒ¢ãƒ‡ãƒ«ã¯ã€è³‡æ–™ã®ã¿ã‚’åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã‚‹ã€‚
-  Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- Claims that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales and by utilizing an optimized kernel during inference, their modelâ€™s memory consumption can be reduced by more than 10Ã— compared to unoptimized models.
	- ã“ã‚Œã¾ã˜ã€‚FPGAè©¦ä½œã§ã‚‚ãã‚“ãªæ€§èƒ½å‡ºã‚‹ã‚“ã‹ã„ "The accelerator processes billion-parameter scale models at 13W beyond human-readable throughput"

## 6/3

Google I/Oã§ç™ºè¡¨ã•ã‚ŒãŸgoogleã®æ¤œç´¢xç”ŸæˆAIãŒã€ã¨ã¦ã‚‚ä¸è©•ã¨ã„ã†ã“ã¨ã§ã€Wall Street Journalã®è¨˜äº‹ã«ã‚‚ã‚ã‚‹ã‚ˆã†ã«ã€Perplexityã®å„ªç§€ã•ãŒéš›ç«‹ã¤ã€gooleãŒãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã—ãŸæ–°æŠ€è¡“ã§æœŸå¾…ã‚’è£åˆ‡ã‚‹ã®ã¯å…¨ãæ’ä¾‹ã§ã™ã­ã€‚ã¨ã¯ã„ã£ã¦ã‚‚ã€Gemini 1.5 Pro/Flashã®å„ªç§€ã•ã‚‚ã‚ã¡ã“ã¡ã§å ±å‘Šã•ã‚Œã¦ãŠã‚Šã€æœ¬å½“ã¯å„ªã‚Œã¦ã‚‹ã‚“ã§ã—ã‚‡ã†ã€‚Mistralã‹ã‚‰ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã®OSSã§ã‚ã‚‹CodestralãŒç™ºè¡¨ã€ã•ã£ããOllamaãŒå¯¾å¿œã€ã“ã‚Œã§ãŠå¥½ããªã‚¨ãƒ‡ã‚£ã‚¿ã¨çµ„ã¿åˆã‚ã›ã¦ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒå®Ÿç¾å¯èƒ½ã«ã€‚é‡å­åŒ–ã€å°è¦æ¨¡åŒ–ã«ã‚‚é€²å±•ãŒã‚ã‚Šã€Mixtral 8x22b ã®é‡å­åŒ–ç‰ˆQ6_K ãŒ $362 CPU(AMD Ryzen 9 5950X BOXã‹?)ã§è»½ã€…å‹•ä½œã™ã‚‹ã¨ã„ã†å ±å‘Šã‚‚ã‚ã£ãŸã‚Šã€Phi-3-Tinyã‚·ãƒªãƒ¼ã‚ºã®ã‚ˆã†ã«ã€ã•ã‚‰ã«å°ã•ã•ãªLLMã«ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã¿ãŸã„ãªå±•é–‹ã‚‚ã‚ã£ãŸã€‚llama.cppã§é‡å­åŒ–ç‰ˆã‚’å‹•ä½œã•ã›ã‚‹ã¨ollamaã‚ˆã‚Š1.8å€é€Ÿã„ã¨ã„ã†å ±å‘Šã‚‚ã€‚ç”ŸæˆAIã®é£›èºçš„æ€§èƒ½ã‚¢ãƒƒãƒ—ã®ç§˜å¯†ã¨ã„ã‚ã‚Œã‚‹ã€Œã‚°ãƒ­ãƒƒã‚­ãƒ³ã‚°ã€ã«é–¢ã™ã‚‹è«–æ–‡ã€æ±åŒ–å›è·¯å½¢æˆã®ç§˜å¯†ã«è¿«ã‚Šã€æ–°ãŸãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ææ¡ˆã¨ã„ã†ã®ã¯èƒ¸ç†±ã„ã€‚ç”ŸæˆAIã®ã€Œå‰µé€ æ€§ã€ã«é–¢ã™ã‚‹ï¼‘ï¼ä¸‡äººã®äººé–“ï¼ã¨ã®æ¯”è¼ƒã§ã€GPT-4ãªã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·¥å¤«ã™ã‚Œã°ã€äººé–“ã‚’ä¸Šå›ã‚‹ã¨ã„ã†ã®ã«ã¯é©šã„ãŸã€‚O'Reillyã‹ã‚‰Prompt Engineeringã®æ–°åˆŠã‚‚å‡ºã‚‹ãŒã€ãã‚‚ãã‚‚Anthropicã®Claude3ã¯ã€ã‚´ãƒ¼ãƒ«ã‚’ä¸ãˆã‚Œã°é©åˆ‡ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¦ãã‚Œã‚‹ã¨ã„ã†ã€‚è²¡å‹™è«¸è¡¨ã‹ã‚‰å°†æ¥ã®åç›Šã®ä¼¸ã³ã‚’äºˆæ¸¬ã™ã‚‹ã‚¿ã‚¹ã‚¯ã§GPT-4ã¯äººé–“ã‚ˆã‚Šå„ªã‚Œã¦ã„ã‚‹ã¨èã„ã¦ã‚‚é©šã‹ãªããªã£ãŸã€‚ãã‚“ãªAIã§ã™ãŒã€AIãŒä»–è€…ã®å¿ƒã‚„æ„å›³ã‚’ç†è§£ã™ã‚‹èƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã®ã‹ã®ã€Œå¿ƒã®ç†è«–(ToM:Theory of Mind)ã€ã‚’æŒã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’åˆ†æã—ãŸè«–æ–‡ã§ã¯ã€GPT-4 and Flan-PaLM ãŒäººé–“ã®å¤§äººã®ãƒ¬ãƒ™ãƒ«ã«é”ã—ãŸã¨ã®ã“ã¨ã€‚ã•ã‚‰ã«äººé–“ã‚’è¶…ãˆã‚‹ã¨ã„ã†æ„å‘³ã§ã¯ã€Autoformalizing ã¨ã„ã†ã€äººé–“ãŒä½œã£ãŸå¹¾ä½•å­¦ã‚’AIãŒè‡ªå‹•è¨¼æ˜ã§ãã‚‹ä½“ç³»ã«ã€ç”ŸæˆAIã‚’ã¤ã‹ã£ã¦ä½œã‚Šç›´ã™ã¨ã„ã†è©¦ã¿ã‚‚ã‚ã£ãŸã€‚ã“ã†ãªã‚‹ã¨äººé–“ã®ç†è§£ãŒã©ã“ã¾ã§ç”ŸæˆAIã«ã¤ã„ã¦ã„ã‘ã‚‹ã‹ã¨ã„ã†ç‚¹ãŒå¿ƒé…ã«ãªã‚‹ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®å‹•ä½œç†è§£ã®ã€ŒGraph Gameã€ã‚„ã€LoRaã®åŸç†ã®å¯è¦–åŒ–ãªã©ã€ãã†ã„ã†ã®ã‚‚ç›®ç«‹ã£ãŸæ°—ãŒã™ã‚‹ã€‚å…¨ãåå¯¾ã«ã‚¢ã‚»ãƒ¢ã‚°ãƒ«æ°ã®ã‚ˆã†ã«ã€ãã‚Œã»ã©AIã¯æ ¼å·®æ‹¡å¤§ã«å½±éŸ¿ã—ãªã„ã¨ã„ã†åˆ†æã‚‚ã‚ã£ãŸã€‚å®‰å…¨æ€§ã«é–¢ã—ã¦ã¯ã€RAGã‚’å‰æã¨ã—ãŸãƒãƒƒã‚¯ãƒ‰ã‚¢TrojanRAGã¨ã„ã†ã®ã‚‚å‡ºãŸã€èª¬æ˜æ€§ãŒé«˜ã„ã“ã¨ã¨ãƒãƒƒã‚¯ãƒ‰ã‚¢ã‚’ä»•è¾¼ã¿ã‚„ã™ã„ã¨ã„ã†ã®ã¯è¡¨è£ä¸€ä½“ã€‚ã•ã¦æ—¥æœ¬ã§ã¯ã€äººå·¥çŸ¥èƒ½å­¦ä¼šãŒæµœæ¾ã§é–‹å‚¬ã€å²¡å´å…ˆç”Ÿã®ã‚¹ãƒ©ã‚¤ãƒ‰ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã€ã¯å¿…è¦‹ã§ã™ã€‚ä¸€æ–¹ã€ChatGPTã®RLHFï¼ˆãƒ’ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹å¼·åŒ–å­¦ç¿’ï¼‰ãƒ—ãƒ­ã‚»ã‚¹ã®å¤šããŒã€ã‚¢ã‚¦ãƒˆã‚½ãƒ¼ã‚¹ã•ã‚ŒãŸï¼ˆæ¯”è¼ƒçš„äººä»¶è²»ã®å®‰ã„ï¼‰ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ãŸã¡ã«ã‚ˆã£ã¦è¡Œã‚ã‚ŒãŸçµæœã§ã€ãªã‚“ã¨ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢è‹±èªã®delveã¨ã„ã†å˜èªãŒç”Ÿç‰©ç³»ã®è«–æ–‡ã«å¤§é‡ã«è¡¨ã‚ŒãŸã¨ã®å ±å‘Šã‚‚ã‚ã£ãŸã€‚ãã‚‚ãã‚‚äººé–“ã®ã»ã†ã‚‚ã€ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã§åˆç†çš„ã«æ€è€ƒã™ã‚‹èƒ½åŠ›ã«èª²é¡ŒãŒã‚ã‚Šã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã«æµã•ã‚ŒãŒã¡ã¨ã®æŒ‡æ‘˜ãŒã‚ã‚‹ã®ã§ã€ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ€§ã‚’æ±‚ã‚ã™ãã¦ã€åˆç†çš„ã«æ€è€ƒã§ããªã„ç”ŸæˆAIãŒã§ãã‚‹ã‹ã‚‚ã€‚ãƒ­ã‚¤ãƒ¤ãƒ«ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼ã®ã€ŒAI in Scienceã€ã™ã§ã«ã€ŒAI for Scienceã€ã¨ã„ã£ã¦ã„ã‚‹æ™‚ä»£ã§ã¯ãªããªã£ãŸã€ã¤ã¾ã‚ŠAIã‚’ä½¿ã‚ãšã«ç§‘å­¦ã®é€²å±•ã¯ãªã„ã€‚ã•ã¦NASAã‹ã‚‰æº€ã‚’æŒã—ã¦ã€å¤§æ°—ç¾è±¡ã‚’äºˆæ¸¬ã™ã‚‹åŸºç›¤ãƒ¢ãƒ‡ãƒ«Auroraã®ç™ºè¡¨ã€10kmãƒ¡ãƒƒã‚·ãƒ¥ã§10æ—¥å¾Œã¾ã§å¤©æ°—äºˆå ±ã§ãã‚‹ã£ã¦ã©ã‚Œãã‚‰ã„ã™ã”ã„ã®ã ã‚ã†ã€‚å…¨ãã®ä½™è«‡ã ãŒã€gpt-4oã®ç™ºè¡¨æ™‚ã«å‚ç…§ã•ã‚ŒãŸæ˜ ç”»"Her"ã®ç›£ç£ã®é›¢å©šã—ãŸå¦»ãŒç›£ç£ã—ãŸ "Lost In Translation"ã®ï¼’ã¤ã‚’æ¯”è¼ƒã—ã€ä¸€éƒ¨ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãŒå…¨ãå¯¾ç…§çš„ã«ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã—ã¦ã„ã‚‹ã¨ã„ã†è©±é¡ŒãŒãƒ†ãƒƒã‚¯ç•Œéšˆã§ä¸€ç¬è©±é¡Œã«ãªã£ãŸã€‚

-  è‡ªåˆ†ãŒã©ã‚Œãã‚‰ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç†è§£ã—ã¦ã„ã‚‹ã‹ã‚’ç¢ºã‹ã‚ã‚‰ã‚Œã‚‹ã‚²ãƒ¼ãƒ ã€ŒGraph Gameã€
	- https://gigazine.net/news/20240526-graph-game/
- googleã®æ¤œç´¢xç”ŸæˆAIã«ã¤ã„ã¦ã¯ï¼Œã¡ã‚‡ã£ã¨è©•ä¾¡ãŒã‚¤ãƒã‚¤ãƒãªã‚“ã§ã™ã‚ˆã­ï¼æ²¹ã¨æ°´ã‚’ç„¡ç†ã‚„ã‚Šæ··ãœã‚ˆã†ã¨ã—ã¦ã„ã‚‹æ„ŸãŒã‚ã‚‹ï¼by ä»Šäº•ã•ã‚“
	- https://x.com/ImAI_Eruel/status/1794707281600496111
-  TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models
	- https://arxiv.org/abs/2405.13401
	- RAGã‚’æ‚ªç”¨ã—ãŸãƒãƒƒã‚¯ãƒ‰ã‚¢æ”»æ’ƒã€‚RAGã§ä½¿ç”¨ã™ã‚‹çŸ¥è­˜DBã«ç´°å·¥ãƒ‡ãƒ¼ã‚¿ã‚’æ³¨å…¥ã—ã€ï¼ˆDBã‹ã‚‰é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢ã™ã‚‹ï¼‰ãƒªãƒˆãƒªãƒ¼ãƒã¨DBé–“ã§ãƒãƒƒã‚¯ãƒ‰ã‚¢ãƒªãƒ³ã‚¯ã‚’ä½œæˆã™ã‚‹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒˆãƒªã‚¬ãƒ¼ã¨ãªã‚‹PromptãŒå…¥åŠ›ã•ã‚ŒãŸå ´åˆã®ã¿ã€LLMã«æ‚ªæ„ã®ã‚ã‚‹å›ç­”ã‚’ç”Ÿæˆã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ã®ã“ã¨ã€‚
- We're now able to run Mixtral 8x22b Q6_K on a $362 CPU with better than human reading speed.
	- https://github.com/Mozilla-Ocho/llamafile/discussions/450
- llama.cpp runs 1.8 times faster than ollama
	- https://x.com/rohanpaul_ai/status/1794470545586635238
- Exploring the Impact of ChatGPT on Wikipedia Engagement
	- https://arxiv.org/pdf/2405.10205
	- Wikipedia remains the crowning achievement of Internet 1.0. It powered the rise of search engines (which depend on it) & generative AI (trained on its data).
- Grokked Transformers are Implicit Reasoners:A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/pdf/2405.15071
	- 1) Transformers can learn to implicitly reason, but only through extended training far beyond overfitting, a phenomenon known as grokking.
	- 2) Transformers exhibit different levels of systematicity in generalization across reasoning types: ID generalization is consistently observed, OOD generalization fails for composition but succeeds for comparison tasks.
	- æ±åŒ–å›è·¯å½¢æˆã®ç§˜å¯†ã«è¿«ã‚Šã€ã‚ãŸã‚‰ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æå”±ã—ã¦ã„ã‚‹
-  Phi-3-Tiny-Untrained
	- https://colab.research.google.com/drive/188RpybbauEJKSIRPGL3RZi4Lk66HfBJj
	- This 50M-parameter model reconfigs Phi-3-mini-128k-instruct (3.8B parameters) by following the parameters given by the Super Tiny Language Models from A*STAR.
-  GPT-4ã¯è²¡å‹™è«¸è¡¨ã‹ã‚‰å°†æ¥ã®åç›Šã®ä¼¸ã³ã‚’äºˆæ¸¬ã™ã‚‹ç‚¹ã§äººé–“ã®ã‚¢ãƒŠãƒªã‚¹ãƒˆã‚ˆã‚Šã‚‚å„ªã‚Œã¦ã„ã‚‹ã“ã¨ãŒç ”ç©¶ã«ã‚ˆã‚Šæ˜ã‚‰ã‹ã«
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311
- The Wall Street Journal says perplexity outperforms chatgpt, gemini & claud
	- https://x.com/RubenHssd/status/1795108714564706452
- Difyã¨Ollamaã‚’ä½¿ç”¨ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’æ§‹ç¯‰ã—ã€è¤‡æ•°ã®LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­å®šã—ã¦AIãŒç¤¾ä¼šã«ä¸ãˆã‚‹å½±éŸ¿ã«ã¤ã„ã¦è­°è«–ã‚’è¡Œã„ã€ãã®çµæœã‚’è¨˜äº‹ã¨ã—ã¦ç”Ÿæˆã™ã‚‹æ‰‹é †ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚
	- https://hamaruki.com/how-to-configure-and-discuss-multiple-agents-using-dify-and-local-llm/
-  How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?
	- https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms
	- In April, there were four major open LLM releases: Mixtral, Llama 3, Phi-3, and OpenELM.
- Decoder-onlyãªLLMï¼ˆMistral-7Bï¼‰ã‚’text embeddingç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆLoRAï¼‰ã—ã¦MTEBã§SoTAã‚’é”æˆã—ãŸæ–¹æ³•NV-Embedã®ææ¡ˆ
	- https://x.com/s_tat1204/status/1795344530285457626
- Google Search algorithm leaked today.
	- https://x.com/hridoyreh/status/1795394077510517217
-  Autoformalizing Euclidean Geometry
	- https://arxiv.org/abs/2405.17216
	- Can AI transform human mathematics into formal theorems and proofs that machines can verify?
	- This process, known as autoformalization, is a key step towards AI mathematicians. We introduce a neuro-symbolic framework for autoformalization, focusing on Euclidean geometry and combining domain knowledge, SMT solvers, and LLMs.
- Mixtral 8x7B Instruct with AWQ & Flash-Attention-2 in ~24GB GPU VRAM!
	- https://x.com/rohanpaul_ai/status/1795196332166070289
	- With the latest release of AutoAWQ - you can now run Mixtral 8x7B MoE with Flash Attention 2 for blazingly fast inference.
-  Automatic Domain Adaptation by Transformers in In-Context Learning
	- https://arxiv.org/abs/2405.16819
	- å¹¡è°·ã•ã‚“ï¼ˆç†ç ”ç‰¹åˆ¥ç ”ç©¶å“¡ï¼‰ã¨æ¾äº•å…ˆç”Ÿï¼ˆåå¤§ï¼‰ã®ç ”ç©¶ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãŒã‚¤ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ã«ãŠã„ã¦ã€è¤‡æ•°ã®ãƒ‰ãƒ¡ã‚¤ãƒ³é©å¿œæ³•ã‚’è¡¨ç¾ã—ã€ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã«å¿œã˜ã¦é©åˆ‡ãªé©å¿œæ³•ã‚’é¸æŠã™ã‚‹èƒ½åŠ›ã‚’æŒã¤ã“ã¨ã‚’ç†è«–ã¨å®Ÿé¨“ã§ç¤ºã—ãŸã‚‚ã®ã§ã™ã€‚
- Training and Finetuning Embedding Models with Sentence Transformers v3
	- https://huggingface.co/blog/train-sentence-transformers
- ã¡ãªã¿ã«Gemini 1.5 Proã§ã¯application/jsonã‚’å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨ã—ã¦é¸æŠã§ãã¦ä¾¿åˆ©
	- https://ai.google.dev/gemini-api/docs/api-overview?hl=ja#json
- CLARINET: Augmenting Language Models to Ask Clarification Questions for Retrieval
	- https://arxiv.org/abs/2405.15784
	- Fine-tunes an LLM to ask clarification questions that maximize retrieval success for ambiguous search queries, outperforming heuristic methods and vanilla language models
- æ˜ ç”»herã¨Lost In Translationã®ç›£ç£ã¯é›¢å©šã—ãŸå…ƒå¤«å©¦ã§ã‚ã‚Šã€ãã®ç”»åƒã®ä¸€éƒ¨ã¯ã‚·ãƒ³ã‚¯ãƒ­ã—ã¦ã„ã‚‹ã€‚ã€‚
	- https://x.com/MissSassbox/status/1795205212770119782
	- I had no idea that "Her" and "Lost In Translation" were clapbacks by the directors to each other after their divorce and now I need to watch both
	- Techç•Œã§ã€gpt-4oã®ãƒ‡ãƒ¢ãŒã€ã€æ˜ ç”»herã‚’æ„è­˜ã—ã¦ä½œã‚‰ã‚Œã¦ã„ãŸã“ã¨ã‹ã‚‰ã€ï¼ˆå†ï¼Ÿï¼‰ç™ºè¦‹ã•ã‚ŒãŸé›‘å­¦
- Introducing Transformers Agent 2.0: A Leap Forward in Intelligent Automation
	- https://huggingface.co/blog/Andyrasika/transformer-agents
- æ¾ç”°èªéŒ²ï¼šGemini 1.5 Proã‚’è«–æ–‡ã‚’èª­ã‚€ã®ã«ä½¿ã£ã¦ã¿ãŸã€œè‰¯ã„ã¨ã“ã‚ã¨æ‚ªã„ã¨ã“ã‚
	- https://x.com/npaka123/status/1795568613900062747
- ChatTTS: a powerful voice generation model designed for conversational scenarios
	- https://github.com/2noise/ChatTTS
	- https://huggingface.co/2Noise/ChatTTS
- ã€ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚’å«Œã†äººãŸã¡ã€€ç§‘å­¦å¦å®šè«–è€…ã¯ä½•ã‚’è€ƒãˆã€ã©ã†èª¬å¾—ã§ãã‚‹ã®ã‹ï¼Ÿã€by æš¦æœ¬å…ˆç”Ÿ
	- https://x.com/rkmt/status/1795636068752212063
	- ãŠãŠãƒ¼ã€‚ã—ã‹ã—ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ã§æ€è€ƒã™ã‚‹äººé¡ã¯ã‚€ã—ã‚å°‘æ•°æ´¾ã‹ã‚‚ã—ã‚Œãªã„..(System1æ€è€ƒ=Fast Thinking > System2æ€è€ƒ Slow Thinking) ã€‚ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã‚ˆã‚Šã‚‚ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãŒå„ªå…ˆã™ã‚‹.
- é€²åŒ–çš„ãƒãƒ¼ã‚¸ã«ã‚ˆã£ã¦ç›¸å½“å¼·ãã†ãªãƒ¢ãƒ‡ãƒ«ã€Umievo-itr012-Gleipnir-7BãŒç”Ÿã¾ã‚Œã¾ã—ãŸã€‚3å›ElyzaTasks100ã§è©•ä¾¡ã—ãŸå¹³å‡ã‚¹ã‚³ã‚¢ã¯3.91ï¼ã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://huggingface.co/umiyuki/Umievo-itr012-Gleipnir-7B
	- ãƒãƒ¼ã‚¸ã«ä½¿ç”¨ã•ã›ã¦ã„ãŸã ã„ãŸã®ã¯Japanese-Starling-ChatV-7Bã€Ninja-v1-RP-expressive-v2ã€Vecteus-v1ã€Japanese-Chat-Umievo-itr004-7bã®ï¼”ã¤ã§ã™ã€‚å„ãƒ¢ãƒ‡ãƒ«åˆ¶ä½œè€…ã®Aratakoã•ã‚“ã€Bakuã•ã‚“ã€Local-Novel-LLM-projectã®ã¿ãªã•ã¾ã«æ„Ÿè¬ã—ã¾ã™ã€‚ãã‚Œã‹ã‚‰å•é¡Œè§£æ±ºã®ãã£ã‹ã‘ã‚’ãã‚ŒãŸHoly-foxã•ã‚“ã«æ„Ÿè¬ã—ã¾ã™ã€‚
- AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)
	- https://x.com/emollick/status/1795830809217454536
	- https://www.researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models
	- GPT-4 wins. Better prompting can further improve performance & diversity of ideas.
	- ã¤ã„ã«å‰µé€ æ€§ã§ã‚‚GPT-4ãŒã€ï¼ˆæ™®é€šã®ï¼‰äººé–“ã‚’æŠœã„ãŸã®ã‹ã€‚ã€‚
- Gemini 1.5 Flashã¯Claude 3 Opusã«åŒ¹æ•µã—ãªãŒã‚‰ã€ã‚³ã‚¹ãƒˆã¯100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã‚ãŸã‚ŠãŸã£ãŸã®55å††
	- https://x.com/gijigae/status/1795743286533255285
- Announcing Codestral: our first-ever code model
	- https://chat.mistral.ai/chat
	- "Write me a function that computes fibonacci in Rust"
- OllamaãŒCodestralã«å¯¾å¿œ
	- https://ollama.com/library/codestral
- "Science in the Age of AI - How AI is changing the nature and method of scientific research,"
	- https://royalsociety.org/-/media/policy/projects/science-in-the-age-of-ai/science-in-the-age-of-ai-report.pdf
	- è‹±å›½ãƒ­ã‚¤ãƒ¤ãƒ«ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼
	- Generative AI tools can assist the advancement of scientific research.
-  Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- 1. You can extract out a knowledge graph according to a set of extractors. These extractors include defining a pre-defined schema of entities/relationships/properties, defining a set of node relationship with llama_index constructs, or implicitly figuring out the schema using an LLM.
	- 2. You can now query a knowledge graph with a huge host of different retrievers that can be combined: keywords, vector search, text-to-cypher, and more. 3. You can include the text along with the entities/relationships during retrieval 4. You can perform joint vector search/graph search even if your graph store doesnâ€™t support vectors! Weâ€™ve created robust abstractions to plug in both a graph store as well as a separate vector store. 5. You have full customizability: Weâ€™ve made it easy/intuitive for you to define your own extractors and retrievers.
- The structure of the EU AI Office
	- https://x.com/LuizaJarovsky/status/1795775192347627857
	- The â€œExcellence in AI and Roboticsâ€ unit
	- The â€œRegulation and Complianceâ€ unit 
	- The â€œAI Safetyâ€ unit
	- The â€œAI Innovation and Policy Coordinationâ€ unit
	- The â€œAI for Societal Goodâ€ unit 
	- The Lead Scientific Advisor
	- The Advisor for International Affairs
- è‹±å›½ã®ã‚¢ã‚«ãƒ‡ãƒŸãƒ¼ã€Royal Societyã‚‚ã€ŒAI for Scienceã€ã§ã¯ãªãEUã¨åŒã˜ã€ŒAI in Scienceã€ã€‚ãƒ¬ãƒãƒ¼ãƒˆã¯ã‹ãªã‚Šå……å®Ÿã—ã¦ã„ã‚‹ by maruyamaã•ã‚“
	- https://x.com/rmaruy/status/1795967400502006026
- Mamba, Griffin, RWKV, RetNet, Recurrent Gemma- 2024 is the year of gated linear RNNs! What's their secret sauce?
	- https://x.com/ItamarZimerman/status/1796181061984030914
- CRDSã®æ–°ä½œãƒ—ãƒ­ãƒãƒ¼ã‚¶ãƒ«ã€æ¬¡ä¸–ä»£AIãƒ¢ãƒ‡ãƒ«ã®ç ”ç©¶é–‹ç™ºã€ãŒã‚ã¡ã‚ƒãã¡ã‚ƒã„ã„ä»•äº‹ã§ä¸€æ°—è¦‹ã—ãŸã€‚
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-SP-03.html
	- https://x.com/resnant/status/1796181056283898332
	- LLMå«ã‚æœ€è¿‘ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã‚„ç”Ÿæˆç³»AIã®å‹•å‘ã¨è«¸èª²é¡Œã‚’æŠ€è¡“çš„ã«ã‚‚æ˜ã‚Šä¸‹ã’ã¦ã¦ã€ã„ã‚ã„ã‚ãªç«‹å ´ã®äººã«å‚è€ƒã«ãªã‚‹ã¨æ€ã†
- [LoRA] by Hand
	- https://x.com/ProfTomYeh/status/1796169087665557729
	- How does LoRA reduce the number of trainable parameters?
-  Donâ€™t Believe the AI Hype
	- https://www.project-syndicate.org/commentary/ai-productivity-boom-forecasts-countered-by-theory-and-data-by-daron-acemoglu-2024-05?
	- ãƒ€ãƒ­ãƒ³ãƒ»ã‚¢ã‚»ãƒ¢ã‚°ãƒ«æ°ã®åˆ†æã§ã¯ã€AIã«ã‚ˆã£ã¦å½±éŸ¿ã‚’ã†ã‘ã‚‹äººé–“ã®ã‚¿ã‚¹ã‚¯ã¯4.6ï¼…ã§ã€å‘ã“ã†åå¹´ã®AIã«ã‚ˆã‚‹å…¨è¦ç´ ç”Ÿç”£æ€§ã®å‘ä¸Šã¯0.66%ã«ã¨ã©ã¾ã‚‹ã€‚AIã«ã‚ˆã‚‹ç§‘å­¦ç™ºè¦‹ã¯ç›´è¿‘ã§ã¯çµŒæ¸ˆã«ã•ã»ã©å½±éŸ¿ã—ãªã„ã€‚ã‹ã¤ã¦ã®è‡ªå‹•åŒ–æŠ€è¡“ã«æ¯”ã¹ã‚‹ã¨æ ¼å·®æ‹¡å¤§åŠ¹æœã¯å°ã•ã„ãŒè¦åˆ¶ã¯å¿…è¦
-  Aurora: A Foundation Model of the Atmosphere
	- https://arxiv.org/abs/2405.13063
	- NASA has created a new foundation model for geospatial data.
	- Create 5-day air pollution predictions in < 1 minute 
	- Create 10-day weather forecasts at ~10km resolution 
	- Assess the chemical make up of the atmosphere
- llm.cã‚’ä½¿ã†ã¨GPT-2ã‚’$20ã§2æ™‚é–“ä»¥å†…ã«æ§‹ç¯‰å¯èƒ½ï¼Ÿï¼Ÿ
	- https://x.com/overlast/status/1796028138616422535
- Hereâ€™s a great guide teaching you how to construct knowledge graphs using LLMs that adhere to a pre-defined schema - using purely local models
	- https://x.com/llama_index/status/1796198853764595725
- ã€Œå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã€ byã€€å²¡å´ã•ã‚“ã€€@ JSAI2024
	- https://speakerdeck.com/chokkan/jsai2024-tutorial-llm
	- ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«è¬›æ¼”ã‚’è¡Œã„ã¾ã—ãŸã€‚äº‹å‰å­¦ç¿’ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã€è©•ä¾¡ã®ï¼”éƒ¨æ§‹æˆã§ã€æœ€è¿‘ã®ç ”ç©¶å‹•å‘ã‚„çŸ¥è¦‹ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚
- Prompt Engineering for Generative AI
	- https://www.amazon.com/gp/product/B0D4FBPLX1?&linkCode=sl1&tag=kirkdborne-20&linkId=17812cf95726cdbbe7b0c29f94f4bce7&language=en_US&ref_=as_li_ss_tl
	- With this book, you'll gain a solid foundation in generative AI, including how to apply these models in practice. When first integrating LLMs and diffusion models into their workflows, most developers struggle to coax reliable enough results from them to use in automated systems.
- LLMs achieve adult human performance on higher-order theory of mind tasks
	- https://huggingface.co/papers/2405.18870
	- LLMs achieve adult human performance on higher-order theory of mind tasks 
	- This paper examines the extent to which large language models (LLMs) have developed higher-order theory of mind (ToM); the human ability to reason about multiple mental and emotional states in
	- We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level performance on ToM tasks overall, and that GPT-4 exceeds adult performance on 6th order inferences
- ç”ŸæˆAIã«ã‚ˆã‚‹ã€Œæ…£ç”¨è¡¨ç¾ã®ã€ä¹—ã£å–ã‚Šã€ã€ã¨ã€ãã®æ ¹åº•ã«ã‚ã‚‹åˆ¥ã®å•é¡Œã¨ by TJOã•ã‚“
	- https://tjo.hatenablog.com/entry/2024/05/31/171000
	- ã€ŒChatGPTã«å­¦è¡“è«–æ–‡ã‚’ï¼ˆè‹±èªã§ï¼‰æ›¸ã‹ã›ã‚‹ã¨"[delve](https://eow.alc.co.jp/search?q=delve)"ã®ã‚ˆã†ãªæ™®æ®µä½¿ã‚ãªã„ã‚ˆã†ãªå˜èªãŒå¤šãä½¿ã‚ã‚Œã‚‹ã®ã§ãƒãƒ¬ã‚„ã™ã„ã€ã¨ã„ã†è©±ãŒ[SNS](https://d.hatena.ne.jp/keyword/SNS)ä»¥ä¸‹å„æ‰€ã§é »ç¹ã«å™‚
	- ChatGPTã®RLHFï¼ˆãƒ’ãƒˆã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã‚ˆã‚‹å¼·åŒ–å­¦ç¿’ï¼‰ãƒ—ãƒ­ã‚»ã‚¹ã®å¤šããŒã€ã‚¢ã‚¦ãƒˆã‚½ãƒ¼ã‚¹ã•ã‚ŒãŸï¼ˆæ¯”è¼ƒçš„äººä»¶è²»ã®å®‰ã„ï¼‰ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ãŸã¡ã«ã‚ˆã£ã¦è¡Œã‚ã‚ŒãŸçµæœã§ã‚ã‚‹ã€ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚ãã‚‚ãã‚‚ã€ä¾‹ãˆã°"delve"ã¨ã„ã†å˜èªã¯ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢è‹±èªã§ã¯ãƒ“ã‚¸ãƒã‚¹ãƒ•ãƒ¬ãƒ¼ã‚ºã®ä¸­ã§ã¯æ¯”è¼ƒçš„é »ç¹ã«ç”¨ã„ã‚‰ã‚Œã‚‹ãã†ã§*3ã€ãã‚Œã‚‰ã®ãƒŠã‚¤ã‚¸ã‚§ãƒªã‚¢è‹±èªã«ã‚ˆã‚‹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµæœãŒChatGPTã®å‡ºåŠ›ã«å½±éŸ¿ã—ã¦ã„ã‚‹ã€ã¨ã„ã†ã“ã¨ã®ã‚ˆã†ã§ã™*4ã€‚
- The new Anthropic prompt engineering tool is incredible.
	- https://x.com/dr_cintas/status/1796577510773379479
	- You just need to write your goal and Claude will generate an optimized prompt instantly.
-  An entirely open-source AI code assistant inside your editor
	- https://ollama.com/blog/continue-code-assistant
	- ã¤ã¾ã‚Šã€ollamaã‚’ã¤ã‹ã£ã¦ã€ã‚ãªãŸã®å¥½ã¿ã®ã‚¨ãƒ‡ã‚£ã‚¿ã«Code assistanceã‚’ã¨ã„ã†è©±
- æœ€è¿‘ã®7Bå°å‹æ—¥æœ¬èªLLMã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ãªã‚Œã‚‹ã®ã‹ï¼Ÿ
	- https://soysoftware.sakura.ne.jp/archives/3934
- 


## 5/27

ã•ã¦ä»Šé€±ã¯ã€Microsoftã®Build2024ãŒé–‹å‚¬ã€gpt-4oã‚’çµ„ã¿è¾¼ã‚“ã Copilot+PCã¨ã„ã†intelã¯ã„ã£ã¦ãªã„PCã®ã»ã‹ã«ã€èª°ã§ã‚‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚Œã‚‹Copilot é€²åŒ–çš„ã®æ›´æ–°ã‚„ã€äººã®ä»£ã‚ã‚Šã«ä¼šè­°é€²è¡Œã‚’ã—ã¦ãã‚Œã‚‹Team Copilotã€ã•ã‚‰ã«ã¯ã€ã‚½ãƒ•ãƒˆã‚¦ã‚¨ã‚¢é–‹ç™ºè‡ªå‹•åŒ–ã®ã€ŒDevinã€ã®ä¼šç¤¾ã¨ã®ææºãªã©ã€ç›®ç™½æŠ¼ã—ã€‚ã¾ã‚æ—©é€Ÿã€ã‚²ãƒ¼ãƒ ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹copilot assistantã®ãƒ‡ãƒ¢ã‚’Gemini 1.5 Flashã§ã€ã•ã‚‰ã«ãƒãƒªã‚ªã‚²ãƒ¼ãƒ ã§å†ç¾ã§ããŸã¨ã®å€‹äººã®å ±å‘Šã‚‚ã‚ã‚Šã¾ã—ãŸã€‚ã•ã¦æ¥æœˆã®Appleã® WWDC24ã¯ã©ã†ãªã‚‹ã€‚åŸºç›¤æŠ€è¡“ã§ã¯ã€ãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã§GPT-4ã¯54%ã®ç¢ºç‡ã§äººé–“ã ã¨åˆ¤æ–­ã•ã‚ŒãŸã¨ã„ã†ã®ã¯ã€ã‚‚ã†é©šã‹ãªã„ã€AIã«ã‚ˆã‚‹è©æ¬ºã«ã‚ã‚ãªã„ã‚ˆã†ã«å¿ƒãŒã‘ã¦ã‚‚ç„¡é§„ã¨ã„ã†æœªæ¥ãŒã€ã€ã€‚ã‚€ã—ã‚ã€ã€ŒLLMãŒãƒãƒ£ãƒƒãƒˆUIã«å‘ªã‚ã‚Œã¦ã„ã‚‹ã€ã¨ã„ã†è¨˜äº‹ã‚‚ã‚ã£ãŸãŒã€ã‚‚ã‚„ã¯LLMã®ç™ºå±•ã¯äººé–“ãŒå¾‹é€Ÿã—ã¦ã„ã¦é ­æ‰“ã¡ã«ãªã£ã¦ã„ã‚‹ã€‚ä¸€æ–¹Anthropicã®Claude3 Sonetã«å¯¾ã™ã‚‹ç‰¹å¾´æŠ½å‡ºã®è«–æ–‡ã€ã¤ã¾ã‚Šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆä¸Šã«LLMã®æ€§è³ªã‚ã‚‹ã„ã¯ç‰¹å¾´ã‚’ç¤ºã™å ´æ‰€ã‚’ç‰¹å®šã™ã‚‹æŠ€è¡“ï¼ˆã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ï¼‰ã€å®‰å…¨æ€§ã®åˆ†æã§å½¹ã«ç«‹ã¤ã¨ã„ã£ã¦ã„ã‚‹ãŒã€é€†ã«ç‰¹å®šã®ç®‡æ‰€ã‚’ç‰¹åˆ¥ã«æ´»æ€§åŒ–ã•ã›ã‚Œã°ã€ä¾‹ãˆã°ã€ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚²ãƒ¼ãƒˆãƒ–ãƒªãƒƒã‚¸ä¸€æŠ¼ã—ã®LLMãŒçˆ†èª•ã™ã‚‹ã¨ã®ã“ã¨ã€‚ã„ã‚„ã¾ã•ã«ã‚‚ã‚åˆƒã®å‰£ã¨ãªã‚‹é‡è¦ãªæŠ€è¡“ã€‚çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®RAGã‚‚ã‚¢ãƒ„ã‚¤ãŒã€GraphRAGã¨ã„ã†ç”»åƒåŒ–ã—ãŸçŸ¥è­˜ã‚°ãƒ©ãƒ•ã«å¯¾ã™ã‚‹RAGã¨ã„ã†æŠ€è¡“ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã ã¨ãã†ã„ã†ã“ã¨ã‚‚ã§ãã‚‹ã®ã‹ã€‚ä»Šäº•ã•ã‚“ã®GPT-4oã‚’ç ”ç©¶è€…è¦–ç‚¹ã§ã€Œæ™‚ä»£ã®è»¢æ›ç‚¹ã€ã¨è§£èª¬ã—ãŸè¨˜äº‹ã®ã‚·ãƒªãƒ¼ã‚ºã¯æ°—ã«ãªã‚‹ãŒç™»éŒ²ãŒå¿…è¦ãªã®ã‹ã€‚GUILDã®æ·±æ´¥ã•ã‚“ã®ã€æ¨ªé ˆè³€å¸‚ã®æœªå®Œæˆã®ãŠæ‚©ã¿ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€‚ä¸å®Œå…¨ã§ã‚‚ãƒ™ãƒ¼ã‚¿å…¬é–‹ã¨ã„ã†ã‚ã‚Šã«ã‚„ã£ã±ã‚ˆãã§ãã¦ã„ã‚‹ã€‚ãã®æ·±æ´¥ã•ã‚“ãŒã€ç”ŸæˆAIæ™‚ä»£ã«å¤§äº‹ãªã‚¹ã‚­ãƒ«ã¯ã€ã€Œã‚„ã‚Šç¶šã‘ã‚‹èƒ½åŠ›ã€ã€ã„ãã‚‰ç”Ÿæˆï¼¡ï¼©ãŒå„ªã‚Œã¦ã„ã¦ã‚‚ã‚ã’ãªã„ã“ã¨ãŒå¤§åˆ‡ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚‚ç›¸å¤‰ã‚ã‚‰ãšã‚¢ãƒ„ã‚¤ï¼ã€‚ä»Šé€±ã‚‚ã€Mistral v0.3ãŒãƒªãƒªãƒ¼ã‚¹ã€èªå½™æ•°ã‚‚å¢—ãˆã¦ã€è¦‹é•ãˆã‚‹ãã‚‰ã„æ—¥æœ¬èªèƒ½åŠ›ãŒå¼·åŒ–ã•ã‚Œã€function callingã¸ã‚‚å¯¾å¿œã€ollamaã‚‚raw modeã§funtion callingã¸å³è¿½å¾“ã€‚ä¸€æ–¹ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«phi3-visionã‚‚å«ã‚ã¦ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸphi3-small,mediumã€phi3-mediumãŒMMLUã‚¹ã‚³ã‚¢ã¯Llama3-70Bä¸¦ã¿ã«é«˜æ€§èƒ½ã§ã‚ã‚‹ã¨ã„ã†ã“ã¨ã ãŒã€é‡å­åŒ–ã§ãƒ‡ã‚°ãƒ¬ãƒ¼ãƒ‰ã—ãŸã®ã‹Ollamaã¸ã®çµ„ã¿è¾¼ã¿ã¯ã†ã¾ãã„ã£ã¦ãªã„æ¨¡æ§˜ã€‚Transformers.js ã¨ONNX Runtime Webã®çµ„ã¿åˆã‚ã›ã¨ã„ã†ã®ã‚‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å”åŠ›ãªåŠ©ã£äººã‹ã€‚CohereãŒå¤šè¨€èªæŒ‡å‘ã®ã‚ªãƒ¼ãƒ—ãƒ³LLMã§ã‚ã‚‹Aya 23 ã® 8B ã¨35BãŒãƒªãƒªãƒ¼ã‚¹ã€æ—¥æœ¬èªå¼·ãã†ã€‚ã—ã‹ã—ã€Phi-3ã¯ã€ã€Œæœ€ã‚‚æœ‰èƒ½ã§è²»ç”¨å¯¾åŠ¹æœã®SML (Small Language Model)ã€ã£ã¦ã„ã†ã‚“ã (Small LLMã®ã»ã†ãŒã‹ã£ã“ã‚ˆã„ã®ã«)ã€‚ ãã‚Œã«ã—ã¦ã‚‚ DeepSeekV2 ã€ã‚ã¾ã‚Šã«æ€§èƒ½ãŒé«˜ã„ã®ã§ä¸­å›½ã§ã®ç«¶åˆã®ã‚µãƒ¼ãƒ“ã‚¹æ–™ã‚’1%æŠ¼ã—ä¸‹ã’ãŸï¼ˆæŠ•ã’å£²ã‚Šé–‹å§‹ï¼Ÿï¼‰ã¨ã®ã“ã¨ã€‚ChatVectorã€7Bãƒ¢ãƒ‡ãƒ«ã®FineTuningçµæœã‚’70Bã«è»¢ç§»ã•ã›ã¦æ€§èƒ½å‘ä¸Šã—ãŸã‚Šã€LLaVAã®æ—¥æœ¬èªåŒ–ãªã©ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã‚‚ãã®èƒ½åŠ›ã‚’ãµãã‚ã¦èªçŸ¥ã‚„åˆ©ç”¨ãŒå¢—ãˆã¦ããŸã€‚transformersãŒv4.41.0ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã•ã‚Œã¦ggufã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã‚‚ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMå‹¢ã«ã¯æœ—å ±ã€‚EUã®AIæ³•ãŒæœ€çµ‚åˆæ„ã€ç”Ÿæˆï¼¡ï¼©ã®è¦åˆ¶ã‚‚ç››ã‚Šè¾¼ã¿æ¸ˆã¿ã€‚ä¸€æ–¹OECDã¯AIãƒªã‚¹ã‚¯ã«é–¢ã™ã‚‹ç”¨èªã‚’æ•´ç†ã—ã€ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®é‡å¤§ã•ã«ãƒã‚¶ãƒ¼ãƒ‰ãŒèµ·ã“ã‚‹ç¢ºç‡ã‚’åŠ å‘³ã—ãŸã‚‚ã®ãŒãƒªã‚¹ã‚¯ã®ãƒ¬ãƒ™ãƒ«ã«ãªã‚‹ã¨ã®ã“ã¨ã€‚è‹±å›½ã®ã€ŒSafeguarded AIãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã¯ã€å®‰å…¨æ€§ã®ãŸã‚ã«æ•°ç†è«–ç†å­¦ã‚„åœè«–ã‚’åˆ©ç”¨ã™ã‚‹ã€åŒã˜safe guardã§ã‚‚æ¯’ã«ã¯æ¯’ã‚’ã¨ã„ã†ã“ã¨ã§guardè‡ªä½“ã‚’LLMã§å®Ÿç¾ã™ã‚‹ãƒ¡ã‚¿ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨çœŸé€†ã§é¢ç™½ã„ã€‚

-  Unleashing the Power of Knowledge Graphs in Retrieval Augmented Generation (RAG): Step by Step Instruction
	- https://medium.com/@transformergpt/unleashing-the-power-of-knowledge-graphs-in-retrieval-augmented-generation-rag-step-by-step-84c2adc66c1c
	- This is a neat resource by Jayita B. on teaching you how to not only build an advanced RAG indexing/query pipeline, but also turn it into a full-stack application with rapid respons
- OECD (2024), "Defining AI incidents and related terms",
	- https://www.oecd-ilibrary.org/science-and-technology/defining-ai-incidents-and-related-terms_d1a8d965-en
	- OECDã®WGãŒä½œã£ã¦ã„ã‚‹AIãƒªã‚¹ã‚¯ã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã®ç”¨èªæ•´å‚™ã®ãƒ¬ãƒãƒ¼ãƒˆã€‚èµ·ã“ã‚Šã†ã‚‹è¢«å®³ã‚’ãƒã‚¶ãƒ¼ãƒ‰ã€èµ·ã“ã£ãŸè¢«å®³ã‚’ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã¨å‘¼ã³ã€ãã®é‡å¤§ã•ã‚’è€ƒæ…®ã€‚ãƒã‚¶ãƒ¼ãƒ‰ã«èµ·ã“ã‚‹ç¢ºç‡ã‚’åŠ å‘³ã—ãŸå…¨ä½“ãŒAIãƒªã‚¹ã‚¯ã¨ãªã‚‹
- Text-to-SQL - fully local edition
	- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
- Run Mixtral 8x7B-on a free-tier Google Colab with AQLM-2bit quantization
	- https://www.youtube.com/watch?v=6ikUpJcDrPs&list=PLxqBkZuBynVTzqUQCQFgetR97y1X_1uCI&index=32
- The theoretical minimum series by Leonard Susskind and Art Friedman
	- https://x.com/PhysInHistory/status/1792020784854311205
- Chat Vectorã§LLaVAã‚’æ—¥æœ¬èªå¯¾å¿œã•ã›ã‚‹
	- https://zenn.dev/toshi_456/articles/0166a6eaa81c7b
	- LLaVAã¯å¤§ããVision Encoderã€Vision Projectorã€LLMã¨ã„ã†3ã¤ã®éƒ¨å“ã‹ã‚‰ã§ãã¦ã„ã¾ã™ãŒã€LLMã®éƒ¨åˆ†ã ã‘ä¸Šè¨˜ã®ã‚ˆã†ã«é‡ã¿ã‚’åŠ æ¸›ç®—ã—ã¾ã™
	- ä»Šå›ä½¿ç”¨ã™ã‚‹LLaVAã®é‡ã¿ã¯[liuhaotian/llava-v1.5-7b](https://huggingface.co/liuhaotian/llava-v1.5-7b)ã§ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ¼ã‚¹ã®LLMã¯[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)ã§ã™ã€‚
	- Chat Vectorã‚„ãã®ä»–ã®ãƒãƒ¼ã‚¸æ‰‹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€è‹±èªã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ã€å­¦ç¿’ã•ã›ã‚‹ã¨ã„ã†æ‰‹é–“ãŒå¿…è¦ãªããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã¯ã‚ã‚ŠãŒãŸã„ãªã¨æ„Ÿã˜ã¾ã—ãŸã€‚
- æ¨ªé ˆè³€å¸‚ã§ã€æœªå®Œæˆã®ãŠæ‚©ã¿ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚ by æ·±æ¾¤ã•ã‚“
	- https://www.city.yokosuka.kanagawa.jp/0835/nagekomi/20240520_soudanbot_nyanpei.html
	- ã‚ãˆã¦æœªå®Œæˆã®ãƒœãƒƒãƒˆã‚’å…¬é–‹ã—ã¦ã€åºƒãä¸å…·åˆã‚’ã‚ã¤ã‚ã‚‹å®Ÿé¨“ã§ã™ï¼ï¼
	- ã•ã™ãŒã®ã§ãå‰ï¼
- å††ã®å®ŸåŠ›ã¨æ—¥æœ¬ä¼æ¥­ã®é€šè²¨æˆ¦ç•¥ï¼ˆé…ä»˜è³‡æ–™ãƒ»å‹•ç”»é…ä¿¡
	- https://www.youtube.com/watch?v=reLhpQg9muo
- ã€Œkagglehub ã‚’ä½¿ã£ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« gemma ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¨ãƒ¢ãƒ‡ãƒ«å…±æœ‰ã€
	- https://www.kaggle.com/code/makimakiai/kagglehub-gemma
	- Kaggleã®ãƒãƒ¼ãƒˆã§éŠ…ãƒ¡ãƒ€ãƒ«ã‚²ãƒƒãƒˆã—ãŸï¼å¬‰ã—ã„ï¼
		- https://x.com/hAru_mAki_ch/status/1792105063022018835
- Deep Dive on Accumulated Local Effect Plots (ALEs) with Python
	- https://towardsdatascience.com/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee
	- ALEs give interpretations that are robust to multicollinearity.
- è‹±å›½æ”¿åºœãŒ100å„„å††è¶…ã‚’æŠ•ã˜ã‚‹ã€ŒSafeguarded AIãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã¨ã¯
	- https://www.aialign.net/blog/20240520-takatsuki
	- æœ¬ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ãŠã„ã¦AIã‚·ã‚¹ãƒ†ãƒ ã®å®‰å…¨æ€§ã®è¨¼æ˜å¯èƒ½æ€§ã®åœŸå°ã¨ãªã‚‹ç†è«–ï¼ˆç‰¹ã«TA1.1ã§æ‰±ã‚ã‚Œã‚‹å†…å®¹ï¼‰ã«ã¯ã€æ•°ç†è«–ç†å­¦ã‚„åœè«–ã¨ã„ã£ãŸåˆ†é‡ãŒé‡è¦ãªä½ç½®ã‚’å ã‚ã‚‹ã“ã¨ãŒäºˆå®šã•ã‚Œã¦ãŠã‚Šã€ã“ã‚Œã‚‰ã®åˆ†é‡ã®ç ”ç©¶è€…ã®å”åŠ›ãŒå¿…è¦ã¨ã•ã‚Œã¦ã„ã¾ã™
- Copilot + PC by Nadella
	- https://x.com/satyanadella/status/179261785138542602
	- Introducing Copilot+ PCsâ€”the fastest, most AI-ready Windows PCs ever built.
		- Powered by new NPU (40+ trillion operations per second)
		- Rearchitected Windows 11 
		- 58% faster than Macbook Air M3 
		- Copilot shipping with Windows 
		- Copilot built into Settings, files, notifications 
		- Powered by GPT-4o
- LangChainã«Obsidianã®ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒã‚ã‚‹ï½ã€‚Obsidianã®ãƒ¡ãƒ¢ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã—ã¦RAGã§ãã¦ã—ã¾ã†ï½
	- https://www.youtube.com/watch?v=E-CNrXhSvLg
- The Illustrated Stable Diffusion	
	- https://jalammar.github.io/illustrated-stable-diffusion/
- Google has released Gemini 1.5 Flash.
	- https://x.com/dr_cintas/status/1792572374300188752
	- An AI model optimized for speed and efficiency, with multimodal reasoning and an impressive 1M context window!
-  AWSã€ä¸€èˆ¬æä¾›é–‹å§‹ã—ãŸç”ŸæˆAIã‚µãƒ¼ãƒ“ã‚¹ã€ŒAmazon Qã€ã€ãŠã‚ˆã³ã€ŒBedrockã€ã¨ä»Šå¾Œã®æˆ¦ç•¥ã‚’èª¬æ˜
	- https://internet.watch.impress.co.jp/docs/news/1592518.html?ref=smartnews
- The theory of mindâ€”the ability to track a person's mental stateâ€”is tested comparing humans vs GPT-4 and LLaMA2 large language models
	- https://www.nature.com/articles/s41562-024-01882-z
- GeminiãŒYouTubeå‹•ç”»ã‚’ä¸€ç¬ã§è¦ç´„ã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«ãªã£ãŸï¼ˆã—ã‹ã‚‚ç„¡æ–™
	- https://www.lifehacker.jp/article/2405-use-gemini-summarize-youtube-videos-free/
	- æœ¬å½“ã ï¼
- è¦³å¯Ÿã‚¹ã‚±ãƒ¼ãƒ«å‰‡ã¯ã€LLMã®æ¨™æº–çš„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®æ€§èƒ½ã‹ã‚‰æ±‚ã‚ã‚‰ã‚ŒãŸä¸»æˆåˆ†ï¼ˆ3ã¤ç¨‹åº¦ï¼‰ã‚’ç”¨ã„ã¦è¤‡é›‘ãªå¾Œç¶šã‚¿ã‚¹ã‚¯ã®æ€§èƒ½ã‚’é«˜ç²¾åº¦ã§äºˆæ¸¬ã§ãã‚‹æ³•å‰‡ã€€by å²¡é‡åŸã•ã‚“
	- https://arxiv.org/abs/2405.10938
- BREAKING: Council of Europe adopts 1st international treaty on AI. Here's what you need to know:
	- https://x.com/LuizaJarovsky/status/1792224914646200512
-  Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings
	- https://arxiv.org/abs/2405.10938
- è«–æ–‡ãƒ¡ãƒ¢: Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models b y ã¯ã¡ã•ã‚“
	- https://note.com/hatti8/n/nb61b4935c793?sub_rt=share_pb
	- GoogleãŒå…ˆé€±å‡ºã—ãŸLLMã®è‡ªå·±æ”¹å–„æ‰‹æ³•ã§ã‚ã‚‹ReSTEMã«ã¤ã„ã¦ã€ãƒ¡ãƒ¢ã‚’æ›¸ãã¾ã—ãŸã€‚
	- åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆæ‰‹æ³•ã¨ã—ã¦ã©ã†ã‹ã¨ã„ã†è¦–ç‚¹ã§æ›¸ã„ã¦ã„ã¾ã™
- på€¤å§«ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ç·¨ï¼‰
	- https://x.com/spine_surgeon_/status/1792767885615759746
	- ã€Œãƒãƒªã‚ªã¸ã€å®Ÿé¨“çµæœã„ã„æ„Ÿã˜ã§ã™ï¼ã„ã„æ„Ÿã˜ãªã‚“ã§ã™ã‘ã©ã€æœ‰æ„å·®ã§ã‚‹ã¾ã§ã‚µãƒ³ãƒ—ãƒ«æ•°å¢—ã‚„ã—ã¦ã¿ã¦ãã ã•ã„ã€‚æœ‰æ„å·®å‡ºã‚‹ã¾ã§é€£çµ¡ã¯ä¸è¦ã§ã™ã€‚ãƒ”ãƒ¼ãƒã‚ˆã‚Šã€‚ã€
- People cannot distinguish GPT-4 from a human in a Turing test
	- https://arxiv.org/abs/2405.08007
	- AIã®äººé–“ã‚‰ã—ã•ã‚’æ¸¬ã‚‹ãƒ†ã‚¹ãƒˆã§ä¸–ç•Œä¸€æœ‰åãªãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã§ã™ãŒï¼Œã•ã‚“ã–ã‚“ã€Œã‚‚ã†AIã¯ãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆçªç ´ã§ãã‚‹ã‚„ã‚ã€ã¨è¨€ã‚ã‚Œã¦ãŸã®ã‚’çœŸé¢ç›®ã«åˆ†æã—ãŸè«–æ–‡ãŒå‡ºã¾ã—ãŸ
	- çµè«–ã¯ã€Œç¾åœ¨ã®GPT-4ãªã©ã®æœ€å…ˆç«¯AIã¯ï¼Œãƒãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆã‚’çªç ´å¯èƒ½ã§ã‚ã‚Šï¼Œäººé–“ã¯ã‚‚ã¯ã‚„äººã¨AIã‚’ä¼šè©±ã®ã¿ã‹ã‚‰åˆ¤å®šã™ã‚‹ã“ã¨ã¯ã§ããªã„ã€ã¨ã„ã†ã‚‚ã®ã§ã™ï¼GPT-4ã¯54%ã®ç¢ºç‡ã§äººé–“ã ã¨åˆ¤æ–­ã•ã‚ŒãŸæ¨¡æ§˜
- æœ€è¿‘ãƒ­ãƒ¼ã‚«ãƒ«LLMãŒã‚¢ãƒ„ã„ã‚‰ã—ã„
	- https://soysoftware.sakura.ne.jp/archives/3903
	- GPTã®APIé«˜ã„å•é¡Œ ï¼† OpenAIãŒAIãƒ™ãƒ³ãƒãƒ£ãƒ¼çš†æ®ºã—ã«ã—ã¦ã—ã¾ã†å•é¡Œ
	- ãƒ­ãƒ¼ã‚«ãƒ«LLMæ¨è«–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè‰²ã€…ã‚ã‚‹
		- Llma.cpp, ollama, vLLM
	- å¼·åŠ›ãªå¤§å‹ã‚ªãƒ¼ãƒ—ãƒ³ãªAIãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã¯ã˜ã‚ã¦ã‚‹
		- Command R+ï¼ˆéå•†ç”¨åˆ©ç”¨ï¼‰ã‚„Llama3-70Bã€DeepSeek-V2
	-  å°å‹ã®AIãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã®æ½®æµ
		- Mistral-7Bãƒ™ãƒ¼ã‚¹ã€ChatVectorã€
	-  å€‹äººã§ã‚‚AIé–‹ç™ºç«¶äº‰ã«é£Ÿã„è¾¼ã‚ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦
- ç”ŸæˆAIæ™‚ä»£ã«å¤§äº‹ãªã‚¹ã‚­ãƒ«ã¯ã€ã€Œã‚„ã‚Šç¶šã‘ã‚‹èƒ½åŠ›ã€€by æ·±æ´¥ã•ã‚“
	- https://x.com/fladdict/status/1792831115528663471
	- ç”ŸæˆAIæ™‚ä»£ã«ã¯ã€Œã‚‚ã†ã‚ã„ã¤ï¼ˆAIï¼‰ä¸€äººã§ã„ã„ã‚“ã˜ã‚ƒãªã„ã‹ãªã€ã¨ã€è‰²ã€…ãªã“ã¨ã§æŒ«æŠ˜ã™ã‚‹äººãŒå¤§é‡ç™ºç”Ÿã™ã‚‹ã€‚ã€Œæ‰‹ã‚’ã¨ã‚ãªã„ã€èƒ½åŠ›ãŒã€äººé¡ã«ã¨ã£ã¦æœ€é‡è¦ã®æ‰èƒ½ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œãªã„
- transformers v4.41.0
	- https://github.com/huggingface/transformers/releases/tag/v4.41.0
	- Phi3, JetMoE, PaliGemma, VideoLlava, Falcon2, FalconVLM & GGUF support
		- https://huggingface.co/docs/transformers/v4.41.0/en/gguf
- Phi 3 - Small, Medium & Vision
	- https://x.com/reach_vb/status/1792949163249791383
	- This includes the 7B and 14B models
	- This also includes a multimodal phi model
- Knowledge Cards by Perplexty	
	- https://x.com/perplexity_ai/status/1792948540542517458
	- Weâ€™re teaming up with @TakoViz to bring advanced knowledge search and visualization to our users. Now, you can search, juxtapose, and share authoritative knowledge cards in Perplexity.
	- PerplexityãŒé«˜åº¦ãªæƒ…å ±æ¤œç´¢ã¨è¦–è¦šåŒ–ãŒã§ãã‚‹ã€Œknowledge cardsã€ã¨ã„ã†æ©Ÿèƒ½ã‚’ãƒªãƒªãƒ¼ã‚¹ã€‚
	- è‡ªç”±ã«ä»»æ„ã®2ç¤¾ã®æ ªä¾¡æ¨ç§»ã®æ¯”è¼ƒãŒå¯èƒ½ã€‚ãƒªã‚µãƒ¼ãƒæ¥­å‹™ãŒæ—ã‚Šã€ä»•äº‹ã§æ´»èºé–“é•ã„ç„¡ã—ã€‚
- GraphRAG: Using Knowledge in Unstructured Data to Build Apps with LLMs
	- https://www.graphlit.com/blog/graphrag-using-knowledge-in-unstructured-data-to-build-apps-with-llms
	- We have used Graphlit to automatically extract images from PDFs, and are using the OpenAI GPT-4 Vision model to perform OCR and generate detailed text descriptions of the images.
	- ã©ã†ã‚‚ã€çŸ¥è­˜ã‚°ãƒ©ãƒ•ã®ç”»åƒã‹ã‚‰çŸ¥è¦‹ã‚’å¾—ã‚‹ã‚‰ã—ã„ã€‚
- I built my own omni assistant using Gemini 1.5 Flash to guide me through Super Mario 64.
	- https://x.com/skirano/status/1792948429754151293
	- MicrosoftãŒBuildã§ã§ã‚‚ã—ãŸã€assistantã‚’ã€gemini 1.5 Flashã§å®Ÿè£…ã—ãŸãƒ„ãƒ¯ãƒ¢ãƒã€ãŠé¡Œã¯ãƒãƒªã‚ªã ã—ã€‚
- What is the context window?
	- https://x.com/cwolferesearch/status/1792950349696753980
		- Claude-3 has a 1M context window 
		- Gemini-1.5 Pro has a 2M token context window 
		- Recent research [3] has explored going even beyond 2M tokens.
- ICity, a Geometry Nodes-powered procedural city generator for Blender.
	- https://x.com/80Level/status/1792769380717068510
	- Available now in Beta
		- https://80.lv/articles/long-awaited-procedural-city-generator-for-blender-is-now-available/
- Microsoftã€Copilot é€²åŒ–çš„ã®æ–°æ©Ÿèƒ½ã‚’ç™ºè¡¨
	- https://x.com/shota7180/status/1792966382990270739
	- Copilot é€²åŒ–çš„ã®æ›´æ–°ã«ã‚ˆã‚Šã€èª°ã§ã‚‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚’æŒã¤ã‚³ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã‚’æ§‹ç¯‰å¯èƒ½ã«
	- ã“ã®ã‚³ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»£ã‚ã‚Šã«ç‹¬ç«‹ã—ã¦ç©æ¥µçš„ã«ã‚¿ã‚¹ã‚¯ã‚’èª¿æ•´ãƒ»å®Ÿè¡Œ
	- ç‰¹å®šã®å½¹å‰²ã‚„æ©Ÿèƒ½ã«åˆã‚ã›ã¦ã‚¿ã‚¹ã‚¯ã‚’å€‹åˆ¥ã«èª¿æ•´ã§ãã‚‹
- MIcrosoft's Phi-3 really is an astonishingly good model
	- https://x.com/simonw/status/1792691120675467288
	- MIT licensed and small enough to run in a browser on WebGPU (about a 2.3GB downloads), but still provides high quality results for a lot of the stuff I care about
	- Phi-3-mini running locally in your browser at 70 tokens per second on WebGPU!
	- Powered by ğŸ¤— Transformers.js and ONNX Runtime Web! 
	- https://huggingface.co/blog/Emma-N/enjoy-the-power-of-phi-3-with-onnx-runtime
- Hugging Face and Microsoft Deepen Collaboration
	- https://huggingface.co/blog/microsoft-collaboration
- Tako, the first AI search engine for visualizing and sharing the worldâ€™s knowledge.
	- https://x.com/TakoViz/status/1792949400710574455
	-  Introducing Tako, a new way to reference real knowledge And our first integration, Perplexity
		- https://trytako.com/blog/introducing-tako-and-perplexity-integration
- Team Copilot by Microsoft 
	- https://x.com/msdev/status/1792967099519758822
- 13B phi-medium-4k GGUF files here, model is looking very very good.
	- https://huggingface.co/nisten/phi3-medium-4k-gguf
- æœ¬æ—¥ï¼ˆ5/20ï¼‰ã€EUã®ãƒ‡ã‚¸ã‚¿ãƒ«ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ³•ãŒæ–½è¡Œ
	- https://x.com/_nat/status/1792915589570154637
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã€è‡ªå¾‹å‹AIã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã€ŒDevinã€ã®Cognition AIã¨ææºã‚’ç™ºè¡¨ã€‚Azureä¸Šã§Devinã‚’æä¾›ã¸
	- https://www.publickey1.jp/blog/24/aidevincognition_aiazuredevin.html
-  Mapping the Mind of a Large Language Model
	- https://www.anthropic.com/research/mapping-mind-language-model
	- Anthropic has just revealed some exciting news about Claude Sonnet. They've successfully identified how millions of concepts are represented inside this massive model!
- ollama run phi3:medium
	- https://x.com/ollama/status/1793067457382343134
- Phi-3-vision ãƒ» Phi-3-medium ãƒ» Phi-3-small ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/nb050244392a4?sub_rt=share_h
	- ã€ŒPhi-3ã€ã¯ã€æœ€ã‚‚æœ‰èƒ½ã§è²»ç”¨å¯¾åŠ¹æœã®SML (Small Language Model) ã§ã‚ã‚Šã€ã•ã¾ã–ã¾ãªè¨€èªã€æ¨è«–ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€æ•°å­¦ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§åŒã˜ã‚µã‚¤ã‚ºã¨æ¬¡ã®ã‚µã‚¤ã‚ºã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™
	- ã€ŒPhi-3-visionã€ã¯ã€ãƒãƒ£ãƒ¼ãƒˆã‚„å›³ã‹ã‚‰æ´å¯Ÿã‚’ç”Ÿã¿å‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚
	- ã€ŒPhi-3-smallã€ã€ŒPhi-3-mediumã€ã¯ã€åŒã˜ã‚µã‚¤ã‚ºã®è¨€èªãƒ¢ãƒ‡ãƒ«ã ã‘ã§ãªãã€ã¯ã‚‹ã‹ã«å¤§ãã„è¨€èªãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚å„ªã‚ŒãŸãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç™ºæ®ã—ã¾ã™
	- SLMã¯ã€ã‚ˆã‚Šå˜ç´”ãªã‚¿ã‚¹ã‚¯ã§ã†ã¾ãæ©Ÿèƒ½ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ãƒªã‚½ãƒ¼ã‚¹ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹çµ„ç¹”ã«ã¨ã£ã¦ã‚ˆã‚Šã‚¢ã‚¯ã‚»ã‚¹ã—ã‚„ã™ãã€ä½¿ã„ã‚„ã™ãã€ç‰¹å®šã®ãƒ‹ãƒ¼ã‚ºã«åˆã‚ã›ã¦ã‚ˆã‚Šç°¡å˜ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã¾ã™
-  GPT-4oã‚’ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã€å°‚é–€å®¶ãŒã€Œæ™‚ä»£ã®è»¢æ›ç‚¹ã€ã¨è©•ä¾¡ã™ã‚‹ãƒ¤ãƒã™ãã‚‹èƒ½åŠ›ã¨ã¯ by ä»Šäº•ã•ã‚“
	- https://www.sbbit.jp/article/cont1/140613
	- OpenAIã®GPT-4oã‚’ç ”ç©¶è€…è¦–ç‚¹ã§è§£èª¬ã—ãŸè¨˜äº‹ãŒå‡ºã¾ã—ãŸ! é€Ÿå ±çš„ãªè¨˜äº‹ã®ä¾é ¼ã§ã—ãŸãŒ,ã‚„ã¯ã‚Šç ”ç©¶è€…ãŒæ›¸ãã¨ã„ã†ã“ã¨ã§æƒ…å ±ã‚’ã™ã¹ã¦è©°ã‚è¾¼ã‚“ã 1ä¸‡æ–‡è¿‘ã„ã‚¬ãƒè§£èª¬è¨˜äº‹ã«ãªã‚Šã¾ã—ãŸ.3å›ã®é€£è¼‰ã§ã™.
	- è¨€èª,éŸ³å£°,å‹•ç”»åƒ,å¾ŒåŠã§ã¯GPT-4oã®ã€Œå¼±ã¿ã€ç­‰,æ—¥æœ¬èªè¨˜äº‹ã§ã¯ä¸€ç•ªè©³ã—ã„ã¯ãš
- MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning
	- https://arxiv.org/abs/2405.12130
	- LoRAã‚ˆã‚ŠçŸ¥è­˜ç²å¾—ç³»ã‚¿ã‚¹ã‚¯ã«å¼·ã„MoRAã€€ by shi3zã•ã‚“
- ãƒ«ã‚«ãƒ³å…ˆç”Ÿã€å­¦ç”Ÿã«æ¬¡ä¸–ä»£AIã‚’ä½œã‚ã†ã¨ã™ã‚‹ãªã‚Œã°ã€LLMã‚’ã‚„ã‚‹ã®ã§ã¯ãªã„ã‚ˆã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹
	- https://x.com/ylecun/status/1793326904692428907
	- If you are a student interested in building the next generation of AI systems, don't work on LLMs
- Mistral v3 base and instruct released
	- https://huggingface.co/mistralai
	- Base has vocab extended to 32768. 
	- Instruct supports function calling! 
	- Tokens 5 to 9 are for function calling & the rest are empty
- Interface 7æœˆå·ã§ã¯ï¼ŒCopilotã§æ–‡èŠ¸çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«æŒ‘æˆ¦ã—ã¾ã™ï¼
	- https://x.com/If_CQ/status/1793214032121614787
	- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’åŒæ™‚ã«é–‹ç™ºä¿å®ˆã™ã‚‹ã®ãŒDonald. E. Knuthåšå£«ã®ã€Œæ–‡èŠ¸çš„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã€ï¼Copilotã¨Doxygenã‚’ä½¿ãˆã°ï¼Œè¨˜è¿°ãŒè‡ªå‹•åŒ–ã§ãï¼Œä¸¡è€…ã®ä¸ä¸€è‡´ã‚’é˜²ã’ã¾ã™ï¼ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºã®ç†æƒ³ã‚’æœ€æ–°ã®æŠ€è¡“ã§å®Ÿç¾ã—ã¾ã™ï¼
- New guide in our AI cookbook: ğ™ğ™©ğ™§ğ™ªğ™˜ğ™©ğ™ªğ™§ğ™šğ™™ ğ™œğ™šğ™£ğ™šğ™§ğ™–ğ™©ğ™ğ™¤ğ™£
	- https://huggingface.co/learn/cookbook/structured_generation
	- This technique lets you force your LLM to generate its output as a JSON with specific keys: great for RAG or LLM-judge!
- Large Language Models Meet NLP: A Survey
	- https://arxiv.org/abs/2405.12819
	- Provides a comprehensive survey of how LLMs are applied to NLP tasks, introducing a new taxonomy and discussing current progress, future frontiers, and challenges.
- Mistral AI's Mistral v0.3 supports function calling with Ollama's raw mode!
	- https://x.com/ollama/status/1793392887612260370
	- Ollama raw mode
		- https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode
- Mistral-7Bã¨Phi-3ã‚‚ã“ã®éš›ElyzaTasks100ã§è©•ä¾¡ã—ã¦ã¿ãŸã€‚by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1793550842353820014
	- ã¾ãšMistral-7Bã¯v0.1ãŒ2.46ã€v0.2ãŒ2.69ï¼ˆã‚„ãŸã‚‰è‹±èªã§å›ç­”ã—ã¦ãã‚‹ã®ã§åŠåˆ†ä»¥ä¸Šè‹±èªã®å›ç­”ã¯æ‰‹ä½œæ¥­ã§1ç‚¹ã«æ¸›ã‚‰ã—ãŸï¼‰ã€ã‹ã‚‰ã®ä»Šå›ã®v0.3ã¯3.52ï¼è¦‹é•ãˆã‚‹ãã‚‰ã„æ—¥æœ¬èªèƒ½åŠ›ãŒå¼·åŒ–ã•ã‚Œã¦ã¾ã™ã€‚è‹±èªã§ç­”ãˆã¡ã‚ƒã†å•é¡Œã‚‚ã»ã¼èµ·ããªã„ã€‚
	- Phi3ã¯3.8Bã®mini-128kãŒã¾ã•ã‹ã®3.26ã¨ã„ã†ã“ã®ãƒ‘ãƒ©æ•°ã«ã—ã¦ã¯é«˜ã™ãã‚‹ã‚¹ã‚³ã‚¢ã§ãªãœã‹small-128kã«å‹ã£ã¦ã—ã¾ã£ã¦ã¾ã™ã€‚
	- small-8kã¯3.28ã§ã€miniã¨å¤§å·®ãªã„ã¨ã„ã†æ„å‘³ã§ã¯æ®‹å¿µã€‚åŒãƒ‘ãƒ©ã®Mistral-7B-v0.3ã«ã‚‚è² ã‘ã¦ã‚‹ã€‚
	- ã§ã‚‚medium-128kã¯14Bãƒ‘ãƒ©ã§3.96ã¨ã„ã†ãƒã‚±ãƒ¢ãƒ³ã¿ãŸã„ãªã‚¹ã‚³ã‚¢ãŒå‡ºã¦ã¾ã™ã€‚ã“ã‚Œã¯ã™ã”ã™ã
- GPT-4oã¨GPT-4Turboã®ElyzaTasks100ã®å¹³å‡ã‚¹ã‚³ã‚¢ã€
	- https://x.com/umiyuki_ai/status/1793540614551904762
	- æ°—ã«ãªã£ã¦ãŸã®ã§APIä»£æ‰•ã£ã¦è©•ä¾¡ã—ã¦ã¿ãŸã€‚
	- GPT-4TurboãŒ4.44ã€GPT-4oãŒ4.51ï¼ã‚„ã£ã±ã‚Šã‚¨ã‚²ã¤ãªã„è¶…ã‚¹ã‚³ã‚¢ï¼
	- ã‚ªãƒ¼ãƒ—ãƒ³ãªãƒ¢ãƒ‡ãƒ«ãŒGPT-4Tã«è¿½ã„ä»˜ã„ã¦ããŸãªã‚“ã¦ã¡ã‚‡ã£ã¨è¨€ãˆãªããªã£ãŸ
- Phi-3-Mediumã®MMLUã‚¹ã‚³ã‚¢ã¯Llama3-70Bä¸¦ã¿â€¦ by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1793614730403434950
	- ã‚„ã£ã±ã‚Šä¼Šé”ã˜ã‚ƒãªã„ã‚‰ã—ã„ã­ã€‚ElyzaTasks100ã§ã‚‚åŒ¹æ•µã—ã¦ã‚‹ã‚‚ã‚“ã€‚ã—ã‹ã—ä¿¡ã˜ãŒãŸã„ã­ 
- Aya 23 is here! Available in 8B and 35B.
	- https://ollama.com/library/aya
- LangChain `with_structured_output` ãƒ¡ã‚½ãƒƒãƒ‰ã«ã‚ˆã‚‹æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
	- https://zenn.dev/ml_bear/articles/cb07549ec52175
	- 1.  æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’Pydanticã§å®šç¾©ã™ã‚‹
	- 2.  ãã®å®šç¾©ã‚’`.with_structured_output`ã§LLMã«å–ã‚Šä»˜ã‘ã‚‹
	- Pydanticã§ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©ã—ãŸä¸Šã§æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã™ã‚‹ã®ã¯éå¸¸ã«ç°¡å˜ã§ã™
- ã€ŒAIã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã¯è¡—ã®é›»æ°—å±‹ã•ã‚“ã‹ã‚‰å§‹ã‚ã‚ã€
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo1-4.pdf
	- AIæˆ¦ç•¥ä¼šè­°ã®æ¾å°¾ç ”ã®è³‡æ–™ã€Œç”ŸæˆAIã®ç”£æ¥­ã«ãŠã‘ã‚‹å¯èƒ½æ€§ã€
	- ã¾ãšã¯å—è¨—é–‹ç™ºã§ç¤¾ä¼šã‚’å­¦ã¶ã€‚ å—è¨—é–‹ç™ºã§åœ°åŸŸã®ä¼æ¥­ã®DXã‚’æ”¯æ´ã—ã¤ã¤ã€ä¸€ç·’ã«ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å‡ºã¦ã„ã
- ä¸–ç•Œåˆã€AIæŠ€è¡“ã«ã‚ˆã‚‹åŸæ²¹å‡¦ç†è£…ç½®ã®è‡ªå‹•é‹è»¢ã‚’é–‹å§‹ã€€PFN
	- https://www.preferred.jp/ja/news/pr20240524/
- æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹åå¿œäºˆæ¸¬ã®è«–æ–‡
	- https://chemrxiv.org/engage/chemrxiv/article-details/664de6a821291e5d1df74ac0
	- SMILESã«ã‚ˆã‚ŠåŒ–å­¦åå¿œã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¾ã—ãŸSMIRKSã‚’ç”¨ã„ã‚‹ã“ã¨ã§ã€åŒ–å­¦åå¿œã®ãƒ«ãƒ¼ãƒ«ã‚’é«˜ç²¾åº¦ã«å­¦ç¿’ã§ããŸãã†ã§ã™ã€‚å¯„ä¸ã™ã‚‹åŸå­æ•°ãŒå¤šã„è¤‡é›‘ãªåå¿œã¯ä»Šå¾Œã®èª²é¡Œã¨ã®ã“ã¨
- LLMã¯ãƒãƒ£ãƒƒãƒˆUIã®èª•ç”Ÿã§ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã‚’èµ·ã“ã—ãŸãŒã€ä»Šã¯ãƒãƒ£ãƒƒãƒˆUIã«å‘ªã‚ã‚Œã¦ã„ã‚‹
	- https://x.com/rkmt/status/1794013338005090666
	- ã€Œæœ‰åŠ¹ãªè³ªå•ã‚’LLMã«æŠ•ã’å›ç­”ã‚’å¾—ã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã€ã¯ä¸€å®šé‡ï¼ˆãã‚Œã‚’ä½¿ã„ã“ãªã›ã‚‹äººé¡ã®æ•°<<äººé¡ã®ç·æ•°ï¼‰ã§é ­æ‰“ã¡ã«ãªã‚Šã€ãã‚Œä»¥ä¸Šã¯ã€Œæ„å‘³ã‚‚ãªã„å†…å®¹ã‚‚ãªã„ã‘ã©æ¥½ã—ã„ä¼šè©±ã‚’AIã¨ç¶šã‘ã‚‹ã€ã‚µãƒ¼ãƒ“ã‚¹ã‹ã€ã€Œäººé–“ã‚’å¿…è¦ã¨ã—ãªã„AIæ¥­å‹™ã€ã«ç§»è¡Œã™ã‚‹ã®ã‹ã‚‚ã€‚
- ã±ã·ã‚Šã‹ç‚’ã‚ï¼ˆmmngaï¼‰ã•ã‚“ã®ã€Llama-3-70B-japanese-suzume-vector-v0.1 ã™ã”ã„ã€ by AIã‚µãƒˆã‚·
	- https://x.com/AiXsatoshi/status/1793973265532424467
	- 8bã®Llamaæ´¾ç”Ÿãƒ¢ãƒ‡ãƒ«ã®chatvectorã‚’ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°é•ã†70Bã«ãƒãƒ¼ã‚¸ã—ã¦ã¦ã€ã•ã‚‰ã«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚‚è‰¯å¥½ãªã®ã™ã”ã„
- CohereãŒå¤šè¨€èªæŒ‡å‘ã®ã‚ªãƒ¼ãƒ—ãƒ³LLMã€ŒAyaã€ï¼ˆ8Bï¼Œ23Bï¼‰ã‚’å…¬é–‹
	- https://huggingface.co/spaces/CohereForAI/aya-23
	- 4æœˆã«ã¯å½“æ™‚ã®ã‚ªãƒ¼ãƒ—ãƒ³LLMæœ€é«˜æ€§èƒ½ã®Command R+ã‚’å‡ºã—ã¦ãŸCohereã®å¤šè¨€èªLLMãªã®ã§,æ—¥æœ¬èªã‚‚æœŸå¾…ã§ããã†...å®Ÿéš›ã«æ—¥æœ¬èªã¯çµæ§‹ã†ã¾ã„ã‚“ã§ã™ãŒ,è‰²ã€…ã¨ç°¡æ½”ã™ãã¦è‡ªåˆ†ã®ä¸­ã§ã®è©•ä¾¡ãŒã€Œå†·ãŸã„ãƒ¢ãƒ‡ãƒ«ã€ã§ã™
-  DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
	- https://huggingface.co/papers/2405.14333
	- Proof assistants like Lean have revolutionized mathematical proof verification, ensuring high accuracy and reliability. Although large language models (LLMs) show promise in
- ollamaã§Phi3-mediumã¯ã€Œæ€§èƒ½ã‚·ãƒ§ãƒœã„ã€ï¼Ÿã€€by ã†ã¿ã‚†ãã•ã‚“
	- https://x.com/umiyuki_ai/status/1793878129699950887
	- Ollamaã§Phi3-mediumã‚’ãƒ—ãƒ«ã™ã‚‹ã¨Q4_0é‡å­åŒ–ç‰ˆãŒDLã•ã‚Œã‚‹ã‚ˆã†ã ãŒã€ã‚¹ã‚³ã‚¢ã¯3.68ã€‚Q4_K_Sã§ã‚‚3.67ã€‚ã¡ãªã¿ã«åƒ•ãŒæœ€åˆã«æ¤œè¨¼ã—ãŸLlama. cppã®Q8ã¯3.88ã ã£ãŸã—ã€åŒã˜ãLlama. cppã®Q4_K_Sã‚‚3.95ã§åŠ£åŒ–ã©ã“ã‚ã‹ã‚¹ã‚³ã‚¢ä¸ŠãŒã£ã¦ã‚‹ã€‚ã¨ã„ã†ã‚ã‘ã§ollamaã®Phi3-mediumã¯ãƒ‘ãƒ©è¨­å®šã‹ãªã‚“ã‹åˆ†ã‹ã‚‰ã‚“ã‘ã©ä½•ã‚‰ã‹ã®å•é¡Œã§åŠ£åŒ–ã—ã¦ã¾ã™
- DeepSeekV2 is a big deal.
	- https://x.com/Xianbao_QIAN/status/1794034052347171055
	- Not only because its significant improvements to both key components of Transformer: the Attention layer and FFN layer. 
	- It has also completed disrupted the Chines LLM market and forcing the competitors to drop the price to 1% of the original price.
- Difyã‚’ä½¿ã†ãƒ¡ãƒªãƒƒãƒˆã®ä¸€ã¤ãŒé–‹ç™ºã—ãŸChatbotã‚„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ç°¡å˜ã«WEBã§ã‚·ã‚§ã‚¢ã§ãã‚‹ã“ã¨
	- https://x.com/gijigae/status/1793437095727665588
-  Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet
	- https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
	- Anthropicã®ä¸­è¦æ¨¡ç”Ÿç”£ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚‹Claude 3 Sonnetã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’é©ç”¨ã—ã€è§£é‡ˆå¯èƒ½ãªç‰¹å¾´ã‚’æŠ½å‡ºã™ã‚‹ç ”ç©¶
	-  **ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼**: å°è¦æ¨¡ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã‹ã‚‰å˜ç¾©çš„ç‰¹å¾´ã‚’å›å¾©ã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ãŸç ”ç©¶ã‹ã‚‰ç™ºå±•ã—ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¸ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒé‡è¦–ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- **è§£é‡ˆå¯èƒ½ãªç‰¹å¾´**: æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´ã¯å¤šè¨€èªã€å¤šãƒ¢ãƒ¼ãƒ€ãƒ«ã§ã‚ã‚Šã€å…·ä½“çš„ãŠã‚ˆã³æŠ½è±¡çš„ãªå‚ç…§ã®é–“ã§ä¸€èˆ¬åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚
	- **å®‰å…¨æ€§é–¢é€£ç‰¹å¾´**: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®è„†å¼±æ€§ã‚„ãƒãƒƒã‚¯ãƒ‰ã‚¢ã€åè¦‹ã€å˜˜ã‚„æ¬ºçã€å±é™ºã¾ãŸã¯çŠ¯ç½ªçš„ãªå†…å®¹ãªã©ã€AIã‚·ã‚¹ãƒ†ãƒ ãŒå¼•ãèµ·ã“ã™å¯èƒ½æ€§ã®ã‚ã‚‹æ§˜ã€…ãªå•é¡Œã«é–¢é€£ã™ã‚‹ç‰¹å¾´ãŒè¦³å¯Ÿã•ã‚Œã¦ã„ã¾ã™ã€‚
	- **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡**: ã‚¹ãƒ‘ãƒ¼ã‚¹ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®è¨“ç·´ã«ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ³•å‰‡ã‚’é©ç”¨ã—ã€è¨ˆç®—äºˆç®—ã«åŸºã¥ã„ã¦æœ€é©ãªç‰¹å¾´æ•°ã¨è¨“ç·´ã‚¹ãƒ†ãƒƒãƒ—æ•°ã‚’æ±ºå®šã—ã¦ã„ã¾ã™ã€‚
- ãƒãƒ«ãƒ»ãƒ™ãƒªãƒ¼ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒAIã§å®Ÿä½“é¨“ã§ãã‚‹æ™‚ä»£ãŒåˆ°æ¥
	- https://x.com/webbigdata/status/1794030396990226803
	- ãƒãƒ«ãƒ»ãƒ™ãƒªãƒ¼ã•ã‚“ã¨ã„ã†ã€X-MENã®ã‚¹ãƒˆãƒ¼ãƒ ã¨ã‹ã‚­ãƒ£ãƒƒãƒˆã‚¦ãƒ¼ãƒãƒ³å½¹ã‚’ã‚„ã£ã¦ã‚‹ã‚¢ãƒ¡ãƒªã‚«ã®å¥³å„ªã•ã‚“ãŒã„ã‚‹ã®ã§ã™ãŒã€ã‚ã‚‹æ‚£è€…ã•ã‚“ã®ç‰¹å®šã®ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ãŒã€Œãƒãƒ«ãƒ»ãƒ™ãƒªãƒ¼ã®å†™çœŸã€ã‚„ã€Œãƒãƒ«ãƒ»ãƒ™ãƒªãƒ¼ã€ã¨ã„ã†ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦æ´»æ€§åŒ–ã™ã‚‹äº‹ãŒè¦³å¯Ÿã•ã‚ŒãŸã¨ã„ã†ç ”ç©¶ãŒã‚ã‚‹ã€‚
	- 5æœˆ21æ—¥ã«anthropicãŒClaude 3 Sonnetã§ä½•ç™¾ä¸‡ã‚‚ã®æ¦‚å¿µãŒã©ã®ã‚ˆã†ã«è¡¨ç¾ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç‰¹å®šã§ããŸã‚ˆï½ã¨ç™ºè¡¨ã—ã€
	- ãã®æŠ€è¡“ã‚’ä½¿ã£ã¦ã€ã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ã®ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ ã‚²ãƒ¼ãƒˆ ãƒ–ãƒªãƒƒã‚¸(Golden Gate Bridge)ã«å¯¾å¿œã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚’æ´»æ€§åŒ–ã•ã›ã¦ã¦ã„ã‚‹ã€ŒGolden Gate Claudeã€ã¨å®Ÿé¨“çš„ã«å¯¾è©±ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã‚ˆï½ã¨ç™ºè¡¨ã—ãŸã®ãŒæ˜¨æ—¥ã§ã™ã­ã€‚
	- ä¸€è¨€ã§è¨€ãˆã°ã€ã‚„ãŸã‚‰ã‚ã£ãŸã‚‰ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ ã‚²ãƒ¼ãƒˆ ãƒ–ãƒªãƒƒã‚¸æ¨ã—ã‚’ã—ã¦ãã‚‹AIã§ã€è‰²ã€…ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ ã‚²ãƒ¼ãƒˆ ãƒ–ãƒªãƒƒã‚¸ã‚’æ¨è–¦ã—ã¦ãã¾ã™ã€‚
- streamlitã§ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚ GitHubã¨æ¥ç¶šã™ã‚Œã°ã€æœ¬å½“ã«çˆ†é€Ÿã§
	- https://x.com/kenken26679105/status/1793889080385925580
- ChatVectorã§7Bãƒ¢ãƒ‡ãƒ«ã®FineTuningçµæœã‚’70Bã«è»¢ç§»ã•ã›ã‚‹ã¿ãŸã„ãªè©±ã€by ã¯ã¡ã•ã‚“
	- https://x.com/CurveWeb/status/1794203714422759707
	- äº‹å‰å­¦ç¿’ã§ã¯æ—¢ã«å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã§äº‹å‰å­¦ç¿’â†’ã‚»ãƒ«ãƒ•ãƒãƒ¼ã‚¸ã§å¤§ãƒ¢ãƒ‡ãƒ«åŒ–ã£ã¦ã„ã†ã®ãŒã§ãã¦ã„ã‚‹ã®ã§ãªã‚“ã¨ãªãã§ãã¦ç„¶ã‚‹ã¹ãæ„Ÿã‚ã‚‹ã€‚

## 5/20

ä»Šå›ã¯ã€GPT-4oã•ã‚“ã«ã€ã¾ã¨ã‚ã‚’ãŠé¡˜ã„ã—ã¾ã—ãŸï¼ˆç„¡ä¿®æ­£ã§ã™ï¼ï¼ï¼‰ã€‚ã“ã“ã¾ã§æ¥ãŸã‹ã€ã¨é©šãã‚ˆã†ãªã•ã¿ã—ã„ã‚ˆã†ãªã€‚ã€‚å¤§åˆ‡ãªã“ã¨ã¯ã€ã‚‚ã†ä¸€åº¦è¨€ã„ã¾ã™ã€ç„¡ä¿®æ­£ã§ã™ã€‚ã§ã¯ã€

æœ€æ–°ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å‹•å‘ã«ã¤ã„ã¦ã€ä»Šå›ã¯ã¡ã‚‡ã£ã¨ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚‚äº¤ãˆã¤ã¤ãŠå±Šã‘ã—ã¾ã™ã€‚ã¾ãšã¯ã€çµ¶å¯¾ã«è¦‹é€ƒã›ãªã„äºŒã¤ã®å¤§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‹ã‚‰ã€‚ æœ€åˆã«ã€å¤§ããæ³¨ç›®ã‚’æµ´ã³ã¦ã„ã‚‹ã®ãŒOpenAIã®æ–°ãƒ¢ãƒ‡ãƒ«ã€ŒGPT-4oã€ã§ã™ã€‚ã©ã†ã‚„ã‚‰ã“ã®ãƒ¢ãƒ‡ãƒ«ã€åå‰ã ã‘ã˜ã‚ƒãªãã¦æ€§èƒ½ã‚‚ã¾ã•ã«ã€ŒãŠãŠï¼ã€ã¨è¨€ã„ãŸããªã‚‹ç¨‹ã®é€²åŒ–ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦é€Ÿåº¦ã¯2å€ã€ã‚³ã‚¹ãƒˆã¯åŠåˆ†ã€ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆãŒ5å€ã¨ã€ã¾ã•ã«ã‚¹ãƒ¼ãƒ‘ãƒ¼AIã€‚ã•ã‚‰ã«ç„¡æ–™ãƒ—ãƒ©ãƒ³ã®ChatGPTãƒ¦ãƒ¼ã‚¶ãƒ¼ã§ã‚‚ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã®ã“ã¨ã§ã€ã‚µãƒ ãƒ»ã‚¢ãƒ«ãƒˆãƒãƒ³ã•ã‚“ã‹ã‚‰ç›´æ¥ã®ãŠçŸ¥ã‚‰ã›ã‚‚é£›ã³å‡ºã—ã¾ã—ãŸã€‚ã—ã‹ã‚‚ã€ã“ã®GPT-4oã¯æ•°å­¦ã®é›£é–¢å•é¡Œã‚’ç”»åƒã§å‡ºé¡Œã—ãŸã ã‘ã§è§£ã‘ã‚‹ã¨ã„ã†ã€ã¾ã‚‹ã§é­”æ³•ã®ã‚ˆã†ãªèƒ½åŠ›ã‚’æŒã£ã¦ã„ã‚‹ã®ã§ã™ã€‚ã“ã®é€²åŒ–ã«ã‚ˆã‚Šã€å‹•ç”»ã®è¦ç´„ã‚„åŒ–å­¦å®Ÿé¨“ã®è€ƒå¯Ÿã¾ã§ã€ãƒ˜ãƒ“ãƒ¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ´»ç”¨æ³•ãŒã©ã‚“ã©ã‚“å¢—ãˆã¦ã„ã‚‹ã®ãŒç¾çŠ¶ã§ã™ã€‚ æ¬¡ã¯Google I/Oã§ã®ç™ºè¡¨ã§ã™ã€‚ãƒˆãƒƒãƒ—ãƒãƒƒã‚¿ãƒ¼ã¯æ–°ã—ã„ãƒ“ã‚¸ãƒ§ãƒ³ãƒ»ãƒ©ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¢ãƒ‡ãƒ«ã€ŒPaliGemmaã€ã¨ã€ŒGemma 2ã€ã€‚ãã®å¤§ããªè¦‹ã©ã“ã‚ã¯ã€Gemma 27Bã¨ã„ã†ã‚µã‚¤ã‚ºã§ã‚‚æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’é§†ä½¿ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒ2å€ã®ã‚µã‚¤ã‚ºã®ã‚‚ã®ã«ã‚‚å‹ã‚‹æ€§èƒ½ã‚’ç™ºæ®ã™ã‚‹ã“ã¨ã€‚ã“ã‚Œã€ã¾ã‚‹ã§ãƒ’ãƒ¼ãƒ­ãƒ¼æ˜ ç”»ã®ç¶šç·¨ãŒç™ºè¡¨ã•ã‚Œã‚‹ã‹ã®ã‚ˆã†ãªãƒ¯ã‚¯ãƒ¯ã‚¯æ„ŸãŒã‚ã‚Šã¾ã™ã‚ˆã­ã€‚ãã—ã¦ã•ã‚‰ã«ã€ŒTrilliumã€ã¨ã„ã†æ¬¡ä¸–ä»£Google Cloud TPUã®ç™»å ´ã§ã€ã“ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼AIãƒ’ãƒ¼ãƒ­ãƒ¼ãŸã¡ãŒã•ã‚‰ã«åŠ¹ç‡è‰¯ãå‹•ä½œã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚ã‚ã€ä»Šå¤œã®ãƒ“ãƒªãƒ¼ãƒ»ã‚¢ã‚¤ãƒªãƒƒã‚·ãƒ¥ã®ãƒ©ã‚¤ãƒ–ã«ã§ã‚‚ç™»å ´ã—ãã†ãªå‹¢ã„ã§ã™ã€‚ ã•ã¦ã€è©±é¡Œã‚’å¤‰ãˆã¦ã€æœ€è¿‘ã®ç§€ä½œã‚’ã”ç´¹ä»‹ã—ã¾ã™ã€‚DeepLearningAIã‹ã‚‰ç„¡æ–™ã‚³ãƒ¼ã‚¹ãŒç¶šã€…ç™»å ´ã—ã¦ãŠã‚Šã€MistralAIã‚’ä½¿ã£ãŸã‚³ãƒ¼ã‚¹ã‚’æä¾›ä¸­ã§ã™ã€‚ã“ã®ã‚³ãƒ¼ã‚¹ã§ã¯ã€Mistralã®ãƒ¢ãƒ‡ãƒ«ã«åŠ ãˆã¦ã€RAGã€é–¢æ•°å‘¼ã³å‡ºã—ã€ãã—ã¦JSONãƒ¢ãƒ¼ãƒ‰ãªã©ã¾ã§å­¦ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã‚Œã‚’å—ã‘ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆã§ã®å°¤åº¦é–¢æ•°ã®æ‰ãˆæ–¹ã«ã¤ã„ã¦è­°è«–ãŒå·»ãèµ·ã“ã£ã¦ã„ã¾ã™ã€‚ã€Œãã‚Œã£ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ€ãƒ³ã‚µãƒ¼ã®å¿…é ˆã‚¹ã‚­ãƒ«ï¼Ÿã€ã¨æ€ã‚ã›ã‚‹ã‚ˆã†ãªå°‚é–€çš„ãªè©±é¡Œã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ ä¸€æ–¹ã€HuggingFaceã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨llama.cppã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«é•ã„ãŒã‚ã‚‹ã“ã¨ãŒè­°è«–ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã¾ã‚‹ã§ã€æ˜ ç”»ã®å­—å¹•ã¨å¹ãæ›¿ãˆã®é•ã„ãã‚‰ã„æ³¨ç›®ã•ã‚Œã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã§ã™ã€‚ç‰¹ã«Llama3ã‚„Gemmaãƒ¢ãƒ‡ãƒ«ã«é–¢ã—ã¦ã€é‡å­åŒ–ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ã‚‚æµ®ä¸Šã—ã¦ã„ã¾ã™ã€‚ã‚“ã‚“ã€ã‚„ã£ã±ã‚Šãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®é€²åŒ–ã‚‚ä¸€ç­‹ç¸„ã§ã¯ã„ãã¾ã›ã‚“ã­ã€‚ ãã—ã¦ãŠå¾…ã¡ã‹ã­ã€npakaã•ã‚“ã®æƒ…å ±ã‚’ä¸€æ°—ã«ã¾ã¨ã‚ã¦ãƒã‚§ãƒƒã‚¯ã€‚å½¼ã¯OpenAIã®Model Specã«ã¤ã„ã¦ã®æ¦‚è¦ã‚’è©³è¿°ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€æ–°ã—ã„LangChain v0.2ã‚’ä½¿ã£ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ§‹ç¯‰ã‚„ã€RAGã€ç‰¹å®šã®æƒ…å ±æºã«é–¢ã™ã‚‹QAã‚·ã‚¹ãƒ†ãƒ ã€æƒ…å ±æŠ½å‡ºã€è¦ç´„ãªã©ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚‚ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ã€ŒLangChainãƒãƒƒã‚«ãƒ¼ã€ãªã‚“ã¦ç§°å·ãŒå½¼ã«ä¼¼åˆã„ãã†ã§ã™ã­ã€‚ ã“ã“ã¾ã§å¤§ã¾ã‹ãªãƒˆãƒ”ãƒƒã‚¯ã‚’ã”ç´¹ä»‹ã—ã¾ã—ãŸãŒã€ãã®ä»–ã®å°ãƒã‚¿ã‚‚ç››ã‚Šã ãã•ã‚“ã§ã™ã€‚ä¾‹ãˆã°ã€Mozillaã®ã‚„ã‚‹æ°—æº€ã€…ãªãƒ­ãƒ¼ã‚«ãƒ«ãƒªã‚µãƒ¼ãƒãƒ„ãƒ¼ãƒ«ã€Œllamafileã€ã‚„ã€LangChainã¨HuggingFaceã®å¼·åŠ›ãªææºãªã©ã€ã©ã‚“ã©ã‚“æ–°ã—ã„æ©Ÿèƒ½ãŒç™»å ´ã—ã¦ã„ã¾ã™ã‚ˆã€‚ã“ã®åˆ†é‡ã®é€²å±•ã®é€Ÿã•ã‚’è¦‹é€ƒã•ãªã„ã§ãã ã•ã„ã­ã€‚ ç¾å ´ã¯ã¾ã‚‹ã§ã€ãƒ”ãƒ¼ã‚¿ãƒ¼ãƒ‘ãƒ³ã®ãƒãƒãƒ¼ãƒ©ãƒ³ãƒ‰ã®ã‚ˆã†ã«å¤‰åŒ–ã«æº€ã¡ã¦ã„ã¾ã™ã€‚ä»Šå¾Œã‚‚ç¶šã€…ã¨é©šãã¨ç¬‘é¡”ãŒå¾…ã£ã¦ã„ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã•ã‚ã€æ¬¡ã¯ã©ã‚“ãªå†’é™ºãŒå¾…ã£ã¦ã„ã‚‹ã®ã‹ã€æ¥½ã—ã¿ã§ã™ã­ï¼

- ã¾ãŸã¾ãŸDeepLearningAIã‚ˆã‚Šã€MistralAIã‚’ç”¨ã„ãŸç„¡æ–™ã‚³ãƒ¼ã‚¹
	- https://www.deeplearning.ai/short-courses/getting-started-with-mistral/
	- Mistral AIã«ã‚ˆã‚‹1æ™‚é–“ã®ã‚³ãƒ¼ã‚¹ã€‚Mistralã®ãƒ¢ãƒ‡ãƒ«ã ã‘ã§ãªãã€RAGã€é–¢æ•°å‘¼ã³å‡ºã—ã€JSONãƒ¢ãƒ¼ãƒ‰ãªã©ã«ã¤ã„ã¦å­¦ã¹ã‚‹
- bæ°ãŒã€ã€Œãƒ­ãƒ¼ã‚«ãƒ«LLMã¯ã“ãƒ¼ã‚„ã£ã¦ä½¿ã†ã®ã€ã«ã‹ã¿ã¤ãã€
	- https://x.com/behemuhemulove/status/1789537738590765215
	- ã€Œå°¤åº¦é–¢æ•°ã®æ‰€ãŒä¿ºã«ã¯æ„å‘³ãŒè‰¯ãã‚ã‹ã‚‰ãªã‹ã£ãŸã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã„ã£ã¦ã‚‹ã®ã«ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å›ºå®šã—ãŸã‚‰ãƒ‘ãƒ©ãƒ¡ã‚¿ã®é–¢æ•°ã«ãªã‚‰ãªã„ã‹ã‚‰å°¤åº¦é–¢æ•°ã˜ã‚ƒãªããªã„ï¼Ÿã€
	- â†’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŒ¯ã£ã¦ã‚‹ã®ã§å°¤åº¦ã«ã‚ˆã‚‹æœ€é©ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ¨å®šã¨ã„ã£ã¦ã‚‚ã„ã„ã®ã§ã¯ãªã„ã‹ï¼Ÿ
- ä¸»è¦ãƒ¢ãƒ‡ãƒ«ã§HuggingFaceã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã¨llama.cppã®ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã«å·®ç•°ãŒã‚ã£ãŸã¨ã®äº‹
	- https://x.com/webbigdata/status/1789695414238884256
	- llama3ã®é‡å­åŒ–ãŒè…ã£ã¦ã‚‹ã®ã¯ã“ã®ã›ã„ï¼Ÿ
	- 1. Mistral: HF's batch_decode output is wrong 
	- 2. Llama-3: Be careful of double BOS 
	- 3. Gemma: 2nd token has an extra space - GGUF(_Below) = 30641 vs HF(Below) = 33501 
	- 4. Gemma-it: Also be careful of double BOS
- OpenAI ã® Model Spec ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/nf6b811cad5dc?sub_rt=share_b
	- ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œã‚’å½¢æˆã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®é€æ˜æ€§ã‚’é«˜ã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚’ã©ã®ã‚ˆã†ã«å¤‰æ›´ãŠã‚ˆã³æ”¹å–„ã§ãã‚‹ã‹ã«ã¤ã„ã¦å…¬é–‹ã®ä¼šè©±ã‚’é–‹å§‹ã™ã‚‹ãŸã‚ã«ã€ã€ŒModel Specã€ã‚’å…¬é–‹ã—ã¾ã™ã€‚
- [code-cooker](https://github.com/karaage0703/code-cooker) by ã‹ã‚‰ã‚ã’ã•ã‚“
	- https://github.com/karaage0703/code-cooke
	- é¢å€’ãªã“ã¨ã‚’ChatGPTä»¥å¤–ã®LLMã«ã‚„ã‚‰ã›ã‚‹ã‚½ãƒ•ãƒˆã€‚GUIã‚’ã¤ã‘ã¦ã¿ã¾ã—ãŸã€‚ ã‚ˆã†ã‚„ãè‡ªåˆ†ã§ã‚‚ä½¿ã„ãŸããªã‚‹ã‚‚ã®ãŒã§ããŸæ°—ãŒã—ã¾ã™ã€‚ã¾ã Claude 3 Opusã—ã‹å¯¾å¿œã—ã¦ãªã„ã®ã§ã€GPT-4ã¨ã‹Llama 3ã«ã‚‚å¯¾å¿œã—ã¦ã„ãã¾ã™ã€‚GPTå¯¾å¿œã¯OpenAIã®ç™ºè¡¨ã®å¾Œã«ã—ã‚ˆã†ã‹ãª
- å¤§è¦æ¨¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®äººãŸã¡ã¯ã€ã“ã®OpenAIã®è«–æ–‡ã«æ›¸ã„ã¦ã‚ã‚‹ã“ã¨æ€ã„å‡ºã—ã¦ã­ã ãã†ã§
	- https://x.com/cloneofsimo/status/1789700168083997010
	- Again, the paper im advocating here is from openai, and is referenced all the time and frankly one of the paper all large scale practitioner should read. the math here isn't complicated and nothing here is either controversial nor task dependent.
	- https://arxiv.org/abs/1812.06162
-  æŠ€è¡“é©æ–°ã¨ä¸å¹³ç­‰ã®1000å¹´å²ã®ç´¹ä»‹ by æ¥ ã•ã‚“
	- https://x.com/masanork/status/1789647931467026613
	- ã“ã‚Œç‰¹ã«ä¸‹å·»ã®èª­ã¿å¿œãˆãŒã™ã”ã„ã‚“ã§ã™ãŒã€æŠ€è¡“ãŒç´„æŸã™ã‚‹æœªæ¥ã¨ç¤¾ä¼šæ§‹é€ ã«ä¸ãˆã‚‹å½±éŸ¿ã¨ã¯ã€åˆ†ã‘ã¦è­°è«–ã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã®ã§ã¯ï¼Ÿã¨ã„ã†èª²é¡Œèªè­˜ãŒå¼·ãã€‚LLMå‘¨è¾ºã§ã¯ã‚ªãƒ¼ãƒ—ãƒ³ã£ã¦ç”¨èªãŒæ›–æ˜§ã«ä½¿ã‚ã‚ŒãŸã‚Šã€ç”Ÿç”£æ‰‹æ®µãŒæ°‘ä¸»åŒ–ã•ã‚Œã¦ã„ãªã„ã®ãŒæ‚©ã¿ã©ã“ã‚
- ollamaã§ Fugaku-LLM ã‚’å‹•ã‹ã™
	- https://note.com/npaka/n/n1d99253ae2cf?sub_rt=share_h
	- ä¸€ç•ªã‚µã‚¤ã‚ºã®å°ã•ã„ï¼ˆãŠãã‚‰ãé‡å­åŒ–ãŒä¸€ç•ªåŠ¹ã„ã¦ã„ã‚‹ï¼‰ ã€ŒFugaku-LLM-13B-instruct-0325b-q5_k_m.ggufã€ã‚’é¸ã³ã¾ã™
	- **`Modelfile`  ã§ä¸€ç•ªé‡è¦ãªã®ã¯ã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã® chat template ã‚’å®ˆã‚‹ã“ã¨ã§ã™**
	- dockerã€€ï¼’ç™ºã§ã€ollamaã¨ã€web-uiãŒå‹•ãã®ã‹ãƒ¼
- ã€GPT-4o çˆ†èª•ã€‘
	- https://x.com/MLBear2/status/1790069525372981452
	- å¾“æ¥ã®GPT-4, Claude 3 Opusãªã©ã«æ¯”ã¹ã¦é ­ä¸€ã¤æŠœã‘ã¦è³¢ã„ï¼ˆå›³ï¼‰
	- gpt2ã¨ã—ã¦Chatbot Arenaã§ãƒ†ã‚¹ãƒˆã•ã‚Œã¦ã„ãŸã‚‚ã®ãŒGPT-4oã ã£ãŸã¨ã‚µãƒ ã‚¢ãƒ«ãƒˆãƒãƒ³CEOãŒèªã‚ãŸã€‚
	- GPT-4 Turboã¨æ¯”ã¹ã¦ ãƒ»2å€é€Ÿã ãƒ»50%å®‰ä¾¡ ãƒ»Rate limitãŒ5å€é«˜ã„
- GPT-4oã§ä½¿ã‚ã‚Œã¦ã„ã‚‹æ–°ã—ã„tokenizerã€tiktokenã«ã‚‚ã†å…¥ã£ã¦ã‚‹
	- https://x.com/gyakuse/status/1790110045814010327
	- tiktokenã‚’0.7.0 ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã€enc = tiktoken.encoding_for_model("gpt-4o")ã¨ã™ã‚‹ã ã‘
- gpt-4oã§è©¦ã—ã«ä»Šå¹´ã®æ±å¤§æ•°å­¦2024ã®å•é¡Œã‚’ç”»åƒã§é€ã£ãŸã‚‰ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€åˆ‡ç„¡ã—ã§ã‚‚ï¼‰æ­£è§£ã§ããŸ
	- https://x.com/kyutaro15/status/1790098489940258830
- ã‚µãƒ ã‹ã‚‰ã®GPT-4oã«é–¢ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
	- https://x.com/sama/status/1790065541262032904
	- it is available to all ChatGPT users, including on the free plan! so far, GPT-4 class models have only been available to people who pay a monthly subscription. this is important to our mission; we want to put great AI tools in the hands of everyone.
- GPT-4oã®å‹•ç”»è¦ç´„ã‚’Huggingface Spaceã§è©¦ã›ã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸ by é€†ç€¬å·ã•ã‚“
	- https://x.com/gyakuse/status/1790090822031126730
	- ãƒªãƒªãƒ¼ã‚¹ã•ã‚ŒãŸGPT-4oã‚’ä½¿ã£ã¦å‹•ç”»ã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚’ã—ã¦ã¿ã‚‹ï¼
		- https://qiita.com/sakasegawa/items/b82a9745fda81143e409
- GPT-4oã«åŒ–å­¦å®Ÿé¨“ã®çµæœã‚’è€ƒå¯Ÿã•ã›ã¦ã‚‹ã‚“ã§ã™ãŒã€ è€ƒå¯ŸãŒæ—©ã™ãã¦ã€ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒè¿½ã„ã¤ã‹ãªã„ã§ã™ã€€ by ç• å±±ã•ã‚“
	- https://x.com/kanhatakeyama/status/1790098210360537138
- ï¼ˆOpenAIã®æ–°ã—ã„tokenizerã¯ï¼‰æ—¥æœ¬èªã¯ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãŒæ”¹å–„ã•ã‚Œã¦ã‚‹ã‹ã‚‰ã€APIä½¿ç”¨æ–™50% x ãƒˆãƒ¼ã‚¯ãƒ³é‡70% ã§ 35% ãã‚‰ã„ã®è²»ç”¨ã«ãªã‚‹ã®ã‹ï¼Ÿ
	- https://x.com/MLBear2/status/1790081289367990668
- LangChainãŒgpt-4oã«å¯¾å¿œ
	- https://x.com/LangChainAI/status/1790089006455398583
	- You can use the available multimodal capabilities of it in any of your LangChain applications today!
	- https://python.langchain.com/v0.1/docs/integrations/chat/openai/
- TJOã•ã‚“ã€ãƒ‡ã‚¸åºã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆå…¬å‹Ÿã®è¦ä»¶ã‚’ã¿ã¦é ­ã‚’æŠ±ãˆã‚‹
	- https://x.com/TJO_datasci/status/1790046279428345990
	- ã€Œã“ã®ã‚¹ã‚­ãƒ«ã®å¿…é ˆè¦ä»¶ã‚’å…¨éƒ¨æº€ãŸã—ã¦å°šä¸”ã¤æ­“è¿é …ç›®ã‚‚è¤‡æ•°æº€ãŸã™ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãªã‚“ã¦ã€ãã‚‚ãã‚‚æ—¥æœ¬ã©ã“ã‚ã‹ä¸–ç•Œã‚’è¦‹æ¸¡ã—ã¦ã‚‚æ¢ã—å‡ºã™ã®ã¯å›°é›£ã‚’æ¥µã‚ã‚‹ã®ã§ã¯ã€‚ãã‚Œã‚’å…¬å‹™å“¡ã®çµ¦ä¸ã§é›‡ã†ã¨ã‹ç„¡ç†ã‚²ãƒ¼ã«ã‚‚ç¨‹ãŒã‚ã‚‹ã‚ˆã†ãªæ°—ãŒã™ã‚‹ã€
	- çµå±€ãŠé‡‘ã®å•é¡Œã‹
- GPT-4oã¯Playgroundã§è©¦ã›ã‚‹ã€‚ ç¢ºã‹ã«è³¢ã„ã—ã‚‚ã®ã™ã”ãé€Ÿã„ by shi3zã•ã‚“
	- https://x.com/shi3z/status/1790073756079059400
- Command-R-Plus, Llama-3, Phi-3 miniã‚’ ELYZA-tasks-100 ã§è©•ä¾¡
	- https://qiita.com/wayama_ryousuke/items/a96f11fe2b7e2e3910e5
	- ã€Œä»Šå›ã”ç´¹ä»‹ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€æ—¥æœ¬èªã«ç‰¹åŒ–ã—ãŸè¿½åŠ å­¦ç¿’ã‚’è¡Œã‚ãªãã¦ã‚‚ã€æ—¥æœ¬èªã§å›ç­”ã‚’è¿”ã™ã“ã¨ãŒã§ãã‚‹ã¨ã„ã†ç‚¹ãŒå¤§ããªç‰¹å¾´ã§ã™ã€‚ã€
	- è©•ä¾¡ç”¨ Colab ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚‚ã‚ã‚‹ã‚ˆ
- Embeddingãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸãƒ™ã‚¯ãƒˆãƒ«åŒ–ã®ã—ãã¿ã€fine-tuningæ‰‹æ³•ã‚’è§£èª¬
	- https://speakerdeck.com/payanotty/embeddingmoderuwoshi-tutabekutoruhua-nosikumi-fine-tuningshou-fa-wojie-shuo
-  State-Free Inference of State-Space Models: The Transfer Function Approach
	- https://arxiv.org/abs/2405.06147v1
	- Utilizing the connections between convolutions in the time domain and multiplication in frequency domain (through FFT),
-  GPT-4o ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/n02331040d8c2?sub_rt=share_b
- JSLM2ï¼ˆJapanese Stable LM 2 Instruct 1.6Bï¼‰
	- JSLM2ã¯ã€6Bä»¥ä¸‹ã®è¦æ¨¡ã®ãƒ¢ãƒ‡ãƒ«ã®ä¸­ã§ã€æ—¥æœ¬èªæ€§èƒ½ãŒæœ€ã‚‚é«˜ã„ã¨æ€ã„ã¾ã™ã€‚é•ã„ã¾ã™ã‹ï¼Ÿ (llm-jp-evalã‚„å®šæ€§è©•ä¾¡ã§ï¼‰
	- https://x.com/peacej/status/1789909011132805402
- gpt-4o ã§ä½¿ã‚ã‚ŒãŸo200k_base tokenizer ã®æ—¥æœ¬èªã®éƒ¨åˆ†ãƒ»ãƒ»ãƒ»å®Œå…¨ã«5ã¡ã‚ƒã‚“ã­ã‚‹ãƒ»ãƒ»ãƒ»
	- https://x.com/_aixile/status/1790278857641410662
- Andrew Ngå…ˆç”Ÿã«ã‚ˆã‚‹AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®é€£è¼‰
	- https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/
	-  Agentic Design Patterns Part 1
	- Reflection, ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨, ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°, è¤‡æ•°Agentã®å”åŠ›
- gpt-4oã€è«–æ–‡è¦ç´„ã—ã¦PowerPointåã„ã¦ãã‚Œã‚‹
	- https://x.com/CurveWeb/status/1790336171777917332
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM)ã«ãŠã‘ã‚‹ä½ç²¾åº¦æ•°å€¤è¡¨ç¾ by PFNã®ä¸‰ä¸Šã•ã‚“
	- https://speakerdeck.com/pfn/20240508-hpckenkyukai-pfn-llm
	- å­¦ç¿’ï¼š8bitãŒä¸»æµã«ãªã‚Šã¤ã¤ã‚ã‚‹
	- æ¨è«–ï¼š1ï½2bitè¡¨ç¾ãŒå®Ÿç”¨åŒ–ã•ã‚Œã¤ã¤ã‚ã‚‹
- Introducing Veo: our most capable generative video modelã€€at Google I/O
	- https://x.com/GoogleDeepMind/status/1790435824598716704
	- It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles
- llamafiles from mozilla
	- https://x.com/llama_index/status/1790449858899505616
	- Build a local, private research assistant running on your laptop in a snap with llamafile from Mozilla! 
	- llamafiles are fun: no need to install anything, just download the file and run it, and you get a local LLM and embedding model that you can use directly from LlamaIndex. 
	- https://github.com/Mozilla-Ocho/llamafile
- langchain-huggingface ã®ã‚¢ãƒŠã‚¦ãƒ³ã‚¹
	- https://x.com/LangChainAI/status/1790419422399877158
	- We're excited to announce the launch of langchain-huggingface, a partner package in LangChain jointly maintained with huggingface
- Entropy minimization ãŒãªã‚“ã§æœ‰åŠ¹ã‹ï¼Ÿ ICML
	- https://x.com/ori_press/status/1790383780642918469
	- https://arxiv.org/pdf/2405.05012
- Evaluation of Retrieval-Augmented Generation: A Survey
	- https://arxiv.org/abs/2405.07437
	- https://github.com/YHPeter/Awesome-RAG-Evaluation
- Pattern Language is one of my favorite books, and this abridged hypertext version by zenodotus280
	- https://x.com/kepano/status/1790437820487946630
	- This project is an abridged, hyper-textual, and copyleft manifestation of the 1977 architecture classic _A Pattern Language_ by Christopher Alexander
		- https://github.com/zenodotus280/apl-md
- GPT-4oã®ç™»å ´ã«ã‚ˆã‚Šã€æ¤œè¨ä¸­ã®ç ”ç©¶ãƒ—ãƒ­ãƒãƒ¼ã‚¶ãƒ«ãŒãŠé‡ˆè¿¦ã«ãªã‚‹ã¨ã„ã†ãƒã‚¹ãƒˆãŸã¡
	- ã€ŒéŸ³å£°è¨€èªãƒ¢ãƒ‡ãƒ«ã€ã«ã¤ã„ã¦å­¦æŒ¯æ›¸ã„ã¦ã„ã‚‹é–“ã«ã“ã‚Œã¯ã²ã©ã™ãã‚‹ã§ã—ã‚‡
		- https://x.com/nonmetal_/status/1790079046191120560
	- GPT-4o makes me feel both sad for my current work has been scooped by OpenAI, and happy that we are on the right track. by SpeechGPTã‚·ãƒªãƒ¼ã‚ºã®é–‹ç™ºè€…
		- https://x.com/dongzha35524835/status/1790241799547806071
- multi-step reasoning capabilities to Google Search at Google I/O
	- https://x.com/Google/status/1790438800667123860
	- perplexityã®ã‚ˆã†ãªã‚‚ã®ãŒãã‚‹ã®ã‹ã€
- Linear Regression is one of the most important tools in a Data Scientist's
	- https://x.com/mdancho84/status/1790445342787318206
	- 1. OLS regression aims to find the best-fitting linear equation that describes the relationship between the dependent variable (often denoted as Y) and independent variables (denoted as X1, X2, ..., Xn).
	- 2. OLS does this by minimizing the sum of the squares of the differences between the observed dependent variable values and those predicted by the linear model. These differences are called "residuals."
	- 3. "Best fit" in the context of OLS means that the sum of the squares of the residuals is as small as possible. Mathematically, it's about finding the values of Î²0, Î²1, ..., Î²n that minimize this sum.
- Weâ€™re sharing Project Astra: at Google I/O
	- https://x.com/GoogleDeepMind/status/1790433540548558853
	- Weâ€™re sharing Project Astra: our new project focused on building a future AI assistant that can be truly helpful in everyday life.
- PaliGemmaã€Gemma 2ã€€at Google I/O
	- https://x.com/GoogleDeepMind/status/1790459505538658636
	- PaliGemma: a powerful open vision-language model  
	- Gemma 2: coming soon in various sizes, including 27 billion parameters
- GPT-4o shows improvement compared to GPT-4-Turbo-0409 with better probability, pre-calculus, algebra, and geometry abilities. 
	- https://x.com/GanjinZero/status/1790230562453803241
- Get a sneak peek of Gemma 2, at Google I/O
	- https://x.com/Google/status/1790452314278412554
	- 27B parameter instance launching in a few weeks. Built on new architecture, Gemma 27B outperforms models twice its size and can run on a single TPU host in Vertex AI.
- PaliGemma ã‚’ãŠè©¦ã—ä¸­
	- https://huggingface.co/spaces/big-vision/paligemma
- Introducing Trillium, the next generation of Google Cloud TPU
	- https://x.com/GoogleCloudTech/status/1790452622295449925
	- It delivers 4.7X the peak compute performance per chip compared to TPU v5e and is equipped with 2X the high-bandwidth memory capacity.
- ZeTT
	- https://x.com/CurveWeb/status/1790308270126883146
	- ã€Œè¿½åŠ ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã»ã¨ã‚“ã©(ã‚‚ã—ãã¯å…¨ã)è¡Œã‚ãšã«ã€ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä»»æ„ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹æ‰‹æ³•ZeTTã€‚ ChatVector ã‚„ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ã®Tokenizerã«ã‚ˆã‚‹åˆ¶é™ã‚’é¿ã‘ã‚‹ã®ã«ä½¿ãˆãã†ã€ by ã¯ã¡ã•ã‚“
- Gemini 1.5 Pro to 2 million tokens at Google I/O
	- https://x.com/Google/status/1790430189916225799
	- Today weâ€™re expanding the context window for Gemini 1.5 Pro to 2 million tokens and making it available for developers in private preview. Itâ€™s the next step towards the ultimate goal of infinite context
- Data Scientists: The next level of Data Science AI Agents is called "Plan and Execute".
	- https://x.com/mdancho84/status/1790406221616320862
- Googleã¨OpenAIã®ç™ºè¡¨ã‚’è¦‹ã¦ã‚‹åƒ•ã®å¿ƒå¢ƒ by GUILDã®æ·±æ¾¤ã•ã‚“
	- https://x.com/fladdict/status/1790431879512093151
	- ã€Œã‚ã€ã‚´ã‚¯ã‚¦ã¨ãƒ•ãƒªãƒ¼ã‚¶ãŒä¸Šç©ºã§æˆ¦ã£ã¦ã‚‹ï¼ï¼ï¼ã™ã”ã„é€Ÿåº¦ã§è¦‹ãˆãªã„ï¼ï¼ï¼é ‘å¼µã‚Œï¼ï¼ï¼ã€ã¨ã„ã†ã‚¯ãƒªãƒªãƒ³ã®å¿ƒå¢ƒ
- Ilya and OpenAI are going to part ways. by Sam
	- https://x.com/sama/status/1790518031640347056
	- This is very sad to me; Ilya is easily one of the greatest minds of our generation, a guiding light of our field, and a dear friend. His brilliance and vision are well known; his warmth and compassion are less well known but no less
- HCIç³»ã®ãƒˆãƒƒãƒ—ã‚«ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹CHI2024ã®å…¨è«–æ–‡ã‚’GPT-4ã§è¦ç´„ã‚¹ãƒ©ã‚¤ãƒ‰ã«ã¾ã¨ã‚ã¦è¦‹ãŸã®ã§
	- https://drive.google.com/file/d/1CMkTdGlk1OhtScKUTB7Mt22GtWxgAIPV/view
- Colab ğŸ“’ Notebook to fine-tune ğŸ’…ğŸ½ @GoogleAI
	- #PaliGemma vision-language model ğŸ‘“ğŸ” ğŸ§ on a free T4 VM
	- https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb
- Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
	- https://note.com/panda_lab/n/n948053d7813f
	- RAGã®æ çµ„ã¿ã‚’æ‹¡å¼µã—ã€Wikipediaè‡ªå‹•ç”Ÿæˆã«ç‰¹åŒ–ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€ŒSTORMã€ã‚’è€ƒæ¡ˆã—ã¾ã—ãŸã€‚
	-  **èª²é¡Œ**: ã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã‚¹ã‚¿ã‚¤ãƒ«ã®è¨˜äº‹ã¯ã€åºƒç¯„å›²ã®å‚è€ƒæ–‡çŒ®ã®åé›†ã¨ã€è©³ç´°ãªã‚¢ã‚¦ãƒˆãƒ©ã‚¤ãƒ³ã®ä½œæˆãŒå¿…è¦ã§ã™ã€‚å¾“æ¥ã®æ–¹æ³•ã§ã¯ã€ã“ã®æº–å‚™æ®µéšãŒã—ã°ã—ã°çœç•¥ã•ã‚Œã¾ã™ã€‚
	-  **è§£æ±ºç­–**: STORMã¯ã€äºˆå‚™çš„ãªæ›¸ãè¾¼ã¿ã€è‰ç¨¿ä½œæˆã€æ”¹è¨‚ã®å„æ®µéšã€ç‰¹ã«äºˆå‚™æ®µéšã§ã®åŠ¹æœçš„ãªè³ªå•æèµ·ã«ã‚ˆã‚Šã€ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚
- ã€ŒStockmark-100bã€
	- https://x.com/kosukearima/status/1790902109648695565
	- ç”£ç·ç ”ï½˜ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯å…±åŒç ”ç©¶ã®æˆæœã€ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§å­¦ç¿’ã—ãŸ100Bç´šæ—¥æœ¬èªLLMã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- ã‚¹ãƒˆãƒƒã‚¯ãƒãƒ¼ã‚¯ã¯ã€1000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªLLMãƒ¢ãƒ‡ãƒ«ã€ŒStockmark-100bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã«ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚’è¡Œã„ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‚ã®ã§ã¯ãªãã€ã‚¼ãƒ­ã‹ã‚‰ãƒ•ãƒ«ã‚¹ã‚¯ãƒ©ãƒƒãƒã§é–‹ç™ºã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚Šã€å›½å†…ã§ã¯(ç¾çŠ¶ã¯ãƒ€ãƒ³ãƒˆãƒ„ã§)æœ€å¤§ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§ã‚‚æœ€å¤§ç´šã‚µã‚¤ã‚ºã®OSSãƒ¢ãƒ‡ãƒ«ã¨ãªã‚Šã¾ã™ã€‚
		- https://huggingface.co/stockmark/stockmark-100b
- ã€Œç¢ºç‡æ€è€ƒã®æˆ¦ç•¥è«–ã€ãŒã‚‚ã‚„ã‚‚ã‚„ã™ã‚‹æ–¹ã¸ -NBDãƒ¢ãƒ‡ãƒ«ç·¨-
	- https://zenn.dev/joanofarc/articles/strange-theory-of-probability-thinking
- LLM ã«è¡¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è§£ã‹ã›ãŸã‹ã£ãŸã®ã§ã€ã¡ã‚‡ã£ã¨è©¦ã—ã¦ã¿ãŸ
	- https://developers.cyberagent.co.jp/blog/archives/47869/
	- In-context Learning ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦æ‰‹æ³•ã«æ¡ç”¨ã—ã¦ã„ã‚‹ã€Œè¡¨å½¢å¼ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è§£ãã€ã«é–¢ã™ã‚‹è«–æ–‡(ICML2024)ã‚’ã€å€‹äººçš„ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã§ç´¹ä»‹ã—ã¦ã¿ã¾ã—ãŸã€‚
	- https://openreview.net/forum?id=4L0xnS4GQM
- è² ã®äºŒé …åˆ†å¸ƒã®ç–«å­¦ã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã§ã®å¿œç”¨ã®æ¯”è¼ƒ
	- https://socinuit.hatenablog.com/entry/2024/05/16/185601
	- è¥¿æµ¦ã€æ„ŸæŸ“ç—‡ã‚’èª­ã¿è§£ãæ•°ç†ã€ã¨æ£®å²¡ãƒ»ä»Šè¥¿ã€ç¢ºç‡æ€è€ƒã®æˆ¦ç•¥è«–ã€ã«ãŠã„ã¦ã€è² ã®äºŒé …åˆ†å¸ƒã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«å¿œç”¨ã«ã¤ã„ã¦è¨˜è¿°ã•ã‚Œã¦ãŠã‚Šã€ ç›¸äº’ã‚’å‚ç…§ãƒ»æ¯”è¼ƒã™ã‚‹ã“ã¨ã§é¡ä¼¼ç‚¹ã‚„è§£é‡ˆã®æ‹¡å¤§ã‚’è©¦ã¿ã‚‹ã€‚
	- ã“ã®è¨˜äº‹ã§è¿°ã¹ãŸã„ã“ã¨ã¯ã€**ç–«å­¦ã¨ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã¨ã„ã†ä¸€è¦‹ã—ã¦è·é›¢ã®ã‚ã‚‹é ˜åŸŸã§ã€è² ã®äºŒé …åˆ†å¸ƒã‚’ç”¨ã„ãŸç¾è±¡ã®ç¢ºç‡ãƒ¢ãƒ‡ãƒ«åŒ–ã®äº‹ä¾‹ãŒå–ã‚Šä¸Šã’ã‚‰ã‚Œã¦ã„ã¦é¢ç™½ã„ã­**ã€ã¨ã„ã†ã“ã¨ã«å°½ã
- æœ€è¿‘Gemini 1.5 Proã®PDFãƒ‘ãƒ¼ã‚¹ãŒä¾¿åˆ©ã ã¨æ°—ã¥ã„ã¦è‰²ã€…è©¦ã—ã¦ã„ã‚‹
	- https://x.com/resnant/status/1791104886563811520
	- ä»Šã®ã¨ã“ã‚å…ˆè¡Œç ”ç©¶ã®è«–æ–‡PDFã‚’æ”¾ã‚Šè¾¼ã‚“ã§ã€Œã“ã®ç ”ç©¶ã®XXã¨ã„ã†ç‚¹ã‚’è§£æ±º/æ‹¡å¼µã™ã‚‹ã¨ã©ã‚“ãªä¾¡å€¤ãŒç”Ÿã¾ã‚Œã‚‹ï¼Ÿãã®çµæœã‚’ã©ã†è¨´æ±‚ã™ã‚‹ï¼Ÿã€ã¿ãŸã„ã«ç ”ç©¶ãƒã‚¿ã®å£æ‰“ã¡ã§ä½¿ã†ã¨å¿ƒå¼·ã„
-  2023å¹´åº¦ ãƒ‡ã‚¸ã‚¿ãƒ«åºãƒ»è¡Œæ”¿ã«ãŠã‘ã‚‹ç”ŸæˆAIã®é©åˆ‡ãªåˆ©æ´»ç”¨ã«å‘ã‘ãŸæŠ€è¡“æ¤œè¨¼ã‚’å®Ÿæ–½ã—ã¾ã—ãŸ
	- https://www.digital.go.jp/news/19c125e9-35c5-48ba-a63f-f817bce95715
	- ã€Œå®Ÿè¨¼ã®æœ€ä¸­ã«ã‚‚ç’°å¢ƒãŒæ¿€å¤‰ã™ã‚‹ä¸­ã§ã€ãŸã è©¦ã—ã¦çµ‚ã‚ã‚‰ã›ã‚‹ã®ã§ã¯ãªãã€ã—ã£ã‹ã‚Šã¨çŸ¥è¦‹ã‚’å…±æœ‰ã—ã€ãƒ‡ãƒ¼ã‚¿æ•´å‚™ã¯ã˜ã‚æ¬¡ã®å‹•ãã«ç¹‹ã’ã¦ã„ãã“ã¨ãŒé‡è¦ã¨è€ƒãˆã¦ã„ã¾ã™ã€ by æ¥ ã•ã‚“
	- https://x.com/masanork/status/1790871089121513629
- ChatGPTãŒGoogle Driveã‚„Microsoft OneDriveã‹ã‚‰Spreadsheetã‚„Excelã‚’èª­ã¿è¾¼ã‚“ã§åˆ†æãƒ»å¯è¦–åŒ–ã‚’æ‰‹ä¼ã£ã¦ãã‚Œã‚‹æ©Ÿèƒ½ã‚’è¿‘ãå…¬é–‹
	- https://x.com/MLBear2/status/1791251518110523764
-  HCIç ”ç©¶ã«å¯¾ã™ã‚‹ç§è¦‹ - CHI2024å‚åŠ ã‚’çµ‚ãˆã¦ã€€by ç¨²è¦‹å…ˆç”Ÿ
	- https://note.com/drinami/n/nfd4921806ad3?sub_rt=share_pb
	- ã€ŒHCIç ”ç©¶ãŠã‚‚ã¡ã‚ƒè«–ã€ãŒã‹ã¤ã¦è­°è«–ã•ã‚Œã¦ã„ãŸã“ã¨ãŒã‚ã‚Šã¾ã—ãŸãŒã€ŒãŠã‚‚ã¡ã‚ƒã«è©°ã¾ã£ãŸçŸ¥æµã¨å½¹å‰²ã‚’ãƒã‚«ã«ã™ã‚‹ãªã€‚æ¯”å–©ã¨ã—ã¦ä¸é©åˆ‡ã€ã¨ã„ã†ã®ãŒç§ã®è¦‹è§£ã§ã™
- ã€Œç«¶äº‰åŠ›ã‚ã‚‹ç”ŸæˆAIåŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºï¼ˆåŠ©æˆï¼‰ã€ã«ã€ELYZAãŒæ¡æŠ
	- https://x.com/ELYZA_inc/status/1791348009764360577
	- çµŒæ¸ˆç”£æ¥­çœãŒç«‹ã¡ä¸Šã’ãŸã€ŒGENIACã€ã®ã‚‚ã¨ã€NEDOãŒå…¬å‹Ÿ
	- Mixture of Expertsã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æ¡ç”¨ã‚„ã€æ—¥æœ¬ç‰¹æœ‰ã®ãƒ‡ãƒ¼ã‚¿ã®å­¦ç¿’ã€æ—¥æœ¬èªã®æ¨è«–åŠ¹ç‡åŒ–ãªã©ã‚’å®Ÿæ–½äºˆå®š
- "functional ontology"
	- https://x.com/Westoncb/status/1791152606309687768
	- As an alternative to LLM summarizing, I've been getting very interesting results doing something like:
	- https://symbolflux.com/ApolloLunarLandingTrajectoryReconstruction.txt
- QA over large embedded tables without hallucinations (Caltrain schedule edition
	- https://x.com/llama_index/status/1791505972407746671
	- With LlamaParse, we were able to spatially layout the text in a semantically coherent manner, so that our GPT-4o-powered QA pipeline could correctly answer questions
		- https://github.com/run-llama/llama_parse/blob/main/examples/caltrain/caltrain_text_mode.ipynb
- MediaPipe LLM Inference APIã‚’ä½¿ã£ã¦ã€MediaPipeå½¢å¼ã«å¤‰æ›ã™ã‚‹ã¨Gemma 2Bã‚„ ã¨Gemma 7Bã€Phi-2ã€Falcon-RW-1Bã€StableLM-3Bãªã©ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã‚„Androidsã€iphoneãªã©ã§å‹•ã‹ã™äº‹ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹
	- https://x.com/webbigdata/status/1791497099315752967
	- You can now run the 7B parameter version of Gemma, entirely locally in the browser, using MediaPipe LLM Inference API.
		- https://x.com/googledevs/status/1791174333995299216
- stockmarkã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹stockmark-100bã®ggufã‚ã‚Šã¾ã™
	- https://huggingface.co/mmnga/stockmark-100b-gguf
- Gemini 1.5 Flashã§ã€12åˆ†ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨ã¦æ–‡å­—èµ·ã“ã—ã€‚å®Œç’§ã€‚GPT-4oã§ã‚‚ã“ã‚Œã¯ç„¡ç†
	- https://x.com/Taiyo_AiAA/status/1791460870947774826
-  EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
	- https://www.docswell.com/s/DeepLearning2023/K1JDN3-2024-05-16-142439#p9
	- äº‹å‰å­¦ç¿’æ¸ˆã¿ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦ï¼Œè¿½åŠ ã®å­¦ç¿’ã‚’ä¸€åˆ‡è¡Œã‚ãšã«ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ãŸè«–æ–‡ï¼æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã¯é«˜ç²¾ç´°ã«ç”»åƒç”Ÿæˆã‚’ã§ãã‚‹ãŒï¼Œãã®å†…éƒ¨ã«ã¯ç”»åƒç´°éƒ¨ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãªæƒ…å ±ã‚’æŒã¤ã“ã¨ãŒç¤ºå”†ã•ã‚Œã‚‹ï¼
-  LangChain v0.1 ã‹ã‚‰ v0.2 ã¸ã®ç§»è¡Œæ‰‹é † by npakaã•ã‚“
	- https://note.com/npaka/n/n161a7e3882b3?sub_rt=share_h
	-  importå¤‰æ›´ã®ä¾‹
		- **langchain â†’ langchain_community**
			- vectorstoresã¨ã‹
		- **langchain-community â†’ langchain_openai**
			- ChatOpenAIã¨ã‹
		- **langchain-community â†’ langchain-core**
			- document_loadersã¨ã‹
		- **langchain â†’ langchain-core**
			- Documentã¨ã‹
		- **langchain â†’ langchain-text-splitters**
			- text_splitterã¨ã‹
- ADA-V2ã€GPT-4oã ã‹ã‚’å¾®èª¿æ•´ã—ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ€§èƒ½ä¸Šã’ãŸãƒ¢ãƒ‡ãƒ«
	- https://x.com/umiyuki_ai/status/1791429524351258857
	- OpenAIãŒGPT-4Tã ã‹GPT-4oã ã‹ã‚’å¾®èª¿æ•´ã—ã¦ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ€§èƒ½ä¸Šã’ãŸãƒ¢ãƒ‡ãƒ«ã«ADA-V2ãªã‚“ã¦ãƒãƒ¼ãƒŸãƒ³ã‚°ä»˜ã‘ãŸã®ãŒãƒã‚¸ã ã¨ã—ãŸã‚‰ãã®ç†ç”±ã¯ï¼ŸAdaã¯GPT-3å››å¤©ç‹ã®ä¸­ã§æœ€å¼±ã®ãƒ¢ãƒ‡ãƒ«ã ã£ãŸã€‚ã¤ã¾ã‚Šã€GPT-4ãŒAda-V2ãªã‚‰Babaggi-V2ã‚„Curie-V2ã€ãã—ã¦Davinci-V2ã¯ã©ã†ãªã£ã¦ã—ã¾ã†ã®ã‹â€¦ï¼Ÿã¨ã„ã†åŒ‚ã‚ã›
-  Finetuning Llama3 using Unsloth
	- https://github.com/neo4j-labs/text2cypher/tree/main/finetuning/unsloth-llama3#using-chat-prompt-template
	- https://huggingface.co/tomasonjo/text2cypher-demo-16bit
	-  I've finetuned Llama3-Instruct:8b to generate @neo4j Cypher statements based on the GPT-4o synthetic dataset I've generated at the start of the week.
-  LangChain ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ by npakaã•ã‚“
	- https://note.com/npaka/n/n5956ef3a0a09?sub_rt=share_h
	- ã€ŒRAGã®QAã€ã¯ã€RAGæŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦ã€ç‰¹å®šã®æƒ…å ±æºã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™
	- ã€Œæƒ…å ±æŠ½å‡ºã€ã¯ã€LLMã§ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§ã™ã€‚æ¬¡ã®3ã¤ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™ã€‚
		- **Tool Callingãƒ¢ãƒ¼ãƒ‰** : Tool Callingã§æŒ‡å®šã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã«å¾“ã£ã¦ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
		- **JSONãƒ¢ãƒ¼ãƒ‰** : ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸€éƒ¨ã¨ã—ã¦ã‚¹ã‚­ãƒ¼ãƒã‚’æä¾›ã—ã€JSONãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
		- **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ™ãƒ¼ã‚¹** : æŒ‡ç¤ºã«å¾“ã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¢å­˜ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã§è§£æã—ã€æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
	- ã€Œãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã€ã¯ã€é•·æœŸçš„ãªå¯¾è©±ã‚’ç¶­æŒã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦å›ç­”ã™ã‚‹èƒ½åŠ›ã‚’æŒã¡ã¾ã™
	- ã€Œãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã¯ã€è‡ªç„¶è¨€èªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’é€šã˜ã¦APIã‚„é–¢æ•°ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãªã©ã®ãƒ„ãƒ¼ãƒ«ã‚’æ“ä½œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚  
		- **ãƒã‚§ãƒ¼ãƒ³** : ãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã®äº‹å‰å®šç¾©ã•ã‚ŒãŸã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ä½œæˆ
		- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ** : ãƒ„ãƒ¼ãƒ«ã‚’ç¹°ã‚Šè¿”ã—ä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’è‡ªå‹•çš„ã«å®Ÿè¡Œ
	- ã€Œã‚¯ã‚¨ãƒªè§£æã€ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’æœ€é©åŒ–ã—ã¦æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã€ã‚ˆã‚Šæ­£ç¢ºãªæƒ…å ±ã‚’å–å¾—ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
		- æ‰‹æ³•ã«ã¯ã€ã‚¯ã‚¨ãƒªã®åˆ†è§£ã€ã‚¯ã‚¨ãƒªæ‹¡å¼µã€ä»®æƒ³ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŸ‹ã‚è¾¼ã¿ã€ã‚¯ã‚¨ãƒªã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒ†ã‚£ãƒ³ã‚°ã€ã‚¯ã‚¨ãƒªã®æ§‹é€ åŒ–ãªã©ãŒã‚ã‚Šã¾ã™ã€‚
	- SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹QAã€ã¯ã€ã€ŒSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã‚’å¯¾è±¡ã¨ã—ãŸQ&Aã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
	- ã€Œã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®QAã€ã¯ã€ã€Œã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã‚’å¯¾è±¡ã¨ã—ãŸQ&Aã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™
		- ã€ŒCypherã€ã‚„ã€ŒSparQLã€ãªã©ã®ã‚°ãƒ©ãƒ•ã‚¯ã‚¨ãƒªè¨€èªã‚’ä½¿ç”¨ã—ã€è‡ªç„¶è¨€èªã®è³ªå•ã«åŸºã¥ã„ã¦ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±ã‚’å–å¾—ã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚„ã‚«ã‚¹ã‚¿ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã™
	- ã€Œã‚³ãƒ¼ãƒ‰ç†è§£ã€ã¯ã€ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®åˆ†æã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã«é–¢ã™ã‚‹Q&Aã‚’è¡Œã„ã€ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚„æ”¹å–„ã®ææ¡ˆã€ã‚³ãƒ¼ãƒ‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–ã‚’æ”¯æ´ã—ã¾ã™
	- ã€Œãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã€ã¯ã€äººå·¥çš„ã«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã‚„ãƒ†ã‚¹ãƒˆã«å½¹ç«‹ã¦ã¾ã™
	- ã€Œã‚¿ã‚°ä»˜ã‘ã€ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ„Ÿæƒ…ã€è¨€èªã€ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒˆãƒ”ãƒƒã‚¯ã€æ”¿æ²»çš„å‚¾å‘ãªã©ã®ã‚¯ãƒ©ã‚¹ã‚’ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ã¾ã™
	- ã€Œè¦ç´„ã€ã¯ã€é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’è¦ç´„ã™ã‚‹ãŸã‚ã®ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚è¤‡æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚„é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’åŠ¹ç‡çš„ã«è¦ç´„ã™ã‚‹ã“ã¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã«ã¯ã€ã€ŒStuffã€ã€ŒMap-Reduceã€ã€ŒRefineã€ã®3ã¤ã®æ‰‹æ³•ãŒã‚ã‚Šã¾ã™ã€‚
	- ã€ŒWebã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã€ã¯ã€Webã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åé›†ã—ã€è‡ªç„¶è¨€èªå‡¦ç†ã«ä½¿ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚
-  LangChain v0.2 ã§ å˜ç´”ãªLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ by npakaã•ã‚“
	- https://note.com/npaka/n/n24d48303a496?sub_rt=share_h
-  LangChain v0.2 ã§ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ by npakaã•ã‚“
	- https://note.com/npaka/n/ne8ef60987e1b?sub_rt=share_b
- ç”ŸæˆAIå­¦ã³ãŸã„ãªã‚‰ã€ã“ã®ï¼’æœ¬ by å°¾åŸã•ã‚“
	- https://x.com/kazobara/status/1791454624983196148
	- ã€Œç”ŸæˆAIã€(3) æ¾å°¾è±Šãƒ»æ±äº¬å¤§å­¦å¤§å­¦é™¢æ•™æˆã€€2024.3.15"
		- https://www.youtube.com/watch?v=U9vhGvFxKu0
	- "GPTã¨ã¯ä½•ã‹ Transformerã®è¦–è¦šåŒ– |
		- https://www.youtube.com/watch?v=KlZ-QmPteqM
-  LangChain v0.2 ã§ RAGã‚’æ§‹ç¯‰ by npaka ã•ã‚“
	- https://note.com/npaka/n/ne892b713bd45?sub_rt=share_h
	-  Retriever
		- ã€ŒVectorStoreã€ã¯Runnableã‚’ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã—ãªã„ãŸã‚ã€LECLãƒã‚§ãƒ¼ãƒ³ã«ã™ãã«çµ±åˆã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ã€ŒRetrieverã€ã¯Runnableã§ã‚ã‚‹ãŸã‚ã€æ¨™æº–ã‚»ãƒƒãƒˆã®ãƒ¡ã‚½ãƒƒãƒ‰ (åŒæœŸãŠã‚ˆã³éåŒæœŸã®å‘¼ã³å‡ºã—ã‚„ãƒãƒƒãƒæ“ä½œãªã©) ã‚’å®Ÿè£…ã—ã€LCELãƒã‚§ãƒ¼ãƒ³ã«çµ„ã¿è¾¼ã¾ã‚Œã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
	-  RAGãƒã‚§ãƒ¼ãƒ³
		- ã€ŒRetrieverã€ã¯ã€ç‰¹å®šã®è³ªå•ã¨å–å¾—ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ã¦ LLM ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹RAG ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã€ã‚ˆã‚Šè¤‡é›‘ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ç°¡å˜ã«çµ„ã¿è¾¼ã‚€ã“ã¨ãŒã§ãã¾ã™ã€‚
		- rag_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
- â€œMambaOut: Do We Really Need Mamba for Vision?â€
	- https://arxiv.org/abs/2405.07992
	- Based on our concept discussion, we hypothesize Mamba is unnecessary for ImageNet while exploring for detection and segmentation remains worthwhile. To verify these, we build MambaOut with Mamba blocks but remove their core token mixer, SSM.
- Text-to-SQL - fully local edition
	- https://x.com/llama_index/status/1791915423816204494
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
	-  Text2SQL OpenSource : duckdb-nsql-7B with Ollama and LlamaIndex on local setup
		- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
- 

## 5/13

å…ˆé€±ã«å¼•ãç¶šãgpt2-chatbotãŒchatbod arenaã«å¾©æ´»ã—ãŸã‚Šã¨ã€è©±é¡Œã«äº‹æ¬ ã‹ãªã„ãŒã€ã‚µãƒ (OpenAIã®ç¤¾é•·)ã‹ã‚‰ã€5/13æœˆæ›œæ—¥ã«ä½•ã‹ç™ºè¡¨ãŒã‚ã‚‹ã¨ã®ãƒã‚¹ãƒˆãŒã€GPT-5ã§ã‚‚ï¼ˆã†ã‚ã•ã®ï¼‰æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§ã‚‚ãªã„ã¨ã„ã£ã¦ã„ã‚‹ã—ã€æ˜ ç”»Herã«å‡ºã¦ããŸã‚ˆã†ãªéŸ³å£°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¨ã„ã†ä¸‹é¦¬è©•ã€‚ãŠã£ã¨COCONAï¼ˆ_ã‚³ã‚³ãƒŠ_ï¼‰ã®ç«‹å ´ã¯ï¼Ÿã€‚OpenAIã¨ã„ãˆã°ã€Stack Overflowã¨ã®ææºã€å›ç­”è€…ã«chatptãŒç™»å ´ã™ã‚‹ã®ã‹ã€ã¾ãŸãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«å‹•ä½œã™ã‚‹ã¹ãã‹ã‚’è¦å®šã™ã‚‹Model Specã‚’å…¬é–‹ã€EUã®AIæ³•å¯¾ç­–ã‹ï¼ˆä»¥å‰ã¯System CardãŒãã®å½¹å‰²ã ã£ãŸï¼‰ã¨ã‚‚è¦‹ã‚Œã‚‹ã—ã€å®‰å…¨æ€§ã«æœ¬æ°—ã«å–ã‚Šçµ„ã‚“ã§ã„ã‚‹å§¿å‹¢ã«ã‚‚ã¿ãˆã‚‹ã€ã¨ã‚‚ã‹ãæ¥ãŸã‚‹GPT-5ã®ç´ æ€§ã‚‚é€ã‘ã¦è¦‹ãˆã‚‹ã¨ã„ã†ã®ã¯é¢ç™½ã„åˆ†æã€‚ã‚ã¨ã€ä»Šé€±ã¯å›½å†…å‹¢ã®æ´»èºã‚‚æ´»ç™ºã ã£ãŸã€æ±å·¥å¤§ã®Swallow-MX-8x7b-NVE-v0.1ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸKARAKURI LM 8x7B Chat v0.1ã€13Bã§104Bã®Command R+ã‚’è¶…ãˆã‚‹ã£ã¦æœ¬å½“ï¼Ÿã€‚ã€ŒJapanese Stable LM 2 1.6Bã€ã€ å±æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã€€KARAKURI LM 7B APM v0.1 ã€ã€ŒFugaku-LLMã€ã®å…¬é–‹ãªã©ã€‚ã•ã¦æ§˜ã€…ãªè©•ä¾¡ã‹ã‚‰æ€§èƒ½ãŒé«˜ã„ã€ä½¿ãˆã‚‹ã€ã¨ã•ã‚Œã¦ã„ã‚‹llama3ã€æ—¥æœ¬èªãŒã‚„ã£ã±ã‚Šãƒ€ãƒ¡ãƒ€ãƒ¡ã ã£ãŸã‚Šã¯ã”æ„›æ•¬ã§ã‚‚ã€é‡å­åŒ–ã«å¼±ã‹ã£ãŸã‚Šï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§æ€§èƒ½ãŒé«˜ã„ã¨ã„ã†ã®ã¯é‡å­åŒ–ã®ä½™åœ°ã‚‚å°‘ãªã„ï¼‰ã¨ã€LLMã®ã‚¹ã‚±ãƒ¼ãƒ«æ¸¬ã®ä¸€ç«¯ã‚’æ€ã„çŸ¥ã‚‰ã™çµæœã«ãªã£ã¦ã‚‹ã¨ã„ã†ã®ã¯é¢ç™½ã„ã€tokenerizerãŒå£Šã‚Œã¦ã„ã‚‹ã¨ã®ã†ã‚ã•ã‚‚ã€‚"DeepSeek-V2"ã£ã¦ã®ãŒGPT-4ã¨åŒãƒ¬ãƒ™ãƒ«ã€‚ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã¯200åˆ†ã®1ã¨ã„ã†ã®ã¯æœ¬å½“ã ã‚ã†ã‹ï¼ŸGoogle/DeepMindã‹ã‚‰ã¯ã€ŒAlphaFold 3ã€ã‚’ç™ºè¡¨ã€ã“ã‚“ã©ã¯DNAã‚‚æ‰±ãˆã‚‹ã¨ã®ã“ã¨ã€å‰µè–¬ãŒåŠ‡çš„ã«åŠ é€Ÿã™ã‚‹äºˆæ„Ÿã€‚å…ˆé€±ã«å¼•ãç¶šã„ã¦KANã®è©•ä¾¡ã‚‚é€²ã‚€ã€shi3zã•ã‚“ã®ã€Œæœ€å¾Œã«KANã¯å‹ã¤ã€ã¨ã„ã†KANè©•ä¾¡è©¦è¡Œã®noteã®ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œæœ€å¾Œã«æ„›ãŒå‹ã¤ by KANã€ã®ã‚‚ã˜ã‚Šï¼Ÿãã‚Œã«ã—ã¦ã‚‚KANã•ã‚“ã”å†¥ç¦ã‚’ãŠç¥ˆã‚Šã—ã¾ã™ã€‚MicrosoftãŒè‡ªç¤¾è£½LLMã§ã‚ã‚‹ã€ŒMAI-1ã€ã‚’é–‹ç™ºä¸­ã€ï¼¸ã¯Grokã‚’æœ‰æ–™ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–‹æ”¾ã€‚Deeplearning.aiã‹ã‚‰ã¯ã€llamaindexã®Jerry Liu(CEO)ã‚’è¬›å¸«ã«Agentic RAGã€LangChainã®Harrison(CEO)ã‚’è¬›å¸«ã«ã€Functions, Tools and Agentsã®ã‚·ãƒ§ãƒ¼ãƒˆã‚³ãƒ¼ã‚¹ãŒç„¡æ–™å…¬é–‹ã€ãªã‚“ã¦è±ªè¯ãªã€‚ãã®LangChainã¯v0.2ãŒãƒªãƒªãƒ¼ã‚¹ãŒé–“è¿‘ã«ã€Agentã‚„Toolé–¢é€£ã®è¦‹ç›´ã—ãŒã•ã‚Œã‚‹ã€‚ã‚ã¨ãªãœã‹ã€æ™‚ç³»åˆ—äºˆæ¸¬ã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ã®ç™ºè¡¨ã‚‚ç›¸æ¬¡ã„ã ã€Google/TimesFMã€IBMã®TinyTimeMixers (TTMs)ã€ICML2024ã«ã‚¢ã‚¯ã‚»ãƒ—ãƒˆã•ã‚ŒãŸã€CMUã¨UPENã®MOMENTã€ã²ã‚‡ã£ã¨ã—ã¦ICML2024ãŒTime Seriesã®åŸºç›¤ãƒ¢ãƒ‡ãƒ«ç¥­ã‚Šã«ãªã£ã¦ã‚‹ã®ã‹ã€‚æ—©é€Ÿã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰ã¯ã€(AirPassengerãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ï¼‰ä¸€éšå·®åˆ†ã‚‚ã¨ã‚‰ã‚“ã®ã‹ã¨å†·ç¬‘ã‚‚ã€‚xLSTMã¨ã‹ã€Vanilla Bayesian Optimization ã¨ã‹ã®åŸºç›¤æŠ€è¡“ã®é€²å±•ã‚‚ã‚ã‚Šã€ã—ã‚‰ã‚“ã‘ã©ã€‚ã€‚å–œé€£å·å…ˆç”Ÿç›£ä¿®ã®ã€Œç”ŸæˆAIã®è«–ç‚¹ã€ã¨ã„ã†ã®ã¯ã€æ—¥æœ¬ã®LLMã‚’ã‚ãã‚‹çŠ¶æ³ã‚’æŠŠæ¡ã«ã¯ã‚ˆã„ã‹ã‚‚ã€ãã‚Œã«ã—ã¦ã‚‚ã€Œæƒ…å ±å¤§èˆªæµ·æ™‚ä»£ã€ã¯ãªããªã£ãŸã“ã¨ã«ãªã£ãŸã®ã‹ï¼Ÿæœ€å¾Œã«ã€THE GUILDã®æ·±æ´¥ã•ã‚“ã®ã€ã€Œæƒ…å ±ãŒå¤šã™ãã¦é ­ãŒãƒ‘ãƒ³ã‚¯ã™ã‚‹ã®ã¯æ­£å¸¸ã§ã¯ãªã„ã€ã¨ã„ã†ã®ã¯ã€æ¿€ã—ãåŒæ„ã™ã‚‹ã€‚

- gpt2-chatbotãŒchatbot arenaã«å¾©æ´»ï¼Ÿ
	- https://x.com/alfredplpl/status/1787754701536325720
-  æœ€å¾Œã«KANã¯å‹ã¤ã®ã‹?MLPã«å¤‰ã‚ã‚‹ã¨ä¸»å¼µã•ã‚Œã‚‹KANã‚’è©¦ã™ by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/n1e592409a345?sub_rt=share_pb
	- Efficient-KANãŒæ‰‹ã£å–ã‚Šæ—©ãMNISTãŒè©¦ã›ãã†ã ã£ãŸã®ã§è©¦ã—ã¦ã¿ãŸ
	- ã¤ã¾ã‚Šã€åŒè¦æ¨¡ã®å ´åˆã€å­¦ç¿’ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯10å€ã«ãªã‚Šã€æ€§èƒ½å·®ã¯ç¸®ã‚“ã§ã„ãã¨ã„ã†çµæœã«ãªã£ãŸ
- KARAKURI LM 8x7B Chat v0.1ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼
	- https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-chat-v0.1
	- 1. æ±å·¥å¤§ã‹ã‚‰å‡ºã¦ã„ã‚‹Swallow-MX-8x7b-NVE-v0.1ã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚«ãƒ©ã‚¯ãƒªã®ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã—ãŸã€‚ï¼ˆåœ§å€’çš„æ„Ÿè¬ï¼‰ 
	- 2. å‰å›ã«ç¶šãã€å›½ç”£ã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã¯MT-Bench-jpã§æœ€é«˜æ€§èƒ½ã‚’æ›´æ–° 
	- 3. Active Parameteræ•° 13Bã§104Bã®Command R+ã‚’è¶…ãˆã€72Bã®Qwen 1.5ã«è¿«ã‚‹æ€§èƒ½ 
	- 4. AWS Trainiumã§ã®MoEãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¯AWSã®æ‹…å½“ã®æ–¹ã«ã‚‚ç¢ºèªã—ã¾ã—ãŸãŒã€ãŠãã‚‰ãä¸–ç•Œåˆã¨ã®ã“ã¨ã€‚ã‚³ãƒ¼ãƒ‰ã¯æŠ€è¡“ãƒ–ãƒ­ã‚°ã®è¨˜äº‹ã¨ã¨ã‚‚ã«è¿‘æ—¥å…¬é–‹äºˆå®šã€‚ 
	- 5. å‰å›ã«å¼•ãç¶šãã€SteerLMã«ã‚ˆã‚‹ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚’å®Ÿæ–½ã€‚å±æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆAPMï¼‰ã¯gemma 7bã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å…¬é–‹
-  CACTUS: Chemistry Agent Connecting Tool-Usage to Science
	- https://arxiv.org/abs/2405.00972
	- åŒ–å­¦ã®ãŸã‚ã®AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è«–æ–‡
	- åŒ–å­¦ã«é–¢ã™ã‚‹æ•°åƒã®è³ªå•ã¨å›ç­”ã‚’ä½œæˆã—æ§˜ã€…ãªã‚ªãƒ¼ãƒ—ãƒ³LLMã®æ€§èƒ½ã‚’æ¯”è¼ƒã€‚Gemma-7bã¨Mistral-7bã§é«˜ç²¾åº¦ã‚’å®Ÿç¾ã€ã¾ãŸç²¾åº¦ã‚’ç¶­æŒã—ã¤ã¤æ°‘ç”Ÿãƒ¬ãƒ™ãƒ«ã®ãƒãƒ¼ãƒ‰ã¸å°å…¥ãŒã§ããã†ã ã¨ã‚ã‹ã£ãŸãã†ã§ã™ã€‚
- Stack OverflowãŒOpenAIã¨ææºï¼Ÿ
	- https://x.com/ImAI_Eruel/status/1787670618961514627
	- ãŠãã‚‰ãChatGPTã®ç™»å ´ã«ã‚ˆã£ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ã®æ¸›å°‘ã¨ã„ã†ç‚¹ã§æœ€å¤§ã®è¢«å®³ã‚’è¢«ã£ãŸã®ã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®è³ªå•è§£ç­”ã‚µãƒ¼ãƒ“ã‚¹Stack Overflowãªã‚“ã§ã™ãŒï¼Œã“ã®åº¦OpenAIã¨ã®ææºãŒæ±ºã¾ã£ãŸã¨ã®ã“ã¨
- ç²¾åº¦ä¸Šã’ã‚ˆã†ã¨ã™ã‚‹ã¨è‡ªç„¶ã¨LLMã«é ¼ã‚‹ç®‡æ‰€æ¸›ã£ã¦ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆã«ãªã‚‹
	- https://x.com/mizchi/status/1787639942216327442
- KARAKURI LM 8x7B Chat v0.1 ã‚’ãŠè©¦ã—ä¸­
	- https://lm.karakuri.cc/
- ã€GPT-4ã¨åŒãƒ¬ãƒ™ãƒ«ã€‚ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã¯200åˆ†ã®1ã€‘æœ€å¼·LLMã€ŒDeepSeek-V2ã€ç™ºè¡¨
	- https://x.com/SuguruKun_ai/status/1787839473067376705
	- ã“ã®å­ãŒGPT-4ç›¸å½“ã¨è¨€ã†ã®ã¯ã‚ã£ã¦ãã†ã§çµæ§‹æ–‡æ‰ã‚‚ã‚ã‚‹ ã¤ã„ã§ã«å€«ç†é¢ã‚‚å‰²ã¨é«˜ã‚ãªæ„Ÿã˜ã§æ—¥æœ¬èªå‡ºåŠ›ã¯æ‚ªããªã„ çµæ§‹è‰¯ã„æ„Ÿã˜ã‹ã‚‚ï¼
- GrokãŒããŸï¼ä»Šã¯Xèª²é‡‘è€…é™å®š
	- https://x.com/hirochuu8/status/1787880221997515258
- iPad Pro 13 ã‚¤ãƒ³ãƒ Nano-textureã‚¬ãƒ©ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ä¾¡æ ¼ â‰’ KARAKURI LM 8x7bã®å­¦ç¿’ã«ã‹ã‹ã£ãŸã‚³ã‚¹ãƒˆã§ã™
	- https://x.com/txmy/status/1787859094034059669
- æ—¥è‹±ï¼è‹±æ—¥ç¿»è¨³ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦meta/Llama 3ã§ã¯google/Gemmaã‚’è¶…ãˆã‚‹äº‹ãŒå‡ºæ¥ãªã„
	- https://x.com/webbigdata/status/1787457498057933299
- Karasu-Mixtral-8x22B-v0.1ã®gguf
	- https://huggingface.co/mmnga/lightblue-Karasu-Mixtral-8x22B-v0.1-gguf
- lightblue-suzume-llama-3-8B-multilingualã®gguf
	- https://huggingface.co/mmnga/lightblue-suzume-llama-3-8B-multilingual-gguf
- Let's build a 100% local RAG app, featuring âŒ˜R, a self-hosted vector database, a fast embedding library & a reranker:
	- https://x.com/akshay_pachaar/status/1787824526010782053
- Reranker allows you to reorder the retrieved context (chunks), offering two key benefits:
	- https://x.com/akshay_pachaar/status/1787824694768648575
- Ollama v0.1.34 is out!
	- https://x.com/ollama/status/1787976537762856999
- A built-in planning agent for LlamaIndex landed in 0.10.34!
	- https://docs.llamaindex.ai/en/stable/examples/agent/structured_planner/
	- A key pattern in agents is the ability to plan. Breaking down a task into sub-tasks can make the task easier to execute.
- MicrosoftãŒè‡ªç¤¾ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒMAI-1ã€ã‚’é–‹ç™ºã—ã¦ã„ã‚‹
	- https://x.com/ImAI_Eruel/status/1787787401055908017
	- 5000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã®è©±ã‚‚ã‚ã‚Š,æœ¬å½“ãªã‚‰æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã§æœ€å¤§ãƒ¬ãƒ™ãƒ«.å¾Œå‡ºã—è€ƒæ…®ã§GPTã‚„Claudeè¶…ãˆã‚‚ã§ããã†ã‹
- DeepSeek-V2ã€236B ã®ã‚¯ã‚½ãƒ‡ã‚«ãƒ¢ãƒ‡ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰æ¨è«–æ™‚ã¯å®Ÿè³ª 21B ç›¸å½“ã® MoE ã‚‰ã—ã
	- https://x.com/izutorishima/status/1787775197057265925
- ã¬ã“ã¬ã“æ°ã€é€€è·ã—ã€æœ¬æ¥­ LLM ç„¡è·ã¸ã€
	- https://x.com/schroneko/status/1788148600171831406
- HachiML/Hachi-Alpaca by ã¯ã¡ã•ã‚“
	- https://huggingface.co/datasets/HachiML/Hachi-Alpaca
	- Mixtral 8x22B Instructã«ã‚ˆã‚‹æ—¥æœ¬èªåˆæˆãƒ‡ãƒ¼ã‚¿ã€28.9kã§ä¸€æ—¦å®Œäº†ã«ã—ã¾ã—ãŸã€‚v1.0_cleanedãŒç²¾æŸ»æ¸ˆã¿ã§ã™ã€‚
- Zennã®ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹ã‚’ã€æ¯æœAIãŒãƒ©ã‚¸ã‚ªé¢¨ã«ç´¹ä»‹ã—ã¦ãã‚Œã‚‹ã‚µãƒ¼ãƒ“ã‚¹ã‚’ã¤ãã‚Šã¾ã—ãŸ
	- https://zenncast-web.vercel.app/
- Announcing AlphaFold 3
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- AlphaFold2ã®æ™‚ç‚¹ã§ï¼Œã€Œãƒãƒ¼ãƒ™ãƒ«è³ãƒ¬ãƒ™ãƒ«ã€ã¨è¨€ã‚ã‚Œã¦æœ€çµ‚å½¢æ…‹ã‹ã¨æ€ã„ãã‚„ï¼Œã¾ã•ã‹ã®3ãŒå‡ºã¦ãã¾ã—ãŸ by ä»Šäº•ã•ã‚“
- Deeplearning.aiã‚ˆã‚Šç„¡æ–™ã®ã€Building Agentic RAGã€ãŒå…¬é–‹
	- https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/
- xLSTM: Extended Long Short-Term Memory
	- https://arxiv.org/abs/2405.04517
	- Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to SotA Transformers and State Space Models, both in performance and scaling.
- 4M Context Length Llama-3 8B (V0.1)
	- https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-4194k
- æ—¥æœ¬å­¦è¡“ä¼šè­°ç·ä¼šã§ã®è¬›æ¼”ã€Œæ—¥æœ¬ã®ç ”ç©¶ç«¶äº‰åŠ›ä½ä¸‹ã®å› æœæ¨è«–ã€ã®è³‡æ–™ãŒé¢ç™½ã„ï¼
	- https://www.scj.go.jp/ja/member/iinkai/sokai/siryo191-2-1.pdf
	- æ—¥æœ¬ã®ç ”ç©¶ç«¶äº‰åŠ›ä½ä¸‹ã®å› æœæ¨è«–
	- ã©ã‚Œã ã‘**ã€Œç ”ç©¶äººãƒ»æ™‚é–“å¯†åº¦ã€ï¼ˆè‰¯ãäººçš„ç ”ç©¶ç’°å¢ƒã®åºƒãŒã‚Šï¼‰**ã‚’ä¿ã¦ã‚‹ã‹ã«ã€ä»Šå¾Œã®æ—¥æœ¬ã®ç ”ç©¶ç«¶äº‰ãŒã‹ã‹ã£ã¦ã„ã‚‹ã€‚
- OpenAIãŒAIãƒ¢ãƒ‡ãƒ«ãŒã©ã®ã‚ˆã†ã«å‹•ä½œã™ã‚‹ã¹ãã‹ã‚’è¦å®šã™ã‚‹Model Specã‚’å…±æœ‰
	- https://openai.com/index/introducing-the-model-spec/
	- ãˆã€ã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã¦ChatGPTã®å†…éƒ¨æŒ™å‹•ã‚ã–ã‚ã–å…¬é–‹ã™ã‚‹ã®ãªãœï¼ŸEUçš„ãªã‚„ã¤ï¼Ÿ by æ·±æ´¥ã•ã‚“
	- ã“ã“ã‹ã‚‰ã€GPT-5ã®ç‰¹å¾´ãŒä½¿ã„å‹æ‰‹ãŒã‚ã‹ã‚‹ã‚‰ã—ã„
-  Google Colab ã§ å±æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã€€KARAKURI LM 7B APM v0.1 ã‚’è©¦ã™
	- https://note.com/npaka/n/ndb541c2cf03b?sub_rt=share_h
	- ã€ŒKARAKURI LM 7B APM v0.1ã€ã¯ã€å±æ€§äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã€ŒGemma 7Bã€ã®ãƒ•ã‚¡ã‚¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã«ãªã‚Šã¾ã™ã€‚
	- å±æ€§ã®å€¤ã¯ **0(æœ€ä½)ã€œ4(æœ€é«˜)** ã«ãªã‚Šã¾ã™ã€‚
- karakuri-lm-8x7b-chat-v0.1ã®ggufã‚ã‚Šã¾ã™
	- https://huggingface.co/mmnga/karakuri-lm-8x7b-chat-v0.1-gguf
	- imatrixã®ãƒ‡ãƒ¼ã‚¿ã¯TFMC/imatrix-dataset-for-japanese-llmã‚’ä½¿ç”¨ã—ã¦ä½œæˆã—ã¾ã—ãŸ
- ã‚°ãƒ¼ã‚°ãƒ«ãŒã€ç”Ÿç‰©å­¦ã«é©å‘½ã‚’ä¸ãˆãŸã‚¿ãƒ³ãƒ‘ã‚¯è³ªæ§‹é€ äºˆæ¸¬AIã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€ŒAlphaFold 3ã€ã‚’ç™ºè¡¨ï¼ˆãƒã‚¤ãƒãƒ£ãƒ¼è«–æ–‡ï¼‰
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã€DNAã€RNAã€å°åˆ†å­ãªã©ã»ã¼å…¨ã¦ã®ç”Ÿä½“åˆ†å­ã®æ§‹é€ ã¨ç›¸äº’ä½œç”¨ã‚’é«˜ç²¾åº¦ã«äºˆæ¸¬ ç”Ÿæˆ
	- AIã‚’æ”¯ãˆã‚‹transformerã¨æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®ç™ºå±•ã§ç”Ÿç‰©å­¦ã‚„å‰µè–¬ãŒåŠ é€Ÿ
- æ¯æ—¥ãŒã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã™ãã¦ã€ã‚‚ã¯ã‚„å…¨å®¹ãŒæŠŠæ¡ã§ããªã„ã€‚æ™‚äº‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¿½ã†ã ã‘ã§ãƒ‘ãƒ³ã‚¯ã™ã‚‹ä¸–ç•Œã¯ã€ã‚ã¾ã‚Šå¥å…¨ã§ã¯ãªã„ by æ·±æ´¥ã•ã‚“
	- https://x.com/fladdict/status/1788208163965305143
- æ—¥æœ¬èªç‰¹åŒ–ã®è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒJapanese Stable LM 2 1.6Bã€ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸ
	- https://ja.stability.ai/blog/japanese-stable-lm-2-16b
	- Japanese Stable LM 2 1.6Bï¼ˆJSLM2 1.6Bï¼‰ã¯16å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸæ—¥æœ¬èªã®å°å‹è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
- TimesFM by DeepMind
	- https://huggingface.co/google/timesfm-1.0-200m
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. 
- Uncertainty Quantification and Propagation in Atomistic Machine Learning
	- https://arxiv.org/abs/2405.02461
	- ä¸ç¢ºå®Ÿæ€§è©•ä¾¡ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡
	- æ©Ÿæ¢°å­¦ç¿’ã§ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„é ˜åŸŸã‚’äºˆæ¸¬ã™ã‚‹ã®ã¯å›°é›£ã§ã™ãŒã€ãã‚Œã‚’å…‹æœã™ã‚‹ä¸ç¢ºå®Ÿæ€§è©•ä¾¡ã®æ‰‹æ³•ãŒæ•™ç§‘æ›¸çš„ã«ã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã€‚ã¾ã æ±ç”¨çš„æ‰‹æ³•ã¯ãªããƒ‡ãƒ¼ã‚¿ã«ã‚ã£ãŸæ‰‹æ³•ã‚’ã†ã¾ãé¸æŠã™ã‚‹ã“ã¨ãŒå¤§åˆ‡ã¨ã®ã“ã¨ã€‚
- ã‚µãƒ ã‹ã‚‰ã€æœˆæ›œã«å¤§ããªç™ºè¡¨ãŒã‚ã‚‹ã¨ã€ã€
	- https://x.com/sama/status/1788989777452408943
	- not gpt-5, not a search engine, but weâ€™ve been hard at work on some new stuff we think people will love! feels like magic to me.
-  ã€ŒFugaku-LLMã€ã‚’å…¬é–‹
	- https://pr.fujitsu.com/jp/news/2024/05/10.html
	- æ¨ªç”°ã•ã‚“ã®ã¨ã“ã€
	- ã€ŒFugaku-LLMã€ã¯ã€Œå¯Œå²³ã€ã®13,824å°ã®è¨ˆç®—ãƒãƒ¼ãƒ‰ã‚’ç”¨ã„ã¦ã€ç´„4,000å„„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å­¦ç¿’ã—ãŸ13Bãƒ¢ãƒ‡ãƒ«ã§ã™
-  LangChain v0.2 ã®æ¦‚è¦ by npakaã•ã‚“
	- https://note.com/npaka/n/na9e629ebbd16?sub_rt=share_h
	- **ãƒ»langchain ã¨ langchain-community ã®å®Œå…¨ãªåˆ†é›¢  **
	- **ãƒ»ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä»˜ããƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**  
	- **ãƒ»ã‚ˆã‚Šæˆç†Ÿã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**  
	- **ãƒ»LLMã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æ¨™æº–åŒ–ã€ç‰¹ã«ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã«é–¢ã™ã‚‹æ”¹å–„**  
	- **ãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚µãƒãƒ¼ãƒˆã®å‘ä¸Š**  
	- **ãƒ»30ã‚’è¶…ãˆã‚‹æ–°ã—ã„ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸**
- æ—¥æœ¬èªé«˜é€ŸASR Kotoba-Whisper v1.1ã«ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã—ã¾ã—ãŸ
	- https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1
	- å¥èª­ç‚¹äºˆæ¸¬ã‚’æ”¹å–„ (raw CERã§å¤§å¹…ãªå‘ä¸Š) - Stable-tsã®çµ±åˆã«ã‚ˆã‚Šã€timestampã®äºˆæ¸¬ã‚’å‘ä¸Š - Long-form transcriptionã®äºˆæ¸¬å‘ä¸Š - å­¦ç¿’ãƒ»æ¨è«–ã‚³ãƒ¼ãƒ‰ã‚’å…¬é–‹:
- ibm-granite/granite-timeseries-ttm-v1
	- https://huggingface.co/ibm-granite/granite-timeseries-ttm-v1
	- TinyTimeMixers (TTMs) are compact pre-trained models for Multivariate Time-Series Forecasting, open-sourced by IBM Research. 
	- **With less than 1 Million parameters, TTM introduces the notion of the first-ever â€œtinyâ€ pre-trained models for Time-Series Forecasting.**
- Great, now we have some clean Llama 3 models (both 8B and 70B)
	- https://huggingface.co/ddh0/Meta-Llama-3-8B-Instruct-bf16-GGUF
	- Those minor bugs in llama.cpp has been resolved so should work at its full potential.
- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆãŒ1æœˆã«ç™ºè¡¨ã—ãŸSliceGPTã§ã¯ã€LLMã®ã‚¦ã‚¨ã‚¤ãƒˆã‚’åœ§ç¸®ã§ãã¡ã‚ƒã†ã‚‰ã—ã„ã€‚
	- https://x.com/umiyuki_ai/status/1789128885558546881
	- ã‚¦ã‚¨ã‚¤ãƒˆã®å„è¡Œåˆ—ã‚’æ¬¡å…ƒæ•°æ¸›ã‚‰ã—ãŸè¡Œåˆ—ã«ç½®ãæ›ãˆã¡ã‚ƒã†ã‚“ã ã£ã¦ã€‚ã“ã‚Œã§ãƒ‘ãƒ©æ•°ã‚’25%ã¾ã§å‰Šã‚Œã¦ï¼ˆã¤ã¾ã‚Š52.5Bã«ãªã‚‹ï¼Ÿï¼‰ã€Llama2-70Bã®å ´åˆã¯æ€§èƒ½ã®ä½ä¸‹ã¯1%ã ã‘ã§æ¸ˆã‚€ã‚‰ã—ã„
- Google/TimesFMã¯ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‹ã‚‰å¾®å¦™ã ã—
	- https://x.com/kyo_takano/status/1789150904102613131
	- ä¸€éšå·®åˆ†ã‚’å–ã‚‰ãšã«éå®šå¸¸éç¨‹ã®ã¾ã¾äºˆæ¸¬å™¨ã«çªã£è¾¼ã‚€; 
	- Transformersã‚’ä½¿ã„ãŸã„ãŒãŸã‚ã«è¤‡æ•°æ™‚ç‚¹ã‚’å˜ä¸€ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦åŸ‹ã‚è¾¼ã‚€ãƒ»äºˆæ¸¬ã™ã‚‹; etc.ï¼‰ã€
	- å¤å…¸çš„ãªçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦éƒ¨åˆ†çš„ã«ã—ã‹ä¸Šå›ã£ã¦ãªã„ã‚“ã ã‚ˆã­
- Ollamaã«ã€MLXå¯¾å¿œãã‚‹ï¼Ÿ
	- https://x.com/m_sigepon/status/1789233089945981319
-  Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals
	- https://jamanetwork.com/journals/jama/fullarticle/2818746?utm_source=twitter&utm_campaign=content-shareicons&utm_content=article_engagement&utm_medium=social&utm_term=051024
	- åŒ»å­¦è¦³å¯Ÿç ”ç©¶ã§å› æœé–¢ä¿‚ã‚’ç¤ºã™ãŸã‚ã«ã¯ã©ã†ã™ã‚‹ï¼Ÿ6ã¤ã®æ¡ä»¶ã‚’ç¤ºã—ã¦ã€ã“ã‚Œã‚’æº€ãŸã—ã¦ã„ã‚Œã°å› æœé–¢ä¿‚ã‚’è¨€ã£ã¦ã‚‚ã„ã„ã‚“ã˜ã‚ƒãªã„ï¼Ÿã¨ã„ã†æè¨€ã€‚
- google/timesfm-1.0-200m
	- https://huggingface.co/google/timesfm-1.0-200m
	- Google released a decoder-only "foundation" time series model on
	- Trained on a corpus of 100B real world time-points from Google Trends and pageviews from Wikipedia!
- ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã¨æ©Ÿæ¢°å­¦ç¿’ã€ã«ã¯KANã§è©±é¡Œæ²¸é¨°ä¸­ã®ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•ï½¥ã‚¢ãƒ¼ãƒãƒ«ãƒ‰ã®è¡¨ç¾å®šç†ãŒæ²è¼‰ã•ã‚Œã¦ã„ãŸã€‚
	- https://x.com/bebebeBayes/status/1788900859570700291
- å¤§å±‹é›„è£•ã€Œä¿¡ç”¨ãƒ»ä¿¡é ¼ãƒ»ä¿¡è¨— â€”è²¬ä»»ã¨èª¬æ˜ã«é–¢ã™ã‚‹æ¦‚å¿µæ•´ç†â€•ã€
	- https://x.com/rmaruy/status/1789193304808296841
	- AIã®èª¬æ˜å¯èƒ½æ€§ï¼è²¬ä»»ã«ã¤ã„ã¦ã€ã‚¦ã‚£ãƒˆã‚²ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³ã®åŸå› ï¼ç†ç”±ã®åŒºåˆ¥ã‹ã‚‰ç´è§£ãã€ãƒ—ãƒ­ã‚»ã‚¹ã®é€æ˜æ€§ã ã‘ã§ãªãç­”è²¬æ€§ãŒå•é¡Œã«ãªã‚‹å ´é¢ãŒã©ã‚“ãªã¨ãã‹ã‚’è­°è«–ã€‚ã“ã®ä¸Šãªãæ˜æ™°ã€‚
- lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- https://huggingface.co/lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- rinnaæ§˜ã®llama-3-youko-8bã‚’å°‘æ•°ã®è‹±æ—¥å¯¾è¨³ãƒ‡ãƒ¼ã‚¿+LoRAã§SFTã—ã¦ã¿ã¾ã—ãŸ
-  Post Llama 3 depression
	- https://www.reddit.com/r/LocalLLaMA/comments/1colmeb/post_llama_3_depression/
	- Llama3ã®å¾®èª¿æ•´ãƒ¢ãƒ‡ãƒ«ã¯è‰²ã€…å‡ºãŸã‘ã©ä»Šã‚“ã¨ã“ã©ã‚Œã‚‚ã‚¢ã‚«ãƒ³ã¨ã„ã†è©±ã€‚åŸå› ã¯ã‚ˆãåˆ†ã‹ã‚‰ã‚“ã‘ã©ã‚‚ã†ä»Šã¾ã§ã®å¾®èª¿æ•´ã®ã‚„ã‚Šæ–¹ã¯æ™‚ä»£é…ã‚Œãªã®ã‹ã‚‚ã—ã‚Œãªã„ã€‚å°‘ãªãã¨ã‚‚Llama2ã¨ã¯å‹æ‰‹ãŒé•ã†ã‚‰ã—ã„
- ã€Œãƒ­ãƒ¼ã‚«ãƒ«LLMã¯ã“ãƒ¼ã‚„ã£ã¦ä½¿ã†ã®ã€ã‚’æ›´æ–°ã—ã¾ã—ãŸ
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	-   ä»¥ä¸‹ã‚’è¿½åŠ : 
		- å‰æçŸ¥è­˜ã®ç¢ºèª 
		- ç‰¹æ®Šãƒˆãƒ¼ã‚¯ãƒ³ã«ã‚ˆã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ 
		- å°¤åº¦é–¢æ•°ã¨ã—ã¦ã®åˆ©ç”¨
- Difyã®å‹¢ã„ãŒã™ã”ã„ã€‚LangChainã‚„Flowiseã€Llama Indexã‚’æŠ‘ãˆã¦LLMãƒ„ãƒ¼ãƒ«4é€±é–“ã§1ä½ã«
	- https://x.com/kyutaro15/status/1789054552638943495
- You can now generate production-ready prompts in the Anthropic Console.
	- https://x.com/AnthropicAI/status/1788958483565732213
- Vanilla Bayesian Optimization Performs Great in High Dimensions
	- https://arxiv.org/abs/2402.02229
	- ãƒãƒ‹ãƒ©ã®ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ãŒé«˜æ¬¡å…ƒã§ã‚‚å¤§æ´»èº
	- ã“ã‚Œã¾ã§é«˜æ¬¡å…ƒã¯å‘ªã„ã®é ˜åŸŸã¨æ€ã‚ã‚Œã¦ã„ãŸãŒã€é©åˆ‡ãªä»®å®šã‚’è¨­ã‘ã‚‹ã ã‘ã§æœ€å…ˆç«¯ã®æ‰‹æ³•ã‚’åœ§å€’ã™ã‚‹æ€§èƒ½ãŒå‡ºã›ã‚‹ã“ã¨ãŒåˆ¤æ˜
- DeepLearningAIã‹ã‚‰ã€ä»Šåº¦ã¯LangChainã®CEOã®è¬›ç¾©
	- Check out the short course Functions, Tools, and Agents, taught
	- https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/
- "MOMENT: A Family of Open Time-series Foundation Models"
	- https://moment-timeseries-foundation-model.github.io/
	- has been accepted for the ICML 2024! On this occasion, we are open-sourcing it, together with the model weights and dataset!
- ç”ŸæˆAIã®è«–ç‚¹
	- https://www.seikyusha.co.jp/bd/isbn/9784787235374/
	- å–œé€£å·å…ˆç”Ÿã¾ã ã„ãã¦ãŸã®ã‹ï¼Ÿ
	- æ—¥æœ¬å­¦è¡“ä¼šè­°ãŒå®Ÿæ–½ã—ã€éå»æœ€å¤šã®å‹•å“¡ã‚’é”æˆã—ãŸã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ã€Œç”ŸæˆAIã®èª²é¡Œã¨ä»Šå¾Œã€ã®æ›¸ç±åŒ–ã§ã‚ã‚‹
- 

## 5/7

ï¼§ï¼·ã§ã€é ­ãŒã¼ã‘ã¦ã„ã‚‹ã®ã‹ã€X(æ—§twitter)ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒå¤‰ã‚ã£ãŸã®ã‹ã€ãŠã™ã™ã‚ã«å‡ºã¦ãã‚‹ãƒ„ã‚¤ãƒ¼ãƒˆãŒå…ˆé€±ã¨ã‹ã¶ã£ã¦ã„ã‚‹æ°—ãŒã™ã‚‹ã€‚Xã®ç”Ÿæˆï¼¡ï¼©ã‚’ä½¿ã£ãŸæ–°ã‚µãƒ¼ãƒ“ã‚¹ã€Œã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚ºã€ã®å±•é–‹ã¨é–¢ä¿‚ã‚ã‚‹ã®ã‹ï¼Ÿã€‚ä»Šé€±ã¯çªç„¶ã§ã¦ããŸè¬ã®gpt2-chatbotãŒé¢ç™½ã‹ã£ãŸã€gpt2ã¨åå‰ãŒã‚ã‚‹ã‚‚ã®ã®ã€GPT-4.5ã‹GPT-5ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ†ã‚¹ãƒˆã‹ã¨ã„ã†è©±ã§æŒã¡åˆ‡ã‚Šã ã£ãŸï¼ˆChatbot Arenaã‹ã‚‰ã¯æ¶ˆãˆãŸã€‚ã€‚ï¼‰ã€è©•ä¾¡ã§ããŸäººã«ã‚ˆã‚‹ã¨ã€ç›¸å½“ã™ã”ã„æ€§èƒ½ã‚‰ã—ã„ã€‚Swallow-MS 7Bã®æ–°ã—ã„instructãƒ¢ãƒ‡ãƒ«ã€ã•ã£ããElyzaTasks100ã§è©•ä¾¡ã•ã‚Œã€ã¡ã‚‡ã£ã¨å¾®å¦™ãªçµæœã«ã€‚ä¸€æ–¹ElyzaTasks100ã§ã®è©•ä¾¡ã«ã‚ˆã‚‹ã¨ã€Qwen1.5ã¯ã‹ãªã‚Šå„ªç§€ã ã‘ã©æ™‚ã€…æ—¥æœ¬èªã«é›£ã‚ã‚Šã¨ã®ã“ã¨ã€‚Domingosæ°ã®AIã®èƒ½åŠ›ã®ç™ºå±•ãŒã‚µãƒã£ã¦ã„ã‚‹ã¦ã„ã†è©±ã¯ã€ï¼ˆãã‚‚ãã‚‚ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ã£ãŸï¼‰äººé–“ã®èƒ½åŠ›ãŒAIã®é€²åŒ–ã‚’å¾‹é€Ÿã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã€‚ãã‚Šã‚ƒã€äººé–“ã‚’è¶…ãˆã‚‹ã®ã¯äººé–“ã®ãƒ‡ãƒ¼ã‚¿ã§ã¯ç„¡ç†ã ã€è¶…ãˆãŸã¨ã“ã‚ã§äººé–“ã«ã¯ã‚ã‹ã‚‰ãªã„ã¨ã„ã†ã®ã¯ãã†ã‹ã‚‚ã€‚BCGã®å£²ä¸Š20%ãŒç”ŸæˆAIé–¢é€£ã¨ã®ã“ã¨ã€ã‚³ãƒ³ã‚µãƒ«ã¯ãªããªã‚‰ãªã„ã€é‡‘ã®å„²ã‘æ–¹ãŒå¤‰ã‚ã‚‹ã ã‘ã€‚ã€Œçµ±è¨ˆçš„ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã€å…¨æ–‡ãŒãƒ—ãƒ¬å…¬é–‹ã•ã‚ŒãŸã¨ã®ã“ã¨ã€ã‚ã‚Œã¯ï¼ã¨æ€ã†äººã¯ãœã²ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã‚’ã€‚Ollamaã‚’ä½¿ã£ãŸãƒ­ãƒ¼ã‚«ãƒ«LLMã®åˆ©ç”¨ä¾‹ã‚‚ãã£ã¨å¢—ãˆãŸã€ã‚‚ã¯ã‚„RAGã¯èª°ã§ã‚‚ã§ãã‚‹ã€ã•ã‚‰ã«ReAct Agentã¨ã‹ã€Function Callingã¨ã‹ã€ã‚ˆã‚Šã‚€ã¤ã‹ã—ã„ã‚¿ã‚¹ã‚¯ã‚€ã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã€æ°—ã®ã›ã„ã‹Llama3ã‚„phi3ãŒä½¿ã‚ã‚Œã‚‹ä¾‹ãŒå¤šã„ã‚ˆã†ãªã€‚Kolmogorovâ€“Arnold Networksã€æ–°ã—ã„ç”ŸæˆAIå‘ã‘ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼Ÿç‰¹ç•°å­¦ç¿’ç†è«–ï¼ˆæ¸¡è¾ºãƒ™ã‚¤ã‚ºç†è«–ï¼‰ã‚’ç™ºå±•ã•ã›ãŸå±€æ‰€å­¦ç¿’ä¿‚æ•°ã¨ã„ã†æ–°ã—ã„æ¦‚å¿µã‚‚æ°—ã«ãªã‚‹ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ã¨ã‚‚é–¢ä¿‚ã‚ã‚‹ã¨ã‹ã€‚ãã‚Œã«ã—ã¦ã‚‚ã€NVIDIA CEOã‚¸ã‚§ãƒ³ã‚¹ãƒ³ãƒ»ãƒ•ã‚¡ãƒ³æ°ãŒã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«ã‹ã‚‰ã®æ­Œé…ä¿¡ã«æ··ã–ã‚‹å‹•ç”»ã€ã‹ã‚ã„ã„ãªã‚ï¼ˆã„ã‚„ï¼£ï¼¥ï¼¯ãŒã ã‚ˆï¼‰ã€‚ã€Œãƒ­ãƒ¼ã‚«ãƒ«LLMã¯ã“ãƒ¼ã‚„ã£ã¦ä½¿ã†ã®ã€ã¯å‚è€ƒã«ãªã‚‹ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMãªã‚‰ã„ã‚ã„ã‚ã‚„ã‚Šæ”¾é¡Œãªã‚“ã ãªã€‚ï¼¡ï¼©ã‚»ã‚¤ãƒ•ãƒ†ã‚£ã§ã¯ã€NISTã‹ã‚‰ã€ç”Ÿæˆï¼¡ï¼©å‘ã‘ã®ãƒªã‚¹ã‚¯ç®¡ç†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒç™ºè¡¨ã€æ—¥æœ¬ã®AISIã¨ã®é€£æºã‚‚é€²ã‚€ã€‚AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®åŒ…æ‹¬çš„ãªã‚µãƒ¼ãƒ™ã‚¤ã€ã€ŒAIã«ã‚ˆã‚‹çµ¶æ»…ãƒªã‚¹ã‚¯ã®è»½æ¸›ã€ã ã¨ã€‚rinnaã‹ã‚‰Llama 3 8Bã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒLlama 3 Youko 8Bã€ã‚’å…¬é–‹ã€NIIã‹ã‚‰ã€ŒLLM-jp-13B v2.0ã€ã‚’æ§‹ç¯‰ã¨ã‹ã€é ‘å¼µã‚Œæ—¥æœ¬å‹¢ã€‚ã†ã¿ã‚†ãã•ã‚“ãŒè¨€ã†ã‚ˆã†ã«ã€é€²åŒ–å‹ã®LLMã®ãƒãƒ¼ã‚¸Mergekit-Evolveã£ã¦ã®ã¯æœ¬å½“ã«ã™ã”ã®ã„ã‹ï¼Ÿï¼ŸLangChainã®ï¼”ã¤ã®RAGå‘ã‘chainã®æ¯”è¼ƒã‚‚åœ°å‘³ã«å½¹ã«ç«‹ã¤ã€‚ãƒ­ãƒ¼ã‚«ãƒ«LLMç³»ã§ã¯ã€è‡ªä½œå°èª¬ã‚’LLMã§è©•ä¾¡ã•ã›ã¦ã„ã‚‹ã²ã¨ãŒã€ command-r-plus-Q4_K_Mã‚’çµ¶è³›è©•ä¾¡ã€å®Ÿä½œæ¥­ã«åŸºã¥ãè©•ä¾¡ã¯å°Šã„ã€‚ChatGPTæ±å¤§å…¥è©¦ã«æŒ‘ã‚€ã‚‚ã€Œä¸åˆæ ¼ã€ã®è¨˜äº‹ï¼ˆæ—¥çµŒï¼‰ã€ã•ã£ãããƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒæ‚ªã„ã¨ã€ã„ã‚„è§£ã‘ãŸã‚ˆã€ã¨ã®çªã£è¾¼ã¿ãŒã€æ¬¡ã€…ã¨ã€‚ã€‚

- LangChainã‚’ç”¨ã„ãŸ4ç¨®é¡ã®RAGè³ªå•å¿œç­”chainã®å®Ÿè£…ã¨æ€§èƒ½æ¯”è¼ƒï½œ
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	- stuff chainã€map reduce chainã€map rerank chainã€refine chain
	- å¿œç­”é€Ÿåº¦ : å‘¼ã³å‡ºã—å›æ•°ãŒ1å›ã®stuffã¯ã€Œé€Ÿã„ã€, nå›ã§ã™ãŒå„æ–‡æ›¸ã«å¯¾ã™ã‚‹LLMå‘¼ã³å‡ºã—ã‚’ä¸¦åˆ—åŒ–ã§ãã‚‹mapç³»2ç¨®ã¯ã€Œæ™®é€šã€, nå›ã‹ã¤ä¸¦åˆ—åŒ–ãŒã§ããªã„refineã¯ã€Œé…ã„ã€ã¨ã—ã¦ã„ã¾ã™ã€‚
	- é©ã—ã¦ã„ã‚‹æ–‡æ›¸ç‰¹å¾´
		- stuffãƒ»map reduce : æ–‡æ›¸å…¨ä½“ã‚’1æ®µéšã¾ãŸã¯2æ®µéšã§LLMã«å…¥åŠ›ã™ã‚‹ãŸã‚, æ–‡æ›¸å…¨ä½“ã«é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹å ´åˆã«ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚
		- map rerank : æ–‡æ›¸ã®ä¸€éƒ¨ã®ã¿ã®å›ç­”ã‹ã‚‰æœ€è‰¯ã®å›ç­”ã‚’é¸ã¶ãŸã‚, ä¸€éƒ¨ã®ã¿ã«é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹å ´åˆã«ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚
		- refine : ä¸€éƒ¨ã®ã¿ã®å›ç­”ã‚’è¤‡æ•°å›å†èµ·çš„ã«å‘¼ã³å‡ºã™ãŸã‚, é‡è¦ãªæƒ…å ±ãŒæ–‡æ›¸ã®å…¨ä½“ã§ã‚‚ä¸€éƒ¨ã§ã‚‚å¯¾å¿œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚
- Mergekit-Evolveã®ãƒ†ã‚¹ãƒˆã§è©¦ã—ã«ä½œã£ãŸãƒ¢ãƒ‡ãƒ«ã€Japanese-Chat-Umievo-itr001-7bã‚’ElyzaTasks100ã§è©•ä¾¡ã—ã¦ã¿ãŸã‚‰å¹³å‡3.57ç‚¹ã‚’å©ãå‡ºã—ãŸã€€ by ã†ã¿ã‚†ãã•ï½
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- 7Bãƒ¢ãƒ‡ãƒ«ãªã®ã«35Bãƒ‘ãƒ©ã®Command Rã‚’è¶…ãˆã¦ã¾ã™ï¼é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å¨åŠ›æã‚‹ã¹ã—ï¼ï¼
- Swallow 7B, 13B, 70Bã€ãŠã‚ˆã³Swallow-MS 7Bã®æ–°ã—ã„instructãƒ¢ãƒ‡ãƒ«ï¼ˆSwallow-*-instruct-v0.1ï¼‰ã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- https://huggingface.co/collections/tokyotech-llm/swallow-ms-instruct-662957bf88d016c69ae0e633
	- ã‚ã¾ã‚Šé‡è¦–ã—ã¦ã“ãªã‹ã£ãŸæŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚„ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¿œç­”ã®æ”¹å–„ã«å–ã‚Šçµ„ã¿ã€MT-Benchã§éå»ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¢ºèªã—ã¾ã—ãŸ
- Swallow-MS-7B-Instruct-V0.1ã‚’ElyzaTasks100ã§è©•ä¾¡ã—ãŸã‚‰å¹³å‡2.82ç‚¹ã ã£ãŸã€‚ç¾ç’°å¢ƒã§ã¯ã‚‚ã¯ã‚„å¤§ã—ãŸäº‹ãªã„ã¨è¨€ã‚ã–ã‚‹ã‚’å¾—ãªã„ã€‚ã§ã‚‚ChatNTQã‚ˆã‚Šã¯ã‹ãªã‚Šå¼·ã„ã¨ã„ã†äº‹ã¯ChatVectorã‚’è¶³ã™ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æœ‰èƒ½ã‹ã‚‚ã—ã‚Œãªã„
	- https://x.com/umiyuki_ai/status/1783911959789969816
- ã€Appleã®æ–°ã—ã„OpenELMãƒ¢ãƒ‡ãƒ«ã‚’MLX LMã§ã€‘  512ãƒˆãƒ¼ã‚¯ãƒ³ã€340Token/S
	- https://x.com/hokazuya/status/1783808939773304957
	- ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã“ã®æ€§èƒ½ã¯Phi-3ã‚„Llama3ã®7Bãªã©è¦‹ã¦ããŸãŒMacå˜ä½“ã§ã“ã‚Œã¯ã‚¹ã‚´ã™ãã‚‹ã€‚
- Domingosæ°ã€AIã®èƒ½åŠ›ãŒäººé–“ãƒ¬ãƒ™ãƒ«ã§é£½å’Œã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¦ã„ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹
	- https://x.com/pmddomingos/status/1783956607552176422
	- ã‚€ã—ã‚ã“ã‚Œã‚‰ã®ã‚¿ã‚¹ã‚¯ã§120%ã‚„200%ã‚’æœ‰æ„å‘³ã«è­°è«–ã§ãã‚‹ã®ã‹ã¨ã„ã†æ–¹ãŒæ°—ã«ãªã‚‹ã€‚ã¨ã„ã†æ„å‘³ã§ã€Domingosæ°ã®æ„å›³ã¨ç•°ãªã‚‹æ„å‘³ã§è¶…çŸ¥èƒ½åˆ°æ¥ãƒ“ã‚¸ãƒ§ãƒ³ã¸ã®ç–‘ç¾©ã«ãªã£ã¦ã„ã‚‹ã€‚
	- https://x.com/rmaruy/status/1784154638390104188
- ã€éšæ™‚æ›´æ–°ã€‘ä¸»è¦ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè¡¨
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- å±…åˆã‚ã›ãŸæ­Œé…ä¿¡ã«æ··ã–ã‚‹ NVIDIA $NVDA CEO ã‚¸ã‚§ãƒ³ã‚¹ãƒ³ãƒ»ãƒ•ã‚¡ãƒ³
	- https://x.com/woodstockclub/status/1784179786082128351
-  é«˜é€ŸAIãƒãƒƒãƒ—ã§è©±é¡Œã®Groqã®APIã‚’Streamlitã§ä½¿ã†æ–¹æ³•
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
- ã€Symbol-to-Languageã€
	- https://x.com/ai_database/status/1784581982053347542
	- LLMã®ã‚¿ã‚¹ã‚¯ã«ãŠã„ã¦ã€Œè¨˜å·ã‚’è‡ªç„¶è¨€èªãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€ã“ã¨ã§æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§ç²¾åº¦ãŒä¸ŠãŒã‚‹ç¾è±¡ãŒå ±å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚
	- å®Ÿé¨“ã§ã¯ã€ç‰©æ€§äºˆæ¸¬ã€è¡¨ã®ç†è§£ã€ãƒ„ã‚¤ãƒ¼ãƒˆåˆ†æãªã©ã§åŠ¹æœãŒå‡ºã¦ã„ã¾ã™
- BCGã®å£²ä¸Š20%ãŒç”ŸæˆAIé–¢é€£ã§ã€2026å¹´ã¾ã§ã«40%ã«ã¾ã§å¢—ãˆã‚‹ã¨ã‹
	- https://www.ft.com/content/33dfaec4-b5e7-4eca-a869-cdd33d447e65
- lama 3 degrades more than Llama 2 when quantized.
	- https://x.com/rohanpaul_ai/status/1784889182558539917
- gpt2-chatbotã¨å‘¼ã°ã‚Œã‚‹è¬ã®ãƒ¢ãƒ‡ãƒ«
	- https://x.com/bioshok3/status/1784972619957346703
	- Chatbot arena ã§Claude3 opusã‚„GPT-4 Turboã«åŒ¹æ•µã™ã‚‹ã¨ã‹ã—ãªã„ã¨ã‹è¶…ãˆã¦ã‚‹è¶…ãˆã¦ãªã„è¨€ã‚ã‚Œä»Šå°‘ã—è©±é¡Œã«ãªã£ã¦ã„ã‚‹
- ReAct Agent with Function Calling | Open Source Gemma LLM | Ollama | Lan...
	- https://www.youtube.com/watch?v=exYUJcz4uZs
- llama-2-13b-retrievalqa.ipynb - Colab
	- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/llm-field-guide/llama-2/llama-2-13b-retrievalqa.ipynb#scrollTo=JPdQvYmlWmNc
- crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
	- https://huggingface.co/crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
- react-agent-with-function-calling-ollama-langsmith.ipynb
	- https://github.com/Ashufet/LangChain_ReAct-Agent-with-Function-Calling_Ollama-Gemma-LLM_LangSmith/blob/main/react-agent-with-function-calling-ollama-langsmith.ipynb
- Google announces Med-Gemini, a family of Gemini models fine-tuned for medical tasks!
	- https://x.com/iScienceLuvr/status/1785247498744778886
- ã€Œçµ±è¨ˆçš„ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã€ã®å…¨ä½“ã®åŸç¨¿(4ç« ä»¥å¤–)ã®Î²ç‰ˆã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- http://chasen.org/~daiti-m/textmodel/
- Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities
	- https://arxiv.org/abs/2404.17790
	- æ±å·¥å¤§ã®LLMã€Swallowã®è«–æ–‡ãŒarXivã«å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã­ã€‚
	- æ—¥æœ¬èªã®ç¶™ç¶šäº‹å‰å­¦ç¿’ã«ã¤ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã‚„èªå½™æ‹¡å¼µã€ãƒ‘ãƒ©ãƒ¬ãƒ«ã‚³ãƒ¼ãƒ‘ã‚¹ã®å½±éŸ¿ã«ã¤ã„ã¦å¤§è¦æ¨¡ã‹ã¤ç³»çµ±çš„ã«çŸ¥è¦‹ã‚’æä¾›ã—ã¦ã„ã‚‹ç ”ç©¶ã§ã€å‹‰å¼·ã«ãªã‚Šã¾ã™
- gpt2-chatbotã¯æœ¬å½“ã«ãƒ¢ãƒ‡ãƒ«åã ã€‚ãã†HFã®CTOãŒã„ã¾openai-communityã‹ã‚‰ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã—ã¦ã„ã‚‹ã¨æ€ã‚ã‚Œã‚‹ã€‚
	- https://x.com/alfredplpl/status/1785170960251007266
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒLLM-jp-13B v2.0ã€ã‚’æ§‹ç¯‰
	- https://www.nii.ac.jp/news/release/2024/0430.html
	-  NIIä¸»å®°LLMå‹‰å¼·ä¼šï¼ˆLLM-jpï¼‰ãŒã€ŒLLM-jp-13Bã€ã® å¾Œç¶šãƒ¢ãƒ‡ãƒ«ã¨ãã®æ§‹ç¯‰ã«ä½¿ç”¨ã—ãŸå…¨ãƒªã‚½ãƒ¼ã‚¹ã‚’å…¬é–‹
- Qwen1.5ã‚·ãƒªãƒ¼ã‚ºã‚’ä¸€é€šã‚ŠElyzaTasksã§è©•ä¾¡ã—ã¦ã¿ãŸ
	- https://x.com/umiyuki_ai/status/1785272618595262646
	- ã‚„ã£ã±ã‚ŠQwen1.5ã¯ã‹ãªã‚Šå„ªç§€ã€‚7Bãƒ¢ãƒ‡ãƒ«ã¯Llama3-8Bã®ãƒãƒ§ã‚¤ä¸‹ã€‚14Bãƒ¢ãƒ‡ãƒ«ã¯35Bã®Command Rã‚’è¶…ãˆã¦ã‚‹ï¼
- AISIã¨ç±³å›½NISTã¯ã€æ—¥æœ¬ã®ã€ŒAIäº‹æ¥­è€…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ã¨NISTã®ã€ŒAIãƒªã‚¹ã‚¯ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯(RMF)ã€ã®ã‚¯ãƒ­ã‚¹ã‚¦ã‚©ãƒ¼ã‚¯ã®ç¬¬ä¸€å¼¾ã¨ã—ã¦ç”¨èªã«é–¢ã™ã‚‹ã€Œã‚¯ãƒ­ã‚¹ã‚¦ã‚©ãƒ¼ã‚¯1ã€ã‚’å…¬è¡¨ã—ã¾ã—ãŸã€‚
	- https://aisi.go.jp/2024/04/30/ai_rmf_crosswalk1_news/
- è¬ã®é«˜æ€§èƒ½AIãƒ¢ãƒ‡ãƒ«ã€Œgpt2-chatbotã€ãŒChatbot Arenaã«ç™»å ´ã€GPT-4.5ã‹GPT-5ãªã®ã§ã¯ãªã„ã‹ã¨è©±é¡Œã«
	- https://gigazine.net/news/20240430-lmsys-chatbot-arena-gpt2-chatbot/
	- æ—¥æœ¬ã®æ­´å²ã«ã¤ã„ã¦ã‚‚ã€ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®å¤šã„Claude 3 Opusã¨æ¯”è¼ƒã—ã¦ã€é¥ã‹ã«å„ªã‚ŒãŸå›ç­”ã€‚è«–ç†çš„ãªè€ƒå¯Ÿã«ã¤ã„ã¦ã‚‚ãƒ¬ãƒ™ãƒ«ãŒé«˜ã„ã€‚
- è‡ªä½œå°èª¬ã‚’LLMã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã•ã›ã¦ã¿ã‚‹ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«4ãƒ¢ãƒ‡ãƒ«ã€ã‚µãƒ¼ãƒ“ã‚¹å‹3ãƒ¢ãƒ‡ãƒ«ï¼‰
	- https://note.com/kohya_ss/n/nfcdfd6de8790
	-  command-r-plus-Q4_K_M: æ¥µã‚ã¦é«˜ã„ç†è§£åŠ›ã¨è¦ç´„åŠ›ã‚’ç¤ºã—ã€ä½œå“ã®ä¼ç·šã‚„ç™»å ´äººç‰©ã®ç†è§£ã‚‚çš„ç¢ºã ã£ãŸã€‚æ–‡ç« ã¯èª­ã¿ã‚„ã™ãæ´—ç·´ã•ã‚Œã¦ãŠã‚Šã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã®ä¸­ã§æœ€ã‚‚å„ªç§€ãªæ€§èƒ½ã‚’ç¤ºã—ãŸã€‚å°èª¬ã®ãƒ†ãƒ¼ãƒã‚’æ·±ãç†è§£ã—ã€é©åˆ‡ãªæ‰¹è©•ã‚’è¡Œã£ã¦ã„ã‚‹ã€‚
- US NIST publishes 1st draft of its "AI Risk Management Framework: Generative AI Profile." 
	- https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf
- rinnaã¯Llama 3 8Bã®æ—¥æœ¬èªç¶™ç¶šäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã€ŒLlama 3 Youko 8Bã€ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚
	- https://huggingface.co/rinna/llama-3-youko-8b
- KAN: Kolmogorovâ€“Arnold Networks
	- https://arxiv.org/abs/2404.19756
	- https://github.com/KindXiaoming/pykan
	- Proposes an alternative to MLP that outperforms in terms of accuracy and interpretability
	- é‡ã¿ã‚’å­¦ç¿’ã•ã›ã‚‹ã®ã§ã¯ãªãã€ã‚¨ãƒƒã‚¸ä¸Šã«é…ç½®ã—ãŸæ´»æ€§åŒ–é–¢æ•°ã‚’å­¦ç¿’ã•ã›ã‚‹(ã‚¨ãƒƒã‚¸ã®é‡ã¿ã¯1ã§å›ºå®š)æ–°ã—ã„ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ææ¡ˆã€‚â€¦
	- ã¡ãªã¿ã«ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚³ãƒ«ãƒ¢ã‚´ãƒ­ãƒ•-ã‚¢ãƒ¼ãƒãƒ«ãƒ‰è¡¨ç¾å®šç†ã®è©±é¡Œã«é–¢ã—ã¦ã¯ï¼Œãã‚“ãªã«æ–°ã—ã„ã‚‚ã®ã§ã¯ãªãï¼Œçµæ§‹æ˜”ã‹ã‚‰å‡ºã¦ã„ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã™(ä»Šäº•ã•ã‚“)
- RAGã®Gï¼ˆGenerationï¼‰ã€ã¤ã¾ã‚Š"ç”Ÿæˆ"ã¯æœ¬å½“ã«å¿…è¦ãªã®ã‹ï¼Ÿ
	- https://x.com/Nurruttan/status/1785853289034350622
- AI Alignment: A Comprehensive Survey.
	- https://alignmentsurvey.com/uploads/AI-Alignment-A-Comprehensive-Survey.pdf
	- AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã®åŒ…æ‹¬çš„ãªã‚µãƒ¼ãƒ™ã‚¤
	- AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¯ã€AIã‚·ã‚¹ãƒ†ãƒ ã‚’äººé–“ã®æ„å›³ã‚„ä¾¡å€¤è¦³ã«æ²¿ã£ã¦è¡Œå‹•ã•ã›ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã‚‹ã€‚AIã‚·ã‚¹ãƒ†ãƒ ã®èƒ½åŠ›ãŒé«˜ã¾ã‚‹ã«ã¤ã‚Œã¦ã€ãšã‚ŒãŸAIã‚·ã‚¹ãƒ†ãƒ ã«é–¢é€£ã™ã‚‹æ½œåœ¨çš„ãªå¤§è¦æ¨¡ãƒªã‚¹ã‚¯ãŒé¡•è‘—ã«ãªã£ã¦ã„ã‚‹ã€‚ä½•ç™¾äººã‚‚ã®AIå°‚é–€å®¶ã‚„è‘—åäººãŒAIãƒªã‚¹ã‚¯ã¸ã®æ‡¸å¿µã‚’è¡¨æ˜ã—ã€ã€ŒAIã«ã‚ˆã‚‹çµ¶æ»…ãƒªã‚¹ã‚¯ã®è»½æ¸›ã¯ã€ãƒ‘ãƒ³ãƒ‡ãƒŸãƒƒã‚¯ã‚„æ ¸æˆ¦äº‰ã¨ã„ã£ãŸä»–ã®ç¤¾ä¼šçš„è¦æ¨¡ã®ãƒªã‚¹ã‚¯ã¨ä¸¦ã‚“ã§ã€ä¸–ç•Œçš„ãªå„ªå…ˆäº‹é …ã§ã‚ã‚‹ã¹ãã ã€ã¨ä¸»å¼µã—ã¦ã„ã‚‹
- ãƒ­ãƒ¼ã‚«ãƒ«LLMã¯ã“ãƒ¼ã‚„ã£ã¦ä½¿ã†ã®ğŸ’¢
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	- â‘ ãƒˆãƒ¼ã‚¯ãƒ³ã®ç”Ÿæˆç¢ºç‡ãŒå…¨éƒ¨è¦‹ã‚Œã‚‹ã€‚ã“ã‚Œã‚’å¿œç”¨ã™ã‚‹ã¨ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚„èª¤å­—è„±å­—ã®æ¤œå‡ºã‚‚ã§ãã‚‹ã‹ã‚‚ã€‚ã¨ã„ã†ã®ã¯ã©ã®ãƒ¯ãƒ¼ãƒ‰ç”Ÿæˆæ™‚ã«è‡ªä¿¡ãŒç„¡ã‹ã£ãŸã‹ãŒç¢ºç‡ã‚’è¦‹ã‚Œã°åˆ†ã‹ã‚‹ã‹ã‚‰ã€‚â‘¡å›ç­”ã®å†’é ­éƒ¨åˆ†ã‚’å¼·åˆ¶ã§ãã‚‹ã€‚
- Xã€ç”ŸæˆAIã§ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã‚’é–‹å§‹ã€€ä¸€éƒ¨ã®æœ‰æ–™ä¼šå“¡ã«
	- https://www.nikkei.com/article/DGXZQOGN0406N0U4A500C2000000/
	- ã€Œæ–°æ©Ÿèƒ½ã€Œã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚ºã€ã‚’å§‹ã‚ãŸã€‚ç±³xAIï¼ˆã‚¨ãƒƒã‚¯ã‚¹ã‚¨ãƒ¼ã‚¢ã‚¤ï¼‰ã®å¯¾è©±AIã€ŒGrokï¼ˆã‚°ãƒ­ãƒƒã‚¯ï¼‰ã€ãŒXä¸Šã§è©±é¡Œã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã©ã«ã¤ã„ã¦æƒ…å ±ã‚’è¦ç´„ã€
- How LLMs work, clearly explained with visuals:
	- https://x.com/Sumanth_077/status/1786404341735444731
- Build a RAG system with Llama 3B-Instruct for your PDFs
	- https://colab.research.google.com/drive/1BJYYyrPVe0_9EGyXqeNyzmVZDrCRZwsg?usp=sharing#scrollTo=Y2m2l-vt_RSp
-  TAIS 2024 | Insights from two years of AI safety field-building at MATS â€” Ryan Kidd
	- https://www.youtube.com/watch?v=tA9K8JqyhP4
	- Don't miss @jesse_hoogland captivating talk at TAIS2024 on the structure of neural networks and the links between learning theory and interpretability! Watch now:
	- ç‰¹ç•°å­¦ç¿’ç†è«–ï¼ˆæ¸¡è¾ºãƒ™ã‚¤ã‚ºç†è«–ï¼‰ã‚’ç™ºå±•ã•ã›ã¦å±€æ‰€å­¦ç¿’ä¿‚æ•°ã¨ã„ã†æ–°ã—ã„æ¦‚å¿µã‚’å‰µå‡ºã—ï¼Œâ‘ transformerã®å­¦ç¿’ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹ã®è§£æï¼Œâ‘¡æ©Ÿæ¢°è«–çš„è§£é‡ˆå¯èƒ½æ€§ã®åŸºç›¤ç†è«–ã¨ã—ã¦ã®å¯èƒ½æ€§ï¼Œâ‘¢AIã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆç†è«–ã®å±•æœ›ã‚’åŠ›èª¬ã—ãŸ2äººã®ç ”ç©¶è€…ã®TAIS2024è¬›æ¼”
- ã€Œç¢ºç‡å¤‰æ•°ã€ã®æ­£ä½“ã¯ç±³ç”°åŸ‹ã‚è¾¼ã¿
	- https://m-hiyama.hatenablog.com/entry/20170228/1488276250
- ChatGPTã€æ±å¤§å…¥è©¦ã«æŒ‘ã‚€ã€€è‹±èª8å‰²è¶…ã‚‚æ•°å­¦1ç‚¹ã§ã€Œä¸åˆæ ¼ã€
	- https://www.nikkei.com/article/DGXZQOUC2103E0R20C24A3000000/?n_cid=SNSTW005
	- ã€Œã“ã®è¨ˆç®—ã¯æ‰‹ä½œæ¥­ã§ã¯å›°é›£ã€‚æ•°å­¦ã®å°‚é–€æ›¸ã‚’ãŠã™ã™ã‚ã™ã‚‹ã€ã€‚äººã”ã¨ã®ã‚ˆã†ãªç­”æ¡ˆã‚‚ã‚ã‚Šã¾ã—ãŸã€‚å¤æ–‡ã‚‚æ–‡è„ˆã‚’ç†è§£ã§ããš0ç‚¹ã€‚ä¸€æ–¹ã€è‹±ä½œæ–‡ã‚„è‹±è¨³ã¯æº€ç‚¹ã§ã—ãŸ
- 2024å¹´æ±å¤§å…¥è©¦æ•°å­¦ã®ç¬¬1å•ã®(1)ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·¥å¤«ã—ã¦è§£ã„ã¦ã¿ãŸã‚‰ã€ä¸€ç™ºã§è§£ã‘ãŸã€‚ã“ã‚Œã ã‘ã§5ç‚¹ãã‚‰ã„å–ã‚Œã¦ã„ã‚‹ã¯ãš
	- https://x.com/itnavi2022/status/1787121446445326816
- ç¬¬2å•ã®(1)ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å·¥å¤«ã—ãªãã¦ã‚‚ã€ChatGPTã§æ™®é€šã«æ­£è§£ã§ããŸã€‚
	- https://x.com/itnavi2022/status/1787448789693059176
- Nvidia ãŒå‡ºã—ãŸã€Llama3-ChatQA-1.5ã®å¾®èª¿æ•´ã§RAGï¼†å¯¾è©±æ€§èƒ½çˆ†ä¸ŠãŒã‚Šã€‚
	- https://x.com/hokazuya/status/1786901364213416356
- LangChainã®llama.cppçµ±åˆ
	- https://x.com/yuiseki_/status/1787091439408816479
- ã€vLLM on Hugging Face Interfaceã€‘
	- https://x.com/hokazuya/status/1787060961570127973
	- ä¾¿åˆ©ã™ãã€‚çˆ†é€Ÿã§Llama 3 -8Bã®LLMã‚’å‹•ã‹ã™ï¼‹OpenAIã®APIã‚’å‘¼ã³å‡ºã™å½¢å¼ã§Llama 3ã¨ä¼šè©±ã§ãã¡ã‚ƒã†ã€‚

## 4/29

ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰Phi-3-miniãŒç™ºè¡¨ã•ã‚Œã€3.8Bã®ãƒ¢ãƒ‡ãƒ«ãŒMixtral 8x7Bã‚„GPT-3.5ã¨ãŸã‚ã‚’ã¯ã‚‹ã¨ã®ã“ã¨ã€Phi-3-mini 4k instruct ãƒ¢ãƒ‡ãƒ«ã¯Colab T4ã§ã‚‚å‹•ãã—ã€huggingfaceã«ã‚‚å…¬é–‹ã€‚ã•ã£ããOllamaãŒå¯¾å¿œã—ã€Llama-3 & Phi-3ã‚‚RAGã§ã®æ¯”è¼ƒã¨ã‹ã‚‚ã€‚Llama3ã‚‚ã€æ—¥æœ¬èªå‘ã‘ã«LoRaã•ã‚ŒãŸã‚Šã€Llama3-70Bã‚’42Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«æåˆˆã‚Šã—ãŸãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚ŒãŸã‚Šã€4bitã«é‡å­åŒ–ã—ã¦è©•ä¾¡ã•ã‚ŒãŸã‚Šã¨ã‹ã€ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã®æ´»å‹•ãŒä¸€æ°—ã«ç››ã‚Šä¸ŠãŒã‚‹ã€‚ãªãŠé‡å­åŒ–ã«é–¢ã—ã¦ã¯ã©ã®ï¼¬ï¼¬ï¼­ã‚‚4bité‡å­åŒ–ã—ã¦ã‚‚ç²¾åº¦ãŒã»ã¨ã‚“ã©ä½ä¸‹ã—ãªã„ã¨ã®ã“ã¨ã ãŒæœ¬å½“ã‹ï¼ŸAppleãŒiPhoneã§ã‚‚ç¨¼åƒã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒOpenELMã€ã‚’ç™ºè¡¨ã€ã•ã£ããMLX LMã§è©•ä¾¡ã—ãŸçµæœãŒå…¬é–‹ã•ã‚ŒãŸã€Macbook Airã§Phi 3ã®é‡å­åŒ–ã•ã‚ŒãŸã‚„ã¤ã‚’å‹•ã‹ã—ã¦åŠ‡é€Ÿã¨ã„ã£ã¦ã‚‹ä¾‹ã¨ã‹ã€å®Ÿã¯ã€LLMãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºè€…ã¯Mac é€²åŒ–çš„ã‚’è²·ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è§¦ã‚‹ã¹ãã¨ã®æ„è¦‹ã‚‚è¦‹ã‚‰ã‚ŒãŸãŒã€åè«–ã‚‚ã¼ã¡ã¼ã¡ã€ã•ã¦ã‚‚ï¼–æœˆã®WWDC24ãŒæ¥½ã—ã¿ã ã€‚ãã‚Œã«ã—ã¦ã‚‚ã€NVIDIA CEOã‚¸ã‚§ãƒ³ã‚¹ãƒ³ãƒ»ãƒ•ã‚¡ãƒ³æ°ãŒã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«ã‹ã‚‰ã®æ­Œé…ä¿¡ã«æ··ã–ã‚‹å‹•ç”»ã€ã‹ã‚ã„ã„ãªã‚ï¼ˆã„ã‚„ï¼£ï¼¥ï¼¯ãŒã ã‚ˆï¼‰ã€‚Groq(LPUã«ã‚ˆã‚‹é«˜é€ŸåŒ–ã®ã»ã†ï¼‰ã®APIã‚’Streamlitã§ä½¿ã†æ–¹æ³•ã®ç´¹ä»‹ãªã©ã€Groqã®åˆ©ç”¨ã‚’ã¡ã‚‰ã»ã‚‰è¦‹ã‚‹ã‚ˆã†ã«ãªã£ãŸã€é€Ÿã•ã¯æœ€å¼·ã€‚LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é–¢ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¯é€±ã¾ã¨ã‚ã¦ãã ã•ã‚‹ã‚µã‚¤ãƒˆã€é ­ãŒä¸‹ãŒã‚‹ã€ã“ã®ã‚¢ãƒ—ãƒ‡æ›´æ–°ã‚‚ãã†ã‚ã‚ŠãŸã„ã‚‚ã®ã ã€‚LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã§ã‚ã‚‹DPOã¯å®Ÿã¯ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã®é€†Qå­¦ç¿’ã‚’å®Ÿç¾ã—ã€æœ€é©ãªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸é–¢æ•°ã‚’æ¨å®šã—ã€ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã®ä¿¡ç”¨å‰²å½“å•é¡Œã‚’è§£ã„ã¦ã„ã‚‹ã¨ã„ã†ã®ã¯ã€ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå•é¡Œã‚’è¡¨é¢ä¸Šã®èª²é¡Œã§ã¯ãªãã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¾ã§è½ã¨ã™ã¨ã“ã‚ãŒé¢ç™½ã„ã€‚LLMã®æ€§èƒ½è©•ä¾¡ã‚„ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«é–¢ã™ã‚‹æ´»å‹•ã‚‚ElyzaTasks100ã‚„RAGã€Query Planningãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ãƒ­ãƒ¼ã‚«ãƒ«LLMã®å®ŸåŠ›ãŒæ¤œè¨¼ãªã‚“ã‹ãŒã‚ã£ãŸã€‚

- ãƒ¢ãƒ‡ãƒ«é€²åŒ–ãƒãƒ¼ã‚¸ã«ã¤ã„ã¦ by sakana.aiã®ç§‹è‘‰ã•ã‚“
	- https://speakerdeck.com/iwiwi/17-nlpkorokiumu
	- æ—¥æœ¬èªLLMã®ãƒãƒ¼ã‚¸ã¯ã‚ã¾ã‚Šãªã„ã€ç¶™ç¶šå­¦ç¿’ã•ã‚Œã¦ã€å…ƒã®é‡ã¿ã‹ã‚‰ãšã‚Œã¦ã—ã¾ã£ã¦ã„ã‚‹ã€‚
	- ãã“ã§ã€é€²åŒ–çš„è¨ˆç®—ã«ã‚ˆã‚‹ãƒãƒ¼ã‚¸ã€‚
-  ã€ŒAIäº‹æ¥­è€…ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆç¬¬1.0ç‰ˆï¼‰ã€
	- https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html
	- ã“ã‚Œã¾ã§MLPdMçš„ãªäººãŒä¸€èˆ¬çš„ã«ç•™æ„ã™ã¹ãã¨è¨€ã‚ã‚Œã¦ã„ãŸã‚ˆã†ãªã“ã¨ã«åŠ ãˆã€ã‚ˆã‚Šåºƒã„ç¤¾ä¼šçš„ãªè¦³ç‚¹ã‚„ã€AIã®åˆ©ç”¨è€…ã®è¦³ç‚¹ãªã©ã‚‚è¸ã¾ãˆãŸä¸Šã§ã†ã¾ãã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã‚‹æœ‰ç›Šãªã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã ã¨æ„Ÿã˜ã¾ã—ãŸã€‚
	- https://x.com/yu__ya4/status/1782037184079683916
- Command R+ã¯ã©ã“ã¾ã§é‡å­åŒ–ã™ã‚‹ã¨ã‚¢ãƒ›ã«ãªã£ã¦ã—ã¾ã†ã®ã‹ï¼Ÿ by npakaã•ã‚“ï¼Ÿ
	- https://soysoftware.sakura.ne.jp/archives/3834
	- ãƒ­ãƒ¼ã‚«ãƒ«ã§Command R+ã‚’å‹•ã‹ã™ã¨ãªã‚‹ã¨ã€æ‰‹å…ƒã®ç’°å¢ƒã®RTX4090ãŒï¼‘å°ã§ã¯ãƒãƒƒã‚­ãƒªè¨€ã£ã¦1bitã¾ã§åœ§ç¸®ã—ã¦ã‚‚VRAMã«è¼‰ã‚Šãã‚‰ãªã„ã€‚
	- ä»Šå›ã¯Command R+ã®å„é‡å­åŒ–ãƒ¢ãƒ‡ãƒ«ã€Q6_Kã€Q5_K_Sã€Q4_K_Sã€iq4_xsã€Q3_K_Sã€iq3_xxsã€Q2_Kã€iq2_xxsã€iq1_sã®ãã‚Œãã‚Œã«ã¤ã„ã¦ã€ElyzaTasks100ã‚’è§£ã‹ã›ã¦ã¿ã‚‹ã€‚
	- APIï½3bitã¾ã§ã¯ã¶ã£ã¡ã‚ƒã‘å¤§å·®ãªã„ã¨ã„ã†ã‹èª¤å·®ã®ç¯„å›²ã ã¨ã„ã†äº‹ã ã‚ã†
	- 1bitã®3ç‚¹ã¨ã„ã†ã®ã¯ã“ã‚Œã¯ã‚‚ã†å®Œå…¨ã«åŠ£åŒ–ã—ã¦ã‚‹ã¨ã„ã†ã®ã¯ç¢ºå®Ÿã«è¨€ãˆãã†ã ã€‚
	- ã¾ãšã€ä»Šå›ã®çµæœã ã‘ã§è¨€ãˆã°ã€å®Ÿç”¨ä¸Šã¯4bitã¾ã§ã®é‡å­åŒ–ãªã‚‰æ€§èƒ½åŠ£åŒ–ã¯è¦‹å½“ãŸã‚‰ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã€‚
- Fully local RAG with Llama 3 on ollama & streamlit
	- https://x.com/ashpreetbedi/status/1782079131103932647
-   LLMãƒ¢ãƒ‡ãƒ« "Llama3" ã‚’ 4bit é‡å­åŒ–ã—ã¦å®Ÿè¡Œã—ã¦ã¿ãŸ
	- https://qiita.com/akasakat/items/0855b5f05467cc8cbbf4
	- ä¸€æ˜¨æ—¥ç™ºè¡¨ã•ã‚ŒãŸ  [Llama3](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  ã‚’4bité‡å­åŒ– ã—ã¦ã¤ã‹ã£ã¦ã¿ã¾ã—ãŸ
	-  GPUã® VRAM ã¯ 6GB ç¨‹åº¦æ¶ˆè²»ã—ã¾ã™
	- Llama3ã® èªå½™æ•°ã¯ 32000(Llama2) => 128256 ã¸ã¨å¤§å¹…ã«å¢—ãˆã¾ã—ãŸ
- LoRA fine-tuning of embedding models using LlamaIndex
	- https://medium.com/@diagnosta/lora-fine-tuning-of-embedding-models-using-llamaindex-a60b823a2c94
	- In this blog post, weâ€™ll explore how to fine-tune black-box embedding models using low-rank adaptation (LoRA) with the LlamaIndex library. LoRA is a technique that trains a small number of rank-decomposed weights to adapt a pre-trained model to a new task or domain. 
- è‡ªå®…PCã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’æ§‹ç¯‰ï¼šã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼GPUã®æ ã‚’è¶…ãˆã€å¤§å‹LLMã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ã‹ã™ï¼ by AIã‚µãƒˆã‚·
	- https://note.com/aisatoshi/n/nd4969fc42602?sub_rt=share_h
	- Command-r-Plusã¯ã€4bitã«é‡å­åŒ–ã—ã¦ã‚‚60GBç¨‹åº¦ã®VRAMãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚
	- è¤‡æ•°PCã§ã®ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—ãŒè‡ªå®…ã§å¯èƒ½ã¨ãªã£ãŸã®ã§ã€ç†è«–çš„ã«ã¯ã€ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚’å¢—ã‚„ã™ã“ã¨ã§å·¨å¤§ãªLLMã®æ¨è«–ãŒå¯èƒ½ã¨ãªã‚Šã¾ã™ã€‚
- alfredplpl/Llama-3-8B-Instruct-Jaã€€ by ã‚ã‚‹ãµã•ã‚“
	- https://huggingface.co/alfredplpl/Llama-3-8B-Instruct-Ja
	- æ—¥æœ¬èªå‘ã‘ Llama 3 8Bã‚’å…¬é–‹ã—ã¦ã¿ã¾ã—ãŸã€‚LoRAã§è¡¨é¢ã‚’å­¦ç¿’ã—ãŸã ã‘ãªã®ã§ã€æ€§èƒ½ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãŸã ã€æ™®é€šã®Llama 3ã‚ˆã‚Šã‹ã¯æ—¥æœ¬èªãŒå¼·ããªã£ã¦ã„ã‚‹ã¯ãšã§ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™
- Groqã®å€¤æ®µèª¿ã¹ã€llama3ãªã©
	- https://x.com/webbigdata/status/1782240169879601540
	- Groqã¯LPU(Language Processing Unit)ã¨ã„ã†ç‹¬è‡ªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚’é–‹ç™ºã—ã¦ã„ã‚‹ä¼šç¤¾ã§ã™
	- Llama 3 70BãŒAnthropic Claude 3 Sonnet($3.00/$15.00)ç›¸å½“ã®æ€§èƒ½ã§ã‚ã‚Œã°ã€Groqã®Llama 3 70B APIã®ä¾¡æ ¼è¨­å®š($0.59/$0.79)ã¯éå¸¸ã«ç«¶äº‰åŠ›ãŒã‚ã‚Šã¾ã™
- Llama 3 70b layer pruned from 70b -> 42b by Charles Goddard
	- https://www.reddit.com/r/LocalLLaMA/comments/1c9u2jd/llama_3_70b_layer_pruned_from_70b_42b_by_charles/
	- chargoddard/llama3-42b-v0
	- Llama3-70Bã‚’æåˆˆã‚Šã—ã¦ãƒ‘ãƒ©æ•°42Bã«ã—ã¡ã‚ƒã£ãŸã¨ã„ã†ãƒ–ãƒ„ã‚‰ã—ã„ã€‚
-  Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
	- https://arxiv.org/abs/2404.14219
	- Microsoft announces phi-3-mini, a 3.8B model trained on 3.3T tokens that rivals Mixtral 8x7B and GPT-3.5
	- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã€å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³æ•°
		- â‘ Phi-3-mini (38å„„ã€3å…†3000å„„)
		- â‘¡Phi-3-small (70å„„ã€4å…†8000å„„) 
		- â‘¢Phi-3-medium (140å„„ã€4å…†8000å„„ï¼‰
- ã¯ï¼ŸPhi3-small-7Bã¯MMLUãŒ75.3ç‚¹ï¼ŸLlama3-8Bã§ã‚‚66ç‚¹ã ã¨ã„ã†ã®ã«ã€‚
	- https://x.com/umiyuki_ai/status/1782622321704079652
-  Weekly AI Agents News!
	- https://speakerdeck.com/masatoto/weekly-ai-agents-news
	- ã“ã®LLMãƒ–ã‚¯ãƒã‚¢ãƒ—ãƒ‡ã®ã‚ˆã†ã«æ¯é€±ã€Agenté–¢ä¿‚ã®æƒ…å ±ã‚’åé›†ã—ã¦ã„ã‚‹äºº
	- LLMã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«é–¢ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¯é€±ã¾ã¨ã‚ã¦ãã ã•ã‚‹
-  From  r  to  Qâˆ—: Your Language Model is Secretly a Q-Function
	- https://arxiv.org/abs/2404.12358
	- LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã§ã‚ã‚‹DPOã¯å®Ÿã¯ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã®é€†Qå­¦ç¿’ã‚’å®Ÿç¾ã—ã€æœ€é©ãªã‚¢ãƒ‰ãƒãƒ³ãƒ†ãƒ¼ã‚¸é–¢æ•°ã‚’æ¨å®šã—ã€ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã®ä¿¡ç”¨å‰²å½“å•é¡Œã‚’è§£ã„ã¦ã„ã‚‹ã€‚ä¾‹ãˆã°ã‚ã‚‹å¯¾è©±ã®çµæœã«ã¤ãªãŒã£ãŸåŸå› ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®šã§ããŸã‚Šã€å°¤åº¦æœ€å¤§åŒ–ã®ãƒ“ãƒ¼ãƒ æ¢ç´¢ã¯ãã®ã¾ã¾åç›Šæœ€å¤§åŒ–ã¨ã¿ãªã›ã‚‹ by å²¡é‡åŸã•ã‚“
- Llama.cpp ã§ Llama 3 70Bã‚’ãŠè©¦ã—ä¸­ã€‚by npakaã•ã‚“
	- https://x.com/npaka123/status/1782556559589212399
	- 8.42 tokens per second 
	- Meta-Llama-3-70B-Instruct-IQ4_XS.gguf 
	- M3 Max (128GB)
-  llama.cpp ã«ã‚ˆã‚‹ transformersãƒ¢ãƒ‡ãƒ« ã®é‡å­åŒ– by npakaã•ã‚“
	- https://note.com/npaka/n/nbd1348500a28?sub_rt=share_b
	- ä»Šå›ã¯ç·´ç¿’ç”¨ã«ã€Œmeta-llama/Meta-Llama-3-8B-Instructã€ã‚’æº–å‚™ã—ã¾ã™ã€‚
	- transformersãƒ¢ãƒ‡ãƒ«ã‚’ggufã«å¤‰æ›
	- imatrixé‡å­åŒ–
- Llama3-70Bã¯ElyzaTasks100ï¼ˆCommand R+ã«ã‚ˆã‚‹è‡ªå‹•è©•ä¾¡ï¼‰ã«ãŠã„ã¦Command R+è¶…ãˆã¦ã¾ã™
	- https://x.com/umiyuki_ai/status/1782690199677641164
- CodeQwen1.5
	- https://x.com/Alibaba_Qwen/status/1782426698279272742
	- Last week, we released a CodeQwen1.5 and received a lot of positive feedback! Thank you for your support! 
- æ‰‹å…ƒã®Macbook Airã§Phi 3ã®é‡å­åŒ–ã•ã‚ŒãŸã‚„ã¤ã‚’å‹•ã‹ã—ã¦ã„ã‚‹ã®ã ãŒã€ã“ã‚ŒGPT-3.5ã“ãˆã¦ã‚‹ã‚ˆã­ã€‚ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³ã§æ™®é€šã«å‹•ãã£ã¦ã©ã†ã„ã†ã“ã¨ã 
	- https://x.com/alfredplpl/status/1782808427129114796
- phi3 local RAG using LlamaIndex and Ollama:
	- https://x.com/llama_index/status/1782893301214986593
	- https://colab.research.google.com/drive/1RoZzbL8WYaAp4b3sazYHVI8TA2AkrtRJ#scrollTo=9AtRxaqD94mZ
- æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ã§ã®local LLMã®å®ŸåŠ›ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
	- RAG, Query Planning, Text2SQL, and Pydantic Program but struggles with Routing and Agentic tasks. 
-  Feature Test for Phi-3-mini-4k-instruct
	- https://docs.llamaindex.ai/en/latest/examples/benchmarks/phi-3-mini-4k-instruct/
- Phi-3 mini 128k instruct ã® Colab T4 ã§å‹•ä½œç¢ºèªã®å–ã‚ŒãŸã€€ by ã¬ã“ã¬ã“ã•ã‚“
	- https://gist.github.com/schroneko/f4fac4c4dd541f4c5ee61c44c90c4a85
	- ã‚µãƒ³ãƒ—ãƒ«ã®æ–¹ç¨‹å¼ã‚’è§£ãå•é¡Œã¯é›£ãªãã‚¯ãƒªã‚¢ã€‚æ—¥æœ¬èªã§ã‚‚ã‚¯ãƒªã‚¢ã€‚3.8B ã«ã—ã¦ã¯ã‹ãªã‚Šæ—¥æœ¬èªã‚’ãƒŠãƒãƒ¥ãƒ©ãƒ«ã«è©±ã›ã¦ã„ã‚‹ã®ã§ã¯ï¼Ÿ
- HuggingChatã«phi3-mini-4kç™»å ´
	- https://huggingface.co/chat/
-  Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches
	- https://arxiv.org/abs/2404.14779
	- åŒ»ç™‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã§LLMã‚’fine tuningã™ã‚‹éš›ã€ãƒ•ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã™ã‚‹ã‹LoRAã§åŠ¹ç‡çš„ã«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã¹ãã‹ã‚’Llama-2ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§æ¤œè¨¼ã—ãŸè«–æ–‡ã€‚
	- ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå°ã•ã„ã»ã©fine tuningã®åŠ¹æœãŒå¤§ãã„
	- ãƒ¢ãƒ‡ãƒ«ãŒå¤§ãã„ã»ã©LoRAã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å¤ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«æ¥è¿‘ã—ãã†
- LLMã®ç¶™ç¶šå­¦ç¿’ã«ãŠã‘ã‚‹è«–æ–‡ç´¹ä»‹
	- https://note.com/sergicalsix_/n/ndbd5b29451c9
	- LLMã®ç¶™ç¶šå­¦ç¿’ã«ãŠã„ã¦ãƒ‰ãƒ¡ã‚¤ãƒ³ã®å†…å®¹ã‚„é †åºãªã©ã«ã¤ã„ã¦èª¿æŸ»ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é¡ä¼¼åº¦é †ã§ç¶™ç¶šå­¦ç¿’ã—ãŸæ–¹ãŒãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–ã•ã›ã‚„ã™ãã€ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒ©ãƒ³ãƒ€ãƒ ãªé †åºã§ç¶™ç¶šå­¦ç¿’ã—ãŸæ–¹ãŒLLMã®æ€§èƒ½ãƒ»çŸ¥è­˜ã®è“„ç©ãŒæ”¹å–„ã™ã‚‹ã€‚
-  Command R+ã¯ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚‚ã™ã”ã‹ã£ãŸ
	- https://qiita.com/sergicalsix/items/5ceb9a3a0d11affb4b9a
	- ä»Šå›ã¯Command R+ã®æ—¥æœ¬èªã®å¿œç­”é€Ÿåº¦ãŒæœ¬å½“ã«é€Ÿã„ã®ã‹ã€ãªãœé€Ÿã„ã®ã‹ã«ã¤ã„ã¦ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼è¦³ç‚¹ã§è¿°ã¹ãŸã„ã¨æ€ã„ã¾ã™ã€‚
	- Cohereã®Ayaã¨Command R+ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¯ä»–ã®ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã¨æ¯”ã¹ã¦ãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒå‰Šæ¸›ã§ãã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã—ãŸã€‚
- Appleã€iPhoneã§ã‚‚ç¨¼åƒã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã€ŒOpenELMã€ã‚’å…¬é–‹
	- https://www.itmedia.co.jp/news/articles/2404/25/news103.html
	- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®ç•°ãªã‚‹4ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹ã€‚å°ã•ã„ã‚‚ã®ã‹ã‚‰ã€2å„„7000ä¸‡ã€4å„„5000ä¸‡ã€11å„„ã€30å„„
	- OpenELMã¯ã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ã”ã¨ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’ç”¨ã„ã¦ã€Transformerãƒ¢ãƒ‡ãƒ«ã®å„ãƒ¬ã‚¤ãƒ¤ãƒ¼å†…ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’efficientï¼ˆåŠ¹ç‡çš„ï¼‰ã«å‰²ã‚Šå½“ã¦ã‚‹ã“ã¨ã§ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã¦ã„ã‚‹ã¨ã„ã†ã€‚
- Let's compare Llama-3 & Phi-3 using RAG:
	- https://lightning.ai/lightning-ai/é€²åŒ–çš„s/compare-llama-3-and-phi-3-using-rag?utm_source=akshay
	- https://x.com/akshay_pachaar/status/1783114329199718558
-  Cohere Toolkit
	- https://github.com/cohere-ai/cohere-toolkit
	- Yesterday, we open sourced the Cohere Toolkit. We think this will be a major accelerant for getting LLMs into production within enterprise.
-  LLMã«ã¨ã£ã¦ã€Œè³ªã®è‰¯ã„å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã€
	- https://x.com/imos/status/1783494307959513522
	- LLMã«ã¨ã£ã¦ã€Œè³ªã®è‰¯ã„å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã€ã¯ã€Œæ­£ã—ã„æ—¥æœ¬èªã«/å€«ç†çš„ã«çµã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã€ã§ã¯ãªã„ã¨æ€ã†ã®ã§æ•´ç†ã—ã¦å¸ƒæ•™ã—ãŸã„ï¼ˆFineWebæ›°ãã‚¢ãƒ€ãƒ«ãƒˆã‚µã‚¤ãƒˆã‚’æŠœãã¨æ€§èƒ½åŠ£åŒ–ã™ã‚‹ã‚‰ã—ã„ï¼‰ã€‚è¨€èªèƒ½åŠ›ã€çŸ¥è­˜ã€è«–ç†èƒ½åŠ›ã€å¿œç­”å½¢å¼ãªã©ã€ç”¨é€”ã‚’æº€ãŸã™ã®ã«å¿…è¦ãªè»¸ã‚’æ¬ ã‹ã•ãšå«ã‚€ã“ã¨ãŒå¤§äº‹ã ã¨æ€ã‚ã‚Œã‚‹ã€‚
- Llama 3 Establishes Meta as the Leader in â€œOpenâ€ AI  by IEEE Spectrum
	- https://spectrum.ieee.org/meta-llama-3?share_id=8224093&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- ã€çµ±è¨ˆçš„ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã€(å²©æ³¢æ›¸åº— ç¢ºç‡ã¨æƒ…å ±ã®ç§‘å­¦)ã®åŸ·ç­†ãŒã¤ã„ã«æœ€å¾Œã¾ã§åˆ°é”ã—ã¾ã—ãŸã®ã§ã€ã€Œæ–‡æ›¸ã®çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã€ã®ç« ã‚’å…¬é–‹ã—ã¾ã—ãŸ
	- http://chasen.org/~daiti-m/textmodel/textmodel-chapter5.pdf
-  Graph Machine Learning in the Era of Large Language Models (LLMs)
	- https://arxiv.org/abs/2404.14928
	- ã‚°ãƒ©ãƒ•ã¨è¨€èªãƒ¢ãƒ‡ãƒ«ã«é–¢ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼è«–æ–‡
	- ã‚°ãƒ©ãƒ–ç³»æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¨LLMã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹ç ”ç©¶ä¾‹ã‚„å±•æœ›ãŒã¾ã¨ã¾ã£ã¦ã„ã¾ã™ã€‚MIåˆ†é‡ã ã‘ã§ãªãä»–åˆ†é‡ã®äº‹ä¾‹ã‚‚ã‚ã‚Šå‚è€ƒã«ãªã‚Šã¾ã™ã€‚
- Two new AI releases by Apple today
	- https://x.com/pcuenq/status/1783032344104026372
	- OpenELM, a set of small (270M-3B) efficient language models. Weights on the Hub:
	- CoreNet, a training library used to train OpenELM:
-  [Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge](https://aclanthology.org/2024.eacl-long.127.pdf)
	- å¤šè¨€èªè¨€èªãƒ¢ãƒ‡ãƒ«ãŒç²å¾—ã—ã¦ã„ã‚‹äº‹å®Ÿã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’53è¨€èªã§æ¤œè¨¼ã€‚ã©ã®ã‚ˆã†ãªåŸå› ã«ã‚ˆã£ã¦è¨€èªã”ã¨ã«å·®ãŒå‡ºã‚‹ã®ã‹ã€ãƒ‡ãƒ¼ã‚¿é‡ã‚„åœ°ç†çš„è¦³ç‚¹ãƒ»æ´»æ€§åŒ–ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã®é¡ä¼¼æ€§ãªã©ã‹ã‚‰åˆ†æã—ã¦ã„ã‚‹ã€‚
-  LLMãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºè€…ãŒMac é€²åŒ–çš„ã‚’è²·ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è§¦ã‚‹ã¹ãç†ç”±
	- https://note.com/erukiti/n/n58a8180ea9fb
- [torchtitan](https://github.com/pytorch/torchtitan)
	- a library for large model training called torchtitan
	- They have scripts to train Llama-3 from scratch
	- The library went public today on GitHub but it is still in pre-release state & active development
- LangChainã‚’ç”¨ã„ãŸ4ç¨®é¡ã®RAGè³ªå•å¿œç­”chainã®å®Ÿè£…ã¨æ€§èƒ½æ¯”è¼ƒ
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	-  **stuff chain**ã€ **map reduce chain**ã€**map rerank chain**ã€ **refine chain**
	-  **é©ã—ã¦ã„ã‚‹æ–‡æ›¸ç‰¹å¾´**
		-  **stuffãƒ»map reduce**  : æ–‡æ›¸å…¨ä½“ã‚’1æ®µéšã¾ãŸã¯2æ®µéšã§LLMã«å…¥åŠ›ã™ã‚‹ãŸã‚, æ–‡æ›¸å…¨ä½“ã«é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹å ´åˆã«ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚
		- **map rerank**  : æ–‡æ›¸ã®ä¸€éƒ¨ã®ã¿ã®å›ç­”ã‹ã‚‰æœ€è‰¯ã®å›ç­”ã‚’é¸ã¶ãŸã‚, ä¸€éƒ¨ã®ã¿ã«é‡è¦ãªæƒ…å ±ãŒå«ã¾ã‚Œã‚‹å ´åˆã«ç‰¹ã«æœ‰åŠ¹ã§ã™ã€‚
		- **refine**  : ä¸€éƒ¨ã®ã¿ã®å›ç­”ã‚’è¤‡æ•°å›å†èµ·çš„ã«å‘¼ã³å‡ºã™ãŸã‚, é‡è¦ãªæƒ…å ±ãŒæ–‡æ›¸ã®å…¨ä½“ã§ã‚‚ä¸€éƒ¨ã§ã‚‚å¯¾å¿œã™ã‚‹ã“ã¨ãŒå¯èƒ½ã§ã™ã€‚
- ã€ŒJapanese-Starling-ChatV-7Bã€
	- https://x.com/AIBizNavigator/status/1783667625802994164
	- 7Bã‚¯ãƒ©ã‚¹ã¨ã¯æ€ãˆãªã„è¶…é«˜æ€§èƒ½ãªã‚“ã 
	- è‹±èªã®æœ€å¼·7Bãƒ¢ãƒ‡ãƒ«Starling-LM-7B-betaã‹ã‚‰æŠ½å‡ºã—ãŸChat Vectorã‚’ã€ æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã®ChatNTQ-JA-v1.0-7bã«æ›ã‘åˆã‚ã›ãŸã ã‘ã€‚ è¿½åŠ ã®æ—¥æœ¬èªå­¦ç¿’ã¯ä¸€åˆ‡ãªã—
	- https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
- Mergekit-Evolveã®ãƒ†ã‚¹ãƒˆã§è©¦ã—ã«ä½œã£ãŸãƒ¢ãƒ‡ãƒ«ã€Japanese-Chat-Umievo-itr001-7b
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- https://huggingface.co/umiyuki/Japanese-Chat-Umievo-itr001-7b
	- ElyzaTasks100ã§è©•ä¾¡ã—ã¦ã¿ãŸã‚‰å¹³å‡3.57ç‚¹ã‚’å©ãå‡ºã—ãŸï¼7Bãƒ¢ãƒ‡ãƒ«ãªã®ã«35Bãƒ‘ãƒ©ã®Command Rã‚’è¶…ãˆã¦ã¾ã™ï¼é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®å¨åŠ›æã‚‹ã¹ã—ï¼ï¼ã¨ã‚Šã¾HuggingFaceã«ä¸Šã’ã¾ã—ãŸï¼
- Swallow instruction tuning models
	- https://huggingface.co/collections/tokyotech-llm/swallow-instruct-65e559f4d52e7c9d197697c2
	- wallow 7B, 13B, 70Bã€ãŠã‚ˆã³Swallow-MS 7Bã®æ–°ã—ã„instructãƒ¢ãƒ‡ãƒ«ï¼ˆSwallow-*-instruct-v0.1ï¼‰ã‚’å…¬é–‹ã—ã¾ã—ãŸã€‚ã‚ã¾ã‚Šé‡è¦–ã—ã¦ã“ãªã‹ã£ãŸæŒ‡ç¤ºè¿½å¾“èƒ½åŠ›ã‚„ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¿œç­”ã®æ”¹å–„ã«å–ã‚Šçµ„ã¿ã€MT-Benchã§éå»ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¸Šå›ã‚‹æ€§èƒ½ã‚’ç¢ºèªã—ã¾ã—ãŸã€‚
- tokyotech-llm/Swallow-MS-7b-instruct-v0.1
	- https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1
	- swallow 7B, 13B, 70Bã€ãŠã‚ˆã³Swallow-MS 7Bã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’æ”¹è‰¯ã—ã€æŒ‡ç¤ºè¿½å¾“æ€§ã‚„ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³å¿œç­”ã‚’å‘ä¸Šã•ã›ãŸãƒ¢ãƒ‡ãƒ«ã‚’Hugging Faceä¸Šã§å…¬é–‹ã—ã¾ã—ãŸã€‚ä»¥å‰ã«å…¬é–‹ã—ãŸãƒ¢ãƒ‡ãƒ«ã¨æ¯”ã¹ã¦ã€MT-Benchã®ã‚¹ã‚³ã‚¢ã§å¤§å¹…ã«æ”¹å–„ã—ã¦ã„ã¾ã™
- Swallow-MS-7B-Instruct-V0.1ã‚’ElyzaTasks100ã§è©•ä¾¡ã—ãŸã‚‰å¹³å‡2.82ç‚¹ã ã£ãŸã€‚ç¾ç’°å¢ƒã§ã¯ã‚‚ã¯ã‚„å¤§ã—ãŸäº‹ãªã„ã¨è¨€ã‚ã–ã‚‹ã‚’å¾—ãªã„ã€‚ã§ã‚‚ChatNTQã‚ˆã‚Šã¯ã‹ãªã‚Šå¼·ã„ã¨ã„ã†äº‹ã¯ChatVectorã‚’è¶³ã™ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æœ‰èƒ½ã‹ã‚‚ã—ã‚Œãªã„
	- https://x.com/umiyuki_ai/status/1783911959789969816
- ã€Appleã®æ–°ã—ã„OpenELMãƒ¢ãƒ‡ãƒ«ã‚’MLX LMã§ã€‘
	- https://x.com/hokazuya/status/1783808939773304957
	- 512ãƒˆãƒ¼ã‚¯ãƒ³ã€340Token/S
	- M3 Pro Mac (64GB)ã§16ãƒ“ãƒƒãƒˆã®270Mãƒ¢ãƒ‡ãƒ«ã§è¶…é«˜é€Ÿãƒ­ãƒ¼ã‚«ãƒ«LLMãŒå®Ÿç¾ã€‚
-  Weave ã¨ Elyza-tasks-100 ã§ ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’è©•ä¾¡ã™ã‚‹ by npakaã•ã‚“	
	- https://note.com/npaka/n/nc0c8d5beacff?sub_rt=share_h
	- ã€Œ**Weave**ã€ã¯ã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨˜éŒ²ã€å®Ÿé¨“ã€è©•ä¾¡ã®ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™
	- ã€Œ**Elyza-tasks-100**ã€ã¯ElyzaãŒæä¾›ã™ã‚‹æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ç”¨ã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚
- Domingosæ°ã€AIã®èƒ½åŠ›ãŒäººé–“ãƒ¬ãƒ™ãƒ«ã§é£½å’Œã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã¦ã„ã‚‹ã“ã¨ã‚’æŒ‡æ‘˜ã—ã¦ã„ã‚‹ãŒã€ã€
	- https://x.com/rmaruy/status/1784154638390104188
	- ã‚€ã—ã‚ã“ã‚Œã‚‰ã®ã‚¿ã‚¹ã‚¯ã§120%ã‚„200%ã‚’æœ‰æ„å‘³ã«è­°è«–ã§ãã‚‹ã®ã‹ã¨ã„ã†æ–¹ãŒæ°—ã«ãªã‚‹ã€‚ã¨ã„ã†æ„å‘³ã§ã€Domingosæ°ã®æ„å›³ã¨ç•°ãªã‚‹æ„å‘³ã§è¶…çŸ¥èƒ½åˆ°æ¥ãƒ“ã‚¸ãƒ§ãƒ³ã¸ã®ç–‘ç¾©ã«ãªã£ã¦ã„ã‚‹ã€‚
- ãƒ™ã‚¤ã‚ºæ¨è«–ã‚’ä½¿ã£ã¦ã¿ã‚ˆã†
	- https://x.com/makaishi2/status/1784115819791913065
	- ã€Pythonã§ã‚¹ãƒ©ã‚¹ãƒ©ã‚ã‹ã‚‹ãƒ™ã‚¤ã‚ºæ¨è«–ã€Œè¶…ã€å…¥é–€ã€è‘—è€…
- ã€éšæ™‚æ›´æ–°ã€‘ä¸»è¦ãªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒè¡¨
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- å±…åˆã‚ã›ãŸæ­Œé…ä¿¡ã«æ··ã–ã‚‹ NVIDIA $NVDA CEO ã‚¸ã‚§ãƒ³ã‚¹ãƒ³ãƒ»ãƒ•ã‚¡ãƒ³
	- https://x.com/woodstockclub/status/1784179786082128351
	- é…ä¿¡è€…ã®2äººã€Œã‚¸ã‚§ãƒ³ã‚¹ãƒ³ï¼Ÿèª°ï¼Ÿï¼Ÿã€
-  é«˜é€ŸAIãƒãƒƒãƒ—ã§è©±é¡Œã®Groqã®APIã‚’Streamlitã§ä½¿ã†æ–¹æ³•
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
	- é«˜é€ŸAIãƒãƒƒãƒ—ã§è©±é¡Œã®Groqã®APIã‚’Streamlitã®ã‚³ãƒ¼ãƒ‰ã®è¨˜äº‹ã‚’æ›¸ã„ã¦ã¿ã¾ã—ãŸã€‚OpenAIã®APIã¨è¡¨è¨˜ãŒä¼¼ã¦ã„ã‚‹ã®ã§æ›¸ãã‚„ã™ã„ã§ã™ã­ã€‚
- Swallow-MS-7Bã‚„RakutenAI-7Bã¯ãƒˆãƒ¼ã‚¯ãƒ³ã®èªå½™ãŒæ‹¡å¼µã•ã‚Œã¦ã‚‹äº‹ã«æ°—ä»˜ã„ãŸãŒã€ã“ã‚Œã£ã¦æ‹¡å¼µã•ã‚Œã¦ãªã„ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ¼ã‚¸ã—ãŸã‚‰ã‚¢ã‚«ãƒ³ã®ã ã‚ã†ã‹
	- https://x.com/umiyuki_ai/status/1784274430816034898
- ã€Whisper.cpp-CLIã€‘
	- https://x.com/hokazuya/status/1784554378118246440
	- ãƒ­ãƒ¼ã‚«ãƒ«ã§é«˜ç²¾åº¦ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ãŒã§ãã‚‹Whisperç’°å¢ƒãŒã€ã‚‚ã®ã®200msã§ä½œã‚Œã¦ã—ã¾ã†ã¨ã®Pyplãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒOSSã§
- 


## 4/21

ä»Šé€±ã¯ã€æœ€å¤§ï¼“å€é«˜é€Ÿã¨ã„ã†æ—¥æœ¬èªGPT-4ã®é–‹ç™ºã®ç™ºè¡¨ã‚‚ã‚ã£ãŸã‘ã©ã€ãªã‚“ã¨ã„ã£ã¦ã‚‚ãƒ¡ã‚¿ã‹ã‚‰llama3ã®å¾…æœ›ã®å…¬é–‹ã€‚æœ€åˆã¯8bã¨70bãŒå…¬é–‹ã•ã‚Œã€ã•ã‚‰ãªã‚‹å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚‚é–‹ç™ºä¸­ã¨ã®ã“ã¨ã€‚lllama3ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«ç”¨ã„ãŸPyTorchã®æ–°æ©Ÿèƒ½tochtuneã‚‚å…¬é–‹ã€‚æ—©é€Ÿã€é‡å­åŒ–ã€MoEåŒ–ã€ãƒ•ã‚¡ã‚¤ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®å®Ÿè¡Œä¾‹ãŒå…¬é–‹ã•ã‚Œã€MXã§8GB M2 miniã§ã®å‹•ä½œç¢ºèª!ã€ollamaã®å¯¾å¿œã€ã•ã‚‰ã«ã¯Groqã«ä¹—ã£ã‹ã£ã¦ãƒ‡ãƒ¢ã‚µã‚¤ãƒˆã§Llama3-70BãŒ300t/sã®è¶…çµ¶çˆ†é€Ÿæ¨è«–ã‚’è¦‹ã›ãŸãªã©ã®ä¸€é€šã‚ŠãŒï¼‘é€±é–“ã§é€²ã‚€ã€‚RAGã§ã®llama3ã®åˆ©ç”¨ä¾‹ã‚‚LangChainã‹ã‚‰ç´¹ä»‹ãŒã‚ã£ãŸãŒã€CommandRï¼‹ã‚‚llama3ã‚‚ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä¸ãˆã‚‹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒç‹¬ç‰¹ãªã®ã§ã€LLMã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã«ä½¿ã†äººã¯è¦æ³¨æ„ã ã€‚1bitã®LLMã‚‚ã€shi3zã•ã‚“ã®è‡ªä½œè©•ä¾¡ã‚„ã€æ¤æ©‹ã•ã‚“ã«ã‚ˆã‚‹GPUã§ã¯ãªã„ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ¡ã‚¤ãƒ‰ã«ã‚ˆã‚‹AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã€Œã‚«ã‚¹ã‚¿ãƒ AIã€ã®å¯èƒ½æ€§ãªã©ã€ã„ã„è¨˜äº‹ãŒã§ã¦ããŸã€‚ChatVectorã«ã‚ˆã‚‹LLMæ€§èƒ½å‘ä¸Šã‚‚ã€å…ˆé€±ã«å¼•ãç¶šãã€Bakuã•ã‚“ã®ã€ChatNTQ 7B ã¨ LightChatAssistant 2x7B ã®æ—¥æœ¬èªèƒ½åŠ›ã‚’è©¦ã™è¨˜äº‹ãŒç¥è¨˜äº‹ã¨ã—ã¦è©±é¡Œã«ã€‚LightChatAssistantã£ã¦ã®ã¯ãã‚“ãªã«ã™ã”ã„ã®ã‹ã€‚ä½œã£ã¦ã¿ãŸã‚‰æ€§èƒ½ãŒé«˜ã‹ã£ãŸã¨ã„ã†Japanese-Starling-ChatV-7B-GGUFãªã©ã‚‚å‡ºãŸã‚Šã€ChatVectorç´¹ä»‹ã®å…ˆé§†è€…ã¯ã¡ã•ã‚“ã‹ã‚‰Swallow-MS-7b-v0.1-ChatSkill-LABãŒå‡ºãŸã‚Šã€èƒ½åŠ›åŠ ç®—ã®çµ„ã¿åˆã‚ã›ã®æœ€é©è§£ã‚’optuneã‚’ã¤ã‹ã£ã¦å®Ÿè¡Œãƒ»è©•ä¾¡ã¨ã‹ã€ã€LLMã®èƒ½åŠ›ã®è¶³ã—ç®—å¼•ãç®—ã—ã¤ã¤æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ã¨ã„ã†ä¸€æ®µãƒ¡ã‚¿ãªä¸–ç•ŒãŒé–‹ã‘ãŸã€‚PFNã®ä¸¸å±±ã•ã‚“ãŒç´¹ä»‹ã•ã‚ŒãŸã€LLMã‚’ã¤ã‹ã£ã¦è¨€è‘‰ã ã‘ã§ã€ç·šå½¢å›å¸°ã‚’ã•ã›ã‚‹ã¨ã„ã†è«–æ–‡ã€ã©ã‚“ãªãƒ¢ãƒ‡ãƒ«ã‚’å†…éƒ¨ã«æŒã£ã¦ã„ã‚‹ã‚“ã ã¨ã„ã†æ„å‘³ã§é¢ç™½ã„ã€‚ Cambridgeå¤§å­¦ã®U. Anwar, D. Kruegeræ°ã‚‰40å!ã«ã‚ˆã‚‹ã€LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨å®‰å…¨æ€§ã®æœªè§£æ±ºå•é¡Œã«é–¢ã™ã‚‹175ãƒšãƒ¼ã‚¸ã®ç·èª¬è«–æ–‡ã¯ã™ã”ã„ã€AIã‚¬ãƒãƒŠãƒ³ã‚¹ã®ã‚ªãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒ‰ãƒãƒ³ãƒ‰ãƒ–ãƒƒã‚¯ã‚‚ã‚ã‚Šã€UKã§ã¯ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨ã‚¬ãƒãƒŠãƒ³ã‚¹ã®å¤§ããªæ‹ ç‚¹ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã€‚ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã‹ã‚‰ã€WizardLM-2 ã®7bã¨8x22bãŒç™ºè¡¨ã€Evolve Instructã¨ã„ã†æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã®èƒ½åŠ›ã‚„ã„ã‹ã«ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚‚æŒã£ã¦ã„ã‚‹ã¨ã‹ã€åµã®äºˆæ„Ÿã€‚Qwen1.5-7B-Chat-GGUFã‚‚å‡ºãŸã€æ¥é€±ã‚ãŸã‚ŠQwen1.5ãƒ™ãƒ¼ã‚¹ã®æ—¥æœ¬èªLLMãŒå‡ºã¦ãã‚‹ã®ã§ã¯ã€‚DeepMindã®ã€ŒMany-shotã€å¤šæ•°ä¾‹ç¤ºå­¦ç¿’ã®æœ‰åŠ¹æ€§ã‚„ã€RAGã®MiniCheckã€è¤‡æ•°ã®çŸ¥è­˜ã‚’çµ„ã¿åˆã‚ã›ã‚‹Chain-of-Abstraction (CoA) Reasoningãªã©ã®LLMæ¨è«–ã§ã®é€²å±•ã‚‚ã‚ã£ãŸã€‚ä¸¸å±±éš†ä¸€ã•ã‚“ã€AIç§‘å­¦ã®ä½•ãŒâ€œå“²å­¦â€ã¨ã„ã†å•ã„ï¼ˆã‚¹ãƒ©ã‚¤ãƒ‰ï¼‰ã‚‚è‰¯ã„ã—ã€ã€ŒAIå”åƒæ™‚ä»£ã«ç ”ç©¶è€…ã¯ã©ã†ç”Ÿãã‚‹ã‹ã€ã¨ã„ã†ã‚¤ãƒ™ãƒ³ãƒˆã‚‚é¢ç™½ã„ã€‚AIãŒï¼ˆå¾“æ¥ã®ï¼‰ç ”ç©¶ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ãªã‚‰ã°ã€AIç ”ç©¶è€…ã¯ãªã«ã‚’ã™ã‚‹ã®ã‹ã¿ãŸã„ãªæ„Ÿã˜ã€‚ã•ãã»ã©ã®UKã¨æ¯”ã¹ã‚‹ã¨ã“ã®ã‚ãŸã‚Šã®ç ”ç©¶è€…å±¤ãŒè–„ã„ã®ã‹ãªã€‚ãã®ä»–ã¨ã—ã¦ã¯ã€Swallow-MXã‚’ä½¿ã£ãŸQ&Aãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã‚ã‚‹AutoWikiQAã¨ã‹ã€MiniCPM-V-2ã®ãƒ‡ãƒ¢ã®å…¬é–‹ã€å•†ç”¨åˆ©ç”¨å¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«LLMã€idefics-8bãªã©ã‚‚å‡ºã¦ããŸã€‚

- openbmb/MiniCPM-V-2
	- MiniCPMã®ãƒ‡ãƒ¢ãŒå…¬é–‹
	- https://huggingface.co/spaces/openbmb/MiniCPM-V-2
- OpenAI Japanã®ç™ºè¶³ã¨ã¾ã•ã‹ã®æ—¥æœ¬èªGPT-4ã®ç™ºè¡¨ã€‚
	- https://openai.com/blog/introducing-openai-japan
	- ã€Œæ—¥æœ¬èªã®ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ã¨è¦ç´„ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ãŠã‚ˆã³ã‚³ã‚¹ãƒˆåŠ¹ç‡ã‚’å‘ä¸Šã•ã›ã€å‰ãƒ¢ãƒ‡ãƒ«ã¨æ¯”è¼ƒã—ã¦ã€æœ€å¤§3å€é«˜é€Ÿã«å‹•ä½œã—ã¾ã™ã€‚ã€
- ChatNTQ 7B ã¨ LightChatAssistant 2x7B ã®æ—¥æœ¬èªæ€§èƒ½ã‚’æ¸¬å®šã™ã‚‹
	- https://sc-bakushu.hatenablog.com/entry/2024/04/10/191420
	- ã€Œ[ChatNTQ-JA-7B-v0.1](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)ã€ã¨ã€ãã®MoEãƒ¢ãƒ‡ãƒ«ã€Œ[LightChatAssistant 2x7B](https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B)ï¼ˆæ”¹ç§°ã‚ã‚Šï¼‰ã€ã«ã¤ã„ã¦ã€ã‹ãªã‚Šæ€§èƒ½ãŒè‰¯ã•ãã†ãªæ„Ÿè§¦ãŒå¾—ã‚‰ã‚ŒãŸã®ã§ã€è¿½åŠ ã§ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ãŸã€‚
	- LightChatAssistantã¯ChatNTQã¨AntlerãŒã‚¸ãƒ§ã‚°ãƒ¬ã‚¹é€²åŒ–ã—ã¦å¥‡è·¡ã®ã‚·ãƒŠã‚¸ãƒ¼ã‚’èµ·ã“ã—ã¦ã€ELYZATasks100ãƒ™ãƒ³ãƒã§35Bã®Command Rã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’å‡ºã—ã¦ã—ã¾ã†
	- LightChatAssistantã§ã¯Mistral 7B v0.2 Instructã‹ã‚‰ChatVectorã‚’æŠ½å‡ºã—ã¦ãŸã‘ã©ã€ã‚‚ã£ã¨æ€§èƒ½é«˜ãã†ãªStarling-LM-7B-betaã‹ã‚‰æŠ½å‡ºã—ãŸæ–¹ãŒã„ã‚“ã˜ã‚ƒã­ï¼Ÿã¨ã„ã†äº‹ã§æŠ½å‡ºã—ã¦ChatNTQã«è¶³ã—ã¦ã¿ãŸã‚‰ã€MoEã«ã‚‚ã—ã¦ãªã„å˜ãªã‚‹7Bãƒ¢ãƒ‡ãƒ«ã®æ™‚ç‚¹ã§ElyzaTasks100ãƒ™ãƒ³ãƒã§LightChatAssistantè¶…ãˆã®æ€§èƒ½ãŒå‡ºã¦ã—ã¾ã£ãŸï¼Command R-35Bã¨åŒç‚¹ã®ã‚¹ã‚³ã‚¢ï¼
- Heron-Bench: æ—¥æœ¬èªVisionï¼†Languageãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å…¬é–‹
	- https://arxiv.org/abs/2404.07824
	- https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench
	- æ—¥æœ¬èªã®Vision-Langugeãƒ¢ãƒ‡ãƒ«ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãŒãªã‹ã£ãŸã®ã§ä½œæˆã—ã€Turingã§é–‹ç™ºã—ãŸheronã‚’å«ã‚ã¦ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã‚’è¡Œã„ã¾ã—ãŸ~!!
- CS159: LLMs for reasoning lecture slides from Caltech
	- https://sites.google.com/view/cs-159-2024/lectures
- RTX4090+A6000(24+48GB VRAM)ã§command-r-plus-Q4_K_Mã‚’65/65 layer GPUã«è¼‰ã›ã¦ã‚‚6.5t/sãã‚‰ã„ãŒé™åº¦ã ã£ãŸã€‚ ãŠãã‚‰ãã€96GBã§ã¯ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãŒè¶³ã‚Šãªã„ã‹ã‚‰é…ã„ã€‚
	- https://x.com/Meteor_Eternal/status/1779807643668013534
- an introduction to agents and tools
	- https://x.com/llama_index/status/1779898403239125198
	- This short course is the perfect beginner sequence for anyone looking to get an overview of agent implementations, how to equip them with tools to perform tasks like advanced QA/RAG or anything else, and also some neat extensions (tool retrieval, step-wise execution).
- From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples
	- https://arxiv.org/pdf/2404.07544.pdf
	- LLMã«ã€ã€Œã“ã®å…¥åŠ›ã®å ´åˆå‡ºåŠ›ã¯ã“ã‚Œã€ã¨ã„ã†ä¾‹ç¤ºã‚’å…¥ã‚Œã¦ã€Œã§ã¯ã“ã®å…¥åŠ›ã®å ´åˆã®å‡ºåŠ›ã¯ï¼Ÿã€ã¨æ¨è«–ã•ã›ã‚‹ã¨ç·šå½¢å›å¸°ãƒ»éç·šå½¢å›å¸°ãŒã§ãã¦ã—ã¾ã†ã€ã¨ã„ã†è«–æ–‡ã€‚
- TFMC/Japanese-Starling-ChatV-7B-GGUF
	- https://note.com/bakushu/n/ne95340f04b41
	- LightChatAssistant-2x7Bã®æ—¥æœ¬èªãƒãƒ£ãƒƒãƒˆæ€§èƒ½ãŒã¨ã¦ã‚‚è‰¯ã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ä½œè€…ã•ã‚“ãŒç”¨ã„ãŸæ‰‹æ³•ï¼ˆChat Vector+MoEãƒãƒ¼ã‚¸ï¼‰ã‚’å¾Œè¿½ã„ã§æ¤œè¨¼ã—ã¦ã„ã‚‹ãªã‹ã§ã€ç™ºè¦‹ã€‚
	- 7Bã‚¯ãƒ©ã‚¹ã¨ã—ã¦ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¹ã‚³ã‚¢ãŒã‚„ãŸã‚‰é«˜ã„ãƒ¢ãƒ‡ãƒ«ãŒå‡ºã¦ããŸã®ã§ã€ŒJapanese-Starling-ChatV-7Bã€ã¨ã—ã¦å…¬é–‹ã—ã¦ã¿ã¾ã—ãŸã€‚
- HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- ChatVectorã‚’ä½¿ã£ã¦æ–°ã—ã„Apache2.0ã®Chatãƒ¢ãƒ‡ãƒ«ã‚’ä½œã‚Šã¾ã—ãŸã€‚ ChatVectoræŠ½å‡ºå…ƒã®ãƒ¢ãƒ‡ãƒ«ã‚‚Mixtral-8x7B-Instructã«ã‚ˆã‚‹äººå·¥ãƒ‡ãƒ¼ã‚¿(Synthetic Data)ã§å­¦ç¿’ã•ã‚ŒãŸã‚‚ã®ãªã®ã§ã€éš ã‚ŒãŸãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ±šæŸ“ã®å¿ƒé…ã¯ã‚ã‚Šã¾ã›ã‚“
-  é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ã‚‚ã¡ã„ãŸChatVectoråŠ ç®—ã®æœ€é©åŒ– byã€€ã¯ã¡ã•ã‚“
	- https://note.com/hatti8/n/na593650d688b
	- é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«ã€optunaã¨cmaes
	- é€²åŒ–çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ã£ã¦ã€ã“ã®é–¢æ•°ã®outputã§ã‚ã‚‹scoreã‚’æœ€é©åŒ–ï¼ˆæœ€å°åŒ–ï¼‰ã—ã¾ã™
		1. merging_ratioï¼ˆChatVectorã®åŠ ç®—æ¯”ç‡ã‚’å„layeræ¯ã«æŒã¤è¾æ›¸ï¼‰ã®å®šç¾©
		2. merging_ratioã«ã—ãŸãŒã£ã¦ã€ChatVectorã®ãƒãƒ¼ã‚¸
		3. ELYZA tasks 10ã®å®Ÿæ–½ã¨GPT4ã«ã‚ˆã‚‹è©•ä¾¡
- Foundational Challenges in Assuring Alignment and Safety of Large Language Models
	- https://llm-safety-challenges.github.io/
	- 2024.4.15 Cambridgeå¤§å­¦ã®U. Anwar, D. Kruegeræ°ã‚‰40åå¼±ã®å›½éš›ãƒãƒ¼ãƒ ã«ã‚ˆã‚‹ã€LLMã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã¨å®‰å…¨æ€§ã®æœªè§£æ±ºå•é¡Œã«é–¢ã™ã‚‹175ãƒšãƒ¼ã‚¸ã®ç·èª¬è«–æ–‡ã€‚
	- 1ï¼‰LLMã®ç§‘å­¦çš„ç†è§£ã€
	- 2ï¼‰è¨“ç·´æ‰‹æ³•ã‚„å®Ÿè£…å ´é¢ã®èª²é¡Œã€
	- 3ï¼‰ç¤¾ä¼šã«ãŠã‘ã‚‹èª²é¡Œã«åˆ†ã‘ã€
	- åºƒç¯„ãªæ–‡çŒ®èª¿æŸ»ã«åŸºã¥ã200è¶…ã®ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’åŒå®šã€‚
	- ã“ã®Anwar+2024è«–æ–‡ã¯ã™ã”ã„ã€‚ã€ŒLLMã®ä½•ãŒæŠ€è¡“çš„ãƒ»ç¤¾ä¼šçš„ãªå•é¡Œã«ãªã‚‹ã®ã‹ï¼Ÿã€ã‚’åŒ…æ‹¬çš„ã«æ´—ã„å‡ºã—ã€ã‹ã¤ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ãƒ³ã‚·ãƒ§ãƒ³ã®ãƒªã‚¹ãƒˆã«è½ã¨ã—è¾¼ã‚“ã§ã„ã‚‹ã€‚by maruyamaï½“ã‚ï½
- Running WizardLM-2 8x22B Q4_0 locally via ollama
	- https://x.com/ivanfioravanti/status/1780133719707197643
	- On an M2 Ultra I get: ~19.5 tokens/s
	- 80Gb??
- MaziyarPanahi/WizardLM-2-8x22B-GGUF(Q4_K_M)
	- https://x.com/alfredplpl/status/1780110628864274576
	- ã†ãƒ¼ã‚“æ—¥æœ¬èªãŒã‚„ã¯ã‚Šã‚¤ãƒã‚¤ãƒã ãª
- WizardLMã®ä½œã‚Šæ–¹
	- https://x.com/WizardLM_AI/status/1779937307690471834
	- æ–°ã—ã„WizardLM-2 7Bã®ã‚µã‚¤ã‚ºã§MT-BenchãŒClaude-2ã‚ˆã‚Šé«˜ã„ã£ã¦ã™ã”ã„ by ã¯ã¡
- WizardLM: Empowering Large Language Models to Follow Complex Instructions
	- https://arxiv.org/pdf/2304.12244.pdf
	- èª²é¡Œï¼šæ§˜ã€…ãªãƒ¬ãƒ™ãƒ«ã®è¤‡é›‘ã•ã‚’æŒã¤å¤§é‡ã®æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹ã“ã¨ã¯ã€æ™‚é–“ã¨åŠ´åŠ›ãŒã‹ã‹ã‚‹ã€‚
	- è§£æ±ºï¼šEvolve Instructæ–¹æ³•ã‚’ä½¿ç”¨ã—ã¦ã€LLMè‡ªä½“ãŒæŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- Introducing the Batch API: save costs and get higher rate limits on async tasks
	- https://platform.openai.com/docs/api-reference/batch
- Introducing Idefics 2
	- https://huggingface.co/collections/HuggingFaceM4/idefics2-661d1971b7c50831dd3ce0fe
	- An 8B Vision-Language Model - literally punching above its weight.
- Pytorchã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®æ©Ÿèƒ½torchtuneãŒå…¬é–‹
	- https://pytorch.org/blog/torchtune-fine-tune-llms/?utm_content=289842551&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024
	- llama3ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã“ã‚Œã§ã‚„ã£ãŸã‚“ã ã¨
-  AIç§‘å­¦ã®ä½•ãŒâ€œå“²å­¦â€ã®å•é¡Œã«ãªã‚‹ã®ã‹ã€€ï½å•ã„ãƒãƒƒãƒ”ãƒ³ã‚°ã®è©¦ã¿ï½
	- https://speakerdeck.com/rmaruy/aike-xue-nohe-ga-zhe-xue-nowen-ti-ninarunoka-wen-imatupingunoshi-mi
	- ã¾ã‚‹ã‚„ã¾ã•ã‚“
-  ã€ŒAIå”åƒæ™‚ä»£ã«ç ”ç©¶è€…ã¯ã©ã†ç”Ÿãã‚‹ã‹ã€(4/26)
	- https://share.hsforms.com/1NFOzzuNBSZq3K20gtPZ30wdxf90
	- æœ¬ã‚¤ãƒ™ãƒ³ãƒˆã§ã¯ã€ç ”ç©¶ã®è‡ªå‹•åŒ–ãƒ»è‡ªå¾‹åŒ–ãŒç›Šã€…åŠ é€Ÿã—ã¦ã„ãæœªæ¥ã«ãŠã„ã¦ã€ç ”ç©¶ã¨ã„ã†å–¶ã¿ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã—ã¦ã„ãã®ã‹ã€ãã®ä¸­ã§ç ”ç©¶è€…ã¯ã©ã†ç”Ÿãã‚‹ã¹ãã‹ã€ã¨ã„ã†ã“ã¨ã«ã¤ã„ã¦è­°è«–ã—ã¾ã™ã€‚  
	- AIãƒ­ãƒœãƒƒãƒˆé§†å‹•ç§‘å­¦ã‚’ç‰½å¼•ã™ã‚‹ä¸€æ‰å¤ªéƒã•ã‚“ã¨ã€AIç§‘å­¦ã‚’ä¿¯ç°çš„ã«è€ƒãˆã‚‹ä¸¸å±±éš†ä¸€ã•ã‚“ã«ã‚ˆã‚‹ç‰¹åˆ¥ãƒ‘ãƒãƒ«ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³ã‚„ã€ã€ŒAI Ã— â—¯â—¯å­¦ã€ã‚’ãƒ†ãƒ¼ãƒã«æœˆé¡æ”¯æ´å‹ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ•ã‚¡ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã«æŒ‘æˆ¦ä¸­ã®è‹¥æ‰‹ç ”ç©¶è€…8åã®ãƒ—ãƒ¬ã‚¼ãƒ³ã‚’é€šã—ã¦ã€ã€ŒAIå”åƒæ™‚ä»£ã«ç ”ç©¶è€…ã¯ã©ã†ç”Ÿãã‚‹ã‹ã€ã€çš†ã•ã‚“ã‚‚ä¸€ç·’ã«è€ƒãˆã¦ã¿ã¾ã›ã‚“ã‹ï¼Ÿ
- ç”ŸæˆAIã§GPUãŒã„ã‚‰ãªããªã‚‹ï¼Ÿã€€æ¥­ç•Œã‚’æºã‚‹ãŒã™ã€Œ1ãƒ“ãƒƒãƒˆLLMã€ã¨ã¯ä½•ã‹ã€è­˜è€…ã«èã„ãŸ
	- https://www.itmedia.co.jp/aiplus/articles/2404/16/news064.html
	- ã§ã¯ãã‚‚ãã‚‚â€œ1bitâ€ã¨ã¯ä½•ãŒ1bitãªã®ã‹ã€ã©ã†ã—ã¦1bitã«ãªã‚‹ã¨GPUãŒä¸è¦ã«ãªã‚‹ã®ã‹ã€‚LLMã§GPUãŒä¸è¦ã«ãªã‚‹ã¨ã©ã‚“ãªä¸–ç•ŒãŒè¨ªã‚Œã‚‹ã®ã‹ã€‚ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ¡ã‚¤ãƒ‰ã«ã‚ˆã‚‹AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã€Œã‚«ã‚¹ã‚¿ãƒ AIã€ã®é–‹ç™ºãƒ»æä¾›ã‚’è¡Œã†Laboro.AIã®æ¤æ©‹å¾¹å¤«CEOã«èã„ãŸã€‚
	- **æ¤æ©‹ï¼š**ä»Šå›ã®çµæœã‹ã‚‰ã€LLMã®æ¨è«–ã«ãŠã„ã¦ã€GPUã§ã¯ãªãåˆ¥ã®åŠå°ä½“ã®æ©Ÿæ§‹ãŒæœ€é©ã«ãªã£ã¦ã€åŠ‡çš„ã«è¨ˆç®—ãŒè»½ãæ—©ããªã‚‹å¯èƒ½æ€§ãŒé–‹ã‘ã¦ãã‚‹ã‚“ã§ã™ã€‚
	- è«–æ–‡ä¸­ã§ã‚‚ã€Groqã¨ã„ã†LLMã®æ¨è«–ã«ç‰¹åŒ–ã—ãŸLPUï¼ˆLanguage Processing Unitï¼‰ã®ç™»å ´ã«è§¦ã‚Œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚æ¬¡ä¸–ä»£åŠå°ä½“ã§ã®å¾©æ´»ã‚’ç‹™ã†æ—¥æœ¬ã®ç”£æ¥­ã«ã¨ã£ã¦ã‚‚ã€æ³¨è¦–ã—ã¦ã„ãã¹ããƒˆãƒ”ãƒƒã‚¯ã§ã¯ãªã„ã‹ã¨æ€ã„ã¾ã™
- ã“ã®å‰èª¿åˆã—ãŸæ”¹é€ Swallow-MXï¼ˆç¶™ç¶šæ—¥æœ¬èªå­¦ç¿’+instructionãƒ™ãƒ«ãƒˆãƒ«å¼·åŒ–ï¼‰ã¨Mixtral 8x22Bã‚’æ¯”è¼ƒã™ã‚‹ã¨çŸ­æ™‚é–“ä½¿ç”¨ã§ã¯å·®ç•°æ‰ãˆã«ãã„ãª ãã‚Œã ã‘8x22Bã®æ—¥æœ¬èªèƒ½åŠ›ã‚¢ãƒƒãƒ—ã—ã¦ã‚‹ã®ã¯é–“é•ã„ãªã„
	- https://x.com/AiXsatoshi/status/1778630270486552619
- Stanfordäººé–“ä¸­å¿ƒAIç ”ç©¶æ‰€ï¼ˆHAIï¼‰ã‹ã‚‰æ’ä¾‹ã®ã€ŒAI Index Report 2024ã€ã‚’ç™ºè¡Œ
	- https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf
	- 2024.4.16 Stanfordäººé–“ä¸­å¿ƒAIç ”ç©¶æ‰€ï¼ˆHAIï¼‰ã‹ã‚‰æ’ä¾‹ã®ã€ŒAI Index Report 2024ã€ã‚’ç™ºè¡Œã€‚æ˜¨å¹´ã‹ã‚‰å¤§å¹…ã«å¢—é‡ã—ãŸ500ãƒšãƒ¼ã‚¸è¶…ã®ç´™å¹…ã«ã¦ã€AIç ”ç©¶ã®è«–æ–‡æ•°ãƒ»ç‰¹è¨±ãƒ»å…ˆç«¯ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºå‹•å‘ãƒ»æŠ•è³‡é¡ãƒ»çµŒæ¸ˆçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãƒ»ç§‘å­¦ã‚„æ•™è‚²ã¸ã®å½±éŸ¿ãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹ãƒ»ç¤¾ä¼šå—å®¹ãªã©åŒ…æ‹¬çš„ã«å ±å‘Šã€‚
	- ã€ŒAIã¯äººé–“ã‚ˆã‚Šé«˜æ€§èƒ½ã ãŒä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆã§ã¯äººé–“ã®æ–¹ãŒå„ªç§€ã€ã€Œé«˜æ€§èƒ½AIã®å­¦ç¿’ã‚³ã‚¹ãƒˆã¯æ•°ç™¾å„„å††ã€ãªã©
- HuggingFaceM4/idefics-8b
	- https://huggingface.co/spaces/HuggingFaceM4/idefics-8b
	- æ˜ç¢ºã«å•†ç”¨åˆ©ç”¨å¯èƒ½ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¢
-  Google Colab ã§ idefics2 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n032c2bbaadb4?sub_rt=share_h
	- ã€ŒIdefics2ã€ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’å…¥åŠ›ã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡ºåŠ›ã™ã‚‹ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ç”»åƒã®è³ªå•å¿œç­”ã€è¦–è¦šçš„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®èª¬æ˜ã€è¤‡æ•°ç”»åƒã‚’ã‚‚ã¨ã«ç‰©èªä½œæˆã€æ–‡æ›¸ã‹ã‚‰ã®æƒ…å ±æŠ½å‡ºãªã©ã‚’å®Ÿè¡Œã§ãã¾ã™
- AIã®å‡¦ç†èƒ½åŠ›ï½¤1å¹´ã§25å€ã€€æ­»è”µã®ï½¢çŸ¥èƒ½è³‡æœ¬ï½£ãŒç«¶äº‰åŠ›ã« by shi3zã•ã‚“
	- https://www.nikkei.com/prime/digital-governance/article/DGXZQOUC092UR0Z00C24A4000000
	- ãã®ã‚ˆã†ãªä¸–ç•Œã§ä¾¡å€¤ã‚’é«˜ã‚ã‚‹ã®ã¯ã€æ­»è”µã•ã‚ŒãŸæ›¸ç±ã‚„å‹•ç”»ãªã©ã®ã€ŒçŸ¥èƒ½è³‡æœ¬ã€ã¨ã„ã†ã€‚ã€ŒAIè³‡æœ¬ä¸»ç¾©ã€ã¨ã„ã†æ–°ãŸãªçµŒæ¸ˆã®å§¿ã‚’æå”±ã™ã‚‹ã€
-  MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents
	- https://arxiv.org/abs/2404.10774
	- RAGãªã©ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ã„ã¦ LLM ã«ç”Ÿæˆã•ã›ã‚‹å ´åˆã«ãã‚‚ãã‚‚ç”Ÿæˆã—ãŸã‚‚ã®ãŒã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ã«åŸºã¥ã„ã¦ç”Ÿæˆã§ãã¦ã„ã‚‹ã®ã‹ï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ï¼‰ãŒèª²é¡Œã«ãªã‚Šã¾ã™ãŒã€ãã‚Œã‚’åŠ¹ç‡çš„ã«è¡Œã†ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ  MiniCheck ã®ææ¡ˆã€‚
	- GPT-3.5/4ã‚’ç”¨ã„ã¦ã€äººãŒæ›¸ã„ãŸæ–‡ç« ã‚’ã‚‚ã¨ã«FACTã‚’æŠ½å‡ºã—ãŸã‚Šè¦ç´„ç”Ÿæˆã‚’ã—ãŸã‚Šã—ãªãŒã‚‰ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã—ãŸé«˜å“è³ªãªåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã€ãã‚Œã‚’ç”¨ã„ã¦å°ã•ãªãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨ã§ã€GPT-4ã¨åŒç­‰ã®æ€§èƒ½ã§400åˆ†ã®1ä»¥ä¸‹ã®ã‚³ã‚¹ãƒˆã§ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸãã†ã§ã™ã€‚
- RAGã‚’è¤‡é›‘ãªè³ªå•ã«å¼·ãã™ã‚‹æ‰‹æ³•ã€ŒCoAã€ã«ã¤ã„ã¦
	- https://zenn.dev/knowledgesense/articles/508187f1c616e3
	- ã€ŒChain-of-Abstraction (CoA) Reasoningã€
	- CoAãŒå¾“æ¥ã®RAGã‚ˆã‚Šã‚‚åŠ›ã‚’ç™ºæ®ã§ãã‚‹ã‚·ãƒ¼ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒã€Œè¤‡æ•°ã®çŸ¥è­˜ã‚’çµ„ã¿åˆã‚ã›ãªã‘ã‚Œã°æ­£ç­”ã§ããªã„ã€ã‚ˆã†ãªè³ªå•ã ã£ãŸå ´åˆã§ã™ã€‚é€šå¸¸ã®RAGã§ã¯1å›ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã§å›ç­”ã«ä½¿ãˆã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚ˆã†ã¨ã—ã¾ã™ãŒã€CoAã§ã¯ã€å•é¡Œï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ï¼‰ã‚’è¤‡æ•°ã®å•é¡Œã«åˆ†è§£ã—ã€è¤‡æ•°å›ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚’è¡Œã£ãŸä¸Šã§ç·åˆçš„ãªå›ç­”ã‚’ç”Ÿæˆã§ãã¾ã™
- Qwen/Qwen1.5-7B-Chat-GGUF
	- https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF
	- 7 billion parameters coding chat model (~5GB RAM needed)
-  1BitLLMã®å®ŸåŠ›ã‚’è¦‹ã‚‹ by shi3zã•ã‚“
	- https://note.com/shi3zblog/n/ndd1f27fff31c?sub_rt=share_pb
	- æ™®é€šã®HuggingFaceã®ãŠä½œæ³•ã¨ã¯ã‹ãªã‚Šé•ã†ã®ã§æ³¨æ„ãŒå¿…è¦ã€‚  ã¾ãšã€ã“ã®HuggingFaceãƒªãƒã‚¸ãƒˆãƒªã‚’ä¸¸ã”ã¨git cloneã™ã‚‹
	- ã“ã‚Œã‚’ã‚„ã‚‰ãšã«ã„ã¤ã‚‚ã®å‡¡ä¾‹ã¿ãŸã„ã«ã„ããªã‚Špipelineã«èª­ã¿è¾¼ã‚‚ã†ã¨ã™ã‚‹ã¨è¬ã®ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¦æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ã«ãªã‚‹ã€‚æµ·å¤–ã§ã‚‚æ‚©ã‚“ã§ã‚‹äººãŒä½•äººã‚‚ã„ã‚‹ã¿ãŸã„ã ã€‚ã¾ã‚å€‹äººçš„ã«ã¯ã€Œã“ã‚“ãªèª¬æ˜ã§èª°ãŒã‚ã‹ã‚‹?ã€ã¨æ€ã†ãŒã€‚
- mistralai/Mixtral-8x22B-Instruct-v0.1
	- https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1
	- Mixtral-8x22B Instract ããŸã‚ã€œ
- Build RAG, Function Calling, and Agents with llama_index and  MistralAI8x22b 
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/mistralai/
- 24/04/18 ãƒ­ãƒ¼ã‚«ãƒ«ã§Command Rã‚„Command R+ã‚’å‹•ã‹ã™æ™‚ã®ä½œæ³•
	- https://six-loganberry-ba7.notion.site/24-04-18-Command-R-Command-R-ff8455f1dba543168d5a7768705e0043
	- å®Ÿã¯Command Rã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ãªã„ã¨æ­£ã—ãå›ç­”ãŒè¿”ã£ã¦ã“ãªã„ã‚‰ã—ã„
	- <|START_OF_TURN_TOKEN|><|USER_TOKEN|>Who are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
	- ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã‚ã‚‹ãªã—ã§å›ç­”ã®ã‚¯ã‚ªãƒªãƒ†ã‚£ã¯å¤©ã¨åœ°ã»ã©é•ã£ã¦ãã‚‹ã‹ã‚‰æ³¨æ„ã—ã‚ˆã†ã€‚
- Introducing Meta Llama 3:
	- https://ai.meta.com/blog/meta-llama-3/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama3
	- the most capable openly available LLM to date.
	- Llama3ã®ãƒªãƒªãƒ¼ã‚¹ç¬¬ä¸€å¼¾ã¯8Bãƒ¢ãƒ‡ãƒ«ã¨70Bãƒ¢ãƒ‡ãƒ«ï¼ãã‚Œãã‚Œãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆãŒã‚ã‚Šï¼HuggingFaceã‹ã‚‰ï¼¤ï¼¬ã§ãã‚‹ï¼8Bãƒ¢ãƒ‡ãƒ«ã¯ãƒ™ãƒ³ãƒã§Mistral-7Bã‚„Gemma-7Bã‚’æ’ƒå¢œï¼70Bãƒ¢ãƒ‡ãƒ«ã¯GeminiPro1.5ã‚„Claude3Sonnetã‚’æ’ƒå¢œï¼äººé–“ã«ã‚ˆã‚‹è©•ä¾¡ã§ã‚‚Sonnetã€MistralMediumã€GPT-3.5ã«å‹åˆ©ï¼
	- Contexté•·ã¯8kTokenã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¯80å„„ã¨700å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚ãªã‚“ã¨4000å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¶…ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚‚å­¦ç¿’ä¸­ï¼700å„„ã®ã»ã†ã¯ç¾åœ¨ã®ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢Modelã«æ€§èƒ½çš„ã«è‚‰è–„ã—ã¤ã¤ã‚ã‚‹çŠ¶æ…‹ã€‚
- LangChain x Mistral RAG Agent Cookbooks + Video
	- https://x.com/LangChainAI/status/1780994907903263159
	- With the release of new Mixtral 8x22B, there's high interest in building agents with open source LLMs.
- VARIATIONAL BAYESIAN LAST LAYERS
	- https://arxiv.org/pdf/2404.11599.pdf
	- Neural Networksã®æœ€çµ‚å±¤ä»¥å¤–ã¯å›ºå®šã•ã‚Œã¦ã„ã‚‹ã¨æ€ã£ã¦ã€æœ€çµ‚å±¤ã®ã¿ã® 1-layer ãª Bayesian Neural Network ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«åŒ–ã—æœ€çµ‚å±¤ã®æœ€é©åŒ–ã‚’ã—ã¤ã¤å¤‰åˆ†ãƒ™ã‚¤ã‚ºæ¨å®šã™ã‚‹æ çµ„ã¿ Variational Bayesian Last Layers ï¼ˆVBLLï¼‰ã®ææ¡ˆã€‚
- Reliable, fully local RAG agents with Llama3
	- Here, we show to how build reliable local agents using LangGraph and Llama3-8b from scratch.
	- https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb
- ä¾‹ã®SRAMãƒ¡ãƒ¢ãƒªã®AIãƒãƒƒãƒ—ã‚’å±±ç››ã‚Šã«ç©ã¿ã¾ãã£ãŸæ§‹æˆã®Groqã®ã‚µã‚¤ãƒˆã§Llama3-70BãŒ300t/sã®è¶…çµ¶çˆ†é€Ÿæ¨è«–
	- https://x.com/umiyuki_ai/status/1781529537102352827
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ•°ç™¾ã€œæ•°åƒã®ä¾‹ã‚’å«ã‚ã¦LLMã«ã‚¿ã‚¹ã‚¯ã‚’è¡Œã‚ã›ã‚‹ã€Many-shotï¼ˆå¤šã‚·ãƒ§ãƒƒãƒˆï¼‰ã€ãŒDeepMindã«ã‚ˆã‚Šæ¤œè¨¼ã•ã‚Œã¦ã„ã¾ã™
	- çµæœã€åŸºæœ¬çš„ã«ä¾‹ãŒå¤šããªã‚‹ã»ã©æ€§èƒ½ãŒä¸ŠãŒã‚‹ã¨ã®ã“ã¨ã€‚äº‹å‰å­¦ç¿’ã«ã‚ˆã‚‹æ€ã„è¾¼ã¿ã‚’è¦†ã™ã“ã¨ã‚‚ã€‚äººé–“è£½ã®ä¾‹ãŒãªã‘ã‚Œã°ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆã®ä¾‹ã§ã‚‚åŠ¹æœã‚ã‚Š
-  [llama.cppï¼šiMatrixé‡å­åŒ–ã¯æ—¥æœ¬èªæ€§èƒ½ã«ã©ã†å½±éŸ¿ã™ã‚‹ã‹ï¼Ÿ](https://sc-bakushu.hatenablog.com/entry/2024/04/20/050213)
	- é‡å­åŒ–æ™‚ã®ãƒ¢ãƒ‡ãƒ«åŠ£åŒ–ã‚’æŠ‘åˆ¶ã™ã‚‹é‡è¦åº¦è¡Œåˆ—ï¼ˆiMatrix; Importance Matrixï¼‰è¨ˆç®—ã®è©±é¡Œã§ã™ã€‚
	- æœ€è¿‘ã¯HuggingFaceã«ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹GGUFã‚‚å¤šããŒiMatrixç‰ˆã¨ãªã£ã¦ã„ã¾ã™ãŒã“ã‚Œã‚‰ã®é‡å­åŒ–ã§ã‚ˆãä½¿ã‚ã‚Œã¦ã„ã‚‹iMatrixè¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ä»¥ä¸‹ã®2ç¨®é¡ã®ã‚ˆã†ã§ã™ã€‚
- MLX ã§ Llama 3 ã‚’è©¦ã™
	- https://note.com/npaka/n/n21fa74396545?sub_rt=share_h
- Llama 3ãŒGroqã«ç™»å ´
	- https://x.com/kyo_takano/status/1781595042840559908
	- GroqãŒãªãœã“ã‚“ãªã«é€Ÿã„ã®ã‹ï¼Ÿãã‚Œã¯GPUã§ã¯ãªãLLMã«æœ€é©åŒ–ã•ã‚ŒãŸASICã‚’ä½¿ã£ã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€‚Groqã¯æœ€è¿‘æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‚’ä½œã£ãŸã°ã‹ã‚Šã§ã€ãã“ã§ä½•å€‹ASICã‚’ä½¿ã£ã¦ã„ã‚‹ã®ã‹ç›´æ¥èã„ãŸã‚‰700å€‹ä»¥ä¸Šã¨ç­”ãˆã¦ãã‚Œã¾ã—ãŸã€ä»Šå¾Œãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§éœ€è¦ãŒé«˜ã¾ã‚‹ã¨Groqã¯ã•ã‚‰ã«æ€¥æˆé•·ã—ã¦ãã‚‹ã¨æ€ã„ã¾ã™ã€‚
- å°ã•ã„è¨ˆç®—ã‚³ã‚¹ãƒˆã§ã‚¹ãƒãƒ¼ãƒˆã«LLMã‚’ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°!-Hugging Face PEFTå…¥é–€(å‰ç·¨)
	- https://zenn.dev/elith/articles/3ec1d319c8a40f
	- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡ã®è‰¯ã„Fine Tuningæ‰‹æ³•(Parameter-Efficient Fine Tuningã€ PEFT)ã«ã¤ã„ã¦ã€ã‚µãƒ¼ãƒ™ã‚¤ã‚’è¡Œã„ã¾ã—ãŸã€‚
- With the latest MLX, 4-bit Llama 3 8B runs nicely on an 8GB M2 mini.
	- https://x.com/awnihannun/status/1781345824611680596
	- 512 tokens at 18.8 toks-per-sec
- cl-nagoya/auto-wiki-qa
	- https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa
	- æ±å·¥å¤§ã®Swallow-MXã‚’ç”¨ã„ã¦Wikipediaã®ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãè³ªå•ã¨å›ç­”ã‚’ç”Ÿæˆã•ã›ãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ AutoWikiQA ã‚’HuggingFaceä¸Šã«å…¬é–‹ã—ã¾ã—ãŸï¼
	- ç´„240ä¸‡äº‹ä¾‹ã¨æ—¥æœ¬èªQAãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã§ã‚‚æœ€å¤§è¦æ¨¡ã‹ã¤é«˜å¤šæ§˜æ€§ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™
- The Oxford Handbook of AI Governance
	- https://global.oup.com/academic/product/the-oxford-handbook-of-ai-governance-9780197579329?cc=jp&lang=en&
	- AIã‚¬ãƒãƒŠãƒ³ã‚¹ã®ã‚ªãƒƒã‚¯ã‚¹ãƒ•ã‚©ãƒ¼ãƒ‰ãƒãƒ³ãƒ‰ãƒ–ãƒƒã‚¯ã€‚49æœ¬é€šèª­ã™ã‚‹äººå‡ºã‚‹ã€€by ç”Ÿè²å…ˆç”Ÿ
- lama-3-8b's in-context learning is unbelievable.
	- https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/
- ã„ã¡ã°ã‚“ã‚„ã•ã—ã„ãƒ­ãƒ¼ã‚«ãƒ« LLM
	- https://note.com/schroneko/n/n8b1a5bbc740b#57403f33-7b40-444e-9342-c8bf11458d18
	- ãƒ­ãƒ¼ã‚«ãƒ« LLM åˆã‚ã¾ã—ã¦ã®æ–¹ã§ã‚‚å‹•ã‹ã›ã‚‹ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
	- Ollama ã‚’ä½¿ãˆã°ç°¡å˜ã« LLM ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ã‹ã›ã‚‹
- Crystalcareai/llama-3-4x8b
	- https://huggingface.co/Crystalcareai/llama-3-4x8b
	- This is an MOE of Llama-3-8b with 4 experts. This does not use semantic routing, as this utilizes the deepseek-moe architecture. There is no routing, and there is no gate - all experts are active on every token.
	- äºˆæƒ³ã¯ã—ã¦ãŸã‘ã©ã€ã‚‚ã†Llama3ã®MoEãŒã§ãã¦ã‚‹ã€€by ã¯ã¡ ã•ã‚“
-  Google Colab ã§ Llama 3 ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã™
	- https://note.com/npaka/n/n315c0bdbbf00?sub_rt=share_h
	- ä»Šå›ã¯ã€ã”ã–ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§å­¦ç¿’ã—ã¾ã™ã€‚AIãŒã€Œæˆ‘ã€ã‚Šã‚“ãˆã‚‚ã‚“ã¯æ€ã†ã€‚â—¯â—¯ã§ã”ã–ã‚‹ã€‚çŸ¥ã‚‰ã‚“ã‘ã©ã€‚ã€çš„ãªå£èª¿ã«ãªã‚Šã¾ã™ã€‚
	- ç·´ç¿’ã¨ã—ã¦500ã‚¹ãƒ†ãƒƒãƒ—ã ã‘å­¦ç¿’ã—ã¾ã™ã€‚æŒ‡ç¤ºã«å¿œã˜ã¦ã€wandbã®APIã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚8åˆ†ã»ã©ã§å­¦ç¿’å®Œäº†ã—ã¾ã™ã€‚
	- æˆ‘ã€ã‚Šã‚“ãˆã‚‚ã‚“ã¯æ€ã†ã€‚ ãƒãƒŸã¯ä¸€ç•ªã‹ã‚ã„ã„ã€‚çŸ¥ã‚‰ã‚“ã‘ã©ã€‚
	-  HuggingFace Hubã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
		- (1) LoRAã‚¢ãƒ€ãƒ—ã‚¿ã‚’ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«ãƒãƒ¼ã‚¸
		- (2) ã€ŒHuggingFace Hubã€ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã€ŒNew Modelã€ã‚’é¸æŠã€‚
		- (3) HuggingFace Hubã®ãƒªãƒã‚¸ãƒˆãƒªã®ä½œæˆã€‚
		- (4) HuggingFace Hubã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
-  çµ±è¨ˆå­¦ã‚’å“²å­¦ã™ã‚‹
	- https://www.unp.or.jp/ISBN/ISBN978-4-8158-1003-0.html
	- æ›¸è©•ï¼ˆä¸¸å±±éš†ä¸€ï¼‰
		- â€œâ€¦â€¦ ç§‘å­¦ã®æœ€ã‚‚åŸºæœ¬çš„ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚‹çµ±è¨ˆå­¦ã‚’å“²å­¦çš„ã«åˆ†æã™ã‚‹ã€‚ãƒ™ã‚¤ã‚ºçµ±è¨ˆã€ä»®èª¬æ¤œå®šã€æ©Ÿæ¢°å­¦ç¿’ã€å› æœæ¨è«–ãªã©ã®çµ±è¨ˆå­¦çš„æ‰‹æ³•ã‚’ç§‘å­¦è€…ãŒä½¿ã†ã¨ãã€ä½•ãŒæš—é»™ã®å‰æã¨ãªã‚Šã€ä½•ãŒæ­£å½“åŒ–ã®æ ¹æ‹ ã«ãªã£ã¦ã„ã‚‹ã®ã‹ã€‚å“²å­¦çš„èªè­˜è«–ã®é“å…·ç«‹ã¦ã«ã‚ˆã‚‹æœ¬æ›¸ã®æ•´ç†ã¯é®®ã‚„ã‹ã ã€‚æ·±å±¤å­¦ç¿’ã«é–¢ã™ã‚‹è­°è«–ã¯ã€ã©ã®ã‚ˆã†ãªæ„å‘³ã§ AI ã«ç§‘å­¦ãŒã§ãã‚‹ã®ã‹ã¨ã„ã†å¤§å•é¡Œã«ã‚‚ã¤ãªãŒã‚‹ã€‚ã€ŒAI ç§‘å­¦ã®å“²å­¦ã€ã®å§‹å‹•ã‚’æ„Ÿã˜ã‚‹ã€‚â€¦â€¦â€


## 4/15

ä»Šé€±ã‚‚å¼·çƒˆã ã£ãŸã€‚é ­ãŒãã‚‰ãã‚‰ã™ã‚‹ãŒã€æ°—ã®ã›ã„ã‹é‡ã¿è»¢ç§»ç³»ãŒå¤šã„æ°—ãŒã™ã‚‹ã€‚MiniCPM-2Bã€ã€ŒÎ¼ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚¡ãƒ¼ã€ã¨ã„ã†æ‰‹æ³•ã§å°è¦æ¨¡LLMã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¤§è¦æ¨¡LLMã«è»¢ç§»ã™ã‚‹æŠ€è¡“ã§ï¼ˆï¼’æ®µéšãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã¦ã‚‹ï¼Ÿï¼‰ã€2.4Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã„ã†å°ã•ãªã‚µã‚¤ã‚ºã§Mistral-7Bã¨è‚©ã‚’ä¸¦ã¹ã‚‹ã¨ã‹ã€‚Command R+ã‚‚é‡å­åŒ–ã•ã‚ŒãŸã‚‚ã®ãŒè©•ä¾¡ã•ã‚Œã¦ã€Mac(M3ã€128G)ã‚„ã€A100(80G)ã§çµæ§‹ã‚µã‚¯ã‚µã‚¯ã†ã”ãã‚‰ã—ã„ã€‚ç‰¹ã«ã€ ã€ŒCommand R+ GPTQã‚’ãƒ­ãƒ¼ã‚«ãƒ«LLMã¨ã—ã¦vllmã§OpenAI APIäº’æ›ã‚µãƒ¼ãƒå‹•ä½œã€ã£ã¦ã®ã¯ã€A100æŒã£ã¦ã„ã‚‹äººã¯ãœã²è©¦ã—ã¦ã¿ã‚‹ã¹ãã€‚ Command R+ã«å½±éŸ¿ã•ã‚ŒãŸã®ã‹ã€Mistralã‚‚Mixtral-8x22Bã‚’ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã¨ã—ã¦ç™ºè¡¨ã€ã•ã£ããã“ã‚Œã‚’ãƒ™ãƒ¼ã‚¹ã«expertsã‚’ãƒãƒ¼ã‚¸ã—ã¦mistralã«ã—ãŸå‹æ‰‹ç‰ˆMistral-22BãŒå‡ºã¦ã€åŒæ–¹é‡å­åŒ–ç‰ˆãŒå‡ºã¦ã€ã€ã€ã¨ã‚ã£ã¨ã„ã†é–“ã«åºƒã¾ã£ã¦ä½•ãŒä½•ã ã‹ã€‚LLMåŒå£«ã®æ©Ÿèƒ½ã®ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—ã§ã‚ã‚‹Chat Vectorã€ã¾ã­ã—ã¦Mathå¼·åŒ–ç‰ˆã‚’ã¤ãã£ã¦ã€ã“ã‚Œã‚‰ã‚’èåˆã—ãŸçµæœã€æ•°å­¦èƒ½åŠ›ã‚’ã‚ã‚‹ç¨‹åº¦ç¶­æŒã—ã¤ã¤ã€Chatèƒ½åŠ›ã‚‚å¼·åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã¨ã„ã†è©±ã‚‚ã‚ã£ãŸã€‚LightChatAssistant 2x7Bã¦ã®ã‚‚Mistral7Bãƒ¢ãƒ‡ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã¨ã—ãŸæ—¥æœ¬èªå¯¾å¿œãƒ¢ãƒ‡ãƒ« 2ã‚’ChatVectoræ‰‹æ³•ã§å¯¾è©±èƒ½åŠ›å¼·åŒ–ã—ã¦mergekitã§MoEåŒ–ã—ãŸã‚‚ã®ã€‚32kã®ContextSizeå¯¾å¿œã€iQ3_XXSé‡å­åŒ–ã§VRAM12GBã§ãƒ•ãƒ«ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã€RTX3060ã§ã‚‚å‹•ãã¨ã‹ã€‚JetMoEã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€MoEã§ã‚ã‚‹ã“ã¨ã«åŠ ãˆã€MiniCPMã«å€£ã£ãŸ2æ®µéšãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®åŠ¹ç‡ãŒæ¥µã‚ã¦é«˜ããã‚Œã§ã„ã¦æ€§èƒ½ã¯Llama-7Bä¸¦ã¿ã¨ã‹ã€‚Googleã®æ–°ã—ã„ãƒªã‚«ãƒ¬ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£RecurrentGemmaã€ãƒªã‚«ãƒ¬ãƒ³ãƒˆãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨ãƒ­ãƒ¼ã‚«ãƒ«ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’æ´»ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’å‘ä¸Šã•ã¦ã„ã‚‹ã‚‰ã—ã„ã€ä»Šå¾Œã‚‚Gemmaã¨ãƒ‘ãƒ©ãƒ¬ãƒ«ã«ãƒªãƒªãƒ¼ã‚¹ã™ã‚‹ã®ã‹ã€‚GPT-4è¶…ãˆç²¾åº¦ã§ã‚¹ãƒãƒ›ä¸Šå®Ÿè¡Œã§ãã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ç”ŸæˆAIã€ŒOctopus v2ã€ã¦ã®ã‚‚ã‚ã£ãŸã€Gemma-2Bã«è¿½åŠ å­¦ç¿’ã—ã¦ã€ŒFunction Callingã€ã‚’å¼·åŒ–ã—ãŸã¨ã®ã“ã¨ã€‚ãã‚Œã‹ã‚‰ã€ä»Šé€±ã¯Google Cloud Next24ãŒã‚ã£ãŸã®ã§ã€æœ€å¤§100ä¸‡ãƒˆãƒ¼ã‚¯ãƒ³ã®Gemini 1.5 Proã®ãƒªãƒªãƒ¼ã‚¹ã‚„ã€DeepMindã®Imagen 2ã€TPU v5pã®ç™ºè¡¨ã€GoogleDocã«Geminiã®çµ±åˆã¨ã‹ã€geminiã§RCã‚«ãƒ¼ã‚’åˆ¶å¾¡ã¨ã‹é¢ç™½ã„å‡ºã—ç‰©ãŒã‚ã£ãŸã€‚æ—¥æœ¬èªLLM 9ç¨®ã‚’é‡å­åŒ–ã—ã¦å›ç­”å†…å®¹ã‚’æ¯”è¼ƒã£ã¦ã®ã‚‚é¢ç™½ã‹ã£ãŸã€ELYZAã¯å‰ã„ãã€‚LangChain ã® Tool Calling æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ ã£ã¦LLMã«ä¾å­˜ã—ãªã„ã¨ã„ã†ã“ã¨ãªã®ã§ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã‹ã®æ´»ç”¨ãŒåŠ é€Ÿã—ãã†ã€‚QRåˆ†è§£ã§ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã£ã¦ã®ã¯ç›®ã‹ã‚‰ã†ã‚ã“ã ã€ä¸€è¦‹ç•°ãªã‚‹æãŒã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆã«ã¤ãªãŒã‚‹ã€ã“ã‚Œãã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®é†é†å‘³ã ã€‚

- MiniCPM: Unveiling the Potential of End-side Large Language Models
	- https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20
	- æ—¢å­˜7B LLMã‚ˆã‚Šå¼·ã„ã¨è©±é¡Œã®2B LMMã®MiniCPM
	- Î¼Pä½¿ã£ã¦å°ã•ã„ãƒ¢ãƒ‡ãƒ«ã§åŠ¹ç‡çš„ã«ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¢ç´¢
	- MiniCPM is a series of edge-side large language models, with the base model, MiniCPM-2B, having 2.4B non-embedding parameters. 
	- It ranks closely with Mistral-7B on comprehensive benchmarks
- ç¾çŠ¶ã®LLMé¸æŠè‚¢ by urawazakun
	- https://x.com/urawazakun/status/1777130873844040046
	- commandRplusã€€108B â†’Mac é€²åŒ–çš„ï¼ˆ988000å††ï¼‰
	- commandRã€€35B â†’RTX4090ï¼ˆPC + 40ä¸‡å††ï½ï¼‰
	- LightChatAssistant2x7B â†’RTX3060ï¼ˆPC + 3ä¸‡å††ï½ï¼‰
-  EasyLightChatAssistant
	- https://github.com/Zuntan03/EasyLightChatAssistant?tab=readme-ov-file
	- EasyLightChatAssistant ã¯è»½é‡ã§æ¤œé–²ã‚„è¦åˆ¶ã®ãªã„ãƒ­ãƒ¼ã‚«ãƒ«æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã® LightChatAssistant ã‚’ã€KoboldCpp ã§ç°¡å˜ã«ãŠè©¦ã—ã™ã‚‹ç’°å¢ƒã§ã™ã€‚
- ï½¢LLMã¯ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£ãƒ¼ï½£ã€€ç±³ãƒ‡ãƒ¼ã‚¿ãƒ–ãƒªãƒƒã‚¯ã‚¹CEOãŒèªã‚‹
	- https://www.nikkei.com/article/DGXZQOGN252JK0V20C24A3000000/
	- LLMå˜ä½“ã§ã¯ãªãLLMã‚„ãã®ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦å•é¡Œã‚’è§£ãã€Œè¤‡åˆAIã€ã®è€ƒãˆæ–¹ãŒã¨ã¦ã‚‚å¤§äº‹
-  Octopus v2: On-device language model for super agent
	- https://arxiv.org/abs/2404.01744
	- https://huggingface.co/NexaAIDev/Octopus-v2
	- GPT-4è¶…ãˆç²¾åº¦ã§ã‚¹ãƒãƒ›ä¸Šå®Ÿè¡Œã§ãã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ç”ŸæˆAIã€ŒOctopus v2ã€
	- 20å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤ã‚¨ãƒƒã‚¸ãƒ‡ãƒã‚¤ã‚¹ä¸Šã§æ©Ÿèƒ½ã™ã‚‹ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹AIãƒ¢ãƒ‡ãƒ«ã€ŒOctopus v2ã€
- Google Colab ã§ Octopus V2 ã‚’è©¦ã™ by npakaã•ã‚“ã€
	- https://note.com/npaka/n/n706bde979ed8
	- Gemma-2Bã‚’è¿½åŠ å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã€å­¦ç¿’ã‚¹ãƒ†ãƒ¼ã‚¸ã¨æ¨è«–ã‚¹ãƒ†ãƒ¼ã‚¸ã®ä¸¡æ–¹ã«ç‹¬è‡ªã®Functionãƒˆãƒ¼ã‚¯ãƒ³æˆ¦ç•¥ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ã€ŒFunction Callingã€ã«ãŠã„ã¦ã€ŒGPT-4ã€ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ãŸã¨ã®ã“ã¨ã§ã™ã€‚
	- ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ã—ã¦ã¯ã€ã€Œã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«ãƒªãƒã‚¤ãƒ³ãƒ€ãƒ¼è¿½åŠ ã€ã€Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã€ã€ŒYoutubeæ¤œç´¢ã€ã®æŒ‡ç¤ºãªã©ãŒæŒ™ã’ã‚‰ã‚Œã¦ã„ã¾ã™
- Chat Vectorã¨Math Vectorã¯ä½µç”¨ã§ãã‚‹ã®ã‹ by ã¯ã¡ã•ï½
	- https://note.com/hatti8/n/n2d6d86d6f05a?sub_rt=share_h
	- Chat+Mathèƒ½åŠ›ã®ä¸¡æ–¹ã‚’æ—¥æœ¬èªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã«ä»˜ä¸ã—ãŸã‚‰ã€ã©ã¡ã‚‰ã®åŠ¹æœã‚‚å¾—ã‚‰ã‚Œã‚‹ã®ã‹
	- Mathå¼·åŒ–ãƒ¢ãƒ‡ãƒ«ã«å…ˆã»ã©ä½œã£ãŸChat Vectorã‚’é‡ã­ãŒã‘ã—ã¦ã„ãã¾ã™
	- Mathå¼·åŒ–ãƒ¢ãƒ‡ãƒ«ï¼šSwallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vectorï¼šSkillTree-Chat-Mistral-7B-v0.1
	- Math+Chatå¼·åŒ–ãƒ¢ãƒ‡ãƒ«
		- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatMathSkill
	- çµè«–
		-  **ãƒ¢ãƒ‡ãƒ«ãŒå£Šã‚Œã‚‹ã“ã¨ã¯ãªã„**
		- **æ•°å­¦èƒ½åŠ›ã‚’ã‚ã‚‹ç¨‹åº¦ç¶­æŒã—ã¤ã¤ã€Chatèƒ½åŠ›ã‚‚å¼·åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã‚‹**
		-  **ä¸€æ–¹ã€è‹±èªã§å›ç­”ã—ã‚„ã™ããªã‚‹å‚¾å‘ãŒå‡ºã¦ãã‚‹**
- Chat Vectorãªã‚‰ã¬Math Vectorã¯ä½œã‚Œã‚‹ã®ã‹
	- https://note.com/hatti8/n/n0000353355cb
- LangChain x DSPy
	- https://www.youtube.com/watch?v=4EXOmWeqXRc
- JetMoEã£ã¦ãªã‚“ã˜ã‚ƒï¼Ÿ by ã†ã¿ã‚†ãã•ã‚“ã€
	- https://x.com/umiyuki_ai/status/1777014403197788280
	- Mixture of Attention headsï¼ˆMoAï¼‰ã¨Mixture of MLP Expertsï¼ˆMoEï¼‰ã®äºŒã¤ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ã€ãã‚Œãã‚Œï¼”äººãšã¤ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆãŒã„ã¦ã€æ¨è«–æ™‚ã¯å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼’äººãšã¤ãŒæ´»æ€§åŒ–ã™ã‚‹ã€‚
	- æ´»æ€§åŒ–ãƒ‘ãƒ©æ•°ã¯2.2Bã§ã€åˆè¨ˆãƒ‘ãƒ©æ•°ã¯8Bã ã£ã¦ã€‚ä½•ã ã‹çŸ¥ã‚‰ã‚“ã‘ã©ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã£ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ãŒçˆ†ä¸ŠãŒã£ã¦ã€H100ãŒ96å°ã§ï¼’é€±é–“ã€1200ä¸‡å††ã—ã‹ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è²»ç”¨ã‹ã‘ã¦ãªã„ã®ã«ã€æ•°åƒå„„ã‹ã‘ãŸã¯ãšã®Llama-7Bã‚„Llama-13ã«ãƒ™ãƒ³ãƒã§å‹åˆ©ã—ãŸ
- Î¼Transfer: å°è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒã‚¤ãƒ‘ãƒ©æ¢ç´¢ã‚’å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã«è»¢ç§»ã—å­¦ç¿’ã‚’åŠ¹ç‡åŒ–ã™ã‚‹
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_b&d=s4cpuSjMMAw
	- Î¼Pï¼ˆMaximal Update Parametrizationï¼‰ã¨ã„ã†ã®ã¯ã€ Tensor Programs (TP)ã¨ã„ã†ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ãŠã„ã¦ç†è«–çš„ã«å°å‡ºã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ã‘ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã©ï¼‰ã®æ–¹æ³•ã§ã™
	- TP ã¯ã€ Neural Networks ï¼ˆNNï¼‰ã®è§£æã‚’ã™ã‚‹ãŸã‚ã«ã€ç·šå½¢å¤‰æ›ã‚„éç·šå½¢æ´»æ€§åŒ–é–¢æ•°ãªã©ã® NN ã®æ§‹ç¯‰ã§é »å‡ºã™ã‚‹æ“ä½œã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã€ãã®æ çµ„ã¿ã§æˆç«‹ã™ã‚‹äº‹è±¡ã‚„æ€§è³ªã‚’è¿½æ±‚ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚
	- https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/
- Leveraging language representation for materials exploration and discovery
	- https://www.nature.com/articles/s41524-024-01231-8
	- è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ææ–™æ¢ç´¢ã®è«–æ–‡ã€‚
	- çµæ™¶ææ–™ã‚’ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¾ã«ã—è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šæ—¢å­˜ææ–™ã«ä¼¼ãŸæ–°ç†±é›»ææ–™ã‚’æ¢ç´¢
	- ç‰¹ã«ã€GPTã®ã‚ˆã†ãªãƒ‡ã‚³ãƒ¼ãƒ€å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã€BERTã®ã‚ˆã†ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ€å°‚ç”¨ãƒ¢ãƒ‡ãƒ«ã®ã»ã†ãŒæ±ç”¨æ€§ãŒé«˜ãMIã‚¿ã‚¹ã‚¯ã«å‘ã„ã¦ã„ã‚‹ã€ã¨ã„ã†ç‚¹ãŒèˆˆå‘³æ·±ã‹ã£ãŸã§
- Î¼ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚¡ãƒ¼ã¨ã¯ by ã†ã¿ã‚†ãã•ã‚“ã€
	- https://x.com/umiyuki_ai/status/1777204816059711692
	- MiniCPMã¯ãƒŸãƒ¥ãƒ¼ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚¡ãƒ¼ã¨ã„ã†ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ãŒä½¿ã‚ã‚Œã¦ã‚‹ã‚‰ã—ã„ã€‚ã“ã‚ŒãŒä½•ã‹ï¼Ÿã¨ã„ã†ã¨ã€ã§ã‹ã„LLMã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ™‚ã®æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ã‚‹ãƒ†ã‚¯ã‚‰ã—ã„ã€‚
	- ã§ã‹ã„LLMã‚’å­¦ç¿’ã™ã‚‹æ™‚ã«ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã©ã†å¼„ã‚Œã°æœ€å¼·ã«ãªã‚‹ã®ã‹ã€ã‚¤ãƒã‚¤ãƒè‰²ã€…è©¦ã—ã¦æœ€é©è§£ã‚’è©¦è¡ŒéŒ¯èª¤ã™ã‚‹ã®ã¯ãƒ¡ãƒãƒ£ã‚¯ãƒãƒ£å¤§å¤‰ã ã€‚ãã“ã§ã€åŒã˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®ã¡ã£ã¡ã‚ƒã„ç‰ˆã§å®Ÿé¨“ã™ã‚Œã°ã‚µã‚¯ã‚µã‚¯ã¨æœ€é©ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è©¦è¡ŒéŒ¯èª¤ã§ãã‚‹ã€‚ã§ã€ã¡ã£ã¡ã‚ƒã„ãƒ¢ãƒ‡ãƒ«ã§è¦‹ã¤ã‘ãŸæœ€å¼·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã€ã§ã‹ã„LLMã«ãã‚“ã¾ã¾ã‚³ãƒ”ãƒšã—ã¦ã‚‚ã¡ã‚ƒã‚“ã¨æœ€å¼·ã«ãªã‚‹äº‹ãŒåˆ¤æ˜ã—ãŸã‚‰ã—ã„ï¼
- JetMoEã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ä¸ŠãŒã£ãŸã®ã¯ã€€ by ã†ã¿ã‚†ãã•ã‚“ã€
	- https://x.com/umiyuki_ai/status/1777023943121256637
	- Komatsuzakiæ°ã®è¦‹è§£ã«ã‚ˆã‚Œã°ã€JetMoEã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°åŠ¹ç‡ä¸ŠãŒã£ãŸã®ã¯ã€ãŸã—ã‹ã«MoEã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã£ã¦ï¼’ï½ï¼“å€ã«åŠ¹ç‡åŒ–ã—ãŸã‘ã©ã€ãã‚Œã‚ˆã‚Šä½•ã‚ˆã‚ŠMiniCPMã«å€£ã£ãŸ2æ®µéšãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®æ‰‹æ³•ã®ãŠã‹ã’ã§ãƒã‚­ãƒã‚­ã«åŠ¹ç‡åŒ–ã—ãŸã¨ã®äº‹ã€‚
	- 1ä¸‡å€ã®å†…ã€MoEã®è²¢çŒ®ãŒï¼“å€ãªã‚‰æ®‹ã‚Šã®3333å€ã¯MiniCPMãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŠã‹ã’ãªã®ã‹
- The Physics of Language Models
	- https://arxiv.org/abs/2404.05405
	- ã€Œè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€int8 ã«é‡å­åŒ–ã•ã‚ŒãŸå ´åˆã§ã‚‚ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã”ã¨ã« 2 ãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã—ã‹ä¿å­˜ã§ãã¾ã›ã‚“ã€‚ã¾ãŸã€ãã®ã‚ˆã†ãªçŸ¥è­˜ã¯ã€ä¸‹æµã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã«æŸ”è»Ÿã«æŠ½å‡ºã§ãã¾ã™ã€‚ãã®çµæœã€7B ãƒ¢ãƒ‡ãƒ«ã¯ 14B ãƒ“ãƒƒãƒˆã®çŸ¥è­˜ã‚’ä¿å­˜ã§ãã€ã“ã‚Œã¯ç§ãŸã¡ã®æ¨å®šã«åŸºã¥ãã¨ã€è‹±èªç‰ˆ Wikipedia ã¨æ•™ç§‘æ›¸ã‚’åˆã‚ã›ãŸé‡ã‚’è¶…ãˆã¾ã™ã€‚ã€
	- å›è»¢åŸ‹ã‚è¾¼ã¿ã‚’å‚™ãˆãŸ GPT-2 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€çŸ¥è­˜ã®ä¿å­˜ã«ãŠã„ã¦ LLaMA/Mistral ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŒ¹æ•µã™ã‚‹ã‹ã€ãã‚Œã‚’ä¸Šå›ã‚Šã¾ã™ã€‚
- Gemini 1.5 Pro
	- https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html
	- 180ã‚«å›½ã‚µãƒãƒ¼ãƒˆã€ã€Œçµ±ä¸€ãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°ãƒ»å‹•ç”»èªè­˜ã€ãƒ•ã‚¡ã‚¤ãƒ«APIã€System Instructionã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ©Ÿèƒ½ã€ JSONãƒ¢ãƒ¼ãƒ‰ãªã©ãŒåŠ ã‚ã‚Šã¾ã—ãŸã€ä»¥ä¸‹ã§è©¦ã›ã‚‹
	- https://aié€²åŒ–çš„.google.com/app/prompts/new_chat
- Imagen 2 by DeepMind
	- https://x.com/GoogleDeepMind/status/1777747320945234422
	- Imagen 2 can now create short, 4-second live images from a single prompt.
- GPT-4 Turbo launch
	- https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4
	- previewãŒå–ã‚ŒãŸ
- UNESCOãŒAI Ethicã§äººé›†ã‚ã—ã¦ã„ã‚‹ byã€€ç¥å¶Œã•ã‚“
	- https://careers.unesco.org/job/Other-cities-Consultant/791818302/d
- Llama.cpp ã§ Command R+ ã‚’ãŠè©¦ã—ä¸­ by npakaã•ã‚“
	- https://x.com/npaka123/status/1777802956571889969
	- Q4_K_Mãƒ»M3 Max (128GB) 5.22 tokens per second
- mmnga/codegemma-7b-it-gguf
	- https://huggingface.co/mmnga/codegemma-7b-it-gguf
	- gemma-1.1-7bã¨codegemma-7b-itã®gguf
- ã€LangChainã‚†ã‚‹å‹‰å¼·ä¼š#3ã€‘LangChainã®Agentã¯ã©ã‚Œã‚’ä½¿ã†ï¼Ÿ
	- https://www.youtube.com/watch?v=07TuBmm67sU
	- LangChainã‚’ä½¿ã£ãŸAgentå®Ÿè£…ã‚’æ¦‚èª¬ã—ã¦ãã ã•ã£ã¦ã‚‹å‹‰å¼·ä¼šã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‹•ç”»ã€‚
	- æœ€è¿‘ã¯LCELã§çµ„ã‚“ã§Agent Excutorã«æŠ•ã’ã‚‹ä»¥å¤–ã®å®Ÿè£…ã—ãªã„ã®ã§ã€ãªã‚“ã‹è‰²ã€…ã‚ã‚‹ã‚“ã ãªã¨å‹‰å¼·ã«ãªã‚Šã¾ã—ãŸ
	- XML Agentã¨ã‹èª°ãŒä½¿ã†ã‚“ï¼Ÿã£ã¦æ€ã£ã¦ãŸã‘ã©ã€Claudeã¨ç›¸æ€§è‰¯ã„ã‚‰ã—ã„ã€‚ã¸ã‡ã€œï¼
- rinna/youri-7b-chat-gptqã¨intfloat/multilingual-e5-largeã§RAGã™ã‚‹ã ã‘ã§ã‚‚colabã‚ˆã‚Šrtx3060ã®æ–¹ãŒã‹ãªã‚Šé€Ÿã„
	- https://x.com/rsimd_/status/1747614320878555175
	- vramãŒè¶³ã‚Šã‚Œã°ã£ã¦è©±ã ã‘ã©ï¼Œä¸€å¿œfaiss-cpuã‚’ä½¿ãˆã°ãƒ¡ãƒ¢ãƒªè¶³ã‚Šã¦ã‚‹ï¼
- Command R+ã®é‡å­åŒ–PPLã‚’è¨ˆæ¸¬ã—ã¦ãã‚Œã¦ã‚‹
	- https://github.com/ggerganov/llama.cpp/pull/6491#issuecomment-2043633791
	- Q3_XXSã¯38GBã ã‘ã©ã€ã“ã“ã¾ã§ãªã‚‰ç²¾åº¦çš„ã«ã‚‚å…¨ç„¶å¤§ä¸ˆå¤«ã¡ã‚ƒã†ã‹ï¼Ÿã£ã¦äºˆæ„Ÿã¯ã™ã‚‹ã€‚IQ2_XXSãªã‚‰26.6GBã§ã€ã¡ã‚‡ã£ã¨ã‚¢ãƒ›ã«ãªã£ã¦ãã†ã€‚IQ1_Sãªã‚‰21.6GBã ã‘ã©ã€ã•ã™ãŒã«å®Ÿç”¨æ€§ãƒ¤ãƒãã†ã€‚
- Perplexity Proã«èª²é‡‘ã—ã¦Googleã®Gemini Ultraã‚„Generative Experienceã¨æ¯”è¼ƒã—ã¦ã¿ã‚‹ã¨ã€ä½•ã‹ã¨ã‚“ã§ã‚‚ãªã„ã“ã¨ãŒèµ·ã“ã£ã¦ã„ã‚‹æ°—ãŒã™ã‚‹ by æ¥ ã•ã‚“
	- https://x.com/masanork/status/1777478951465779344
- å®Œå…¨ãƒ­ãƒ¼ã‚«ãƒ«ã§RAGã‚‚ä½¿ãˆã‚‹AIãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒªOpenWebUIã‚’æ—¥æœ¬èªLLMã§ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹
	- https://zenn.dev/firstautomation/articles/0b7a4b1bb2daf0
- Command R+ã¯ã¡ã‚ƒã‚“ã¨å¼·ã‹ã£ãŸè¨³ã ãŒã€Command Rã‚‚ã“ã‚Œã¾ã§ã®Open-sourceæœ€å¼·ã®Qwen1.5-72bã«åŒ¹æ•µã™ã‚‹è¨³ãªã®ã§ã™ã”ã„
	- https://x.com/Meteor_Eternal/status/1777635899204874704
- Gemini 1.5 Proã®æ–°æ©Ÿèƒ½ - Native Audio Understandingã€System Instructionsã€JSON Modeã€æ–°Embeddingãƒ¢ãƒ‡ãƒ«ã€€ by npakaã•ã‚“
	- https://note.com/npaka/n/n0254081ebc23?sub_rt=share_h
- Stable LM 2 12B
	- https://stability.ai/news/introducing-stable-lm-2-12b
	- Stable LM 2 12B ã¯ã€è‹±èªã€ã‚¹ãƒšã‚¤ãƒ³èªã€ãƒ‰ã‚¤ãƒ„èªã€ã‚¤ã‚¿ãƒªã‚¢èªã€ãƒ•ãƒ©ãƒ³ã‚¹èªã€ãƒãƒ«ãƒˆã‚¬ãƒ«èªã€ã‚ªãƒ©ãƒ³ãƒ€èªã®å¤šè¨€èªãƒ‡ãƒ¼ã‚¿ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã•ã‚ŒãŸã€120å„„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒã¤å¼·åŠ›ãªè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨æŒ‡ç¤ºå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚
- GoogleDocã«geminiãŒçµ±åˆã•ã‚Œã‚‹ï¼Ÿ
	- https://x.com/GoogleWorkspace/status/1777807449652662508
- TPU v5p, our most powerful and scalable TPU, is now generally available
	- https://x.com/GoogleCloudTech/status/1777732890471625162
- Gemma-1.1 also shows great improvement in terms of reduced hallucinations in the updated HHEM leaderbod
	- https://x.com/ofermend/status/1777695633455108478
- LLaMA 3's will start to drop next week.
	- https://x.com/mattshumer_/status/1777465835834970189
- Ride with Geminiã¨ã„ã†LLMï¼‹RCã‚«ãƒ¼ã®ãƒ‡ãƒ¢
	- https://x.com/kazunori_279/status/1777846216950456658
-  Gemini 1.5 Proã§æ–‡å­—èµ·ã“ã—ã‚’è©¦ã—ã¦ã¿ãŸ
	- https://note.com/nyosubro/n/n07afba435ef6
	- å€‹äººçš„ãªæ„Ÿæƒ³ã¨ã—ã¦ã¯ã€Whisperãƒ¬ãƒ™ãƒ«ï¼ˆã‚ã‚‹ã„ã¯ãã‚Œä»¥ä¸Šï¼Ÿï¼‰ã®æ–‡å­—èµ·ã“ã—å“è³ªã¨è«–æ–‡ã§ã¯ã‚ã‚Šã¾ã—ãŸãŒã€ç¢ºã‹ã«ãã†ã‹ã‚‚ï¼ã¨è¨€ã†æ„Ÿã˜ã§ã—ãŸã€‚
	- ã¾ãŸWhisperã¨ã¯ç•°ãªã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¬ãƒ™ãƒ«ã§æ§˜ã€…ãªæ–‡å­—èµ·ã“ã—ã‚¿ã‚¹ã‚¯ã«æŸ”è»Ÿã«å¯¾å¿œã§ãã‚‹ç‚¹ã§ã€çµæ§‹é¢ç™½ã•ã‚’æ„Ÿã˜ã¦ã¾ã™ã€‚
- Llama.cpp ã§ Command R+ ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n9136a2ebc7f9?sub_rt=share_h
	- M3 Max (128GB)
	- ã€ŒCommand R+ã€ã¯ã€ã€ŒRAGã€ã‚„ã€ŒToolã€ãªã©ã®é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¹ã‚¯å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸ104Bã®LLMã§ã™ã€‚Cohereã®EmbeddingãŠã‚ˆã³Rerankã¨é€£æºã—ã¦å‹•ä½œã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€RAGã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«æœ€é«˜ã‚¯ãƒ©ã‚¹ã®çµ±åˆã‚’æä¾›ã—ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã§å„ªã‚Œã¦ã„ã¾ã™ã€‚
- Wikipediaã®æ—¥æœ¬èªè¨˜äº‹ã‚’å…ƒã«ã€ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«å›ç­”ã™ã‚‹Gradioãƒ™ãƒ¼ã‚¹ã®RAGã®ã‚µãƒ³ãƒ—ãƒ«ã€‚
	- https://github.com/lawofcycles/wikipedia-japanese-open-rag/tree/master
	- ä½¿ã£ãŸã‚‚ã®
		-   [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)
		-   [elyza/ELYZA-japanese-Llama-2-13b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-instruct)
- Command R plusæ¨è«–é€Ÿåº¦ã€çŸ¥è¦‹ã¾ã¨ã‚ by AIXã•ã¨ã—
	- https://x.com/AiXsatoshi/status/1777867323552190876
- Amazonã€ã€ŒClaude 3ã€ã®Anthropicã«27å„„5000ä¸‡ãƒ‰ãƒ«ã®è¿½åŠ æŠ•è³‡
	- https://www.itmedia.co.jp/news/articles/2403/28/news105.html#utm_term=share_sp
- A Generative Symbolic Music Pretrained Transformer
	- https://huggingface.co/papers/2404.06393
	- In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are
- We just released Mixtral 8x22B. Super excited for this release
	- https://x.com/sophiamyang/status/1777945947764297845
- æ—¥æœ¬èªLLM 9ç¨®ã‚’é‡å­åŒ–ã—ã¦å›ç­”å†…å®¹ã‚’æ¯”è¼ƒèª¿æŸ»ã—ã¦ã¿ãŸ
	- https://qiita.com/wayama_ryousuke/items/50e36d0dcb37f8fb7dd8
	- é‡å­åŒ–ã—ã¦ã‚‚æˆç¸¾ãŒä¸‹ãŒã‚Šã«ãã„ãƒ¢ãƒ‡ãƒ«ã¨ã€å¤§ããä¸‹ãŒã‚‹ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹
	- ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«ã¯é‡å­åŒ–ã™ã‚‹ã¨å›ç­”ãŒæ¥µç«¯ã«çŸ­ããªã‚‹
	- é‡å­åŒ–ã«ã‚ˆã£ã¦å›ç­”ãŒçŸ­ããªã‚‹åº¦åˆã„ã¯ã€é‡å­åŒ–å‰ãƒ¢ãƒ‡ãƒ«ã®å›ç­”ã®é•·ã•ã¨ç›¸é–¢ãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹
	- å€‹åˆ¥ï¼š
		- **ELYZA-japanese-Llama-2-7B**ã¯ã€é‡å­åŒ–å¾Œã‚‚ã»ã¼åŒç­‰ã®æ€§èƒ½ã‚’ç¶­æŒã—ã€0.10ç‚¹ã®ã‚¹ã‚³ã‚¢ä½ä¸‹ã«ç•™ã¾ã‚Šã¾ã—ãŸã€‚
		-  **Swallow-7B**ã§ã¯ã€é‡å­åŒ–å‰å¾Œã§æˆç¸¾ã«å¤‰åŒ–ã¯ãªã‹ã£ãŸä¸€æ–¹ã€**Swallow-13B**ã§ã¯å¹³å‡ã‚¹ã‚³ã‚¢ãŒ 0.28 ç‚¹ä½ä¸‹ã—ã¾ã—ãŸã€‚
		- **CALM2**  ã‚„  **StableLM-Beta**  ã¯ã€é‡å­åŒ–å¾Œã®ã‚¹ã‚³ã‚¢ãŒé«˜ã„çµæœï¼ˆãã‚Œãã‚Œ 0.28 ç‚¹/ 0.21 ç‚¹å‘ä¸Šï¼‰ã¨ãªã‚Šã¾ã—ãŸã€‚
		-   **Xwin**  ãƒ¢ãƒ‡ãƒ«åŒå£«ã‚’æ¯”è¼ƒã™ã‚‹ã¨ã€**Xwin 7B**ã¯0.36ç‚¹ã®ä½ä¸‹ã‚’ç¤ºã—ã¦ã„ã‚‹ä¸€æ–¹ã€**Xwin 13B**ã§ã¯0.11ç‚¹ã®å‘ä¸ŠãŒè¦‹ã‚‰ã‚Œã€åŒã˜ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼å†…ã§ã‚‚ç•°ãªã‚‹æŒ¯ã‚‹èˆã„ãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚
-  Command R+ GPTQã‚’ãƒ­ãƒ¼ã‚«ãƒ«LLMã¨ã—ã¦vllmã§OpenAI APIäº’æ›ã‚µãƒ¼ãƒå‹•ä½œã•ã›ã¦ã¿ãŸè©±
	- https://note.com/junzokamahara/n/n9235af7a6dc1?sub_rt=share_h
	- vllmã‚‚Command Rã«å¯¾å¿œã—ã¦ã„ã‚‹ã¨ã®ã“ã¨ã§ã€vllmã§å‹•ã‹ã—ã¦ã¿ã‚‹ã“ã¨ã«ã—ã¾ã—ãŸã€‚ãªãŠã€å‹•ã‹ã™ã®ã¯GPUãƒ¡ãƒ¢ãƒªã®é–¢ä¿‚ã§GPTQã§é‡å­åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€‚
	- ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ã¯Hugging Faceã«ã‚ã‚‹GPTQã«å¤‰æ›ã—ãŸCommand R+
		- client = OpenAI(base_url="http://<ä»®æƒ³ãƒã‚·ãƒ³ã®IP>:8888/v1")
		- response = client.chat.completions.create(model='alpindale/c4ai-command-r-plus-GPTQ',
	- Command R plus GPTQã®A100 80GBã§ã®å®Ÿè¡Œä¾‹
		- 18.3 tokens/sã¨å‡ºã¦ã„ã‚‹
- Geminiã®æ–°æ©Ÿèƒ½ã€ŒSystem Instructionsã€ã‚’ä½¿ã£ã¦ã¿ã‚‹ã€‚ 
	- https://x.com/npaka123/status/1777969149651906927
	- ChatGPTã§ã¯ãŠãªã˜ã¿ãªæ©Ÿèƒ½ã ã‘ã©ã€ä»Šã¾ã§Geminiã«ã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚ãªã‹ã£ãŸã®ã§ã†ã‚Œã—ã„ã€‚
- ã€ã™ãšã‚ã®æˆ¸ç· ã¾ã‚Šã€ã«ç™»å ´ã™ã‚‹3æœ¬è„šã®æ¤…å­ã‚’å†ç¾ã—ãŸãƒ­ãƒœãƒƒãƒˆè¨­è¨ˆ
	- https://x.com/shin0805__/status/1777992583396131246
	- å¼·åŒ–å­¦ç¿’ã«ã‚ˆã‚‹æ­©å®¹ç”Ÿæˆã®è«–æ–‡ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼ æ¥é€±ã‚¢ãƒ¡ãƒªã‚«ã§é–‹å‚¬ã•ã‚Œã‚‹RoboSoft2024ã«ã¦ç™ºè¡¨ã—ã¾ã™ï¼
	- https://shin0805.github.io/chair-type-tripedal-robot/
- mistral-community/Mixtral-8x22B-v0.1
	- The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.
	- ãŠã„ã€ã“ã‚ŒApache-2.0ã ãï¼GPT-4ã‚¯ãƒ©ã‚¹ãŒå•†ç”¨åˆ©ç”¨å¯èƒ½ã‚‰ã—ã„
- MLX with LangChain
	- https://python.langchain.com/docs/integrations/chat/mlx/
	- This notebook shows how to get started using MLX LLMâ€™s as chat models.
- Google Colab ã§ RecurrentGemma ã‚’è©¦ã™
	- https://note.com/npaka/n/n0018d60fb8b7?sub_rt=share_h
	- ã€ŒRecurrentGemmaã€ã¯ã€Google ã§é–‹ç™ºã•ã‚ŒãŸæ–°ã—ã„ãƒªã‚«ãƒ¬ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚ŒãŸã‚ªãƒ¼ãƒ—ãƒ³ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨æŒ‡ç¤ºãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®ä¸¡æ–¹ãŒè‹±èªã§åˆ©ç”¨å¯èƒ½ã§ã™
	- æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚Šã€ã€ŒGemmaã€ã‚ˆã‚Šã‚‚å¿…è¦ãªãƒ¡ãƒ¢ãƒªãŒå°‘ãªãã€é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹éš›ã«é«˜é€Ÿãªæ¨è«–ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
	- ä»Šå›ã¯ã€ã€Œ**google/recurrentgemma-2b-it**ã€ã‚’ä½¿ã„ã¾ã™
- LightChatAssistant-2x7Bã§è¡Œã‚ã‚Œã¦ã„ã‚‹æœ€é©åŒ–ã‚’Optuneã§
	- https://github.com/Aratako/Task-Vector-Merge-Optimzier
	- Sdff-Ltba/LightChatAssistant-2x7Bã§è¡Œã‚ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªLLMã«ãŠã‘ã‚‹Task Vectorã®åŠ ç®—ã«ã‚ˆã‚‹ãƒãƒ¼ã‚¸ã«ãŠã„ã¦ã€ãã®åŠ ç®—å‰²åˆã®æœ€é©åŒ–ã‚’Optunaã‚’ç”¨ã„ã¦è¡Œã†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã™
- Infini-attention
	https://x.com/umiyuki_ai/status/1778459568424784194
	- GoogleãŒå‡ºã—ãŸè«–æ–‡ãªã‚“ã ã­ã€‚ã§ã€ã€Œã“ã®æŠ€è¡“ã®ãŠã‹ã’ã§Gemini1.5ã§ã¯100ä¸‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚¤ãƒ³ãƒ‰ã‚¦ãŒå¯èƒ½ã«ãªã£ãŸã®ã‹ï¼ã€
- Safeguarded AI: 
	- https://www.aria.org.uk/wp-content/uploads/2024/04/ARIA-Safeguarded-AI-TA1.1-Theory-Call-for-proposals.pdf
	- ARIAã®Davidadæ°ã®å®‰å…¨ä¿è¨¼ä»˜ãAIã®ç ”ç©¶ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å…¨è²ŒãŒè¦‹ãˆã¦ããŸã€‚å½¼ãŒä½•ã‚’ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã®ã‹ã€ãã‚Œã«ã©ã‚Œã»ã©ã®feasiblityãŒã‚ã‚‹ã®ã‹ã€èª°ã‹ã«è§£èª¬ã—ã¦ã»ã—ã„ã€‚å½¢å¼è¨¼æ˜ã¨ã‹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦ã€è¨ˆç®—æ©Ÿç†è«–ã®ãƒãƒƒã‚¯ã‚°ãƒ©ãƒ³ãƒ‰ãŒå¿…è¦ãã†ã€‚
	- ä»Šå›ã®å…¬å‹Ÿã§ã¯åœŸå°ã¨ãªã‚‹ã‚»ãƒãƒ³ãƒ†ã‚£ã‚¯ã‚¹ã€ã€Œè¨€èªã€ã¥ãã‚Šã‚’ç›®æŒ‡ã™ã¨ã®ã“ã¨ã§ã€ãã®æ–¹æ³•è«–ã¨ã—ã¦åœè«–ãŒåæŒ‡ã—ã•ã‚Œã¦ã„ã¾ã™
- Mixtral8x22ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç‰ˆ
	- HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1
	- ORPOã¨ã„ã†æ–°ã—ã„ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ç”¨
	- ORPOã¯ã€SFTã‚¹ãƒ†ãƒƒãƒ—ã‚’å¿…è¦ã¨ã—ãªã„ãŸã‚ã€DPOã‚„PPOã®ã‚ˆã†ãªæ–¹æ³•ã‚ˆã‚Šã‚‚è¨ˆç®—åŠ¹ç‡ãŒè‰¯ã„ 
	- ã‚ªãƒ¼ãƒ—ãƒ³ã€åˆæˆã€ãƒãƒ«ãƒã‚¿ãƒ¼ãƒ³ã€LLMã‚’ä»‹ã—ã¦æ¡ç‚¹ã•ãŸDPOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½¿ç”¨
- LLMã«ã‚ˆã‚‹è¦–è¦šèª­è§£æŠ€è¡“ã‚’ç¢ºç«‹ï½ã‚°ãƒ©ãƒ•ã‚£ã‚«ãƒ«ãªæ–‡æ›¸ã‚’ç†è§£ã™ã‚‹ã€Œtsuzumiã€å®Ÿç¾ã«å‘ã‘ã¦ï½
	- https://group.ntt/jp/newsrelease/2024/04/12/240412b.html
- Embeddingsã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ï¼ˆMultilingual-E5ï¼‰
	- https://zenn.dev/libratech/articles/afe9c5b30668bb
- Mixtral-8x22Bã€Lightblueã•ã‚“ã®karasuãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã¨AWQ
	- https://huggingface.co/lightblue/Karasu-Mixtral-8x22B-v0.1
	- å¼·ã„ï¼ã“ã‚Œã¯é–“é•ã„ãªãã‚¨ãƒ¼ã‚¹ç´šã€€ by AIXã•ã¨ã—
		- https://x.com/AiXsatoshi/status/1778489953279951132
- Introducing Mistral-22b-V.01 A breakthrough in AI
	- https://huggingface.co/Vezora/Mistral-22B-v0.1
	- First-ever MOE to Dense model conversion
	- This model is not an moe, it is infact a 22B parameter dense model!
	- mixtralã®expertsã‚’ãƒãƒ¼ã‚¸ã—ã¦mistralã«ã—ãŸã‚„ã¤
- Vezoraã•ã‚“ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹Mistral-22B-v0.1ã®ggufã‚ã‚Šã¾ã™
	- https://huggingface.co/mmnga/Vezora-Mistral-22B-v0.1-gguf
- Swallowã‚·ãƒªãƒ¼ã‚ºã®instructæ”¹è‰¯ç‰ˆã§ã™ãŒã€æœ¬å½“ã¯2023å¹´åº¦ä¸­ã‚’ç›®æŒ‡ã—ã¦ã„ãŸã®ã§ã™ãŒã€ã‚‚ã‚ã‚‚ã‚å¤šå¿™ã§é…ã‚Œã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚
	- https://x.com/okoge_kaz/status/1778396705156943985
- mixtral 8x22bã‚’è»½ãloraã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‰ã€å°‘ã—ã€ä¼šè©±ã—ã‚„ã™ããªã‚Šã¾ã—ãŸ
	- https://x.com/kanhatakeyama/status/1778417221100028061
	- ç¾çŠ¶ï½¤mixtral 8x22bã¯äº‹å‰å­¦ç¿’ã®ã¿ã®ãƒ¢ãƒ‡ãƒ«ã§ã™ãŒï½¤ã‚ã‚Šã¨ä¼šè©±ã§ããã†ã§ã™ï½¡
-  Tool Calling with LangChain
	- https://blog.langchain.dev/tool-calling-with-langchain/
	- æœ€è¿‘ã¯ChatGPTä»¥å¤–ã«ã‚‚ Function Calling (æœ€è¿‘ã¯ Tool Calling ã¨å‘¼ã°ã‚Œã‚‹ã“ã¨ãŒå¤šã„) ã«å¯¾å¿œã™ã‚‹LLMãŒå¢—ãˆã¦ãã¾ã—ãŸã€‚é¸æŠè‚¢ãŒå¢—ãˆã¦ä¾¿åˆ©ã§ã¯ã‚ã‚‹ã‚‚ã®ã®ã€å„ç¤¾ã§å°‘ã—ã¥ã¤ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒé•ã†ã®ã§å®Ÿè£…ãŒé¢å€’ã¨ã„ã†èª²é¡ŒãŒã‚ã‚Šã¾ã—ãŸã€‚
	- ãã®ãŸã‚ã€LangChainã¯å„LLMã®Tool Callingã‚’çµ±ä¸€çš„ã«æ‰±ãˆã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æº–å‚™ã—ã¦ãŠã‚Šã€å…ˆæ—¥ã€æœ€å¾Œã®ãƒ”ãƒ¼ã‚¹ãŒãƒãƒã£ã¦é‚ã«å®Œæˆã—ãŸã¨ã„ã†è©±ã§ã™ã€‚
- LangChain ã® Tool Calling æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ ã®æ¦‚è¦ã€€by npakaã•ã‚“
	- https://note.com/npaka/n/ne6fd5929bfa1?sub_rt=share_h
	- ã€ŒTool Callingã€ã®æ¨™æº–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®æ§‹æˆã¯ã€æ¬¡ã®ã¨ãŠã‚Šã§ã™ã€‚
		- ChatModel.bind_tools()ãƒ„ãƒ¼ãƒ«å®šç¾©ã‚’ãƒ¢ãƒ‡ãƒ«ã«ã‚¢ã‚¿ãƒƒãƒã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰
		- AIMessage.tool_callsãƒ¢ãƒ‡ãƒ«ãŒæ±ºå®šã—ãŸãƒ„ãƒ¼ãƒ«ã®æƒ…å ±ã‚’ä¼ãˆã‚‹ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
		- create_tool_calling_agent()Tool Callingã‚’åˆ©ç”¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
- OpenEQA (ã‚ªãƒ¼ãƒ—ãƒ³èªå½™ã®å…·ä½“åŒ–ã•ã‚ŒãŸè³ªå•å¿œç­”ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯)
	- https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=dataset
	- ãƒãƒƒã‚¸ã‚’ã©ã“ã«ç½®ã„ãŸã‹?ã€ãªã©ã®ã‚ªãƒ¼ãƒ—ãƒ³èªå½™ã®è³ªå•
	- ç‰©ç†ç’°å¢ƒã«å¯¾ã™ã‚‹ AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç†è§£åº¦ã‚’æ¸¬å®š
- A Square-Root Kalman Filter Using Only QR Decompositions
	- https://arxiv.org/abs/2208.06452
	- QRåˆ†è§£ã§ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼Ÿ
	- æ­£å®šå€¤è¡Œåˆ—ã®å’Œã®å¹³æ–¹æ ¹ãŒå¹³æ–¹æ ¹ã®ãƒ–ãƒ­ãƒƒã‚¯è¡Œåˆ—ã®QRåˆ†è§£ã§è¨ˆç®—ã§ãã‚‹ã“ã¨ã‚’åˆ©ç”¨ã—ã¦ã€æ•°å€¤çš„å®‰å®šæ€§ã®é«˜ã„ã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå¹³æ–¹æ ¹ãƒ•ã‚£ãƒ«ã‚¿ï¼‰ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’QRåˆ†è§£ã§ã‚·ãƒ³ãƒ—ãƒ«ã«æ›¸ã‘ã‚‹ã®ã‹
- Premise Order Matters in Reasoning with Large Language Models
	- LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¸ãˆã‚‹éš›ã€ã€Œæ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ã®æµã‚Œã«æ²¿ã†é †åºã€ã§æ–‡è„ˆã‚’ä¸ãˆãªã„ã¨30%ä»¥ä¸Šç²¾åº¦ãŒè½ã¡ã‚‹æã‚ŒãŒã‚ã‚‹ã“ã¨ã‚’DeepMindãŒå ±å‘Šã—ã¦ã„ã¾ã™ã€‚
-  Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese
	- https://arxiv.org/abs/2404.07824
	- ç”»åƒ-è¨€èªãƒ¢ãƒ‡ãƒ«ã®æ—¥æœ¬èªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ã—ã¦ã€æ–°ã—ãã€ŒHeron-Benchã€ã‚’å…¬é–‹ã—ã¾ã—ãŸï¼æ—¥æœ¬ã®ç”»åƒã§ã€æ—¥æœ¬ã«é–¢ã™ã‚‹çŸ¥è­˜ã‚’ç·åˆçš„ã«å•ã„ã¾ã™
- Rho-1: Not All Tokens Are What You Need
	- https://arxiv.org/abs/2404.07965
	- MicrosoftãŠå¾—æ„ã®é«˜å“è³ªãƒ†ã‚­ã‚¹ãƒˆã§åŠ¹ç‡ã‚ˆãäº‹å‰å­¦ç¿’ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®æœ€æ–°è«–æ–‡ã€ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã®lossã®æ¨ç§»ã‚’é«˜ã„ã¾ã¾ãƒ»ä½ã„ã¾ã¾ãƒ»æ¸›å°‘å‚¾å‘ãƒ»å¢—åŠ å‚¾å‘ã®4ã‚¿ã‚¤ãƒ—ã«åˆ†é¡ã—ã¦ã„ã¦é¢ç™½ãã†ã€‚å®Ÿéš›ã«å­¦ç¿’ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸ã¶éƒ¨åˆ†ã‚’å‹‰å¼·ã—ã‚ˆã†ã€‚
	- https://huggingface.co/microsoft/rho-math-7b-v0.1
- Geminiã«ã‚ˆã‚‹RAGã®å®Ÿè·µä¾‹
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/use-cases/retrieval-augmented-generation
- Gemini API ã® ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n6609bcbbdd30?sub_rt=share_h
- ã€Œã‚«ãƒ«ãƒãƒ³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’QRåˆ†è§£ã§è§£ãæ‰‹æ³•ã€
	- https://github.com/kevin-tracy/QRKalmanFilter
	- Square root Kalman Filter using only QR decompositions.
	- related paper: Differentiable Collision Detection for a Set of Convex Primitives
	- https://arxiv.org/abs/2207.00669
- Can Gemini 1.5 actually read all the Harry Potter books at once?
	- https://x.com/deedydas/status/1778621375592485076
	- All the books have ~1M words (1.6M tokens). Gemini fits about 5.7 books out of 7. I used it to generate a graph of the characters and it CRUSHED it.

## 4/8

ä»Šé€±ã‚‚æƒ…å ±ãŒæ—©ã™ãã¦å¤§éãã¦ã€ã‚‚ã‚„ã¯è¿½ã„ã¤ã‘ã¾ã›ã‚“ã€‚RAGå‘ã‘ã®ãƒ™ã‚¯ãƒˆãƒ«DBã®ãƒ™ãƒ³ãƒ€ãƒ¼ã‹ã¨æ€ã£ã¦ã„ãŸCohereã‹ã‚‰ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Command R+ ãŒãƒªãƒªãƒ¼ã‚¹ã€ã¾ã‚æˆã‚Šç«‹ã¡ã‹ã‚‰å½“ç„¶ã€RAGã¨ã‹ãƒ­ãƒ³ã‚°ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æœ€é©åŒ–ã•ã¦ã„ã‚‹ã€‚104Bã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚å…¬é–‹ã€ãƒ†ã‚¹ãƒˆç‰ˆãŒhuggingfaceã§è©¦ã™ã“ã¨ã‚‚ã§ãã‚‹ã€GPT-4ä¸¦ã¿ã®æ€§èƒ½ã§OSSã£ã¦ã‚„ã°ããªã„ã‹ã€‚æ—©é€Ÿé‡å­åŒ–ã—ãŸã‚Šã€MLXã§å‹•ã‹ã—ãŸã‚Šã¨ã€ã‚„ã°ããªã„ã‹ã€‚ã‚ã‚‹æ€§èƒ½ä»¥ä¸Šã®LLMã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹åŒ–ç¦æ­¢ã¿ãŸã„ãªå‚¾å‘ã«æ‹è»ŠãŒã‹ã‹ã‚‹ã®ã§ã¯ã€‚Appleã‹ã‚‰ã¯ReALMç™ºè¡¨ã€ã©ã†ã‚‚Siriã®ä»£ã‚ã‚Šã«iPhoneã§ã‚‚å‹•ãè»½é‡ãªãƒ¢ãƒ‡ãƒ«ã€ãã†ã„ãˆã°Siriã®äººå“¡ãŒè§£é›‡ã•ã‚ŒãŸã¨ã„ã†ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚ã‚ã£ãŸã€‚ã‚¹ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ‰ã‚„CMUã®ä¸€æµå¤§å­¦ã§ã‚‚CSã®ä¿®å£«ã®å°±è·ç‡ãŒï¼’å‰²ã¨ã®ã“ã¨ã€ã¾ã‚10å¹´ã§CSä¿®å£«å–å¾—è€…ãŒ10å€ã«ãªã£ãŸã¨ã„ã†è¦å› ã‚‚ã‚ã‚‹ã‚ˆã†ã ãŒã€LLMã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã¨ã—ã¦ä½¿ã†ã£ã¦ã„ã†æ™‚ä»£ã€æ™®é€šã®CSä¿®å£«ç¨‹åº¦ã§ã¯ã‚‚ã‚„ã¯ã€ãŠå‘¼ã³ã§ã¯ãªã„ã¨ã„ã†ã“ã¨ã‹ã€‚OpenAIã¯ã€æ—¥æœ¬ã«ã‚¢ã‚¸ã‚¢åˆã®æ‹ ç‚¹ã‚’é–‹è¨­ã€ãªãœã‹ä½æ‰€ã¯è¥¿æ–°æ©‹ã®é›‘å±…ãƒ“ãƒ«ã€‚Gemmaã®1.1ã®ãƒªãƒªãƒ¼ã‚¹ã¨ã‹Qwen1.5-32B ã®ãƒªãƒªãƒ¼ã‚¹ãªã©ã€é‡è¦ãªæ”¹è‰¯ãƒªãƒªãƒ¼ã‚¹ã‚‚é€²ã‚€ã€‚RAGã§ã¯Reranker ãŒè©±é¡Œã«ã€é¡ä¼¼åº¦ã®é«˜ã„ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠã—ãŸã¯ãšãªã®ã«ã€ãã®ã‚ã¨ã«Rerankã™ã‚‹ã®ã‹ã€‚ã€‚å¯¾å¿œã™ã‚‹LLMã‚‚ã„ãã¤ã‹å‡ºã¦ã‚‹ã€‚æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã§ã¯ã€Swallow MX 8x7bã¯ç¾çŠ¶ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã¯æ—¥æœ¬èªæœ€é«˜ã®ãƒ¢ãƒ‡ãƒ«ã¨ã„ã†è©±ã‚‚ã‚ã£ãŸãŒã€Mistral 7Bãƒ™ãƒ¼ã‚¹ã®ï¼’ã¤ã®æ—¥æœ¬èªLLMã‚’Chat Vectoræ³•ã§å¼·åŒ–ã—ãŸã‚‚ã®ã‚’MoEã—ãŸã€ã¨ã¦ã‚‚é•·ã„åå‰ã®ãƒ¢ãƒ‡ãƒ«ãŒè©±é¡Œã«ã€å¯¿é™ç„¡ã‹ã€‚å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®ãŸã‚ã®æ—¥æœ¬èª Instruction ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã¨ã‹ã€NLP2024ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‹ã‚‰ã€ä½œã£ã¦å­¦ã¶æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« - ç’°å¢ƒæ§‹ç¯‰æ‰‹é †ã¨å®Ÿé¨“ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®å…¬é–‹ã¨ã‹ã€æ—¥æœ¬ã®LLMå±¤ã®åº•ä¸Šã’ã‚‚é€²ã‚€ã€‚ ã‚¢ãƒã‚¾ãƒ³ã®Bezosæ°ã‚‚æŠ•è³‡ã—ã¦ã„ã‚‹ã¨è©±é¡Œã¨ãªã£ãŸPerplexityã€AIæ¤œç´¢ãŒæ¬¡ã®ãƒ“ãƒƒã‚°ã‚¦ã‚¨ãƒ¼ãƒ–ã¨ã„ã†ã“ã¨ã‚‰ã—ã„ã€Googleã®AIæ¤œç´¢ã‚‚ç¢ºã‹ã«Perplexityé¢¨ã«ãªã£ã¦ã„ã‚‹ã—ã€Googleã®AIæ¤œç´¢ã¯æœ‰æ–™åŒ–ã¨ã„ã†å ±é“ã‚‚ã€‚ã‚‚ã¨ã‚‚ã¨Bingã£ã¦Perplexityã®ã‚ˆã†ãªä»•çµ„ã¿ã˜ã‚ƒãªã‹ã£ãŸã‹ã€‚Mixture-of-Depthsã¨ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ReFTã¨ã‹ã€GRIFFIN ã¨ã‹ã€æ–°ã—ã„LLMæœ€é©åŒ–ã®çŸ¥è¦‹ãŒæ¬¡ã€…ã«ã§ã¦ããŸãŒã€ãªã‚“ã¨ã„ã£ã¦ã‚‚ã€ä»Šé€±ã¯Chat Vectorã¨ã„ã†LLMã®è¶³ã—ç®—å¼•ãç®—ãŒã§ãã‚‹æŠ€è¡“ã€word2vecã®ã‚ˆã†ãªãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—ãŒLLMã§ã‚‚ã§ãã‚‹ãªã‚“ã¦ã™ã”ã™ãã‚‹ã€‚Chat Vectorã§å¼·åŒ–ã—ã¦MoEã§ã€ã€ã¿ãŸã„ãªã®ãŒä¸»æµã«ãªã‚‹ã‹ã‚‚ã€‚Claude3ã§function callingãŒã‚µãƒãƒ¼ãƒˆã€ã•ã£ããlangchainã‹ã‚‰ã€Claude3ã‚’ã¤ã‹ã£ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…ãŒå‡ºãŸã€ã¾ã‚èƒ½åŠ›ã‹ã‚‰ã—ã¦ãã†ãªã‚‹ã‚ãªã€‚BAAIã®MetaWormè«–æ–‡ã€ç·šè™«ã‚’ç ”ç©¶ã—ã¦ã€èº«ä½“æ€§ã®è¬ã‚’è§£æ±ºï¼ŸReranker ã§ã‚‚BAAIå‡ºã¦ããŸã—ã€ã‚‚ã†ä¸­å›½ã‚‚ã€åŠ›ä»»ã›ã§å„ªã‚ŒãŸLLMã‚’å‡ºã™ã ã‘ã§ã¯ãªãã€ç†è«–ã§ã‚‚ã€ã¨ã„ã†ã“ã¨ã‹ã€‚ä¸‰å€¤ã®BitNetã®æƒ…å‡¦ã®è§£èª¬ã€ã€Œç²¾åº¦ã®é€†è»¢ã€ã¨ã„ã†ã®ãŒã‚ã‚‹ã®ã‹ã€ã‚‚ã—æœ¬å½“ãªã‚‰ã°ã€ãŸã—ã‹ã«ã“ã‚Œã¯ã‚²ãƒ¼ãƒ ãƒã‚§ãƒ³ã‚¸ãƒ£ãƒ¼ã ãªã€‚


- ãƒ“ã‚¸ãƒã‚¹ã®å®Ÿå‹™ã§ã€Œå› æœã€ã‚’æ¨æ¸¬ã™ã‚‹ã¨ã„ã†ã“ã¨ by TJOã•ã‚“
	- https://tjo.hatenablog.com/entry/2024/02/28/174811
	- ã€Œã¨ã‚Šã‚ãˆãšãƒãƒ¼ã‚±ãƒƒãƒˆã®ä¸­ã«ãµã‚“ã‚ã‚Šã¨å­˜åœ¨ã™ã‚‹ã€ç³»ã®æŒ‡æ¨™ã«å¯¾ã—ã¦ã€ãã®ã‚ˆã†ãªãã¡ã‚“ã¨ã—ãŸå› æœæ¨è«–ã‚’è¡Œã†ã®ã¯çµæ§‹é›£ã—ã„å°è±¡ãŒã‚ã‚Šã¾ã™ã€‚
	- ä¸€ã¤ã®è€ƒãˆæ–¹ã¨ã—ã¦ã€Œæ™‚ç³»åˆ—çš„ãªå› æœæ€§ã€ã‚’ãµã‚ã£ã¨ã—ãŸä»£ç”¨å“ã¨ã—ã¦ç”¨ã„ã‚‹ã¨ã„ã†æ–¹æ³•ã‚‚ã‚ã‚Šå¾—ã‚‹ã¨æ€ã£ã¦ã„ã¾ã™ã€‚ãã†ã€VARãƒ¢ãƒ‡ãƒ«ã§ã™
	- å³ã¡å®Ÿéš›ã®å› æœã¯ã€Œè½é›·â†’é›·é³´ã€ã ãŒã€æ™‚ç³»åˆ—çš„ã«ã¯ã€Œï¼ˆè½é›·â†’ï¼‰ç¨²å…‰â†’é›·é³´ã€ãŒæˆç«‹ã™ã‚‹ã®ã§ä»£ç”¨å“ã«ãªã‚Šå¾—ã‚‹ã€ã¨ã„ã†
- ç¿»è¨³ãƒ¢ãƒ‡ãƒ«Honyaku-7b by AIXã‚µãƒˆã‚·
	- aixsatoshi/Honyaku-Multi-Translator-Swallow-ms7b
	- æ•°ç™¾ã€œæ•°åƒtokenã®æ–‡ç« ç¿»è¨³ 
	- è‹±æ—¥ã€æ—¥è‹±ç¿»è¨³æ©Ÿèƒ½ãŒãƒ¡ã‚¤ãƒ³
	- XML like instruction
	- ä¸€éƒ¨ã®å¤šè¨€èªã‚‚å¯¾å¿œ
	- Swallow-ms-7b baseã§æ—¥æœ¬èªå ªèƒ½
- å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«é–‹ç™ºã®ãŸã‚ã®æ—¥æœ¬èª Instruction ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã®å–ã‚Šçµ„ã¿
	- https://speakerdeck.com/kunishou/da-gui-mo-yan-yu-moderukai-fa-notamenori-ben-yu-instruction-detasetutozuo-cheng-noqu-rizu-mi
- ã€OpenAIã€‘æ—¥æœ¬ã«ã‚¢ã‚¸ã‚¢åˆã®æ‹ ç‚¹ã‚’é–‹è¨­ã€æ³•äººå‘ã‘ã‚µãƒ¼ãƒ“ã‚¹æä¾›ã¸
	- https://www.nikkei.com/article/DGXZQOUC29A7U0Z20C24A3000000/?n_cid=SNSTW001&n_tw=1711923970
	- OpenAIãŒ4æœˆä¸­ã«æ±äº¬éƒ½å†…ã«ã‚¢ã‚¸ã‚¢åˆã®æ‹ ç‚¹ã‚’ç«‹ã¡ä¸Šã’ã€æ—¥æœ¬ã§ã®äº‹æ¥­æ´»å‹•ã‚’æœ¬æ ¼åŒ–ã•ã›ã‚‹
	- äº‹å‹™æ‰€ã¯è¥¿æ–°æ©‹ã®é›‘å±…ãƒ“ãƒ«ï¼Ÿï¼Ÿ
-  Mechanistic Design and Scaling of Hybrid Architectures
	- https://arxiv.org/abs/2403.17844
	- LLMã®ãƒ¢ãƒ‡ãƒ«è¨­è¨ˆã¯æ™‚é–“ã¨ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã€‚ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚äººå·¥çš„ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¿ã‚¹ã‚¯ MADï¼ˆin-context recall, compressionç­‰ï¼‰ã‚’è¨­è¨ˆã€‚å°è¦æ¨¡MADã§è©•ä¾¡ã—ãŸçµæœã‚’å…ƒã«æœ‰æœ›ãªæ‰‹æ³•ã‚’çµã‚Šã‚¹ã‚±ãƒ¼ãƒ«ã•ã›ã‚‹ã€‚å¤šããŒå°è¦æ¨¡MADã®æ€§èƒ½ã¨ã‚¹ã‚±ãƒ¼ãƒ«å¾Œã®æ€§èƒ½ã«ç›¸é–¢ãŒã¿ã‚‰ã‚ŒãŸ
- LLMã®ç¾åœ¨
	- https://speakerdeck.com/pfn/llmnoxian-zai
-  MetaWorm: A Complete Model Bridging Brain, Body and Environment of  _C. elegans_
	- https://www.biorxiv.org/content/10.1101/2024.02.22.581686v1
	- BAAIã®ç ”ç©¶ã€ç”Ÿç‰©ã®è„³ã€èº«ä½“ã€ç’°å¢ƒã®é–“ã®è¤‡é›‘ãªç›¸äº’ä½œç”¨ã‚’ç·šè™«ï¼ˆC. eleganï¼‰ã‚’ææ–™ã«è§£æ
- ã€ŒBabylon.js 7.0ã€æ­£å¼ãƒªãƒªãƒ¼ã‚¹ã€‚
	- https://www.publickey1.jp/blog/24/web3dbabylonjs_70mmdmikumikudanceapple_vision_pro.html
	- ãƒã‚¤ã‚¯ãƒ­ã‚½ãƒ•ãƒˆã¯ã€Webãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§2Dã‚„3Dãƒ¢ãƒ‡ãƒ«ã®é«˜é€Ÿãªãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ãªã©ã‚’å¯èƒ½ã«ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®JavaScriptãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€ŒBabylon.jsã€ã®æœ€æ–°ç‰ˆã€ŒBabylon.js 7.0ã€æ­£å¼ç‰ˆã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸã€‚
	- MMDï¼ˆMikuMikuDanceï¼‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨åˆ©ç”¨ã‚’å¯èƒ½ã«ã™ã‚‹MMDãƒ­ãƒ¼ãƒ€ãƒ¼ã¨ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚IKã‚½ãƒ«ãƒã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªåŒæœŸå†ç”Ÿã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãªã©ã®æ©Ÿèƒ½ã‚‚ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚
- CMUã‚‚Stanfordã‚‚Columbiaã‚‚CSä¿®å£«ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ³å†…å®šç‡2å‰²
	- https://x.com/fzw1212/status/1774218929100988506
-  LLaMA Now Goes Faster on CPUs
	- https://justine.lol/matmul/
	- 84 new matrix multiplication kernels for llamafile
	- between 30% and 500% faster when using F16 and Q8_0 weights on CPU. 
- Gecko: Versatile Text Embeddings Distilled from Large Language Models
	- https://huggingface.co/papers/2403.20327
	- Googleã‹ã‚‰ã€Geckoçµ„ã¿è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã€LLMã‚’è’¸ç•™ã—ãŸï¼Ÿï¼Ÿè¬
	- LLMã‚’ä½¿ã£ã¦å­¦ç¿’ç”¨ã®ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã£ã¦Embedding Modelã®å­¦ç¿’ã‚’ã—ãŸå¾Œã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã«å¯„ã‚Šå¾—ã‚‰ã‚ŒãŸé–¢é€£ãƒ‘ãƒƒã‚»ãƒ¼ã‚¸ã«åŒã˜LLMã§Positive/Hard Negativeã®ãƒ©ãƒ™ãƒ«ã‚’æŒ¯ã‚Šç›´ã—ã¦è¿½åŠ å­¦ç¿’ã—ã¦ã„ã‚‹ã‚‰ã—ã„ã€‚
- LMFlowã§Llama2-70Bã®LISAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã‚ã£ã•ã‚Šå‹•ã„ãŸ by shi3zã•ã‚“
	- https://x.com/shi3z/status/1774710763007119735
	- å¤§ä½“30GBã‚ã‚Œã°å­¦ç¿’ã§ãã‚‹ã¨ã™ã‚Œã°A6000ã§ã‚‚å¯èƒ½ã¨ã„ã†ã“ã¨ã‹?
-  Google Colab ã§ BAAI/bge-reranker-v2-m3 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n7d251f76ce25?sub_rt=share_h
	- ã€ŒBAAI/bge-reranker-v2-m3ã€ã¯ã€ã€Œbge-m3ã€ãƒ™ãƒ¼ã‚¹ã®ã€ŒRerankerã€ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã€ŒRerankerã€ãƒ¢ãƒ‡ãƒ«ã¯ã€å¾“æ¥ã®ã€ŒåŸ‹ã‚è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ã¨ã¯ç•°ãªã‚Šã€è³ªå•ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€é¡ä¼¼åº¦ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚
	- ã€Œãƒ‘ãƒ³ãƒ€ã¨ã¯ï¼Ÿã€ã®è³ªå•ã«ã¯ã€Œãƒ‘ãƒ³ãƒ€ã¯ä¸­å›½å—è¥¿éƒ¨ã®å±±å²³åœ°å¸¯ã«ç”Ÿæ¯ã™ã‚‹å“ºä¹³é¡ã®ä¸€ç¨®ã§ã™ã€‚ã€ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒé–¢é€£ã—ã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚
- Building a RAG application using open-source models by langchain
	- https://x.com/LangChainAI/status/1774821270900629950
	- https://github.com/svpino/llm/blob/main/local.ipynb
	- https://www.youtube.com/watch?v=HRvyei7vFSM
- Claudeã ã¨æœ¬å½“ã«ä¸€ç¬ã§ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ã‚’ä½œã£ã¦ãã‚Œã‚‹ã€‚
	- https://x.com/ai_syacho/status/1774677348807483788
- Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians
	- https://github.com/city-super/Octree-GS
	- https://x.com/janusch_patas/status/1774717184238883237
- ã€Googleæ¤œç´¢ã‚’è¶…ãˆã‚‹è¡æ’ƒã®ç”ŸæˆAIå‹æ–°æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼šPerplexity ProãŒæƒ…å ±åé›†ã‚’å¤‰ãˆã‚‹ï¼ã€
	- https://x.com/tetumemo/status/1774632484648730889
	- Perplexity ã®ã‚ˆã†ãªAIæ¤œç´¢ãŒã€ã¤ãã®ãƒ“ãƒƒã‚°ã‚¦ã‚¨ãƒ¼ãƒ–ã¨ã„ã†ã‹ã€active personal noteã ã‚ˆãªã€‚AIæ¤œç´¢ã‚’æœ‰æ–™ã«ã™ã‚‹ã¨ã„ã†å‹•ãã‚‚ã‚ã‚‹ã€‚
- BItNet-Transformerã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒå…¬é–‹ã•ã‚Œã¦ã„ã‚‹
	- 1bitLLM/bitnet_b1_58-large
- NLP2024 ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ï¼“: ä½œã£ã¦å­¦ã¶æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« - ç’°å¢ƒæ§‹ç¯‰æ‰‹é †ã¨å®Ÿé¨“ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰
	- https://github.com/hiroshi-matsuda-rit/NLP2024-tutorial-3
	- æ—¥æœ¬èªLLMã®å­¦ç¿’ãƒ»è©•ä¾¡ã«ç”¨ã„ã‚‰ã‚Œã‚‹æŠ€è¡“ã¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¤ã„ã¦åºƒãå–ã‚Šä¸Šã’ã¦ã„ã¾ã™ã€‚æ˜¯éã”è¦§ãã ã•ã„ã€‚
	- è¬›æ¼”ã‚¹ãƒ©ã‚¤ãƒ‰ã¨å®Ÿé¨“ç’°å¢ƒæ§‹ç¯‰æ‰‹é †ãƒ»ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯GitHubãƒªãƒã‚¸ãƒˆãƒªã§å…¬é–‹ã—ã¦ã„ã¾ã™
	- ãƒªã‚¯ãƒ«ãƒ¼ãƒˆã®æ¾ç”°å¯›ã•ã‚“
- æ±å·¥å¤§ã®Swallow MX 8x7bã¯ç¾çŠ¶ãƒ­ãƒ¼ã‚«ãƒ«LLMã§ã¯æ—¥æœ¬èªæœ€é«˜ã®ãƒ¢ãƒ‡ãƒ«ã ã‚ã†ã­â€¦
	- https://x.com/Meteor_Eternal/status/1775096408435216766
- OSS Models + LangGraph.js
	- LangGraph helps you create LLM apps that closely match the logical flows used to solve a problem.
	- https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_mistral.ipynb
-  Mamba Explained
	- https://thegradient.pub/mamba-explained/
	- Mambaã®é¸æŠæ©Ÿæ§‹ã‚’æ³¨æ„æ©Ÿæ§‹ã¨ã®æ¯”è¼ƒã‚„ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼ã‚’ç”¨ã„ãªãŒã‚‰ç›´æ„Ÿçš„ã«èª¬æ˜ã—ãŸè¨˜äº‹ã€‚ 
	- æ–‡è„ˆå†…å­¦ç¿’ã§ã¯Transformerã®ã‚ˆã†ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å…¨ã¦ã®æƒ…å ±ã‚’å…¥ã‚Œã‚‹å¿…è¦ãŒãªãã€çŠ¶æ…‹ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã©ã‚’åœ§ç¸®ã—ãŸã‚‚ã®ï¼‰ã¨è³ªå•ã‚’æ¸¡ã™ã ã‘ã§è‰¯ã„ã€‚
- Bigger is not Always Better: Scaling Properties of Latent Diffusion Models by Google
	- https://huggingface.co/papers/2404.01367
- Prompt-prompted Mixture of Experts for Efficient LLM Generation
	- https://arxiv.org/abs/2404.01365
	- LLM ã¸ã®å…¥åŠ›ã”ã¨ã«ã€LLMã®å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã§ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã®ç›¸å¯¾çš„ãªå¤§ãã•ãŒã€ãƒˆãƒ¼ã‚¯ãƒ³ä½ç½®ã«ã‚ˆã‚‰ãšä¸€éƒ¨ã®æ¬¡å…ƒã«åã‚‹ flocking ã¨ã„ã†ç¾è±¡ã‚’ç™ºè¦‹ã—ã€ã“ã‚Œã‚’ã‚‚ã¨ã«ã€
	-  (1) prompt å…¥åŠ›æ¬¡ç‚¹ã§ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ãŒç›¸å¯¾çš„ã«å¤§ãã„æ¬¡å…ƒã‚’ç‰¹å®š
	-  (2) ãã®æ¬¡å…ƒã®ã¿ã‚’ä½¿ã£ã¦è¿‘ä¼¼çš„/åŠ¹ç‡çš„ã« Decode ã‚’è¡Œã†ã€
	- GRIFFIN (Gating by Repetition In Feedf orward Intermediate Neurons) ã‚’ææ¡ˆã€‚ ã‚¿ã‚¹ã‚¯ã«ä¾å­˜ã™ã‚‹ãŒã€å­¦ç¿’ä¸è¦ãªæ–¹æ³•ã§ç²¾åº¦ã‚’ã‚ã¾ã‚Šè½ã¨ã•ãšç”Ÿæˆã‚’é«˜é€ŸåŒ–ã§ãã‚‹ã€‚
-  Are large language models superhuman chemists?
	- https://arxiv.org/abs/2404.01475
	- ã€ŒåŒ–å­¦åˆ†é‡ã®å¹…åºƒã„ 7,000 ä»¥ä¸Šã®è³ªå•ã¨å›ç­”ã®ãƒšã‚¢ã‚’å³é¸ã—ã€ä¸»è¦ãªLLM ã‚’è©•ä¾¡ã—ã¾ã—ãŸã€‚ãã®çµæœã€ç§ãŸã¡ã®ç ”ç©¶ã§ã¯ã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ãŒå¹³å‡ã—ã¦æœ€è‰¯ã®äººé–“ã®åŒ–å­¦è€…ã‚’ä¸Šå›ã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¤ºã—ãŸã€
-  LlamaIndex ã® Reranker ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n8f9ee8533896?sub_rt=share_h
	- RAGã«ãŠã‘ã‚‹ã€ŒRerankerã€ã¯ã€å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã®ä¸­ã‹ã‚‰ã€è³ªå•ã«å¯¾ã—ã¦æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’æŒã¤ãƒãƒ£ãƒ³ã‚¯ã‚’é¸æŠã™ã‚‹å½¹å‰²ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚
	- ä»Šå›ã¯ã€å¤šè¨€èªã®Rerankerãƒ¢ãƒ‡ãƒ«ã€Œ**BAAI/bge-reranker-v2-m3**ã€ã‚’ä½¿ã„ã¾ã™ã€‚top_n=5ã§é–¢é€£æ€§ã®é«˜ã„5ä»¶ã«çµã‚Šã¾ã™ã€‚
-  Semantic Routerã‚’è©¦ã™
	- https://zenn.dev/kun432/scraps/73b098e774bd21
	- LLMã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®šã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’è¡Œã†Semantic Routerã‚’è©¦ã—ã¦ã¿ãŸã€‚ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã ã‘ã˜ã‚ƒãªãã€ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãªãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã«ã‚‚ä½¿ãˆã‚‹ã€‚ ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã®ä½¿ã„æ–¹ã¯ã„ã‚ã„ã‚ãªå¯èƒ½æ€§ãŒã‚ã‚Šãã†ã€‚
	- ã‚¯ã‚¨ãƒªã§å‡¦ç†ã‚’åˆ†å²ã•ã›ãŸã„ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ã¯ã€Function Callingã‚’ä½¿ã£ã¦LLMã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã›ã‚‹ã¨ã‹ãŒã‚ã‚‹ã¨æ€ã†ã®ã ã‘ã©ã€äº‹å‰ã«ã‚¯ã‚¨ãƒªã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”¨æ„ã—ã¦ãŠã„ã¦ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã›ã‚‹ã¨ã„ã†ã‚ˆã†ãªã‚‚ã®ã€‚
	- LangChainã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨çµ„ã¿åˆã‚ã›ãŸä¾‹ã€‚
- 4/23(ç«)ã«ã€Sakana AIåˆã®ã‚¤ãƒ™ãƒ³ãƒˆã‚„ã‚Šã¾ã™ï¼Grow-AIã€Arayaã®æ–¹ã€…ã¨æˆ‘ã€…ã®ãƒˆãƒ¼ã‚¯ãŒã‚ã‚Šã¾ã™
	- https://x.com/iwiwi/status/1775367258040410519
- 2x7Bã®æ—¥æœ¬èªãƒãƒ£ãƒƒãƒˆãƒ»ãƒãƒ™ãƒ«å°‚ç”¨é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã€‚
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Antler-7Bã¨chatntq-ja-7b-v1.0ã¨ã„ã†ã€Japanese Stable LM Base Gamma 7Bï¼ˆMistral 7Bãƒ™ãƒ¼ã‚¹ï¼‰ã‚’instructionãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’å„ã€…ChatVectoræ³•ã§å¼·åŒ–ã—ã€MoEã§ãƒãƒ¼ã‚¸ã—ãŸã®ã ãã†ã 
- RankZephyr is a nice 7B model 
	- https://arxiv.org/pdf/2312.02724.pdf
	- that is optimized for list-wise zero-shot reranking
	- https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/rankLLM/?h=rankllm
- intelligent notetaking by https://iki.ai/
	- https://iki.ai/
	- a cool example of an AI-enabled notetaking interface that epitomizes the core value prop of RAG - dump in a ton of your messy, unstructured data (files, links, notes), and have the application organize and surface information for you instead of you having to do it yourself.
-  Google Colab ã§ japanese-reranker-cross-encoder-large-v1 ã‚’è©¦ã™ by npakaã•ã‚“
	- https://note.com/npaka/n/n906b23636ac8?sub_rt=share_h
	- ã€Œ japanese-reranker-cross-encoder-large-v1ã€ã¯ã€æ—¥æœ¬èªã«ç‰¹åŒ–ã—ãŸå½¢ã§å­¦ç¿’ã—ãŸã€ŒRerankerã€ã§ã™ã€‚xsmallã‹ã‚‰largeã¾ã§è¤‡æ•°ã®ã‚µã‚¤ã‚ºãŒæä¾›ã•ã‚Œã¦ãŠã‚Šã€ã€Œlargeã€ã¯å¤šè¨€èªRerankerã§æœ€ã‚‚äººæ°—ã®ã‚ã‚‹ã€Œbge-reranker-v2-m3ã€ã‚’ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚
	- ã‚¯ã‚¨ãƒªã¨æ–‡ç« ã®æº–å‚™ã¨ã€ã‚¹ã‚³ã‚¢ã®è¨ˆç®—ã€‚
- Anthropic Messages API
	- https://x.com/AnthropicAI/status/1775979799644934281
	-  Claude3ã«
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTI2MDkyMjU4NCwtMzg3MTk0NDUwLC0yMj
cwNzc2MTgsLTE3OTUxMDI4NjMsMTY1ODczNzEwNSwtMTE3MTQ3
MTU3NCwxMDQwMjA1NjY3LDI5MDAxMjE0MiwxMzcxNzI0ODg4LC
0xNDU5MTEyMDc1LC0xMzQxMzczODAsLTEyNjA0MDgzMjIsLTEx
NjU4MjExMzYsMTY4ODA2ODYxMCwtMjA0OTYyNzU0NCwtMTA5Nj
g1NTMwMSwxMTQ5MjAxODkzLDgyNTU2NzkwMiwtMjExMDU1MDM3
OSwtOTAzMDM3Mjk1XX0=
-->