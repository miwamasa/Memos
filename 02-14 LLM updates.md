# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。

## 24/7/29

- 日本の企業活動は、初等・中等教育までの知識で成り立っているのに対して、アメリカの企業活動は、大学院教育に基づいて成り立っている
	- https://x.com/yukionoguchi10/status/1814670633277792779
- MITダロン・アセモグル教授
	- https://x.com/kiyoshi_shin/status/1813799795221471701
	- 元論文もあった。発表は今年4月
		- https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf
		- AIの登場は、新市場を作り出すのではなく、既存市場の効率化に向かうので、市場規模全体が広がるわけではないので、経済成長が起きるという点には懐疑的。
		- AIのミクロ経済効果がタスクレベルでのコスト削減（または生産性向上）によってもたらされる場合、そのマクロ経済への影響はハルテンの定理の一種によって示されると主張しています。つまり、GDPと総生産性の向上は、AIの影響を受けるタスクの割合とタスクレベルでの平均コスト削減によって推定できるというものです。
		- 既存の推定値を用いて、今後10年間の総要素生産性（TFP）への影響は0.71％を超えないと論文は結論づけています。
		- さらに、初期の証拠は「学習しやすい」タスクからのものであるため、この推定値は誇張されている可能性があると主張しています。
		- 将来の影響の一部は、「学習しにくい」タスクからもたらされるため、TFPの増加はさらに控えめになると予想されます。
		- AIが特定のタスクにおいて低スキル労働者の生産性を向上させたとしても（彼らに新しいタスクを生み出すことなく）、不平等を減少させるどころか増加させる可能性があることを理論的に示しています。
		- AIによって生み出される新しいタスクの中には、オンライン操作のためのアルゴリズム設計など、社会的に負の価値を持つものがあるかもしれないと指摘しています
-  Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies
	- https://arxiv.org/abs/2407.13623
	- 語彙数も考慮に入れたスケール則を導出。異なる語彙数間で比較するためUnigram分を引いた損失で評価。非語彙埋め込みパラメータ数の0.83乗に比例するペースで語彙を増やすと良い。学習データが増えるほど最適な語彙数は増加する。既存LLMの語彙数は最適よりも数倍少ない。
- Sakana AIは、日本の美を学んだAIとして、浮世絵風画像生成モデルEvo-Ukiyoeと、浮世絵カラー化モデルEvo-Nishikieを公開します。
	- https://x.com/SakanaAILabs/status/1815192991453401092
- NVIDIA proposes ChatQA 2, a Llama3-based model for enhanced long-context understanding and RAG capabilities.
	- https://x.com/omarsar0/status/1815219911276580951
	- The idea is to bridge the gap between open-access and leading proprietary models like GPT-4-Turbo.
	- Results demonstrate that the Llama3-ChatQA-2-70B model achieves accuracy comparable to GPT-4-Turbo2024-0409 on many long-context understanding tasks and surpasses it on the RAG benchmark.
-  データマネジメントと生成AI
	- https://qiita.com/moritata9/items/f1f8538b559a007217af
	- データを見つける際のデータ抽出を自然言語で行うユースケースが多いね。
	- コーディングはLLMが得意な領域だから、自然言語でSQLを書いてもらうことはいい使い方だね。
	- ただ、品質担保が仕切れるかどうかはまだわからないから、SQL生成をしてユーザーがチェックできる仕組みにしているように見えるね。
	- 効率化される側ではなくて、効率化する側になることが大事だね。
- UnslothでLlamaのQLoRA finetuning試してみましたが最高ですね
	- https://x.com/arumaekawa/status/1814995731972755787
- Transformer Dissection: A Unified Understanding of Transformer’s Attention via the Lens of Kernel
	- https://arxiv.org/pdf/1908.11775
	- https://x.com/myamada0/status/1814793268074586460
	- Transformerはカーネル法使って早くなる論文読んで、カーネル法こんな使い方あったか、面白い！！！って思ったけど、共著論文書いてたの思い出した。(引用されてた)
-  Mixture of LoRA Experts
	- https://arxiv.org/abs/2404.13628
	- 複数のLoRAをマージするにあたり、ただ足し合わせたりといった方法だと各LoRAの性質が失われる課題があった。本研究ではLoRAの各層ごとにGating Functionを学習することで、低コストで複数のLoRAの性質を引き継ぐ手法を提案。V&LやNLPにおいて、既存手法を上回る性能となった
- Anthropic CEOは、人類に脅威を与えるAI(ASL-4水準)の到来は、2025年から2028年と予想
	- https://x.com/0317_hiroya/status/1815237370935136299
- DCLM 7B is based on OpenELM, trained on 2.5T tokens with 63.72 MMLU.
	- https://x.com/AlphaSignalAI/status/1815425975926006036
	- Apple just released a 7B model that beats Mistral 7B.
- 「How is Mem0 different from RAG?」
	- https://x.com/Harappa80/status/1815358200826462272
	-  AIとの対話を長期記録してLLMの応答をパーソナライズする「Mem0」
- IMO questions only need high school level math knowledge and first one is the easiest so best humans can solve it in <60 mins
	- https://x.com/sytelus/status/1815203516941766757
- カーネル法とTransformerの論文とか本当に胸熱
	- https://x.com/m0chi_kokeshi/status/1815015579453133180
- Mistral-Nemo-Instruct-2407のggufあります
	- https://huggingface.co/mmnga/Mistral-Nemo-Instruct-2407-gguf
	- imatrixのデータはTFMC/imatrix-dataset-for-japanese-llmを使用して作成しました
- Llama 3.1 70B seems like the most interesting model launching tomorrow. HumanEval jumped from 39% to 79% between llama 3 and 3.1 70B
	- https://x.com/phill__1/status/1815426904289312788
-  深津式プロンプトを超える、ロング コンテキスト時代のテクニック指南
	- https://note.com/google_gemini/n/nbbe40969c653?sub_rt=share_h
	- これから必要なのは「プロンプトの暗記」ではない
	- 考え方としては大きく 2 種類あります。ひとつが、問題の適正なフレームを作ること。
	- もうひとつが、問題を簡単に解決できるであろう方法を指定することです。
	- ロング コンテキストの活用法というと大量の情報の要約と言われがちでそれももちろんなのですが、でもそれだけでなく、ビジネスデータの分析、対話履歴の分析、コード生成など、幅広い活用が可能です。僕的には特に分析力を活用することで、新たな価値を生み出すことができると考えているんです。
- LazyLLM:Dynamic Token Pruning for Efficient Long Context LLM Inference
	- https://huggingface.co/papers/2407.14057
	- Apple presents LazyLLM
- 著者らの実装よりも効率的なKANのバージョンが公開されている
	- https://github.com/Blealtan/efficient-kan
	-  An Efficient Implementation of Kolmogorov-Arnold Network
- Advanced RAG service
	- https://techcommunity.microsoft.com/t5/modern-work-app-consult-blog/exploring-the-advanced-rag-retrieval-augmented-generation/ba-p/4197836
	- 話題のMicrosoft ResearchのGraphRAGをはじめ、様々なRAGの構成技術を簡易なWebアプリ上で簡単に試せるAdvanced RAG AI Service。
- With our new InteractiveSheet feature you can create and edit Google Sheets from a Colab notebook!
	- https://x.com/GoogleColab/status/1815500302277394779
- Google、アプリ実行時に生成AIが適切なUIを構成し動的生成する「AI Generated UI」発表
	- https://x.com/publickey/status/1815596621586891029
- MacStudioでさえローカルLLMの電気代とGPT-4ominiのAPIコストがトントンだとしたらGPUでのローカルLLMなんて完全敗北確定じゃないですか～ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1815620439940727067
- Build a mixture of agents with llama_index and ollama
	- https://x.com/jerryjliu0/status/1815534962785071442
- LLMによって専門的な心理テストをRPG風などのゲームに変換し、楽しませながら測定するアプローチが検証されました。
	- https://arxiv.org/abs/2402.12326
	- LLM Agents for Psychology: A Study on Gamified Assessments
- 寝る前に頑張ったLLama 3.1気になる部分まとめ
	- https://x.com/webbigdata/status/1815784455413612734
	- LLama 3.1 8BはほとんどのベンチマークでGemma 2 9Bを上回る
	-  LLama 3.1 70BはほとんどのベンチマークでGPT-3.5 turboを上回る 
	- LLama 3.1 405BはほとんどのベンチマークでGPT-4を上回る 
	- LLama 3.1 405BはGPT-4 Omni、Claude 3.5 sonnetとほぼ互角
-  The Llama 3 Herd of Models
	- https://ai.meta.com/research/publications/the-llama-3-herd-of-models/
- Tool calling with Ollama by LangChin
	- https://x.com/LangChainAI/status/1815860475441393845
	- https://github.com/langchain-ai/langchain/blob/master/docs/docs/integrations/chat/ollama.ipynb
-  Towards Causal Foundation Model: on Duality between Causal Inference and Attention
	- https://arxiv.org/abs/2310.00809
	- 本当なら凄い。
	- his is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention,
- Metaは先陣を切って明確に「EUをハブる」方向に舵を切り,他機関も続きそうです
	- https://x.com/ImAI_Eruel/status/1815935567680659803
	- EUは厳しいAI規制をしようと動いており，EU圏外の生成AI開発が「EUに合わせる」のか「EUをハブる」のか動向が注視されていた
	- 今日のLlama3.1ですが，論文（https://ai.meta.com/research/publications/the-llama-3-herd-of-models/）を見てみると，総計算量が3.8x10^25 で，EUが定めた規制対象「systemic risk」の基準である1.0x10^25を超えています．これを超えるとEU内で色々と厄介な扱いを受けるはずなのですが，LeCun自身はこの話題に関して「EUは自ら最新モデルにアクセスできないように首を絞めている」というツイートもRTしており，意図的に踏み越えている感じです
- Fine-tuning gpt-4o-mini is *free* for up to 2M tok/day??
	- https://x.com/moyix/status/1815840634013639086
- Llama-3.1-8B-Instructに、Llama3時代のSwallowブランチ差分をマージし日本語圏の知識を学習させる実験
	- https://huggingface.co/aixsatoshi/Meta-Llama-3.1-8B-Instruct-plus-Swallow
- GPT-4o miniが200万トークンまでだと無料でファインチューニングできるとのこと👏。早速、Govbotのデータを使って、ファインチューニングを実施中↓😇。RAGとの精度を比較してみたい。用途に合わせたモデルがこれほど簡単に作れるのがホントすごい。しかも、無料！
	- https://x.com/gijigae/status/1815966274511348157
- I made the closed-source vs. open-weight models figure for this moment.
	- https://x.com/maximelabonne/status/1816008591934922915
	-  **閉源モデルとオープンウェイトモデルの性能差の縮小:** 2022年頃から、オープンウェイトモデルの性能が急速に向上しており、閉源モデルとの差が縮小していることがわかります。特に、Llama 3.1 405Bの登場により、初めて閉源モデルに匹敵する性能が実現されました。
	-   **モデルのパラメータ数と性能の関係:** 一般的に、モデルのパラメータ数が増えるほど性能が向上する傾向が見られます。しかし、必ずしもパラメータ数が多いモデルが常に高い性能を示すとは限りません。
	- **モデルの進化のスピード:** 自然言語処理モデルの性能向上は非常に速く、数ヶ月ごとに新しいモデルが登場し、
- 機械学習ハミルトニアンの論文。by 横山さん
	-  Deep learning density functional theory Hamiltonian in real space
	- https://arxiv.org/abs/2407.14379
	- 従来の機械学習によるハミルトニアン予測は基底関数の選択が結果に大きく影響したのに対し、実空間のポテンシャルを直接予測することで基底関数に依存せず正確に電子状態を予測できたそうです。
- llama3.1を日本語対応させたLlama3.1-ArrowSE-v0.4を公開します。しっかり日本語で応答します。
	- https://huggingface.co/DataPilot/Llama3.1-ArrowSE-v0.4
- Fully local agents with Llama3.1
	- https://x.com/LangChainAI/status/1816150605318304166
- Mistral large2、123Bパラメーターで日本語に正式対応
	- https://x.com/AiXsatoshi/status/1816135011294404767
- Mistralからまたしても新モデル投下！！Mistral-Large2！！前のMistral-Largeはクローズモデルだったのに今回はオープン公開！！パラ数は123B！！405Bほどじゃないけどでかい。コンテキスト長128k！多言語対応で日本語もイン！！MT-Benchで8.63でSonnet3.5やGPT-4o並みらしい！！　 by うみゆきさん
	- https://x.com/umiyuki_ai/status/1816154383211770096
- 特許番号を入れるとAIが自動的に特許に基づくアイディアを考えてくれる
	- https://chizaizukan.com/property/ideaflow/
- ベイズ統計入門　by 渡辺澄夫
	- https://warp.ndl.go.jp/info:ndljp/pid/12364128/watanabe-www.math.dis.titech.ac.jp/users/swatanab/joho-gakushu6.html
	- もう主義も論争もいりません
	- 現代の統計学において「主義」が無意味であることは、わかっている人はみなわかっているが、「導入本」「ＳＮＳ上」「また聞き」には「ベイズ主義」、「頻度主義」という言葉や論争をあおる説明が書かれている場合が多く、これを読んだユーザーが「どちらが正しいか」という問いかけを始めてしまいやすい。
- Llama 3.1 performing multi-step planning, reasoning, and tool calling. This is without an agent framework!
	- https://x.com/tom_doerr/status/1816118804541329533
-  Improving Model Safety Behavior with Rule-Based Rewards
	- https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards/
	- We’ve developed Rule-Based Rewards (RBRs) to align AI behavior safely by OpenAI
- OpenAIのRBRの記事、Sonnetに読んでもろうた by うみゆきさん
	- https://x.com/umiyuki_ai/status/1816165449136267352
	- OpenAIは今までLLM開発の仕上げにRLHFで大量の人間によるフィードバックで調教していたけど、イチイチ大勢でRLHFするのいい加減ダルくなってきたので「せや！AIにAIのフィードバックやらせたろ！」と思った。そんで評価AIにルールを与えてフィードバックさせたらいい感じの結果だった。
- OpenAIが今年度7700億円の損失、増資しないと資金が向こう12ヶ月で尽きる可能性あり
	- https://x.com/Haruki_Sonehara/status/1816230832849465415
	- モデルのトレーニングで1兆円ほどコストがかかり、人材の維持確保に2000億円。
-  Llama3.1-405Bを継之助で動かす by shi3zさん
	- https://www.free-ai.ltd/post/llama3-1-405b
	- 動いた Meta-Llama-3.1-405B running on A100x8
	- 仮にFP8(8ビット浮動小数点数)モデルであったとしてもFP8に対応していないAmpare世代のA100 80GBx8しか持ってない当社の社長、継之助(AIスーパーコンピュータ)では動かせそうもないと諦めていました
	- vllmではA100でFP8をエミュレートする機能が備わっているので、A100x8でもLlama-3.1-405Bが動作するとのこと!!マジかよ!
	- 

## 24/7/22

今週もいろいろありました、GPT-4o miniの発表のほかにAI数学オリンピック関連が目立ちました。OpenAIから出たGPT-4o mini、GPT-4よりも賢く、GPT-4oより約30倍も安いということですが、語彙数128KのTekkenトークナイザーの採用で日本語への効果も期待されるとのこと、量子化を想定した学習ってどういうこと？。OpenAIの「Prover-Verifier Games」は強いAIの出力が人間が理解するために弱いAIに説明させるという論文。まあ、LLMに対して「心の理論」を実装したエージェントの優秀性とか、Claudeにも考える時間をあげると良いという<thinking>タグの話とか、LLMの深層で何が起きているかはもはや人にはわからないのか。OpenAIの最近の活動は、Anthropicもそうだけど、LLMを取り扱うLLMというメタな活動が増えてきた感じ。Mistralからは、mambaを採用したcodestral-mambaをリリース、HumanEvalのPythonコーディングテストで人間の75%を達しただと。同時に数学モデルMathtraをリリース、OSSで数学モデルをというプロジェクト Numinaと関連している。AI-MOがリリースしたNuminaMath-7B-TIRは、AI数学オリンピックで優勝したもの、デモもあるが、量子化版はllmcppでも動くらしい。Kaggleには数学モデル用のデータの整備の記事がLLM活用のお手本のような感じ。マイクロソフトからは、エクセルを対象としたLLMである、「SpreadsheetLLM」、シートコンプレッサーってのが肝の技術だったのか。マイクロソフトのQ-Sparse、Mistral7Bベースで試したら、活性化パラ数を2.8Bくらいまで切り詰めてもあんまベンチスコア下がらないとのこと、これはすごい。ローカルLLMでGraphRAGを実装する例なども出てきて、GraphRAGのブームも続く。材料系・化学系だと、反応予測の機械学習モデル、専門家が選定した素反応データをグラフ・文字列ベースのモデルで学習するこで、中間体や副生成物も予測できるとか、 By My Eyes論文のように可視化ツールをMLLMに選ばせてセンサデータを二次元画像化してからMLLMで予測するとか、もはやマルチモーダル機能を使えば下手な人間による前処理が不要なのか？マイクロソフトからは、汎用機械学習ポテンシャル、新しい機能性材料の探索や、地球内部での元素の分布予測、効率的な化学プロセスの設計などが期待できる。それにしても、Googleの「自己複製するプログラム」の論文、「Brainfuck Family」（BFF）と呼ばれる言語環境というのは、創発というか計算機科学世界の創生の再現を狙っているのか。いもす氏の「LLMの現在」や、鈴木大慈先生の「深層学習の数理 」を読めば、最新のLLMの理論的動向に追いつけそう。BCGの、「フェッショナル経営参謀」、これをＬＬＭに教えると、いやコンサルＬＬＭが爆誕しそうだ。言語資源というか、日本語による技術知識が公共財となり日本の発展を支えたという論文、レアな良質な知識がそこにあるからという理由ならば、今のマルチ言語の世界では新しい方向性を見つけなければ、世界に埋もれてしまう気がする。MITのアセモグル先生による、AIが労働者の生産性に対して「わずか」な改善効果しかもたらさず、今後10年間の米国の経済成長への寄与率は1％未満だと予測ってのは、世の中の大勢の予測の逆張りで興味深い。ELYZA-tasks-100を人間が解くと何点取れるのかという記事も面白かった、こういう地に着いた活動ができる人が強いね、問題が人用にいまいちという感じもするが、これからデータサイエンティストの採用試験にしたらどうか。。

-  Common 7B Language Models Already Possess Strong Math Capabilities
	- https://arxiv.org/abs/2403.04706
	- his paper employs this straightforward approach achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B models, surpassing previous models by 14.2% and 20.8%, respectively.
	- 7Bクラスで数学的な能力70パー越え。見たことないレベル。
-  マリオカートのER図について考える
	- https://qiita.com/assu_ming/items/9d80320e6f778d83c61f
	-  1.最終的に出したいイメージを考える
	- 2.どんなデータが必要か列挙する
	- 3.時系列で並べる
	- 4.データのかたまり毎に分類してみる
	- 5.エンティティ同士の関係性を線でつなぐ
	- 6.それらしいカッコイイ項目名を付けてあげる（英語）
	- 7.図に落とし込む
- Incredible things are happening on my bag of legumes
	- https://x.com/stackofbears/status/1811837627357622398
- Kaggle のAI数学オリンピックコンペのfirst solution面白かった。
	- https://x.com/corochann/status/1812447716410281986
	- 数学の問題を解くLLMの学習データセット生成をするためにTIR (Tool Integrated Reasoning)でCode execution feedbackをいれたり、Self-Consistencyとして複数生成させた結果のMajority votingとったりしている
	- https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/discussion/519303
- ColPali: Efficient Document Retrieval with Vision Language Models
	- https://arxiv.org/pdf/2407.01449
	- Repurposing PaliGemma as multimodal multi-vector encoder
	- ColPali, a ColBERT-inspired multimodal multi-vector encoder using PaliGemma as a basis for document retrieval.
- a knowledge graph agent into the 🐫 CAMEL framework.
	- https://x.com/CamelAIOrg/status/1812168079712895059
- Camel AIのKnowlegeGraphを抽出するプロンプト
	- https://x.com/guohao_li/status/1812406721547256100
- ローカルLLMでGraphRAGを実装して「クリスマスキャロル」を分析してみた
	- https://hamaruki.com/analyzing-christmas-carol-with-local-llm-graphrag-2/
- llama3 8B (not quantized) running on an heterogeneous home cluster made of:
	- https://x.com/evilsocket/status/1812110504531259900
-  Context Embeddings for Efficient Answer Generation in RAG
	- https://arxiv.org/abs/2407.09252
	- Speeds up generation time while improving answer quality by compressing multiple contexts into a small number of embeddings, offering flexible compression rates.
- LLMの現在 by いもす
	- https://speakerdeck.com/pfn/llmnoxian-zai
	- 生成AIに関わるなら教養として読んでおきたい資料。 この資料からわかることとしては、 
		- 長いスパンで見た現在の生成AIブームの立ち位置 
		- 事前学習からfine tuning,推論の仕組みなど 
		- 開発における課題など LLMに関する一歩踏み込んだ内容を体系的に理解できます！ 
	- G検定でも生成AI周りの出題は増えてきているし、ここまでまとまった資料が無料で見れるのはありがたい。
	- https://x.com/blue_statistics/status/1812785366925218181
- BCGの元日本代表の杉田さんの「フェッショナル経営参謀」
	- https://x.com/akino2425/status/1812627073913217357
	- 解くべき課題　論点設定のチェックリスト
		- 1. 解くべき課題は自社のものか？
			- どの企業に置き換えても同じような課題設定になっていないか？
		- 2. それが解けたら次に進むべき「次の課題」は見えているか？
			- 自社にとって意味のある大きな境変を意識できているか？
		- 3. そこから得られるものが見えているか？
			- 何かを内包する、はて争上の観点が芽吹くのか？
		- 4. AかBかの究極の選択を迫るものではないか？
			- あるいは新たな局面を切り開くものか？
		- 5. 「この問題に対処するためにこんなことができますよ」と自信を持って言える具体性を持っているか？
		- 6. 具体性がなくてもよいので「例えば」の仮説を提示できるか？
		- 7. それが真の課題の設定と言えるか？
			- 真の課題は、問題点と事象に明確な因果関係があるのが、真の問題
		- 8. その判断が今できるか？今、解ける課題か？
		- 9. 解くべき論点の仮設は初期に作るが、その仮設も含めて、進化しているか？
			- 論点自体も変わってくる。あくまで解くべき点は進化する
		- 10.そのプロセスを経て深めていくものか？
			- 一つの事象だがシンプルで、広い見通しを持っているか？
- BCGのレポートでは、世界の地政学的な秩序の変化によって貿易活動がどのような影響を受けるのかが、スッキリ整理されている
	- https://x.com/Collie_Collie_/status/1812155080268984486
	- 例えば、ASEANが新たな輸出のプラットフォームとして浮上しているとのこと。
	- https://www.bcg.com/ja-jp/publications/2024/jobs-national-security-and-the-future-of-trade
- AI Math Olympiad Winner - Running on Mac! 100% local
	- https://x.com/reach_vb/status/1812916171902976256
		- llama-cli
		- NuminaMath-7B-TIR-Q8_0-GGUF
		- "For how many values of the constant $ k $ will the polynomial $ x^{2}+kx+36$ have two distinct integer roots?"
- Deploy llama-agents running entirely self-hosted agents using arcee_ai, MistralAI and ollama!
	- https://x.com/llama_index/status/1812884178616406422
- CEE’s new online graduate certificate, civil engineers can learn how to merge AI with digital twins to improve the predictive capabilities of their organization.
	- https://www.cmu.edu/online/aie-dta/rfi/index.html?utm_source=cee&utm_medium=social&utm_campaign=none&utm_content=fa24
-  Codification, Technology Absorption, and the Globalization of the Industrial Revolution
	- https://www.nber.org/papers/w32667
	- 外国からの技術的な知識を日本語に翻訳して公共財として普及させたことが明治時代の西欧へのキャッチアップにつながった必要条件だった。明治の日本がなんでうまく行ったのかの要因を説明する一つ。
- ポストシンギュラリティ共生学の活動を拡大中です。 by 山川さん
	- https://x.com/hymkw/status/1812857636708294778
- BM42が現れてBM25から新時代に移行する雰囲気出た直後にBM25Sとかいう亜種出てきてるし、そもそもBM42の性能も新時代と言えるか怪しいしカオス
	- https://x.com/goto_yuta_/status/1812861309534564516
- We've doubled the max output token limit for Claude 3.5 Sonnet from 4096 to 8192 in the Anthropic API.
	- https://x.com/alexalbert__/status/1812921642143900036
- Claude Sonnet 3.5 Coding System Prompt.
	- https://x.com/rohanpaul_ai/status/1812973162906460460
- Agentic RAG, explained visually
	- https://x.com/jerryjliu0/status/1812991904268849343
	- Check out nicolaygerold's full thread + diagrams below on agentic RAG + multi-agent architecture concepts, which we talked about during our aiDotEngineer talk 👇
	- https://www.youtube.com/watch?v=zeAyuLc_f3Q
- ELYZA-tasks-100を人間が解くと何点取れるのか？
	- https://zenn.dev/yuki127/articles/2496cd8383c84c
	- 日本語LLM評価でよく用いられるelyza/ELYZA-tasks-100を人間が解いたら何点取れるのかを検証する
	- 2024/7/16時点で日本語性能が最も高いLLMの一つとされるClaude 3.5 Sonnetと点数を比較する
	- 解くにあたって難しかった問題や、LLMの立場でプロンプトはどうあってほしいかを解説する
	- Sonnet3.5は、**4.42点(+0.02 / -0.02)**
	- レポーターは、**3.69点(+0.03 / -0.03)**
- 深層学習の数理 by 鈴木大慈
	- https://ibis.t.u-tokyo.ac.jp/suzuki/lecture/2023/TohokuUniv/%E6%9D%B1%E5%8C%97%E5%A4%A7%E5%AD%A62023.pdf
		- 深さに対して指数関数的に“表現力”が上がる
		- 線形モデル→カーネルモデル→深層モデル
		- 訓練誤差と汎化誤差
		- 深層学習はなぜうまくいくのか？ [世界的課題]
		- 数学による深層学習の原理究明
		  - 「表現能力」、「汎化能力」、「最適化」
	  - **学習**
		  - カーネル法、スパース推定、テンソル分解、特徴抽出
	  - **深層学習の理論**
	  - **数学**
		  -  Besov空間、連続方程式、関数近似理論、確率集中不等式、Wasserstein幾何、確率過程
	  - 理論により深層学習を"謎の技術"から"制御可能な技術"へ  
	  - 深層学習を超える方法論の構築へ
	- Deep Learningについて深く理解したい人は、東北大学の集中講義「深層学習の数理」を読んだ方がいいです。
	- 深層学習の「よくわからないけど、精度がよい」という認識を超え、一歩深い理解ができるように、原理を解明しようとしている資料です。
	- 特に「深層学習の解釈可能性」は、ビジネスサイドでも必見です。
- MatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures
	- https://arxiv.org/abs/2405.04967
	- 汎用機械学習ポテンシャル
	- Microsoftさんは1700万データでM3GNetを訓練した機械学習ポテンシャルを用いて有限温度・圧力下の自由エネルギーを正確に予測できたそうです。
	- 広範な元素・温度・圧力条件に対応できる汎用的なモデルを構築したことです。
	- 新しい機能性材料の探索や、地球内部での元素の分布予測、効率的な化学プロセスの設計など
- OllamaがOpenAIのAPI互換のツール使用をサポートだって
	- https://x.com/umiyuki_ai/status/1813096846656430429
- Mistralが、数学モデルと、Mambaのコード生成モデル　by AIXサトシさん
	- https://x.com/AiXsatoshi/status/1813315144254115987
	- https://mistral.ai/news/codestral-mamba/
	- https://mistral.ai/news/mathstral/
- ollama runs mathtral
	- https://ollama.com/library/mathstral
- 9.11 > 9.9? Someone suspected this is learned from version numbers. Here's some concrete proof.
	- https://x.com/liujc1998/status/1813244909501182310
- An underrated capability of sonnet-3.5 is that it’s really good at chart understanding from llamaindex
	- https://x.com/llama_index/status/1813249175817232782
	- compared to gpt-4o it’s much better at inferring chart values into a structured table.
	- Thanks to our brand-new LlamaParse release 💫 you can easily use SOTA multimodal models like
- Math Olympiad Solver
	- https://huggingface.co/spaces/AI-MO/math-olympiad-solver
	- Demo of the [Numina-Math-7B-TIR](https://huggingface.co/AI-MO/NuminaMath-7B-TIR). Example data are drawn randomly from AMC12, year 2022-2023.
- InternVL2-Llama3-76B
	- https://huggingface.co/OpenGVLab/InternVL2-Llama3-76B
- Codestral Mamba 7B is a Code LLM based on the Mamba2 architecture. Released under Apache 2.0 and achieves 75% on HumanEval for Python Coding.
	- https://x.com/_philschmid/status/1813222276617412943
	- https://mistral.ai/news/codestral-mamba/
- By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting
	- https://x.com/sei_shinagawa/status/1813189318392885311
	- センサデータをMLLMで処理する方法として、可視化ツールをMLLMに選ばせてセンサデータを二次元画像化してからMLLMで予測する。すべてを画像にしてやるぜという意欲作再びだ・・
-  Computational Life: How Well-formed, Self-replicating Programs Emerge from Simple Interaction
	- https://arxiv.org/abs/2406.19108
	- Googleの研究者らが「自己複製するプログラム」の自然発生を確認
	- この研究の中心となったのは、「Brainfuck」（BF）という極めて単純な言語を拡張した「Brainfuck Family」（BFF）と呼ばれる言語環境である。
	- BFFでは、_**64バイトの長さを持つ131,072個のランダムなプログラムによって、「原始スープ」（Primordial-soup）と呼ばれる環境を形成する**_。
	- 言語BrainfuckやZ80の原始スープ環境を構築。2の17乗のプログラムが相互作用し自己修正するだけで自己複製プログラムが出現。これらが環境を支配し競争し共生する生命に似た振る舞いを見せた
-  Microsoftがスプレッドシートを理解できる言語モデル「SpreadsheetLLM」を発表、Excelの仕事もAIがこなす時代に
	- https://gigazine.net/news/20240716-microsofts-ai-spreadsheetllm/
- Google accidentally updated their website with Gemini 2.0 and Bing indexing caught it
	- https://x.com/phill__1/status/1813307823570157899
-  Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models
	- https://www.arxiv.org/abs/2407.07086
	- LLMに対して「心の理論」を実装したエージェントは、そうでないLLMエージェントや強化学習エージェントと比べて様々な競争で優位に立つことを示す実験結果が報告されています。
- Anthropic APIのClaude 3.5 Sonnetの最大出力トークン数が4096から8192に倍増。
	- https://x.com/masahirochaen/status/1813333555185164637
	- GPT-4oも4K程度なので2倍に 8KだとGemini 1.5 Proレベル
-  Prover-Verifier Games improve legibility of language model outputs by OpenAI
	- https://openai.com/index/prover-verifier-games-improve-legibility/
	- We trained advanced language models to generate text that weaker models can easily verify, and found it also made these texts easier for human evaluation. 
	- This research could help AI systems be more verifiable and trustworthy in the real world.
	- OpenAIが作ってるAIが賢くなりすぎてて、AIがいくら正確な回答しても人間はアホだから内容を理解できないのがもはや問題になってるらしい。by うみゆきさん
	- https://x.com/umiyuki_ai/status/1813635128570311037
	- そこで、しょうがねえから人間の代わりにアホなAIを用意して、つよつよAIにアホAIでも理解できるように説明しろ！って訓練をさせたらしい。
	- 結果、人間にも分かりやすく説明してくれるようになりました！だってさ。
- AIは生産性を大きく高めない 議論を呼ぶMIT教授の悲観論
	- https://www.asahi.com/articles/ASS7J33L5S7JUHMC003M.html
	- アセモグル教授はこう結論づける。AIは労働者の生産性に対して「わずか」な改善効果しかもたらさず、今後10年間の米国の経済成長への寄与率は1％未満しかない、と。
- very glad President Trump is safe!　by Sam Altman
	- https://x.com/sama/status/1812325941647233057
-  Reproducing Reaction Mechanisms with Machine Learning Models Trained on a Large-Scale Mechanistic Dataset
	- https://onlinelibrary.wiley.com/doi/10.1002/anie.202411296
	- 機械学習による反応予測の論文 by 横山さん
	- https://x.com/yoko_materialDX/status/1813891469880459534
	- 従来は主生成物しか予測しなかったのに対し、専門家が選定した素反応データをグラフ・文字列ベースのモデルで学習するこで、中間体や副生成物も予測できたそうです。
	- 現状の課題は誤差蓄積と保存則を破ってしまうことらしい。なるほど。
-  Taming the chaos gently: a Predictive Alignment learning rule in recurrent neural networks
	- https://www.biorxiv.org/content/10.1101/2024.07.14.603423v1
	- How can a biologically plausible synaptic plasticity rule tame the chaos in recurrent neural networks?
- new GPT-4o mini release!
	- https://x.com/OpenAI/status/1813991706083340798
	- Introducing GPT-4o mini! It’s our most intelligent and affordable small model, available today in the API. GPT-4o mini is significantly smarter and cheaper than GPT-3.5 Turbo.
	- GPT-4o mini's early version "upcoming-gpt-mini" was tested in Arena in the past week. by lmsysorg
		- https://x.com/lmsysorg/status/1813999088758673875
- MistralがNVidiaと強力タッグを組んで12BパラのMistral-Nemoをオープンリリース by うみゆきさん
	- https://x.com/umiyuki_ai/status/1813961423653077246
	- コンテキストウインドウ128k！
	- 量子化認識でトレーニングされており、パフォーマンスを損なうことなく FP8 推論できる！
	- ベンチスコアはMMLU以外はGemma2-9Bを圧倒！Tekkenトークナイザで日本語のトークン効率爆上がり！
- GPT-4o miniは、GPT-4よりも賢く、GPT-4oより約30倍も安い、革命的なAIモデルです
	- https://x.com/ctgptlb/status/1813998168931192843
- 128k長文対応、12BモデルMistral NeMo Apache 2.0でリリース！　 by AIXサトシさん
	- https://x.com/AiXsatoshi/status/1814012421889216576
	- 語彙数128KのTekkenトークナイザーで、多言語、コード生成、マルチターン会話に強い Gemma 2 9BおよびLlama 3 8Bと比較して高い精度 FP8推論で性能低下しないよう学習している
	- 日本語1.56倍圧縮するトークナイザ
	- https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407
-  Codification, Technology Absorption, and the Globalization of the Industrial Revolution
	- https://x.com/nberpubs/status/1813589839951868033
	- Japan’s massive public investments in codifying technical knowledge explain why it was unique among non-Western countries in industrializing in the 19th and early 20th centuries,
	- 現在、世界には4種類の高所得国しかない。1) 英語圏、2) イギリスに近い国、3) 資源に恵まれた国、そして4) 日本とその旧植民地である。」 1〜3まではよく研究されているが、なぜ4なのか？
	- 産業革命がなぜ日本に最初に広がり、他の非西洋諸国には広がらなかったのかに関するデータドリブンの研究。
-  GPT-4o mini の概要 by npakaさん
	- https://note.com/npaka/n/nd985687d6cb1?sub_rt=share_h
	- 「GPT-4o mini」は、インテリジェンスをより手頃な価格にすることで、AIで構築されるアプリの範囲を大幅に拡大すると期待しているモデルです。
	- 2. 優れたテキストインテリジェンスとマルチモーダル推論を備えた小型モデル
	- 3. 組み込みの安全対策
	- ChatGPTでは、Free、Plus、Team ユーザーは、GPT-3.5 の代わりに、本日より「GPT-4o mini」にアクセスできるようになります。
-  Q-Sparse: All Large Language Models can be Fully Sparsely-Activated
	- https://arxiv.org/abs/2407.10969
	- Microsoft Research is excited to introduce Q-Sparse: a breakthrough in training fully sparsely-activated LLMs. Q-Sparse supports both full-precision and 1-bit LLMs. Its synergy with BitNet b1.58 advances LLM efficiency, including cost and energy use.
	- LLMをスパース化させて推論時に使うパラ数減らせて処理効率爆上がるらしい！Mistral7Bベースで試したら、活性化パラ数を2.8Bくらいまで切り詰めてもあんまベンチスコア下がらないらしい　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1813974577187537074
- 早稲田大学内のWi-Fi経由でchatGPTやDeepLが使えなくなりました。
	- https://x.com/aisa_rizapuro/status/1813900610946957600
	- テスト期間限定の制限かもしれませんが、今この時代に生成AIツールを禁止するのはいかがなものかと思います
	- 一方でchatGPTを推奨する先生もいらっしゃるので教授会の中でも意見が割れてそうです…
- 深層NNもTransformerも結局はカーネル法なのです．すべてはカーネル法のためにあるのです
	- https://x.com/btreetaiji/status/1814319983150932222
- Claudeにも考える時間をあげると良いんだ…
	- https://x.com/shiranui_it/status/1814580977576124535
	- <thinking></thinking>内で考えてください。。
- 


## 24/7/14

先週公開された、GraphRAG関連の、チュートリアル公表や評価がすすんでいます。RAGとQFS(Query-Focused Summarization)のギャップをうめる一手法であるというのはなんか納得。Gemma-2:9bでもGraphRAGが動くという報告も。Gemma2は、tokenizerに不具合があるらしいが、AUTOMATIC1111さんが動いているなら、治るのは時間の問題。さてRAGの対抗馬？としてすぐに話題になるのは、ロングコンテキスト、マイクロソフトからは１Mトークン処理を１０倍とうたうMInference 1.0が登場、Dynamic Sparse Attentionって技術を使うのね、デモサイトで無双ぶりを試してみるのもよいかも。Interface 8月号特集は「生成AI」、LoRaを手を動かして理解が進むかも。NVIDIAからは、RankRAGが登場、context rankingという仕掛けをLLMに埋め込んだということらしい。NVIDIA的にはローカルな知識を高精度で使えるから、オンプレでGPUどんどん買ってねということか。UnslothからはGemma-2:9bでファインチューニングの速度が２倍になったと、、colabでも試せるのか？。Transformerの次のアーキテクチャの１つだとされる、Mamba-based Language Modelsの定量的な評価が出てきた、相当期待がもてそう。先週の自然な会話ができるオープンソースのMoshiもすごかったのだけど、TerifAI (terrify) ってのも、自分声をまねることができるなんて、もうオレオレ詐欺LLMの登場は時間の問題、最初に「オレオレだけど、、」と発する規制が必要。Artifactsで快進撃のClaude、今度は作ったArtifctsのライブプレビューにURL公開機能が搭載って、これはすごすぎでしょう、どういうエコシステムができるんだろうか？。Anthoropicがプロンプトの自動生成や評価機能を備えて、１世紀分のプログラミングの歴史をおそらく1年でトレースするという話も納得な動き。アルトマン氏とハフィントン氏によるThrive AI Health、行動を変えることにより健康になるというのは、なんか耳が痛いが、期待できそう。Ollama 0.2、gemma-2対応のバグとかも治ったみたいだど、複数のモデルを並列に動作可能とのこと、これって、モデルとLlamaGuardのようなLLMによるセーフガード実装を同時に動かすことができるということ。理論面では、強化学習の概念を取り入れたQ*アルゴリズム、またまた話題になる。LLMの多段推論をマルコフ決定過程でモデル化し、A-starサーチで探索するってどれだけ計算コストがかかるのか。岡野原さんの、非平衡熱力学と拡散モデルの接点の論文の紹介、大学生（３年生）との共著というのが、驚きだ。MoEはエキスパートを小さく数を増やすほど性能が改善されるのか、それにしても100万のエキスパートってどうやって作るの？。Llamaindexからは、llama-agentsを発表、そういえば、Claudeが５月に発表したサービス「Tool Use」って自律的に動くエージェントに備えたという話も今週あった。DeepMindのハサビス氏、「現時点での汎用AIは猫程度のIQしかない」と、歩調をあわせるようにOpenAIからは、「AIが人間の知能にどれだけ近づいたか」を評価する５段階のレベルの基準を公開、現在のAIはレベル1でもうすぐ「Reasoners」と呼ぶ第2レベルに到達できそうとのこと。猫でも十分な気もするが。。地味ですが新刊「Pythonで学ぶ実験計画法入門」、みなさんタイトルは控えめですが、ガウス過程回帰や、ベイズ最適化の本ですよ。

- GraphRAG: How to Develop AI That Thinks Like a Librarian
	- https://x.com/IntuitMachine/status/1809903707535868260
	-  Graph RAG is an innovative approach that bridges the gap between retrieval-augmented generation (RAG) and query-focused summarization (QFS) methods, addressing the limitations of existing techniques in handling global questions about extensive document collections.
- Gemma2のtokenizerにまだ不具合があるとissuesが新しく登録されていたので見てみたらまさかのAUTOMATIC1111
	- https://x.com/webbigdata/status/1810143355013390779
	- 画像生成AIで有名なツールstable-diffusion-webuiの作者の人です。ツール名称が一般的すぎるので、AUTOとかAUTOMATICとか作者名で呼んでる人が多いツールです
- BM25S: Orders of magnitude faster lexical search via eager sparse scoring
	- https://x.com/_reachsumit/status/1810157881536430178
	- Introduces a fast Python implementation of BM25 that pre-computes scores during indexing using sparse matrices to achieve significant speed improvements
- MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention
	- https://x.com/schroneko/status/1810212258003480757
	- https://hqjiang.com/minference.html
	- Microsoft の Long-Context LLM の推論高速化手法
	- Dynamic Sparse Attention を用いて精度維持＆高速化 
	- A100 一台 x 1M tokens の処理で 10 倍 
	- 既存の LLM にそのまま適用できて追加の学習は不要 
	- マルチモーダルや encoder-decoder にも使えるっぽい
- 【Interface 8月号特集「生成AI」ちょっと記事紹介】
	- https://x.com/If_CQ/status/1810282808587538468
	- 第4部2章は「ローカルLLMを自分用にファイン・チューニング」です．「LoRA」が小コストで学習できる仕組みを解説し，実際に試します
- Google Cloud TPUs made available to Hugging Face users
	- https://huggingface.co/blog/tpu-inference-endpoints-spaces
	- > Google Cloud TPUs available on Spaces and Inference Endpoints > 3 options: 16GB to 128GB TPU memory (1x1, 2x2, 2x4 v5e TPU) > Use Spaces for ML demos or dev mode for easy training
-  RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs
	- https://arxiv.org/abs/2407.02485
	- Llama3-RankRAG from nvidia significantly outperforms GPT-4 models on 9 knowledge-intensive benchmarks
	- The secret is a novel instruction fine-tuning framework, named RankRAG
	- Llama3-RankRAG-8B and Llama3-RankRAG-70B outperforms Llama3-ChatQA-1.5-8B and Llama3-ChatQA-1.5-70B by a margin, respectively.
	- The problem with traditional RAG was that LLM typically utilize the top-k contexts from a retriever.
	- RankRAG instruction-tunes a single LLM for dual purposes: context ranking and answer generation in RAG. This unified approach allows the model to excel at both tasks simultaneously. The process incorporates a small fraction of ranking data (about 50k examples) alongside other task-specific datasets. Yields superior ranking performance compared to models trained on much larger ranking datasets.
-  Learning to (Learn at Test Time): RNNs with Expressive Hidden States
	- https://arxiv.org/abs/2407.04620
	- https://x.com/xiaolonw/status/1810387662060269668
	- we have been developing a new LLM architecture, with linear complexity and expressive hidden states, for long-context modeling. The following plots show our model trained from Books scale better (from 125M to 1.3B) than Mamba and Transformer, and our 1.3B model works better and better with longer context.
-  Intent-based Prompt Calibration: Enhancing Prompt Optimization
	- https://x.com/IntuitMachine/status/1810258617473356140
	- IPC works by iteratively refining prompts through the generation of synthetic, challenging boundary cases. This process eliminates the need for large pre-existing benchmarks, 
- MInference by Microsoft is released
	- https://github.com/microsoft/MInference
	- Milliontokens Inference achieves a 10x speedup for pre-filling and maintains accuracy with 1M tokens
	- https://huggingface.co/spaces/microsoft/MInference
- 先月からこれはQ*かと考えられるような探索手法+LLMの論文がリリースされている。
	- https://x.com/bioshok3/status/1810302795402408116
	- 例えば以下はモンテカルロ法でGPT-4レベル付近に数学関連のデータセットでllama3 8bで到達
	- Q*という論文も出ている
		- https://arxiv.org/abs/2406.14283
		- これはLLMの多段推論をマルコフ決定過程でモデル化し、A-starサーチで探索するというシンプルなアルゴリズム。具体的には、マルコフ決定過程の行動価値関数（Q学習で用いられる関数）の最大値を、A-starサーチのヒューリスティクス関数として採用するというもの。
-  Issue 17: Moshi Challenges OpenAI, Compare LLM pricing and better understand long context LLMs  -  July 7, 2024
	- https://www.philschmid.de/cloud-attention/issue-17
- 6-part video series on Property Graphs in LlamaIndex using mistralai, neo4j and ollama
	- https://x.com/llama_index/status/1810410943215710510
	- https://www.youtube.com/playlist?list=PLTZkGHtR085ZYstpcTFWqP27D-SPZe6EZ
		- What’s a property graph and why is it useful?
		- How to build a property graph in LlamaIndex
		- Building graph data extractors and retrievers
		- Using Neo4j with LlamaIndex
		- Using Ollama with pre-defined schemas
		- Building custom retrievers
-  An Empirical Study of Mamba-based Language Models
	- https://x.com/rohanpaul_ai/status/1810340344158167066
	- 8B-parameter Mamba-2-Hybrid exceeds the 8B-parameter Transformer on all 12 standard tasks we evaluated
- 日本気象協会が予測誤差を最大40％改善、経済効果1800億円の商品需要予測に適用
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09502/?n_cid=nbpnxt_twbn
	- 生成AIで天気図を画像として〜みたいな話ではなく、説明変数に入れる海域を拡大→LASSO回帰で多重共線性を押さえて精度向上してるの、L1正則化推しとしてはグッと来る。
- Introducing TerifAI (terrify) - the ai that steals your voice
	- https://x.com/amanmibra/status/1810498609613553741
	- It's an educational experience that shows why AI has become a catalyst to voice phishing
- PaintsUndo: A Base Model of Drawing Behaviors in Digital Paintings
	- https://lllyasviel.github.io/pages/paints_undo/
	- 静止画像を入力して、そのイメージの描画シーケンスを出力するモデルｗ lllyasvielさんまた面白いの考えるね！
	- https://x.com/forasteran/status/1810595599173226582
- Alpaca + Gemma2 9b Unsloth 2x faster finetuning.ipynb
	- https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing
	- Fixed some bugs for DPO, saving to GGUF, Ollama auto modelfile creation, enabled RoPE scaling for Gemma-2, so >8192 context lengths now work & more!
-  Speed-accuracy trade-off for the diffusion models: Wisdom from nonequilibrium thermodynamics and optimal transport
	- https://arxiv.org/abs/2407.04495
	- 池田さん、宇田さん、伊藤先生との共著です。非平衡熱力学と拡散モデルの接点をまとめると共に、その知見に基づき、生成品質と拡散過程におけるエントロピー生成率や最適輸送との関係、既存手法の妥当性を示しました。伊藤先生のスレッドに経緯やまとめがあります。様々な発展が考えられると思います
- TTT could model long sequences with linear time complexity. It's a drop-in upgrade for any sequence modeling operators like self-attention.
	- https://x.com/Jerry_XU_Jiarui/status/1810401509366181968
	- It has been super fun to work on TTT with the amazing team!
	- https://github.com/test-time-training/ttt-lm-jax
- (*AMERICAN*) Football Analytics with Python and R — Learning DataScience Through the Lens of Sports: 
	- https://www.amazon.com/gp/product/1492099627?&linkCode=sl1&tag=kirkdborne-20&linkId=114a75558fca86195c93513bf81a439d&language=en_US&ref_=as_li_ss_tl
- Sam Altman and Arianna Huffington launch AI health company
	- https://x.com/HealthcareAIGuy/status/1810480678473232769
	- The company is building an AI health coach to drive personalized behavior change to improve health outcomes.
- Ollama 0.2 can now
	- https://x.com/jmorgan/status/1810486878799560765
	- * Run different models side-by-side 
	- * Process multiple requests in parallel
-  RAGの次「AIエージェント」の威力、アンソロピック社員が国内AWSユーザーに力説
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09497/
	- Vo氏がプレゼンで強調したのが、2024年5月31日にアンソロピックが発表したサービス「Tool Use」の活用方法だ。Tool Useは、AIが人の代わりとなって自律的にタスクを実行する「AIエージェント」を実装するためのサービスである。
-  Language-Guided World Models: A Model-Based Approach to AI Control
	- https://arxiv.org/abs/2402.01695
	- Our paper is perhaps the first to demonstrate compositional generalization with concepts that involve interactions among multiple entities.
- GPT-4o Capabilities
	- https://x.com/InterestingSTEM/status/1810387007312429094
- これな．日本は検索技術について，著作権法とは関係なく，正々堂々と完全に技術力でGoogleに負けたの
	- https://x.com/yutakashino/status/1810190400487121282
	- ＞国内では当初、検索エンジンがデータをクローリングし、一時的にキャッシュとして保存する行為が「著作権法違反ではないかとの議論があった」と松尾教授は振り返る。 
	- ↑ 松尾先生嘘はよくない 文化庁資料読むとそんな議論起こってない
- Today Sam Altman and I published a piece in TIME sharing our vision for how AI-driven personalized behavior change can transform healthcare and announcing the launch of Thrive AI Health
	- https://x.com/ariannahuff/status/1810273407944040897
	- https://time.com/6994739/ai-behavior-change-health-care/
	- With AI-driven personalized behavior change, we have the chance to finally reverse the trend lines on chronic diseases like diabetes and cardiovascular diseases, which are directly related to daily behaviors but not distributed equally across demographics.
- 新サービス「Dataplex Catalog」が公開
	- https://x.com/y_sugi_it/status/1810446290330976501
	- Google Cloud上の各種データに対するメタデータ管理。従来の「Data Catalog」よりDataplexとの統合が強化。Aspectという設定値によりメタデータを付与・管理。順次ロールアウトのため徐々に使えるようになる
-  Mixture of A Million Experts
	- https://arxiv.org/abs/2407.04153
	- MoEはエキスパートを小さく数を増やすほど性能が改善される。PEERは各エキスパートが隠れ層に1ニューロンしか持たないほど小さくし、エキスパート数を100万まで増やす。キーを部分キーの積の形で表しTopKを効率的に探索できるようにし、従来MoEよりさらに性能を改善 by 岡野原さん
-  MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases
	- https://arxiv.org/abs/2402.14905
	- MobileLLMは125/350Mのモデル。携帯向けでは性能、バッテリー消費量の観点からモデルを小さくするのが重要。1B以下が有効 1) 幅より深さが重要。従来の12層より30~42層まで増やす 2) 埋め込み層は共有 3) パラメータ共有した層を2回ずつ繰り返す。メモリ転送量も抑えられる。by 岡野原さん
- Claudeのライブプレビュー機能「Artifacts」にURL公開機能が搭載
	- https://x.com/masahirochaen/status/1810722296501596237
- 生成AIによるMOFの逆設計の論文。by 横山さん
	- https://chemrxiv.org/engage/chemrxiv/article-details/668775805101a2ffa871a56c
	- 3Dモデリング技術を応用し符号付き距離関数を入力表現としたマルチモーダル拡散モデルを開発、物性やテキストから条件を満たすMOF構造を正確に生成できたそうです。
-  GraphRAGシステムの使い方：初心者向け完全ガイド
	- https://hamaruki.com/graphrag-beginners-guide/
- 有識者取材の申し込みが、目撃者取材と同じ手法になってきたとか、世も末。
	- https://x.com/HiromitsuTakagi/status/1810550259866910838
	- テレ朝、ひろみちゅ先生に取材DM送る。。。
- Claudeはプロンプトをプログラミング言語と位置付け、猛烈な速度で１世紀分のプログラミングの歴史をおそらく1年でトレースしようと考えている。
	- https://x.com/ai_syacho/status/1810835403940995383
-  Evaluate prompts in the developer console
	- https://www.anthropic.com/news/evaluate-prompts
- 時系列データのための大規模言語モデル
	- https://zenn.dev/tsurubee/articles/00446669b6c83a
	- まず、時系列データをテキストデータとして取り扱うPropmtingは、ファインチューニングを行うことなく事前学習したLLMの能力を活用できる。
	- 単純な季節的な周期やトレンドを持つような時系列データではPropmtingによるアプローチは有効であるが、より複雑な時系列性を持つデータでは十分な性能が期待できないかもしれない
	- そのため、十分な学習データを用意できる場合は、QuantizationまたはAligningベースの方法がより有効になるだろう
	- Aligningは、時系列データと言語空間のモダリティ間を整合させるアプローチであるので、時系列データと言語がペアとなるようなデータを使ったタスクの有力な選択肢になると思われる。例えば、心電図シグナルとテキスト形式のレポートの二つのデータから対象者の診断カテゴリを分類するタスクを解いたETPや、対話中の脳波と自然言語の二つのデータから感情予測や関係検出のタスクを解いたMTAMがその例である。
- 天気予報でLassoが使われたんですか？ 本当ならややびっくり
	- https://x.com/Idesan/status/1810903568100077906
- 多重共線性のある線形モデルに対しては、Lassoをやると汎化性能は上がっても必ずしも「本来削られるべき変数」が削られるわけではないとされていて、
	- https://x.com/TJO_datasci/status/1810852746406604931
- Artifacts made with Claude can now be published and shared.
	- https://x.com/AnthropicAI/status/1810698780263563325
- Open source AI model for semiconductor design.
	- https://x.com/pentagoniac/status/1810768232401473680
	- Industry’s first-ever open-source Semiconductor domain-specific model “SemiKong”, being announced at　SEMICONWest by me (!)
- gemini 1.5 pro の jsonモード、めちゃ便利。jsonであることだけでなく、任意のスキーマを指定できる。
	- https://developers.googleblog.com/en/gemini-15-pro-now-available-in-180-countries-with-native-audio-understanding-system-instructions-json-mode-and-more/
- 批判家ゲイリーマーカス氏は、2016年にWSCで限界説を主張したが後に研究者たちによって突破され、2018年に深層学習の限界説を主張してAIの冬時代を予想したが外れて、2022年には深層学習は壁にぶつかっていると言ってから今回の生成AIブームがきてGPT-4が登場。その後も発展が継続中
	- https://x.com/jaguring1/status/1810993416991559893
- a16zがGPU(H100)2万個買い占めて安く投資先に使わせてるとか。VCの域を超えたパワープレイや
	- https://x.com/kubotamas/status/1810985069131223355
- BedrockにマネージドDify来たやんこれ
	- https://x.com/minorun365/status/1811041517479547097
- NotionはNotionをどう使っているか
	- https://notion.notion.site/Notion-Notion-15c4497a18e54de7a7ca696bc8fe688a#65c847c6692f45898edc17912667d4db
- Last week we launched llama-agents, a brand new multi-agent deployment framework,
	- https://x.com/llama_index/status/1811147950388916420
	- @MervinPraison has a great walkthrough of how to use lllama-agents on YouTube, 
	- https://www.youtube.com/watch?v=nEQCpSd5mx8
- Microsoft のGraphRAGがgemma2:9bで動きそうな感じ！！
	- https://x.com/hAru_mAki_ch/status/1811039029305233825
- あまり話題になっていないが、Claudeにプロンプトの評価機能が実装されたのが個人的に超助かる。
	- https://x.com/masahirochaen/status/1811311003084394517
	- テスト用のプロンプトも自動で生成可能で、生成結果の評価点の入力も可能。
-  最適輸送入門
	- https://speakerdeck.com/joisino/zui-shi-shu-song-ru-men
	- 適輸送とKLダイバージェンスの違いの説明が分かりやすかったです！
- DifySandbox がオープンソースになりました！
	- https://x.com/DifyJapan/status/1811260209438101754
	- DifySandbox は、Dify におけるエージェント型ワークフローの中核の一つです。ユーザーが書いたコードの実行環境として機能し、悪意のあるコードをブロックして、システムのセキュリティを確保します
- Magpieの手法を用いて様々なモデルから作成した日本語29647件、英語39560件、合計約69207件のコードSFT用データセットを公開しました
	- https://x.com/Aratako_LM/status/1811418924472492470
	- https://huggingface.co/datasets/Aratako/Synthetic-JP-EN-Coding-Dataset-Magpie-69k
- We made a step-by-step tutorial on how to finetune Llama-3 with Google Colab & deploy it to Ollama
	- https://x.com/UnslothAI/status/1811447913962438994
	- https://docs.unsloth.ai/tutorials/how-to-finetune-llama-3-and-export-to-ollama
	- https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing
- 統計的リテラシーの動向と課題―概念と学習指導に着目して―
	- https://www.jstage.jst.go.jp/article/jssej/48/2/48_133/_article/-char/ja/
	- これまでの実践研究を概観すると，学習指導の方法の特徴として以下 5 点が挙げられる
	- 1 点目は，「実際にメディアから発信された統計情報を題材の中心としていること」
	- 2 点目は，「統計情報の内容に対して問いを持つように，問いの例を示すこと」
	- 3 点目は，「統計情報の内容を学習者同士で議論する活動を取り入れること」
	- 4 点目は，「知識の習得や活用を意図した個人の活動が展開されていること」
	- 5 点目は，「統計情報を適切に解釈するための読み方の習得を意図した個人の活動が展開されていること」
- Temporal distances (expected number of time steps between states) in stochastic MDPs in general lack metric structure.
	- https://x.com/svlevine/status/1811253559603888439
	- we propose this metric. Intuitively, the difference between state s and goal g is given by log of probability ratio between reaching g from g (self-loop) and reaching g from s.
	- https://arxiv.org/abs/2406.17098v1
- 「現時点での汎用AIは猫程度のIQしかない」とGoogle DeepMindのデミス・ハサビスCEOが主張
	- https://x.com/gigazine/status/1811143437975970124
	- 自身の研究はAIではなくAGI(汎用人工知能)に焦点を当てていることを強調。その上で、ハサビスCEOは「現代のAIは人間と見間違うほどの文章を書いたり、絵を描いたり、音楽を作曲したりすることができますが、AGIとしては普通の飼い猫の方がはるかに高い知能をもっています」と述べました。
- OpenAIは火曜全体会議でAI進捗をレベル分け。レベル1が現在でもうすぐ「Reasoners」と呼ぶ第2レベルにもうすぐ到達するところだと語ったと広報担当者は述べている。
	- https://x.com/StockMKTNewz/status/1811488448001294720
	- Reasonersとは、ツールにアクセスできない博士レベルの教育を受けた人間と同様に基本的な問題解決タスクを実行できるシステム
- パープレの公式日本アカウントです！日本の皆さんと繋がることを楽しみにしています。
	- https://x.com/perplexity_jp/status/1811555477588738436
- OpenAIが「大規模言語モデルが人間の知能にどれだけ近づいたか」を評価する基準を作成
	- https://gigazine.net/news/20240712-openai-super-intelligent-ai-scale/?utm_source=x&utm_medium=sns&utm_campaign=x_post&utm_content=20240712-openai-super-intelligent-ai-scale
	- OpenAIは記事作成時点での大規模言語モデルはレベル1であり、レベル2に近づいているとしています。OpenAIによれば、
	- レベル2は博士レベルの教育を受けた人間と同等の基本的な問題解決能力を持つシステムと評価されるそうです。また、
	- レベル3は「ユーザーに代わって行動できる」、
	- レベル4は「新しいイノベーションを生み出せる」、
	- 最高段階のレベル5は「組織全体の仕事を行うことができる」レベルに設定されているそうです。
- Mixture of Agents on Groq
	- https://x.com/KapadiaSoami/status/1811657156082712605
	- Introducing a fully configurable, Mixture-of-Agents framework powered by GroqInc using LangChainAI
- Pythonで学ぶ実験計画法入門
	- https://x.com/mimikousi/status/1812071977441513954
	- 書籍名からは想像できないが、「ガウス過程回帰」の解説もサンプルコードも掲載されている。 参考にしながらコードを書いてみたら、かなり簡単に実装できた。 取り急ぎ、GtiHubにアップしたけど、時間ができたらブログで解説記事を書きたいな。
	- https://github.com/mimikousi/regression_model/blob/main/gpr_regression.ipynb
- 【最尤推定による回帰直線 vs ベイズ推論による回帰直線】
	- https://x.com/DS_school_1/status/1812280249763455444
	- 最尤推定法は最も確からしい１つの回帰直線を算出でき、ベイズ推論は信頼できる幅を持った回帰直線を算出できる特徴があるね👍面白い！！
- `statsmodels`と`sklearn`でのロジスティック回帰の挙動の違いについて
	- https://zenn.dev/0_u0/articles/6a43ff43b02399
	- `sklearn.linear_model.LogisticRegression`はデフォルトで正則化(L2=1)がついている
	- `statsmodels.api.Logit`は正則化がついていない
	- `sklearn`は機械学習の領域で広く使われるライブラリの1つであるから、統計モデリングをこれを使って実施する場面も多いだろうが、正則化項については気をつけた方が良い。
- Statistics for Mathematicians by Victor M. Panaretos
	- https://x.com/probnstat/status/1811833201612014073
	- Presents a rigorous yet elementary introduction to the main concepts and methods of statistical inference
	- Targets students of mathematics taking their first course in statistics
 

	- 


## 24/7/8

先週きら星のように登場したgemma-2の評価、DeepMind自身によるgemma-2論文では、2倍以上大きなサイズのLlama 3に匹敵する性能とGPT-4oに相当する安全性といっているが、 スライディングウィンドウのアテンション、知識蒸留、ソフトキャッピングによるトレーニングの安定性、WARPと呼ばれる新しいマージング技術などがてんこ盛りの模様、9Bと27Bでは作り方も変えてきた。gemma-2-27b-itのElyzaベンチの結果もいいし、gemma-2-27b-itの日本語imatrix量子化ggufも上がってる。SPPOってのは、LLMの最適化を二人対戦型の定数和ゲームとして定式化し、その均衡点を近似的に求める自己対戦型の選好最適化手法を利用することで人間の選好を正確に反映する学習と最適化手法だそうで、つまりalignmentとも相性が良いそうなんですが、Gemma-2にSPPOを適用したGemma2-9B-it-SPPO-Iter3なんかがベンチマークで高得点をマークしたとの報告もあり、性能にも効くみたいだ。gemma-2、新世代のLLMのお手本みたいな構成で、次のGeminiへのイントロとしては満点。まあ、といっても、うみゆきさんの報告のように、Sonnet3.5をShaberi3ベンチで評価したら8.39というように、依然横綱はSonnet3.5か。今週もClaudeのArtifacts機能でマインクラフト作った例が報告され、わくわくが止まらない。Artifactsのプロンプトも見つかり、function callingのお手本のようだという。プロンプトを自動生成するClaude の "Generate a prompt" に代表されるように、LLMをdogfoodとして自ら使いこなし、イノベーションを加速させているのは、AnthropicとOpenAIで、その他Googleなどが進めるLLMの進化は、着実なんだけど、想像可能な範囲かなあ。Llama3-Swallow-8Bとか、CALM3-22B-Chatとか、日本のLLMも健闘してますが、ちょっと厳しい。Runwayからテキストから動画、画像から動画、テキストから画像を生成するGen-3が話題になった、人の顔って動くと不自然さがわかるはずなのに、Gen-3の生成する動画では、もはや識別不能、不気味の壁を越えたか。メタも人知れず「Meta 3D Gen」を発表、評価を待とう。非営利団体Kyutaiが突然発表したリアルタイムマルチーモーダル基盤モデル「Moshi」、自然な対話がgpt-4oとそん色ないんだけど、オープンソース化されると、詐欺LLMが誰でも作れちゃう、ちょっと不安だ。RAG関連では、先週話題となったMicrosoftのGraphRAG論文、発表したばかりなのに実装がgithubに公開、こっちもプロンプトの見本のような内容、ollama/gemma-2でも動く模様。RAG survey論文、"Naive RAG", "Advanced RAG", "Modular RAG"という歴史的な視点から、細かい技術まで徹底的に網羅、いやこんな手法があるのかと大変参考になる。TJOさんも絶賛、というか後出しじゃんけんぽくてみっともないな。基盤技術も、BM42とか、RetrievaBERTとか、FastEmbed、とか文書検索やエンベディングなどの基礎となる技術も着実に進化がある、今後の発展に期待。一方、今週はLLMの進歩に対する冷静な記事も目立った。LLMの基本的な性質に対して物申すKey Claims 論文、LLMがあんなことできた、こんなことできたというのは、所詮、汎化性のないSOTAの集まりみたいな感じか、確かにLLMの特徴ってそれが発現する条件を備考に乗せると長くなる気がする、でもClaudeなんかを見てると、LLMによるイノベーションの実現って作者が知らないところで起きているのかもしれない。汎化性はGrokked Transformersに期待。経済的な視点では、「エコノミスト」誌のAI革命は今のところ経済的インパクトがほとんど確認できないとい記事も、確かに、誰が開発やGPUを動かすお金を払ってるんだろうと冷静な分析。GPTZeroの報告にあったように、Perplexityのユーザーは平均で、3回プロンプト試行をすれば、生成されたソースに遭遇するというのだから、データの枯渇もそろそろLLMの発展に影響し始めるのか。明るいような暗いようなそういう話題の混ざった週でした。


-  Self-Play Preference Optimization for Language Model Alignment
	- https://huggingface.co/papers/2405.00675
	- SPPO論文
- Gemma-2のSelf-Play Preference Optimization (SPPO) を適用版
	- https://huggingface.co/UCLA-AGI/Gemma-2-9B-It-SPPO-Iter3
	- AlpacaEval 2.0 で 53.27%と驚異的 たった9BでGPT-4と肩を並べるレベルは新時代か by AIXサトシ
- NICT内にGPAI（AIに関するグローバル・パートナーシップ ）東京専門家支援センター。
	- https://x.com/ikegai/status/1807668045302857856
	- 日本政府は、GPAI議長国として、生成AIの政策立案のためのエビデンスを蓄積するプロジェクト等の活動を推進し、GPAIへのさらなる貢献を果たすため、
	- https://www.soumu.go.jp/menu_news/s-news/01tsushin06_02000292.html
- Llama3から継続事前学習をしたLlama-3-Swallowモデルのリリース
	- https://huggingface.co/tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1
-  Imperative Learning: A Self-supervised Neural-Symbolic Learning Framework for Robot Autonomy
	- https://arxiv.org/abs/2406.16087
	- What is Neural-Symbolic AI? How do we use it for Robot Autonomy? How to overcome the generalization challenge of RL and Imitation Learning? In this article (https://arxiv.org/abs/2406.16087), we introduce Imperative Learning, a Self-supervised Neural-Symbolic  Framework as our answer.
- NICTとKDDI、大規模言語モデルに関する共同研究を開始
	- https://newsroom.kddi.com/news/detail/kddi_nr-154_3422.html
- gemma-2-27b-itの日本語imatrix量子化gguf
	- https://huggingface.co/grapevine-AI/gemma-2-27b-it-gguf
	- Googleさんのgemma-2-27b-itの日本語imatrix量子化ggufが完成しました！ 軽量なのにとんでもなく賢い、現状最強のローカルLLMだと思います
	- https://x.com/2022_technology/status/1807301685276217458
- gemma-2-27b-itのElyza tasks 100のスコア
	- https://x.com/2022_technology/status/1807302310114267186
	- どのモデルよりも高い3.88点です！驚異のジャイアントキリング！
-  ClaudeのArtifacts機能でマインクラフトを作ろう！
	- https://note.com/yoshi8__/n/n0d2816815fba?sub_rt=share_pb
	- 今回は、Three.jsという３Dモデルが作れるJavaScriptライブラリを使って、簡単なマインクラフト風の3Dゲームを作成する方法をトライしました。
	- ゲーム開発経験がない僕でも、Claudeを使って簡単なWebゲームを作ることができました！「追加して欲しい機能をうまく伝えること」が鍵かなって思っています。
- 『AI時代の質問力 プロンプトリテラシー 「問い」と「指示」が生成AIの可能性を最大限に引き出す』
	- https://www.shoeisha.co.jp/book/detail/9784798183459
	- 本書は、大規模言語モデルの仕組みと「プロンプトエンジニアリング」の基本を理解するところから、AIに適切な質問をし、AIとより効果的な対話をするための「プロンプトパターン」「トリガープロンプト」、さらに進んだ発展的な技術、また最先端の「AIエージェント」にいたるまで、AIとのやりとりを最適化するための知識とノウハウが学べます
-  Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning
	- https://arxiv.org/abs/2406.19502
	- Excited to share our latest paper on the reasoning capabilities of LLMs! Our research dives into how these models recall and utilize factual knowledge during solving complex questions
	- Take this question as an example: "Why does ReLU training take less time than sigmoid or tanh training?". One must not only *recall* what an activation function is, but also *compare*
	- we propose breaking down complex questions into a graph structure, with each node representing a specific depth of understanding: recall (D1), application (D2), and strategic thinking (D3). Our approach emphasizes accumulating and integrating knowledge to
-  Scaling Synthetic Data Creation with 1,000,000,000 Persona
	- https://arxiv.org/abs/2406.20094
	- It's easy to generate synthetic data but hard to scale up its diversity which is essential for its application.
	- This paper proposes a novel persona-driven data synthesis methodology to generate diverse and distinct data covering a wide range of perspectives.
- Llama3-Swallow-8B-Instruct-v0.1のShaberi3ベンチスコアは6.78。by うみゆきさん
	- https://x.com/umiyuki_ai/status/1807840130016989601
	- モデル公開してくれるのはありがたいんだけどちょっと擁護が難しいパフォーマンス。ベースになったLlama8-8B（6.91）にも負けてんだけど、
- たったいま一般公開された『Gen-3』 実際に作ってみたけどヤバすぎるわ
	- https://x.com/ryo_kun0811/status/1807829970577920352
-  Semiautomated experiment with a robotic system and data generation by foundation models for synthesis of polyamic acid particle
	- https://www.nature.com/articles/s41428-024-00930-9
	- ポリマー微粒子のロボット合成実験 + マルチモーダルGPT-4で実験観察、解析、自省などがどれくらいできるかを調べてみた論文がpublishされました(polymer journal)。
- 「ゴミを食べ、ゴミを吐く」、ベゾスも出資するAI検索エンジンの品質問題
	- https://forbesjapan.com/articles/detail/72055?read_more=1
	- GPTZeroの研究で、パープレキシティのユーザーは平均3回のプロンプト（命令文）の入力でAIが生成した情報源に遭遇することが判明した。「彼らのサービスの質は、その引用元の質に依存している。情報源がAIのハルシネーションによって生み出されたものであるなら、その出力も同様だ」
	-  ニュース記事の「盗用」
- Position: Key Claims in LLM Research Have a Long Tail of Footnotes
	- https://arxiv.org/abs/2308.07120
	- LLMに関する”一般的な主張”を批判的に検討してまとめています。LLMの定義、特性、影響力について分析を行い、多くの主張がもしかすると十分な根拠を欠いている可能性があることを指摘しています。
	- 例えば以下は鵜呑みにできないとのこと。
		- 新しい問題にも柔軟に取り組める 
		- 自然言語処理でベストなツール 
		- 性能向上は単にスケーリングによるもの 
		- 歴史的な汎用技術
		- 創発的な特性がある
- Gemma 2: Improving Open Language Models at a Practical Size
	- https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf
	- 軽量なオープンソースLLMのGemma 2の性能は、
	- 2倍以上大きなサイズのLlama 3に匹敵することが示されています。 
	- 安全性評価ではGPT-4oと同等以上の結果も。 
	- また、使い心地の評価（Chatbot Arena）では既に多くのモデルを上回っています。
-  Googleが公開した新しいオープンLLM、Gemma 2へようこそ！
	- https://hamaruki.com/welcome-to-gemma-2-googles-new-open-llm-2/
	- スライディングウィンドウアテンション：高品質な生成のために、スライディングウィンドウと完全な二次アテンションを交互に配置します。
	- 対数 ソフトキャッピング：ロジットを一定の範囲にスケーリングすることで、ロジットが過度に大きくなるのを防ぎ、学習を改善します。
	- 蒸留：より大きな教師モデルを活用して、より小さなモデル（9Bモデルの場合）を学習します。
	- モデルマージ：2つ以上のLLMを組み合わせて、単一の新しいモデルを作成します。
- Microsoft 生成AI活用事例と評価方法について
	- https://speakerdeck.com/daikikanemitsu/microsoft-sheng-cheng-aihuo-yong-shi-li-toping-jia-fang-fa-nituite
	- Microsoftが公開している「生成AI活用事例」が有益。
	- 一人当たり"月17時間の業務時間削減" を達成した内訳を定性的・定量的に効果測定している。
-  Impact of Data Bias on Machine Learning for Crystal Compound Synthesizability Predictions
	- https://arxiv.org/abs/2406.17956
	- データ偏りの影響を調査した論文。
	- 学習データ偏りから意図しない相関を学習することがありますが、実構造と仮想構造を混ぜた偏りの強いデータとDFT緩和構造の偏りの弱いデータを使いこの影響を比較、前者は信頼性が低かったとのこと。
	- 異種データを混ぜる際にはご注意を。by 横山さん
-  Meta、LLMコンパイラを公開——AIがプログラミングの常識を変えるかも
	- https://thebridge.jp/2024/07/metas-llm-compiler-is-the-latest-ai-breakthrough-to-change-the-way-we-code
	- https://huggingface.co/collections/facebook/llm-compiler-667c5b05557fe99a9edd25cb
	- LLVM-IR とアセンブリコードの5,460億トークンからなる膨大なコーパスでモデルをトレーニングすることで、コンパイラの中間表現、アセンブリ言語、最適化テクニックを理解できるようになった。
	- LLM コンパイラは、コードサイズの最適化において目覚ましい成果を上げた。このモデルはテストにおいて、オートチューニング探索の最適化ポテンシャルの77%に達した
- Sonnet3.5をShaberi3ベンチで評価したら、8.39！！　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1808203661623058684
	- やはり世界最強、王者の性能を叩き出してGPT-4TやOpusに勝利しました。お前がナンバーワンだ
- GraphRAG from Microsoft is just open sourced
	- https://github.com/microsoft/graphrag
- GraphRAG from MS
	- https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/
	- GraphRAG, a graph-based approach to retrieval-augmented generation (RAG) that significantly improves question-answering over private or previously unseen datasets, is now available on GitHub. Learn more
	-  Advantages of community summaries for “global questions”
	- The results show that GraphRAG, when using community summaries at any level of the community hierarchy, outperforms naive RAG on comprehensiveness and diversity (~70–80% win rate). 
	- GraphRAG using intermediate- and low-level community summaries also performed better than source text summarization on these metrics at lower token costs (~20–70% token use per query). 
	- Performance was competitive with hierarchical source text summarization for the highest-level communities at substantially lower token costs (~2–3% token use per query).
-  GraphRAG Ollama: 100% Local Setup, Keeping your Data Private
	- https://www.youtube.com/watch?v=BLyGDTNdad0
-  Retrieval-Augmented Generation for Large Language Models: A Survey
	- https://arxiv.org/abs/2312.10997
	- [RAGのSurvey論文からRAG関連技術を俯瞰する](https://sue124.hatenablog.com/entry/2024/07/02/233616)
	- 「教師なしFine-tuningが（Fine-tuning前のモデルと比較して）若干の改善を示す一方で、RAGは、事前学習中に遭遇した既存の知識と全く新しい知識の両方に対して、一貫してFine-tuningのモデルの性能を上回ることを明らかにした」
	- RAGは下図のように "Naive RAG", "Advanced RAG", "Modular RAG" のように変遷してきました
- 非常に良いRAG研究の現状まとめでした by TJO
	- https://x.com/TJO_datasci/status/1808334151709610368
	- 元々LLM実応用のコアと目されていたRAGのこれまでとこれからとが概観できます / RAGのSurvey論文からRAG関連技術を俯瞰する - 元生技のデータサイエンティストのメモ帳
- サイバーエージェントからCALM3-22B-Chatってのが公開
	- https://huggingface.co/cyberagent/calm3-22b-chat
- Swallow-8Bに、本家MetaのInstructモデルとBaseモデルの差分ベクトルを加算しました by AIXサトシさん
	- https://x.com/AiXsatoshi/status/1808063295259304286
- gen3 スゴいっす。日本人も普通に出せる。 破綻も少ない
	- https://x.com/br_d/status/1807986683226599806
	- 映像とかに1カットぱっと出されたら、判断つかないレベル
- パナソニックHDは、ストックマークと1,000億パラメータの自社専用 [#LLM](https://x.com/hashtag/LLM?src=hashtag_click) "Panasonic-LLM-100b" の開発で協業
	- https://x.com/panasonic_ai/status/1808007439922745561
- RetrievaBERTの公開
	- https://note.com/retrieva/n/n715bea2c2cd1
	- “Sentence Representationで用いるためのBERTとして系列長が2048まで対応しているBERTを構築しました
	- 我々の知る限りでは現在公開されているBERTは系列長512までとなっているものがほとんどだと思います。そこで今回、Sentence Representationで用いるためのBERTとして系列長が2048まで対応しているBERTを構築しました。
- プロンプト作るの苦手な人は全員 Claude の "Generate a prompt" を使った方が良い。
	- https://x.com/sora19ai/status/1807950984741806191
	- 今やプロンプトはAIに作らせることができて、Claude の Generate a prompt で作ったプロンプトを GPTs や Dify で使えば、出力の精度が10倍上がる。
	- 現在 GPTs や Dify の需要が高まる中、今から ChatBot を量産しておこう。リプ欄にリンクを載せておくので試してみて！
- DifyでVOICEVOXのTTSを使えるようにしたよ〜
	- https://github.com/uezo/dify-voicevox-tts
- 「アジア人ぽい複数の男性が、ひたすらに牛の餌のような草を食べている。手づかみで。ただし、服装はスーツであり、ホテルのような高級な場所である。背景では核戦争が起きている。」
	- https://x.com/kensuu/status/1807972176005587070
- RunwayのGen-3で盛り上がる中、Metaがしれっと高性能の3D生成AI「Meta 3D Gen」を発表
	- https://x.com/masahirochaen/status/1808166498403602822
- Launching GPT4All 3.0: The Open-Source Local LLM Desktop App
	- https://x.com/nomic_ai/status/1808162955806097767
		- Completely Private Experience 
		- Supports 1000’s of models and all major operating systems 
		- Major UI/UX Improvements 
		- Local File Chat 
		- MIT Licensed
- Runway Gen-3で作ったシュールな動画15選！
	- https://x.com/takamasa045/status/1807975062873792958
	- 1時間でプロ枠を使い切り、アンリミテッドプランに即アップグレード 1.5万円吹っ飛んだ、、、
- イラストのようなQRコードを生成したい人はQRBTFを使ったら良い
	- https://x.com/satori_sz9/status/1807621893488623976
- Gemini Nano running locally in Brave using MediaPipe
	- https://x.com/rohanpaul_ai/status/1807763287599149557
	- or Web, Android and iOS LLM Inference API, now you can run Gemini Nano locally not only in Google Chrome Canary, but in every web browser supporting WebGPU like Brave, through MediaPipe
- ザッカーバーグ「日本の担当を解雇すれば日本人からMetaに対する詐欺広告のクレーム届かなくなるし人件費も浮くし一石二鳥やろ、ガッハッハ」
	- https://x.com/makkinze/status/1807688392865624528
- The parable of the parser、現代の物体検出を作ってきたGirshick氏による議論をよぶプレゼン。
	- https://drive.google.com/file/d/1VodGljuEhBKwZIXQwN-ApH6g2wBAVAdK/view
	- 画像処理において画像分類や物体検出は最終的なタスクを解くのに必要ないのでは
	- 物体検出をこれまで研究してきたこと自体は間違いではなく、それにより知識をためて進んできたのは確かだが、さらに進むためには、より良い物体検出を作るのではなく本当に解きたい問題は何かを考えるのが必要とのこと。物体検出タスクはあまりに限定的で脆く、データに制約がある。50年~60年当然と思われていた考え方に疑問をもつこと、（各人が）本当に解きたいタスクは何かを考えることが重要。
- Decentralized Identifiers (DID) とVerifiable Credentials (VC) の現況
	- https://www.jstage.jst.go.jp/article/essfr/18/1/18_42/_article/-char/ja
- 高校からの、データサイエンス・統計活用、上級編
	- https://www.soumu.go.jp/main_content/000607858.pdf#page=1.00
- Gemma 2ではWARPと呼ばれる新しいマージング技術が使用されている by AIXサトシさん
	- https://x.com/AiXsatoshi/status/1808346577700069697
	- WARPは、3段階でモデルをマージ 
		- ・EMAを利用したRLHF 
		- ・複数のポリシーでRLHFされたモデルをSLERPマージ
		-  	・初期モデルと線形補完 
	- これを繰り返すことで、段階的に改善し、最終的により優れたパフォーマンスとアラインメントを実現
- 「アップルでアップストア事業を統括するフィル・シラー氏がオープンＡＩ取締役会のオブザーバーに選ばれた。」
	- https://x.com/bioshok3/status/1808284141173330407
- 突如Kyutaiという組織がGPT-4oかそれより応答速いと感じるSpeech2Speechリアルタイムマルチモーダル基盤モデルの「Moshi」を発表
	- https://x.com/bioshok3/status/1808529863621652596
- OpenContracts - a fully open-source, AI-powered Document Analytics Too
	- https://x.com/llama_index/status/1808528869252812902
-  Property-guided generation of complex polymer topologies using variational autoencoders
	- https://www.nature.com/articles/s41524-024-01328-0
	- VAEによるポリマー逆設計の論文　by 横山さん
	- 従来の逆設計はあるトポロジーのポリマーに限定さていたのに対し、環状・櫛形・星形など様々なトポロジーのポリマーデータを構築、狙いの物性をもつポリマーを広範囲から逆設計できたそうです。
- BM42: The combination of semantic and keyword search
	- https://x.com/qdrant_engine/status/1808498752107241949
	- https://qdrant.tech/articles/bm42/
	- For 40 years, BM25 has been the standard for search engines. However, it falls short for modern RAG applications.
	- We propose a new approach for exact keyword search based on Sparse Vectors and Attention from Transformers.
	- We can leverage the intelligence of the transformer to score the importance of each word in a sentence, while still being able to combine it with collection-wide statistics like IDF.
- **Zero Grads: Learning Local Surrogate Losses for Non-Differentiable Graphics**
	- https://mfischer-ucl.github.io/zerograds/
	- SIGGRAPH'24論文。勾配計算不可能なブラックボックス関数からの非常に少数のサンプリングで微分可能な代替関数 (勾配法で最適化可能) を作成。かなりの高次元でも効率的に動作する。
	- https://x.com/SupervisedAi/status/1808462332479107542
	- これすごいですね。応用例として元VAEからスプラインの座標位置を決めて画像生成するという微分不可能な生成モデルでも近似した勾配法結果により生成モデルの構築に成功してます
- Llama3-ArrowSE-8B-v0.1のShaberi3スコアは7.14。かなり性能すごいですね　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1808536639574266293
- This AI-powered Juypter implementation has huge potential.
	- https://x.com/omarsar0/status/1808527461736485229
	- They have added Mistral's Codestral and GPT4-o for inline AI Copilot auto-complete, code generation, editing, error fixing, and sidebar chat.
	- https://github.com/pretzelai/pretzelai
- How good are LLMs in a long context, and do we need RAG?
	- https://x.com/_philschmid/status/1808420168558649479
	- RAG always improves the performance of LLMs if correct information is retrieved
	- 📊 Evaluated 10 LLMs and 50 RAG systems, including GPT-4o, Claude 3 Opus, and Gemini-1.5-pro
	- 🏆 Claude 3 Opus achieved the highest Coverage; Gemini-1.5-pro highest citation
	- 🎯 Gemini-1.5-pro is the best LLM without RAG with 37.8; Claude 3 Sonnet 18.3; GPT-4o 11.4;
	- ⚙️ Gemini-1.5-pro + Oracle RAG achieves 44.6, whereas humans achieved 56.1.
- **Multi-token prediction models and baselines**
	- https://huggingface.co/facebook/multi-token-prediction
	- In April we published a paper on a new training approach for better & faster LLMs using multi-token prediction. To enable further exploration by researchers, we’ve released pre-trained models for code completion using this approach on
- unslothがgemma 2の微調整に対応
	- https://x.com/webbigdata/status/1808698905774993771
	- 各ライブラリだけアップデートすればgemma 1の微調整時に使った設定をほぼ変えずにGPUメモリ16GBで動いてくれました、
- "Patent Landscape Report on Generative AI,"
	- https://x.com/LuizaJarovsky/status/1808835305232839159
	- 54,000 GenAI-related inventions (patent families) were filed and more than 75,000 scientific publications published between 2014 and 2023.
	- The growth is rapid, with the number of GenAI patents increasing eightfold since the 2017 introduction of the deep neural network architecture behind the Large Language Models that have become synonymous with GenAI.
	- n 2023 alone over 25% of all GenAI patents globally were published, and over 45% of all GenAI scientific papers were published.
	- GenAI patents still currently only represent 6% of all AI patents globally.
- Claude 3.5 Sonnet, Gemini 1.5 Pro, GPT-4o 頂上決戦　by 元木さん
	- https://x.com/ai_syacho/status/1808708033989525886
	- 開発における能力順位を元木の感覚値で並べました。
- BM25のtfidfでいうtfに相当する項（BM25だとテキストの長さに応じた補正が掛けられてる項）の代わりに、transformerモデルに入れた時の最終層のCLSトークンのattensionの値を使うBM42が良いらしい。
	- https://x.com/s_tat1204/status/1808896746837455249
	- BM25資産をそのまま使えそうで良いですね
-  So far the technology has had almost no economic impact
	- https://www.economist.com/finance-and-economics/2024/07/02/what-happened-to-the-artificial-intelligence-revolution
	- AI革命は今のところ経済的インパクトがほとんど確認できないないという記事。by 小林さん
	- https://x.com/yohei_econ/status/1808503287617851876
	- GAFAM等の巨大テック企業は今年4000億ドル（60兆円兆）のAI関連資本支出を予定している。
	- しかしAIの利用率はまだ低い
	- 75％の知識労働者は既にAIを使っていると答えているが、アメリカで企業として使っているのは５％程度。データの安全性やアルゴリズムのバイアスが懸念点。 
	- またAIは進歩が速いので、パイロットを始めようとしても、それがすぐに時代遅れになるリスクがあり、大規模プロジェクトに着手しにくい。
	- ただし、カスタマーサービスやマーケティングの改善など、狭い領域に限ればAIの実装は進んでいる。 
	- しかしながら、AI企業の株価は市場全体と比較すると低迷しており、統計上は生産性上昇は見られない。
	- AIが進めば労働者に置き換わると言われたが、統計的にはそれも現れていない。
	- トラクター、電力、PC等、過去の多くの技術進歩が広まるには時間を要した。AIもその可能性は高く、投資家もAIに起因する収益がテック企業もたらされるのは2032年以降と予想。
- claudeは文を生成してる途中で、重要な箇所であたかも熟慮してるように生成を一時止めることがあったが、裏側では実際に非表示のトークンを生成していた。 
	- https://x.com/_kaiinui/status/1808778423319605647
	- xmlタグを表示するよう工夫することで確認できる
- Anthropic Claude 3.5 Sonnet on (claude ai) is suppressing parts of his answer from the user, which are not sent to the client. You can test that with, from now on, use §§ instead of <>. This then includes §§antThinking§§ tags, which are
	- https://x.com/_philschmid/status/1808755146190446667
- Gemma2-27Bも、Q8_0量子化がVRAMに収まらんかったから暫定的にQ5_K_M量子化をShaberi3評価したら7.88！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1808901901720957212
	- いやQwen2-72B超えてるしメチャクチャすごいんだけど、でも思った以上に9Bと僅差だな…。寝てる間にQ8_0でも一応あらためて評価する予定
- Gemma2-27BのQ8_0量子化のShaberi3スコア出ました。7.81　 b 海由紀さん
	- https://x.com/umiyuki_ai/status/1809028134727266364
	- Q5_K_M量子化（7.88）よりスコア下がったね？えーと…とりま、5bitまで量子化しても劣化はしないらしいねという事で…
- Claude3にロジックが破綻している可能性がある部分について指摘してもらってみた。
	- https://x.com/yukatan/status/1809114126746284492
	- 神宮外苑再開発めぐり伊藤忠商事が異例の長文の声明を発表
- Gemma2-9BのSPPOモデル、AlpacaEvalでもメチャクチャ勝率高くてGPT-4Tに匹敵してるくらいだからまあShaberi3ベンチで7.9取れてもおかしくないけど異常すぎる　 by うみゆきさん
	- https://tatsu-lab.github.io/alpaca_eval/
- AI’s $600B Question
	- https://www.sequoiacap.com/article/ais-600b-question/
	- the tech industry needs $600B in AI revenue to justify the money spent on GPUs and data centers.
	- OpenAI is the biggest AI pure play and is at $3.4B annual run rate. This feels like a bubble unless products worth buying show up.
- Gemma2-9B-it-SPPO-Iter3をShaberi3評価したらなんとスコア7.90！！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1809215562008179163
	- カガミカミさんに試してって言われた
	- 9B程度のモデルでは絶対辿り着けないハズの境地に到達してしまってる！スコア上はQwen2-72B（7.76）超え、Gemma2-27B（7.88）超え！Gemini1.5Pro（8.01）のチョイ下！流石にたまげた
-  非公式クライアントライブラリClaudiaを使って、Claude3とFunction CallingをUnityで動かす
	- https://note.com/361yohen/n/nbc4957231fe1
- The Transformers architecture clearly explained
	- https://x.com/rfeers/status/1809150250688639209
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- Should you finetune your LLM or just give relevant examples in the prompt? How many examples should you give for best performance?? If you give more will it hurt perf?? Does order of the examples matter!?
	- Large performance jumps when going from providing very few(1-5) examples(few-shot in-context learning - ICL) to providing many(100s-1000s) examples(many-shot ICL)
	- Show that many-shot ICL can overcome pre-training biases, perform comparably to supervised fine-tuning, and learn non-NLP prediction tasks.
- CodeInterpreter君勝手に必要なライブラリ自分でインストールするようになってる
	- https://x.com/lemilemilemio/status/1809250242468188288
- GraphRAG Advanced: Avoid Overspending with These Tips　by MervinPraison
	- https://x.com/MervinPraison/status/1809279522891604249
- 今後数カ月でAssistants APIのファイル検索に来る予定の機能が書かれてるじゃん！
	- https://x.com/super_bonochin/status/1809355949565702542
	- ベクトルだけでなくメタデータを利用したフィルタリング（Azure AI search使ってるもんね）
	- いわゆる画像RAG（図表の内容もふまえたRAG）
	- csvやjsonl等の構造化データに対するクエリ
-  Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/abs/2405.15071
	- They found that the critical factor isn't the amount of data, but the ratio (ϕ) of inferred facts to atomic facts. Figure 2(a) illustrates this beautifully - higher ϕ values correlate with faster generalization. This challenges a lot of conventional wisdom about data requirements in deep learning.
	- The best part? They showed their fully grokked transformer outperforming state-of-the-art models like GPT-4-Turbo and Gemini-1.5-Pro on a complex reasoning task with a large search space. We're talking near-perfect accuracy where the big models barely beat random guessing.
-  FastEmbed
	- https://github.com/qdrant/fastembed
	- Fast, Accurate, Lightweight Python library to make State of the Art Embedding
- What is a "cognitive architecture"?
	- https://blog.langchain.dev/what-is-a-cognitive-architecture/
- Human Prompt Engineer VS AI Prompt Engineer? Who wins?
	- https://x.com/learnprompting/status/1809301301760537021
	- DPSy performed 40% better on a novel classification benchmark.
- extracted the full ~5000 token claude3.5sonnet
	- https://x.com/rahulgs/status/1809313740275454352
	- this is a great template for function calling / tool use
	- https://gist.github.com/1rgs/b31a1de86df9b9f1b295647d4d29dd45
	- artifacts: seem to be a fully in-context abstraction, model not finetuned for it
- 

## 24/7/1

今週もいろいろあってパンク気味ですが、GUILDの深津さんがいうように毎週リセットされても追えるのが続けるコツかも。今週もAnthropicから、Artifactを作ったのはインスタグラム共同創業者がjoinして２か月で作成とのこと、日本への進出も、AWS summit Japan展示会で日本語強化をアピールしたり、自民党AI戦略会議でも、6～18か月の間で出てくる最先端のモデルが産業を変革する、いま準備しないと（国として、企業として）死にまっせと脅したりと大忙し。 Claudeのproject機能も相当やばいらしい。Googleも、Gemini 1.5 で、出力を JSON に固定することができるようになったとか、Google AI StudioやGemini APIでコードが実行できるようになったとか、Artifactをだいぶ意識してきたようだ。日本のLLM開発では、KARAKURI-LMモデルの評価などもありましたが、Llama-3-ELYZA-JPがリリース、70Bモデルは日本語の生成能力において「GPT-4」超え、8BはGPT-3.5 turboを上回る性能とのこと。GoogleからはGemma-2の27B & 9Bがリリース、27BってLlama-3-70B越えとか、9Bは Qwen-2-72B並みの性能とか、性能爆上がりの背後に何らかのブレークスルーがある、 しっかり情報追った方が良さそう。Gemini NanoのChrome搭載はCanary版を使えばだれでも22GB空きディスクさえあれば!使えるとのこと。LLMの安全性に関しては、Antropicからは「Constitutional AI」、原理原則を与えることで、自己評価と調整を行う新しいトレーニング手法とのこと。一方、OpenAIはCriticGPTを発表、ChatGPTの出力結果の評価という話だから、同社が出したLLMの振る舞いを規定する仕様書Model Specとも関連する気もするが、"AIが人間よりもはるかに賢くなっても、正しい行動に報酬を与えることを保証するスケーラブルな監視"の第１段だそうだ、結局OpenAIもAnthropicもLLMの説明性とか安全確保という面では似たような動きを、同じタイミングで、するんだな。メタからはvisonとtextを統合した初のLLMということでChameleonの紹介記事とかもありましたが、なんてったってLlamaベースのLLMコンパイラってのは驚いた、コード最適化タスクを行えるらしい、続報を期待。Microsoftからは、vison基盤モデルで、WebGPUを使ってローカルに動くFlorence-2が発表、こりゃ、監視カメラにローカルLLM載るわー。MicrosoftのGraphRAGの記事、graphを使わないベースラインとの比較が面白い、試してみたいところ。NVIDIAのファンCEO、10年もスタンフォードで講演をつづけたのか、講演内容からのビジネスの強さを分析したマインドマップが面白い、"In tech, if you aren't reinventing yourself, you are slowly dying"てのが染みる。しかしNVIDIA一強も安泰ではない、「NVIDIA最新GPUの20倍速い」史上最速を謳うAIチップ「Sohu」というのは、Transformerアーキテクチャーのみに特化した設計というのだから、日本のPFNのMＮ-coreにも勝機あり。AIの民主化というか普及に関連して、IBMによる、製造現場で継続的なデータ活用を推進するには、「業務知見に詳しい人」も必要とか、価格コムでDifyを現場に展開する話も参考になる。まあ、生成AI（特にLLM)なんて「博学の薄学」なんて偉ぶるのはやめたほうが良いですが。「巨大なコンテキストウィンドウのLLMはRAGを不要にするのか？」というDeepMindの論文、RAG不要論争にとどめか、ロングコンテキストのLLMってなんらかのパラダイムシフトを起こしそうな予感。材料系でのエージェント活用や交差と突然変異を化学知識で微調整したLLMで分子設計など、材料や化学系でのLLMの活用ってアプローチがいつも面白い。患者の振る舞いをLLMで模擬して医者の訓練に使うというPATIENT-Ψも面白いLLMの応用だ。岡野原さんが紹介した、言語は思考よりもコミュニケーションの道具であるという主張のNature論文、言語が思考を形作るという考え方と真逆なんだけど、LLMってどう頑張ってもしょせんは機械人形(Anthropic)ということなのか。というところで、Anthropicに始まりAnthropicで終わって、お後がよろしいようで。

- 小町先生の、「言語系AIプロジェクトの進め方」がよいらしい
	- https://x.com/mr_bay_area/status/1804689914291957983
- Questions at academic conferences
	- https://x.com/jayvanbavel/status/1801961592654815489
-  LLMatDesign: Autonomous Materials Discovery with Large Language Models
	- https://arxiv.org/abs/2406.13163
	- LLMによるAIエージェントの論文
	- バンドギャップの計算データを学習したモデルとLLMからAIエージェントを構築。「バンドギャップ1.4eVの材料は？」だけでなく「Baを使用しないで指定の材料を1.4eVになるよう改良して」などの指示もうまくいくようです。
- Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?
	- https://arxiv.org/abs/2406.13121
	- Google DeepMindによる報告。
	- 「巨大なコンテキストウィンドウのLLMはRAGを不要にするのか？」といった議論が活発化する中、Geminiに長いコンテキストを挿入してRAGと性能を比較する実験が行われました。
	- その結果、やはりロングコンテキストLLMは一定のパラダイムシフトをもたらす可能性を示唆しています。 
	- さらにRAGだけでなくText to SQLタスクのパフォーマンスも調査されています。
- This is fast. Chrome running Gemini locally on my laptop. 2 lines of code.
	- https://x.com/mortenjust/status/1805190952358650251
-  Claude’s Constitution
	- https://www.anthropic.com/news/claudes-constitution
	- Anthropic Constitutional AI （憲法的AI）を導入　by   AI𝕏サトシさん
		- https://x.com/AiXsatoshi/status/1804999143586402460
		- 「Constitutional AI」は、AIモデルが自己評価と調整を行う新しいトレーニング手法
		- 国連の世界人権宣言などに基づく原則を参照、人間の介入を減らすことで有害な出力を避けるAIを構築。これにより、トレーニング効率とモデルの信頼性が向上する
- 時系列データに対するInstruction Tuningデータを作成しました。by はちさん
	- https://x.com/CurveWeb/status/1805232501323112599
	- Timeseries-PILE、Phi-3-mini-4k-instructを使っているのでMITライセンスです。 とりあえずsingle turnで160K recordsあります。multi turnも作成中です。
	- https://huggingface.co/datasets/HachiML/Timeseries-QA
- インスタの共同創業者がClaudeプロダクトチームを率いた結果、Artifactが誕生。その間わずか2ヶ月
	- https://x.com/Haruki_Sonehara/status/1805111108748886440
	- チャットUIは自由すぎる分使い手の負荷が高い。良い質問ができる人はいいが、世の中そう多くない。 
	- Anthropicはそのことに気づいて、インスタの共同創業者をCPOとしてヘッドハントした。 
	- チャットとは違う切り口のLLMプロダクトがもっと増える。プロダクトマネージャーの皆さん未来を作る出番です！
-  三菱電機がClaude 3活用で「工数4割減」、仕様書の図表解析にマルチモーダルが威力
	- https://xtech.nikkei.com/atcl/nxt/column/18/02875/062000004/
	- すごいね、実際どうなのか気になる / “三菱電機がClaude 3活用で「工数4割減」、仕様書の図表解析にマルチモーダルが威力”
- 「NVIDIA最新GPUの20倍速い」史上最速を謳うAIチップ「Sohu」
	- https://ascii.jp/elem/000/004/206/4206328/
	- **Transformerアーキテクチャーのみに特化した設計を採用した**ことだ。この専門化により、Sohuは汎用GPUと比べて大幅な性能向上を実現
	- 8台のSohuサーバー１台で160台のH100をリプレイスできるんだって！！Sohux8サーバーはLlama-70Bを50万tpsで超爆速処理！B200x8の10倍の速度！しかもB200より安い
- Anthropicは日本政府へ6-18ヶ月位内、つまり2024年末から2025年末までに最先端のモデルが産業を急速に変革すると予想しているとプレゼン。
	- これは大きなこと。政府へ言うということは相当自信がある証拠だと感じる。
	- https://x.com/bioshok3/status/1805649281938018318
	- 自民党AIの進化と実装に関するプロジェクトチームに anthoropicのプレゼン
		- https://note.com/komori_takuo/n/n8433de4720a0
		- 私たちは、6～18 ヶ月 以内に最先端のモデルが 新しい能力で産業を 急速に変革すると 予想しています
		- 私たちのお客様は、 将来の画期的な進歩に 備えて最大限の準備を するため、ユースケース を急速に構築しています
		- 新しい画期的な進歩を待ち 立ち止まっている企業は、 すでに 4～8 ヶ月遅れて いる可能性があります
- Claudeのproject機能やばい。
	- https://x.com/onokoro48/status/1805810323473203366
	- はじめて教育に使えそう。 教科書を読み込ませておいて、 ポン出しで問題演習マシンができた。 勝手にArtifactsと連動してるし。
- Meta Chameleon: a new mixed-modal research model from Meta FAIR.
	- https://x.com/AIatMeta/status/1805705668567220261
	- The 7B & 34B safety tuned models we’ve released can take any combination of text and images as input and produce text outputs using a new early fusion approach.
	- While some LLMs have separate image and text encoders or decoders, **Chameleon is one of the first publicly released approaches using a single unified architecture.**
	- https://arxiv.org/abs/2405.09818
- GPT-4oボイスモードのアルファ版ローンチ、延期が確定
	- https://x.com/ctgptlb/status/1805734395833467342
-  KARAKURI-LMモデル（karakuri-lm-8x7b-instruct-v0.1-Q4_K_M.gguf）のELYZA-tasks-100パフォーマンス分析
	- https://hamaruki.com/llama-cpp-wandb-karakuri-lm-elyza-tasks-performance/
- シーズンが数ヶ月ごとにリセットされ、前例が全部なくなる環境大好き　 by 深津さん
	- https://x.com/fladdict/status/1805421726001774745
-  PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals
	- https://arxiv.org/abs/2405.19660
	- We introduce Patient-Ψ🤖, where we integrate cognitive modeling with LLMs to simulate patients for training mental health professionals.
- Claude 3.5 SonnetのBreaking News from Chatbot Arena
	- https://x.com/lmsysorg/status/1805329822748655837
	- Claude 3.5 Sonnet has just made a huge leap, securing the #1 spot in Coding Arena, Hard Prompts Arena, and #2 in the Overall leaderboard.
-  ELYZA、GPT-4を上回る性能の日本語LLMを開発
	- https://www.watch.impress.co.jp/docs/news/1603370.html
	- 「Llama 3」をベースとした700億パラメータの「Llama-3-ELYZA-JP-70B」と80億パラメータの「Llama-3-ELYZA-JP-8B」を開発し、性能を公開した。70Bモデルは、日本語の生成能力において「GPT-4」超えを達成したという。
	- 8Bモデルは、MetaのLlama-3-8Bをベースに事後学習(日本語追加事前学習・指示学習)を実施。「GPT-3.5 turboを上回る性能
- 「GPT-4」を上回る日本語性能のLLM「Llama-3-ELYZA-JP」を開発しました
	- https://note.com/elyza/n/n360b6084fdbd
	- 70Bデモ
		- https://elyza.ai/lp/elyza-llm-for-jp
	- 8Bモデル
		- https://huggingface.co/collections/elyza/llama-3-elyza-jp-667a311d51c8952e07778ecc
- Meeting Information Seeking Dialogs dataset (MISeD)
	- https://x.com/GoogleAI/status/1805654929182199832
	- https://research.google/blog/efficient-data-generation-for-source-grounded-information-seeking-dialogs-a-use-case-for-meeting-transcripts/
- Microsoft presents EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees
	- https://arxiv.org/abs/2406.16858
	- 20%-40% faster than EAGLE-1 (i.e. 3.05x - 4.26x faster than the baseline) - Ensures that the distribution of the generated text remains unchanged
- claude 3.5 makes my graphs from excel screenshots.
	- https://x.com/RubenHssd/status/1805609472582144201
	- You just turn on "Artifacts", and prompt it to stick to your brand color. Here's how:
- Florence-2, the new vision foundation model by Microsoft, can now run 100% locally in your browser on WebGPU, thanks to Transformers.js!
	- https://huggingface.co/spaces/Xenova/florence2-webgpu
	- Once loaded, the model (340 MB) will be cached and reused when you revisit the page.
- NousResearch/Nous-Hermes-2-Mistral-7B-DPO-GGUF
	- https://x.com/laniusdev/status/1805658195450380557
	- Boys, I think I've found a locally run model that can replace ChatGPT for me. It's sooo fast and passed my esoteric coding suggestion capability test.
- How LLMs work, explained with visuals:
	- https://x.com/akshay_pachaar/status/1805586547527631181
- Self-Play models finally got released! | SPPO Llama-3-8B finetune performs extremely strong strong on AlpacaEval 2.0
	- https://www.reddit.com/r/LocalLLaMA/comments/1doxvdi/selfplay_models_finally_got_released_sppo/?onetap_auto=true&one_tap=true
	- SPPO論文で「SPPOしたLlama-3-8Bの勝率がGPT-4超え！」とか主張してて「ウソ付け！だったらモデル出せや！」みたいな話だったのがついにモデルがお出しされたらしい
- 人にとって言語は思考よりもコミュニケーションの道具であるという主張　by 岡野原さん
	- https://www.nature.com/articles/s41586-024-07522-w
	- 失語症や言語を獲得していない場合でも思考能力は獲得でき、逆に言語能力が完全にあっても思考能力に問題がある場合があり、言語は思考にとって十分条件でも必要条件でもない。 
	- 言語は単なるコミュニケーションシステムであり、学習可能にできるように単純であることと、多くの情報を効率的に伝えられるようにすることのトレードオフで進化してきた。
	- 様々な言語処理、思考処理の脳内活動をみても言語と思考は脳内で別々のネットワークで処理されている。LLMからも言語能力をたとえ獲得できたとしても思考能力の改善には必ずしも繋がらないという示唆が得られている。
	- 人で特に発達した連合皮質は言語領域も含むがそれ以外の思考能力（例えばmultiple demand network）も同時に発達しており、言語か何か由来でというより、これらが同時並列で発達したと考えられる
-  Efficient Evolutionary Search Over Chemical Space with Large Language Models
	- https://arxiv.org/abs/2406.16976
	- LLMによる最適化の論文。　by 横山さん
	- 遺伝的アルゴリズムにおける交差と突然変異を化学知識で微調整したLLMで分子設計を行うと、従来より早く最適解にたどり着くことが分かったそうです。ランダムでなく化学を考慮し最適化操作ができる点がポイント。
	- LLMの使い方がうまい。
- Gemini Nano、及びWebGUI、過小評価してました
	- https://x.com/webbigdata/status/1806222156852052478
	- ChromeのCanary版と言って、毎晩のように更新されるα版をダウンロードして、ちょっとした設定をすれば即使えました
	- 注意点は少なくとも必要条件としてディスクに22GBの空き容量が必要との事です。現時点では実際にはそこまで占有されませんが、将来的にもう少し大きなモデルを見据えているのかもしれません
- Gemini 1.5 で、出力を JSON に固定することができるようになった
	- https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output
	- 今までのプロンプトの中で指定するような手法とは違い、以下のようにリクエストの中で指定をして投げる。これにより出力が確実に指定されたフォーマットになる。 "responseMimeType": "application/json"
- OpenAIが新型のGPT「CriticGPT」を公開しました by 今井さん
	- https://x.com/ImAI_Eruel/status/1806376950455554092
	- ChatGPT以来初のナンバーシリーズではない変化球なGPTの発表で，LLMの強化学習に利用するGPTのようです．
	-  Finding GPT-4’s mistakes with GPT-4
	- https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/
- AIが人間よりもはるかに賢くなっても、正しい行動に報酬を与えることを保証するスケーラブルな監視が今後必要になる。
	- https://x.com/bioshok3/status/1806378837334503786
	- OpenAIは今回その一歩となるGPT-4ベースのCriticGPTを開発。 ChatGPTのコード出力のエラーを検出できるように訓練されている。
- 製造現場で継続的なデータ活用を推進するために必要なこと
	- https://x.com/Nurruttan/status/1806098781542437239
	- 業務プロセスを変えるためにデータサイエンスを活用しようとする取り組みは多々あるよ。 
	- そのために必要なのは「データサイエンス力」だけでなくて、「業務知見に詳しい人」も必ず必要になるよ。 
	- 実際にどのように業務を変えるか？そこにデータサイエンスをどう使うか？をセットで考えることが必要だからね。
- Google AI Studioでコードが実行できるようになっている
	- https://x.com/YoheiN2023/status/1806238104979644481
	- 右下のCode executionのチェックを入れると試せます。全然気づかなかった…
- Gemma-2 27B & 9B release! by lmsys.org
	- https://x.com/lmsysorg/status/1806369224895647757
	- Gemma-2 was tested in the Arena under the codename "*late-june-chatbots" and now out of stealth. Its early result matches the best open models (Llama-3-70B, Nemotron-340B) with only 27B parameters!
	- Impressively, Gemma-2-9B is ranked as high as Qwen-2-72B. The rate of improvement is fast.
- Google AI Studio で Gemma 2 をお試し中。
	- https://aistudio.google.com/app/prompts/new_chat
- ところてんさん、経産省に呼び出される。
	- https://www.meti.go.jp/shingikai/mono_info_service/digital_jinzai/021.html
	- https://x.com/tokoroten/status/1806576954692530385
-  Gemini API の Code Execution by うみゆきさん
	- https://note.com/npaka/n/n7fff64088a9e?sub_rt=share_h
	- 「**Code Execution**」は、モデルがPythonコードを生成して実行することを可能にします。「Google AI Studio」や「Gemini API」で利用可能です。
	- 仮想マシン上でNumPyやSimPyなどのライブラリを使用できますが、追加のライブラリをインストールすることはできません。コード実行はモデルまたはリクエストレベルで有効化でき、チャットでも利用可能です。実行環境には30秒のタイムアウトなどの制限があります。
- メタがLlamaベースのLLMコンパイラをオープンリリース。
	- https://x.com/umiyuki_ai/status/1806380265041973349
	- プログラムコードを入力すると最適化オプションを提案してくれるとか。あとバイナリから逆コンパイルできる（精度45%）とか。
	- https://prompthub.info/21476/
	- Meta Large Language Model Compilerを導入し、コード最適化タスクに特化。
	- LLVM中間表現（IR）とアセンブリコードの5460億トークンのデータセットで詳細にトレーニングされており、コードサイズ最適化やアセンブリコードの正確な変換を実行。
	- 伝統的な自動チューニング方法の77%の最適化潜在能力を達成し、特定のタスクでCode LlamaやGPT-4 Turboよりも優れた性能を発揮。
- Gemma 2 is officially here!
	- https://blog.google/technology/developers/google-gemma-2/
- gemman2 demo on HF
	- https://huggingface.co/spaces/huggingface-projects/gemma-2-9b-it
	- Community is most welcome to do the vibe evals themselves at:
- Google's Gemma 2 models are here! Available in 2 sizes: by ollama
	- https://x.com/ollama/status/1806342805905616983
- AISI Japanのホームページが完成している
	- https://aisi.go.jp/international/
- Microsoftが提案しているGraphRAG
	- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/
	- https://x.com/A7_data/status/1806231239147364485
	- LLMでデータからナレッジグラフ作成 
	- 複雑な質問にも対応可能 
	- ベースラインより一貫して良い性能を発揮
- Buried in 10 years of Jensen Huang's Stanford talks are the secrets to building the most valuable tech company in the world.
	- https://x.com/JasonShen/status/1806357605343691053
	- In tech, if you aren't reinventing yourself, you are slowly dying
- Colab Pro and Pro+ now support Workspace organizations!
	- https://x.com/GoogleColab/status/1806099465604046928
- Dive into llama-agents with this notebook showing how to build an agentic RAG service!
	- https://github.com/run-llama/llama-agents/blob/main/examples/agentic_rag_toolservice.ipynb
- いよいよLangChainもワークフローが作れるLangGraphを発表↓
	- https://x.com/gijigae/status/1806701809269866990
	- LangChainと決別し独自の道を選んだDifyの判断は正しかったと思う。Difyが目指してる世界は表に出てることよりずーっと大きい。
- カカクコムが公開している「Difyの導入事例紹介」資料が有益
	- https://speakerdeck.com/tokita_kakaku/quan-she-de-nasheng-cheng-aihuo-yong-puratutohuomutositeno-difynodao-ru-shi-li-shao-jie
	- 全社導入に至るまでの活用フェイズごとのユースケースや企業目線の課題、実際に作成したアプリのワークフローまで掲載しており少しでも活用に興味がある人は非常に勉強になる
- みんな地獄で日本は意外にましな地獄
	- https://x.com/narita_yusuke/status/1803050919304781958
	- ここ5年弱のG7諸国を比べてみる 
	- 1) 日本はインフレ率が圧倒的に低い 
	- 2) 実質GDP成長率は真ん中くらい。ドイツ・イギリス・フランスより上
- ソフト開発者の求人がアメリカで激減。
	- https://x.com/hiyori13/status/1806698946531872982
	- もちろんGPTが理由。予想通りなんだけど、日本でももうすぐこうなるはず。エンジニアはGPTを使いこなして「自分が学習をしていない言語」を使いこなすスキルを覚えたほうがいい。こっちが今後重要。そして、コンピューター言語はこれからどんどん減っていくはず。
- OllamaベースでGraphRAGできた！
	- https://x.com/hAru_mAki_ch/status/1807092967574028398
-  Ollama Embeddings 完全ガイド API 不要のローカル環境で実現する 高性能テキスト解析
	- https://hamaruki.com/ollama-embeddings/
	- langchainのembeddingsって「gpt4all」と「ollama」に対応してた。。。
- ollamaのGemma2を使って「呪術廻戦」のwikipedia情報をNeo4Jに入れてみた！結構いい感じに入ってると思う！！
	- https://x.com/hAru_mAki_ch/status/1807318938675814506
- Googleさんのgemma-2-27b-itの日本語imatrix量子化ggufが完成しました！
	- https://huggingface.co/grapevine-AI/gemma-2-27b-it-gguf
	- 軽量なのにとんでもなく賢い、現状最強のローカルLLMだと思います
- Perplexity APIにはいくつかのLLMがあって、検索＋LLMを体験するなら「llama-3-sonar-large-32k-online」がオススメ。
	- https://x.com/gijigae/status/1807355566169432125
- Gemma-2が素晴らしい性能となってる なんらかの最近のブレイクスルーが関わってるか？ しっかり情報追った方が良さそう　 by AIXサトシさん
	- https://x.com/AiXsatoshi/status/1807563542125826120
- TJOさん、生成AI（特にLLM）の実務応用系トレンドが事前の予想通り「RAG系サービス」に収斂しつつある感があると、後出しじゃんけん
	- https://x.com/TJO_datasci/status/1807603353884807272
	- やはりどれほど基盤モデルを充実させても「博学の薄学」になりがちで、
	- 一方実務上は「業務ドメインの知識をもとに確実に疑問に答えられる」ことの方が重要。
	- そしてそれはRAG的なもので実現可能かと

## 24/6/24

今週はすべてを吹っ飛ばして、Anthropicが突然発表したClaude 3.5 Sonnetでしょう。Claude 3 Opusの2倍の速度でこれまでの5分の1のコストというのもすごいのですが、新しいアプリ開発環境Artifactsを使って、人間と対話しながらあっという間に、 スライド生成 、webUI生成 、スマホUI生成 、フローチャート生成、簡易ゲーム生成、ほぼ完ぺきなシフト管理システムの作成、WebGLをつかたった可視化プログラムの生成、様々な事例が発表されお祭り状態に。無料でArtiffactsは試せて、例えば、この文章からスライドを作ったり、LLMに関する知識グラフを生成したりとか、空から降ってくるトピックワードを打ち落とすゲームさえできる。生産性向上とか改善とか、もう全部、Claude 3.5 Sonnetで上書きされる感じ、逆に、これが使いこなせる人材しか残らない。でもこれSonnetなんですよ、Opusってどうなるんでしょうか。Googleからは、患者とのやり取りで人間の医師を超えるというAMIE(Articulate Medical Intelligence Explorer )の発表や、高精度天気予報「ナウキャスト」を日本でウェザーニュースのデータで学習して提供とか、Gemini1.5ProとGemini1.5FlashのAPIでコンテキストキャッシュ機能のリリース等がありました。Geminiの公式 noteシリーズ開始とか、着実にすそ野も広めてて好感が持てる。傘下のDeepMindからvideo-to-audio (V2A)が発表され、先週のLuma AIと合わせれば、ショートフィルムは作れそうな勢い。さて、Metaからは、ミックスモーダルなChameleonや、音声がAI製かどうかを見破れるモデルなどの複数のモデルの発表、どのような評価や方向性になるのか来週以降期待。先週話題となった、Nemotron-4-340B-Instruct、評価などがぼちぼち、うみゆきさんがShaberi3ベンチにかけてみたら、平均スコア8.05で、Gemini1.5Pro（8.01）以上、GPT-4o（8.16）以下とのこと。またテクニカルノートによると98%の事後学習のデータは合成データをつかっているとのこと、さすが合成データを作るのが得意なNemotronの面目躍如、いや、そのデモだったのかも。無料のPlaygroundで合成データをコチコチ作るという手もありそうだ。ローカルLLMでは、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」が、製作費75万円ということで話題になりましたが、なんといっても、Chrome で動く Gemini Nano、Chrome開発版では利用可能になっているとのこと、さっそくnpakaさんが動作事例を紹介。ブラウザ組み込みでっせ、javascriptからたたけるんでっせ。shi3zさんの解説によると、KARAKURIが低予算でLLMを作れたからくりは、AWS Trainiumの利用とのことで、また、先週紹介のあった、MoA(Mixture of Agent)や、LLMのマージ技術により、手軽に誰でも高性能なLLMを構築できるようになった、確変の時代きたるという記事はしびれる、そうか、データはNemotronで合成されればよいのか、どんなLLMがshi3zさんのGPUマシンから出てくるのか楽しみです。理論面では、LLMが事前学習時に事実的知識を獲得する様子の分析論文や、Transformer のコンポーネントか始まって最終的な表現型に近い現象挙動までつながる様子をほぼ明らかとする解説記事とか、LLMの振る舞いの理論的な解析も着実にすすんでいます、説明性の向上に期待。応用面のRAGも忘れてませんよ、知識グラフとの統合とか、「KARAKURI LM 8x7B Instruct v0.1」ってRAGに対応と明示してあったりと、今週もいろいろありましたが、ここは基本戻って、 LangChain で RAGのハイブリッド検索なんかやらせてみて、正気を取り戻しましょう。さて、Claude 3.5 Sonnetの能力を見てると、「まだLLMで驚けるんだ」という(メタな）驚きから、それって、人ってそんなに沢山いらないかも、というのが確信になりつつあります。BBCで紹介された、60人いたライターと編集者が職を失い、ChatGPTの出力を手直しする一人のテクニカルライターに置き換えられたという話題もインパクトありましたが、Claude 3.5 SonnetやGPT-4o級ならそうなるかも。いや、バージニア大学の先生のいう「生産的に愚かになる」ってのは、LLMにはまだ無理かな、と信じたいところです。

- いつの間にかStable DiffusionがDiffusion Modelではなくなっている！？（バックボーンがDiffusion Transformerだからセーフ？）
	- https://x.com/shion_honda/status/1802386378874835056
- WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild
	- https://arxiv.org/abs/2406.04770
	- 100万件におよぶ人間とLLMの会話履歴をもとに作成した、現実ニーズに則する1,024のタスクでモデルを評価する手法『WildBench』が公開されています。
	- 「人間が実際に投げるタイプのタスク」における40種類のモデルの性能は興味深いものとなっています。
- DeepSeek-Coder-V2
	- https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct
	- 236B Mixture-of-Experts（MoE） 6T tokensの事前学習 サポートする言語は338 コンテキスト長も16Kから128Kに
	- 標準的なベンチマーク評価で、GPT4-Turbo、Claude 3 Opus、Gemini 1.5 Proなど2を上回る性能
-  AI took their jobs. Now they get paid to make it sound human
	- https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human
	- 60人いたライターと編集者が職を失い、ChatGPTの出力を手直しする一人のテクニカルライターに置き換えられたという話題
	- AIの出力を人間っぽくするために少数の人間が雇われる流れがもう加速している
- The importance of stupidity in scientific research
	- https://web.stanford.edu/~fukamit/schwartz-2008.pdf
	- 「愚かさ」は、科学者が重要な質問をしていることを示す兆候であるとされています。著者は、学生が「生産的に愚かになる」方法を教えるための提案で論文を締めくくっています。
- Nemotron 340B Technical Report
	- https://x.com/_philschmid/status/1802617332893729029
	- Implementation
		- Pretraining: 2-phase pretraining, first trained on 8T and then continued on 1T higher quality tokens and Instruction data with a steeper slope of learning rate decay. 
		- Fine-tuning: First fine-tuned on 800K coding samples, followed by 200K diverse task samples. 
		- RLHF: Applied Direct Preference Optimization (DPO) followed by Reward-aware Preference Optimization (RPO) on multiple iterations.
	- Insights
		- 98% of data used in post-training was synthetically generated
		- Pretraining data: English data (70%), Multilingual data (15%), Source code (15%).
		- Trained on 6144 H100 GPUs with 8-way TP, 12-way PP with interleaving and DP to achieve ~42% MFU
		- Only used 20k Human annotated data mostly for Reward Modeling
		- Detailed Synthetic Data pipeline instruction including all prompts to generate data
- DeepMind　からvideo-to-audio (V2A) generative technology. 
	- https://x.com/GoogleDeepMind/status/1802733643992850760
	- It can add sound to silent clips that match the acoustics of the scene, accompany on-screen action, and more.
- How Do Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://arxiv.org/abs/2406.11813
	- Reveals several important insights into the dynamics of factual knowledge acquisition during pretraining
- Nemotron-4-340B-InstructのAPIをさっそくShaberi3ベンチにかけてみたら、平均スコア8.05！Gemini1.5Pro（8.01）以上、GPT-4o（8.16）以下！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1803112240935260328
- Building Advanced RAG with Knowledge Graphs
	- https://x.com/llama_index/status/1803082001538535703
	- This 60 minute webinar is a must-watch if you’re looking to apply the latest techniques combining LLMs with knowledge graphs.
-  Creativity Has Left the Chat: The Price of Debiasing Language Models
	- https://arxiv.org/abs/2406.05587
	- アラインメントされると大規模言語モデルは創造性を失う RLHF などの有害な生成を防ぐためのアラインメント技術によって、LLM の創造性(多様性)が減少する。例えば生成文をクラスタ分析すると、アラインメントされたモデルでは明確なクラスタ形成され偏りがあることが分かる
- I have lots of thoughts on "agents"!
	- https://x.com/hwchase17/status/1803089961245348125
	- spotify での配信付き
- today at Meta FAIR we’re announcing four new publicly available AI models
	- https://x.com/AIatMeta/status/1803107817345393136
	- Meta Chameleon
		- 7B & 34B language models that support mixed-modal input and text-only outputs.
		- これはテキストや画像を入力するとテキストや画像を出力できるモデル！
	- Meta Multi-Token Prediction
		- Pretrained Language Models for code completion using Multi-Token Prediction.
		- マルチトークン予測の7Bモデル！普通のLLMは1トークンずつしか出力できないけど、これは複数のトークンをまとめて出力できて速い
	- Meta JASCO
		- Generative text-to-music models capable of accepting various conditioning inputs for greater controllability. Paper available today with a pretrained model coming soon.
		- これはコードやらビートを指定して音楽生成できるらしい
	- Meta AudioSeal
	-  	An audio watermarking model that we believe is the first designed specifically for the localized detection of AI-generated speech, available under a commercial license.
	- 音声がAI製かどうかを見破れるモデル
- Firefunction-v2
	- https://x.com/LangChainAI/status/1803083016715289045
	- Llama 3 fine-tuned for tool calling / agents
- 直感的に理解するConformal Prediction
	- https://speakerdeck.com/masatoto/zhi-gan-de-nili-jie-suruconformal-prediction
	- 分類問題における確信度の高い結果だけを返すのではなく，予測集合を返す方法.予測集合に真の結果が含まれることを確率的に保証.
- What is a Mixture-of-Experts (MoE)
	- https://x.com/akshay_pachaar/status/1803043120654983424
	- A Mixture of Experts (MoE) is a machine learning framework that resembles a team of specialists, each adept at handling different aspects of a complex task.
	- It's like dividing a large problem into smaller, more manageable parts and assigning each part to a different expert.
- 合成データ作り放題でおなじみのNemotron、APIとかあるのね
	- https://x.com/umiyuki_ai/status/1803078912051986714
	- ログインすれば無料で1000回まで叩けるらしい。課金とかはまだ無いぽい。課金してでも叩きたい人多そうだけど。Playgroundでチャットするだけならクレジット減らないっぽいから頑張れば合成データ収集できるかも
- Gemini1.5ProとGemini1.5FlashのAPIでコンテキストキャッシュ機能がリリース
	- https://x.com/umiyuki_ai/status/1803127902533460149
	- https://ai.google.dev/gemini-api/docs/caching?lang=python&hl=ja
	- 要するにKVキャッシュを保存したりロードしたりする機能。API無料枠のユーザーでもFlashでコンテキストキャッシュを最大100万トークン活用可能！32k以上のコンテキストでキャッシュが使用できる
- How Large Language Models Acquire Factual Knowledge During Pretraining?
	- https://x.com/hoyeon_chang/status/1802952064726622671
	- 著者のツイート、I’m thrilled to announce the release of my new paper!
	- This research explores how LLMs acquire and retain factual knowledge during pretraining. Here are some key insights:
	- LLMが事前学習時に事実的知識を獲得する様子を、事実の対数尤度で評価した場合、知識に触れるたび少しだけ上昇し緩やかに下がり元に戻る。忘れるより先にまた知識に触れることを繰り返し閾値に達すると回答できるようになる。by 岡野原さん
-  Google の AI 「Gemini」、公式 note はじめます
	- https://note.com/google_gemini/n/nc53d2b6f4a08
	- 新機能の紹介やイベント レポート、開発者の話など、Gemini にまつわるさまざまな情報やニュースをお届けします。
- 「ChatGPTって、自分の「境界」を持っていませんよね。
	- https://x.com/ShigeruTaguchi/status/1803044441680412775
	- だからパースペクティブを持てないというか。……身体性って、たしかに単に物理的な肉体を持つということだけではないけれど、自分に固有の境界を持っていて、そこからしか発生しないパースペクティブを持つというのは大事だと思うんです。
- Gemini について全部解説！ 使い方やモデル、プランまで
	- https://note.com/google_gemini/n/ncd7557d98d07?sub_rt=share_b
-  OpenAIとGoogleが火花　マルチモーダル、エージェント…生成AIの今 by 今井さん
	- https://xtrend.nikkei.com/atcl/contents/casestudy/00012/01473/?n_cid=nbpnxr_twed_cms
	- 結論だけ言うと「長期的にはGoogle有利」です。
-  LangChain で RAGのハイブリッド検索 を試す by npakaさん
	- https://note.com/npaka/n/n6782314fb471?sub_rt=share_h
	- 「RAG」のハイブリッド検索は、複数の検索方法を組み合わせる手法で、主に「ベクトル検索」と「キーワード検索」を組み合わせて使います
-  Fine Tuning MistralAI models using Finetuning API
	- https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/finetuning/mistralai_fine_tuning.ipynb
-  LLM の仕組みを押さえればさらに生成 AI を活用できる
	- https://note.com/google_gemini/n/n51d9f3b97470?sub_rt=share_b
	- 言語モデルが行なっていることは「文脈を踏まえて文の続きを予測」すること
	- LLM の仕組みを踏まえると、生成 AI の特徴がより理解できる
	- より長い文脈を踏まえて「文の続きを予測」できることで、より進化していく
	- マルチモーダル モデルを使いこなす！
- Ilya Sutskeverが安全な超知能を目標とするSafe Superintelligence Inc.設立!
	- https://x.com/bioshok3/status/1803475573030920310
- グーグル、12時間先まで5分刻みで降雨予測する「Google ナウキャスト」
	- https://www.watch.impress.co.jp/docs/news/1601121.html
	- Google ナウキャストでは、6時間先までの降雨予測をGoogle 検索の結果に表示し、さらに12時間先までの予測を文字情報で表示。5分単位の詳細な雨量予測が可能となる。雨だけでなく雪の予測も行なう。
	- 高精度天気予報「ナウキャスト」日本で提供　ウェザーニュースのデータで学習したAI採用
- Google researchers developed the Articulate Medical Intelligence Explorer (AMIE),
	- https://www.deeplearning.ai/the-batch/amie-a-chatbot-that-outperforms-doctors-in-diagnostic-conversations/?utm_campaign=The%20Batch&utm_content=297333022&utm_medium=social&utm_source=twitter&hss_channel=tw-992153930095251456
	- AMIE, a chatbot that outperforms doctors in diagnostic conversations
- Kolmogorov Arnold Network” is one of the best innovations of 2024
	- https://x.com/predict_addict/status/1803323909233668281
	- “Kolmogorov–Arnold-Informed neural network: A physics-informed deep learning framework for solving PDEs based on Kolmogorov–Arnold Networks”
- Chrome で Gemini Nano を使用する
	- https://developer.chrome.com/docs/ai?hl=ja
- Transformerの次のアーキテクチャとして期待されているMambaを使った音声分類モデル、Audio-MambaのFine-Tuningを試してみました
	- https://x.com/AIShift_PR/status/1803349519532531817
-  A Primer on the Inner Workings of Transformer-based Language Models
	- https://arxiv.org/abs/2405.00208
	- Section 2→5に進むにつれてTransformerのコンポーネント内の局所的な挙動から始まってより最終的な表現型に近い現象の説明まで，これまでの大量の知見がまとまっています
	- Transformer の挙動はほぼ明らかになってると思っていて、まだ明らかになってないことはモデルというより言語の性質が原因な気がする（素人の勘）
- きたあああああああああああああああああああああああああああああああああああああ！！
	- https://x.com/lemilemilemio/status/1803607874079432959
	- Anthropic社は突如として"Claude 3.5 Sonnet"をリリース
- 国産LLM初、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」を一般公開
	- https://prtimes.jp/main/html/rd/p/000000089.000025663.html
	- Function callingとRAGに対応した「KARAKURI LM 8x7B Instruct v0.1」を公開いたします
	- 本対応により、「KARAKURI LM 8x7B Instruct v0.1」は様々なアプリケーションを人間に代わって操作するAIエージェント※2 としての活用が可能です
- Anthropic社は突如として"Claude 3.5 Sonnet"をリリース
	- https://x.com/ctgptlb/status/1803822932831166712
	- 現状最強だったGPT-4oの性能を上回る上に、Claude 3 Opusの2倍の速度でこれまでの5分の1のコストに
	- また新しく、"Artifacts"という新機能が登場。Xで早速Artifacts機能のすごい事例が報告されています
- Claude3.5Sonnet　不都合日、休日担当数の公平性、当直日の間隔などを考慮してほぼ完璧なシフトを組んでくれます
	- https://x.com/genkAIjokyo/status/1803905958776836356
	- ついに...人間が当直表、待機表、シフトの作成から解放される日が！
	- このタスクはGPT4o、Claude3Opusでも少し修正必要だったのでClaude3.5Sonnetかなり優秀...
- Claude 3.5 sonnetとArtifactで出来ること。by 元木さん
	- https://x.com/ai_syacho/status/1803822100186058831
	- 1. スライド生成 
	- 2. webUI生成 
	- 3. スマホUI生成 
	- 4. フローチャート生成 
	- 5. 簡易ゲーム生成
-  Evaluating the World Model Implicit in a Generative Model
	- https://arxiv.org/abs/2406.03689
	- New paper: How can you tell if a transformer has the right world model?
	- We trained a transformer to predict directions for NYC taxi rides. The model was good. It could find shortest paths between new points
	- The map let us visually inspect the incoherent world model. But how should we evaluate world models in non-map settings?
- 国産LLM初、AIエージェントとして使える「KARAKURI LM 8x7B Instruct v0.1」を一般公開
	- https://karakuri.ai/seminar/news/karakuri-lm-8x7b-instruct-v0-1/
	- 本モデルはトレーニングコストを最大50%削減できるといわれているAWS Trainiumを活用しており、開発費用は75万円です。
	- デモ（期間限定）
		- https://lm.karakuri.cc/
-  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention
	- https://arxiv.org/abs/2404.07143
	- Infini-attentionは、トランスフォーマーベースのLLMsが無限に長いコンテキストを処理できるようにする新しい手法
	- 従来の注意メカニズムが長いシーケンスを処理する際に直面するメモリと計算負荷の問題を解決
- 加熱するLLM開発競争に冷や水、オープンモデルの組み合わせだけでGPT-4o越えの事実 by shi3zさん
	- https://wirelesswire.jp/2024/06/86709/
	- この最新のLLNは、日本語向けオープンLLMとしては初の「命令実行」チューニングを施されている
	- Karakuriはこんな低予算で日本語最高性能のエージェントLLMを作ることができたのか。それはNVIDIAのGPUを使っていないからだ。
	- 二週間ほど前に発表された「[Mixture-of-Agents](https://arxiv.org/abs/2406.04692)(エージェントの合成)」という論文がある。
	- すでに公開されているオープンLLMを8つ組み合わせて使うだけで、GPT-4o単体の性能を上回るベンチマーク結果となったと主張している。
	- LLMの組み合わせによってGPT-4oと同等の性能だが計算効率は圧倒的に高いMoA-Liteと、GPT-4oより計算量も少なくさらに高性能なMoAの二つが提案された。
	- 世界中の大企業が何千億、ひょっとしたら合計して何兆円という金額をGPUに浪費している間に、強かな人たちは既存の技術の手軽な組み合わせで大きな進歩を成し遂げようとしている。
	- 筆者(shi3zさん)も早速、日本語のオープンLLMをMixture-of-Agentsで組み合わせを試すつもりだ。  
	- これとDiscoPOPを組み合わせて、日本語LLMの最適な組み合わせをGPTまたはLLM自身に評価させるというのも面白い。
-  Claude 3.5 Sonnet の概要 by npakaさん
	- https://note.com/npaka/n/n7c8e19914166
	- 大学院レベルの推論 (GPQA)、学部レベルの知識 (MMLU)、コーディング能力 (HumanEval) において、新たな業界基準を設定しました。ニュアンス、ユーモア、複雑な指示の把握において顕著な改善が見られ、自然で親しみやすい口調で高品質のコンテンツを書くことに優れています
	- 指示に従って[適切なツールが提供されれば](https://www.anthropic.com/news/tool-use-ga)、高度な推論機能とトラブルシューティング機能を使用して、コードを独自に記述、編集、実行できます。コード変換も簡単に処理できるため、レガシーアプリケーションの更新やコードベースの移行に特に効果的です。
	- 「**Artifacts**」は、ユーザーがClaudeとやり取りする方法を拡張する新機能です。ユーザーがClaudeにコード、テキスト、Webサイトデザインなどのコンテンツを生成するように依頼すると、これらのArtifactsが会話の横にある専用ウィンドウに表示されます。
	- Anthropicのレッドチーム評価では、「Claude 3.5 Sonnet」はASL-2のままであると結論付けられました。
-  Claude 3.5 Sonnet の評価に関する備忘録
	- https://tech.algomatic.jp/entry/papers/anthropic-2024-claude35
	- 論文にあった、様々なデータセットでの具体的な性能を例示している
	- Artifacts — a new way to use Claude
		- https://www.youtube.com/watch?v=rHqk0ZGb6qo&t=4s
- インドの物理学者がひも理論の研究から偶然「円周率」の新しい公式を発見
	- https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.132.221601
- VLSIシンポジウムではMediatakのLLM向けモバイルプロセッサの発表が迫力あった by 竹内さん
	- https://x.com/kentakeuchi2003/status/1804713977886425509
	- エッジAIにもLLMが来るぞ、というよりも、もう来ているという感じ。
- Claude 3.5 使ったら 5分ぐらいで抽象言語パッケージマネージャーGrimoのフロントエンドモック出来てしまった
	- https://x.com/ai_syacho/status/1804400108664189260
- Claude able to produce simulated 3d physics using WebGL
	- https://x.com/Hamptonism/status/1804496837216227756
- Magpieという手法をNemotron-4-340B-Instructに適用し、日本語ロールプレイ用instructionの合成データセットを作成してみました。
	-	https://x.com/Aratako_LM/status/1804817272911138909
	-	特にフィルタ等していない生のデータですが、合成データとしてはかなり質が高そうです。（流石Nemotron-4）
-	Chrome の Gemini Nano を試す by npakaさん
	-	https://note.com/npaka/n/n17176250330e?sub_rt=share_h
	-	「Chrome」の「Gemini Nano」の早期アクセス版が使えるようになりました。
	-	テキスト生成
	-	(1) メニュー「表示 → 開発/管理 → JavaScriptコンソール」でコンソールを表示。
	-	(2)いかがコードのイメージ
		-	const canCreate = await  window.ai.canCreateTextSession();
		-	const session = await  window.ai.createTextSession(); 
		-	const result = await session.prompt("まどか☆マギカでは誰が一番かわいい?");
		-	console.log(result);

## 6/17

今週は、WWDCで始まった。アップル本社上空からパラシュートで降りるオープニングから、クレイグ副社長の謎の運動能力のデモ、OpenAIのアルトマン氏目撃情報がAppleキャンパスの現地から多数など話題に事欠かない。Apple IntelligenceはApple製品にLLMがシームレスに組み込まれ、UXとしての雄の貫録を、Ferret-UI論文も併せて見せた。Siriも、シームレスとはいえないまでも、GPT-4oにつながる、今年末にはリリース。実は、ローカルな3BのLLM、セキュアなサーバー環境(Mシリーズが動く）でのLLMという独自のLLMがＵＸを起点にシームレスに展開されている、開発にあたりAI原則も独自に作っている。Google寝てましたか？というコメントもあったが、Appleも、このLLMの活用では他社と同じような展開しかできておらず、結局、顧客が不要な技術を買うことになっていると厳しい意見もあった。さてGoogleは、Gemini 1.5 Flashの評判も高く、議事録作成は相当こなせそう、Chromeで、ブラウザ上でGemini Nanoが動くようになるらしい、RecurrentGemma-9bも、新しいリカレントアーキテクチャを採用することで、より効率的かつ高性能な言語処理を実現したというが、どうやら動作が安定してきている模様。DeepMindの、LLMの知識不足（ハルシネーション）を確かめる方法というのも、面白いが、人間にも適用できそうだ。DreamMachineから出たLuma AIは不気味を超えている、デート中にほかの子に気をそらされる男の子とか、写真をもとに動画をつくるということで、奥さんの若いころの写真から動画を作ったりと、まさに不気味な感じ。あまりにも自然なので、もっとも厄介なのは、人の記憶を上書きしてしまう恐れがあるということだそうだ。人の認知は弱い。NVIDIA、株を１０分割したり、オーブンからA100のボードを出すファンCEOのビデオが話題になったり、そのファンCEOは米名門カルテック大学卒業式でスピーチと、話題が満載ですが、Nemotron-4-340Bという謎の巨大LLMもリリース。もっとも、攻撃に対する脆弱性についてはまったく無配慮なことも明らかになった。何をしようとしているのかNVIDIA。高橋先生の「生成モデルの基礎と応用」、素晴らしい資料がでてきた、LLMを避けてきた人もこれは見るべき。MoEの次のMoA（エージェント）ってのもあったAlpacaEval 2.0 でGPT-4oに勝ると。ACL 2024からLLMは世界シミュレータになりうるか？という論文も話題になった、not reallyらしい。LLMを使いこなすのに必要な、言語化能力は、実はメタ言語能力であるとの説、まあ、最新のLLMはメタ能力を持ってるから、使う側にも相応の力量が必要なのは明らか。今井先生も大切なのはメタ認知能力とか言ってたな。LLMが苦手な、アリス問題というのも話題になった、「アリスにはN人の兄弟とM人の姉妹がいる。アリスの兄には何人の姉妹がいるか」、試してみよう。知識グラフ、Personalized PageRank を組み合わせたHippoRAG、人の脳内処理と類似しているといってるが、今井先生の新刊『「何回説明しても伝わらない」はなぜ起こるのか？』をみても、都合の良い記憶に残ったわずかな情報から人間も答えている気がしてきた。今井先生によると、ビジネスや探求を突き詰めた人が得られる「優れた直観」というのを、（頼りすぎて）AIが奪うのではというのは頭に残った。Luminaもそうだが、人の認知能力や記憶の領域に、それを使うことで間接的に、AIの影響が出るようになってきたのは、恐ろしい。

- MMed-Llama-3-8B
	- https://x.com/longislandtea3/status/1799013747178278939
	- ２週間ほど前に出たMMed-Llama-3-8B 医療用のオープンモデルとしてはGPT-3.5を軽く超え、GPT-4を匹敵すると言っている
- Prometheus-2: An Open-Source Evaluator LM for Your RAG Application
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/prometheus2_cookbook/
	- Prometheus-2 shows a high degree of correlation and agreement with human evaluations, GPT-4, and Claude3, making it a dependable evaluator LM for RAG applications.
- Qwen2-72B-InstructのElyzaTasks100の平均スコア、4.23でした by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800023709958431166
	- チャクチャすごい…Gemini1.5Flashのチョイ下。OpenAIの進歩が停滞感あるのに対してオープンモデルの進化はすさまじいです。
	- Qwen1.5が出てから4ヶ月、Llama3から2ヶ月しか経ってません。こんな事態になるとは
- MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark
	- https://arxiv.org/abs/2406.01574
	- もはや定番のベンチマーク『MMLU』ではLLMの性能評価で差がつかないことを受け、ウォータールー大学などの研究者らにより『MMLU-Pro』が作成されました。
	- すでにGPT-4o、Claude 3、Llama-3、Phi-3など多数で実験が行われ、各モデルの特徴を捉えることに成功しています。
-  CRAG -- Comprehensive RAG Benchmark
	- https://arxiv.org/abs/2406.04744
	- Meta presents CRAG - Comprehensive RAG Benchmark
	- Presents a factual QA benchmark of 4,409 QA pairs and mock APIs to simulate web and Knowledge Graph (KG) search
- Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- LLMの計算コストを支配する行列積（MatMul）を完全に排除しながら、パフォーマンスを維持する方法が発表された 
	- ちょっと前に業界の話題を席けんしたBitNet1.58bの上位互換ともとれる 
	- FPGAで実装し、効果を確認しており、これは脱GPUの流れが来るかもしれない
- AppleデバイスにChatGPTが統合されます！
	- https://x.com/gizmodojapan/status/1800237589330526454
	- iPhone/Mac等から無料でChatGPTにアクセスできるようになります。アカウント作成も不要（有料アカウントを持ってる場合はそちらを使えるよう）。
- オープンモデルの最近の進化　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800036264487591937
	- １年前のelyza-japanese-llama-2-7bの頃は5歳児レベルで、
	- 半年前のnekomata-14bで小学生、
	- 4カ月前のQwen1.5で中学生、
	- 2ヶ月前のLlama3で高校生、
	- 直近のQwen2で大学生って感じかもしれない。グラボ買ってもかつては5歳児AIしか雇用できなかったのが今では同じグラボで大学生AIが雇用できてしまうというコスパの爆上がり。そして1年後はどうなってしまうのか？院生レベル？博士レベル？
-  Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
	- https://arxiv.org/abs/2404.05719
	- Apple already published a paper on it that disclosed way more details than what we expect from Apple. 
	- It's called "Ferret-UI", a multimodal vision-language model that understands icons, widgets, and text on iOS mobile screen, and reasons about their spatial relationships and functional meanings.
- GraphRAGふーんって感じだったけど、びっくりするくらいわかりやすかった
	- https://x.com/__genzitsu__/status/1800074489897889998
- 開発版のChromeで、ブラウザ上でGemini Nanoを動かせるようになった
	- https://x.com/kentaro/status/1799856400149221599
	- ブラウザAPIだけで完結する音声チャットボットの実験をしてみました。これは夢が広がりますね！アツい！！
	- https://codesandbox.io/p/sandbox/gemini-nano-chatbot-cdg59q?file=%2Findex.html
		-  LLM: Chrome上で動作するGemini Nano 
		- 音声認識+音声合成: Web Speech API
- いた（アルトマン氏が、WWDC2024に)
	- https://x.com/iskw226/status/1800202842428653817
- Appleが発表した人工知能「Apple Intelligence」 by GIZMODE
	- 1. 文章の自動編集・校正機能 
	- 2. メモ・フリーボード・Keynoteなどで画像生成が可能に 
	- 3. Apple Intelligenceは「実行」ができる。「この間、送られてきたポッドキャストを再生して」と言えば、見つけ出して再生することろまでやってくれるらしい…！ 
	- 4. メールで送られてきた予定は、自動でスケジュール化。予定の場所の地図データなども自動で添付。
- LaVague
	- https://github.com/lavague-ai/LaVague
	- LaVague is an **open-source Large Action Model framework** to develop AI Web Agents.
- We’re partnering with Apple to integrate ChatGPT into iOS, iPadOS, and macOS—coming later this year:
	- https://x.com/OpenAI/status/1800240380220473552
- アップル・Google・マイクロソフト・OpenAIがみんなこの技術を同じことにしか使えていないという現実
	- https://x.com/mehori/status/1800239908713283836
	- そしてその限界は、できることから逆算して必ずしも必要としない機能をユーザーにおしつけることにつながっている
- very happy to be partnering with apple to integrate chatgpt into their devices later this year! by Sam
	- https://x.com/sama/status/1800237314360127905
- 旅行プランに迷う人は全員Geminiを使った方が良い。
	- https://x.com/SuguruKun_ai/status/1799695851968942167
- Appleの人工知能（生成AI）「Apple Intelligence」は、オンデバイス（データーをサーバーに送信せずに処理）を基本とするそうです。
	- https://x.com/gizmodojapan/status/1800231580788736014
- Apple WWDC intro was so lit
	- https://x.com/ai_for_success/status/1800214745078968712
	- ああ、空から、スカイダイビングして、アップル本社に降りるという画像、これは本物か？？
- AppleにここまでAIスマホ統合で先を越されたGoogleって今まで何してたの？マヌケですか？　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1800236837665206563
-  Mixture-of-Agents Enhances Large Language Model Capabilities
	- https://huggingface.co/papers/2406.04692
	- With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction.
	- we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology.
	- our MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni.
- 議事録取ってるならGemini 1.5 Flashは使った方が良い
	- https://x.com/keitowebai/status/1800006621780951533
	- 録画データをアップロードして「要点をまとめて」と言うだけで要約完了。これで報告は3分で終わらせようか。
- LLMに入力するプロンプトを書くときには言語化能力が必要、というのは正しいと思うのだけど、じゃあ言語化能力ってなんやねん、というときに、「構造化されていて分かりやすく、綺麗で論理的な文章」、ではない、と私は思っている。by mutaguchi
	- https://x.com/mutaguchi/status/1799899202803433571
	- 実はLLMくんはかしこくて、かしこくないので、ぜんぜん構造化されてない、論理も破綻していて、文字も間違いだらけで、言語としても成立していないようなぐちょぐちょテキストでも、勝手に雰囲気で補間・修正して読み取ってくれる。ただし、プロンプトには出力に必要な情報が過不足なく指定されていることは必要となる。
	- つまりプロンプトを書くのに必要な言語化能力というのは、LLMの出力（入力プロンプトに対する補完）を引き出すために必要な文字列を、過不足なく仕込む能力ではあるのだが、必ずしも人間が見て「この人言語化能力高いなあ」と評価されるような文章を書く能力が必要とされているとは限らない、と考えている。
- (LLMに入力するプロンプトを書くとき必要なのは)メタ言語能力、言語に対するメタ認知かな
	- https://x.com/erukiti/status/1799945431864254487
	- 会話とか言語化レベルではなく、言語を扱うLLMをhackするように、言語を間接的に扱う能力が必須。観察・気づき・制御・ねじ伏せ
	- 1. 対象のドメイン知識とボキャブラリが死ぬほど必要（ここまでは普通の言語能力。簡単やね、やった！） 
	- 2. LLMがどの程度理解が定まってるかの見極めが必要（一発で指定できるケースもあれば、説明文が必要、定義を一通り渡す必要などのケースもある。ここらへんはもう言語能力というよりメタ言語能力） 
	- 3. 2で見極めた範囲内で指示をどれだけ最低限に軽量化できるか？複雑な指示は、指示を解釈するところにLLMの知性を使いすぎて、指示そのものに追従できなくなることがあるから、指示に従えるギリギリ最小限を狙うことになる（メタ言語能力） 
	- あと、プロンプトやコードをLLMで生成するメタプロンプトやメタプログラミングみたいなのも普通に出てくるから、そういう意味でもメタ言語能力が必要だと思う
- If Apple integrates OpenAI at the OS level, then Apple devices will be banned at my companies. by maskさｎ
	- https://x.com/elonmusk/status/1800265431078551973
- 統計学の本質の一つは仮定にあると思う。 
	- https://x.com/1kn29cgQJzRwtgd/status/1800005796585259435
	- そもそも統計学関係なく、データを解釈する際、人間は仮定をおく。 通常それは暗黙の仮定だが、統計学はそれを明示し、その仮定でよいのかや仮定がズレることの影響を議論できるようにする。 仮定を明示し、議論の俎上にのせる。これが統計学の効能の一つ
- SEDDは離散データに対する拡散モデル。by 岡野原さん
	- https://x.com/hillbig/status/1800303691364470800
	- 離散版のスコアであるコンクリートスコア（p(y)/p(x)）をデノイジングスコアエントロピー最小化で求める。スコアエントロピーはELBOとみなせ尤度の下限を与えられる。言語モデルなどで同パラメータモデルに匹敵する性能。一貫性に優れる
-  To Believe or Not to Believe Your LLM　by DeepMind
	- https://arxiv.org/abs/2406.02543
	- Google DeepMindは、ある問題におけるLLMの知識不足（ハルシネーション）を確かめる方法を考案しています。
	- 同じ質問に対する回答のバラつきを見ることで、自信を持って正しい回答をしているのか、知識不足のために間違った回答をしているのかを判断できるとのことです。
-  Appleのオンデバイス・サーバー基盤モデルの概要 by npakaさん
	- https://note.com/npaka/n/ncd651c042e6a?sub_rt=share_h
	- 「Apple Intelligence」は、ユーザーの日常的なタスクに特化した複数の高性能生成モデルで構成されており、現在のアクティビティに即座に適応できます。
	- https://machinelearning.apple.com/research/introducing-apple-foundation-models
	- 「**約3Bパラメータを持つオンデバイスの言語モデル**」と「**Private Cloud Computeで利用できるサーバーの言語モデル**」が、特殊なタスクを効率的、正確、責任を持って実行するためにどのように構築および適応されたかを説明します。
	- AIツールの開発方法とそれを支えるモデルをガイドする責任あるAI原則を作成しました。
-  Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/html/2406.02061v1
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
- Sam Altman’s blue backpack didn’t show up today at Apple Park which is a notable shift for AI safety and preparedness.
	- https://x.com/RayFernando1337/status/1800366357902709184
	- どうも、アルトマン氏の青いバックパックには、ChtGPTを止めるスイッチが入っているらしい。
- Appleのクレイグ副社長、尋常でない運動能力を見せる。。
	https://x.com/durreadan01/status/1800453311382147219
- guide on finetuning an LLM to query knowledge graphs (through text-to-cypher).
	- https://github.com/neo4j-labs/text2cypher/blob/main/finetuning/unsloth-llama3/README.md#llamaindex
	- that allows you to directly use this LLM to generate cypher statements and retrieve knowledge graph entities as "chunks" for your Graph RAG pipeline!
- RecurrentGemma 9B 
	- https://huggingface.co/collections/google/recurrentgemma-release-66152cbdd2d6619cb1665b7a
	- This new model achieves performance comparable to the largest Gemma 1 model, but with significantly greater efficiency.
	- For example, on a single TPU-v4, it delivers 80x higher throughput when sampling 1k tokens from a 2k token prompt.
- Doing RAG? Vector search is *not* enough
	- https://techcommunity.microsoft.com/t5/microsoft-developer-community/doing-rag-vector-search-is-not-enough/ba-p/4161073
	- RAGにおいて、ベクトル検索だけじゃなく全文検索も加えたハイブリッド検索じゃないとパフォーマンスが出ないことを試してみた、というMicrosoft方の記事
	- RAG ＝ベクトル検索という風潮があるが、そうではない、と
-  Llama for Scalable Image Generation a.k.a LlamaGen
	- https://github.com/FoundationVision/LlamaGen
	- 拡散モデルを上回るTransformerによる画像生成
- Apple Intelligence の性能の自社評価の結果。
	- https://x.com/overlast/status/1800746455159963737
	- デバイス内モデルでは7Bモデルの上位に位置していて、サーバー内モデルではGPT-3.5 Turboを凌駕しているとのこと。粛々と性能を上げていて凄い |
-  RecurrentGemma-9b: 革新的な自然言語処理モデルの登場
	- https://hamaruki.com/recurrentgemma-introducing-a-revolutionary-natural-language-processing-model/
	- RecurrentGemmaは、従来のGemmaモデルをベースに、新しいリカレントアーキテクチャを採用することで、より効率的かつ高性能な言語処理を実現しました。
	- Colab notebook
	- https://colab.research.google.com/drive/1jDbbKhBs-A__QOtp7S6WxGxBH4J6gtuj?usp=sharing
-  Advancing personal health and wellness insights with AI
	- https://research.google/blog/advancing-personal-health-and-wellness-insights-with-ai/
	- Today on the blog, read about the latest from our two new research papers on how AI, particularly fine-tuned Gemini models, can create personalized health experiences that cater to individuals’ unique health journeys.
- LLM CLI tool are the cool things you can do with piping.
	- https://x.com/HamelHusain/status/1800741993276203043
- 最新のLLMの多くは「アリスにはN人の兄弟とM人の姉妹がいる。アリスの兄には何人の姉妹がいるか」という簡単な推論と常識を必要とする問題が解けないことを指摘。
	- https://x.com/shion_honda/status/1800895368458305643
- 「生成モデルの基礎と応用」の講義資料を公開します by 大阪大学　高橋先生
	- https://x.com/taka8hiroshi/status/1801177682450981251
	- 最尤推定からスタートして、深層生成モデルやTransformerを一通り理解しようという内容です。ぜひご覧ください
		- https://speakerdeck.com/takahashihiroshi/generative-models
- サカナAIが1年でユニコーン　日本最速､200億円追加調達
	- https://www.nikkei.com/article/DGXZQOUC144OB0U4A610C2000000/
- Oumuamua-7b-instruct-v2、Shaberi3ベンチマークで平均点7.25です by うみゆきさん
	- https://x.com/umiyuki_ai/status/1801836418744127702
	- GPT3.5T（7.16）やQwen2-7B（7.23）を超えてます。メッチャ強い
- 巨人オープンLLMで話題の Nemotron-340B お試し by AIXさとしさん
	- https://x.com/AiXsatoshi/status/1801865161717760380
	- 日本語推論、生成可能、オープンLLMとしては、知識は非常に正確
- RecurrentGemma 9Bは、Griffinアーキテクチャに基づいたGemmaモデル
	- https://x.com/webbigdata/status/1801928695764099084
	- Gemma 7Bは特定の知識ベースのタスク(科学、数学、プログラミング問題)で高いパフォーマンス 
	- RecurrentGemma 9Bは、常識推論や一般知識を必要とするタスクで高いパフォーマンス と言う違いがあります
	- RecurrentGemma 9BはHugging faceのTransformesrで微調整サポートはされていますが、issues見る限り危険な香りがするので
-  HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models
	- https://arxiv.org/abs/2405.14831
	- 知識グラフ、Personalized PageRank アルゴリズムを組み合わせたRAGの手法の提案。人間の脳の記憶の仕組みを模倣。
-  Nemotron-4 340B from NVIDA
	- https://research.nvidia.com/publication/2024-06_nemotron-4-340b
	- 昨日に出たNemotron-4 340Bも、人間が2万件、残り98%(98万件?)は合成データでalignmentした模様(?)
- サクッと論文読むならGoogleのNotebookLMを使ったほうが良い
	- https://x.com/tetumemo/status/1801889597871558864
- nvidia/Nemotron-4-340B-Instruct
	- https://huggingface.co/nvidia/Nemotron-4-340B-Instruct
	- https://x.com/webbigdata/status/1802173127767802234
		- モデルは商業的に利用可能です。 
		- 派生モデルは自由に作成および配布できます。 
		- NVIDIA は、モデルまたは派生モデルを使用して生成された出力に対する所有権を主張しません。
-  An Empirical Study of Mamba-based Language Models
	- https://arxiv.org/abs/2406.07887
	- Mamba2とTransformerの比較。学習量が1.1TtokenだとTransformerの方が精度が良い。一方3.5Ttoken学習するとMamba2が良くなる。
	- https://x.com/jnishi/status/1801842541639438494
	- ICLの性能はMamba2はTransformerに及ばないが、Mamba2とMLPとself-attentionを少しで構成したMamba2-HybridはICL性能は高い。
- nitky/Oumuamua-7b-instruct-v2
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
-  LLMFlex
	- https://github.com/nath1295/LLMFlex
	- LLMFlex。LangChainよりも色々と簡単にしつつ、StreamLitでフロントエンドUIまで付けてくれちゃってるブツ。こういうのありがたいね。GPTQやGGUFモデルがロードできる。DuckDuckGo検索ツールやドキュメントでRAGとかもパッとできる
- Dream Machine by Luma AI is just 3 days old.
	- https://x.com/hey_madni/status/1801900554488291414
	- 1. Distracted boyfriend
	- 2. Disaster girl with firefighters
- Ninja-v1のバージョンアップ、Ninja-V2-7Bをリリース致します。
	- https://huggingface.co/Local-Novel-LLM-project/Ninja-V2-7B
	- ベクトルマージ等の技術を活用し作成したMistralベースの70億パラメーターモデルです。
	- Gemini pro 1.0評価で Elyza taskで3.71 JP MT Benchで8.24
- Flaxを使用したRecurrentGemma2Bグリフィンモデルのファインチューニングチュートリアル(Kaggle、GoogleColabノート付)
	- https://x.com/hAru_mAki_ch/status/1802227933534429614
- Nemotron-4 340B is a huge release by NVIDIA!
	- https://x.com/omarsar0/status/1802024352851878296
	- The Nemotron-4 340B instruct model lets you generate high-quality data and then the reward model (also released) can filter out data on several attributes.
	- The results show that Nemotron-4 340B is a strong model. Check out those MMLU, GSM8K, and Arena Hard numbers.
- たとえばDream Machineに昔の写真入れて動画にすると、それは100%ウソのハズなのに、なんか50%くらい本当だったような気がしてくるというような
	- https://x.com/hirochuu8/status/1801986929183142369
- Exciting that our Mixture of Agents (MoA) tops the AlpacaEval leaderboard!
	- https://x.com/james_y_zou/status/1801656163936964919
- Ninja-V2-7BのShaberi3ベンチマークスコアは6.80でした
	- https://x.com/umiyuki_ai/status/1802027838524321839
- Can language models be used as world simulators? In our ACL 2024 paper, we show -- not really.
	- https://arxiv.org/pdf/2406.06485
	- GPT-4 is only ~60% accurate at simulating state changes based on common-sense tasks, like boiling water.
- nvidiaのファンCEO、Caltecの卒業式でスピーチ
	- https://x.com/shuki004/status/1801681153705054588
-  Lares smart home assistant: A toy AI agent demonstrating emergent behavior
	- https://interconnected.org/more/2024/lares/
	- This is a great little example of how simple agent-based systems can lead to emergent behavior, even with tiny AIs like Apple's on-device LLM.
	- Matt Webb built a demo AI smart home, when he asks it "turn on the light for my dog" the home figures out how.
- DreamMachineが危険なのは、生成動画を見たら「本人の記憶が上書きされる」点だと思う
	- https://x.com/genmeisui/status/1801944958062239884
	- 例えば痴漢冤罪の人に「触った瞬間の動画が見つかった」と生成動画を見せ続けたら、「やったかも」と思い込ませることは難しくない
- 予想はしていたけど5人目が出てきた時点でダメだった [#DreamMachine](https://x.com/hashtag/DreamMachine?src=hashtag_click)
	- https://x.com/kizuki_jpn/status/1801950889747354076
-  Coupled Ocean-Atmosphere Dynamics in a Machine Learning Earth System Model
	- https://arxiv.org/abs/2406.08632
	- New Earth-2 nvidia preprint about AI forecasting for seasonal timescales including interactive ocean coupling. The generated El Niño looks realistic including its subsurface thermal structure. Internship project led by 
- GPT-4レベルのNemotron-4-340B無茶苦茶脆弱
	- https://x.com/maksym_andr/status/1802011165670735946
	- leads to 100% attack success rate on 50 harmful requests from AdvBench using GPT-4 as a judge. There is no need to do any random search or random restarts, the model just complies directly.
- AI革命、すでに失速している
	- https://newspicks.com/news/10094191/body/
	- 学習データの不足でモデルの性能向上の頭打ちが見えており、運用が高コストに。現時点ではAIの利用シーンも限定的のため、収益成長も伸び悩むと
- nitkyさんが、新たなマージ7Bモデル Oumuamua-7b-instruct-v2 を出してくれました。
	- https://huggingface.co/nitky/Oumuamua-7b-instruct-v2
	- ７Bサイズながら、⌘R+以上、GPT3.5未満みたいなベンチマークらしいです。
- Oumuamua-7bのElyzaTasks100スコアは3.85でした。相当強いです by うみゆきさん
	- https://x.com/umiyuki_ai/status/1797191209976537102
- 『何回説明しても伝わらないはなぜ起こるのか？』（今井むつみ）
	- https://x.com/JunkudoT/status/1791361304655241449
	- 人間は聞き逃し、都合よく解釈し、忘れる。そんな人間同士がそれでも伝え合うことは可能なのか？理解し合うことが難しい世の中で「伝えわかり合う」ことに探求するあなたをサポートする一冊です。


## 6/10

今週はNotebookLMがすごかった。LLMの躍進にやられぱなしであるが、LLM活用で希望を持てる事例も。理論面では、Transformerの次のアーキテクチャと下馬評の高いMambaであるが、CMUによるMamba-2の提案では新しく導入された状態空間双対性(SSD)によって、Transformerに匹敵する性能を達成しながら、Transformerよりも効率的にスケールするそうだ。岡野原さんによるとtransformerとSSMが統一されたとのこと。LSTMを改良してtransformer並みのスケーラビリティがあるというxLSTMというのも気になる。OpenAIがGPT-4の内部表現分析に活用した**k-Sparse Autoencoders**って、Anthropicがつい最近発表したスパースオートエンコーダの利用と同列か、なおスパースオートエンコーダ自身はICLR 2014 で発表されたと著者がツイート。さて、新しいLLMの発表では、アリババがQwen2を発表、全体的にLlama3超えとか、最上位モデル以外はApacheライセンスとか、ollamaがさっそく対応とか、7B-instructのお試しをhuggingface spaceにAIXサトシさんが提供とか、にぎやかだ、これからの評価が気になる。GLM4-9Bって 智谱AIのモデルも相当性能が高いらしい、双方とも中華LLMらしく日本語堪能なのだがライセンスには注意が必要とのこと。GoogleのGemini 1.5 Proだって日本語性能すごい、布留川さんのGoogle Gemini 1.5の新刊もでるので、是非お試しを。 Google AI Studioで無料お試しでそのポテンシャルは明らかなわけであるが、gpt-4oに話題を持っていかれ気味。そこで、一気に挽回というわけではないが、Gemini 1.5 ProをバックエンドにもつNotebookLMの試行が開始。PDF、テキスト、URLをソースとして登録すると、そのソースに対して、概要やFAQ、さらにはチャットによる応答と根拠箇所の表示ができるという代物。いや、ローカルドキュメントでRAG作るみたいな話は全部吹っ飛ぶような話ではあるが、生成の部分の抽出の部分のバランスが正味どれくらいかこれからの評価が気になる。AIに情報をまとめてきてもらうついでにそれをWeb記事の体裁でまとめて公開するPerplexity Pagesなんかも、そうだけど、各社ともチャットの次のキラーアプリを探して試行している感じかなー。最悪のシナリオはこれらの試行の結果、使いこなせる人は少なかったという結論になること。kobayashiさんの、「LLM を使いこなせる人 ＝ 言語能力が高い人」というのは、このような能力を得るには、リスキングでは追いつけないという身もふたもない話。AIリテラシーはいかに言語能力を上げるかにかかっている。言語能力が高い人の例とは、例えば、コンサルタントが本物か偽物かを見抜く１０の質問みたいなやつができる人か。一方NTTのstreamitを使ったAIの民主化とか、概念データモデルをつかったデータの整理など、現場にはまだ力があって、これを生成AIを使って会社のDXにつなげるってのも、希望を持てるLLM活用パターンな感じがしてきた。これらに比べてAIで生産性を上げて人手不足を解消し、余った人向けに転職促進という、政府の成長戦略の薄っぺらいことよ。放送大学の教科書『自然言語処理』の改訂版と三訂版の比較、いかに言語処理の基本構成がtransformerの登場で大きく書き換わったかが目次だけでもよくわかる。しかし、「知識グラフって最近聞かなないなあ」とは、小町先生冷たすぎ。GraphRAGとかProperty Graph Indexとか、LLM応用界隈では知識グラフはまだホットだし、Document Intelligenceのようにハルシネーションを抑える手段としての知識の重要さもわかってきたところなんですけど。最後に、Hassabis がインタビューで言及したProject Astra(Goole I/O 2024でデモしたやつ）、あと１から２年でリリース、普通の人が使えるアシスタントとしてゲームチェンジャーになるとのこと。

- Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality
	- https://arxiv.org/abs/2405.21060
	- 現在生成AIで主流のTransformerの「次」のアーキテクチャとして期待されるMamba-2を提案
	- **状態空間モデル（SSM）** は、構造化行列 を用いることで、従来のアテンションと密接に関連していることが明らかになり、
	- 状態空間モデル（SSM） と アテンション の変種との間の理論的な関連性を示すフレームワーク**状態空間双対性（SSD）**を提案
	- その結果、線形時間計算 と 二次時間計算 の両方の形式を持つことが示されています。
	- この 状態空間双対性（SSD） フレームワークは、Mamba-2 と呼ばれる新しいアーキテクチャの設計を導き、言語モデリングにおいてTransformerに匹敵する性能を達成しながら、Transformerよりも効率的にスケールします。
	- Mamba2は新しく導出されたSSDを使い、系列長に対し線形の計算量、メモリ使用量で効率的に学習、推論でき、TransformerやMambaよりPPLや下流タスクで性能が高い。SSMとTransformerが統一的な枠組みで扱えることも示す by 岡野原さん
- GPT-4 is 1.8T MoE, thanks Nvidia Presentation
	- https://x.com/literallydenis/status/1797531945926287497
- LLMを活用した大規模商品カテゴリ分類への取り組み
	- https://engineering.mercari.com/blog/entry/20240411-large-scale-item-categoraization-using-llm/
	- GPTを商品カテゴリ分類に活用した事例と工夫したポイントがまとまっているよ
		- EmbeddingモデルはOSSでも問題なし
		- GPT4はコスト的に使えなかった
		- max_tokensとChain of Thought での効率化
		- Numbaへの書き換えもGPTを使って効率化
-  Hugging FaceのZeroGPUでAIのデモを作る方法: 初級編
	- https://qiita.com/alfredplpl/items/abb30283b578dc984d16
	- ZeroGPU とは、デモの利用者が使う瞬間だけ高性能なGPUが借りられるというサービスです。現在はA100 40GBが一瞬借りられます。これを実現できているのは世界でHugging Faceだけでしょう。お値段は月額9ドル（約1500円）です
	- Hugging FaceのZeroGPUはAIのデモを作るのに最適だとわかりました。いかがでしたでしょうか。ぜひみなさんもデモを作ってみてください。なお、私は責任を持ちません。
- lmsys.org でGoogleのGemini 1.5 Pro（5/14モデル）が日本語で世界一になりました。２ヶ月前のモデル (4/9モデル）よりかなり改善されました
	- https://x.com/shanegJP/status/1797798176344453414
- Perplexity Pages、AIに情報をまとめてきてもらうついでにそれをWeb記事の体裁でまとめて公開できちゃうのかあ。
	- https://x.com/umiyuki_ai/status/1797871157850620270
- 富士通は、特化型の生成AI混合技術とナレッジグラフ拡張RAGというマニアックな方向に進化することになりました。
	- https://x.com/AsamaKotaro/status/1797844740328804563
-  the benefits of Google Gemini's gigantic 1 million token context window in action!
	- https://x.com/llama_index/status/1798049438814081138
	- In this quick notebook, we show Gemini built into a LlamaIndex agent attempting to answer a multi-part question from a set of complicated, heterogeneous documents.
- 富士通の研究戦略発表会、最適化問題と生成AIによる制約条件の生成が相性が良いという発想
	- https://x.com/tokoroten/status/1797851927457546682
	- 議事録やマニュアルから制約条件を起こしたり、AIとの対話を通じて制約条件を起こしたり
- 概念データモデルから始める真にデータドリブンな製造業DX
	- https://www.qunie.com/quriosity/231218_00/
	- 概念データモデルは個々の業務改革やモダナイゼーションに着手する前に作成するデータモデルである。特定の業務領域だけでなく、製造業のバリューチェーン全体をモデルとして表現する。
	- 論理データモデルのような厳密さは不要で、関連するデータをグループ化したデータ群と、そのキー項目（全てのデータ項目は不要）、データ群のつながりを示す。
	- バリューチェーン全体を俯瞰した概念データモデルがあるからこそ、企業全体の改革に一本の芯が通ることになるのだ。あるお客さまは、概念データモデルのことを“自社の憲法”と表現されていたが、まさにその通りである。
- ELYZAが、国立研究開発法人 産業技術総合研究所が募集した大規模生成AI研究開発支援プログラムに採択されました。
	- https://x.com/ELYZA_inc/status/1797780304717078689
-  論文解説をGPT-4oを使って自動的に生成してみる by 逆瀬川さん
	- https://qiita.com/sakasegawa/items/8e17ede26dd96e7e3280
	- PDFを画像として取り扱うと処理は遅いが格段に安い！！ 
	- 論文のPDFを画像として扱い、GPT-4oで落合メソッドを使って解説を生成させる
	- 論文のPDFから数式や図表を抽出し、個々に解説を生成
- もはやAIの性能を人間が測定できない by  karaage. [からあげ]さん
	- https://karaage.hatenadiary.jp/entry/2024/06/04/073000
	- そもそもAIの性能を人間が測定するのが難しい領域に来ているなと実感しました。
- Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming
	- https://arxiv.org/abs/2406.00592
- LLM Basics - Why can't we use regular LoRA for pre-training LLMs
	- https://x.com/rohanpaul_ai/status/1797759219891937324
	- LoRA (Low-Rank Adaptation), targets a subset of a neural network's parameters, specifically focusing on the weight matrices of transformer models. It represents these large matrices as the product of smaller
- Why AI wont take your job just yet
	- https://medium.com/@starloba/why-ai-wont-take-your-job-just-yet-13e95cd05da8
	- 汎用的なタスクをAIに解かせるようになると、人間はよりクリエイティブな問題に注力できるようになる。より正確に言うなら、強制的に注力しないといけない状況に追い込まれる。
- Microsoft has built a weather forecasting model named 'Aurora
	- https://x.com/MSFTResearch/status/1797662278394827029
-  Heuristics on the high seas: Mathematical optimization for cargo ships
	- https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/
	- Today we present new solutions to the Liner Shipping Network Design and Scheduling Problem, released as part of our new Shipping Network Design API, with the goal of maximizing the efficiency of container shipping networks at world-wide scale
- Unslothはこの論文に対抗してLoRAでの継続事前学習を徹底的に最適化した結果、今までのLoRA学習の２倍の効率で学習できて、VRAMも半分で済む
	- https://x.com/umiyuki_ai/status/1798221784334160262
	- 24GBのVRAMでLlama3-8BやMistral-7BがLoRA継続事前学習できる
- GLM4-9Bだって。26言語対応。GPT-4に匹敵する関数呼び出し能力
	- https://x.com/umiyuki_ai/status/1798292824544420150
-  中国製LLMのライセンス問題と国安法について
	- https://note.com/willplion/n/n2710f60b381a
- 継続事前学習(CPT: Continued Pre-Training)をQLoRAでやろうとする試み
	- https://x.com/webbigdata/status/1798313713654776062
	- Colab無料版でもmistral-7b-v0.3なら十分動きました
	- llama3 8bやgemma7bでは有料版のL4(24GB)でもメモリ不足になってしまいましたがllama2という手もあります
-  佐賀の織田病院がオンプレGPUサーバーでLLM稼働、電子カルテ情報を生成AIが要約
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09236/
	- これまで利用してきた電子カルテシステムにオプティムが提供する生成AI「OPTiM AI」を組み合わせ、看護師の業務効率を高める実証に乗り出し
	- 米NVIDIAのRTX A2000を搭載したGPU（画像処理半導体）サーバー1台を新たに院内に用意した。LLMの学習や推論に用いる
- Introducing AI Agents in LangGraph!　 by Deeplearning.ai
	- https://x.com/DeepLearningAI/status/1798376731188834780
	- In this course taught by hwchase17, LangChainAI CEO, and weiss_rotem, tavilyai CEO, you’ll learn to use LangGraph to create controllable agents, and agentic search for agents to enhance their output.
- ChatGPTでレ・ミゼラブルの人物相関3Dネットワークグラフを作成
	- https://x.com/itnavi2022/status/1798320618695438647
- GLM4-9B-ChatをElyzaTasks100で評価した by うみゆきさん
	- https://x.com/umiyuki_ai/status/1798328337699606704
	- スコアはなんと3.92！！やべえ！！！！Gleipnir-7Bの3.91より勝ってる！メチャクチャかしこい！このモデル、スペックだけのコケオドシじゃない！
- ReFT: Representation Finetuning for Language Models
	- https://x.com/rohanpaul_ai/status/1798026828017197256
	- 10x-50x more parameter-efficient than prior state-of-the-art PEFT methods.
- Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks
	- https://arxiv.org/abs/2406.02550
-  xLSTM: Extended Long Short-Term Memo	
	- https://arxiv.org/abs/2405.04517
	- LSTM（Long Short-Term Memory）を改良し、数十億パラメーターの言語モデルにおいてTransformer並みかそれ以上の拡張性（スケーラビリティー）を持たせたという。
-  In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter Optimization
	- https://arxiv.org/abs/2404.16795
	- ベイズ最適化は更に革新的に!
	- この論文では、トランスフォーマーベースのPFNを活用した"In-Context Freeze-Thaw BO"を提案!
	- 従来手法に比べ10〜100倍高速かつ精度良く学習曲線を予測できるという驚きの結果!
- 『Google Gemini 1.5／LlamaIndex／LangChain 人工知能プログラミング実践入門』の出版記念イベント
	- https://x.com/npaka123/status/1798557659693781217
	- 25年間で技術書49冊、年間300以上の技術記事を書いている著者が、Google Geminiの最新技術情報に加えて、マルチモーダルとローカルLLMの未来予想を紹介します。
	- https://studyco.connpass.com/event/319990/
- Qwen2が来た！0.5B、1.5B、7B、57B-A14B、72Bの５種類
	- https://x.com/umiyuki_ai/status/1798762190729777185
	- 1.5から性能バキバキに上げてきた！全体的にLlama3超え！
	- 72Bは今までと同じライセンスだけど、他のモデルはApacheライセンスに変更
- GoogleNotebookLM
	- https://notebooklm.google/
	- Gemini1.5Proを使ったRAG専用のチャットサービス。
	- 約５万字の本を入力して質問してみたのだけど、GPT-4oでもClaude3でも微妙だったのに、結構いい感じの回答でビックリしたのだ。
- 時系列基盤モデルによる株価データ(多変量)の類似度算出と検索
	- https://note.com/hatti8/n/n6c1a91a3b6ba?sub_rt=share_pb
	- 時系列基盤モデルを使って、 ・多変量の時系列データEmbedding作成 ・時系列データ同士の類似度を算出 というのを試してみました。
- Hello Qwen 2!　by ollama
	- https://x.com/ollama/status/1798807013327241302
	- ollamaが qwen2に対応
-  Extracting Concepts from GPT-4
	- https://openai.com/index/extracting-concepts-from-gpt-4/
	- OpenAIは先ほどLLMの動きを理解するための研究を共有。GPT-4の内部表現を1600万の特徴に分解することに成功したことを発表。
- GoogleのAIサービスである「Notebook」
	- https://x.com/kensuu/status/1798876734298935771
	- 本のPDFをアップロードする - すると中身が全部左側に出てくる
	- AIに色々質問ができる - 答えに出てきた部分を左側で読める 
	- 回答をピン留めするとメモとして保存できる。メモを自分で書くこともできる
- Qwen2-7BをさっそくElyzaTasks100にかけたらスコア4.01！！！ by うみゆきさん
	- https://x.com/umiyuki_ai/status/1798777448282378254
- Qwen 2 みんな触られましたかね？指示性能と知識えぐない..　by ぬこぬこさん
	- https://x.com/i/bookmarks
	- 0.5B の海外モデルで日本語話せるなんて聞いていないよ...
- Qwen2-7B-instructのデモをスペースに設置しました by AIXサトシさん
	- https://huggingface.co/spaces/aixsatoshi/Qwen-7B-instruct
- Recipes for open source / local agents w/ Llama 3
	- https://x.com/LangChainAI/status/1799109018163761588
	- https://github.com/meta-llama/llama-recipes/tree/main/recipes/use_cases/agents/langchain
- From simple to advanced Agents
	- https://x.com/jerryjliu0/status/1799107241695715773
	- Before you build a complex multi-agent systems, learn the core abstractions for building a single powerful assistant over your data: routing, memory, tool use, and sequential to DAG-based planning.
- It's finally possible: real-time in-browser speech recognition with OpenAI Whisper!
	- https://x.com/xenovacom/status/1799110540700078422
- Democratizing Data Across NTT docomo with Streamlit
	- https://x.com/pei0804/status/1798501802415210935
	- streamlitを使った誰でもデータを使って洞察を得られる環境を作った話。 めちゃくちゃ良すぎて最高だった。ここまでやり遂げてることに、本当に尊敬しかない。ちなみに、今後の展望も良すぎた。
- 何が凄いのか？最新の技術GraphRAGについて解説してみた
	- https://www.youtube.com/watch?v=PqAgkfg0MA0
- 政府の成長戦略発表されました！
	- https://x.com/sirap_kuro/status/1799032255828140169
	- AIで生産性向上/人手不足解決、
	- そのあとに襲ってくる一般ホワイトカラーの需要減/失業などには、転職を促すことによって対処。
	- 普及の足かせになる安全/安心懸念については、政府で”AI制度研究会”を開き、議論。
	- また政府自身AIを調達する。
- Demis Hassabis says he is most excited about DeepMind's work on Universal Multimodal AI Agents (Project Astra).
	- https://x.com/electrik_dreams/status/1799139945560363264
	- These agents, to be launched in 1-2 years, will serve as highly intelligent assistants for all general humans tasks, and "will be a pretty big game changer", he thinks.
- Introducing GraphRAG with LangChain and Neo4j
	- https://medium.com/microsoftazure/introducing-graphrag-with-langchain-and-neo4j-90446df17c1e
	- Great introduction to using Graphs - instead of pure vector DBs - to power RAG applications
	- The relationships that graphs provide can empower better retrieval which can yield better answers
- Graph RAG makes sense if you think about it as a superset of "standard" vector RAG:
	- https://x.com/jerryjliu0/status/1797057726994092492
- コンサルタントは本物と偽物が混在　実力を見抜く10の質問
	- https://bookplus.nikkei.com/atcl/column/041500053/052900298/
- Safety Alignment Should Be Made More Than Just a Few Tokens Deep
	- https://xiangyuqi.com/shallow-vs-deep-alignment.github.io/
	- 1. Crrent LLM safety alignment is only a few tokens deep. 
	- 2. Deepening the safety alignment can make it more robust against multiple jailbreak attacks. 
	- 3. Protecting initial token positions can make the alignment more robust against fine-tuning attacks.
- LlamaIndex Introduces the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- In addition to the existing KnowledgeGraphIndex, LlamaIndex's new Property Graph Index enables:
- i heard people are rediscovering ReNet in its (almost) 10y anniversary
	- https://x.com/kchonyc/status/1799067177276014784
- Open-Endedness is Essential for Artificial Superhuman Intelligence
	- https://arxiv.org/pdf/2406.04268
	- "In this position paper, we argue that the ingredients are now in place to achieve open-endedness in AI systems with respect to a human observer. Furthermore, we claim that such open-endedness is an essential property of any artificial superhuman intelligence (ASI)."
-  An Easy Way to Comprehend How GraphRAG Works
	- https://towardsdatascience.com/an-easy-way-to-comprehend-how-graphrag-works-6d53f8b540d0
	- In a beginner-friendly explainer, Rendy Dalimunthe introduces GraphRAG, explains how it works, and outlines its benefits compared to traditional retrieval-augmented generation systems.
- OpenAI is using "k-Sparse Autoencoders" (my ICLR 2014 paper) to extract interpretable features from GPT-4,and showing that it outperforms other methods on sparsity-reconstruction frontier:
	- https://x.com/AliMakhzani/status/1799472688026517666
	-  k-Sparse Autoencoders
		- https://arxiv.org/abs/1312.5663
- 放送大学の教科書『自然言語処理』の改訂版と三訂版の比較
	- https://yudukikun5120.hatenadiary.jp/entry/2024/01/20/003314
	- 全体的に系列・意味論・構文論等の分野ごとに分離されていた古典的手法が、単一のニューラルネットワーク的手法に圧倒されていくさまを見ることができる。
	- 「今日では、超大規模コーパスで学習される汎用言語モデル（8章）が非常に強力であり、自然言語処理の観点では知識グラフの相対的価値は減少しつつある (p.44)」
	- 確かにもう自然言語処理では知識グラフってそんな言わないかな。。
		- https://x.com/mamoruk/status/1799070548863205470
- 「LLMの回答結果を評価する仕組み作り」は「LLMから良い回答を引き出すこと」と同じくらい重要です。
	- https://x.com/hiro_gamo/status/1799470543491694643
- 深層学習を含む多くの実応用モデルでは，パラメータ空間上でフィッシャー・ラオ計量が退化し，双対平坦構造が定義できなくなる．すなわち情報幾何が展開できなくなる
	- https://x.com/hayashiyus/status/1799457123103072282
	- すなわち情報幾何が展開できなくなる．双対平坦構造を一般化した概コダッチ構造を導入することでこの課題を克服した論文
- Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models
	- https://arxiv.org/pdf/2406.02061
	- This paper investigates the dramatic breakdown of state-of-the-art LLMs' reasoning capabilities when confronted with a simple common sense problem called the "Alice In Wonderland (AIW) problem".
	- The AIW problem is a concise natural language task that asks: "Alice has N brothers and she also has M sisters. How many sisters does Alice's brother have?" While easily solvable by humans using common sense reasoning (the correct answer is M+1), most tested LLMs, including GPT-3.5/4, Claude, Gemini, LLaMA, Mistral, and others, show a severe collapse in performance, often providing nonsensical answers and reasoning.
- アリス問題による日本語推論能力の比較
	- https://note.com/willplion/n/n5842538dd13d
	- 「女の子のアリスには4人の兄弟と1人の姉妹がいます。アリスの兄弟には何人の姉妹がいますか？」とし、LLMがアリスの性別がわからない為答えられませんとか言い出すことがないように調整した。
	- ほとんどのLLMプロバイダーの上位モデルにおいては、アリス問題に関しては回答ができることがわかった。特に最新のモデルであれば答えられて当たり前といった状態になっている。
- 『今の生成AIの本質的な難しさは「何をAIに生成させるしても、全て適確な言葉を使ってAIに指示を与えたほうが結果が良い」ということ』
	- https://x.com/izutorishima/status/1799568010950348942
	- 「LLM を使いこなせる人 ＝ 言語能力が高い人」と言い切れるくらいには ChatGPT を使いこなせてる人が少ない最大の理由
	- この使う人の言語リテラシーに相当依存するという仕様は、技術面ではなかなか個々人の差を埋めることはできないんじゃないかという懸念がある。何故なら、どんなにAIが頑張っても、そのAIがサポートする人間の言語能力の引き上げには限界があるから。
	- この言語能力の育成と強化という課題は、本来は大学教育以上のレベルで行われる過程で、自分の経験では大学院の研究室などで日々叩かれることによって磨かれる種類のものだと思っている。そういう点では、例え大卒の学歴を持っているとしても、本気でAIを本質的に使いこなせるようになるように再教育するためには、いわゆる「社会人のリスキリング」どころではないレベルの再教育が本当は必要なのだろう。
	- https://x.com/nyaa_toraneko/status/1799302550841364919
- AzureのサービスでGPT-4oを強化すると最強だというのが分かってもらえると思う。
	- https://x.com/super_bonochin/status/1799452550665773447
	- GPT-4oは、日本語OCR周りが強化されたとはいえ、特に手書きとかだとまだまだハルシネーション気味。 ワイのアプリではGPT-4oによる画像認識に、Document Intelligenceによって構造化した情報を付加することで、精度を飛躍的に上げることに成功しているのだｗ
		- https://x.com/super_bonochin/status/1799445107579695606
- NotebookLM、やっとコンセプトがわかったのですが
	- https://x.com/0317_hiroya/status/1799617523148796068
	- 【AIチャットボット + RAG】 
		- AIが主で、情報源が従 
		- 情報源を使うようになるけど、AIが学習した内容と合わせて、回答を生成する 
	- 【NotebookLM】 
		- 情報源が主で、AIが従
		- モデルは、資料のみを利用できるように設計されている。
-  Scalable MatMul-free Language Modeling
	- https://arxiv.org/abs/2406.02528
	- Claims that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales and by utilizing an optimized kernel during inference, their model’s memory consumption can be reduced by more than 10× compared to unoptimized models.
	- これまじ。FPGA試作でもそんな性能出るんかい "The accelerator processes billion-parameter scale models at 13W beyond human-readable throughput"

## 6/3

Google I/Oで発表されたgoogleの検索x生成AIが、とても不評ということで、Wall Street Journalの記事にもあるように、Perplexityの優秀さが際立つ、gooleがプレスリリースした新技術で期待を裏切るのは全く恒例ですね。とはいっても、Gemini 1.5 Pro/Flashの優秀さもあちこちで報告されており、本当は優れてるんでしょう。Mistralからコード生成のOSSであるCodestralが発表、さっそくOllamaが対応、これでお好きなエディタと組み合わせてプログラミングのアシスタントが実現可能に。量子化、小規模化にも進展があり、Mixtral 8x22b の量子化版Q6_K が $362 CPU(AMD Ryzen 9 5950X BOXか?)で軽々動作するという報告もあったり、Phi-3-Tinyシリーズのように、さらに小ささなLLMにチャレンジみたいな展開もあった。llama.cppで量子化版を動作させるとollamaより1.8倍速いという報告も。生成AIの飛躍的性能アップの秘密といわれる「グロッキング」に関する論文、汎化回路形成の秘密に迫り、新たなアーキテクチャ提案というのは胸熱い。生成AIの「創造性」に関する１０万人の人間！との比較で、GPT-4ならプロンプトを工夫すれば、人間を上回るというのには驚いた。O'ReillyからPrompt Engineeringの新刊も出るが、そもそもAnthropicのClaude3は、ゴールを与えれば適切なプロンプトを生成してくれるという。財務諸表から将来の収益の伸びを予測するタスクでGPT-4は人間より優れていると聞いても驚かなくなった。そんなAIですが、AIが他者の心や意図を理解する能力を持っているのかの「心の理論(ToM:Theory of Mind)」を持っているかどうかを分析した論文では、GPT-4 and Flan-PaLM が人間の大人のレベルに達したとのこと。さらに人間を超えるという意味では、Autoformalizing という、人間が作った幾何学をAIが自動証明できる体系に、生成AIをつかって作り直すという試みもあった。こうなると人間の理解がどこまで生成AIについていけるかという点が心配になる、ニューラルネットの動作理解の「Graph Game」や、LoRaの原理の可視化など、そういうのも目立った気がする。全く反対にアセモグル氏のように、それほどAIは格差拡大に影響しないという分析もあった。安全性に関しては、RAGを前提としたバックドアTrojanRAGというのも出た、説明性が高いこととバックドアを仕込みやすいというのは表裏一体。さて日本では、人工知能学会が浜松で開催、岡崎先生のスライド「大規模言語モデルの開発」は必見です。一方、ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果で、なんとナイジェリア英語のdelveという単語が生物系の論文に大量に表れたとの報告もあった。そもそも人間のほうも、エビデンスベースで合理的に思考する能力に課題があり、ストーリーに流されがちとの指摘があるので、ストーリー性を求めすぎて、合理的に思考できない生成AIができるかも。ロイヤルアカデミーの「AI in Science」すでに「AI for Science」といっている時代ではなくなった、つまりAIを使わずに科学の進展はない。さてNASAから満を持して、大気現象を予測する基盤モデルAuroraの発表、10kmメッシュで10日後まで天気予報できるってどれぐらいすごいのだろう。全くの余談だが、gpt-4oの発表時に参照された映画"Her"の監督の離婚した妻が監督した "Lost In Translation"の２つを比較し、一部シーケンスが全く対照的にアライメントしているという話題がテック界隈で一瞬話題になった。

-  自分がどれくらいニューラルネットワークを理解しているかを確かめられるゲーム「Graph Game」
	- https://gigazine.net/news/20240526-graph-game/
- googleの検索x生成AIについては，ちょっと評価がイマイチなんですよね．油と水を無理やり混ぜようとしている感がある．by 今井さん
	- https://x.com/ImAI_Eruel/status/1794707281600496111
-  TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models
	- https://arxiv.org/abs/2405.13401
	- RAGを悪用したバックドア攻撃。RAGで使用する知識DBに細工データを注入し、（DBから関連データを検索する）リトリーバとDB間でバックドアリンクを作成する。これにより、トリガーとなるPromptが入力された場合のみ、LLMに悪意のある回答を生成させることができるとのこと。
- We're now able to run Mixtral 8x22b Q6_K on a $362 CPU with better than human reading speed.
	- https://github.com/Mozilla-Ocho/llamafile/discussions/450
- llama.cpp runs 1.8 times faster than ollama
	- https://x.com/rohanpaul_ai/status/1794470545586635238
- Exploring the Impact of ChatGPT on Wikipedia Engagement
	- https://arxiv.org/pdf/2405.10205
	- Wikipedia remains the crowning achievement of Internet 1.0. It powered the rise of search engines (which depend on it) & generative AI (trained on its data).
- Grokked Transformers are Implicit Reasoners:A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/pdf/2405.15071
	- 1) Transformers can learn to implicitly reason, but only through extended training far beyond overfitting, a phenomenon known as grokking.
	- 2) Transformers exhibit different levels of systematicity in generalization across reasoning types: ID generalization is consistently observed, OOD generalization fails for composition but succeeds for comparison tasks.
	- 汎化回路形成の秘密に迫り、あたらなアーキテクチャを提唱している
-  Phi-3-Tiny-Untrained
	- https://colab.research.google.com/drive/188RpybbauEJKSIRPGL3RZi4Lk66HfBJj
	- This 50M-parameter model reconfigs Phi-3-mini-128k-instruct (3.8B parameters) by following the parameters given by the Super Tiny Language Models from A*STAR.
-  GPT-4は財務諸表から将来の収益の伸びを予測する点で人間のアナリストよりも優れていることが研究により明らかに
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311
- The Wall Street Journal says perplexity outperforms chatgpt, gemini & claud
	- https://x.com/RubenHssd/status/1795108714564706452
- DifyとOllamaを使用してローカルLLMを構築し、複数のLLMエージェントを設定してAIが社会に与える影響について議論を行い、その結果を記事として生成する手順について説明します。
	- https://hamaruki.com/how-to-configure-and-discuss-multiple-agents-using-dify-and-local-llm/
-  How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?
	- https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms
	- In April, there were four major open LLM releases: Mixtral, Llama 3, Phi-3, and OpenELM.
- Decoder-onlyなLLM（Mistral-7B）をtext embedding用にファインチューニング（LoRA）してMTEBでSoTAを達成した方法NV-Embedの提案
	- https://x.com/s_tat1204/status/1795344530285457626
- Google Search algorithm leaked today.
	- https://x.com/hridoyreh/status/1795394077510517217
-  Autoformalizing Euclidean Geometry
	- https://arxiv.org/abs/2405.17216
	- Can AI transform human mathematics into formal theorems and proofs that machines can verify?
	- This process, known as autoformalization, is a key step towards AI mathematicians. We introduce a neuro-symbolic framework for autoformalization, focusing on Euclidean geometry and combining domain knowledge, SMT solvers, and LLMs.
- Mixtral 8x7B Instruct with AWQ & Flash-Attention-2 in ~24GB GPU VRAM!
	- https://x.com/rohanpaul_ai/status/1795196332166070289
	- With the latest release of AutoAWQ - you can now run Mixtral 8x7B MoE with Flash Attention 2 for blazingly fast inference.
-  Automatic Domain Adaptation by Transformers in In-Context Learning
	- https://arxiv.org/abs/2405.16819
	- 幡谷さん（理研特別研究員）と松井先生（名大）の研究を公開しました。トランスフォーマーがインコンテキスト学習において、複数のドメイン適応法を表現し、さらにデータに応じて適切な適応法を選択する能力を持つことを理論と実験で示したものです。
- Training and Finetuning Embedding Models with Sentence Transformers v3
	- https://huggingface.co/blog/train-sentence-transformers
- ちなみにGemini 1.5 Proではapplication/jsonを出力フォーマットとして選択できて便利
	- https://ai.google.dev/gemini-api/docs/api-overview?hl=ja#json
- CLARINET: Augmenting Language Models to Ask Clarification Questions for Retrieval
	- https://arxiv.org/abs/2405.15784
	- Fine-tunes an LLM to ask clarification questions that maximize retrieval success for ambiguous search queries, outperforming heuristic methods and vanilla language models
- 映画herとLost In Translationの監督は離婚した元夫婦であり、その画像の一部はシンクロしている。。
	- https://x.com/MissSassbox/status/1795205212770119782
	- I had no idea that "Her" and "Lost In Translation" were clapbacks by the directors to each other after their divorce and now I need to watch both
	- Tech界で、gpt-4oのデモが、、映画herを意識して作られていたことから、（再？）発見された雑学
- Introducing Transformers Agent 2.0: A Leap Forward in Intelligent Automation
	- https://huggingface.co/blog/Andyrasika/transformer-agents
- 松田語録：Gemini 1.5 Proを論文を読むのに使ってみた〜良いところと悪いところ
	- https://x.com/npaka123/status/1795568613900062747
- ChatTTS: a powerful voice generation model designed for conversational scenarios
	- https://github.com/2noise/ChatTTS
	- https://huggingface.co/2Noise/ChatTTS
- 『エビデンスを嫌う人たち　科学否定論者は何を考え、どう説得できるのか？』by 暦本先生
	- https://x.com/rkmt/status/1795636068752212063
	- おおー。しかしエビデンスベースで思考する人類はむしろ少数派かもしれない..(System1思考=Fast Thinking > System2思考 Slow Thinking) 。エビデンスよりもストーリーが優先する.
- 進化的マージによって相当強そうなモデル、Umievo-itr012-Gleipnir-7Bが生まれました。3回ElyzaTasks100で評価した平均スコアは3.91！　by うみゆきさん
	- https://huggingface.co/umiyuki/Umievo-itr012-Gleipnir-7B
	- マージに使用させていただいたのはJapanese-Starling-ChatV-7B、Ninja-v1-RP-expressive-v2、Vecteus-v1、Japanese-Chat-Umievo-itr004-7bの４つです。各モデル制作者のAratakoさん、Bakuさん、Local-Novel-LLM-projectのみなさまに感謝します。それから問題解決のきっかけをくれたHoly-foxさんに感謝します。
- AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)
	- https://x.com/emollick/status/1795830809217454536
	- https://www.researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models
	- GPT-4 wins. Better prompting can further improve performance & diversity of ideas.
	- ついに創造性でもGPT-4が、（普通の）人間を抜いたのか。。
- Gemini 1.5 FlashはClaude 3 Opusに匹敵しながら、コストは100万トークンあたりたったの55円
	- https://x.com/gijigae/status/1795743286533255285
- Announcing Codestral: our first-ever code model
	- https://chat.mistral.ai/chat
	- "Write me a function that computes fibonacci in Rust"
- OllamaがCodestralに対応
	- https://ollama.com/library/codestral
- "Science in the Age of AI - How AI is changing the nature and method of scientific research,"
	- https://royalsociety.org/-/media/policy/projects/science-in-the-age-of-ai/science-in-the-age-of-ai-report.pdf
	- 英国ロイヤルアカデミー
	- Generative AI tools can assist the advancement of scientific research.
-  Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- 1. You can extract out a knowledge graph according to a set of extractors. These extractors include defining a pre-defined schema of entities/relationships/properties, defining a set of node relationship with llama_index constructs, or implicitly figuring out the schema using an LLM.
	- 2. You can now query a knowledge graph with a huge host of different retrievers that can be combined: keywords, vector search, text-to-cypher, and more. 3. You can include the text along with the entities/relationships during retrieval 4. You can perform joint vector search/graph search even if your graph store doesn’t support vectors! We’ve created robust abstractions to plug in both a graph store as well as a separate vector store. 5. You have full customizability: We’ve made it easy/intuitive for you to define your own extractors and retrievers.
- The structure of the EU AI Office
	- https://x.com/LuizaJarovsky/status/1795775192347627857
	- The “Excellence in AI and Robotics” unit
	- The “Regulation and Compliance” unit 
	- The “AI Safety” unit
	- The “AI Innovation and Policy Coordination” unit
	- The “AI for Societal Good” unit 
	- The Lead Scientific Advisor
	- The Advisor for International Affairs
- 英国のアカデミー、Royal Societyも「AI for Science」ではなくEUと同じ「AI in Science」。レポートはかなり充実している by maruyamaさん
	- https://x.com/rmaruy/status/1795967400502006026
- Mamba, Griffin, RWKV, RetNet, Recurrent Gemma- 2024 is the year of gated linear RNNs! What's their secret sauce?
	- https://x.com/ItamarZimerman/status/1796181061984030914
- CRDSの新作プロポーザル『次世代AIモデルの研究開発』がめちゃくちゃいい仕事で一気見した。
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-SP-03.html
	- https://x.com/resnant/status/1796181056283898332
	- LLM含め最近の基盤モデルや生成系AIの動向と諸課題を技術的にも掘り下げてて、いろいろな立場の人に参考になると思う
- [LoRA] by Hand
	- https://x.com/ProfTomYeh/status/1796169087665557729
	- How does LoRA reduce the number of trainable parameters?
-  Don’t Believe the AI Hype
	- https://www.project-syndicate.org/commentary/ai-productivity-boom-forecasts-countered-by-theory-and-data-by-daron-acemoglu-2024-05?
	- ダロン・アセモグル氏の分析では、AIによって影響をうける人間のタスクは4.6％で、向こう十年のAIによる全要素生産性の向上は0.66%にとどまる。AIによる科学発見は直近では経済にさほど影響しない。かつての自動化技術に比べると格差拡大効果は小さいが規制は必要
-  Aurora: A Foundation Model of the Atmosphere
	- https://arxiv.org/abs/2405.13063
	- NASA has created a new foundation model for geospatial data.
	- Create 5-day air pollution predictions in < 1 minute 
	- Create 10-day weather forecasts at ~10km resolution 
	- Assess the chemical make up of the atmosphere
- llm.cを使うとGPT-2を$20で2時間以内に構築可能？？
	- https://x.com/overlast/status/1796028138616422535
- Here’s a great guide teaching you how to construct knowledge graphs using LLMs that adhere to a pre-defined schema - using purely local models
	- https://x.com/llama_index/status/1796198853764595725
- 「大規模言語モデルの開発」 by　岡崎さん　@ JSAI2024
	- https://speakerdeck.com/chokkan/jsai2024-tutorial-llm
	- チュートリアル講演を行いました。事前学習、インストラクションチューニング、アライメント、評価の４部構成で、最近の研究動向や知見を紹介しました。
- Prompt Engineering for Generative AI
	- https://www.amazon.com/gp/product/B0D4FBPLX1?&linkCode=sl1&tag=kirkdborne-20&linkId=17812cf95726cdbbe7b0c29f94f4bce7&language=en_US&ref_=as_li_ss_tl
	- With this book, you'll gain a solid foundation in generative AI, including how to apply these models in practice. When first integrating LLMs and diffusion models into their workflows, most developers struggle to coax reliable enough results from them to use in automated systems.
- LLMs achieve adult human performance on higher-order theory of mind tasks
	- https://huggingface.co/papers/2405.18870
	- LLMs achieve adult human performance on higher-order theory of mind tasks 
	- This paper examines the extent to which large language models (LLMs) have developed higher-order theory of mind (ToM); the human ability to reason about multiple mental and emotional states in
	- We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level performance on ToM tasks overall, and that GPT-4 exceeds adult performance on 6th order inferences
- 生成AIによる「慣用表現の『乗っ取り』」と、その根底にある別の問題と by TJOさん
	- https://tjo.hatenablog.com/entry/2024/05/31/171000
	- 「ChatGPTに学術論文を（英語で）書かせると"[delve](https://eow.alc.co.jp/search?q=delve)"のような普段使わないような単語が多く使われるのでバレやすい」という話が[SNS](https://d.hatena.ne.jp/keyword/SNS)以下各所で頻繁に噂
	- ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果である、というものです。そもそも、例えば"delve"という単語はナイジェリア英語ではビジネスフレーズの中では比較的頻繁に用いられるそうで*3、それらのナイジェリア英語によるチューニングの結果がChatGPTの出力に影響している、ということのようです*4。
- The new Anthropic prompt engineering tool is incredible.
	- https://x.com/dr_cintas/status/1796577510773379479
	- You just need to write your goal and Claude will generate an optimized prompt instantly.
-  An entirely open-source AI code assistant inside your editor
	- https://ollama.com/blog/continue-code-assistant
	- つまり、ollamaをつかって、あなたの好みのエディタにCode assistanceをという話
- 最近の7B小型日本語LLMはエージェントになれるのか？
	- https://soysoftware.sakura.ne.jp/archives/3934
- 


## 5/27

さて今週は、MicrosoftのBuild2024が開催、gpt-4oを組み込んだCopilot+PCというintelはいってないPCのほかに、誰でもエージェントを作れるCopilot 進化的の更新や、人の代わりに会議進行をしてくれるTeam Copilot、さらには、ソフトウエア開発自動化の「Devin」の会社との提携など、目白押し。まあ早速、ゲームをサポートするcopilot assistantのデモをGemini 1.5 Flashで、さらにマリオゲームで再現できたとの個人の報告もありました。さて来月のAppleの WWDC24はどうなる。基盤技術では、チューリングテストでGPT-4は54%の確率で人間だと判断されたというのは、もう驚かない、AIによる詐欺にあわないように心がけても無駄という未来が、、。むしろ、「LLMがチャットUIに呪われている」という記事もあったが、もやはLLMの発展は人間が律速していて頭打ちになっている。一方AnthropicのClaude3 Sonetに対する特徴抽出の論文、つまりニューラルネット上にLLMの性質あるいは特徴を示す場所を特定する技術（スパースオートエンコーダ）、安全性の分析で役に立つといっているが、逆に特定の箇所を特別に活性化させれば、例えば、ゴールデンゲートブリッジ一押しのLLMが爆誕するとのこと。いやまさにもろ刃の剣となる重要な技術。知識グラフのRAGもアツイが、GraphRAGという画像化した知識グラフに対するRAGという技術、マルチモーダルだとそういうこともできるのか。今井さんのGPT-4oを研究者視点で「時代の転換点」と解説した記事のシリーズは気になるが登録が必要なのか。GUILDの深津さんの、横須賀市の未完成のお悩み相談チャットボット。不完全でもベータ公開というわりにやっぱよくできている。その深津さんが、生成AI時代に大事なスキルは、「やり続ける能力」、いくら生成ＡＩが優れていてもめげないことが大切。ローカルLLMも相変わらずアツイ！。今週も、Mistral v0.3がリリース、語彙数も増えて、見違えるくらい日本語能力が強化され、function callingへも対応、ollamaもraw modeでfuntion callingへ即追従。一方、マルチモーダルphi3-visionも含めてリリースされたphi3-small,medium、phi3-mediumがMMLUスコアはLlama3-70B並みに高性能であるということだが、量子化でデグレードしたのかOllamaへの組み込みはうまくいってない模様。Transformers.js とONNX Runtime Webの組み合わせというのも、ローカルLLMの協力な助っ人か。Cohereが多言語指向のオープンLLMであるAya 23 の 8B と35Bがリリース、日本語強そう。しかし、Phi-3は、「最も有能で費用対効果のSML (Small Language Model)」っていうんだ(Small LLMのほうがかっこよいのに)。 それにしても DeepSeekV2 、あまりに性能が高いので中国での競合のサービス料を1%押し下げた（投げ売り開始？）とのこと。ChatVector、7BモデルのFineTuning結果を70Bに転移させて性能向上したり、LLaVAの日本語化など、ローカルLLMでもその能力をふくめて認知や利用が増えてきた。transformersがv4.41.0にアップデートされてggufをサポートするようになったのも、ローカルLLM勢には朗報。EUのAI法が最終合意、生成ＡＩの規制も盛り込み済み。一方OECDはAIリスクに関する用語を整理し、インシデントの重大さにハザードが起こる確率を加味したものがリスクのレベルになるとのこと。英国の「Safeguarded AIプログラム」は、安全性のために数理論理学や圏論を利用する、同じsafe guardでも毒には毒をということでguard自体をLLMで実現するメタのアプローチと真逆で面白い。

-  Unleashing the Power of Knowledge Graphs in Retrieval Augmented Generation (RAG): Step by Step Instruction
	- https://medium.com/@transformergpt/unleashing-the-power-of-knowledge-graphs-in-retrieval-augmented-generation-rag-step-by-step-84c2adc66c1c
	- This is a neat resource by Jayita B. on teaching you how to not only build an advanced RAG indexing/query pipeline, but also turn it into a full-stack application with rapid respons
- OECD (2024), "Defining AI incidents and related terms",
	- https://www.oecd-ilibrary.org/science-and-technology/defining-ai-incidents-and-related-terms_d1a8d965-en
	- OECDのWGが作っているAIリスクを分類するための用語整備のレポート。起こりうる被害をハザード、起こった被害をインシデントと呼び、その重大さを考慮。ハザードに起こる確率を加味した全体がAIリスクとなる
- Text-to-SQL - fully local edition
	- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
- Run Mixtral 8x7B-on a free-tier Google Colab with AQLM-2bit quantization
	- https://www.youtube.com/watch?v=6ikUpJcDrPs&list=PLxqBkZuBynVTzqUQCQFgetR97y1X_1uCI&index=32
- The theoretical minimum series by Leonard Susskind and Art Friedman
	- https://x.com/PhysInHistory/status/1792020784854311205
- Chat VectorでLLaVAを日本語対応させる
	- https://zenn.dev/toshi_456/articles/0166a6eaa81c7b
	- LLaVAは大きくVision Encoder、Vision Projector、LLMという3つの部品からできていますが、LLMの部分だけ上記のように重みを加減算します
	- 今回使用するLLaVAの重みは[liuhaotian/llava-v1.5-7b](https://huggingface.co/liuhaotian/llava-v1.5-7b)です。このモデルのベースのLLMは[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)です。
	- Chat Vectorやその他のマージ手法を使用することで、英語のデータセットを日本語に翻訳して、学習させるという手間が必要なくなる可能性があるのはありがたいなと感じました。
- 横須賀市で、未完成のお悩み相談チャットボットをリリースしました。 by 深澤さん
	- https://www.city.yokosuka.kanagawa.jp/0835/nagekomi/20240520_soudanbot_nyanpei.html
	- あえて未完成のボットを公開して、広く不具合をあつめる実験です！！
	- さすがのでき前！
- 円の実力と日本企業の通貨戦略（配付資料・動画配信
	- https://www.youtube.com/watch?v=reLhpQg9muo
- 「kagglehub を使った大規模言語モデル gemma のファインチューニングとモデル共有」
	- https://www.kaggle.com/code/makimakiai/kagglehub-gemma
	- Kaggleのノートで銅メダルゲットした！嬉しい！
		- https://x.com/hAru_mAki_ch/status/1792105063022018835
- Deep Dive on Accumulated Local Effect Plots (ALEs) with Python
	- https://towardsdatascience.com/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee
	- ALEs give interpretations that are robust to multicollinearity.
- 英国政府が100億円超を投じる「Safeguarded AIプログラム」とは
	- https://www.aialign.net/blog/20240520-takatsuki
	- 本プログラムにおいてAIシステムの安全性の証明可能性の土台となる理論（特にTA1.1で扱われる内容）には、数理論理学や圏論といった分野が重要な位置を占めることが予定されており、これらの分野の研究者の協力が必要とされています
- Copilot + PC by Nadella
	- https://x.com/satyanadella/status/179261785138542602
	- Introducing Copilot+ PCs—the fastest, most AI-ready Windows PCs ever built.
		- Powered by new NPU (40+ trillion operations per second)
		- Rearchitected Windows 11 
		- 58% faster than Macbook Air M3 
		- Copilot shipping with Windows 
		- Copilot built into Settings, files, notifications 
		- Powered by GPT-4o
- LangChainにObsidianのローダーがある～。ObsidianのメモをベクトルストアしてRAGできてしまう～
	- https://www.youtube.com/watch?v=E-CNrXhSvLg
- The Illustrated Stable Diffusion	
	- https://jalammar.github.io/illustrated-stable-diffusion/
- Google has released Gemini 1.5 Flash.
	- https://x.com/dr_cintas/status/1792572374300188752
	- An AI model optimized for speed and efficiency, with multimodal reasoning and an impressive 1M context window!
-  AWS、一般提供開始した生成AIサービス「Amazon Q」、および「Bedrock」と今後の戦略を説明
	- https://internet.watch.impress.co.jp/docs/news/1592518.html?ref=smartnews
- The theory of mind—the ability to track a person's mental state—is tested comparing humans vs GPT-4 and LLaMA2 large language models
	- https://www.nature.com/articles/s41562-024-01882-z
- GeminiがYouTube動画を一瞬で要約してくれるようになった（しかも無料
	- https://www.lifehacker.jp/article/2405-use-gemini-summarize-youtube-videos-free/
	- 本当だ！
- 観察スケール則は、LLMの標準的ベンチマークの性能から求められた主成分（3つ程度）を用いて複雑な後続タスクの性能を高精度で予測できる法則　by 岡野原さん
	- https://arxiv.org/abs/2405.10938
- BREAKING: Council of Europe adopts 1st international treaty on AI. Here's what you need to know:
	- https://x.com/LuizaJarovsky/status/1792224914646200512
-  Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings
	- https://arxiv.org/abs/2405.10938
- 論文メモ: Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models b y はちさん
	- https://note.com/hatti8/n/nb61b4935c793?sub_rt=share_pb
	- Googleが先週出したLLMの自己改善手法であるReSTEMについて、メモを書きました。
	- 合成データ生成手法としてどうかという視点で書いています
- p値姫（サンプル数編）
	- https://x.com/spine_surgeon_/status/1792767885615759746
	- 「マリオへ、実験結果いい感じです！いい感じなんですけど、有意差でるまでサンプル数増やしてみてください。有意差出るまで連絡は不要です。ピーチより。」
- People cannot distinguish GPT-4 from a human in a Turing test
	- https://arxiv.org/abs/2405.08007
	- AIの人間らしさを測るテストで世界一有名なチューリングテストですが，さんざん「もうAIはチューリングテスト突破できるやろ」と言われてたのを真面目に分析した論文が出ました
	- 結論は「現在のGPT-4などの最先端AIは，チューリングテストを突破可能であり，人間はもはや人とAIを会話のみから判定することはできない」というものです．GPT-4は54%の確率で人間だと判断された模様
- 最近ローカルLLMがアツいらしい
	- https://soysoftware.sakura.ne.jp/archives/3903
	- GPTのAPI高い問題 ＆ OpenAIがAIベンチャー皆殺しにしてしまう問題
	- ローカルLLM推論ライブラリが色々ある
		- Llma.cpp, ollama, vLLM
	- 強力な大型オープンなAIモデルが公開されはじめてる
		- Command R+（非商用利用）やLlama3-70B、DeepSeek-V2
	-  小型のAIモデルの性能向上の潮流
		- Mistral-7Bベース、ChatVector、
	-  個人でもAI開発競争に食い込める可能性について
- 生成AI時代に大事なスキルは、「やり続ける能力　by 深津さん
	- https://x.com/fladdict/status/1792831115528663471
	- 生成AI時代には「もうあいつ（AI）一人でいいんじゃないかな」と、色々なことで挫折する人が大量発生する。「手をとめない」能力が、人類にとって最重要の才能になるかもしれない
- transformers v4.41.0
	- https://github.com/huggingface/transformers/releases/tag/v4.41.0
	- Phi3, JetMoE, PaliGemma, VideoLlava, Falcon2, FalconVLM & GGUF support
		- https://huggingface.co/docs/transformers/v4.41.0/en/gguf
- Phi 3 - Small, Medium & Vision
	- https://x.com/reach_vb/status/1792949163249791383
	- This includes the 7B and 14B models
	- This also includes a multimodal phi model
- Knowledge Cards by Perplexty	
	- https://x.com/perplexity_ai/status/1792948540542517458
	- We’re teaming up with @TakoViz to bring advanced knowledge search and visualization to our users. Now, you can search, juxtapose, and share authoritative knowledge cards in Perplexity.
	- Perplexityが高度な情報検索と視覚化ができる「knowledge cards」という機能をリリース。
	- 自由に任意の2社の株価推移の比較が可能。リサーチ業務が捗り、仕事で活躍間違い無し。
- GraphRAG: Using Knowledge in Unstructured Data to Build Apps with LLMs
	- https://www.graphlit.com/blog/graphrag-using-knowledge-in-unstructured-data-to-build-apps-with-llms
	- We have used Graphlit to automatically extract images from PDFs, and are using the OpenAI GPT-4 Vision model to perform OCR and generate detailed text descriptions of the images.
	- どうも、知識グラフの画像から知見を得るらしい。
- I built my own omni assistant using Gemini 1.5 Flash to guide me through Super Mario 64.
	- https://x.com/skirano/status/1792948429754151293
	- MicrosoftがBuildででもした、assistantを、gemini 1.5 Flashで実装したツワモノ、お題はマリオだし。
- What is the context window?
	- https://x.com/cwolferesearch/status/1792950349696753980
		- Claude-3 has a 1M context window 
		- Gemini-1.5 Pro has a 2M token context window 
		- Recent research [3] has explored going even beyond 2M tokens.
- ICity, a Geometry Nodes-powered procedural city generator for Blender.
	- https://x.com/80Level/status/1792769380717068510
	- Available now in Beta
		- https://80.lv/articles/long-awaited-procedural-city-generator-for-blender-is-now-available/
- Microsoft、Copilot 進化的の新機能を発表
	- https://x.com/shota7180/status/1792966382990270739
	- Copilot 進化的の更新により、誰でもエージェント機能を持つコパイロットを構築可能に
	- このコパイロットは、ユーザーの代わりに独立して積極的にタスクを調整・実行
	- 特定の役割や機能に合わせてタスクを個別に調整できる
- MIcrosoft's Phi-3 really is an astonishingly good model
	- https://x.com/simonw/status/1792691120675467288
	- MIT licensed and small enough to run in a browser on WebGPU (about a 2.3GB downloads), but still provides high quality results for a lot of the stuff I care about
	- Phi-3-mini running locally in your browser at 70 tokens per second on WebGPU!
	- Powered by 🤗 Transformers.js and ONNX Runtime Web! 
	- https://huggingface.co/blog/Emma-N/enjoy-the-power-of-phi-3-with-onnx-runtime
- Hugging Face and Microsoft Deepen Collaboration
	- https://huggingface.co/blog/microsoft-collaboration
- Tako, the first AI search engine for visualizing and sharing the world’s knowledge.
	- https://x.com/TakoViz/status/1792949400710574455
	-  Introducing Tako, a new way to reference real knowledge And our first integration, Perplexity
		- https://trytako.com/blog/introducing-tako-and-perplexity-integration
- Team Copilot by Microsoft 
	- https://x.com/msdev/status/1792967099519758822
- 13B phi-medium-4k GGUF files here, model is looking very very good.
	- https://huggingface.co/nisten/phi3-medium-4k-gguf
- 本日（5/20）、EUのデジタルアイデンティティ法が施行
	- https://x.com/_nat/status/1792915589570154637
- マイクロソフト、自律型AIソフトウェアエンジニア「Devin」のCognition AIと提携を発表。Azure上でDevinを提供へ
	- https://www.publickey1.jp/blog/24/aidevincognition_aiazuredevin.html
-  Mapping the Mind of a Large Language Model
	- https://www.anthropic.com/research/mapping-mind-language-model
	- Anthropic has just revealed some exciting news about Claude Sonnet. They've successfully identified how millions of concepts are represented inside this massive model!
- ollama run phi3:medium
	- https://x.com/ollama/status/1793067457382343134
- Phi-3-vision ・ Phi-3-medium ・ Phi-3-small の概要 by npakaさん
	- https://note.com/npaka/n/nb050244392a4?sub_rt=share_h
	- 「Phi-3」は、最も有能で費用対効果のSML (Small Language Model) であり、さまざまな言語、推論、コーディング、数学のベンチマークで同じサイズと次のサイズのモデルを上回っています
	- 「Phi-3-vision」は、チャートや図から洞察を生み出すことができます。
	- 「Phi-3-small」「Phi-3-medium」は、同じサイズの言語モデルだけでなく、はるかに大きい言語モデルよりも優れたパフォーマンスを発揮します
	- SLMは、より単純なタスクでうまく機能するように設計されており、リソースが限られている組織にとってよりアクセスしやすく、使いやすく、特定のニーズに合わせてより簡単にファインチューニングできます
-  GPT-4oをわかりやすく解説、専門家が「時代の転換点」と評価するヤバすぎる能力とは by 今井さん
	- https://www.sbbit.jp/article/cont1/140613
	- OpenAIのGPT-4oを研究者視点で解説した記事が出ました! 速報的な記事の依頼でしたが,やはり研究者が書くということで情報をすべて詰め込んだ1万文近いガチ解説記事になりました.3回の連載です.
	- 言語,音声,動画像,後半ではGPT-4oの「弱み」等,日本語記事では一番詳しいはず
- MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning
	- https://arxiv.org/abs/2405.12130
	- LoRAより知識獲得系タスクに強いMoRA　 by shi3zさん
- ルカン先生、学生に次世代AIを作ろうとするなれば、LLMをやるのではないよとアドバイス
	- https://x.com/ylecun/status/1793326904692428907
	- If you are a student interested in building the next generation of AI systems, don't work on LLMs
- Mistral v3 base and instruct released
	- https://huggingface.co/mistralai
	- Base has vocab extended to 32768. 
	- Instruct supports function calling! 
	- Tokens 5 to 9 are for function calling & the rest are empty
- Interface 7月号では，Copilotで文芸的プログラミングに挑戦します．
	- https://x.com/If_CQ/status/1793214032121614787
	- ドキュメントとソースコードを同時に開発保守するのがDonald. E. Knuth博士の「文芸的プログラミング」．CopilotとDoxygenを使えば，記述が自動化でき，両者の不一致を防げます．ソフトウェア開発の理想を最新の技術で実現します．
- New guide in our AI cookbook: 𝙎𝙩𝙧𝙪𝙘𝙩𝙪𝙧𝙚𝙙 𝙜𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣
	- https://huggingface.co/learn/cookbook/structured_generation
	- This technique lets you force your LLM to generate its output as a JSON with specific keys: great for RAG or LLM-judge!
- Large Language Models Meet NLP: A Survey
	- https://arxiv.org/abs/2405.12819
	- Provides a comprehensive survey of how LLMs are applied to NLP tasks, introducing a new taxonomy and discussing current progress, future frontiers, and challenges.
- Mistral AI's Mistral v0.3 supports function calling with Ollama's raw mode!
	- https://x.com/ollama/status/1793392887612260370
	- Ollama raw mode
		- https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode
- Mistral-7BとPhi-3もこの際ElyzaTasks100で評価してみた。by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793550842353820014
	- まずMistral-7Bはv0.1が2.46、v0.2が2.69（やたら英語で回答してくるので半分以上英語の回答は手作業で1点に減らした）、からの今回のv0.3は3.52！見違えるくらい日本語能力が強化されてます。英語で答えちゃう問題もほぼ起きない。
	- Phi3は3.8Bのmini-128kがまさかの3.26というこのパラ数にしては高すぎるスコアでなぜかsmall-128kに勝ってしまってます。
	- small-8kは3.28で、miniと大差ないという意味では残念。同パラのMistral-7B-v0.3にも負けてる。
	- でもmedium-128kは14Bパラで3.96というバケモンみたいなスコアが出てます。これはすごすぎ
- GPT-4oとGPT-4TurboのElyzaTasks100の平均スコア、
	- https://x.com/umiyuki_ai/status/1793540614551904762
	- 気になってたのでAPI代払って評価してみた。
	- GPT-4Turboが4.44、GPT-4oが4.51！やっぱりエゲつない超スコア！
	- オープンなモデルがGPT-4Tに追い付いてきたなんてちょっと言えなくなった
- Phi-3-MediumのMMLUスコアはLlama3-70B並み… by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793614730403434950
	- やっぱり伊達じゃないらしいね。ElyzaTasks100でも匹敵してるもん。しかし信じがたいね 
- Aya 23 is here! Available in 8B and 35B.
	- https://ollama.com/library/aya
- LangChain `with_structured_output` メソッドによる構造化データ抽出
	- https://zenn.dev/ml_bear/articles/cb07549ec52175
	- 1.  構造化データをPydanticで定義する
	- 2.  その定義を`.with_structured_output`でLLMに取り付ける
	- Pydanticでスキーマを定義した上で構造化データ抽出するのは非常に簡単です
- 「AIスタートアップは街の電気屋さんから始めろ」
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo1-4.pdf
	- AI戦略会議の松尾研の資料「生成AIの産業における可能性」
	- まずは受託開発で社会を学ぶ。 受託開発で地域の企業のDXを支援しつつ、一緒にグローバルに出ていく
- 世界初、AI技術による原油処理装置の自動運転を開始　PFN
	- https://www.preferred.jp/ja/news/pr20240524/
- 機械学習による反応予測の論文
	- https://chemrxiv.org/engage/chemrxiv/article-details/664de6a821291e5d1df74ac0
	- SMILESにより化学反応をテキストで表現したSMIRKSを用いることで、化学反応のルールを高精度に学習できたそうです。寄与する原子数が多い複雑な反応は今後の課題とのこと
- LLMはチャットUIの誕生でブレイクスルーを起こしたが、今はチャットUIに呪われている
	- https://x.com/rkmt/status/1794013338005090666
	- 「有効な質問をLLMに投げ回答を得るサービス」は一定量（それを使いこなせる人類の数<<人類の総数）で頭打ちになり、それ以上は「意味もない内容もないけど楽しい会話をAIと続ける」サービスか、「人間を必要としないAI業務」に移行するのかも。
- ぱぷりか炒め（mmnga）さんの、Llama-3-70B-japanese-suzume-vector-v0.1 すごい、 by AIサトシ
	- https://x.com/AiXsatoshi/status/1793973265532424467
	- 8bのLlama派生モデルのchatvectorを、パラメータ数違う70Bにマージしてて、さらにベンチマーク結果も良好なのすごい
- Cohereが多言語指向のオープンLLM「Aya」（8B，23B）を公開
	- https://huggingface.co/spaces/CohereForAI/aya-23
	- 4月には当時のオープンLLM最高性能のCommand R+を出してたCohereの多言語LLMなので,日本語も期待できそう...実際に日本語は結構うまいんですが,色々と簡潔すぎて自分の中での評価が「冷たいモデル」です
-  DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
	- https://huggingface.co/papers/2405.14333
	- Proof assistants like Lean have revolutionized mathematical proof verification, ensuring high accuracy and reliability. Although large language models (LLMs) show promise in
- ollamaでPhi3-mediumは「性能ショボい」？　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793878129699950887
	- OllamaでPhi3-mediumをプルするとQ4_0量子化版がDLされるようだが、スコアは3.68。Q4_K_Sでも3.67。ちなみに僕が最初に検証したLlama. cppのQ8は3.88だったし、同じくLlama. cppのQ4_K_Sも3.95で劣化どころかスコア上がってる。というわけでollamaのPhi3-mediumはパラ設定かなんか分からんけど何らかの問題で劣化してます
- DeepSeekV2 is a big deal.
	- https://x.com/Xianbao_QIAN/status/1794034052347171055
	- Not only because its significant improvements to both key components of Transformer: the Attention layer and FFN layer. 
	- It has also completed disrupted the Chines LLM market and forcing the competitors to drop the price to 1% of the original price.
- Difyを使うメリットの一つが開発したChatbotやワークフローを簡単にWEBでシェアできること
	- https://x.com/gijigae/status/1793437095727665588
-  Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet
	- https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
	- Anthropicの中規模生産モデルであるClaude 3 Sonnetにスケールアップされたスパースオートエンコーダーを適用し、解釈可能な特徴を抽出する研究
	-  **スパースオートエンコーダー**: 小規模トランスフォーマーから単義的特徴を回復する方法を示した研究から発展し、大規模モデルへのスケーリングが重視されています。
	- **解釈可能な特徴**: 抽出された特徴は多言語、多モーダルであり、具体的および抽象的な参照の間で一般化されています。
	- **安全性関連特徴**: セキュリティの脆弱性やバックドア、偏見、嘘や欺瞞、危険または犯罪的な内容など、AIシステムが引き起こす可能性のある様々な問題に関連する特徴が観察されています。
	- **スケーリング法則**: スパースオートエンコーダーの訓練にスケーリング法則を適用し、計算予算に基づいて最適な特徴数と訓練ステップ数を決定しています。
- ハル・ベリーニューロンがAIで実体験できる時代が到来
	- https://x.com/webbigdata/status/1794030396990226803
	- ハル・ベリーさんという、X-MENのストームとかキャットウーマン役をやってるアメリカの女優さんがいるのですが、ある患者さんの特定のニューロンが「ハル・ベリーの写真」や「ハル・ベリー」というテキストに対して活性化する事が観察されたという研究がある。
	- 5月21日にanthropicがClaude 3 Sonnetで何百万もの概念がどのように表現されているかを特定できたよ～と発表し、
	- その技術を使って、サンフランシスコのゴールデン ゲート ブリッジ(Golden Gate Bridge)に対応するニューロンを活性化させてている「Golden Gate Claude」と実験的に対話できるようにしたよ～と発表したのが昨日ですね。
	- 一言で言えば、やたらめったらゴールデン ゲート ブリッジ推しをしてくるAIで、色々なタイミングでゴールデン ゲート ブリッジを推薦してきます。
- streamlitでデプロイするイメージです。 GitHubと接続すれば、本当に爆速で
	- https://x.com/kenken26679105/status/1793889080385925580
- ChatVectorで7BモデルのFineTuning結果を70Bに転移させるみたいな話、by はちさん
	- https://x.com/CurveWeb/status/1794203714422759707
	- 事前学習では既に小さいモデルで事前学習→セルフマージで大モデル化っていうのができているのでなんとなくできて然るべき感ある。

## 5/20

今回は、GPT-4oさんに、まとめをお願いしました（無修正です！！）。ここまで来たか、と驚くようなさみしいような。。大切なことは、もう一度言います、無修正です。では、

最新の大規模言語モデル（LLM）の動向について、今回はちょっとユーモアも交えつつお届けします。まずは、絶対に見逃せない二つの大ニュースから。 最初に、大きく注目を浴びているのがOpenAIの新モデル「GPT-4o」です。どうやらこのモデル、名前だけじゃなくて性能もまさに「おお！」と言いたくなる程の進化を遂げています。他のモデルと比べて速度は2倍、コストは半分、レートリミットが5倍と、まさにスーパーAI。さらに無料プランのChatGPTユーザーでも使えるようになるとのことで、サム・アルトマンさんから直接のお知らせも飛び出しました。しかも、このGPT-4oは数学の難関問題を画像で出題しただけで解けるという、まるで魔法のような能力を持っているのです。この進化により、動画の要約や化学実験の考察まで、ヘビーユーザーの活用法がどんどん増えているのが現状です。 次はGoogle I/Oでの発表です。トップバッターは新しいビジョン・ランゲージモデル「PaliGemma」と「Gemma 2」。その大きな見どころは、Gemma 27Bというサイズでも新しいアーキテクチャを駆使して、モデルが2倍のサイズのものにも勝る性能を発揮すること。これ、まるでヒーロー映画の続編が発表されるかのようなワクワク感がありますよね。そしてさらに「Trillium」という次世代Google Cloud TPUの登場で、このスーパーAIヒーローたちがさらに効率良く動作することが期待されています。ああ、今夜のビリー・アイリッシュのライブにでも登場しそうな勢いです。 さて、話題を変えて、最近の秀作をご紹介します。DeepLearningAIから無料コースが続々登場しており、MistralAIを使ったコースを提供中です。このコースでは、Mistralのモデルに加えて、RAG、関数呼び出し、そしてJSONモードなどまで学ぶことができます。これを受けて、プロンプト設計での尤度関数の捉え方について議論が巻き起こっています。「それってプロンプトダンサーの必須スキル？」と思わせるような専門的な話題も含まれています。 一方、HuggingFaceのトークン化とllama.cppのトークン化に違いがあることが議論されています。これはまるで、映画の字幕と吹き替えの違いくらい注目されているトピックです。特にLlama3やGemmaモデルに関して、量子化に問題がある可能性も浮上しています。んん、やっぱりテクノロジーの進化も一筋縄ではいきませんね。 そしてお待ちかね、npakaさんの情報を一気にまとめてチェック。彼はOpenAIのModel Specについての概要を詳述しています。また、新しいLangChain v0.2を使ったエージェント構築や、RAG、特定の情報源に関するQAシステム、情報抽出、要約などのユースケースも紹介しています。「LangChainハッカー」なんて称号が彼に似合いそうですね。 ここまで大まかなトピックをご紹介しましたが、その他の小ネタも盛りだくさんです。例えば、Mozillaのやる気満々なローカルリサーチツール「llamafile」や、LangChainとHuggingFaceの強力な提携など、どんどん新しい機能が登場していますよ。この分野の進展の速さを見逃さないでくださいね。 現場はまるで、ピーターパンのネバーランドのように変化に満ちています。今後も続々と驚きと笑顔が待っているかもしれません。さあ、次はどんな冒険が待っているのか、楽しみですね！

- またまたDeepLearningAIより、MistralAIを用いた無料コース
	- https://www.deeplearning.ai/short-courses/getting-started-with-mistral/
	- Mistral AIによる1時間のコース。Mistralのモデルだけでなく、RAG、関数呼び出し、JSONモードなどについて学べる
- b氏が、「ローカルLLMはこーやって使うの」にかみつく、
	- https://x.com/behemuhemulove/status/1789537738590765215
	- 「尤度関数の所が俺には意味が良くわからなかった。プロンプトをパラメータといってるのに、プロンプトを固定したらパラメタの関数にならないから尤度関数じゃなくない？」
	- →プロンプト振ってるので尤度による最適なプロンプトの推定といってもいいのではないか？
- 主要モデルでHuggingFaceのトークン化とllama.cppのトークン化に差異があったとの事
	- https://x.com/webbigdata/status/1789695414238884256
	- llama3の量子化が腐ってるのはこのせい？
	- 1. Mistral: HF's batch_decode output is wrong 
	- 2. Llama-3: Be careful of double BOS 
	- 3. Gemma: 2nd token has an extra space - GGUF(_Below) = 30641 vs HF(Below) = 33501 
	- 4. Gemma-it: Also be careful of double BOS
- OpenAI の Model Spec の概要 by npakaさん
	- https://note.com/npaka/n/nf6b811cad5dc?sub_rt=share_b
	- モデルの動作を形成するアプローチの透明性を高め、モデルをどのように変更および改善できるかについて公開の会話を開始するために、「Model Spec」を公開します。
- [code-cooker](https://github.com/karaage0703/code-cooker) by からあげさん
	- https://github.com/karaage0703/code-cooke
	- 面倒なことをChatGPT以外のLLMにやらせるソフト。GUIをつけてみました。 ようやく自分でも使いたくなるものができた気がします。まだClaude 3 Opusしか対応してないので、GPT-4とかLlama 3にも対応していきます。GPT対応はOpenAIの発表の後にしようかな
- 大規模パラメータモデルの人たちは、このOpenAIの論文に書いてあること思い出してねだそうで
	- https://x.com/cloneofsimo/status/1789700168083997010
	- Again, the paper im advocating here is from openai, and is referenced all the time and frankly one of the paper all large scale practitioner should read. the math here isn't complicated and nothing here is either controversial nor task dependent.
	- https://arxiv.org/abs/1812.06162
-  技術革新と不平等の1000年史の紹介 by 楠さん
	- https://x.com/masanork/status/1789647931467026613
	- これ特に下巻の読み応えがすごいんですが、技術が約束する未来と社会構造に与える影響とは、分けて議論しなければならないのでは？という課題認識が強く。LLM周辺ではオープンって用語が曖昧に使われたり、生産手段が民主化されていないのが悩みどころ
- ollamaで Fugaku-LLM を動かす
	- https://note.com/npaka/n/n1d99253ae2cf?sub_rt=share_h
	- 一番サイズの小さい（おそらく量子化が一番効いている） 「Fugaku-LLM-13B-instruct-0325b-q5_k_m.gguf」を選びます
	- **`Modelfile`  で一番重要なのは、トークナイザの chat template を守ることです**
	- docker　２発で、ollamaと、web-uiが動くのかー
- 【GPT-4o 爆誕】
	- https://x.com/MLBear2/status/1790069525372981452
	- 従来のGPT-4, Claude 3 Opusなどに比べて頭一つ抜けて賢い（図）
	- gpt2としてChatbot ArenaでテストされていたものがGPT-4oだったとサムアルトマンCEOが認めた。
	- GPT-4 Turboと比べて ・2倍速く ・50%安価 ・Rate limitが5倍高い
- GPT-4oで使われている新しいtokenizer、tiktokenにもう入ってる
	- https://x.com/gyakuse/status/1790110045814010327
	- tiktokenを0.7.0 にアップデートし、enc = tiktoken.encoding_for_model("gpt-4o")とするだけ
- gpt-4oで試しに今年の東大数学2024の問題を画像で送ったら（プロンプト一切無しでも）正解できた
	- https://x.com/kyutaro15/status/1790098489940258830
- サムからのGPT-4oに関するメッセージ
	- https://x.com/sama/status/1790065541262032904
	- it is available to all ChatGPT users, including on the free plan! so far, GPT-4 class models have only been available to people who pay a monthly subscription. this is important to our mission; we want to put great AI tools in the hands of everyone.
- GPT-4oの動画要約をHuggingface Spaceで試せるようにしました by 逆瀬川さん
	- https://x.com/gyakuse/status/1790090822031126730
	- リリースされたGPT-4oを使って動画のサマリー生成をしてみる！
		- https://qiita.com/sakasegawa/items/b82a9745fda81143e409
- GPT-4oに化学実験の結果を考察させてるんですが、 考察が早すぎて、スクロールが追いつかないです　 by 畠山さん
	- https://x.com/kanhatakeyama/status/1790098210360537138
- （OpenAIの新しいtokenizerは）日本語はトークナイザーが改善されてるから、API使用料50% x トークン量70% で 35% ぐらいの費用になるのか？
	- https://x.com/MLBear2/status/1790081289367990668
- LangChainがgpt-4oに対応
	- https://x.com/LangChainAI/status/1790089006455398583
	- You can use the available multimodal capabilities of it in any of your LangChain applications today!
	- https://python.langchain.com/v0.1/docs/integrations/chat/openai/
- TJOさん、デジ庁、データサイエンティスト公募の要件をみて頭を抱える
	- https://x.com/TJO_datasci/status/1790046279428345990
	- 「このスキルの必須要件を全部満たして尚且つ歓迎項目も複数満たすデータサイエンティストなんて、そもそも日本どころか世界を見渡しても探し出すのは困難を極めるのでは。それを公務員の給与で雇うとか無理ゲーにも程があるような気がする」
	- 結局お金の問題か
- GPT-4oはPlaygroundで試せる。 確かに賢いしものすごく速い by shi3zさん
	- https://x.com/shi3z/status/1790073756079059400
- Command-R-Plus, Llama-3, Phi-3 miniを ELYZA-tasks-100 で評価
	- https://qiita.com/wayama_ryousuke/items/a96f11fe2b7e2e3910e5
	- 「今回ご紹介したモデルは、日本語に特化した追加学習を行わなくても、日本語で回答を返すことができるという点が大きな特徴です。」
	- 評価用 Colab ノートブックもあるよ
- Embeddingモデルを使ったベクトル化のしくみ、fine-tuning手法を解説
	- https://speakerdeck.com/payanotty/embeddingmoderuwoshi-tutabekutoruhua-nosikumi-fine-tuningshou-fa-wojie-shuo
-  State-Free Inference of State-Space Models: The Transfer Function Approach
	- https://arxiv.org/abs/2405.06147v1
	- Utilizing the connections between convolutions in the time domain and multiplication in frequency domain (through FFT),
-  GPT-4o の概要 by npakaさん
	- https://note.com/npaka/n/n02331040d8c2?sub_rt=share_b
- JSLM2（Japanese Stable LM 2 Instruct 1.6B）
	- JSLM2は、6B以下の規模のモデルの中で、日本語性能が最も高いと思います。違いますか？ (llm-jp-evalや定性評価で）
	- https://x.com/peacej/status/1789909011132805402
- gpt-4o で使われたo200k_base tokenizer の日本語の部分・・・完全に5ちゃんねる・・・
	- https://x.com/_aixile/status/1790278857641410662
- Andrew Ng先生によるAI エージェント設計パターンの連載
	- https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/
	-  Agentic Design Patterns Part 1
	- Reflection, ツールの使用, プランニング, 複数Agentの協力
- gpt-4o、論文要約してPowerPoint吐いてくれる
	- https://x.com/CurveWeb/status/1790336171777917332
- 大規模言語モデル (LLM)における低精度数値表現 by PFNの三上さん
	- https://speakerdeck.com/pfn/20240508-hpckenkyukai-pfn-llm
	- 学習：8bitが主流になりつつある
	- 推論：1～2bit表現が実用化されつつある
- Introducing Veo: our most capable generative video model　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790435824598716704
	- It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles
- llamafiles from mozilla
	- https://x.com/llama_index/status/1790449858899505616
	- Build a local, private research assistant running on your laptop in a snap with llamafile from Mozilla! 
	- llamafiles are fun: no need to install anything, just download the file and run it, and you get a local LLM and embedding model that you can use directly from LlamaIndex. 
	- https://github.com/Mozilla-Ocho/llamafile
- langchain-huggingface のアナウンス
	- https://x.com/LangChainAI/status/1790419422399877158
	- We're excited to announce the launch of langchain-huggingface, a partner package in LangChain jointly maintained with huggingface
- Entropy minimization がなんで有効か？ ICML
	- https://x.com/ori_press/status/1790383780642918469
	- https://arxiv.org/pdf/2405.05012
- Evaluation of Retrieval-Augmented Generation: A Survey
	- https://arxiv.org/abs/2405.07437
	- https://github.com/YHPeter/Awesome-RAG-Evaluation
- Pattern Language is one of my favorite books, and this abridged hypertext version by zenodotus280
	- https://x.com/kepano/status/1790437820487946630
	- This project is an abridged, hyper-textual, and copyleft manifestation of the 1977 architecture classic _A Pattern Language_ by Christopher Alexander
		- https://github.com/zenodotus280/apl-md
- GPT-4oの登場により、検討中の研究プロポーザルがお釈迦になるというポストたち
	- 「音声言語モデル」について学振書いている間にこれはひどすぎるでしょ
		- https://x.com/nonmetal_/status/1790079046191120560
	- GPT-4o makes me feel both sad for my current work has been scooped by OpenAI, and happy that we are on the right track. by SpeechGPTシリーズの開発者
		- https://x.com/dongzha35524835/status/1790241799547806071
- multi-step reasoning capabilities to Google Search at Google I/O
	- https://x.com/Google/status/1790438800667123860
	- perplexityのようなものがくるのか、
- Linear Regression is one of the most important tools in a Data Scientist's
	- https://x.com/mdancho84/status/1790445342787318206
	- 1. OLS regression aims to find the best-fitting linear equation that describes the relationship between the dependent variable (often denoted as Y) and independent variables (denoted as X1, X2, ..., Xn).
	- 2. OLS does this by minimizing the sum of the squares of the differences between the observed dependent variable values and those predicted by the linear model. These differences are called "residuals."
	- 3. "Best fit" in the context of OLS means that the sum of the squares of the residuals is as small as possible. Mathematically, it's about finding the values of β0, β1, ..., βn that minimize this sum.
- We’re sharing Project Astra: at Google I/O
	- https://x.com/GoogleDeepMind/status/1790433540548558853
	- We’re sharing Project Astra: our new project focused on building a future AI assistant that can be truly helpful in everyday life.
- PaliGemma、Gemma 2　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790459505538658636
	- PaliGemma: a powerful open vision-language model  
	- Gemma 2: coming soon in various sizes, including 27 billion parameters
- GPT-4o shows improvement compared to GPT-4-Turbo-0409 with better probability, pre-calculus, algebra, and geometry abilities. 
	- https://x.com/GanjinZero/status/1790230562453803241
- Get a sneak peek of Gemma 2, at Google I/O
	- https://x.com/Google/status/1790452314278412554
	- 27B parameter instance launching in a few weeks. Built on new architecture, Gemma 27B outperforms models twice its size and can run on a single TPU host in Vertex AI.
- PaliGemma をお試し中
	- https://huggingface.co/spaces/big-vision/paligemma
- Introducing Trillium, the next generation of Google Cloud TPU
	- https://x.com/GoogleCloudTech/status/1790452622295449925
	- It delivers 4.7X the peak compute performance per chip compared to TPU v5e and is equipped with 2X the high-bandwidth memory capacity.
- ZeTT
	- https://x.com/CurveWeb/status/1790308270126883146
	- 「追加のトレーニングをほとんど(もしくは全く)行わずに、任意のモデルを任意のトークナイザーで使用できるようにする手法ZeTT。 ChatVector やモデルマージのTokenizerによる制限を避けるのに使えそう」 by はちさん
- Gemini 1.5 Pro to 2 million tokens at Google I/O
	- https://x.com/Google/status/1790430189916225799
	- Today we’re expanding the context window for Gemini 1.5 Pro to 2 million tokens and making it available for developers in private preview. It’s the next step towards the ultimate goal of infinite context
- Data Scientists: The next level of Data Science AI Agents is called "Plan and Execute".
	- https://x.com/mdancho84/status/1790406221616320862
- GoogleとOpenAIの発表を見てる僕の心境 by GUILDの深澤さん
	- https://x.com/fladdict/status/1790431879512093151
	- 「あ、ゴクウとフリーザが上空で戦ってる！！！すごい速度で見えない！！！頑張れ！！！」というクリリンの心境
- Ilya and OpenAI are going to part ways. by Sam
	- https://x.com/sama/status/1790518031640347056
	- This is very sad to me; Ilya is easily one of the greatest minds of our generation, a guiding light of our field, and a dear friend. His brilliance and vision are well known; his warmth and compassion are less well known but no less
- HCI系のトップカンファレンスCHI2024の全論文をGPT-4で要約スライドにまとめて見たので
	- https://drive.google.com/file/d/1CMkTdGlk1OhtScKUTB7Mt22GtWxgAIPV/view
- Colab 📒 Notebook to fine-tune 💅🏽 @GoogleAI
	- #PaliGemma vision-language model 👓🔠🧠on a free T4 VM
	- https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb
- Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
	- https://note.com/panda_lab/n/n948053d7813f
	- RAGの枠組みを拡張し、Wikipedia自動生成に特化したフレームワーク「STORM」を考案しました。
	-  **課題**: ウィキペディアスタイルの記事は、広範囲の参考文献の収集と、詳細なアウトラインの作成が必要です。従来の方法では、この準備段階がしばしば省略されます。
	-  **解決策**: STORMは、予備的な書き込み、草稿作成、改訂の各段階、特に予備段階での効果的な質問提起により、このプロセスを自動化します。
- 「Stockmark-100b」
	- https://x.com/kosukearima/status/1790902109648695565
	- 産総研ｘストックマーク共同研究の成果、フルスクラッチで学習した100B級日本語LLMを公開しました
	- ストックマークは、1000億パラメータの日本語LLMモデル「Stockmark-100b」を公開しました。 既存のモデルにデータ追加を行いチューニングしたものではなく、ゼロからフルスクラッチで開発したモデルであり、国内では(現状はダントツで)最大、グローバルでも最大級サイズのOSSモデルとなります。
		- https://huggingface.co/stockmark/stockmark-100b
- 「確率思考の戦略論」がもやもやする方へ -NBDモデル編-
	- https://zenn.dev/joanofarc/articles/strange-theory-of-probability-thinking
- LLM に表データを読み解かせたかったので、ちょっと試してみた
	- https://developers.cyberagent.co.jp/blog/archives/47869/
	- In-context Learning をベースとして手法に採用している「表形式データの読み解き」に関する論文(ICML2024)を、個人的ピックアップで紹介してみました。
	- https://openreview.net/forum?id=4L0xnS4GQM
- 負の二項分布の疫学とマーケティングでの応用の比較
	- https://socinuit.hatenablog.com/entry/2024/05/16/185601
	- 西浦『感染症を読み解く数理』と森岡・今西『確率思考の戦略論』において、負の二項分布を用いたモデル応用について記述されており、 相互を参照・比較することで類似点や解釈の拡大を試みる。
	- この記事で述べたいことは、**疫学とマーケティングという一見して距離のある領域で、負の二項分布を用いた現象の確率モデル化の事例が取り上げられていて面白いね**、ということに尽き
- 最近Gemini 1.5 ProのPDFパースが便利だと気づいて色々試している
	- https://x.com/resnant/status/1791104886563811520
	- 今のところ先行研究の論文PDFを放り込んで「この研究のXXという点を解決/拡張するとどんな価値が生まれる？その結果をどう訴求する？」みたいに研究ネタの壁打ちで使うと心強い
-  2023年度 デジタル庁・行政における生成AIの適切な利活用に向けた技術検証を実施しました
	- https://www.digital.go.jp/news/19c125e9-35c5-48ba-a63f-f817bce95715
	- 「実証の最中にも環境が激変する中で、ただ試して終わらせるのではなく、しっかりと知見を共有し、データ整備はじめ次の動きに繋げていくことが重要と考えています」 by 楠さん
	- https://x.com/masanork/status/1790871089121513629
- ChatGPTがGoogle DriveやMicrosoft OneDriveからSpreadsheetやExcelを読み込んで分析・可視化を手伝ってくれる機能を近く公開
	- https://x.com/MLBear2/status/1791251518110523764
-  HCI研究に対する私見 - CHI2024参加を終えて　by 稲見先生
	- https://note.com/drinami/n/nfd4921806ad3?sub_rt=share_pb
	- 「HCI研究おもちゃ論」がかつて議論されていたことがありましたが「おもちゃに詰まった知恵と役割をバカにするな。比喩として不適切」というのが私の見解です
- 「競争力ある生成AI基盤モデルの開発（助成）」に、ELYZAが採択
	- https://x.com/ELYZA_inc/status/1791348009764360577
	- 経済産業省が立ち上げた「GENIAC」のもと、NEDOが公募
	- Mixture of Expertsアプローチの採用や、日本特有のデータの学習、日本語の推論効率化などを実施予定
- "functional ontology"
	- https://x.com/Westoncb/status/1791152606309687768
	- As an alternative to LLM summarizing, I've been getting very interesting results doing something like:
	- https://symbolflux.com/ApolloLunarLandingTrajectoryReconstruction.txt
- QA over large embedded tables without hallucinations (Caltrain schedule edition
	- https://x.com/llama_index/status/1791505972407746671
	- With LlamaParse, we were able to spatially layout the text in a semantically coherent manner, so that our GPT-4o-powered QA pipeline could correctly answer questions
		- https://github.com/run-llama/llama_parse/blob/main/examples/caltrain/caltrain_text_mode.ipynb
- MediaPipe LLM Inference APIを使って、MediaPipe形式に変換するとGemma 2Bや とGemma 7B、Phi-2、Falcon-RW-1B、StableLM-3BなどをブラウザやAndroids、iphoneなどで動かす事ができるようになる
	- https://x.com/webbigdata/status/1791497099315752967
	- You can now run the 7B parameter version of Gemma, entirely locally in the browser, using MediaPipe LLM Inference API.
		- https://x.com/googledevs/status/1791174333995299216
- stockmarkさんが公開されているstockmark-100bのggufあります
	- https://huggingface.co/mmnga/stockmark-100b-gguf
- Gemini 1.5 Flashで、12分の音声ファイルを全て文字起こし。完璧。GPT-4oでもこれは無理
	- https://x.com/Taiyo_AiAA/status/1791460870947774826
-  EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
	- https://www.docswell.com/s/DeepLearning2023/K1JDN3-2024-05-16-142439#p9
	- 事前学習済みの拡散モデルを用いて，追加の学習を一切行わずにセグメンテーションを行うことができることを示した論文．拡散モデルは高精細に画像生成をできるが，その内部には画像細部のセマンティックな情報を持つことが示唆される．
-  LangChain v0.1 から v0.2 への移行手順 by npakaさん
	- https://note.com/npaka/n/n161a7e3882b3?sub_rt=share_h
	-  import変更の例
		- **langchain → langchain_community**
			- vectorstoresとか
		- **langchain-community → langchain_openai**
			- ChatOpenAIとか
		- **langchain-community → langchain-core**
			- document_loadersとか
		- **langchain → langchain-core**
			- Documentとか
		- **langchain → langchain-text-splitters**
			- text_splitterとか
- ADA-V2、GPT-4oだかを微調整してコーディング性能上げたモデル
	- https://x.com/umiyuki_ai/status/1791429524351258857
	- OpenAIがGPT-4TだかGPT-4oだかを微調整してコーディング性能上げたモデルにADA-V2なんてネーミング付けたのがマジだとしたらその理由は？AdaはGPT-3四天王の中で最弱のモデルだった。つまり、GPT-4がAda-V2ならBabaggi-V2やCurie-V2、そしてDavinci-V2はどうなってしまうのか…？という匂わせ
-  Finetuning Llama3 using Unsloth
	- https://github.com/neo4j-labs/text2cypher/tree/main/finetuning/unsloth-llama3#using-chat-prompt-template
	- https://huggingface.co/tomasonjo/text2cypher-demo-16bit
	-  I've finetuned Llama3-Instruct:8b to generate @neo4j Cypher statements based on the GPT-4o synthetic dataset I've generated at the start of the week.
-  LangChain のユースケース by npakaさん
	- https://note.com/npaka/n/n5956ef3a0a09?sub_rt=share_h
	- 「RAGのQA」は、RAG技術を使用して、特定の情報源に関する質問に回答するチャットボットを構築します
	- 「情報抽出」は、LLMでテキストから構造化データを抽出するユースケースです。次の3つのアプローチがあります。
		- **Tool Callingモード** : Tool Callingで指定されたスキーマに従って、構造化データを出力
		- **JSONモード** : プロンプトの一部としてスキーマを提供し、JSONデータを出力
		- **プロンプトベース** : 指示に従って生成されたテキストを既存のパーサーで解析し、構造化データを出力
	- 「チャットボット」は、長期的な対話を維持し、ユーザーの質問に関連情報を使用して回答する能力を持ちます
	- 「ツールエージェント」は、自然言語インターフェースを通じてAPIや関数、データベースなどのツールを操作するシステムを構築します。  
		- **チェーン** : ツール使用の事前定義されたシーケンスを作成
		- **エージェント** : ツールを繰り返し使用してタスクを自動的に実行
	- 「クエリ解析」は、ユーザーの質問を最適化して検索クエリを生成し、より正確な情報を取得することを目的としています。
		- 手法には、クエリの分解、クエリ拡張、仮想ドキュメントの埋め込み、クエリのルーティング、ステップバックプロンプティング、クエリの構造化などがあります。
	- SQLデータベースQA」は、「SQLデータベース」を対象としたQ&Aシステムを構築します。
	- 「グラフデータベースのQA」は、「グラフデータベース」を対象としたQ&Aシステムを構築します
		- 「Cypher」や「SparQL」などのグラフクエリ言語を使用し、自然言語の質問に基づいてクエリを生成し、データベースからの情報を取得して回答を生成するチャットボットやカスタムダッシュボードを作成します
	- 「コード理解」は、ソースコードの分析を目的としています。具体的には、コードベースに関するQ&Aを行い、リファクタリングや改善の提案、コードのドキュメント化を支援します
	- 「データ生成」は、人工的にデータを生成することで、機械学習モデルの学習やテストに役立てます
	- 「タグ付け」は、ドキュメントに感情、言語、スタイル、トピック、政治的傾向などのクラスをラベル付けします
	- 「要約」は、長いドキュメントの内容を要約するためのシステムを構築します。複数のドキュメントや長文テキストを効率的に要約することが可能になります。これには、「Stuff」「Map-Reduce」「Refine」の3つの手法があります。
	- 「Webスクレイピング」は、Webからコンテンツを収集し、自然言語処理に使用するシステムを構築します。
-  LangChain v0.2 で 単純なLLMアプリケーションを構築 by npakaさん
	- https://note.com/npaka/n/n24d48303a496?sub_rt=share_h
-  LangChain v0.2 で エージェントを構築 by npakaさん
	- https://note.com/npaka/n/ne8ef60987e1b?sub_rt=share_b
- 生成AI学びたいなら、この２本 by 尾原さん
	- https://x.com/kazobara/status/1791454624983196148
	- 「生成AI」(3) 松尾豊・東京大学大学院教授　2024.3.15"
		- https://www.youtube.com/watch?v=U9vhGvFxKu0
	- "GPTとは何か Transformerの視覚化 |
		- https://www.youtube.com/watch?v=KlZ-QmPteqM
-  LangChain v0.2 で RAGを構築 by npaka さん
	- https://note.com/npaka/n/ne892b713bd45?sub_rt=share_h
	-  Retriever
		- 「VectorStore」はRunnableをサブクラス化しないため、LECLチェーンにすぐに統合することはできません。「Retriever」はRunnableであるため、標準セットのメソッド (同期および非同期の呼び出しやバッチ操作など) を実装し、LCELチェーンに組み込まれるように設計されています。
	-  RAGチェーン
		- 「Retriever」は、特定の質問と取得したコンテキストを組み合わせて LLM のプロンプトを生成するRAG アプリケーションなど、より複雑なアプリケーションに簡単に組み込むことができます。
		- rag_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
- “MambaOut: Do We Really Need Mamba for Vision?”
	- https://arxiv.org/abs/2405.07992
	- Based on our concept discussion, we hypothesize Mamba is unnecessary for ImageNet while exploring for detection and segmentation remains worthwhile. To verify these, we build MambaOut with Mamba blocks but remove their core token mixer, SSM.
- Text-to-SQL - fully local edition
	- https://x.com/llama_index/status/1791915423816204494
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
	-  Text2SQL OpenSource : duckdb-nsql-7B with Ollama and LlamaIndex on local setup
		- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
- 

## 5/13

先週に引き続きgpt2-chatbotがchatbod arenaに復活したりと、話題に事欠かないが、サム(OpenAIの社長)から、5/13月曜日に何か発表があるとのポストが、GPT-5でも（うわさの）検索エンジンでもないといっているし、映画Herに出てきたような音声アシスタントという下馬評。おっとCOCONA（_ココナ_）の立場は？。OpenAIといえば、Stack Overflowとの提携、回答者にchatptが登場するのか、またモデルがどのように動作するべきかを規定するModel Specを公開、EUのAI法対策か（以前はSystem Cardがその役割だった）とも見れるし、安全性に本気に取り組んでいる姿勢にもみえる、ともかく来たるGPT-5の素性も透けて見えるというのは面白い分析。あと、今週は国内勢の活躍も活発だった、東工大のSwallow-MX-8x7b-NVE-v0.1をファインチューニングしたKARAKURI LM 8x7B Chat v0.1、13Bで104BのCommand R+を超えるって本当？。「Japanese Stable LM 2 1.6B」、 属性予測モデル　KARAKURI LM 7B APM v0.1 、「Fugaku-LLM」の公開など。さて様々な評価から性能が高い、使える、とされているllama3、日本語がやっぱりダメダメだったりはご愛敬でも、量子化に弱かったり（コンパクトで性能が高いというのは量子化の余地も少ない）と、LLMのスケール測の一端を思い知らす結果になってるというのは面白い、tokenerizerが壊れているとのうわさも。"DeepSeek-V2"ってのがGPT-4と同レベル。かかるコストは200分の1というのは本当だろうか？Google/DeepMindからは「AlphaFold 3」を発表、こんどはDNAも扱えるとのこと、創薬が劇的に加速する予感。先週に引き続いてKANの評価も進む、shi3zさんの「最後にKANは勝つ」というKAN評価試行のnoteのタイトルは「最後に愛が勝つ by KAN」のもじり？それにしてもKANさんご冥福をお祈りします。Microsoftが自社製LLMである「MAI-1」を開発中、ＸはGrokを有料ユーザーに開放。Deeplearning.aiからは、llamaindexのJerry Liu(CEO)を講師にAgentic RAG、LangChainのHarrison(CEO)を講師に、Functions, Tools and Agentsのショートコースが無料公開、なんて豪華な。そのLangChainはv0.2がリリースが間近に、AgentやTool関連の見直しがされる。あとなぜか、時系列予測の基盤モデルの発表も相次いだ、Google/TimesFM、IBMのTinyTimeMixers (TTMs)、ICML2024にアクセプトされた、CMUとUPENのMOMENT、ひょっとしてICML2024がTime Seriesの基盤モデル祭りになってるのか。早速、データサイエンスクラスタからは、(AirPassengerデータに対し）一階差分もとらんのかと冷笑も。xLSTMとか、Vanilla Bayesian Optimization とかの基盤技術の進展もあり、しらんけど。。喜連川先生監修の「生成AIの論点」というのは、日本のLLMをめぐる状況を把握にはよいかも、それにしても「情報大航海時代」はなくなったことになったのか？最後に、THE GUILDの深津さんの、「情報が多すぎて頭がパンクするのは正常ではない」というのは、激しく同意する。

- gpt2-chatbotがchatbot arenaに復活？
	- https://x.com/alfredplpl/status/1787754701536325720
-  最後にKANは勝つのか?MLPに変わると主張されるKANを試す by shi3zさん
	- https://note.com/shi3zblog/n/n1e592409a345?sub_rt=share_pb
	- Efficient-KANが手っ取り早くMNISTが試せそうだったので試してみた
	- つまり、同規模の場合、学習すべきパラメータ数は10倍になり、性能差は縮んでいくという結果になった
- KARAKURI LM 8x7B Chat v0.1を公開しました！
	- https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-chat-v0.1
	- 1. 東工大から出ているSwallow-MX-8x7b-NVE-v0.1をベースにカラクリのデータでチューニングしました。（圧倒的感謝） 
	- 2. 前回に続き、国産オープンモデルとしてはMT-Bench-jpで最高性能を更新 
	- 3. Active Parameter数 13Bで104BのCommand R+を超え、72BのQwen 1.5に迫る性能 
	- 4. AWS TrainiumでのMoEモデルの学習はAWSの担当の方にも確認しましたが、おそらく世界初とのこと。コードは技術ブログの記事とともに近日公開予定。 
	- 5. 前回に引き続き、SteerLMによるアライメントを実施。属性予測モデル（APM）はgemma 7bをチューニングし、公開
-  CACTUS: Chemistry Agent Connecting Tool-Usage to Science
	- https://arxiv.org/abs/2405.00972
	- 化学のためのAIエージェントの論文
	- 化学に関する数千の質問と回答を作成し様々なオープンLLMの性能を比較。Gemma-7bとMistral-7bで高精度を実現、また精度を維持しつつ民生レベルのハードへ導入ができそうだとわかったそうです。
- Stack OverflowがOpenAIと提携？
	- https://x.com/ImAI_Eruel/status/1787670618961514627
	- おそらくChatGPTの登場によってユーザー数の減少という点で最大の被害を被ったのはプログラミングの質問解答サービスStack Overflowなんですが，この度OpenAIとの提携が決まったとのこと
- 精度上げようとすると自然とLLMに頼る箇所減ってピンポイントになる
	- https://x.com/mizchi/status/1787639942216327442
- KARAKURI LM 8x7B Chat v0.1 をお試し中
	- https://lm.karakuri.cc/
- 【GPT-4と同レベル。かかるコストは200分の1】最強LLM「DeepSeek-V2」発表
	- https://x.com/SuguruKun_ai/status/1787839473067376705
	- この子がGPT-4相当と言うのはあってそうで結構文才もある ついでに倫理面も割と高めな感じで日本語出力は悪くない 結構良い感じかも！
- Grokがきた！今はX課金者限定
	- https://x.com/hirochuu8/status/1787880221997515258
- iPad Pro 13 インチ Nano-textureガラスモデルの価格 ≒ KARAKURI LM 8x7bの学習にかかったコストです
	- https://x.com/txmy/status/1787859094034059669
- 日英／英日翻訳タスクにおいてmeta/Llama 3ではgoogle/Gemmaを超える事が出来ない
	- https://x.com/webbigdata/status/1787457498057933299
- Karasu-Mixtral-8x22B-v0.1のgguf
	- https://huggingface.co/mmnga/lightblue-Karasu-Mixtral-8x22B-v0.1-gguf
- lightblue-suzume-llama-3-8B-multilingualのgguf
	- https://huggingface.co/mmnga/lightblue-suzume-llama-3-8B-multilingual-gguf
- Let's build a 100% local RAG app, featuring ⌘R, a self-hosted vector database, a fast embedding library & a reranker:
	- https://x.com/akshay_pachaar/status/1787824526010782053
- Reranker allows you to reorder the retrieved context (chunks), offering two key benefits:
	- https://x.com/akshay_pachaar/status/1787824694768648575
- Ollama v0.1.34 is out!
	- https://x.com/ollama/status/1787976537762856999
- A built-in planning agent for LlamaIndex landed in 0.10.34!
	- https://docs.llamaindex.ai/en/stable/examples/agent/structured_planner/
	- A key pattern in agents is the ability to plan. Breaking down a task into sub-tasks can make the task easier to execute.
- Microsoftが自社の大規模言語モデル「MAI-1」を開発している
	- https://x.com/ImAI_Eruel/status/1787787401055908017
	- 5000億パラメータとの話もあり,本当なら既存モデルで最大レベル.後出し考慮でGPTやClaude超えもできそうか
- DeepSeek-V2、236B のクソデカモデルでありながら推論時は実質 21B 相当の MoE らしく
	- https://x.com/izutorishima/status/1787775197057265925
- ぬこぬこ氏、退職し、本業 LLM 無職へ、
	- https://x.com/schroneko/status/1788148600171831406
- HachiML/Hachi-Alpaca by はちさん
	- https://huggingface.co/datasets/HachiML/Hachi-Alpaca
	- Mixtral 8x22B Instructによる日本語合成データ、28.9kで一旦完了にしました。v1.0_cleanedが精査済みです。
- Zennのトレンド記事を、毎朝AIがラジオ風に紹介してくれるサービスをつくりました
	- https://zenncast-web.vercel.app/
- Announcing AlphaFold 3
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- AlphaFold2の時点で，「ノーベル賞レベル」と言われて最終形態かと思いきや，まさかの3が出てきました by 今井さん
- Deeplearning.aiより無料の、Building Agentic RAG、が公開
	- https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/
- xLSTM: Extended Long Short-Term Memory
	- https://arxiv.org/abs/2405.04517
	- Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to SotA Transformers and State Space Models, both in performance and scaling.
- 4M Context Length Llama-3 8B (V0.1)
	- https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-4194k
- 日本学術会議総会での講演「日本の研究競争力低下の因果推論」の資料が面白い．
	- https://www.scj.go.jp/ja/member/iinkai/sokai/siryo191-2-1.pdf
	- 日本の研究競争力低下の因果推論
	- どれだけ**「研究人・時間密度」（良き人的研究環境の広がり）**を保てるかに、今後の日本の研究競争がかかっている。
- OpenAIがAIモデルがどのように動作するべきかを規定するModel Specを共有
	- https://openai.com/index/introducing-the-model-spec/
	- え、このタイミングてChatGPTの内部挙動わざわざ公開するのなぜ？EU的なやつ？ by 深津さん
	- ここから、GPT-5の特徴が使い勝手がわかるらしい
-  Google Colab で 属性予測モデル　KARAKURI LM 7B APM v0.1 を試す
	- https://note.com/npaka/n/ndb541c2cf03b?sub_rt=share_h
	- 「KARAKURI LM 7B APM v0.1」は、属性予測モデルです。「Gemma 7B」のファイチューニングモデルになります。
	- 属性の値は **0(最低)〜4(最高)** になります。
- karakuri-lm-8x7b-chat-v0.1のggufあります
	- https://huggingface.co/mmnga/karakuri-lm-8x7b-chat-v0.1-gguf
	- imatrixのデータはTFMC/imatrix-dataset-for-japanese-llmを使用して作成しました
- グーグルが、生物学に革命を与えたタンパク質構造予測AIの最新モデル「AlphaFold 3」を発表（ネイチャー論文）
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- タンパク質、DNA、RNA、小分子などほぼ全ての生体分子の構造と相互作用を高精度に予測 生成
	- AIを支えるtransformerと拡散モデルの発展で生物学や創薬が加速
- 毎日がイノベーションすぎて、もはや全容が把握できない。時事ニュース追うだけでパンクする世界は、あまり健全ではない by 深津さん
	- https://x.com/fladdict/status/1788208163965305143
- 日本語特化の言語モデル「Japanese Stable LM 2 1.6B」をリリースしました
	- https://ja.stability.ai/blog/japanese-stable-lm-2-16b
	- Japanese Stable LM 2 1.6B（JSLM2 1.6B）は16億パラメータで学習した日本語の小型言語モデルです。
- TimesFM by DeepMind
	- https://huggingface.co/google/timesfm-1.0-200m
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. 
- Uncertainty Quantification and Propagation in Atomistic Machine Learning
	- https://arxiv.org/abs/2405.02461
	- 不確実性評価のレビュー論文
	- 機械学習でデータが少ない領域を予測するのは困難ですが、それを克服する不確実性評価の手法が教科書的にまとまっています。まだ汎用的手法はなくデータにあった手法をうまく選択することが大切とのこと。
- サムから、月曜に大きな発表があると、、
	- https://x.com/sama/status/1788989777452408943
	- not gpt-5, not a search engine, but we’ve been hard at work on some new stuff we think people will love! feels like magic to me.
-  「Fugaku-LLM」を公開
	- https://pr.fujitsu.com/jp/news/2024/05/10.html
	- 横田さんのとこ、
	- 「Fugaku-LLM」は「富岳」の13,824台の計算ノードを用いて、約4,000億トークンを学習した13Bモデルです
-  LangChain v0.2 の概要 by npakaさん
	- https://note.com/npaka/n/na9e629ebbd16?sub_rt=share_h
	- **・langchain と langchain-community の完全な分離  **
	- **・バージョン付きドキュメント**  
	- **・より成熟したエージェントフレームワーク**  
	- **・LLMインターフェースの標準化、特にツール呼び出しに関する改善**  
	- **・ストリーミングサポートの向上**  
	- **・30を超える新しいパートナー パッケージ**
- 日本語高速ASR Kotoba-Whisper v1.1にアップデートしました
	- https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1
	- 句読点予測を改善 (raw CERで大幅な向上) - Stable-tsの統合により、timestampの予測を向上 - Long-form transcriptionの予測向上 - 学習・推論コードを公開:
- ibm-granite/granite-timeseries-ttm-v1
	- https://huggingface.co/ibm-granite/granite-timeseries-ttm-v1
	- TinyTimeMixers (TTMs) are compact pre-trained models for Multivariate Time-Series Forecasting, open-sourced by IBM Research. 
	- **With less than 1 Million parameters, TTM introduces the notion of the first-ever “tiny” pre-trained models for Time-Series Forecasting.**
- Great, now we have some clean Llama 3 models (both 8B and 70B)
	- https://huggingface.co/ddh0/Meta-Llama-3-8B-Instruct-bf16-GGUF
	- Those minor bugs in llama.cpp has been resolved so should work at its full potential.
- マイクロソフトが1月に発表したSliceGPTでは、LLMのウエイトを圧縮できちゃうらしい。
	- https://x.com/umiyuki_ai/status/1789128885558546881
	- ウエイトの各行列を次元数減らした行列に置き換えちゃうんだって。これでパラ数を25%まで削れて（つまり52.5Bになる？）、Llama2-70Bの場合は性能の低下は1%だけで済むらしい
- Google/TimesFMはモデリングから微妙だし
	- https://x.com/kyo_takano/status/1789150904102613131
	- 一階差分を取らずに非定常過程のまま予測器に突っ込む; 
	- Transformersを使いたいがために複数時点を単一トークンとして埋め込む・予測する; etc.）、
	- 古典的な統計モデルに対して部分的にしか上回ってないんだよね
- Ollamaに、MLX対応くる？
	- https://x.com/m_sigepon/status/1789233089945981319
-  Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals
	- https://jamanetwork.com/journals/jama/fullarticle/2818746?utm_source=twitter&utm_campaign=content-shareicons&utm_content=article_engagement&utm_medium=social&utm_term=051024
	- 医学観察研究で因果関係を示すためにはどうする？6つの条件を示して、これを満たしていれば因果関係を言ってもいいんじゃない？という提言。
- google/timesfm-1.0-200m
	- https://huggingface.co/google/timesfm-1.0-200m
	- Google released a decoder-only "foundation" time series model on
	- Trained on a corpus of 100B real world time-points from Google Trends and pageviews from Wikipedia!
- 『データサイエンスと機械学習』にはKANで話題沸騰中のコルモゴロフ･アーノルドの表現定理が掲載されていた。
	- https://x.com/bebebeBayes/status/1788900859570700291
- 大屋雄裕「信用・信頼・信託 —責任と説明に関する概念整理―」
	- https://x.com/rmaruy/status/1789193304808296841
	- AIの説明可能性／責任について、ウィトゲンシュタインの原因／理由の区別から紐解き、プロセスの透明性だけでなく答責性が問題になる場面がどんなときかを議論。この上なく明晰。
- lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- https://huggingface.co/lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- rinna様のllama-3-youko-8bを少数の英日対訳データ+LoRAでSFTしてみました
-  Post Llama 3 depression
	- https://www.reddit.com/r/LocalLLaMA/comments/1colmeb/post_llama_3_depression/
	- Llama3の微調整モデルは色々出たけど今んとこどれもアカンという話。原因はよく分からんけどもう今までの微調整のやり方は時代遅れなのかもしれない。少なくともLlama2とは勝手が違うらしい
- 「ローカルLLMはこーやって使うの」を更新しました
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	-   以下を追加: 
		- 前提知識の確認 
		- 特殊トークンによるプロンプトインジェクション 
		- 尤度関数としての利用
- Difyの勢いがすごい。LangChainやFlowise、Llama Indexを抑えてLLMツール4週間で1位に
	- https://x.com/kyutaro15/status/1789054552638943495
- You can now generate production-ready prompts in the Anthropic Console.
	- https://x.com/AnthropicAI/status/1788958483565732213
- Vanilla Bayesian Optimization Performs Great in High Dimensions
	- https://arxiv.org/abs/2402.02229
	- バニラのベイズ最適化が高次元でも大活躍
	- これまで高次元は呪いの領域と思われていたが、適切な仮定を設けるだけで最先端の手法を圧倒する性能が出せることが判明
- DeepLearningAIから、今度はLangChainのCEOの講義
	- Check out the short course Functions, Tools, and Agents, taught
	- https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/
- "MOMENT: A Family of Open Time-series Foundation Models"
	- https://moment-timeseries-foundation-model.github.io/
	- has been accepted for the ICML 2024! On this occasion, we are open-sourcing it, together with the model weights and dataset!
- 生成AIの論点
	- https://www.seikyusha.co.jp/bd/isbn/9784787235374/
	- 喜連川先生まだいきてたのか？
	- 日本学術会議が実施し、過去最多の動員を達成したシンポジウム「生成AIの課題と今後」の書籍化である
- 

## 5/7

ＧＷで、頭がぼけているのか、X(旧twitter)のアルゴリズムが変わったのか、おすすめに出てくるツイートが先週とかぶっている気がする。Xの生成ＡＩを使った新サービス「ストーリーズ」の展開と関係あるのか？。今週は突然でてきた謎のgpt2-chatbotが面白かった、gpt2と名前があるものの、GPT-4.5かGPT-5のフィールドテストかという話で持ち切りだった（Chatbot Arenaからは消えた。。）、評価できた人によると、相当すごい性能らしい。Swallow-MS 7Bの新しいinstructモデル、さっそくElyzaTasks100で評価され、ちょっと微妙な結果に。一方ElyzaTasks100での評価によると、Qwen1.5はかなり優秀だけど時々日本語に難ありとのこと。Domingos氏のAIの能力の発展がサチっているていう話は、（そもそもデータとして使った）人間の能力がAIの進化を律速しているとのこと。そりゃ、人間を超えるのは人間のデータでは無理だ、超えたところで人間にはわからないというのはそうかも。BCGの売上20%が生成AI関連とのこと、コンサルはなくならない、金の儲け方が変わるだけ。「統計的テキストモデル」全文がプレ公開されたとのこと、われは！と思う人はぜひチャレンジを。Ollamaを使ったローカルLLMの利用例もぐっと増えた、もはやRAGは誰でもできる、さらにReAct Agentとか、Function Callingとか、よりむつかしいタスクむできるようになった、気のせいかLlama3やphi3が使われる例が多いような。Kolmogorov–Arnold Networks、新しい生成AI向けニューラルアーキテクチャ？特異学習理論（渡辺ベイズ理論）を発展させた局所学習係数という新しい概念も気になる、アライメントととも関係あるとか。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。「ローカルLLMはこーやって使うの」は参考になる、ローカルLLMならいろいろやり放題なんだな。ＡＩセイフティでは、NISTから、生成ＡＩ向けのリスク管理フレームワークが発表、日本のAISIとの連携も進む。AIアライメントの包括的なサーベイ、「AIによる絶滅リスクの軽減」だと。rinnaからLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開、NIIから「LLM-jp-13B v2.0」を構築とか、頑張れ日本勢。うみゆきさんが言うように、進化型のLLMのマージMergekit-Evolveってのは本当にすごのいか？？LangChainの４つのRAG向けchainの比較も地味に役に立つ。ローカルLLM系では、自作小説をLLMで評価させているひとが、 command-r-plus-Q4_K_Mを絶賛評価、実作業に基づく評価は尊い。ChatGPT東大入試に挑むも「不合格」の記事（日経）、さっそくプロンプトが悪いと、いや解けたよ、との突っ込みが、次々と。。

- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較｜
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	- stuff chain、map reduce chain、map rerank chain、refine chain
	- 応答速度 : 呼び出し回数が1回のstuffは「速い」, n回ですが各文書に対するLLM呼び出しを並列化できるmap系2種は「普通」, n回かつ並列化ができないrefineは「遅い」としています。
	- 適している文書特徴
		- stuff・map reduce : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- map rerank : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- refine : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7bをElyzaTasks100で評価してみたら平均3.57点を叩き出した　 by うみゆきさｎ
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- 7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！
- Swallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました
	- https://huggingface.co/collections/tokyotech-llm/swallow-ms-instruct-662957bf88d016c69ae0e633
	- あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】  512トークン、340Token/S
	- https://x.com/hokazuya/status/1783808939773304957
	- ローカルLLMでこの性能はPhi-3やLlama3の7Bなど見てきたがMac単体でこれはスゴすぎる。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘している
	- https://x.com/pmddomingos/status/1783956607552176422
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
	- https://x.com/rmaruy/status/1784154638390104188
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
- 『Symbol-to-Language』
	- https://x.com/ai_database/status/1784581982053347542
	- LLMのタスクにおいて「記号を自然言語テキストに変換する」ことで様々なタスクで精度が上がる現象が報告されています。
	- 実験では、物性予測、表の理解、ツイート分析などで効果が出ています
- BCGの売上20%が生成AI関連で、2026年までに40%にまで増えるとか
	- https://www.ft.com/content/33dfaec4-b5e7-4eca-a869-cdd33d447e65
- lama 3 degrades more than Llama 2 when quantized.
	- https://x.com/rohanpaul_ai/status/1784889182558539917
- gpt2-chatbotと呼ばれる謎のモデル
	- https://x.com/bioshok3/status/1784972619957346703
	- Chatbot arena でClaude3 opusやGPT-4 Turboに匹敵するとかしないとか超えてる超えてない言われ今少し話題になっている
- ReAct Agent with Function Calling | Open Source Gemma LLM | Ollama | Lan...
	- https://www.youtube.com/watch?v=exYUJcz4uZs
- llama-2-13b-retrievalqa.ipynb - Colab
	- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/llm-field-guide/llama-2/llama-2-13b-retrievalqa.ipynb#scrollTo=JPdQvYmlWmNc
- crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
	- https://huggingface.co/crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
- react-agent-with-function-calling-ollama-langsmith.ipynb
	- https://github.com/Ashufet/LangChain_ReAct-Agent-with-Function-Calling_Ollama-Gemma-LLM_LangSmith/blob/main/react-agent-with-function-calling-ollama-langsmith.ipynb
- Google announces Med-Gemini, a family of Gemini models fine-tuned for medical tasks!
	- https://x.com/iScienceLuvr/status/1785247498744778886
- 「統計的テキストモデル」の全体の原稿(4章以外)のβ版を公開しました
	- http://chasen.org/~daiti-m/textmodel/
- Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities
	- https://arxiv.org/abs/2404.17790
	- 東工大のLLM、Swallowの論文がarXivに公開されていますね。
	- 日本語の継続事前学習について、データのスケーラビリティや語彙拡張、パラレルコーパスの影響について大規模かつ系統的に知見を提供している研究で、勉強になります
- gpt2-chatbotは本当にモデル名だ。そうHFのCTOがいまopenai-communityからホスティングしていると思われる。
	- https://x.com/alfredplpl/status/1785170960251007266
- 大規模言語モデル「LLM-jp-13B v2.0」を構築
	- https://www.nii.ac.jp/news/release/2024/0430.html
	-  NII主宰LLM勉強会（LLM-jp）が「LLM-jp-13B」の 後続モデルとその構築に使用した全リソースを公開
- Qwen1.5シリーズを一通りElyzaTasksで評価してみた
	- https://x.com/umiyuki_ai/status/1785272618595262646
	- やっぱりQwen1.5はかなり優秀。7BモデルはLlama3-8Bのチョイ下。14Bモデルは35BのCommand Rを超えてる！
- AISIと米国NISTは、日本の「AI事業者ガイドライン」とNISTの「AIリスクマネジメントフレームワーク(RMF)」のクロスウォークの第一弾として用語に関する「クロスウォーク1」を公表しました。
	- https://aisi.go.jp/2024/04/30/ai_rmf_crosswalk1_news/
- 謎の高性能AIモデル「gpt2-chatbot」がChatbot Arenaに登場、GPT-4.5かGPT-5なのではないかと話題に
	- https://gigazine.net/news/20240430-lmsys-chatbot-arena-gpt2-chatbot/
	- 日本の歴史についても、ハルシネーションの多いClaude 3 Opusと比較して、遥かに優れた回答。論理的な考察についてもレベルが高い。
- 自作小説をLLMにレビューさせてみる（ローカル4モデル、サービス型3モデル）
	- https://note.com/kohya_ss/n/nfcdfd6de8790
	-  command-r-plus-Q4_K_M: 極めて高い理解力と要約力を示し、作品の伏線や登場人物の理解も的確だった。文章は読みやすく洗練されており、ローカルLLMの中で最も優秀な性能を示した。小説のテーマを深く理解し、適切な批評を行っている。
- US NIST publishes 1st draft of its "AI Risk Management Framework: Generative AI Profile." 
	- https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf
- rinnaはLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開しました。
	- https://huggingface.co/rinna/llama-3-youko-8b
- KAN: Kolmogorov–Arnold Networks
	- https://arxiv.org/abs/2404.19756
	- https://github.com/KindXiaoming/pykan
	- Proposes an alternative to MLP that outperforms in terms of accuracy and interpretability
	- 重みを学習させるのではなく、エッジ上に配置した活性化関数を学習させる(エッジの重みは1で固定)新しいニューラルネットワークのアーキテクチャの提案。…
	- ちなみにニューラルネットワークとコルモゴロフ-アーノルド表現定理の話題に関しては，そんなに新しいものではなく，結構昔から出ているものではあります(今井さん)
- RAGのG（Generation）、つまり"生成"は本当に必要なのか？
	- https://x.com/Nurruttan/status/1785853289034350622
- AI Alignment: A Comprehensive Survey.
	- https://alignmentsurvey.com/uploads/AI-Alignment-A-Comprehensive-Survey.pdf
	- AIアライメントの包括的なサーベイ
	- AIアライメントは、AIシステムを人間の意図や価値観に沿って行動させることを目的としている。AIシステムの能力が高まるにつれて、ずれたAIシステムに関連する潜在的な大規模リスクが顕著になっている。何百人ものAI専門家や著名人がAIリスクへの懸念を表明し、「AIによる絶滅リスクの軽減は、パンデミックや核戦争といった他の社会的規模のリスクと並んで、世界的な優先事項であるべきだ」と主張している
- ローカルLLMはこーやって使うの💢
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	- ①トークンの生成確率が全部見れる。これを応用するとハルシネーションや誤字脱字の検出もできるかも。というのはどのワード生成時に自信が無かったかが確率を見れば分かるから。②回答の冒頭部分を強制できる。
- X、生成AIでニュースの要約を開始　一部の有料会員に
	- https://www.nikkei.com/article/DGXZQOGN0406N0U4A500C2000000/
	- 「新機能「ストーリーズ」を始めた。米xAI（エックスエーアイ）の対話AI「Grok（グロック）」がX上で話題のニュースなどについて情報を要約」
- How LLMs work, clearly explained with visuals:
	- https://x.com/Sumanth_077/status/1786404341735444731
- Build a RAG system with Llama 3B-Instruct for your PDFs
	- https://colab.research.google.com/drive/1BJYYyrPVe0_9EGyXqeNyzmVZDrCRZwsg?usp=sharing#scrollTo=Y2m2l-vt_RSp
-  TAIS 2024 | Insights from two years of AI safety field-building at MATS — Ryan Kidd
	- https://www.youtube.com/watch?v=tA9K8JqyhP4
	- Don't miss @jesse_hoogland captivating talk at TAIS2024 on the structure of neural networks and the links between learning theory and interpretability! Watch now:
	- 特異学習理論（渡辺ベイズ理論）を発展させて局所学習係数という新しい概念を創出し，①transformerの学習ダイナミクスの解析，②機械論的解釈可能性の基盤理論としての可能性，③AIアライメント理論の展望を力説した2人の研究者のTAIS2024講演
- 「確率変数」の正体は米田埋め込み
	- https://m-hiyama.hatenablog.com/entry/20170228/1488276250
- ChatGPT、東大入試に挑む　英語8割超も数学1点で「不合格」
	- https://www.nikkei.com/article/DGXZQOUC2103E0R20C24A3000000/?n_cid=SNSTW005
	- 「この計算は手作業では困難。数学の専門書をおすすめする」。人ごとのような答案もありました。古文も文脈を理解できず0点。一方、英作文や英訳は満点でした
- 2024年東大入試数学の第1問の(1)をプロンプトを工夫して解いてみたら、一発で解けた。これだけで5点くらい取れているはず
	- https://x.com/itnavi2022/status/1787121446445326816
- 第2問の(1)は、プロンプトを工夫しなくても、ChatGPTで普通に正解できた。
	- https://x.com/itnavi2022/status/1787448789693059176
- Nvidia が出した、Llama3-ChatQA-1.5の微調整でRAG＆対話性能爆上がり。
	- https://x.com/hokazuya/status/1786901364213416356
- LangChainのllama.cpp統合
	- https://x.com/yuiseki_/status/1787091439408816479
- 【vLLM on Hugging Face Interface】
	- https://x.com/hokazuya/status/1787060961570127973
	- 便利すぎ。爆速でLlama 3 -8BのLLMを動かす＋OpenAIのAPIを呼び出す形式でLlama 3と会話できちゃう。

## 4/29

マイクロソフトからPhi-3-miniが発表され、3.8BのモデルがMixtral 8x7BやGPT-3.5とためをはるとのこと、Phi-3-mini 4k instruct モデルはColab T4でも動くし、huggingfaceにも公開。さっそくOllamaが対応し、Llama-3 & Phi-3もRAGでの比較とかも。Llama3も、日本語向けにLoRaされたり、Llama3-70Bを42Bパラメータに枝刈りしたモデルが公開されたり、4bitに量子化して評価されたりとか、コミュニティの活動が一気に盛り上がる。なお量子化に関してはどのＬＬＭも4bit量子化しても精度がほとんど低下しないとのことだが本当か？AppleがiPhoneでも稼働するオープンな言語モデル「OpenELM」を発表、さっそくMLX LMで評価した結果が公開された、Macbook AirでPhi 3の量子化されたやつを動かして劇速といってる例とか、実は、LLMプロダクト開発者はMac 進化的を買ってローカルLLMを触るべきとの意見も見られたが、反論もぼちぼち、さても６月のWWDC24が楽しみだ。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。Groq(LPUによる高速化のほう）のAPIをStreamlitで使う方法の紹介など、Groqの利用をちらほら見るようになった、速さは最強。LLMエージェントに関するニュースを毎週まとめてくださるサイト、頭が下がる、このアプデ更新もそうありたいものだ。LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いているというのは、アライメント問題を表面上の課題ではなくアーキテクチャまで落とすところが面白い。LLMの性能評価やベンチマークに関する活動もElyzaTasks100やRAG、Query PlanningなどのタスクにおけるローカルLLMの実力が検証なんかがあった。

- モデル進化マージについて by sakana.aiの秋葉さん
	- https://speakerdeck.com/iwiwi/17-nlpkorokiumu
	- 日本語LLMのマージはあまりない、継続学習されて、元の重みからずれてしまっている。
	- そこで、進化的計算によるマージ。
-  「AI事業者ガイドライン（第1.0版）」
	- https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html
	- これまでMLPdM的な人が一般的に留意すべきと言われていたようなことに加え、より広い社会的な観点や、AIの利用者の観点なども踏まえた上でうまくまとめられている有益なガイドラインだと感じました。
	- https://x.com/yu__ya4/status/1782037184079683916
- Command R+はどこまで量子化するとアホになってしまうのか？ by npakaさん？
	- https://soysoftware.sakura.ne.jp/archives/3834
	- ローカルでCommand R+を動かすとなると、手元の環境のRTX4090が１台ではハッキリ言って1bitまで圧縮してもVRAMに載りきらない。
	- 今回はCommand R+の各量子化モデル、Q6_K、Q5_K_S、Q4_K_S、iq4_xs、Q3_K_S、iq3_xxs、Q2_K、iq2_xxs、iq1_sのそれぞれについて、ElyzaTasks100を解かせてみる。
	- API～3bitまではぶっちゃけ大差ないというか誤差の範囲だという事だろう
	- 1bitの3点というのはこれはもう完全に劣化してるというのは確実に言えそうだ。
	- まず、今回の結果だけで言えば、実用上は4bitまでの量子化なら性能劣化は見当たらないように見える。
- Fully local RAG with Llama 3 on ollama & streamlit
	- https://x.com/ashpreetbedi/status/1782079131103932647
-   LLMモデル "Llama3" を 4bit 量子化して実行してみた
	- https://qiita.com/akasakat/items/0855b5f05467cc8cbbf4
	- 一昨日発表された  [Llama3](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  を4bit量子化 してつかってみました
	-  GPUの VRAM は 6GB 程度消費します
	- Llama3の 語彙数は 32000(Llama2) => 128256 へと大幅に増えました
- LoRA fine-tuning of embedding models using LlamaIndex
	- https://medium.com/@diagnosta/lora-fine-tuning-of-embedding-models-using-llamaindex-a60b823a2c94
	- In this blog post, we’ll explore how to fine-tune black-box embedding models using low-rank adaptation (LoRA) with the LlamaIndex library. LoRA is a technique that trains a small number of rank-decomposed weights to adapt a pre-trained model to a new task or domain. 
- 自宅PCでクラスターを構築：コンシューマーGPUの枠を超え、大型LLMをローカルで動かす！ by AIサトシ
	- https://note.com/aisatoshi/n/nd4969fc42602?sub_rt=share_h
	- Command-r-Plusは、4bitに量子化しても60GB程度のVRAMが必要となります。
	- 複数PCでのモデル並列が自宅で可能となったので、理論的には、デスクトップを増やすことで巨大なLLMの推論が可能となります。
- alfredplpl/Llama-3-8B-Instruct-Ja　 by あるふさん
	- https://huggingface.co/alfredplpl/Llama-3-8B-Instruct-Ja
	- 日本語向け Llama 3 8Bを公開してみました。LoRAで表面を学習しただけなので、性能はありません。ただ、普通のLlama 3よりかは日本語が強くなっているはずです。よろしくお願いします
- Groqの値段調べ、llama3など
	- https://x.com/webbigdata/status/1782240169879601540
	- GroqはLPU(Language Processing Unit)という独自ハードウェアを開発している会社です
	- Llama 3 70BがAnthropic Claude 3 Sonnet($3.00/$15.00)相当の性能であれば、GroqのLlama 3 70B APIの価格設定($0.59/$0.79)は非常に競争力があります
- Llama 3 70b layer pruned from 70b -> 42b by Charles Goddard
	- https://www.reddit.com/r/LocalLLaMA/comments/1c9u2jd/llama_3_70b_layer_pruned_from_70b_42b_by_charles/
	- chargoddard/llama3-42b-v0
	- Llama3-70Bを枝刈りしてパラ数42Bにしちゃったというブツらしい。
-  Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
	- https://arxiv.org/abs/2404.14219
	- Microsoft announces phi-3-mini, a 3.8B model trained on 3.3T tokens that rivals Mixtral 8x7B and GPT-3.5
	- パラメータ数、学習トークン数
		- ①Phi-3-mini (38億、3兆3000億)
		- ②Phi-3-small (70億、4兆8000億) 
		- ③Phi-3-medium (140億、4兆8000億）
- は？Phi3-small-7BはMMLUが75.3点？Llama3-8Bでも66点だというのに。
	- https://x.com/umiyuki_ai/status/1782622321704079652
-  Weekly AI Agents News!
	- https://speakerdeck.com/masatoto/weekly-ai-agents-news
	- このLLMブクマアプデのように毎週、Agent関係の情報を収集している人
	- LLMエージェントに関するニュースを毎週まとめてくださる
-  From  r  to  Q∗: Your Language Model is Secretly a Q-Function
	- https://arxiv.org/abs/2404.12358
	- LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いている。例えばある対話の結果につながった原因のトークンを特定できたり、尤度最大化のビーム探索はそのまま収益最大化とみなせる by 岡野原さん
- Llama.cpp で Llama 3 70Bをお試し中。by npakaさん
	- https://x.com/npaka123/status/1782556559589212399
	- 8.42 tokens per second 
	- Meta-Llama-3-70B-Instruct-IQ4_XS.gguf 
	- M3 Max (128GB)
-  llama.cpp による transformersモデル の量子化 by npakaさん
	- https://note.com/npaka/n/nbd1348500a28?sub_rt=share_b
	- 今回は練習用に「meta-llama/Meta-Llama-3-8B-Instruct」を準備します。
	- transformersモデルをggufに変換
	- imatrix量子化
- Llama3-70BはElyzaTasks100（Command R+による自動評価）においてCommand R+超えてます
	- https://x.com/umiyuki_ai/status/1782690199677641164
- CodeQwen1.5
	- https://x.com/Alibaba_Qwen/status/1782426698279272742
	- Last week, we released a CodeQwen1.5 and received a lot of positive feedback! Thank you for your support! 
- 手元のMacbook AirでPhi 3の量子化されたやつを動かしているのだが、これGPT-3.5こえてるよね。ノートパソコンで普通に動くってどういうことだ
	- https://x.com/alfredplpl/status/1782808427129114796
- phi3 local RAG using LlamaIndex and Ollama:
	- https://x.com/llama_index/status/1782893301214986593
	- https://colab.research.google.com/drive/1RoZzbL8WYaAp4b3sazYHVI8TA2AkrtRJ#scrollTo=9AtRxaqD94mZ
- 様々なタスクでのlocal LLMの実力のベンチマーク
	- RAG, Query Planning, Text2SQL, and Pydantic Program but struggles with Routing and Agentic tasks. 
-  Feature Test for Phi-3-mini-4k-instruct
	- https://docs.llamaindex.ai/en/latest/examples/benchmarks/phi-3-mini-4k-instruct/
- Phi-3 mini 128k instruct の Colab T4 で動作確認の取れた　 by ぬこぬこさん
	- https://gist.github.com/schroneko/f4fac4c4dd541f4c5ee61c44c90c4a85
	- サンプルの方程式を解く問題は難なくクリア。日本語でもクリア。3.8B にしてはかなり日本語をナチュラルに話せているのでは？
- HuggingChatにphi3-mini-4k登場
	- https://huggingface.co/chat/
-  Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches
	- https://arxiv.org/abs/2404.14779
	- 医療ドメインでLLMをfine tuningする際、フルパラメータのチューニングをするかLoRAで効率的にチューニングするべきかをLlama-2ベースのモデルで検証した論文。
	- モデルサイズが小さいほどfine tuningの効果が大きい
	- モデルが大きいほどLoRAのパフォーマンスは古パラメータのチューニングに接近しそう
- LLMの継続学習における論文紹介
	- https://note.com/sergicalsix_/n/ndbd5b29451c9
	- LLMの継続学習においてドメインの内容や順序などについて調査。ドメインを類似度順で継続学習した方がドメイン特化させやすく、ドメインをランダムな順序で継続学習した方がLLMの性能・知識の蓄積が改善する。
-  Command R+はトークナイザーもすごかった
	- https://qiita.com/sergicalsix/items/5ceb9a3a0d11affb4b9a
	- 今回はCommand R+の日本語の応答速度が本当に速いのか、なぜ速いのかについてトークナイザー観点で述べたいと思います。
	- CohereのAyaとCommand R+のトークナイザーは他のトークナイザーと比べてトークン数が削減できていることがわかりました。
- Apple、iPhoneでも稼働するオープンな言語モデル「OpenELM」を公開
	- https://www.itmedia.co.jp/news/articles/2404/25/news103.html
	- パラメータ数の異なる4つのモデルがある。小さいものから、2億7000万、4億5000万、11億、30億
	- OpenELMは、レイヤーごとのスケーリング戦略を用いて、Transformerモデルの各レイヤー内でパラメータをefficient（効率的）に割り当てることで精度を向上させているという。
- Let's compare Llama-3 & Phi-3 using RAG:
	- https://lightning.ai/lightning-ai/進化的s/compare-llama-3-and-phi-3-using-rag?utm_source=akshay
	- https://x.com/akshay_pachaar/status/1783114329199718558
-  Cohere Toolkit
	- https://github.com/cohere-ai/cohere-toolkit
	- Yesterday, we open sourced the Cohere Toolkit. We think this will be a major accelerant for getting LLMs into production within enterprise.
-  LLMにとって「質の良い学習用データ」
	- https://x.com/imos/status/1783494307959513522
	- LLMにとって「質の良い学習用データ」は「正しい日本語に/倫理的に絞られたデータ」ではないと思うので整理して布教したい（FineWeb曰くアダルトサイトを抜くと性能劣化するらしい）。言語能力、知識、論理能力、応答形式など、用途を満たすのに必要な軸を欠かさず含むことが大事だと思われる。
- Llama 3 Establishes Meta as the Leader in “Open” AI  by IEEE Spectrum
	- https://spectrum.ieee.org/meta-llama-3?share_id=8224093&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- 『統計的テキストモデル』(岩波書店 確率と情報の科学)の執筆がついに最後まで到達しましたので、「文書の統計モデル」の章を公開しました
	- http://chasen.org/~daiti-m/textmodel/textmodel-chapter5.pdf
-  Graph Machine Learning in the Era of Large Language Models (LLMs)
	- https://arxiv.org/abs/2404.14928
	- グラフと言語モデルに関するレビュー論文
	- グラブ系機械学習モデルとLLMの組み合わせによる研究例や展望がまとまっています。MI分野だけでなく他分野の事例もあり参考になります。
- Two new AI releases by Apple today
	- https://x.com/pcuenq/status/1783032344104026372
	- OpenELM, a set of small (270M-3B) efficient language models. Weights on the Hub:
	- CoreNet, a training library used to train OpenELM:
-  [Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge](https://aclanthology.org/2024.eacl-long.127.pdf)
	- 多言語言語モデルが獲得している事実に関する知識を53言語で検証。どのような原因によって言語ごとに差が出るのか、データ量や地理的観点・活性化されたニューロンの類似性などから分析している。
-  LLMプロダクト開発者がMac 進化的を買ってローカルLLMを触るべき理由
	- https://note.com/erukiti/n/n58a8180ea9fb
- [torchtitan](https://github.com/pytorch/torchtitan)
	- a library for large model training called torchtitan
	- They have scripts to train Llama-3 from scratch
	- The library went public today on GitHub but it is still in pre-release state & active development
- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	-  **stuff chain**、 **map reduce chain**、**map rerank chain**、 **refine chain**
	-  **適している文書特徴**
		-  **stuff・map reduce**  : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- **map rerank**  : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- **refine**  : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- 「Japanese-Starling-ChatV-7B」
	- https://x.com/AIBizNavigator/status/1783667625802994164
	- 7Bクラスとは思えない超高性能なんだ
	- 英語の最強7BモデルStarling-LM-7B-betaから抽出したChat Vectorを、 日本語モデルのChatNTQ-JA-v1.0-7bに掛け合わせただけ。 追加の日本語学習は一切なし
	- https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7b
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- https://huggingface.co/umiyuki/Japanese-Chat-Umievo-itr001-7b
	- ElyzaTasks100で評価してみたら平均3.57点を叩き出した！7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！とりまHuggingFaceに上げました！
- Swallow instruction tuning models
	- https://huggingface.co/collections/tokyotech-llm/swallow-instruct-65e559f4d52e7c9d197697c2
	- wallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました。あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました。
- tokyotech-llm/Swallow-MS-7b-instruct-v0.1
	- https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1
	- swallow 7B, 13B, 70B、およびSwallow-MS 7Bのインストラクション・チューニングを改良し、指示追従性やマルチターン応答を向上させたモデルをHugging Face上で公開しました。以前に公開したモデルと比べて、MT-Benchのスコアで大幅に改善しています
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】
	- https://x.com/hokazuya/status/1783808939773304957
	- 512トークン、340Token/S
	- M3 Pro Mac (64GB)で16ビットの270Mモデルで超高速ローカルLLMが実現。
-  Weave と Elyza-tasks-100 で ローカルLLMを評価する by npakaさん	
	- https://note.com/npaka/n/nc0c8d5beacff?sub_rt=share_h
	- 「**Weave**」は、LLMアプリケーションの記録、実験、評価のためのツールです
	- 「**Elyza-tasks-100**」はElyzaが提供する指示チューニングモデル用の評価用データセットです。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘しているが、、
	- https://x.com/rmaruy/status/1784154638390104188
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
- ベイズ推論を使ってみよう
	- https://x.com/makaishi2/status/1784115819791913065
	- 『Pythonでスラスラわかるベイズ推論「超」入門』著者
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
	- 配信者の2人「ジェンスン？誰？？」
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
	- 高速AIチップで話題のGroqのAPIをStreamlitのコードの記事を書いてみました。OpenAIのAPIと表記が似ているので書きやすいですね。
- Swallow-MS-7BやRakutenAI-7Bはトークンの語彙が拡張されてる事に気付いたが、これって拡張されてない他のモデルとマージしたらアカンのだろうか
	- https://x.com/umiyuki_ai/status/1784274430816034898
- 【Whisper.cpp-CLI】
	- https://x.com/hokazuya/status/1784554378118246440
	- ローカルで高精度の音声文字起こしができるWhisper環境が、ものの200msで作れてしまうとのPyplパッケージがOSSで
- 


## 4/21

今週は、最大３倍高速という日本語GPT-4の開発の発表もあったけど、なんといってもメタからllama3の待望の公開。最初は8bと70bが公開され、さらなる大規模モデルも開発中とのこと。lllama3のファインチューニングに用いたPyTorchの新機能tochtuneも公開。早速、量子化、MoE化、ファイチューニングの実行例が公開され、MXで8GB M2 miniでの動作確認!、ollamaの対応、さらにはGroqに乗っかってデモサイトでLlama3-70Bが300t/sの超絶爆速推論を見せたなどの一通りが１週間で進む。RAGでのllama3の利用例もLangChainから紹介があったが、CommandR＋もllama3も、プロンプトに与えるテンプレートが独特なので、LLMをネイティブに使う人は要注意だ。1bitのLLMも、shi3zさんの自作評価や、椎橋さんによるGPUではないオーダーメイドによるAIソリューション「カスタムAI」の可能性など、いい記事がでてきた。ChatVectorによるLLM性能向上も、先週に引き続き、Bakuさんの、ChatNTQ 7B と LightChatAssistant 2x7B の日本語能力を試す記事が神記事として話題に。LightChatAssistantってのはそんなにすごいのか。作ってみたら性能が高かったというJapanese-Starling-ChatV-7B-GGUFなども出たり、ChatVector紹介の先駆者はちさんからSwallow-MS-7b-v0.1-ChatSkill-LABが出たり、能力加算の組み合わせの最適解をoptuneをつかって実行・評価とか、、LLMの能力の足し算引き算しつつ性能を評価するという一段メタな世界が開けた。PFNの丸山さんが紹介された、LLMをつかって言葉だけで、線形回帰をさせるという論文、どんなモデルを内部に持っているんだという意味で面白い。 Cambridge大学のU. Anwar, D. Krueger氏ら40名!による、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文はすごい、AIガバナンスのオックスフォードハンドブックもあり、UKではアライメントとガバナンスの大きな拠点になっているのか。マイクロソフトから、WizardLM-2 の7bと8x22bが発表、Evolve Instructという新しいファインチューニング手法の能力やいかに、エージェント機能も持っているとか、嵐の予感。Qwen1.5-7B-Chat-GGUFも出た、来週あたりQwen1.5ベースの日本語LLMが出てくるのでは。DeepMindの「Many-shot」多数例示学習の有効性や、RAGのMiniCheck、複数の知識を組み合わせるChain-of-Abstraction (CoA) ReasoningなどのLLM推論での進展もあった。丸山隆一さん、AI科学の何が“哲学”という問い（スライド）も良いし、「AI協働時代に研究者はどう生きるか」というイベントも面白い。AIが（従来の）研究ができるようになるならば、AI研究者はなにをするのかみたいな感じ。さきほどのUKと比べるとこのあたりの研究者層が薄いのかな。その他としては、Swallow-MXを使ったQ&AデータセットであるAutoWikiQAとか、MiniCPM-V-2のデモの公開、商用利用可能なマルチモーダルLLM、idefics-8bなども出てきた。

- openbmb/MiniCPM-V-2
	- MiniCPMのデモが公開
	- https://huggingface.co/spaces/openbmb/MiniCPM-V-2
- OpenAI Japanの発足とまさかの日本語GPT-4の発表。
	- https://openai.com/blog/introducing-openai-japan
	- 「日本語のテキストの翻訳と要約のパフォーマンス、およびコスト効率を向上させ、前モデルと比較して、最大3倍高速に動作します。」
- ChatNTQ 7B と LightChatAssistant 2x7B の日本語性能を測定する
	- https://sc-bakushu.hatenablog.com/entry/2024/04/10/191420
	- 「[ChatNTQ-JA-7B-v0.1](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)」と、そのMoEモデル「[LightChatAssistant 2x7B](https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B)（改称あり）」について、かなり性能が良さそうな感触が得られたので、追加でテストしてみました。
	- LightChatAssistantはChatNTQとAntlerがジョグレス進化して奇跡のシナジーを起こして、ELYZATasks100ベンチで35BのCommand Rに匹敵する性能を出してしまう
	- LightChatAssistantではMistral 7B v0.2 InstructからChatVectorを抽出してたけど、もっと性能高そうなStarling-LM-7B-betaから抽出した方がいんじゃね？という事で抽出してChatNTQに足してみたら、MoEにもしてない単なる7Bモデルの時点でElyzaTasks100ベンチでLightChatAssistant超えの性能が出てしまった！Command R-35Bと同点のスコア！
- Heron-Bench: 日本語Vision＆Languageモデルの性能評価ベンチマークの公開
	- https://arxiv.org/abs/2404.07824
	- https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench
	- 日本語のVision-Langugeモデルのベンチマークがなかったので作成し、Turingで開発したheronを含めてモデルの比較を行いました~!!
- CS159: LLMs for reasoning lecture slides from Caltech
	- https://sites.google.com/view/cs-159-2024/lectures
- RTX4090+A6000(24+48GB VRAM)でcommand-r-plus-Q4_K_Mを65/65 layer GPUに載せても6.5t/sくらいが限度だった。 おそらく、96GBではメインメモリが足りないから遅い。
	- https://x.com/Meteor_Eternal/status/1779807643668013534
- an introduction to agents and tools
	- https://x.com/llama_index/status/1779898403239125198
	- This short course is the perfect beginner sequence for anyone looking to get an overview of agent implementations, how to equip them with tools to perform tasks like advanced QA/RAG or anything else, and also some neat extensions (tool retrieval, step-wise execution).
- From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples
	- https://arxiv.org/pdf/2404.07544.pdf
	- LLMに、「この入力の場合出力はこれ」という例示を入れて「ではこの入力の場合の出力は？」と推論させると線形回帰・非線形回帰ができてしまう、という論文。
- TFMC/Japanese-Starling-ChatV-7B-GGUF
	- https://note.com/bakushu/n/ne95340f04b41
	- LightChatAssistant-2x7Bの日本語チャット性能がとても良いため、モデル作者さんが用いた手法（Chat Vector+MoEマージ）を後追いで検証しているなかで、発見。
	- 7Bクラスとしてはベンチマークスコアがやたら高いモデルが出てきたので「Japanese-Starling-ChatV-7B」として公開してみました。
- HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- ChatVectorを使って新しいApache2.0のChatモデルを作りました。 ChatVector抽出元のモデルもMixtral-8x7B-Instructによる人工データ(Synthetic Data)で学習されたものなので、隠れたライセンス汚染の心配はありません
-  進化的アルゴリズムをもちいたChatVector加算の最適化 by　はちさん
	- https://note.com/hatti8/n/na593650d688b
	- 進化的アルゴリズムを使用するために、optunaとcmaes
	- 進化的アルゴリズムを使って、この関数のoutputであるscoreを最適化（最小化）します
		1. merging_ratio（ChatVectorの加算比率を各layer毎に持つ辞書）の定義
		2. merging_ratioにしたがって、ChatVectorのマージ
		3. ELYZA tasks 10の実施とGPT4による評価
- Foundational Challenges in Assuring Alignment and Safety of Large Language Models
	- https://llm-safety-challenges.github.io/
	- 2024.4.15 Cambridge大学のU. Anwar, D. Krueger氏ら40名弱の国際チームによる、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文。
	- 1）LLMの科学的理解、
	- 2）訓練手法や実装場面の課題、
	- 3）社会における課題に分け、
	- 広範な文献調査に基づき200超のリサーチクエスチョンを同定。
	- このAnwar+2024論文はすごい。「LLMの何が技術的・社会的な問題になるのか？」を包括的に洗い出し、かつリサーチクエンションのリストに落とし込んでいる。by maruyamaｓあｎ
- Running WizardLM-2 8x22B Q4_0 locally via ollama
	- https://x.com/ivanfioravanti/status/1780133719707197643
	- On an M2 Ultra I get: ~19.5 tokens/s
	- 80Gb??
- MaziyarPanahi/WizardLM-2-8x22B-GGUF(Q4_K_M)
	- https://x.com/alfredplpl/status/1780110628864274576
	- うーん日本語がやはりイマイチだな
- WizardLMの作り方
	- https://x.com/WizardLM_AI/status/1779937307690471834
	- 新しいWizardLM-2 7BのサイズでMT-BenchがClaude-2より高いってすごい by はち
- WizardLM: Empowering Large Language Models to Follow Complex Instructions
	- https://arxiv.org/pdf/2304.12244.pdf
	- 課題：様々なレベルの複雑さを持つ大量の指示データを作成することは、時間と労力がかかる。
	- 解決：Evolve Instruct方法を使用して、LLM自体が指示データを生成する新しいファインチューニング
- Introducing the Batch API: save costs and get higher rate limits on async tasks
	- https://platform.openai.com/docs/api-reference/batch
- Introducing Idefics 2
	- https://huggingface.co/collections/HuggingFaceM4/idefics2-661d1971b7c50831dd3ce0fe
	- An 8B Vision-Language Model - literally punching above its weight.
- Pytorchからファインチューニング用の機能torchtuneが公開
	- https://pytorch.org/blog/torchtune-fine-tune-llms/?utm_content=289842551&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024
	- llama3のファインチューニングをこれでやったんだと
-  AI科学の何が“哲学”の問題になるのか　～問いマッピングの試み～
	- https://speakerdeck.com/rmaruy/aike-xue-nohe-ga-zhe-xue-nowen-ti-ninarunoka-wen-imatupingunoshi-mi
	- まるやまさん
-  「AI協働時代に研究者はどう生きるか」(4/26)
	- https://share.hsforms.com/1NFOzzuNBSZq3K20gtPZ30wdxf90
	- 本イベントでは、研究の自動化・自律化が益々加速していく未来において、研究という営みがどのように変化していくのか、その中で研究者はどう生きるべきか、ということについて議論します。  
	- AIロボット駆動科学を牽引する一杉太郎さんと、AI科学を俯瞰的に考える丸山隆一さんによる特別パネルディスカッションや、「AI × ◯◯学」をテーマに月額支援型クラウドファンディングに挑戦中の若手研究者8名のプレゼンを通して、「AI協働時代に研究者はどう生きるか」、皆さんも一緒に考えてみませんか？
- 生成AIでGPUがいらなくなる？　業界を揺るがす「1ビットLLM」とは何か、識者に聞いた
	- https://www.itmedia.co.jp/aiplus/articles/2404/16/news064.html
	- ではそもそも“1bit”とは何が1bitなのか、どうして1bitになるとGPUが不要になるのか。LLMでGPUが不要になるとどんな世界が訪れるのか。オーダーメイドによるAIソリューション「カスタムAI」の開発・提供を行うLaboro.AIの椎橋徹夫CEOに聞いた。
	- **椎橋：**今回の結果から、LLMの推論において、GPUではなく別の半導体の機構が最適になって、劇的に計算が軽く早くなる可能性が開けてくるんです。
	- 論文中でも、GroqというLLMの推論に特化したLPU（Language Processing Unit）の登場に触れられています。次世代半導体での復活を狙う日本の産業にとっても、注視していくべきトピックではないかと思います
- この前調合した改造Swallow-MX（継続日本語学習+instructionベルトル強化）とMixtral 8x22Bを比較すると短時間使用では差異捉えにくいな それだけ8x22Bの日本語能力アップしてるのは間違いない
	- https://x.com/AiXsatoshi/status/1778630270486552619
- Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行
	- https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf
	- 2024.4.16 Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行。昨年から大幅に増量した500ページ超の紙幅にて、AI研究の論文数・特許・先端モデルの開発動向・投資額・経済的インパクト・科学や教育への影響・ガバナンス・社会受容など包括的に報告。
	- 「AIは人間より高性能だが一部のテストでは人間の方が優秀」「高性能AIの学習コストは数百億円」など
- HuggingFaceM4/idefics-8b
	- https://huggingface.co/spaces/HuggingFaceM4/idefics-8b
	- 明確に商用利用可能なマルチモーダルモデルのデモ
-  Google Colab で idefics2 を試す by npakaさん
	- https://note.com/npaka/n/n032c2bbaadb4?sub_rt=share_h
	- 「Idefics2」は、テキストと画像を入力し、テキストを出力するマルチモーダルモデルです。画像の質問応答、視覚的コンテンツの説明、複数画像をもとに物語作成、文書からの情報抽出などを実行できます
- AIの処理能力､1年で25倍　死蔵の｢知能資本｣が競争力に by shi3zさん
	- https://www.nikkei.com/prime/digital-governance/article/DGXZQOUC092UR0Z00C24A4000000
	- そのような世界で価値を高めるのは、死蔵された書籍や動画などの「知能資本」という。「AI資本主義」という新たな経済の姿を提唱する、
-  MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents
	- https://arxiv.org/abs/2404.10774
	- RAGなどエビデンスに基づいて LLM に生成させる場合にそもそも生成したものがエビデンスに基づいて生成できているのか（ファクトチェック）が課題になりますが、それを効率的に行うモデルを学習するシステム MiniCheck の提案。
	- GPT-3.5/4を用いて、人が書いた文章をもとにFACTを抽出したり要約生成をしたりしながらファクトチェックタスクに特化した高品質な合成データを生成し、それを用いて小さなモデルを学習することで、GPT-4と同等の性能で400分の1以下のコストでファクトチェックができるようになったそうです。
- RAGを複雑な質問に強くする手法「CoA」について
	- https://zenn.dev/knowledgesense/articles/508187f1c616e3
	- 「Chain-of-Abstraction (CoA) Reasoning」
	- CoAが従来のRAGよりも力を発揮できるシーンは、ユーザーの質問が「複数の知識を組み合わせなければ正答できない」ような質問だった場合です。通常のRAGでは1回のドキュメント検索で回答に使えるドキュメントを見つけようとしますが、CoAでは、問題（ユーザーからの質問）を複数の問題に分解し、複数回のドキュメント検索を行った上で総合的な回答を生成できます
- Qwen/Qwen1.5-7B-Chat-GGUF
	- https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF
	- 7 billion parameters coding chat model (~5GB RAM needed)
-  1BitLLMの実力を見る by shi3zさん
	- https://note.com/shi3zblog/n/ndd1f27fff31c?sub_rt=share_pb
	- 普通のHuggingFaceのお作法とはかなり違うので注意が必要。  まず、このHuggingFaceリポジトリを丸ごとgit cloneする
	- これをやらずにいつもの凡例みたいにいきなりpipelineに読み込もうとすると謎のエラーが出て悩まされることになる。海外でも悩んでる人が何人もいるみたいだ。まあ個人的には「こんな説明で誰がわかる?」と思うが。
- mistralai/Mixtral-8x22B-Instruct-v0.1
	- https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1
	- Mixtral-8x22B Instract きたわ〜
- Build RAG, Function Calling, and Agents with llama_index and  MistralAI8x22b 
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/mistralai/
- 24/04/18 ローカルでCommand RやCommand R+を動かす時の作法
	- https://six-loganberry-ba7.notion.site/24-04-18-Command-R-Command-R-ff8455f1dba543168d5a7768705e0043
	- 実はCommand Rはプロンプトにチャットテンプレートを使用しないと正しく回答が返ってこないらしい
	- <|START_OF_TURN_TOKEN|><|USER_TOKEN|>Who are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
	- チャットテンプレートのあるなしで回答のクオリティは天と地ほど違ってくるから注意しよう。
- Introducing Meta Llama 3:
	- https://ai.meta.com/blog/meta-llama-3/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama3
	- the most capable openly available LLM to date.
	- Llama3のリリース第一弾は8Bモデルと70Bモデル！それぞれベースモデルと指示チューニング版があり！HuggingFaceからＤＬできる！8BモデルはベンチでMistral-7BやGemma-7Bを撃墜！70BモデルはGeminiPro1.5やClaude3Sonnetを撃墜！人間による評価でもSonnet、MistralMedium、GPT-3.5に勝利！
	- Context長は8kTokenでパラメータ数は80億と700億パラメータ。なんと4000億パラメータを超えるモデルも学習中！700億のほうは現在のフロンティアModelに性能的に肉薄しつつある状態。
- LangChain x Mistral RAG Agent Cookbooks + Video
	- https://x.com/LangChainAI/status/1780994907903263159
	- With the release of new Mixtral 8x22B, there's high interest in building agents with open source LLMs.
- VARIATIONAL BAYESIAN LAST LAYERS
	- https://arxiv.org/pdf/2404.11599.pdf
	- Neural Networksの最終層以外は固定されていると思って、最終層のみの 1-layer な Bayesian Neural Network としてモデル化し最終層の最適化をしつつ変分ベイズ推定する枠組み Variational Bayesian Last Layers （VBLL）の提案。
- Reliable, fully local RAG agents with Llama3
	- Here, we show to how build reliable local agents using LangGraph and Llama3-8b from scratch.
	- https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb
- 例のSRAMメモリのAIチップを山盛りに積みまくった構成のGroqのサイトでLlama3-70Bが300t/sの超絶爆速推論
	- https://x.com/umiyuki_ai/status/1781529537102352827
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- プロンプトに数百〜数千の例を含めてLLMにタスクを行わせる『Many-shot（多ショット）』がDeepMindにより検証されています
	- 結果、基本的に例が多くなるほど性能が上がるとのこと。事前学習による思い込みを覆すことも。人間製の例がなければモデル生成の例でも効果あり
-  [llama.cpp：iMatrix量子化は日本語性能にどう影響するか？](https://sc-bakushu.hatenablog.com/entry/2024/04/20/050213)
	- 量子化時のモデル劣化を抑制する重要度行列（iMatrix; Importance Matrix）計算の話題です。
	- 最近はHuggingFaceにアップされるGGUFも多くがiMatrix版となっていますがこれらの量子化でよく使われているiMatrix計算用データセットは以下の2種類のようです。
- MLX で Llama 3 を試す
	- https://note.com/npaka/n/n21fa74396545?sub_rt=share_h
- Llama 3がGroqに登場
	- https://x.com/kyo_takano/status/1781595042840559908
	- Groqがなぜこんなに速いのか？それはGPUではなくLLMに最適化されたASICを使っているからです。Groqは最近新しいデータセンターを作ったばかりで、そこで何個ASICを使っているのか直接聞いたら700個以上と答えてくれました、今後リアルタイム性需要が高まるとGroqはさらに急成長してくると思います。
- 小さい計算コストでスマートにLLMをチューニング!-Hugging Face PEFT入門(前編)
	- https://zenn.dev/elith/articles/3ec1d319c8a40f
	- パラメータ効率の良いFine Tuning手法(Parameter-Efficient Fine Tuning、 PEFT)について、サーベイを行いました。
- With the latest MLX, 4-bit Llama 3 8B runs nicely on an 8GB M2 mini.
	- https://x.com/awnihannun/status/1781345824611680596
	- 512 tokens at 18.8 toks-per-sec
- cl-nagoya/auto-wiki-qa
	- https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa
	- 東工大のSwallow-MXを用いてWikipediaのテキストに基づく質問と回答を生成させたデータセット AutoWikiQA をHuggingFace上に公開しました！
	- 約240万事例と日本語QAデータセットの中でも最大規模かつ高多様性なデータセットです
- The Oxford Handbook of AI Governance
	- https://global.oup.com/academic/product/the-oxford-handbook-of-ai-governance-9780197579329?cc=jp&lang=en&
	- AIガバナンスのオックスフォードハンドブック。49本通読する人出る　by 生貝先生
- lama-3-8b's in-context learning is unbelievable.
	- https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/
- いちばんやさしいローカル LLM
	- https://note.com/schroneko/n/n8b1a5bbc740b#57403f33-7b40-444e-9342-c8bf11458d18
	- ローカル LLM 初めましての方でも動かせるチュートリアル
	- Ollama を使えば簡単に LLM をローカル環境で動かせる
- Crystalcareai/llama-3-4x8b
	- https://huggingface.co/Crystalcareai/llama-3-4x8b
	- This is an MOE of Llama-3-8b with 4 experts. This does not use semantic routing, as this utilizes the deepseek-moe architecture. There is no routing, and there is no gate - all experts are active on every token.
	- 予想はしてたけど、もうLlama3のMoEができてる　by はち さん
-  Google Colab で Llama 3 のファインチューニングを試す
	- https://note.com/npaka/n/n315c0bdbbf00?sub_rt=share_h
	- 今回は、ござるデータセットで学習します。AIが「我、りんえもんは思う。◯◯でござる。知らんけど。」的な口調になります。
	- 練習として500ステップだけ学習します。指示に応じて、wandbのAPIを入力してください。8分ほどで学習完了します。
	- 我、りんえもんは思う。 マミは一番かわいい。知らんけど。
	-  HuggingFace Hubへのアップロード
		- (1) LoRAアダプタをベースモデルにマージ
		- (2) 「HuggingFace Hub」のメニュー「New Model」を選択。
		- (3) HuggingFace Hubのリポジトリの作成。
		- (4) HuggingFace Hubへのアップロード
-  統計学を哲学する
	- https://www.unp.or.jp/ISBN/ISBN978-4-8158-1003-0.html
	- 書評（丸山隆一）
		- “…… 科学の最も基本的なツールである統計学を哲学的に分析する。ベイズ統計、仮説検定、機械学習、因果推論などの統計学的手法を科学者が使うとき、何が暗黙の前提となり、何が正当化の根拠になっているのか。哲学的認識論の道具立てによる本書の整理は鮮やかだ。深層学習に関する議論は、どのような意味で AI に科学ができるのかという大問題にもつながる。「AI 科学の哲学」の始動を感じる。……”


## 4/15

今週も強烈だった。頭がくらくらするが、気のせいか重み転移系が多い気がする。MiniCPM-2B、「μトランスファー」という手法で小規模LLMで最適化されたパラメータを大規模LLMに転移する技術で（２段階トレーニングと呼ばれてる？）、2.4Bパラメータという小さなサイズでMistral-7Bと肩を並べるとか。Command R+も量子化されたものが評価されて、Mac(M3、128G)や、A100(80G)で結構サクサクうごくらしい。特に、 「Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作」ってのは、A100持っている人はぜひ試してみるべき。 Command R+に影響されたのか、MistralもMixtral-8x22Bをオープンソースとして発表、さっそくこれをベースにexpertsをマージしてmistralにした勝手版Mistral-22Bが出て、双方量子化版が出て、、、とあっという間に広まって何が何だか。LLM同士の機能のベクトル演算であるChat Vector、まねしてMath強化版をつくって、これらを融合した結果、数学能力をある程度維持しつつ、Chat能力も強化することができるという話もあった。LightChatAssistant 2x7BてのもMistral7Bモデルをベースとした日本語対応モデル 2をChatVector手法で対話能力強化してmergekitでMoE化したもの。32kのContextSize対応、iQ3_XXS量子化でVRAM12GBでフルロード可能、RTX3060でも動くとか。JetMoEという新しいアーキテクチャ、MoEであることに加え、MiniCPMに倣った2段階トレーニングの効率が極めて高くそれでいて性能はLlama-7B並みとか。Googleの新しいリカレントアーキテクチャRecurrentGemma、リカレントニューラルネットワークとローカルアテンションを活用してメモリ効率を向上さているらしい、今後もGemmaとパラレルにリリースするのか。GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」てのもあった、Gemma-2Bに追加学習して「Function Calling」を強化したとのこと。それから、今週はGoogle Cloud Next24があったので、最大100万トークンのGemini 1.5 Proのリリースや、DeepMindのImagen 2、TPU v5pの発表、GoogleDocにGeminiの統合とか、geminiでRCカーを制御とか面白い出し物があった。日本語LLM 9種を量子化して回答内容を比較ってのも面白かった、ELYZAは偉いぞ。LangChain の Tool Calling 標準インタフェース ってLLMに依存しないということなので、エージェントとかの活用が加速しそう。QR分解でカルマンフィルターってのは目からうろこだ、一見異なる枝がエレガントにつながる、これぞサイエンスの醍醐味だ。

- MiniCPM: Unveiling the Potential of End-side Large Language Models
	- https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20
	- 既存7B LLMより強いと話題の2B LMMのMiniCPM
	- μP使って小さいモデルで効率的にハイパーパラメータ探索
	- MiniCPM is a series of edge-side large language models, with the base model, MiniCPM-2B, having 2.4B non-embedding parameters. 
	- It ranks closely with Mistral-7B on comprehensive benchmarks
- 現状のLLM選択肢 by urawazakun
	- https://x.com/urawazakun/status/1777130873844040046
	- commandRplus　108B →Mac 進化的（988000円）
	- commandR　35B →RTX4090（PC + 40万円～）
	- LightChatAssistant2x7B →RTX3060（PC + 3万円～）
-  EasyLightChatAssistant
	- https://github.com/Zuntan03/EasyLightChatAssistant?tab=readme-ov-file
	- EasyLightChatAssistant は軽量で検閲や規制のないローカル日本語モデルの LightChatAssistant を、KoboldCpp で簡単にお試しする環境です。
- ｢LLMはコモディティー｣　米データブリックスCEOが語る
	- https://www.nikkei.com/article/DGXZQOGN252JK0V20C24A3000000/
	- LLM単体ではなくLLMやその他のモジュールを組み合わせて問題を解く「複合AI」の考え方がとても大事
-  Octopus v2: On-device language model for super agent
	- https://arxiv.org/abs/2404.01744
	- https://huggingface.co/NexaAIDev/Octopus-v2
	- GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」
	- 20億パラメータを持つエッジデバイス上で機能するオンデバイスAIモデル「Octopus v2」
- Google Colab で Octopus V2 を試す by npakaさん、
	- https://note.com/npaka/n/n706bde979ed8
	- Gemma-2Bを追加学習したモデルで、学習ステージと推論ステージの両方に独自のFunctionトークン戦略を導入することで、「Function Calling」において「GPT-4」に匹敵する性能を達成したとのことです。
	- ユースケースとしては、「カレンダーにリマインダー追加」「メッセージ送信」「Youtube検索」の指示などが挙げられています
- Chat VectorとMath Vectorは併用できるのか by はちさｎ
	- https://note.com/hatti8/n/n2d6d86d6f05a?sub_rt=share_h
	- Chat+Math能力の両方を日本語ベースモデルに付与したら、どちらの効果も得られるのか
	- Math強化モデルに先ほど作ったChat Vectorを重ねがけしていきます
	- Math強化モデル：Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vector：SkillTree-Chat-Mistral-7B-v0.1
	- Math+Chat強化モデル
		- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatMathSkill
	- 結論
		-  **モデルが壊れることはない**
		- **数学能力をある程度維持しつつ、Chat能力も強化することができる**
		-  **一方、英語で回答しやすくなる傾向が出てくる**
- Chat VectorならぬMath Vectorは作れるのか
	- https://note.com/hatti8/n/n0000353355cb
- LangChain x DSPy
	- https://www.youtube.com/watch?v=4EXOmWeqXRc
- JetMoEってなんじゃ？ by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777014403197788280
	- Mixture of Attention heads（MoA）とMixture of MLP Experts（MoE）の二つのレイヤーに、それぞれ４人ずつエキスパートがいて、推論時は各レイヤー２人ずつが活性化する。
	- 活性化パラ数は2.2Bで、合計パラ数は8Bだって。何だか知らんけどこのアーキテクチャによってトレーニング効率が爆上がって、H100が96台で２週間、1200万円しかトレーニング費用かけてないのに、数千億かけたはずのLlama-7BやLlama-13にベンチで勝利した
- μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_b&d=s4cpuSjMMAw
	- μP（Maximal Update Parametrization）というのは、 Tensor Programs (TP)というフレームワークにおいて理論的に導出されたパラメータ付け（パラメータのスケーリングなど）の方法です
	- TP は、 Neural Networks （NN）の解析をするために、線形変換や非線形活性化関数などの NN の構築で頻出する操作をリストアップし、その枠組みで成立する事象や性質を追求するフレームワークです。
	- https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/
- Leveraging language representation for materials exploration and discovery
	- https://www.nature.com/articles/s41524-024-01231-8
	- 言語モデルによる材料探索の論文。
	- 結晶材料をテキスト表現にし言語モデルにより既存材料に似た新熱電材料を探索
	- 特に、GPTのようなデコーダ専用モデルより、BERTのようなエンコーダ専用モデルのほうが汎用性が高くMIタスクに向いている、という点が興味深かったで
- μトランスファーとは by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777204816059711692
	- MiniCPMはミュートランスファーというテクニックが使われてるらしい。これが何か？というと、でかいLLMをトレーニングする時の最適パラメータを探るテクらしい。
	- でかいLLMを学習する時に、ハイパーパラメータをどう弄れば最強になるのか、イチイチ色々試して最適解を試行錯誤するのはメチャクチャ大変だ。そこで、同じアーキテクチャのちっちゃい版で実験すればサクサクと最適なパラメータを試行錯誤できる。で、ちっちゃいモデルで見つけた最強パラメータが、でかいLLMにそんままコピペしてもちゃんと最強になる事が判明したらしい！
- JetMoEのトレーニング効率上がったのは　 by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777023943121256637
	- Komatsuzaki氏の見解によれば、JetMoEのトレーニング効率上がったのは、たしかにMoEアーキテクチャによって２～３倍に効率化したけど、それより何よりMiniCPMに倣った2段階トレーニングの手法のおかげでバキバキに効率化したとの事。
	- 1万倍の内、MoEの貢献が３倍なら残りの3333倍はMiniCPMトレーニングのおかげなのか
- The Physics of Language Models
	- https://arxiv.org/abs/2404.05405
	- 「言語モデルは、int8 に量子化された場合でも、パラメータごとに 2 ビットの知識しか保存できません。また、そのような知識は、下流のアプリケーション用に柔軟に抽出できます。その結果、7B モデルは 14B ビットの知識を保存でき、これは私たちの推定に基づくと、英語版 Wikipedia と教科書を合わせた量を超えます。」
	- 回転埋め込みを備えた GPT-2 アーキテクチャは、知識の保存において LLaMA/Mistral アーキテクチャに匹敵するか、それを上回ります。
- Gemini 1.5 Pro
	- https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html
	- 180カ国サポート、「統一モデル」音声・動画認識、ファイルAPI、System Instructionカスタマイズ機能、 JSONモードなどが加わりました、以下で試せる
	- https://ai進化的.google.com/app/prompts/new_chat
- Imagen 2 by DeepMind
	- https://x.com/GoogleDeepMind/status/1777747320945234422
	- Imagen 2 can now create short, 4-second live images from a single prompt.
- GPT-4 Turbo launch
	- https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4
	- previewが取れた
- UNESCOがAI Ethicで人集めしている by　神嶌さん
	- https://careers.unesco.org/job/Other-cities-Consultant/791818302/d
- Llama.cpp で Command R+ をお試し中 by npakaさん
	- https://x.com/npaka123/status/1777802956571889969
	- Q4_K_M・M3 Max (128GB) 5.22 tokens per second
- mmnga/codegemma-7b-it-gguf
	- https://huggingface.co/mmnga/codegemma-7b-it-gguf
	- gemma-1.1-7bとcodegemma-7b-itのgguf
- 【LangChainゆる勉強会#3】LangChainのAgentはどれを使う？
	- https://www.youtube.com/watch?v=07TuBmm67sU
	- LangChainを使ったAgent実装を概説してくださってる勉強会のアーカイブ動画。
	- 最近はLCELで組んでAgent Excutorに投げる以外の実装しないので、なんか色々あるんだなと勉強になりました
	- XML Agentとか誰が使うん？って思ってたけど、Claudeと相性良いらしい。へぇ〜！
- rinna/youri-7b-chat-gptqとintfloat/multilingual-e5-largeでRAGするだけでもcolabよりrtx3060の方がかなり速い
	- https://x.com/rsimd_/status/1747614320878555175
	- vramが足りればって話だけど，一応faiss-cpuを使えばメモリ足りてる．
- Command R+の量子化PPLを計測してくれてる
	- https://github.com/ggerganov/llama.cpp/pull/6491#issuecomment-2043633791
	- Q3_XXSは38GBだけど、ここまでなら精度的にも全然大丈夫ちゃうか？って予感はする。IQ2_XXSなら26.6GBで、ちょっとアホになってそう。IQ1_Sなら21.6GBだけど、さすがに実用性ヤバそう。
- Perplexity Proに課金してGoogleのGemini UltraやGenerative Experienceと比較してみると、何かとんでもないことが起こっている気がする by 楠さん
	- https://x.com/masanork/status/1777478951465779344
- 完全ローカルでRAGも使えるAIチャットアプリOpenWebUIを日本語LLMでセットアップする
	- https://zenn.dev/firstautomation/articles/0b7a4b1bb2daf0
- Command R+はちゃんと強かった訳だが、Command RもこれまでのOpen-source最強のQwen1.5-72bに匹敵する訳なのですごい
	- https://x.com/Meteor_Eternal/status/1777635899204874704
- Gemini 1.5 Proの新機能 - Native Audio Understanding、System Instructions、JSON Mode、新Embeddingモデル　 by npakaさん
	- https://note.com/npaka/n/n0254081ebc23?sub_rt=share_h
- Stable LM 2 12B
	- https://stability.ai/news/introducing-stable-lm-2-12b
	- Stable LM 2 12B は、英語、スペイン語、ドイツ語、イタリア語、フランス語、ポルトガル語、オランダ語の多言語データでトレーニングされされた、120億パラメータを持つ強力な言語モデルです。 ベースモデルと指示学習済みモデルを備えています。
- GoogleDocにgeminiが統合される？
	- https://x.com/GoogleWorkspace/status/1777807449652662508
- TPU v5p, our most powerful and scalable TPU, is now generally available
	- https://x.com/GoogleCloudTech/status/1777732890471625162
- Gemma-1.1 also shows great improvement in terms of reduced hallucinations in the updated HHEM leaderbod
	- https://x.com/ofermend/status/1777695633455108478
- LLaMA 3's will start to drop next week.
	- https://x.com/mattshumer_/status/1777465835834970189
- Ride with GeminiというLLM＋RCカーのデモ
	- https://x.com/kazunori_279/status/1777846216950456658
-  Gemini 1.5 Proで文字起こしを試してみた
	- https://note.com/nyosubro/n/n07afba435ef6
	- 個人的な感想としては、Whisperレベル（あるいはそれ以上？）の文字起こし品質と論文ではありましたが、確かにそうかも！と言う感じでした。
	- またWhisperとは異なり、プロンプトレベルで様々な文字起こしタスクに柔軟に対応できる点で、結構面白さを感じてます。
- Llama.cpp で Command R+ を試す by npakaさん
	- https://note.com/npaka/n/n9136a2ebc7f9?sub_rt=share_h
	- M3 Max (128GB)
	- 「Command R+」は、「RAG」や「Tool」などの長いコンテキストタスク向けに最適化された104BのLLMです。CohereのEmbeddingおよびRerankと連携して動作するように設計されており、RAGアプリケーションに最高クラスの統合を提供し、エンタープライズユースケースで優れています。
- Wikipediaの日本語記事を元に、ユーザの質問に回答するGradioベースのRAGのサンプル。
	- https://github.com/lawofcycles/wikipedia-japanese-open-rag/tree/master
	- 使ったもの
		-   [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)
		-   [elyza/ELYZA-japanese-Llama-2-13b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-instruct)
- Command R plus推論速度、知見まとめ by AIXさとし
	- https://x.com/AiXsatoshi/status/1777867323552190876
- Amazon、「Claude 3」のAnthropicに27億5000万ドルの追加投資
	- https://www.itmedia.co.jp/news/articles/2403/28/news105.html#utm_term=share_sp
- A Generative Symbolic Music Pretrained Transformer
	- https://huggingface.co/papers/2404.06393
	- In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are
- We just released Mixtral 8x22B. Super excited for this release
	- https://x.com/sophiamyang/status/1777945947764297845
- 日本語LLM 9種を量子化して回答内容を比較調査してみた
	- https://qiita.com/wayama_ryousuke/items/50e36d0dcb37f8fb7dd8
	- 量子化しても成績が下がりにくいモデルと、大きく下がるモデルがある
	- 一部のモデルは量子化すると回答が極端に短くなる
	- 量子化によって回答が短くなる度合いは、量子化前モデルの回答の長さと相関がある可能性がある
	- 個別：
		- **ELYZA-japanese-Llama-2-7B**は、量子化後もほぼ同等の性能を維持し、0.10点のスコア低下に留まりました。
		-  **Swallow-7B**では、量子化前後で成績に変化はなかった一方、**Swallow-13B**では平均スコアが 0.28 点低下しました。
		- **CALM2**  や  **StableLM-Beta**  は、量子化後のスコアが高い結果（それぞれ 0.28 点/ 0.21 点向上）となりました。
		-   **Xwin**  モデル同士を比較すると、**Xwin 7B**は0.36点の低下を示している一方、**Xwin 13B**では0.11点の向上が見られ、同じモデルファミリー内でも異なる振る舞いが確認されました。
-  Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作させてみた話
	- https://note.com/junzokamahara/n/n9235af7a6dc1?sub_rt=share_h
	- vllmもCommand Rに対応しているとのことで、vllmで動かしてみることにしました。なお、動かすのはGPUメモリの関係でGPTQで量子化されたモデル。
	- 使用するモデルのはHugging FaceにあるGPTQに変換したCommand R+
		- client = OpenAI(base_url="http://<仮想マシンのIP>:8888/v1")
		- response = client.chat.completions.create(model='alpindale/c4ai-command-r-plus-GPTQ',
	- Command R plus GPTQのA100 80GBでの実行例
		- 18.3 tokens/sと出ている
- Geminiの新機能「System Instructions」を使ってみる。 
	- https://x.com/npaka123/status/1777969149651906927
	- ChatGPTではおなじみな機能だけど、今までGeminiにはシステムメッセージもなかったのでうれしい。
- 『すずめの戸締まり』に登場する3本脚の椅子を再現したロボット設計
	- https://x.com/shin0805__/status/1777992583396131246
	- 強化学習による歩容生成の論文を公開しました！ 来週アメリカで開催されるRoboSoft2024にて発表します！
	- https://shin0805.github.io/chair-type-tripedal-robot/
- mistral-community/Mixtral-8x22B-v0.1
	- The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.
	- おい、これApache-2.0だぞ！GPT-4クラスが商用利用可能らしい
- MLX with LangChain
	- https://python.langchain.com/docs/integrations/chat/mlx/
	- This notebook shows how to get started using MLX LLM’s as chat models.
- Google Colab で RecurrentGemma を試す
	- https://note.com/npaka/n/n0018d60fb8b7?sub_rt=share_h
	- 「RecurrentGemma」は、Google で開発された新しいリカレントアーキテクチャに基づいて構築されたオープンモデルです。 事前学習済みモデルと指示チューニングモデルの両方が英語で利用可能です
	- 新しいアーキテクチャにより、「Gemma」よりも必要なメモリが少なく、長いシーケンスを生成する際に高速な推論を実現します。
	- 今回は、「**google/recurrentgemma-2b-it**」を使います
- LightChatAssistant-2x7Bで行われている最適化をOptuneで
	- https://github.com/Aratako/Task-Vector-Merge-Optimzier
	- Sdff-Ltba/LightChatAssistant-2x7Bで行われているようなLLMにおけるTask Vectorの加算によるマージにおいて、その加算割合の最適化をOptunaを用いて行うスクリプトです
- Infini-attention
	https://x.com/umiyuki_ai/status/1778459568424784194
	- Googleが出した論文なんだね。で、「この技術のおかげでGemini1.5では100万コンテキストウインドウが可能になったのか！」
- Safeguarded AI: 
	- https://www.aria.org.uk/wp-content/uploads/2024/04/ARIA-Safeguarded-AI-TA1.1-Theory-Call-for-proposals.pdf
	- ARIAのDavidad氏の安全保証付きAIの研究プログラムの全貌が見えてきた。彼が何をしようとしているのか、それにどれほどのfeasiblityがあるのか、誰かに解説してほしい。形式証明とか、ソフトウェア工学、計算機理論のバックグランドが必要そう。
	- 今回の公募では土台となるセマンティクス、「言語」づくりを目指すとのことで、その方法論として圏論が名指しされています
- Mixtral8x22チューニング版
	- HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1
	- ORPOという新しいアライメントアルゴリズムを使用
	- ORPOは、SFTステップを必要としないため、DPOやPPOのような方法よりも計算効率が良い 
	- オープン、合成、マルチターン、LLMを介して採点さたDPOデータセット使用
- LLMによる視覚読解技術を確立～グラフィカルな文書を理解する「tsuzumi」実現に向けて～
	- https://group.ntt/jp/newsrelease/2024/04/12/240412b.html
- Embeddingsを使ってローカルでテキストをクラスタリングする（Multilingual-E5）
	- https://zenn.dev/libratech/articles/afe9c5b30668bb
- Mixtral-8x22B、LightblueさんのkarasuチューニングモデルとAWQ
	- https://huggingface.co/lightblue/Karasu-Mixtral-8x22B-v0.1
	- 強い！これは間違いなくエース級　 by AIXさとし
		- https://x.com/AiXsatoshi/status/1778489953279951132
- Introducing Mistral-22b-V.01 A breakthrough in AI
	- https://huggingface.co/Vezora/Mistral-22B-v0.1
	- First-ever MOE to Dense model conversion
	- This model is not an moe, it is infact a 22B parameter dense model!
	- mixtralのexpertsをマージしてmistralにしたやつ
- Vezoraさんが公開されているMistral-22B-v0.1のggufあります
	- https://huggingface.co/mmnga/Vezora-Mistral-22B-v0.1-gguf
- Swallowシリーズのinstruct改良版ですが、本当は2023年度中を目指していたのですが、もろもろ多忙で遅れてしまっています。
	- https://x.com/okoge_kaz/status/1778396705156943985
- mixtral 8x22bを軽くloraでファインチューニングしたら、少し、会話しやすくなりました
	- https://x.com/kanhatakeyama/status/1778417221100028061
	- 現状､mixtral 8x22bは事前学習のみのモデルですが､わりと会話できそうです｡
-  Tool Calling with LangChain
	- https://blog.langchain.dev/tool-calling-with-langchain/
	- 最近はChatGPT以外にも Function Calling (最近は Tool Calling と呼ばれることが多い) に対応するLLMが増えてきました。選択肢が増えて便利ではあるものの、各社で少しづつインターフェースが違うので実装が面倒という課題がありました。
	- そのため、LangChainは各LLMのTool Callingを統一的に扱えるインターフェースを準備しており、先日、最後のピースがハマって遂に完成したという話です。
- LangChain の Tool Calling 標準インタフェース の概要　by npakaさん
	- https://note.com/npaka/n/ne6fd5929bfa1?sub_rt=share_h
	- 「Tool Calling」の標準インターフェイスの構成は、次のとおりです。
		- ChatModel.bind_tools()ツール定義をモデルにアタッチするメソッド
		- AIMessage.tool_callsモデルが決定したツールの情報を伝えるプロパティ
		- create_tool_calling_agent()Tool Callingを利用するエージェントのコンストラクタ
- OpenEQA (オープン語彙の具体化された質問応答ベンチマーク)
	- https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=dataset
	- バッジをどこに置いたか?」などのオープン語彙の質問
	- 物理環境に対する AI エージェントの理解度を測定
- A Square-Root Kalman Filter Using Only QR Decompositions
	- https://arxiv.org/abs/2208.06452
	- QR分解でカルマンフィルター？
	- 正定値行列の和の平方根が平方根のブロック行列のQR分解で計算できることを利用して、数値的安定性の高いカルマンフィルタ（平方根フィルタ）のアルゴリズムをQR分解でシンプルに書けるのか
- Premise Order Matters in Reasoning with Large Language Models
	- LLMにプロンプトを与える際、「推論ステップの流れに沿う順序」で文脈を与えないと30%以上精度が落ちる恐れがあることをDeepMindが報告しています。
-  Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese
	- https://arxiv.org/abs/2404.07824
	- 画像-言語モデルの日本語ベンチマークとして、新しく「Heron-Bench」を公開しました！日本の画像で、日本に関する知識を総合的に問います
- Rho-1: Not All Tokens Are What You Need
	- https://arxiv.org/abs/2404.07965
	- Microsoftお得意の高品質テキストで効率よく事前学習するアプローチの最新論文、トークン単位のlossの推移を高いまま・低いまま・減少傾向・増加傾向の4タイプに分類していて面白そう。実際に学習トークンを選ぶ部分を勉強しよう。
	- https://huggingface.co/microsoft/rho-math-7b-v0.1
- GeminiによるRAGの実践例
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/use-cases/retrieval-augmented-generation
- Gemini API の ファインチューニング を試す by npakaさん
	- https://note.com/npaka/n/n6609bcbbdd30?sub_rt=share_h
- 「カルマンフィルターをQR分解で解く手法」
	- https://github.com/kevin-tracy/QRKalmanFilter
	- Square root Kalman Filter using only QR decompositions.
	- related paper: Differentiable Collision Detection for a Set of Convex Primitives
	- https://arxiv.org/abs/2207.00669
- Can Gemini 1.5 actually read all the Harry Potter books at once?
	- https://x.com/deedydas/status/1778621375592485076
	- All the books have ~1M words (1.6M tokens). Gemini fits about 5.7 books out of 7. I used it to generate a graph of the characters and it CRUSHED it.

## 4/8

今週も情報が早すぎて大過ぎて、もやは追いつけません。RAG向けのベクトルDBのベンダーかと思っていたCohereから、オープンソースのCommand R+ がリリース、まあ成り立ちから当然、RAGとかロングコンテキストに最適化さている。104Bでパラメータも公開、テスト版がhuggingfaceで試すこともできる、GPT-4並みの性能でOSSってやばくないか。早速量子化したり、MLXで動かしたりと、やばくないか。ある性能以上のLLMのオープンソース化禁止みたいな傾向に拍車がかかるのでは。AppleからはReALM発表、どうもSiriの代わりにiPhoneでも動く軽量なモデル、そういえばSiriの人員が解雇されたというニュースもあった。スタンフォードやCMUの一流大学でもCSの修士の就職率が２割とのこと、まあ10年でCS修士取得者が10倍になったという要因もあるようだが、LLMをコンパイラとして使うっていう時代、普通のCS修士程度ではもやは、お呼びではないということか。OpenAIは、日本にアジア初の拠点を開設、なぜか住所は西新橋の雑居ビル。Gemmaの1.1のリリースとかQwen1.5-32B のリリースなど、重要な改良リリースも進む。RAGではReranker が話題に、類似度の高いチャンクを選択したはずなのに、そのあとにRerankするのか。。対応するLLMもいくつか出てる。日本語モデルでは、Swallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルという話もあったが、Mistral 7Bベースの２つの日本語LLMをChat Vector法で強化したものをMoEした、とても長い名前のモデルが話題に、寿限無か。大規模言語モデル開発のための日本語 Instruction データセット作成とか、NLP2024のチュートリアルから、作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコードの公開とか、日本のLLM層の底上げも進む。 アマゾンのBezos氏も投資していると話題となったPerplexity、AI検索が次のビッグウエーブということらしい、GoogleのAI検索も確かにPerplexity風になっているし、GoogleのAI検索は有料化という報道も。もともとBingってPerplexityのような仕組みじゃなかったか。Mixture-of-Depthsとか、ファインチューニングのReFTとか、GRIFFIN とか、新しいLLM最適化の知見が次々にでてきたが、なんといっても、今週はChat VectorというLLMの足し算引き算ができる技術、word2vecのようなベクトル計算がLLMでもできるなんてすごすぎる。Chat Vectorで強化してMoEで、、みたいなのが主流になるかも。Claude3でfunction callingがサポート、さっそくlangchainから、Claude3をつかったエージェント実装が出た、まあ能力からしてそうなるわな。BAAIのMetaWorm論文、線虫を研究して、身体性の謎を解決？Reranker でもBAAI出てきたし、もう中国も、力任せで優れたLLMを出すだけではなく、理論でも、ということか。三値のBitNetの情処の解説、「精度の逆転」というのがあるのか、もし本当ならば、たしかにこれはゲームチェンジャーだな。


- ビジネスの実務で「因果」を推測するということ by TJOさん
	- https://tjo.hatenablog.com/entry/2024/02/28/174811
	- 「とりあえずマーケットの中にふんわりと存在する」系の指標に対して、そのようなきちんとした因果推論を行うのは結構難しい印象があります。
	- 一つの考え方として「時系列的な因果性」をふわっとした代用品として用いるという方法もあり得ると思っています。そう、VARモデルです
	- 即ち実際の因果は「落雷→雷鳴」だが、時系列的には「（落雷→）稲光→雷鳴」が成立するので代用品になり得る、という
- 翻訳モデルHonyaku-7b by AIXサトシ
	- aixsatoshi/Honyaku-Multi-Translator-Swallow-ms7b
	- 数百〜数千tokenの文章翻訳 
	- 英日、日英翻訳機能がメイン
	- XML like instruction
	- 一部の多言語も対応
	- Swallow-ms-7b baseで日本語堪能
- 大規模言語モデル開発のための日本語 Instruction データセット作成の取り組み
	- https://speakerdeck.com/kunishou/da-gui-mo-yan-yu-moderukai-fa-notamenori-ben-yu-instruction-detasetutozuo-cheng-noqu-rizu-mi
- 【OpenAI】日本にアジア初の拠点を開設、法人向けサービス提供へ
	- https://www.nikkei.com/article/DGXZQOUC29A7U0Z20C24A3000000/?n_cid=SNSTW001&n_tw=1711923970
	- OpenAIが4月中に東京都内にアジア初の拠点を立ち上げ、日本での事業活動を本格化させる
	- 事務所は西新橋の雑居ビル？？
-  Mechanistic Design and Scaling of Hybrid Architectures
	- https://arxiv.org/abs/2403.17844
	- LLMのモデル設計は時間とコストがかかる。これを解決するため人工的なベンチマークタスク MAD（in-context recall, compression等）を設計。小規模MADで評価した結果を元に有望な手法を絞りスケールさせる。多くが小規模MADの性能とスケール後の性能に相関がみられた
- LLMの現在
	- https://speakerdeck.com/pfn/llmnoxian-zai
-  MetaWorm: A Complete Model Bridging Brain, Body and Environment of  _C. elegans_
	- https://www.biorxiv.org/content/10.1101/2024.02.22.581686v1
	- BAAIの研究、生物の脳、身体、環境の間の複雑な相互作用を線虫（C. elegan）を材料に解析
- 「Babylon.js 7.0」正式リリース。
	- https://www.publickey1.jp/blog/24/web3dbabylonjs_70mmdmikumikudanceapple_vision_pro.html
	- マイクロソフトは、Webブラウザ上で2Dや3Dモデルの高速なレンダリングなどを可能にするオープンソースのJavaScriptライブラリ「Babylon.js」の最新版「Babylon.js 7.0」正式版をリリースしました。
	- MMD（MikuMikuDance）のインポートと利用を可能にするMMDローダーとランタイムが追加されました。IKソルバ、オーディオ同期再生、プレイヤーコントロールなどの機能も用意されています。
- CMUもStanfordもColumbiaもCS修士のインターン内定率2割
	- https://x.com/fzw1212/status/1774218929100988506
-  LLaMA Now Goes Faster on CPUs
	- https://justine.lol/matmul/
	- 84 new matrix multiplication kernels for llamafile
	- between 30% and 500% faster when using F16 and Q8_0 weights on CPU. 
- Gecko: Versatile Text Embeddings Distilled from Large Language Models
	- https://huggingface.co/papers/2403.20327
	- Googleから、Gecko組み込みモデル、LLMを蒸留した？？謎
	- LLMを使って学習用のペアデータを作ってEmbedding Modelの学習をした後、このモデルに寄り得られた関連パッセージに同じLLMでPositive/Hard Negativeのラベルを振り直して追加学習しているらしい。
- LMFlowでLlama2-70BのLISAファインチューニングがあっさり動いた by shi3zさん
	- https://x.com/shi3z/status/1774710763007119735
	- 大体30GBあれば学習できるとすればA6000でも可能ということか?
-  Google Colab で BAAI/bge-reranker-v2-m3 を試す by npakaさん
	- https://note.com/npaka/n/n7d251f76ce25?sub_rt=share_h
	- 「BAAI/bge-reranker-v2-m3」は、「bge-m3」ベースの「Reranker」モデルです。「Reranker」モデルは、従来の「埋め込み」モデルとは異なり、質問とドキュメントを入力として受け取り、類似度を出力します。
	- 「パンダとは？」の質問には「パンダは中国南西部の山岳地帯に生息する哺乳類の一種です。」のドキュメントが関連していることがわかります。
- Building a RAG application using open-source models by langchain
	- https://x.com/LangChainAI/status/1774821270900629950
	- https://github.com/svpino/llm/blob/main/local.ipynb
	- https://www.youtube.com/watch?v=HRvyei7vFSM
- Claudeだと本当に一瞬で以下のようなアーキテクチャ図を作ってくれる。
	- https://x.com/ai_syacho/status/1774677348807483788
- Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians
	- https://github.com/city-super/Octree-GS
	- https://x.com/janusch_patas/status/1774717184238883237
- 『Google検索を超える衝撃の生成AI型新検索エンジン：Perplexity Proが情報収集を変える！』
	- https://x.com/tetumemo/status/1774632484648730889
	- Perplexity のようなAI検索が、つぎのビッグウエーブというか、active personal noteだよな。AI検索を有料にするという動きもある。
- BItNet-Transformerの学習済みモデルが公開されている
	- 1bitLLM/bitnet_b1_58-large
- NLP2024 チュートリアル３: 作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコード
	- https://github.com/hiroshi-matsuda-rit/NLP2024-tutorial-3
	- 日本語LLMの学習・評価に用いられる技術とデータセットについて広く取り上げています。是非ご覧ください。
	- 講演スライドと実験環境構築手順・ソースコードはGitHubリポジトリで公開しています
	- リクルートの松田寛さん
- 東工大のSwallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルだろうね…
	- https://x.com/Meteor_Eternal/status/1775096408435216766
- OSS Models + LangGraph.js
	- LangGraph helps you create LLM apps that closely match the logical flows used to solve a problem.
	- https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_mistral.ipynb
-  Mamba Explained
	- https://thegradient.pub/mamba-explained/
	- Mambaの選択機構を注意機構との比較やアナロジーを用いながら直感的に説明した記事。 
	- 文脈内学習ではTransformerのようにプロンプトに全ての情報を入れる必要がなく、状態（システムプロンプトなどを圧縮したもの）と質問を渡すだけで良い。
- Bigger is not Always Better: Scaling Properties of Latent Diffusion Models by Google
	- https://huggingface.co/papers/2404.01367
- Prompt-prompted Mixture of Experts for Efficient LLM Generation
	- https://arxiv.org/abs/2404.01365
	- LLM への入力ごとに、LLMの各レイヤーでのアクティベーションの相対的な大きさが、トークン位置によらず一部の次元に偏る flocking という現象を発見し、これをもとに、
	-  (1) prompt 入力次点でアクティベーションが相対的に大きい次元を特定
	-  (2) その次元のみを使って近似的/効率的に Decode を行う、
	- GRIFFIN (Gating by Repetition In Feedf orward Intermediate Neurons) を提案。 タスクに依存するが、学習不要な方法で精度をあまり落とさず生成を高速化できる。
-  Are large language models superhuman chemists?
	- https://arxiv.org/abs/2404.01475
	- 「化学分野の幅広い 7,000 以上の質問と回答のペアを厳選し、主要なLLM を評価しました。その結果、私たちの研究では、最良のモデルが平均して最良の人間の化学者を上回るパフォーマンスを示した」
-  LlamaIndex の Reranker を試す by npakaさん
	- https://note.com/npaka/n/n8f9ee8533896?sub_rt=share_h
	- RAGにおける「Reranker」は、取得したチャンクの中から、質問に対して最も関連性の高い情報を持つチャンクを選択する役割を担っています。
	- 今回は、多言語のRerankerモデル「**BAAI/bge-reranker-v2-m3**」を使います。top_n=5で関連性の高い5件に絞ります。
-  Semantic Routerを試す
	- https://zenn.dev/kun432/scraps/73b098e774bd21
	- LLMやエージェントの意思決定のルーティングを行うSemantic Routerを試してみた。ルーティングだけじゃなく、セマンティックなチャンク分割にも使える。 ベクトル検索の使い方はいろいろな可能性がありそう。
	- クエリで処理を分岐させたいようなケースは、Function Callingを使ってLLMにルーティングさせるとかがあると思うのだけど、事前にクエリのサンプルを用意しておいてベクトル検索でルーティングさせるというようなもの。
	- LangChainのエージェントと組み合わせた例。
- 4/23(火)に、Sakana AI初のイベントやります！Grow-AI、Arayaの方々と我々のトークがあります
	- https://x.com/iwiwi/status/1775367258040410519
- 2x7Bの日本語チャット・ノベル専用高性能モデル。
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Antler-7Bとchatntq-ja-7b-v1.0という、Japanese Stable LM Base Gamma 7B（Mistral 7Bベース）をinstructionチューニングしたモデルを各々ChatVector法で強化し、MoEでマージしたのだそうだ
- RankZephyr is a nice 7B model 
	- https://arxiv.org/pdf/2312.02724.pdf
	- that is optimized for list-wise zero-shot reranking
	- https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/rankLLM/?h=rankllm
- intelligent notetaking by https://iki.ai/
	- https://iki.ai/
	- a cool example of an AI-enabled notetaking interface that epitomizes the core value prop of RAG - dump in a ton of your messy, unstructured data (files, links, notes), and have the application organize and surface information for you instead of you having to do it yourself.
-  Google Colab で japanese-reranker-cross-encoder-large-v1 を試す by npakaさん
	- https://note.com/npaka/n/n906b23636ac8?sub_rt=share_h
	- 「 japanese-reranker-cross-encoder-large-v1」は、日本語に特化した形で学習した「Reranker」です。xsmallからlargeまで複数のサイズが提供されており、「large」は多言語Rerankerで最も人気のある「bge-reranker-v2-m3」をベンチマークで上回っています。
	- クエリと文章の準備と、スコアの計算。
- Anthropic Messages API
	- https://x.com/AnthropicAI/status/1775979799644934281
	-  Claude3に
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTI2MDkyMjU4NCwtMzg3MTk0NDUwLC0yMj
cwNzc2MTgsLTE3OTUxMDI4NjMsMTY1ODczNzEwNSwtMTE3MTQ3
MTU3NCwxMDQwMjA1NjY3LDI5MDAxMjE0MiwxMzcxNzI0ODg4LC
0xNDU5MTEyMDc1LC0xMzQxMzczODAsLTEyNjA0MDgzMjIsLTEx
NjU4MjExMzYsMTY4ODA2ODYxMCwtMjA0OTYyNzU0NCwtMTA5Nj
g1NTMwMSwxMTQ5MjAxODkzLDgyNTU2NzkwMiwtMjExMDU1MDM3
OSwtOTAzMDM3Mjk1XX0=
-->