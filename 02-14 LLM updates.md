# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。

## 6/10

- Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality
	- https://arxiv.org/abs/2405.21060
	- 現在生成AIで主流のTransformerの「次」のアーキテクチャとして期待されるMamba-2を提案
	- Mamba2は新しく導出されたSSDを使い、系列長に対し線形の計算量、メモリ使用量で効率的に学習、推論でき、TransformerやMambaよりPPLや下流タスクで性能が高い。SSMとTransformerが統一的な枠組みで扱えることも示す by 岡野原さん
- GPT-4 is 1.8T MoE, thanks Nvidia Presentation
	- https://x.com/literallydenis/status/1797531945926287497
- LLMを活用した大規模商品カテゴリ分類への取り組み
	- https://engineering.mercari.com/blog/entry/20240411-large-scale-item-categoraization-using-llm/
	- GPTを商品カテゴリ分類に活用した事例と工夫したポイントがまとまっているよ
		- EmbeddingモデルはOSSでも問題なし
		- GPT4はコスト的に使えなかった
		- max_tokensとChain of Thought での効率化
		- Numbaへの書き換えもGPTを使って効率化
-  Hugging FaceのZeroGPUでAIのデモを作る方法: 初級編
	- https://qiita.com/alfredplpl/items/abb30283b578dc984d16
	- ZeroGPU とは、デモの利用者が使う瞬間だけ高性能なGPUが借りられるというサービスです。現在はA100 40GBが一瞬借りられます。これを実現できているのは世界でHugging Faceだけでしょう。お値段は月額9ドル（約1500円）です
	- Hugging FaceのZeroGPUはAIのデモを作るのに最適だとわかりました。いかがでしたでしょうか。ぜひみなさんもデモを作ってみてください。なお、私は責任を持ちません。
- lmsys.org でGoogleのGemini 1.5 Pro（5/14モデル）が日本語で世界一になりました。２ヶ月前のモデル (4/9モデル）よりかなり改善されました
	- https://x.com/shanegJP/status/1797798176344453414
- Perplexity Pages、AIに情報をまとめてきてもらうついでにそれをWeb記事の体裁でまとめて公開できちゃうのかあ。
	- https://x.com/umiyuki_ai/status/1797871157850620270
- 富士通は、特化型の生成AI混合技術とナレッジグラフ拡張RAGというマニアックな方向に進化することになりました。
	- https://x.com/AsamaKotaro/status/1797844740328804563
-  the benefits of Google Gemini's gigantic 1 million token context window in action!
	- https://x.com/llama_index/status/1798049438814081138
	- In this quick notebook, we show Gemini built into a LlamaIndex agent attempting to answer a multi-part question from a set of complicated, heterogeneous documents.
- 富士通の研究戦略発表会、最適化問題と生成AIによる制約条件の生成が相性が良いという発想
	- https://x.com/tokoroten/status/1797851927457546682
	- 議事録やマニュアルから制約条件を起こしたり、AIとの対話を通じて制約条件を起こしたり
- 概念データモデルから始める真にデータドリブンな製造業DX
	- https://www.qunie.com/quriosity/231218_00/
	- 概念データモデルは個々の業務改革やモダナイゼーションに着手する前に作成するデータモデルである。特定の業務領域だけでなく、製造業のバリューチェーン全体をモデルとして表現する。
	- 論理データモデルのような厳密さは不要で、関連するデータをグループ化したデータ群と、そのキー項目（全てのデータ項目は不要）、データ群のつながりを示す。
	- バリューチェーン全体を俯瞰した概念データモデルがあるからこそ、企業全体の改革に一本の芯が通ることになるのだ。あるお客さまは、概念データモデルのことを“自社の憲法”と表現されていたが、まさにその通りである。
- ELYZAが、国立研究開発法人 産業技術総合研究所が募集した大規模生成AI研究開発支援プログラムに採択されました。
	- https://x.com/ELYZA_inc/status/1797780304717078689
-  論文解説をGPT-4oを使って自動的に生成してみる by 逆瀬川さん
	- https://qiita.com/sakasegawa/items/8e17ede26dd96e7e3280
	- PDFを画像として取り扱うと処理は遅いが格段に安い！！ 
	- 論文のPDFを画像として扱い、GPT-4oで落合メソッドを使って解説を生成させる
	- 論文のPDFから数式や図表を抽出し、個々に解説を生成
- もはやAIの性能を人間が測定できない by  karaage. [からあげ]さん
	- https://karaage.hatenadiary.jp/entry/2024/06/04/073000
	- そもそもAIの性能を人間が測定するのが難しい領域に来ているなと実感しました。
- Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming
	- https://arxiv.org/abs/2406.00592
- LLM Basics - Why can't we use regular LoRA for pre-training LLMs
	- https://x.com/rohanpaul_ai/status/1797759219891937324
	- LoRA (Low-Rank Adaptation), targets a subset of a neural network's parameters, specifically focusing on the weight matrices of transformer models. It represents these large matrices as the product of smaller
- Why AI wont take your job just yet
	- https://medium.com/@starloba/why-ai-wont-take-your-job-just-yet-13e95cd05da8
	- 汎用的なタスクをAIに解かせるようになると、人間はよりクリエイティブな問題に注力できるようになる。より正確に言うなら、強制的に注力しないといけない状況に追い込まれる。
- Microsoft has built a weather forecasting model named 'Aurora
	- https://x.com/MSFTResearch/status/1797662278394827029
-  Heuristics on the high seas: Mathematical optimization for cargo ships
	- https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/
	- Today we present new solutions to the Liner Shipping Network Design and Scheduling Problem, released as part of our new Shipping Network Design API, with the goal of maximizing the efficiency of container shipping networks at world-wide scale
- Unslothはこの論文に対抗してLoRAでの継続事前学習を徹底的に最適化した結果、今までのLoRA学習の２倍の効率で学習できて、VRAMも半分で済む
	- https://x.com/umiyuki_ai/status/1798221784334160262
	- 24GBのVRAMでLlama3-8BやMistral-7BがLoRA継続事前学習できる
- GLM4-9Bだって。26言語対応。GPT-4に匹敵する関数呼び出し能力
	- https://x.com/umiyuki_ai/status/1798292824544420150
- 継続事前学習(CPT: Continued Pre-Training)をQLoRAでやろうとする試み
	- https://x.com/webbigdata/status/1798313713654776062
	- Colab無料版でもmistral-7b-v0.3なら十分動きました
	- llama3 8bやgemma7bでは有料版のL4(24GB)でもメモリ不足になってしまいましたがllama2という手もあります
-  佐賀の織田病院がオンプレGPUサーバーでLLM稼働、電子カルテ情報を生成AIが要約
	- https://xtech.nikkei.com/atcl/nxt/column/18/00001/09236/
	- これまで利用してきた電子カルテシステムにオプティムが提供する生成AI「OPTiM AI」を組み合わせ、看護師の業務効率を高める実証に乗り出し
	- 米NVIDIAのRTX A2000を搭載したGPU（画像処理半導体）サーバー1台を新たに院内に用意した。LLMの学習や推論に用いる
- Introducing AI Agents in LangGraph!　 by Deeplearning.ai
	- https://x.com/DeepLearningAI/status/1798376731188834780
	- In this course taught by hwchase17, LangChainAI CEO, and weiss_rotem, tavilyai CEO, you’ll learn to use LangGraph to create controllable agents, and agentic search for agents to enhance their output.
- ChatGPTでレ・ミゼラブルの人物相関3Dネットワークグラフを作成
	- https://x.com/itnavi2022/status/1798320618695438647
	- 
- 

## 6/3

Google I/Oで発表されたgoogleの検索x生成AIが、とても不評ということで、Wall Street Journalの記事にもあるように、Perplexityの優秀さが際立つ、gooleがプレスリリースした新技術で期待を裏切るのは全く恒例ですね。とはいっても、Gemini 1.5 Pro/Flashの優秀さもあちこちで報告されており、本当は優れてるんでしょう。Mistralからコード生成のOSSであるCodestralが発表、さっそくOllamaが対応、これでお好きなエディタと組み合わせてプログラミングのアシスタントが実現可能に。量子化、小規模化にも進展があり、Mixtral 8x22b の量子化版Q6_K が $362 CPU(AMD Ryzen 9 5950X BOXか?)で軽々動作するという報告もあったり、Phi-3-Tinyシリーズのように、さらに小ささなLLMにチャレンジみたいな展開もあった。llama.cppで量子化版を動作させるとollamaより1.8倍速いという報告も。生成AIの飛躍的性能アップの秘密といわれる「グロッキング」に関する論文、汎化回路形成の秘密に迫り、新たなアーキテクチャ提案というのは胸熱い。生成AIの「創造性」に関する１０万人の人間！との比較で、GPT-4ならプロンプトを工夫すれば、人間を上回るというのには驚いた。O'ReillyからPrompt Engineeringの新刊も出るが、そもそもAnthropicのClaude3は、ゴールを与えれば適切なプロンプトを生成してくれるという。財務諸表から将来の収益の伸びを予測するタスクでGPT-4は人間より優れていると聞いても驚かなくなった。そんなAIですが、AIが他者の心や意図を理解する能力を持っているのかの「心の理論(ToM:Theory of Mind)」を持っているかどうかを分析した論文では、GPT-4 and Flan-PaLM が人間の大人のレベルに達したとのこと。さらに人間を超えるという意味では、Autoformalizing という、人間が作った幾何学をAIが自動証明できる体系に、生成AIをつかって作り直すという試みもあった。こうなると人間の理解がどこまで生成AIについていけるかという点が心配になる、ニューラルネットの動作理解の「Graph Game」や、LoRaの原理の可視化など、そういうのも目立った気がする。全く反対にアセモグル氏のように、それほどAIは格差拡大に影響しないという分析もあった。安全性に関しては、RAGを前提としたバックドアTrojanRAGというのも出た、説明性が高いこととバックドアを仕込みやすいというのは表裏一体。さて日本では、人工知能学会が浜松で開催、岡崎先生のスライド「大規模言語モデルの開発」は必見です。一方、ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果で、なんとナイジェリア英語のdelveという単語が生物系の論文に大量に表れたとの報告もあった。そもそも人間のほうも、エビデンスベースで合理的に思考する能力に課題があり、ストーリーに流されがちとの指摘があるので、ストーリー性を求めすぎて、合理的に思考できない生成AIができるかも。ロイヤルアカデミーの「AI in Science」すでに「AI for Science」といっている時代ではなくなった、つまりAIを使わずに科学の進展はない。さてNASAから満を持して、大気現象を予測する基盤モデルAuroraの発表、10kmメッシュで10日後まで天気予報できるってどれぐらいすごいのだろう。全くの余談だが、gpt-4oの発表時に参照された映画"Her"の監督の離婚した妻が監督した "Lost In Translation"の２つを比較し、一部シーケンスが全く対照的にアライメントしているという話題がテック界隈で一瞬話題になった。

-  自分がどれくらいニューラルネットワークを理解しているかを確かめられるゲーム「Graph Game」
	- https://gigazine.net/news/20240526-graph-game/
- googleの検索x生成AIについては，ちょっと評価がイマイチなんですよね．油と水を無理やり混ぜようとしている感がある．by 今井さん
	- https://x.com/ImAI_Eruel/status/1794707281600496111
-  TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models
	- https://arxiv.org/abs/2405.13401
	- RAGを悪用したバックドア攻撃。RAGで使用する知識DBに細工データを注入し、（DBから関連データを検索する）リトリーバとDB間でバックドアリンクを作成する。これにより、トリガーとなるPromptが入力された場合のみ、LLMに悪意のある回答を生成させることができるとのこと。
- We're now able to run Mixtral 8x22b Q6_K on a $362 CPU with better than human reading speed.
	- https://github.com/Mozilla-Ocho/llamafile/discussions/450
- llama.cpp runs 1.8 times faster than ollama
	- https://x.com/rohanpaul_ai/status/1794470545586635238
- Exploring the Impact of ChatGPT on Wikipedia Engagement
	- https://arxiv.org/pdf/2405.10205
	- Wikipedia remains the crowning achievement of Internet 1.0. It powered the rise of search engines (which depend on it) & generative AI (trained on its data).
- Grokked Transformers are Implicit Reasoners:A Mechanistic Journey to the Edge of Generalization
	- https://arxiv.org/pdf/2405.15071
	- 1) Transformers can learn to implicitly reason, but only through extended training far beyond overfitting, a phenomenon known as grokking.
	- 2) Transformers exhibit different levels of systematicity in generalization across reasoning types: ID generalization is consistently observed, OOD generalization fails for composition but succeeds for comparison tasks.
	- 汎化回路形成の秘密に迫り、あたらなアーキテクチャを提唱している
-  Phi-3-Tiny-Untrained
	- https://colab.research.google.com/drive/188RpybbauEJKSIRPGL3RZi4Lk66HfBJj
	- This 50M-parameter model reconfigs Phi-3-mini-128k-instruct (3.8B parameters) by following the parameters given by the Super Tiny Language Models from A*STAR.
-  GPT-4は財務諸表から将来の収益の伸びを予測する点で人間のアナリストよりも優れていることが研究により明らかに
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311
- The Wall Street Journal says perplexity outperforms chatgpt, gemini & claud
	- https://x.com/RubenHssd/status/1795108714564706452
- DifyとOllamaを使用してローカルLLMを構築し、複数のLLMエージェントを設定してAIが社会に与える影響について議論を行い、その結果を記事として生成する手順について説明します。
	- https://hamaruki.com/how-to-configure-and-discuss-multiple-agents-using-dify-and-local-llm/
-  How Good Are the Latest Open LLMs? And Is DPO Better Than PPO?
	- https://magazine.sebastianraschka.com/p/how-good-are-the-latest-open-llms
	- In April, there were four major open LLM releases: Mixtral, Llama 3, Phi-3, and OpenELM.
- Decoder-onlyなLLM（Mistral-7B）をtext embedding用にファインチューニング（LoRA）してMTEBでSoTAを達成した方法NV-Embedの提案
	- https://x.com/s_tat1204/status/1795344530285457626
- Google Search algorithm leaked today.
	- https://x.com/hridoyreh/status/1795394077510517217
-  Autoformalizing Euclidean Geometry
	- https://arxiv.org/abs/2405.17216
	- Can AI transform human mathematics into formal theorems and proofs that machines can verify?
	- This process, known as autoformalization, is a key step towards AI mathematicians. We introduce a neuro-symbolic framework for autoformalization, focusing on Euclidean geometry and combining domain knowledge, SMT solvers, and LLMs.
- Mixtral 8x7B Instruct with AWQ & Flash-Attention-2 in ~24GB GPU VRAM!
	- https://x.com/rohanpaul_ai/status/1795196332166070289
	- With the latest release of AutoAWQ - you can now run Mixtral 8x7B MoE with Flash Attention 2 for blazingly fast inference.
-  Automatic Domain Adaptation by Transformers in In-Context Learning
	- https://arxiv.org/abs/2405.16819
	- 幡谷さん（理研特別研究員）と松井先生（名大）の研究を公開しました。トランスフォーマーがインコンテキスト学習において、複数のドメイン適応法を表現し、さらにデータに応じて適切な適応法を選択する能力を持つことを理論と実験で示したものです。
- Training and Finetuning Embedding Models with Sentence Transformers v3
	- https://huggingface.co/blog/train-sentence-transformers
- ちなみにGemini 1.5 Proではapplication/jsonを出力フォーマットとして選択できて便利
	- https://ai.google.dev/gemini-api/docs/api-overview?hl=ja#json
- CLARINET: Augmenting Language Models to Ask Clarification Questions for Retrieval
	- https://arxiv.org/abs/2405.15784
	- Fine-tunes an LLM to ask clarification questions that maximize retrieval success for ambiguous search queries, outperforming heuristic methods and vanilla language models
- 映画herとLost In Translationの監督は離婚した元夫婦であり、その画像の一部はシンクロしている。。
	- https://x.com/MissSassbox/status/1795205212770119782
	- I had no idea that "Her" and "Lost In Translation" were clapbacks by the directors to each other after their divorce and now I need to watch both
	- Tech界で、gpt-4oのデモが、、映画herを意識して作られていたことから、（再？）発見された雑学
- Introducing Transformers Agent 2.0: A Leap Forward in Intelligent Automation
	- https://huggingface.co/blog/Andyrasika/transformer-agents
- 松田語録：Gemini 1.5 Proを論文を読むのに使ってみた〜良いところと悪いところ
	- https://x.com/npaka123/status/1795568613900062747
- ChatTTS: a powerful voice generation model designed for conversational scenarios
	- https://github.com/2noise/ChatTTS
	- https://huggingface.co/2Noise/ChatTTS
- 『エビデンスを嫌う人たち　科学否定論者は何を考え、どう説得できるのか？』by 暦本先生
	- https://x.com/rkmt/status/1795636068752212063
	- おおー。しかしエビデンスベースで思考する人類はむしろ少数派かもしれない..(System1思考=Fast Thinking > System2思考 Slow Thinking) 。エビデンスよりもストーリーが優先する.
- 進化的マージによって相当強そうなモデル、Umievo-itr012-Gleipnir-7Bが生まれました。3回ElyzaTasks100で評価した平均スコアは3.91！　by うみゆきさん
	- https://huggingface.co/umiyuki/Umievo-itr012-Gleipnir-7B
	- マージに使用させていただいたのはJapanese-Starling-ChatV-7B、Ninja-v1-RP-expressive-v2、Vecteus-v1、Japanese-Chat-Umievo-itr004-7bの４つです。各モデル制作者のAratakoさん、Bakuさん、Local-Novel-LLM-projectのみなさまに感謝します。それから問題解決のきっかけをくれたHoly-foxさんに感謝します。
- AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)
	- https://x.com/emollick/status/1795830809217454536
	- https://www.researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models
	- GPT-4 wins. Better prompting can further improve performance & diversity of ideas.
	- ついに創造性でもGPT-4が、（普通の）人間を抜いたのか。。
- Gemini 1.5 FlashはClaude 3 Opusに匹敵しながら、コストは100万トークンあたりたったの55円
	- https://x.com/gijigae/status/1795743286533255285
- Announcing Codestral: our first-ever code model
	- https://chat.mistral.ai/chat
	- "Write me a function that computes fibonacci in Rust"
- OllamaがCodestralに対応
	- https://ollama.com/library/codestral
- "Science in the Age of AI - How AI is changing the nature and method of scientific research,"
	- https://royalsociety.org/-/media/policy/projects/science-in-the-age-of-ai/science-in-the-age-of-ai-report.pdf
	- 英国ロイヤルアカデミー
	- Generative AI tools can assist the advancement of scientific research.
-  Introducing the Property Graph Index: A Powerful New Way to Build Knowledge Graphs with LLMs
	- https://www.llamaindex.ai/blog/introducing-the-property-graph-index-a-powerful-new-way-to-build-knowledge-graphs-with-llms
	- 1. You can extract out a knowledge graph according to a set of extractors. These extractors include defining a pre-defined schema of entities/relationships/properties, defining a set of node relationship with llama_index constructs, or implicitly figuring out the schema using an LLM.
	- 2. You can now query a knowledge graph with a huge host of different retrievers that can be combined: keywords, vector search, text-to-cypher, and more. 3. You can include the text along with the entities/relationships during retrieval 4. You can perform joint vector search/graph search even if your graph store doesn’t support vectors! We’ve created robust abstractions to plug in both a graph store as well as a separate vector store. 5. You have full customizability: We’ve made it easy/intuitive for you to define your own extractors and retrievers.
- The structure of the EU AI Office
	- https://x.com/LuizaJarovsky/status/1795775192347627857
	- The “Excellence in AI and Robotics” unit
	- The “Regulation and Compliance” unit 
	- The “AI Safety” unit
	- The “AI Innovation and Policy Coordination” unit
	- The “AI for Societal Good” unit 
	- The Lead Scientific Advisor
	- The Advisor for International Affairs
- 英国のアカデミー、Royal Societyも「AI for Science」ではなくEUと同じ「AI in Science」。レポートはかなり充実している by maruyamaさん
	- https://x.com/rmaruy/status/1795967400502006026
- Mamba, Griffin, RWKV, RetNet, Recurrent Gemma- 2024 is the year of gated linear RNNs! What's their secret sauce?
	- https://x.com/ItamarZimerman/status/1796181061984030914
- CRDSの新作プロポーザル『次世代AIモデルの研究開発』がめちゃくちゃいい仕事で一気見した。
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-SP-03.html
	- https://x.com/resnant/status/1796181056283898332
	- LLM含め最近の基盤モデルや生成系AIの動向と諸課題を技術的にも掘り下げてて、いろいろな立場の人に参考になると思う
- [LoRA] by Hand
	- https://x.com/ProfTomYeh/status/1796169087665557729
	- How does LoRA reduce the number of trainable parameters?
-  Don’t Believe the AI Hype
	- https://www.project-syndicate.org/commentary/ai-productivity-boom-forecasts-countered-by-theory-and-data-by-daron-acemoglu-2024-05?
	- ダロン・アセモグル氏の分析では、AIによって影響をうける人間のタスクは4.6％で、向こう十年のAIによる全要素生産性の向上は0.66%にとどまる。AIによる科学発見は直近では経済にさほど影響しない。かつての自動化技術に比べると格差拡大効果は小さいが規制は必要
-  Aurora: A Foundation Model of the Atmosphere
	- https://arxiv.org/abs/2405.13063
	- NASA has created a new foundation model for geospatial data.
	- Create 5-day air pollution predictions in < 1 minute 
	- Create 10-day weather forecasts at ~10km resolution 
	- Assess the chemical make up of the atmosphere
- llm.cを使うとGPT-2を$20で2時間以内に構築可能？？
	- https://x.com/overlast/status/1796028138616422535
- Here’s a great guide teaching you how to construct knowledge graphs using LLMs that adhere to a pre-defined schema - using purely local models
	- https://x.com/llama_index/status/1796198853764595725
- 「大規模言語モデルの開発」 by　岡崎さん　@ JSAI2024
	- https://speakerdeck.com/chokkan/jsai2024-tutorial-llm
	- チュートリアル講演を行いました。事前学習、インストラクションチューニング、アライメント、評価の４部構成で、最近の研究動向や知見を紹介しました。
- Prompt Engineering for Generative AI
	- https://www.amazon.com/gp/product/B0D4FBPLX1?&linkCode=sl1&tag=kirkdborne-20&linkId=17812cf95726cdbbe7b0c29f94f4bce7&language=en_US&ref_=as_li_ss_tl
	- With this book, you'll gain a solid foundation in generative AI, including how to apply these models in practice. When first integrating LLMs and diffusion models into their workflows, most developers struggle to coax reliable enough results from them to use in automated systems.
- LLMs achieve adult human performance on higher-order theory of mind tasks
	- https://huggingface.co/papers/2405.18870
	- LLMs achieve adult human performance on higher-order theory of mind tasks 
	- This paper examines the extent to which large language models (LLMs) have developed higher-order theory of mind (ToM); the human ability to reason about multiple mental and emotional states in
	- We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level performance on ToM tasks overall, and that GPT-4 exceeds adult performance on 6th order inferences
- 生成AIによる「慣用表現の『乗っ取り』」と、その根底にある別の問題と by TJOさん
	- https://tjo.hatenablog.com/entry/2024/05/31/171000
	- 「ChatGPTに学術論文を（英語で）書かせると"[delve](https://eow.alc.co.jp/search?q=delve)"のような普段使わないような単語が多く使われるのでバレやすい」という話が[SNS](https://d.hatena.ne.jp/keyword/SNS)以下各所で頻繁に噂
	- ChatGPTのRLHF（ヒトのフィードバックによる強化学習）プロセスの多くが、アウトソースされた（比較的人件費の安い）ナイジェリアのオペレーターたちによって行われた結果である、というものです。そもそも、例えば"delve"という単語はナイジェリア英語ではビジネスフレーズの中では比較的頻繁に用いられるそうで*3、それらのナイジェリア英語によるチューニングの結果がChatGPTの出力に影響している、ということのようです*4。
- The new Anthropic prompt engineering tool is incredible.
	- https://x.com/dr_cintas/status/1796577510773379479
	- You just need to write your goal and Claude will generate an optimized prompt instantly.
-  An entirely open-source AI code assistant inside your editor
	- https://ollama.com/blog/continue-code-assistant
	- つまり、ollamaをつかって、あなたの好みのエディタにCode assistanceをという話
- 最近の7B小型日本語LLMはエージェントになれるのか？
	- https://soysoftware.sakura.ne.jp/archives/3934
- 


## 5/27

さて今週は、MicrosoftのBuild2024が開催、gpt-4oを組み込んだCopilot+PCというintelはいってないPCのほかに、誰でもエージェントを作れるCopilot 進化的の更新や、人の代わりに会議進行をしてくれるTeam Copilot、さらには、ソフトウエア開発自動化の「Devin」の会社との提携など、目白押し。まあ早速、ゲームをサポートするcopilot assistantのデモをGemini 1.5 Flashで、さらにマリオゲームで再現できたとの個人の報告もありました。さて来月のAppleの WWDC24はどうなる。基盤技術では、チューリングテストでGPT-4は54%の確率で人間だと判断されたというのは、もう驚かない、AIによる詐欺にあわないように心がけても無駄という未来が、、。むしろ、「LLMがチャットUIに呪われている」という記事もあったが、もやはLLMの発展は人間が律速していて頭打ちになっている。一方AnthropicのClaude3 Sonetに対する特徴抽出の論文、つまりニューラルネット上にLLMの性質あるいは特徴を示す場所を特定する技術（スパースオートエンコーダ）、安全性の分析で役に立つといっているが、逆に特定の箇所を特別に活性化させれば、例えば、ゴールデンゲートブリッジ一押しのLLMが爆誕するとのこと。いやまさにもろ刃の剣となる重要な技術。知識グラフのRAGもアツイが、GraphRAGという画像化した知識グラフに対するRAGという技術、マルチモーダルだとそういうこともできるのか。今井さんのGPT-4oを研究者視点で「時代の転換点」と解説した記事のシリーズは気になるが登録が必要なのか。GUILDの深津さんの、横須賀市の未完成のお悩み相談チャットボット。不完全でもベータ公開というわりにやっぱよくできている。その深津さんが、生成AI時代に大事なスキルは、「やり続ける能力」、いくら生成ＡＩが優れていてもめげないことが大切。ローカルLLMも相変わらずアツイ！。今週も、Mistral v0.3がリリース、語彙数も増えて、見違えるくらい日本語能力が強化され、function callingへも対応、ollamaもraw modeでfuntion callingへ即追従。一方、マルチモーダルphi3-visionも含めてリリースされたphi3-small,medium、phi3-mediumがMMLUスコアはLlama3-70B並みに高性能であるということだが、量子化でデグレードしたのかOllamaへの組み込みはうまくいってない模様。Transformers.js とONNX Runtime Webの組み合わせというのも、ローカルLLMの協力な助っ人か。Cohereが多言語指向のオープンLLMであるAya 23 の 8B と35Bがリリース、日本語強そう。しかし、Phi-3は、「最も有能で費用対効果のSML (Small Language Model)」っていうんだ(Small LLMのほうがかっこよいのに)。 それにしても DeepSeekV2 、あまりに性能が高いので中国での競合のサービス料を1%押し下げた（投げ売り開始？）とのこと。ChatVector、7BモデルのFineTuning結果を70Bに転移させて性能向上したり、LLaVAの日本語化など、ローカルLLMでもその能力をふくめて認知や利用が増えてきた。transformersがv4.41.0にアップデートされてggufをサポートするようになったのも、ローカルLLM勢には朗報。EUのAI法が最終合意、生成ＡＩの規制も盛り込み済み。一方OECDはAIリスクに関する用語を整理し、インシデントの重大さにハザードが起こる確率を加味したものがリスクのレベルになるとのこと。英国の「Safeguarded AIプログラム」は、安全性のために数理論理学や圏論を利用する、同じsafe guardでも毒には毒をということでguard自体をLLMで実現するメタのアプローチと真逆で面白い。

-  Unleashing the Power of Knowledge Graphs in Retrieval Augmented Generation (RAG): Step by Step Instruction
	- https://medium.com/@transformergpt/unleashing-the-power-of-knowledge-graphs-in-retrieval-augmented-generation-rag-step-by-step-84c2adc66c1c
	- This is a neat resource by Jayita B. on teaching you how to not only build an advanced RAG indexing/query pipeline, but also turn it into a full-stack application with rapid respons
- OECD (2024), "Defining AI incidents and related terms",
	- https://www.oecd-ilibrary.org/science-and-technology/defining-ai-incidents-and-related-terms_d1a8d965-en
	- OECDのWGが作っているAIリスクを分類するための用語整備のレポート。起こりうる被害をハザード、起こった被害をインシデントと呼び、その重大さを考慮。ハザードに起こる確率を加味した全体がAIリスクとなる
- Text-to-SQL - fully local edition
	- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
- Run Mixtral 8x7B-on a free-tier Google Colab with AQLM-2bit quantization
	- https://www.youtube.com/watch?v=6ikUpJcDrPs&list=PLxqBkZuBynVTzqUQCQFgetR97y1X_1uCI&index=32
- The theoretical minimum series by Leonard Susskind and Art Friedman
	- https://x.com/PhysInHistory/status/1792020784854311205
- Chat VectorでLLaVAを日本語対応させる
	- https://zenn.dev/toshi_456/articles/0166a6eaa81c7b
	- LLaVAは大きくVision Encoder、Vision Projector、LLMという3つの部品からできていますが、LLMの部分だけ上記のように重みを加減算します
	- 今回使用するLLaVAの重みは[liuhaotian/llava-v1.5-7b](https://huggingface.co/liuhaotian/llava-v1.5-7b)です。このモデルのベースのLLMは[meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)です。
	- Chat Vectorやその他のマージ手法を使用することで、英語のデータセットを日本語に翻訳して、学習させるという手間が必要なくなる可能性があるのはありがたいなと感じました。
- 横須賀市で、未完成のお悩み相談チャットボットをリリースしました。 by 深澤さん
	- https://www.city.yokosuka.kanagawa.jp/0835/nagekomi/20240520_soudanbot_nyanpei.html
	- あえて未完成のボットを公開して、広く不具合をあつめる実験です！！
	- さすがのでき前！
- 円の実力と日本企業の通貨戦略（配付資料・動画配信
	- https://www.youtube.com/watch?v=reLhpQg9muo
- 「kagglehub を使った大規模言語モデル gemma のファインチューニングとモデル共有」
	- https://www.kaggle.com/code/makimakiai/kagglehub-gemma
	- Kaggleのノートで銅メダルゲットした！嬉しい！
		- https://x.com/hAru_mAki_ch/status/1792105063022018835
- Deep Dive on Accumulated Local Effect Plots (ALEs) with Python
	- https://towardsdatascience.com/deep-dive-on-accumulated-local-effect-plots-ales-with-python-0fc9698ed0ee
	- ALEs give interpretations that are robust to multicollinearity.
- 英国政府が100億円超を投じる「Safeguarded AIプログラム」とは
	- https://www.aialign.net/blog/20240520-takatsuki
	- 本プログラムにおいてAIシステムの安全性の証明可能性の土台となる理論（特にTA1.1で扱われる内容）には、数理論理学や圏論といった分野が重要な位置を占めることが予定されており、これらの分野の研究者の協力が必要とされています
- Copilot + PC by Nadella
	- https://x.com/satyanadella/status/179261785138542602
	- Introducing Copilot+ PCs—the fastest, most AI-ready Windows PCs ever built.
		- Powered by new NPU (40+ trillion operations per second)
		- Rearchitected Windows 11 
		- 58% faster than Macbook Air M3 
		- Copilot shipping with Windows 
		- Copilot built into Settings, files, notifications 
		- Powered by GPT-4o
- LangChainにObsidianのローダーがある～。ObsidianのメモをベクトルストアしてRAGできてしまう～
	- https://www.youtube.com/watch?v=E-CNrXhSvLg
- The Illustrated Stable Diffusion	
	- https://jalammar.github.io/illustrated-stable-diffusion/
- Google has released Gemini 1.5 Flash.
	- https://x.com/dr_cintas/status/1792572374300188752
	- An AI model optimized for speed and efficiency, with multimodal reasoning and an impressive 1M context window!
-  AWS、一般提供開始した生成AIサービス「Amazon Q」、および「Bedrock」と今後の戦略を説明
	- https://internet.watch.impress.co.jp/docs/news/1592518.html?ref=smartnews
- The theory of mind—the ability to track a person's mental state—is tested comparing humans vs GPT-4 and LLaMA2 large language models
	- https://www.nature.com/articles/s41562-024-01882-z
- GeminiがYouTube動画を一瞬で要約してくれるようになった（しかも無料
	- https://www.lifehacker.jp/article/2405-use-gemini-summarize-youtube-videos-free/
	- 本当だ！
- 観察スケール則は、LLMの標準的ベンチマークの性能から求められた主成分（3つ程度）を用いて複雑な後続タスクの性能を高精度で予測できる法則　by 岡野原さん
	- https://arxiv.org/abs/2405.10938
- BREAKING: Council of Europe adopts 1st international treaty on AI. Here's what you need to know:
	- https://x.com/LuizaJarovsky/status/1792224914646200512
-  Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings
	- https://arxiv.org/abs/2405.10938
- 論文メモ: Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models b y はちさん
	- https://note.com/hatti8/n/nb61b4935c793?sub_rt=share_pb
	- Googleが先週出したLLMの自己改善手法であるReSTEMについて、メモを書きました。
	- 合成データ生成手法としてどうかという視点で書いています
- p値姫（サンプル数編）
	- https://x.com/spine_surgeon_/status/1792767885615759746
	- 「マリオへ、実験結果いい感じです！いい感じなんですけど、有意差でるまでサンプル数増やしてみてください。有意差出るまで連絡は不要です。ピーチより。」
- People cannot distinguish GPT-4 from a human in a Turing test
	- https://arxiv.org/abs/2405.08007
	- AIの人間らしさを測るテストで世界一有名なチューリングテストですが，さんざん「もうAIはチューリングテスト突破できるやろ」と言われてたのを真面目に分析した論文が出ました
	- 結論は「現在のGPT-4などの最先端AIは，チューリングテストを突破可能であり，人間はもはや人とAIを会話のみから判定することはできない」というものです．GPT-4は54%の確率で人間だと判断された模様
- 最近ローカルLLMがアツいらしい
	- https://soysoftware.sakura.ne.jp/archives/3903
	- GPTのAPI高い問題 ＆ OpenAIがAIベンチャー皆殺しにしてしまう問題
	- ローカルLLM推論ライブラリが色々ある
		- Llma.cpp, ollama, vLLM
	- 強力な大型オープンなAIモデルが公開されはじめてる
		- Command R+（非商用利用）やLlama3-70B、DeepSeek-V2
	-  小型のAIモデルの性能向上の潮流
		- Mistral-7Bベース、ChatVector、
	-  個人でもAI開発競争に食い込める可能性について
- 生成AI時代に大事なスキルは、「やり続ける能力　by 深津さん
	- https://x.com/fladdict/status/1792831115528663471
	- 生成AI時代には「もうあいつ（AI）一人でいいんじゃないかな」と、色々なことで挫折する人が大量発生する。「手をとめない」能力が、人類にとって最重要の才能になるかもしれない
- transformers v4.41.0
	- https://github.com/huggingface/transformers/releases/tag/v4.41.0
	- Phi3, JetMoE, PaliGemma, VideoLlava, Falcon2, FalconVLM & GGUF support
		- https://huggingface.co/docs/transformers/v4.41.0/en/gguf
- Phi 3 - Small, Medium & Vision
	- https://x.com/reach_vb/status/1792949163249791383
	- This includes the 7B and 14B models
	- This also includes a multimodal phi model
- Knowledge Cards by Perplexty	
	- https://x.com/perplexity_ai/status/1792948540542517458
	- We’re teaming up with @TakoViz to bring advanced knowledge search and visualization to our users. Now, you can search, juxtapose, and share authoritative knowledge cards in Perplexity.
	- Perplexityが高度な情報検索と視覚化ができる「knowledge cards」という機能をリリース。
	- 自由に任意の2社の株価推移の比較が可能。リサーチ業務が捗り、仕事で活躍間違い無し。
- GraphRAG: Using Knowledge in Unstructured Data to Build Apps with LLMs
	- https://www.graphlit.com/blog/graphrag-using-knowledge-in-unstructured-data-to-build-apps-with-llms
	- We have used Graphlit to automatically extract images from PDFs, and are using the OpenAI GPT-4 Vision model to perform OCR and generate detailed text descriptions of the images.
	- どうも、知識グラフの画像から知見を得るらしい。
- I built my own omni assistant using Gemini 1.5 Flash to guide me through Super Mario 64.
	- https://x.com/skirano/status/1792948429754151293
	- MicrosoftがBuildででもした、assistantを、gemini 1.5 Flashで実装したツワモノ、お題はマリオだし。
- What is the context window?
	- https://x.com/cwolferesearch/status/1792950349696753980
		- Claude-3 has a 1M context window 
		- Gemini-1.5 Pro has a 2M token context window 
		- Recent research [3] has explored going even beyond 2M tokens.
- ICity, a Geometry Nodes-powered procedural city generator for Blender.
	- https://x.com/80Level/status/1792769380717068510
	- Available now in Beta
		- https://80.lv/articles/long-awaited-procedural-city-generator-for-blender-is-now-available/
- Microsoft、Copilot 進化的の新機能を発表
	- https://x.com/shota7180/status/1792966382990270739
	- Copilot 進化的の更新により、誰でもエージェント機能を持つコパイロットを構築可能に
	- このコパイロットは、ユーザーの代わりに独立して積極的にタスクを調整・実行
	- 特定の役割や機能に合わせてタスクを個別に調整できる
- MIcrosoft's Phi-3 really is an astonishingly good model
	- https://x.com/simonw/status/1792691120675467288
	- MIT licensed and small enough to run in a browser on WebGPU (about a 2.3GB downloads), but still provides high quality results for a lot of the stuff I care about
	- Phi-3-mini running locally in your browser at 70 tokens per second on WebGPU!
	- Powered by 🤗 Transformers.js and ONNX Runtime Web! 
	- https://huggingface.co/blog/Emma-N/enjoy-the-power-of-phi-3-with-onnx-runtime
- Hugging Face and Microsoft Deepen Collaboration
	- https://huggingface.co/blog/microsoft-collaboration
- Tako, the first AI search engine for visualizing and sharing the world’s knowledge.
	- https://x.com/TakoViz/status/1792949400710574455
	-  Introducing Tako, a new way to reference real knowledge And our first integration, Perplexity
		- https://trytako.com/blog/introducing-tako-and-perplexity-integration
- Team Copilot by Microsoft 
	- https://x.com/msdev/status/1792967099519758822
- 13B phi-medium-4k GGUF files here, model is looking very very good.
	- https://huggingface.co/nisten/phi3-medium-4k-gguf
- 本日（5/20）、EUのデジタルアイデンティティ法が施行
	- https://x.com/_nat/status/1792915589570154637
- マイクロソフト、自律型AIソフトウェアエンジニア「Devin」のCognition AIと提携を発表。Azure上でDevinを提供へ
	- https://www.publickey1.jp/blog/24/aidevincognition_aiazuredevin.html
-  Mapping the Mind of a Large Language Model
	- https://www.anthropic.com/research/mapping-mind-language-model
	- Anthropic has just revealed some exciting news about Claude Sonnet. They've successfully identified how millions of concepts are represented inside this massive model!
- ollama run phi3:medium
	- https://x.com/ollama/status/1793067457382343134
- Phi-3-vision ・ Phi-3-medium ・ Phi-3-small の概要 by npakaさん
	- https://note.com/npaka/n/nb050244392a4?sub_rt=share_h
	- 「Phi-3」は、最も有能で費用対効果のSML (Small Language Model) であり、さまざまな言語、推論、コーディング、数学のベンチマークで同じサイズと次のサイズのモデルを上回っています
	- 「Phi-3-vision」は、チャートや図から洞察を生み出すことができます。
	- 「Phi-3-small」「Phi-3-medium」は、同じサイズの言語モデルだけでなく、はるかに大きい言語モデルよりも優れたパフォーマンスを発揮します
	- SLMは、より単純なタスクでうまく機能するように設計されており、リソースが限られている組織にとってよりアクセスしやすく、使いやすく、特定のニーズに合わせてより簡単にファインチューニングできます
-  GPT-4oをわかりやすく解説、専門家が「時代の転換点」と評価するヤバすぎる能力とは by 今井さん
	- https://www.sbbit.jp/article/cont1/140613
	- OpenAIのGPT-4oを研究者視点で解説した記事が出ました! 速報的な記事の依頼でしたが,やはり研究者が書くということで情報をすべて詰め込んだ1万文近いガチ解説記事になりました.3回の連載です.
	- 言語,音声,動画像,後半ではGPT-4oの「弱み」等,日本語記事では一番詳しいはず
- MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning
	- https://arxiv.org/abs/2405.12130
	- LoRAより知識獲得系タスクに強いMoRA　 by shi3zさん
- ルカン先生、学生に次世代AIを作ろうとするなれば、LLMをやるのではないよとアドバイス
	- https://x.com/ylecun/status/1793326904692428907
	- If you are a student interested in building the next generation of AI systems, don't work on LLMs
- Mistral v3 base and instruct released
	- https://huggingface.co/mistralai
	- Base has vocab extended to 32768. 
	- Instruct supports function calling! 
	- Tokens 5 to 9 are for function calling & the rest are empty
- Interface 7月号では，Copilotで文芸的プログラミングに挑戦します．
	- https://x.com/If_CQ/status/1793214032121614787
	- ドキュメントとソースコードを同時に開発保守するのがDonald. E. Knuth博士の「文芸的プログラミング」．CopilotとDoxygenを使えば，記述が自動化でき，両者の不一致を防げます．ソフトウェア開発の理想を最新の技術で実現します．
- New guide in our AI cookbook: 𝙎𝙩𝙧𝙪𝙘𝙩𝙪𝙧𝙚𝙙 𝙜𝙚𝙣𝙚𝙧𝙖𝙩𝙞𝙤𝙣
	- https://huggingface.co/learn/cookbook/structured_generation
	- This technique lets you force your LLM to generate its output as a JSON with specific keys: great for RAG or LLM-judge!
- Large Language Models Meet NLP: A Survey
	- https://arxiv.org/abs/2405.12819
	- Provides a comprehensive survey of how LLMs are applied to NLP tasks, introducing a new taxonomy and discussing current progress, future frontiers, and challenges.
- Mistral AI's Mistral v0.3 supports function calling with Ollama's raw mode!
	- https://x.com/ollama/status/1793392887612260370
	- Ollama raw mode
		- https://github.com/ollama/ollama/blob/main/docs/api.md#request-raw-mode
- Mistral-7BとPhi-3もこの際ElyzaTasks100で評価してみた。by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793550842353820014
	- まずMistral-7Bはv0.1が2.46、v0.2が2.69（やたら英語で回答してくるので半分以上英語の回答は手作業で1点に減らした）、からの今回のv0.3は3.52！見違えるくらい日本語能力が強化されてます。英語で答えちゃう問題もほぼ起きない。
	- Phi3は3.8Bのmini-128kがまさかの3.26というこのパラ数にしては高すぎるスコアでなぜかsmall-128kに勝ってしまってます。
	- small-8kは3.28で、miniと大差ないという意味では残念。同パラのMistral-7B-v0.3にも負けてる。
	- でもmedium-128kは14Bパラで3.96というバケモンみたいなスコアが出てます。これはすごすぎ
- GPT-4oとGPT-4TurboのElyzaTasks100の平均スコア、
	- https://x.com/umiyuki_ai/status/1793540614551904762
	- 気になってたのでAPI代払って評価してみた。
	- GPT-4Turboが4.44、GPT-4oが4.51！やっぱりエゲつない超スコア！
	- オープンなモデルがGPT-4Tに追い付いてきたなんてちょっと言えなくなった
- Phi-3-MediumのMMLUスコアはLlama3-70B並み… by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793614730403434950
	- やっぱり伊達じゃないらしいね。ElyzaTasks100でも匹敵してるもん。しかし信じがたいね 
- Aya 23 is here! Available in 8B and 35B.
	- https://ollama.com/library/aya
- LangChain `with_structured_output` メソッドによる構造化データ抽出
	- https://zenn.dev/ml_bear/articles/cb07549ec52175
	- 1.  構造化データをPydanticで定義する
	- 2.  その定義を`.with_structured_output`でLLMに取り付ける
	- Pydanticでスキーマを定義した上で構造化データ抽出するのは非常に簡単です
- 「AIスタートアップは街の電気屋さんから始めろ」
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/9kai/shiryo1-4.pdf
	- AI戦略会議の松尾研の資料「生成AIの産業における可能性」
	- まずは受託開発で社会を学ぶ。 受託開発で地域の企業のDXを支援しつつ、一緒にグローバルに出ていく
- 世界初、AI技術による原油処理装置の自動運転を開始　PFN
	- https://www.preferred.jp/ja/news/pr20240524/
- 機械学習による反応予測の論文
	- https://chemrxiv.org/engage/chemrxiv/article-details/664de6a821291e5d1df74ac0
	- SMILESにより化学反応をテキストで表現したSMIRKSを用いることで、化学反応のルールを高精度に学習できたそうです。寄与する原子数が多い複雑な反応は今後の課題とのこと
- LLMはチャットUIの誕生でブレイクスルーを起こしたが、今はチャットUIに呪われている
	- https://x.com/rkmt/status/1794013338005090666
	- 「有効な質問をLLMに投げ回答を得るサービス」は一定量（それを使いこなせる人類の数<<人類の総数）で頭打ちになり、それ以上は「意味もない内容もないけど楽しい会話をAIと続ける」サービスか、「人間を必要としないAI業務」に移行するのかも。
- ぱぷりか炒め（mmnga）さんの、Llama-3-70B-japanese-suzume-vector-v0.1 すごい、 by AIサトシ
	- https://x.com/AiXsatoshi/status/1793973265532424467
	- 8bのLlama派生モデルのchatvectorを、パラメータ数違う70Bにマージしてて、さらにベンチマーク結果も良好なのすごい
- Cohereが多言語指向のオープンLLM「Aya」（8B，23B）を公開
	- https://huggingface.co/spaces/CohereForAI/aya-23
	- 4月には当時のオープンLLM最高性能のCommand R+を出してたCohereの多言語LLMなので,日本語も期待できそう...実際に日本語は結構うまいんですが,色々と簡潔すぎて自分の中での評価が「冷たいモデル」です
-  DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
	- https://huggingface.co/papers/2405.14333
	- Proof assistants like Lean have revolutionized mathematical proof verification, ensuring high accuracy and reliability. Although large language models (LLMs) show promise in
- ollamaでPhi3-mediumは「性能ショボい」？　by うみゆきさん
	- https://x.com/umiyuki_ai/status/1793878129699950887
	- OllamaでPhi3-mediumをプルするとQ4_0量子化版がDLされるようだが、スコアは3.68。Q4_K_Sでも3.67。ちなみに僕が最初に検証したLlama. cppのQ8は3.88だったし、同じくLlama. cppのQ4_K_Sも3.95で劣化どころかスコア上がってる。というわけでollamaのPhi3-mediumはパラ設定かなんか分からんけど何らかの問題で劣化してます
- DeepSeekV2 is a big deal.
	- https://x.com/Xianbao_QIAN/status/1794034052347171055
	- Not only because its significant improvements to both key components of Transformer: the Attention layer and FFN layer. 
	- It has also completed disrupted the Chines LLM market and forcing the competitors to drop the price to 1% of the original price.
- Difyを使うメリットの一つが開発したChatbotやワークフローを簡単にWEBでシェアできること
	- https://x.com/gijigae/status/1793437095727665588
-  Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet
	- https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
	- Anthropicの中規模生産モデルであるClaude 3 Sonnetにスケールアップされたスパースオートエンコーダーを適用し、解釈可能な特徴を抽出する研究
	-  **スパースオートエンコーダー**: 小規模トランスフォーマーから単義的特徴を回復する方法を示した研究から発展し、大規模モデルへのスケーリングが重視されています。
	- **解釈可能な特徴**: 抽出された特徴は多言語、多モーダルであり、具体的および抽象的な参照の間で一般化されています。
	- **安全性関連特徴**: セキュリティの脆弱性やバックドア、偏見、嘘や欺瞞、危険または犯罪的な内容など、AIシステムが引き起こす可能性のある様々な問題に関連する特徴が観察されています。
	- **スケーリング法則**: スパースオートエンコーダーの訓練にスケーリング法則を適用し、計算予算に基づいて最適な特徴数と訓練ステップ数を決定しています。
- ハル・ベリーニューロンがAIで実体験できる時代が到来
	- https://x.com/webbigdata/status/1794030396990226803
	- ハル・ベリーさんという、X-MENのストームとかキャットウーマン役をやってるアメリカの女優さんがいるのですが、ある患者さんの特定のニューロンが「ハル・ベリーの写真」や「ハル・ベリー」というテキストに対して活性化する事が観察されたという研究がある。
	- 5月21日にanthropicがClaude 3 Sonnetで何百万もの概念がどのように表現されているかを特定できたよ～と発表し、
	- その技術を使って、サンフランシスコのゴールデン ゲート ブリッジ(Golden Gate Bridge)に対応するニューロンを活性化させてている「Golden Gate Claude」と実験的に対話できるようにしたよ～と発表したのが昨日ですね。
	- 一言で言えば、やたらめったらゴールデン ゲート ブリッジ推しをしてくるAIで、色々なタイミングでゴールデン ゲート ブリッジを推薦してきます。
- streamlitでデプロイするイメージです。 GitHubと接続すれば、本当に爆速で
	- https://x.com/kenken26679105/status/1793889080385925580
- ChatVectorで7BモデルのFineTuning結果を70Bに転移させるみたいな話、by はちさん
	- https://x.com/CurveWeb/status/1794203714422759707
	- 事前学習では既に小さいモデルで事前学習→セルフマージで大モデル化っていうのができているのでなんとなくできて然るべき感ある。

## 5/20

今回は、GPT-4oさんに、まとめをお願いしました（無修正です！！）。ここまで来たか、と驚くようなさみしいような。。大切なことは、もう一度言います、無修正です。では、

最新の大規模言語モデル（LLM）の動向について、今回はちょっとユーモアも交えつつお届けします。まずは、絶対に見逃せない二つの大ニュースから。 最初に、大きく注目を浴びているのがOpenAIの新モデル「GPT-4o」です。どうやらこのモデル、名前だけじゃなくて性能もまさに「おお！」と言いたくなる程の進化を遂げています。他のモデルと比べて速度は2倍、コストは半分、レートリミットが5倍と、まさにスーパーAI。さらに無料プランのChatGPTユーザーでも使えるようになるとのことで、サム・アルトマンさんから直接のお知らせも飛び出しました。しかも、このGPT-4oは数学の難関問題を画像で出題しただけで解けるという、まるで魔法のような能力を持っているのです。この進化により、動画の要約や化学実験の考察まで、ヘビーユーザーの活用法がどんどん増えているのが現状です。 次はGoogle I/Oでの発表です。トップバッターは新しいビジョン・ランゲージモデル「PaliGemma」と「Gemma 2」。その大きな見どころは、Gemma 27Bというサイズでも新しいアーキテクチャを駆使して、モデルが2倍のサイズのものにも勝る性能を発揮すること。これ、まるでヒーロー映画の続編が発表されるかのようなワクワク感がありますよね。そしてさらに「Trillium」という次世代Google Cloud TPUの登場で、このスーパーAIヒーローたちがさらに効率良く動作することが期待されています。ああ、今夜のビリー・アイリッシュのライブにでも登場しそうな勢いです。 さて、話題を変えて、最近の秀作をご紹介します。DeepLearningAIから無料コースが続々登場しており、MistralAIを使ったコースを提供中です。このコースでは、Mistralのモデルに加えて、RAG、関数呼び出し、そしてJSONモードなどまで学ぶことができます。これを受けて、プロンプト設計での尤度関数の捉え方について議論が巻き起こっています。「それってプロンプトダンサーの必須スキル？」と思わせるような専門的な話題も含まれています。 一方、HuggingFaceのトークン化とllama.cppのトークン化に違いがあることが議論されています。これはまるで、映画の字幕と吹き替えの違いくらい注目されているトピックです。特にLlama3やGemmaモデルに関して、量子化に問題がある可能性も浮上しています。んん、やっぱりテクノロジーの進化も一筋縄ではいきませんね。 そしてお待ちかね、npakaさんの情報を一気にまとめてチェック。彼はOpenAIのModel Specについての概要を詳述しています。また、新しいLangChain v0.2を使ったエージェント構築や、RAG、特定の情報源に関するQAシステム、情報抽出、要約などのユースケースも紹介しています。「LangChainハッカー」なんて称号が彼に似合いそうですね。 ここまで大まかなトピックをご紹介しましたが、その他の小ネタも盛りだくさんです。例えば、Mozillaのやる気満々なローカルリサーチツール「llamafile」や、LangChainとHuggingFaceの強力な提携など、どんどん新しい機能が登場していますよ。この分野の進展の速さを見逃さないでくださいね。 現場はまるで、ピーターパンのネバーランドのように変化に満ちています。今後も続々と驚きと笑顔が待っているかもしれません。さあ、次はどんな冒険が待っているのか、楽しみですね！

- またまたDeepLearningAIより、MistralAIを用いた無料コース
	- https://www.deeplearning.ai/short-courses/getting-started-with-mistral/
	- Mistral AIによる1時間のコース。Mistralのモデルだけでなく、RAG、関数呼び出し、JSONモードなどについて学べる
- b氏が、「ローカルLLMはこーやって使うの」にかみつく、
	- https://x.com/behemuhemulove/status/1789537738590765215
	- 「尤度関数の所が俺には意味が良くわからなかった。プロンプトをパラメータといってるのに、プロンプトを固定したらパラメタの関数にならないから尤度関数じゃなくない？」
	- →プロンプト振ってるので尤度による最適なプロンプトの推定といってもいいのではないか？
- 主要モデルでHuggingFaceのトークン化とllama.cppのトークン化に差異があったとの事
	- https://x.com/webbigdata/status/1789695414238884256
	- llama3の量子化が腐ってるのはこのせい？
	- 1. Mistral: HF's batch_decode output is wrong 
	- 2. Llama-3: Be careful of double BOS 
	- 3. Gemma: 2nd token has an extra space - GGUF(_Below) = 30641 vs HF(Below) = 33501 
	- 4. Gemma-it: Also be careful of double BOS
- OpenAI の Model Spec の概要 by npakaさん
	- https://note.com/npaka/n/nf6b811cad5dc?sub_rt=share_b
	- モデルの動作を形成するアプローチの透明性を高め、モデルをどのように変更および改善できるかについて公開の会話を開始するために、「Model Spec」を公開します。
- [code-cooker](https://github.com/karaage0703/code-cooker) by からあげさん
	- https://github.com/karaage0703/code-cooke
	- 面倒なことをChatGPT以外のLLMにやらせるソフト。GUIをつけてみました。 ようやく自分でも使いたくなるものができた気がします。まだClaude 3 Opusしか対応してないので、GPT-4とかLlama 3にも対応していきます。GPT対応はOpenAIの発表の後にしようかな
- 大規模パラメータモデルの人たちは、このOpenAIの論文に書いてあること思い出してねだそうで
	- https://x.com/cloneofsimo/status/1789700168083997010
	- Again, the paper im advocating here is from openai, and is referenced all the time and frankly one of the paper all large scale practitioner should read. the math here isn't complicated and nothing here is either controversial nor task dependent.
	- https://arxiv.org/abs/1812.06162
-  技術革新と不平等の1000年史の紹介 by 楠さん
	- https://x.com/masanork/status/1789647931467026613
	- これ特に下巻の読み応えがすごいんですが、技術が約束する未来と社会構造に与える影響とは、分けて議論しなければならないのでは？という課題認識が強く。LLM周辺ではオープンって用語が曖昧に使われたり、生産手段が民主化されていないのが悩みどころ
- ollamaで Fugaku-LLM を動かす
	- https://note.com/npaka/n/n1d99253ae2cf?sub_rt=share_h
	- 一番サイズの小さい（おそらく量子化が一番効いている） 「Fugaku-LLM-13B-instruct-0325b-q5_k_m.gguf」を選びます
	- **`Modelfile`  で一番重要なのは、トークナイザの chat template を守ることです**
	- docker　２発で、ollamaと、web-uiが動くのかー
- 【GPT-4o 爆誕】
	- https://x.com/MLBear2/status/1790069525372981452
	- 従来のGPT-4, Claude 3 Opusなどに比べて頭一つ抜けて賢い（図）
	- gpt2としてChatbot ArenaでテストされていたものがGPT-4oだったとサムアルトマンCEOが認めた。
	- GPT-4 Turboと比べて ・2倍速く ・50%安価 ・Rate limitが5倍高い
- GPT-4oで使われている新しいtokenizer、tiktokenにもう入ってる
	- https://x.com/gyakuse/status/1790110045814010327
	- tiktokenを0.7.0 にアップデートし、enc = tiktoken.encoding_for_model("gpt-4o")とするだけ
- gpt-4oで試しに今年の東大数学2024の問題を画像で送ったら（プロンプト一切無しでも）正解できた
	- https://x.com/kyutaro15/status/1790098489940258830
- サムからのGPT-4oに関するメッセージ
	- https://x.com/sama/status/1790065541262032904
	- it is available to all ChatGPT users, including on the free plan! so far, GPT-4 class models have only been available to people who pay a monthly subscription. this is important to our mission; we want to put great AI tools in the hands of everyone.
- GPT-4oの動画要約をHuggingface Spaceで試せるようにしました by 逆瀬川さん
	- https://x.com/gyakuse/status/1790090822031126730
	- リリースされたGPT-4oを使って動画のサマリー生成をしてみる！
		- https://qiita.com/sakasegawa/items/b82a9745fda81143e409
- GPT-4oに化学実験の結果を考察させてるんですが、 考察が早すぎて、スクロールが追いつかないです　 by 畠山さん
	- https://x.com/kanhatakeyama/status/1790098210360537138
- （OpenAIの新しいtokenizerは）日本語はトークナイザーが改善されてるから、API使用料50% x トークン量70% で 35% ぐらいの費用になるのか？
	- https://x.com/MLBear2/status/1790081289367990668
- LangChainがgpt-4oに対応
	- https://x.com/LangChainAI/status/1790089006455398583
	- You can use the available multimodal capabilities of it in any of your LangChain applications today!
	- https://python.langchain.com/v0.1/docs/integrations/chat/openai/
- TJOさん、デジ庁、データサイエンティスト公募の要件をみて頭を抱える
	- https://x.com/TJO_datasci/status/1790046279428345990
	- 「このスキルの必須要件を全部満たして尚且つ歓迎項目も複数満たすデータサイエンティストなんて、そもそも日本どころか世界を見渡しても探し出すのは困難を極めるのでは。それを公務員の給与で雇うとか無理ゲーにも程があるような気がする」
	- 結局お金の問題か
- GPT-4oはPlaygroundで試せる。 確かに賢いしものすごく速い by shi3zさん
	- https://x.com/shi3z/status/1790073756079059400
- Command-R-Plus, Llama-3, Phi-3 miniを ELYZA-tasks-100 で評価
	- https://qiita.com/wayama_ryousuke/items/a96f11fe2b7e2e3910e5
	- 「今回ご紹介したモデルは、日本語に特化した追加学習を行わなくても、日本語で回答を返すことができるという点が大きな特徴です。」
	- 評価用 Colab ノートブックもあるよ
- Embeddingモデルを使ったベクトル化のしくみ、fine-tuning手法を解説
	- https://speakerdeck.com/payanotty/embeddingmoderuwoshi-tutabekutoruhua-nosikumi-fine-tuningshou-fa-wojie-shuo
-  State-Free Inference of State-Space Models: The Transfer Function Approach
	- https://arxiv.org/abs/2405.06147v1
	- Utilizing the connections between convolutions in the time domain and multiplication in frequency domain (through FFT),
-  GPT-4o の概要 by npakaさん
	- https://note.com/npaka/n/n02331040d8c2?sub_rt=share_b
- JSLM2（Japanese Stable LM 2 Instruct 1.6B）
	- JSLM2は、6B以下の規模のモデルの中で、日本語性能が最も高いと思います。違いますか？ (llm-jp-evalや定性評価で）
	- https://x.com/peacej/status/1789909011132805402
- gpt-4o で使われたo200k_base tokenizer の日本語の部分・・・完全に5ちゃんねる・・・
	- https://x.com/_aixile/status/1790278857641410662
- Andrew Ng先生によるAI エージェント設計パターンの連載
	- https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/
	-  Agentic Design Patterns Part 1
	- Reflection, ツールの使用, プランニング, 複数Agentの協力
- gpt-4o、論文要約してPowerPoint吐いてくれる
	- https://x.com/CurveWeb/status/1790336171777917332
- 大規模言語モデル (LLM)における低精度数値表現 by PFNの三上さん
	- https://speakerdeck.com/pfn/20240508-hpckenkyukai-pfn-llm
	- 学習：8bitが主流になりつつある
	- 推論：1～2bit表現が実用化されつつある
- Introducing Veo: our most capable generative video model　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790435824598716704
	- It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles
- llamafiles from mozilla
	- https://x.com/llama_index/status/1790449858899505616
	- Build a local, private research assistant running on your laptop in a snap with llamafile from Mozilla! 
	- llamafiles are fun: no need to install anything, just download the file and run it, and you get a local LLM and embedding model that you can use directly from LlamaIndex. 
	- https://github.com/Mozilla-Ocho/llamafile
- langchain-huggingface のアナウンス
	- https://x.com/LangChainAI/status/1790419422399877158
	- We're excited to announce the launch of langchain-huggingface, a partner package in LangChain jointly maintained with huggingface
- Entropy minimization がなんで有効か？ ICML
	- https://x.com/ori_press/status/1790383780642918469
	- https://arxiv.org/pdf/2405.05012
- Evaluation of Retrieval-Augmented Generation: A Survey
	- https://arxiv.org/abs/2405.07437
	- https://github.com/YHPeter/Awesome-RAG-Evaluation
- Pattern Language is one of my favorite books, and this abridged hypertext version by zenodotus280
	- https://x.com/kepano/status/1790437820487946630
	- This project is an abridged, hyper-textual, and copyleft manifestation of the 1977 architecture classic _A Pattern Language_ by Christopher Alexander
		- https://github.com/zenodotus280/apl-md
- GPT-4oの登場により、検討中の研究プロポーザルがお釈迦になるというポストたち
	- 「音声言語モデル」について学振書いている間にこれはひどすぎるでしょ
		- https://x.com/nonmetal_/status/1790079046191120560
	- GPT-4o makes me feel both sad for my current work has been scooped by OpenAI, and happy that we are on the right track. by SpeechGPTシリーズの開発者
		- https://x.com/dongzha35524835/status/1790241799547806071
- multi-step reasoning capabilities to Google Search at Google I/O
	- https://x.com/Google/status/1790438800667123860
	- perplexityのようなものがくるのか、
- Linear Regression is one of the most important tools in a Data Scientist's
	- https://x.com/mdancho84/status/1790445342787318206
	- 1. OLS regression aims to find the best-fitting linear equation that describes the relationship between the dependent variable (often denoted as Y) and independent variables (denoted as X1, X2, ..., Xn).
	- 2. OLS does this by minimizing the sum of the squares of the differences between the observed dependent variable values and those predicted by the linear model. These differences are called "residuals."
	- 3. "Best fit" in the context of OLS means that the sum of the squares of the residuals is as small as possible. Mathematically, it's about finding the values of β0, β1, ..., βn that minimize this sum.
- We’re sharing Project Astra: at Google I/O
	- https://x.com/GoogleDeepMind/status/1790433540548558853
	- We’re sharing Project Astra: our new project focused on building a future AI assistant that can be truly helpful in everyday life.
- PaliGemma、Gemma 2　at Google I/O
	- https://x.com/GoogleDeepMind/status/1790459505538658636
	- PaliGemma: a powerful open vision-language model  
	- Gemma 2: coming soon in various sizes, including 27 billion parameters
- GPT-4o shows improvement compared to GPT-4-Turbo-0409 with better probability, pre-calculus, algebra, and geometry abilities. 
	- https://x.com/GanjinZero/status/1790230562453803241
- Get a sneak peek of Gemma 2, at Google I/O
	- https://x.com/Google/status/1790452314278412554
	- 27B parameter instance launching in a few weeks. Built on new architecture, Gemma 27B outperforms models twice its size and can run on a single TPU host in Vertex AI.
- PaliGemma をお試し中
	- https://huggingface.co/spaces/big-vision/paligemma
- Introducing Trillium, the next generation of Google Cloud TPU
	- https://x.com/GoogleCloudTech/status/1790452622295449925
	- It delivers 4.7X the peak compute performance per chip compared to TPU v5e and is equipped with 2X the high-bandwidth memory capacity.
- ZeTT
	- https://x.com/CurveWeb/status/1790308270126883146
	- 「追加のトレーニングをほとんど(もしくは全く)行わずに、任意のモデルを任意のトークナイザーで使用できるようにする手法ZeTT。 ChatVector やモデルマージのTokenizerによる制限を避けるのに使えそう」 by はちさん
- Gemini 1.5 Pro to 2 million tokens at Google I/O
	- https://x.com/Google/status/1790430189916225799
	- Today we’re expanding the context window for Gemini 1.5 Pro to 2 million tokens and making it available for developers in private preview. It’s the next step towards the ultimate goal of infinite context
- Data Scientists: The next level of Data Science AI Agents is called "Plan and Execute".
	- https://x.com/mdancho84/status/1790406221616320862
- GoogleとOpenAIの発表を見てる僕の心境 by GUILDの深澤さん
	- https://x.com/fladdict/status/1790431879512093151
	- 「あ、ゴクウとフリーザが上空で戦ってる！！！すごい速度で見えない！！！頑張れ！！！」というクリリンの心境
- Ilya and OpenAI are going to part ways. by Sam
	- https://x.com/sama/status/1790518031640347056
	- This is very sad to me; Ilya is easily one of the greatest minds of our generation, a guiding light of our field, and a dear friend. His brilliance and vision are well known; his warmth and compassion are less well known but no less
- HCI系のトップカンファレンスCHI2024の全論文をGPT-4で要約スライドにまとめて見たので
	- https://drive.google.com/file/d/1CMkTdGlk1OhtScKUTB7Mt22GtWxgAIPV/view
- Colab 📒 Notebook to fine-tune 💅🏽 @GoogleAI
	- #PaliGemma vision-language model 👓🔠🧠on a free T4 VM
	- https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb
- Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models
	- https://note.com/panda_lab/n/n948053d7813f
	- RAGの枠組みを拡張し、Wikipedia自動生成に特化したフレームワーク「STORM」を考案しました。
	-  **課題**: ウィキペディアスタイルの記事は、広範囲の参考文献の収集と、詳細なアウトラインの作成が必要です。従来の方法では、この準備段階がしばしば省略されます。
	-  **解決策**: STORMは、予備的な書き込み、草稿作成、改訂の各段階、特に予備段階での効果的な質問提起により、このプロセスを自動化します。
- 「Stockmark-100b」
	- https://x.com/kosukearima/status/1790902109648695565
	- 産総研ｘストックマーク共同研究の成果、フルスクラッチで学習した100B級日本語LLMを公開しました
	- ストックマークは、1000億パラメータの日本語LLMモデル「Stockmark-100b」を公開しました。 既存のモデルにデータ追加を行いチューニングしたものではなく、ゼロからフルスクラッチで開発したモデルであり、国内では(現状はダントツで)最大、グローバルでも最大級サイズのOSSモデルとなります。
		- https://huggingface.co/stockmark/stockmark-100b
- 「確率思考の戦略論」がもやもやする方へ -NBDモデル編-
	- https://zenn.dev/joanofarc/articles/strange-theory-of-probability-thinking
- LLM に表データを読み解かせたかったので、ちょっと試してみた
	- https://developers.cyberagent.co.jp/blog/archives/47869/
	- In-context Learning をベースとして手法に採用している「表形式データの読み解き」に関する論文(ICML2024)を、個人的ピックアップで紹介してみました。
	- https://openreview.net/forum?id=4L0xnS4GQM
- 負の二項分布の疫学とマーケティングでの応用の比較
	- https://socinuit.hatenablog.com/entry/2024/05/16/185601
	- 西浦『感染症を読み解く数理』と森岡・今西『確率思考の戦略論』において、負の二項分布を用いたモデル応用について記述されており、 相互を参照・比較することで類似点や解釈の拡大を試みる。
	- この記事で述べたいことは、**疫学とマーケティングという一見して距離のある領域で、負の二項分布を用いた現象の確率モデル化の事例が取り上げられていて面白いね**、ということに尽き
- 最近Gemini 1.5 ProのPDFパースが便利だと気づいて色々試している
	- https://x.com/resnant/status/1791104886563811520
	- 今のところ先行研究の論文PDFを放り込んで「この研究のXXという点を解決/拡張するとどんな価値が生まれる？その結果をどう訴求する？」みたいに研究ネタの壁打ちで使うと心強い
-  2023年度 デジタル庁・行政における生成AIの適切な利活用に向けた技術検証を実施しました
	- https://www.digital.go.jp/news/19c125e9-35c5-48ba-a63f-f817bce95715
	- 「実証の最中にも環境が激変する中で、ただ試して終わらせるのではなく、しっかりと知見を共有し、データ整備はじめ次の動きに繋げていくことが重要と考えています」 by 楠さん
	- https://x.com/masanork/status/1790871089121513629
- ChatGPTがGoogle DriveやMicrosoft OneDriveからSpreadsheetやExcelを読み込んで分析・可視化を手伝ってくれる機能を近く公開
	- https://x.com/MLBear2/status/1791251518110523764
-  HCI研究に対する私見 - CHI2024参加を終えて　by 稲見先生
	- https://note.com/drinami/n/nfd4921806ad3?sub_rt=share_pb
	- 「HCI研究おもちゃ論」がかつて議論されていたことがありましたが「おもちゃに詰まった知恵と役割をバカにするな。比喩として不適切」というのが私の見解です
- 「競争力ある生成AI基盤モデルの開発（助成）」に、ELYZAが採択
	- https://x.com/ELYZA_inc/status/1791348009764360577
	- 経済産業省が立ち上げた「GENIAC」のもと、NEDOが公募
	- Mixture of Expertsアプローチの採用や、日本特有のデータの学習、日本語の推論効率化などを実施予定
- "functional ontology"
	- https://x.com/Westoncb/status/1791152606309687768
	- As an alternative to LLM summarizing, I've been getting very interesting results doing something like:
	- https://symbolflux.com/ApolloLunarLandingTrajectoryReconstruction.txt
- QA over large embedded tables without hallucinations (Caltrain schedule edition
	- https://x.com/llama_index/status/1791505972407746671
	- With LlamaParse, we were able to spatially layout the text in a semantically coherent manner, so that our GPT-4o-powered QA pipeline could correctly answer questions
		- https://github.com/run-llama/llama_parse/blob/main/examples/caltrain/caltrain_text_mode.ipynb
- MediaPipe LLM Inference APIを使って、MediaPipe形式に変換するとGemma 2Bや とGemma 7B、Phi-2、Falcon-RW-1B、StableLM-3BなどをブラウザやAndroids、iphoneなどで動かす事ができるようになる
	- https://x.com/webbigdata/status/1791497099315752967
	- You can now run the 7B parameter version of Gemma, entirely locally in the browser, using MediaPipe LLM Inference API.
		- https://x.com/googledevs/status/1791174333995299216
- stockmarkさんが公開されているstockmark-100bのggufあります
	- https://huggingface.co/mmnga/stockmark-100b-gguf
- Gemini 1.5 Flashで、12分の音声ファイルを全て文字起こし。完璧。GPT-4oでもこれは無理
	- https://x.com/Taiyo_AiAA/status/1791460870947774826
-  EmerDiff: Emerging Pixel-level Semantic Knowledge in Diffusion Models
	- https://www.docswell.com/s/DeepLearning2023/K1JDN3-2024-05-16-142439#p9
	- 事前学習済みの拡散モデルを用いて，追加の学習を一切行わずにセグメンテーションを行うことができることを示した論文．拡散モデルは高精細に画像生成をできるが，その内部には画像細部のセマンティックな情報を持つことが示唆される．
-  LangChain v0.1 から v0.2 への移行手順 by npakaさん
	- https://note.com/npaka/n/n161a7e3882b3?sub_rt=share_h
	-  import変更の例
		- **langchain → langchain_community**
			- vectorstoresとか
		- **langchain-community → langchain_openai**
			- ChatOpenAIとか
		- **langchain-community → langchain-core**
			- document_loadersとか
		- **langchain → langchain-core**
			- Documentとか
		- **langchain → langchain-text-splitters**
			- text_splitterとか
- ADA-V2、GPT-4oだかを微調整してコーディング性能上げたモデル
	- https://x.com/umiyuki_ai/status/1791429524351258857
	- OpenAIがGPT-4TだかGPT-4oだかを微調整してコーディング性能上げたモデルにADA-V2なんてネーミング付けたのがマジだとしたらその理由は？AdaはGPT-3四天王の中で最弱のモデルだった。つまり、GPT-4がAda-V2ならBabaggi-V2やCurie-V2、そしてDavinci-V2はどうなってしまうのか…？という匂わせ
-  Finetuning Llama3 using Unsloth
	- https://github.com/neo4j-labs/text2cypher/tree/main/finetuning/unsloth-llama3#using-chat-prompt-template
	- https://huggingface.co/tomasonjo/text2cypher-demo-16bit
	-  I've finetuned Llama3-Instruct:8b to generate @neo4j Cypher statements based on the GPT-4o synthetic dataset I've generated at the start of the week.
-  LangChain のユースケース by npakaさん
	- https://note.com/npaka/n/n5956ef3a0a09?sub_rt=share_h
	- 「RAGのQA」は、RAG技術を使用して、特定の情報源に関する質問に回答するチャットボットを構築します
	- 「情報抽出」は、LLMでテキストから構造化データを抽出するユースケースです。次の3つのアプローチがあります。
		- **Tool Callingモード** : Tool Callingで指定されたスキーマに従って、構造化データを出力
		- **JSONモード** : プロンプトの一部としてスキーマを提供し、JSONデータを出力
		- **プロンプトベース** : 指示に従って生成されたテキストを既存のパーサーで解析し、構造化データを出力
	- 「チャットボット」は、長期的な対話を維持し、ユーザーの質問に関連情報を使用して回答する能力を持ちます
	- 「ツールエージェント」は、自然言語インターフェースを通じてAPIや関数、データベースなどのツールを操作するシステムを構築します。  
		- **チェーン** : ツール使用の事前定義されたシーケンスを作成
		- **エージェント** : ツールを繰り返し使用してタスクを自動的に実行
	- 「クエリ解析」は、ユーザーの質問を最適化して検索クエリを生成し、より正確な情報を取得することを目的としています。
		- 手法には、クエリの分解、クエリ拡張、仮想ドキュメントの埋め込み、クエリのルーティング、ステップバックプロンプティング、クエリの構造化などがあります。
	- SQLデータベースQA」は、「SQLデータベース」を対象としたQ&Aシステムを構築します。
	- 「グラフデータベースのQA」は、「グラフデータベース」を対象としたQ&Aシステムを構築します
		- 「Cypher」や「SparQL」などのグラフクエリ言語を使用し、自然言語の質問に基づいてクエリを生成し、データベースからの情報を取得して回答を生成するチャットボットやカスタムダッシュボードを作成します
	- 「コード理解」は、ソースコードの分析を目的としています。具体的には、コードベースに関するQ&Aを行い、リファクタリングや改善の提案、コードのドキュメント化を支援します
	- 「データ生成」は、人工的にデータを生成することで、機械学習モデルの学習やテストに役立てます
	- 「タグ付け」は、ドキュメントに感情、言語、スタイル、トピック、政治的傾向などのクラスをラベル付けします
	- 「要約」は、長いドキュメントの内容を要約するためのシステムを構築します。複数のドキュメントや長文テキストを効率的に要約することが可能になります。これには、「Stuff」「Map-Reduce」「Refine」の3つの手法があります。
	- 「Webスクレイピング」は、Webからコンテンツを収集し、自然言語処理に使用するシステムを構築します。
-  LangChain v0.2 で 単純なLLMアプリケーションを構築 by npakaさん
	- https://note.com/npaka/n/n24d48303a496?sub_rt=share_h
-  LangChain v0.2 で エージェントを構築 by npakaさん
	- https://note.com/npaka/n/ne8ef60987e1b?sub_rt=share_b
- 生成AI学びたいなら、この２本 by 尾原さん
	- https://x.com/kazobara/status/1791454624983196148
	- 「生成AI」(3) 松尾豊・東京大学大学院教授　2024.3.15"
		- https://www.youtube.com/watch?v=U9vhGvFxKu0
	- "GPTとは何か Transformerの視覚化 |
		- https://www.youtube.com/watch?v=KlZ-QmPteqM
-  LangChain v0.2 で RAGを構築 by npaka さん
	- https://note.com/npaka/n/ne892b713bd45?sub_rt=share_h
	-  Retriever
		- 「VectorStore」はRunnableをサブクラス化しないため、LECLチェーンにすぐに統合することはできません。「Retriever」はRunnableであるため、標準セットのメソッド (同期および非同期の呼び出しやバッチ操作など) を実装し、LCELチェーンに組み込まれるように設計されています。
	-  RAGチェーン
		- 「Retriever」は、特定の質問と取得したコンテキストを組み合わせて LLM のプロンプトを生成するRAG アプリケーションなど、より複雑なアプリケーションに簡単に組み込むことができます。
		- rag_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | llm
- “MambaOut: Do We Really Need Mamba for Vision?”
	- https://arxiv.org/abs/2405.07992
	- Based on our concept discussion, we hypothesize Mamba is unnecessary for ImageNet while exploring for detection and segmentation remains worthwhile. To verify these, we build MambaOut with Mamba blocks but remove their core token mixer, SSM.
- Text-to-SQL - fully local edition
	- https://x.com/llama_index/status/1791915423816204494
	- The latest local LLMs are not only capable of RAG synthesis, but also querying structured databases. Diptiman Raichaudhuri has a great tutorial on how to build a fully local text-to-SQL setup, letting you query local databases without an internet connection.
	-  Text2SQL OpenSource : duckdb-nsql-7B with Ollama and LlamaIndex on local setup
		- https://diptimanrc.medium.com/text2sql-opensource-duckdb-nsql-7b-with-ollama-and-llamaindex-on-local-setup-6f266f78bc4f
- 

## 5/13

先週に引き続きgpt2-chatbotがchatbod arenaに復活したりと、話題に事欠かないが、サム(OpenAIの社長)から、5/13月曜日に何か発表があるとのポストが、GPT-5でも（うわさの）検索エンジンでもないといっているし、映画Herに出てきたような音声アシスタントという下馬評。おっとCOCONA（_ココナ_）の立場は？。OpenAIといえば、Stack Overflowとの提携、回答者にchatptが登場するのか、またモデルがどのように動作するべきかを規定するModel Specを公開、EUのAI法対策か（以前はSystem Cardがその役割だった）とも見れるし、安全性に本気に取り組んでいる姿勢にもみえる、ともかく来たるGPT-5の素性も透けて見えるというのは面白い分析。あと、今週は国内勢の活躍も活発だった、東工大のSwallow-MX-8x7b-NVE-v0.1をファインチューニングしたKARAKURI LM 8x7B Chat v0.1、13Bで104BのCommand R+を超えるって本当？。「Japanese Stable LM 2 1.6B」、 属性予測モデル　KARAKURI LM 7B APM v0.1 、「Fugaku-LLM」の公開など。さて様々な評価から性能が高い、使える、とされているllama3、日本語がやっぱりダメダメだったりはご愛敬でも、量子化に弱かったり（コンパクトで性能が高いというのは量子化の余地も少ない）と、LLMのスケール測の一端を思い知らす結果になってるというのは面白い、tokenerizerが壊れているとのうわさも。"DeepSeek-V2"ってのがGPT-4と同レベル。かかるコストは200分の1というのは本当だろうか？Google/DeepMindからは「AlphaFold 3」を発表、こんどはDNAも扱えるとのこと、創薬が劇的に加速する予感。先週に引き続いてKANの評価も進む、shi3zさんの「最後にKANは勝つ」というKAN評価試行のnoteのタイトルは「最後に愛が勝つ by KAN」のもじり？それにしてもKANさんご冥福をお祈りします。Microsoftが自社製LLMである「MAI-1」を開発中、ＸはGrokを有料ユーザーに開放。Deeplearning.aiからは、llamaindexのJerry Liu(CEO)を講師にAgentic RAG、LangChainのHarrison(CEO)を講師に、Functions, Tools and Agentsのショートコースが無料公開、なんて豪華な。そのLangChainはv0.2がリリースが間近に、AgentやTool関連の見直しがされる。あとなぜか、時系列予測の基盤モデルの発表も相次いだ、Google/TimesFM、IBMのTinyTimeMixers (TTMs)、ICML2024にアクセプトされた、CMUとUPENのMOMENT、ひょっとしてICML2024がTime Seriesの基盤モデル祭りになってるのか。早速、データサイエンスクラスタからは、(AirPassengerデータに対し）一階差分もとらんのかと冷笑も。xLSTMとか、Vanilla Bayesian Optimization とかの基盤技術の進展もあり、しらんけど。。喜連川先生監修の「生成AIの論点」というのは、日本のLLMをめぐる状況を把握にはよいかも、それにしても「情報大航海時代」はなくなったことになったのか？最後に、THE GUILDの深津さんの、「情報が多すぎて頭がパンクするのは正常ではない」というのは、激しく同意する。

- gpt2-chatbotがchatbot arenaに復活？
	- https://x.com/alfredplpl/status/1787754701536325720
-  最後にKANは勝つのか?MLPに変わると主張されるKANを試す by shi3zさん
	- https://note.com/shi3zblog/n/n1e592409a345?sub_rt=share_pb
	- Efficient-KANが手っ取り早くMNISTが試せそうだったので試してみた
	- つまり、同規模の場合、学習すべきパラメータ数は10倍になり、性能差は縮んでいくという結果になった
- KARAKURI LM 8x7B Chat v0.1を公開しました！
	- https://huggingface.co/karakuri-ai/karakuri-lm-8x7b-chat-v0.1
	- 1. 東工大から出ているSwallow-MX-8x7b-NVE-v0.1をベースにカラクリのデータでチューニングしました。（圧倒的感謝） 
	- 2. 前回に続き、国産オープンモデルとしてはMT-Bench-jpで最高性能を更新 
	- 3. Active Parameter数 13Bで104BのCommand R+を超え、72BのQwen 1.5に迫る性能 
	- 4. AWS TrainiumでのMoEモデルの学習はAWSの担当の方にも確認しましたが、おそらく世界初とのこと。コードは技術ブログの記事とともに近日公開予定。 
	- 5. 前回に引き続き、SteerLMによるアライメントを実施。属性予測モデル（APM）はgemma 7bをチューニングし、公開
-  CACTUS: Chemistry Agent Connecting Tool-Usage to Science
	- https://arxiv.org/abs/2405.00972
	- 化学のためのAIエージェントの論文
	- 化学に関する数千の質問と回答を作成し様々なオープンLLMの性能を比較。Gemma-7bとMistral-7bで高精度を実現、また精度を維持しつつ民生レベルのハードへ導入ができそうだとわかったそうです。
- Stack OverflowがOpenAIと提携？
	- https://x.com/ImAI_Eruel/status/1787670618961514627
	- おそらくChatGPTの登場によってユーザー数の減少という点で最大の被害を被ったのはプログラミングの質問解答サービスStack Overflowなんですが，この度OpenAIとの提携が決まったとのこと
- 精度上げようとすると自然とLLMに頼る箇所減ってピンポイントになる
	- https://x.com/mizchi/status/1787639942216327442
- KARAKURI LM 8x7B Chat v0.1 をお試し中
	- https://lm.karakuri.cc/
- 【GPT-4と同レベル。かかるコストは200分の1】最強LLM「DeepSeek-V2」発表
	- https://x.com/SuguruKun_ai/status/1787839473067376705
	- この子がGPT-4相当と言うのはあってそうで結構文才もある ついでに倫理面も割と高めな感じで日本語出力は悪くない 結構良い感じかも！
- Grokがきた！今はX課金者限定
	- https://x.com/hirochuu8/status/1787880221997515258
- iPad Pro 13 インチ Nano-textureガラスモデルの価格 ≒ KARAKURI LM 8x7bの学習にかかったコストです
	- https://x.com/txmy/status/1787859094034059669
- 日英／英日翻訳タスクにおいてmeta/Llama 3ではgoogle/Gemmaを超える事が出来ない
	- https://x.com/webbigdata/status/1787457498057933299
- Karasu-Mixtral-8x22B-v0.1のgguf
	- https://huggingface.co/mmnga/lightblue-Karasu-Mixtral-8x22B-v0.1-gguf
- lightblue-suzume-llama-3-8B-multilingualのgguf
	- https://huggingface.co/mmnga/lightblue-suzume-llama-3-8B-multilingual-gguf
- Let's build a 100% local RAG app, featuring ⌘R, a self-hosted vector database, a fast embedding library & a reranker:
	- https://x.com/akshay_pachaar/status/1787824526010782053
- Reranker allows you to reorder the retrieved context (chunks), offering two key benefits:
	- https://x.com/akshay_pachaar/status/1787824694768648575
- Ollama v0.1.34 is out!
	- https://x.com/ollama/status/1787976537762856999
- A built-in planning agent for LlamaIndex landed in 0.10.34!
	- https://docs.llamaindex.ai/en/stable/examples/agent/structured_planner/
	- A key pattern in agents is the ability to plan. Breaking down a task into sub-tasks can make the task easier to execute.
- Microsoftが自社の大規模言語モデル「MAI-1」を開発している
	- https://x.com/ImAI_Eruel/status/1787787401055908017
	- 5000億パラメータとの話もあり,本当なら既存モデルで最大レベル.後出し考慮でGPTやClaude超えもできそうか
- DeepSeek-V2、236B のクソデカモデルでありながら推論時は実質 21B 相当の MoE らしく
	- https://x.com/izutorishima/status/1787775197057265925
- ぬこぬこ氏、退職し、本業 LLM 無職へ、
	- https://x.com/schroneko/status/1788148600171831406
- HachiML/Hachi-Alpaca by はちさん
	- https://huggingface.co/datasets/HachiML/Hachi-Alpaca
	- Mixtral 8x22B Instructによる日本語合成データ、28.9kで一旦完了にしました。v1.0_cleanedが精査済みです。
- Zennのトレンド記事を、毎朝AIがラジオ風に紹介してくれるサービスをつくりました
	- https://zenncast-web.vercel.app/
- Announcing AlphaFold 3
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- AlphaFold2の時点で，「ノーベル賞レベル」と言われて最終形態かと思いきや，まさかの3が出てきました by 今井さん
- Deeplearning.aiより無料の、Building Agentic RAG、が公開
	- https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/
- xLSTM: Extended Long Short-Term Memory
	- https://arxiv.org/abs/2405.04517
	- Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to SotA Transformers and State Space Models, both in performance and scaling.
- 4M Context Length Llama-3 8B (V0.1)
	- https://huggingface.co/gradientai/Llama-3-8B-Instruct-Gradient-4194k
- 日本学術会議総会での講演「日本の研究競争力低下の因果推論」の資料が面白い．
	- https://www.scj.go.jp/ja/member/iinkai/sokai/siryo191-2-1.pdf
	- 日本の研究競争力低下の因果推論
	- どれだけ**「研究人・時間密度」（良き人的研究環境の広がり）**を保てるかに、今後の日本の研究競争がかかっている。
- OpenAIがAIモデルがどのように動作するべきかを規定するModel Specを共有
	- https://openai.com/index/introducing-the-model-spec/
	- え、このタイミングてChatGPTの内部挙動わざわざ公開するのなぜ？EU的なやつ？ by 深津さん
	- ここから、GPT-5の特徴が使い勝手がわかるらしい
-  Google Colab で 属性予測モデル　KARAKURI LM 7B APM v0.1 を試す
	- https://note.com/npaka/n/ndb541c2cf03b?sub_rt=share_h
	- 「KARAKURI LM 7B APM v0.1」は、属性予測モデルです。「Gemma 7B」のファイチューニングモデルになります。
	- 属性の値は **0(最低)〜4(最高)** になります。
- karakuri-lm-8x7b-chat-v0.1のggufあります
	- https://huggingface.co/mmnga/karakuri-lm-8x7b-chat-v0.1-gguf
	- imatrixのデータはTFMC/imatrix-dataset-for-japanese-llmを使用して作成しました
- グーグルが、生物学に革命を与えたタンパク質構造予測AIの最新モデル「AlphaFold 3」を発表（ネイチャー論文）
	- https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/
	- タンパク質、DNA、RNA、小分子などほぼ全ての生体分子の構造と相互作用を高精度に予測 生成
	- AIを支えるtransformerと拡散モデルの発展で生物学や創薬が加速
- 毎日がイノベーションすぎて、もはや全容が把握できない。時事ニュース追うだけでパンクする世界は、あまり健全ではない by 深津さん
	- https://x.com/fladdict/status/1788208163965305143
- 日本語特化の言語モデル「Japanese Stable LM 2 1.6B」をリリースしました
	- https://ja.stability.ai/blog/japanese-stable-lm-2-16b
	- Japanese Stable LM 2 1.6B（JSLM2 1.6B）は16億パラメータで学習した日本語の小型言語モデルです。
- TimesFM by DeepMind
	- https://huggingface.co/google/timesfm-1.0-200m
	- TimesFM is a forecasting model, pre-trained on a large time-series corpus of 100 billion real world time-points, that displays impressive zero-shot performance on a variety of public benchmarks from different domains and granularities. 
- Uncertainty Quantification and Propagation in Atomistic Machine Learning
	- https://arxiv.org/abs/2405.02461
	- 不確実性評価のレビュー論文
	- 機械学習でデータが少ない領域を予測するのは困難ですが、それを克服する不確実性評価の手法が教科書的にまとまっています。まだ汎用的手法はなくデータにあった手法をうまく選択することが大切とのこと。
- サムから、月曜に大きな発表があると、、
	- https://x.com/sama/status/1788989777452408943
	- not gpt-5, not a search engine, but we’ve been hard at work on some new stuff we think people will love! feels like magic to me.
-  「Fugaku-LLM」を公開
	- https://pr.fujitsu.com/jp/news/2024/05/10.html
	- 横田さんのとこ、
	- 「Fugaku-LLM」は「富岳」の13,824台の計算ノードを用いて、約4,000億トークンを学習した13Bモデルです
-  LangChain v0.2 の概要 by npakaさん
	- https://note.com/npaka/n/na9e629ebbd16?sub_rt=share_h
	- **・langchain と langchain-community の完全な分離  **
	- **・バージョン付きドキュメント**  
	- **・より成熟したエージェントフレームワーク**  
	- **・LLMインターフェースの標準化、特にツール呼び出しに関する改善**  
	- **・ストリーミングサポートの向上**  
	- **・30を超える新しいパートナー パッケージ**
- 日本語高速ASR Kotoba-Whisper v1.1にアップデートしました
	- https://huggingface.co/kotoba-tech/kotoba-whisper-v1.1
	- 句読点予測を改善 (raw CERで大幅な向上) - Stable-tsの統合により、timestampの予測を向上 - Long-form transcriptionの予測向上 - 学習・推論コードを公開:
- ibm-granite/granite-timeseries-ttm-v1
	- https://huggingface.co/ibm-granite/granite-timeseries-ttm-v1
	- TinyTimeMixers (TTMs) are compact pre-trained models for Multivariate Time-Series Forecasting, open-sourced by IBM Research. 
	- **With less than 1 Million parameters, TTM introduces the notion of the first-ever “tiny” pre-trained models for Time-Series Forecasting.**
- Great, now we have some clean Llama 3 models (both 8B and 70B)
	- https://huggingface.co/ddh0/Meta-Llama-3-8B-Instruct-bf16-GGUF
	- Those minor bugs in llama.cpp has been resolved so should work at its full potential.
- マイクロソフトが1月に発表したSliceGPTでは、LLMのウエイトを圧縮できちゃうらしい。
	- https://x.com/umiyuki_ai/status/1789128885558546881
	- ウエイトの各行列を次元数減らした行列に置き換えちゃうんだって。これでパラ数を25%まで削れて（つまり52.5Bになる？）、Llama2-70Bの場合は性能の低下は1%だけで済むらしい
- Google/TimesFMはモデリングから微妙だし
	- https://x.com/kyo_takano/status/1789150904102613131
	- 一階差分を取らずに非定常過程のまま予測器に突っ込む; 
	- Transformersを使いたいがために複数時点を単一トークンとして埋め込む・予測する; etc.）、
	- 古典的な統計モデルに対して部分的にしか上回ってないんだよね
- Ollamaに、MLX対応くる？
	- https://x.com/m_sigepon/status/1789233089945981319
-  Causal Inference About the Effects of Interventions From Observational Studies in Medical Journals
	- https://jamanetwork.com/journals/jama/fullarticle/2818746?utm_source=twitter&utm_campaign=content-shareicons&utm_content=article_engagement&utm_medium=social&utm_term=051024
	- 医学観察研究で因果関係を示すためにはどうする？6つの条件を示して、これを満たしていれば因果関係を言ってもいいんじゃない？という提言。
- google/timesfm-1.0-200m
	- https://huggingface.co/google/timesfm-1.0-200m
	- Google released a decoder-only "foundation" time series model on
	- Trained on a corpus of 100B real world time-points from Google Trends and pageviews from Wikipedia!
- 『データサイエンスと機械学習』にはKANで話題沸騰中のコルモゴロフ･アーノルドの表現定理が掲載されていた。
	- https://x.com/bebebeBayes/status/1788900859570700291
- 大屋雄裕「信用・信頼・信託 —責任と説明に関する概念整理―」
	- https://x.com/rmaruy/status/1789193304808296841
	- AIの説明可能性／責任について、ウィトゲンシュタインの原因／理由の区別から紐解き、プロセスの透明性だけでなく答責性が問題になる場面がどんなときかを議論。この上なく明晰。
- lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- https://huggingface.co/lyu-boxuan/llama-3-youko-8b-En-Ja-MT-LoRA
	- rinna様のllama-3-youko-8bを少数の英日対訳データ+LoRAでSFTしてみました
-  Post Llama 3 depression
	- https://www.reddit.com/r/LocalLLaMA/comments/1colmeb/post_llama_3_depression/
	- Llama3の微調整モデルは色々出たけど今んとこどれもアカンという話。原因はよく分からんけどもう今までの微調整のやり方は時代遅れなのかもしれない。少なくともLlama2とは勝手が違うらしい
- 「ローカルLLMはこーやって使うの」を更新しました
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	-   以下を追加: 
		- 前提知識の確認 
		- 特殊トークンによるプロンプトインジェクション 
		- 尤度関数としての利用
- Difyの勢いがすごい。LangChainやFlowise、Llama Indexを抑えてLLMツール4週間で1位に
	- https://x.com/kyutaro15/status/1789054552638943495
- You can now generate production-ready prompts in the Anthropic Console.
	- https://x.com/AnthropicAI/status/1788958483565732213
- Vanilla Bayesian Optimization Performs Great in High Dimensions
	- https://arxiv.org/abs/2402.02229
	- バニラのベイズ最適化が高次元でも大活躍
	- これまで高次元は呪いの領域と思われていたが、適切な仮定を設けるだけで最先端の手法を圧倒する性能が出せることが判明
- DeepLearningAIから、今度はLangChainのCEOの講義
	- Check out the short course Functions, Tools, and Agents, taught
	- https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/
- "MOMENT: A Family of Open Time-series Foundation Models"
	- https://moment-timeseries-foundation-model.github.io/
	- has been accepted for the ICML 2024! On this occasion, we are open-sourcing it, together with the model weights and dataset!
- 生成AIの論点
	- https://www.seikyusha.co.jp/bd/isbn/9784787235374/
	- 喜連川先生まだいきてたのか？
	- 日本学術会議が実施し、過去最多の動員を達成したシンポジウム「生成AIの課題と今後」の書籍化である
- 

## 5/7

ＧＷで、頭がぼけているのか、X(旧twitter)のアルゴリズムが変わったのか、おすすめに出てくるツイートが先週とかぶっている気がする。Xの生成ＡＩを使った新サービス「ストーリーズ」の展開と関係あるのか？。今週は突然でてきた謎のgpt2-chatbotが面白かった、gpt2と名前があるものの、GPT-4.5かGPT-5のフィールドテストかという話で持ち切りだった（Chatbot Arenaからは消えた。。）、評価できた人によると、相当すごい性能らしい。Swallow-MS 7Bの新しいinstructモデル、さっそくElyzaTasks100で評価され、ちょっと微妙な結果に。一方ElyzaTasks100での評価によると、Qwen1.5はかなり優秀だけど時々日本語に難ありとのこと。Domingos氏のAIの能力の発展がサチっているていう話は、（そもそもデータとして使った）人間の能力がAIの進化を律速しているとのこと。そりゃ、人間を超えるのは人間のデータでは無理だ、超えたところで人間にはわからないというのはそうかも。BCGの売上20%が生成AI関連とのこと、コンサルはなくならない、金の儲け方が変わるだけ。「統計的テキストモデル」全文がプレ公開されたとのこと、われは！と思う人はぜひチャレンジを。Ollamaを使ったローカルLLMの利用例もぐっと増えた、もはやRAGは誰でもできる、さらにReAct Agentとか、Function Callingとか、よりむつかしいタスクむできるようになった、気のせいかLlama3やphi3が使われる例が多いような。Kolmogorov–Arnold Networks、新しい生成AI向けニューラルアーキテクチャ？特異学習理論（渡辺ベイズ理論）を発展させた局所学習係数という新しい概念も気になる、アライメントととも関係あるとか。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。「ローカルLLMはこーやって使うの」は参考になる、ローカルLLMならいろいろやり放題なんだな。ＡＩセイフティでは、NISTから、生成ＡＩ向けのリスク管理フレームワークが発表、日本のAISIとの連携も進む。AIアライメントの包括的なサーベイ、「AIによる絶滅リスクの軽減」だと。rinnaからLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開、NIIから「LLM-jp-13B v2.0」を構築とか、頑張れ日本勢。うみゆきさんが言うように、進化型のLLMのマージMergekit-Evolveってのは本当にすごのいか？？LangChainの４つのRAG向けchainの比較も地味に役に立つ。ローカルLLM系では、自作小説をLLMで評価させているひとが、 command-r-plus-Q4_K_Mを絶賛評価、実作業に基づく評価は尊い。ChatGPT東大入試に挑むも「不合格」の記事（日経）、さっそくプロンプトが悪いと、いや解けたよ、との突っ込みが、次々と。。

- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較｜
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	- stuff chain、map reduce chain、map rerank chain、refine chain
	- 応答速度 : 呼び出し回数が1回のstuffは「速い」, n回ですが各文書に対するLLM呼び出しを並列化できるmap系2種は「普通」, n回かつ並列化ができないrefineは「遅い」としています。
	- 適している文書特徴
		- stuff・map reduce : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- map rerank : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- refine : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7bをElyzaTasks100で評価してみたら平均3.57点を叩き出した　 by うみゆきさｎ
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- 7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！
- Swallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました
	- https://huggingface.co/collections/tokyotech-llm/swallow-ms-instruct-662957bf88d016c69ae0e633
	- あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】  512トークン、340Token/S
	- https://x.com/hokazuya/status/1783808939773304957
	- ローカルLLMでこの性能はPhi-3やLlama3の7Bなど見てきたがMac単体でこれはスゴすぎる。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘している
	- https://x.com/pmddomingos/status/1783956607552176422
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
	- https://x.com/rmaruy/status/1784154638390104188
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
- 『Symbol-to-Language』
	- https://x.com/ai_database/status/1784581982053347542
	- LLMのタスクにおいて「記号を自然言語テキストに変換する」ことで様々なタスクで精度が上がる現象が報告されています。
	- 実験では、物性予測、表の理解、ツイート分析などで効果が出ています
- BCGの売上20%が生成AI関連で、2026年までに40%にまで増えるとか
	- https://www.ft.com/content/33dfaec4-b5e7-4eca-a869-cdd33d447e65
- lama 3 degrades more than Llama 2 when quantized.
	- https://x.com/rohanpaul_ai/status/1784889182558539917
- gpt2-chatbotと呼ばれる謎のモデル
	- https://x.com/bioshok3/status/1784972619957346703
	- Chatbot arena でClaude3 opusやGPT-4 Turboに匹敵するとかしないとか超えてる超えてない言われ今少し話題になっている
- ReAct Agent with Function Calling | Open Source Gemma LLM | Ollama | Lan...
	- https://www.youtube.com/watch?v=exYUJcz4uZs
- llama-2-13b-retrievalqa.ipynb - Colab
	- https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/llm-field-guide/llama-2/llama-2-13b-retrievalqa.ipynb#scrollTo=JPdQvYmlWmNc
- crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
	- https://huggingface.co/crusoeai/Llama-3-8B-Instruct-Gradient-1048k-GGUF
- react-agent-with-function-calling-ollama-langsmith.ipynb
	- https://github.com/Ashufet/LangChain_ReAct-Agent-with-Function-Calling_Ollama-Gemma-LLM_LangSmith/blob/main/react-agent-with-function-calling-ollama-langsmith.ipynb
- Google announces Med-Gemini, a family of Gemini models fine-tuned for medical tasks!
	- https://x.com/iScienceLuvr/status/1785247498744778886
- 「統計的テキストモデル」の全体の原稿(4章以外)のβ版を公開しました
	- http://chasen.org/~daiti-m/textmodel/
- Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities
	- https://arxiv.org/abs/2404.17790
	- 東工大のLLM、Swallowの論文がarXivに公開されていますね。
	- 日本語の継続事前学習について、データのスケーラビリティや語彙拡張、パラレルコーパスの影響について大規模かつ系統的に知見を提供している研究で、勉強になります
- gpt2-chatbotは本当にモデル名だ。そうHFのCTOがいまopenai-communityからホスティングしていると思われる。
	- https://x.com/alfredplpl/status/1785170960251007266
- 大規模言語モデル「LLM-jp-13B v2.0」を構築
	- https://www.nii.ac.jp/news/release/2024/0430.html
	-  NII主宰LLM勉強会（LLM-jp）が「LLM-jp-13B」の 後続モデルとその構築に使用した全リソースを公開
- Qwen1.5シリーズを一通りElyzaTasksで評価してみた
	- https://x.com/umiyuki_ai/status/1785272618595262646
	- やっぱりQwen1.5はかなり優秀。7BモデルはLlama3-8Bのチョイ下。14Bモデルは35BのCommand Rを超えてる！
- AISIと米国NISTは、日本の「AI事業者ガイドライン」とNISTの「AIリスクマネジメントフレームワーク(RMF)」のクロスウォークの第一弾として用語に関する「クロスウォーク1」を公表しました。
	- https://aisi.go.jp/2024/04/30/ai_rmf_crosswalk1_news/
- 謎の高性能AIモデル「gpt2-chatbot」がChatbot Arenaに登場、GPT-4.5かGPT-5なのではないかと話題に
	- https://gigazine.net/news/20240430-lmsys-chatbot-arena-gpt2-chatbot/
	- 日本の歴史についても、ハルシネーションの多いClaude 3 Opusと比較して、遥かに優れた回答。論理的な考察についてもレベルが高い。
- 自作小説をLLMにレビューさせてみる（ローカル4モデル、サービス型3モデル）
	- https://note.com/kohya_ss/n/nfcdfd6de8790
	-  command-r-plus-Q4_K_M: 極めて高い理解力と要約力を示し、作品の伏線や登場人物の理解も的確だった。文章は読みやすく洗練されており、ローカルLLMの中で最も優秀な性能を示した。小説のテーマを深く理解し、適切な批評を行っている。
- US NIST publishes 1st draft of its "AI Risk Management Framework: Generative AI Profile." 
	- https://airc.nist.gov/docs/NIST.AI.600-1.GenAI-Profile.ipd.pdf
- rinnaはLlama 3 8Bの日本語継続事前学習モデル「Llama 3 Youko 8B」を公開しました。
	- https://huggingface.co/rinna/llama-3-youko-8b
- KAN: Kolmogorov–Arnold Networks
	- https://arxiv.org/abs/2404.19756
	- https://github.com/KindXiaoming/pykan
	- Proposes an alternative to MLP that outperforms in terms of accuracy and interpretability
	- 重みを学習させるのではなく、エッジ上に配置した活性化関数を学習させる(エッジの重みは1で固定)新しいニューラルネットワークのアーキテクチャの提案。…
	- ちなみにニューラルネットワークとコルモゴロフ-アーノルド表現定理の話題に関しては，そんなに新しいものではなく，結構昔から出ているものではあります(今井さん)
- RAGのG（Generation）、つまり"生成"は本当に必要なのか？
	- https://x.com/Nurruttan/status/1785853289034350622
- AI Alignment: A Comprehensive Survey.
	- https://alignmentsurvey.com/uploads/AI-Alignment-A-Comprehensive-Survey.pdf
	- AIアライメントの包括的なサーベイ
	- AIアライメントは、AIシステムを人間の意図や価値観に沿って行動させることを目的としている。AIシステムの能力が高まるにつれて、ずれたAIシステムに関連する潜在的な大規模リスクが顕著になっている。何百人ものAI専門家や著名人がAIリスクへの懸念を表明し、「AIによる絶滅リスクの軽減は、パンデミックや核戦争といった他の社会的規模のリスクと並んで、世界的な優先事項であるべきだ」と主張している
- ローカルLLMはこーやって使うの💢
	- https://gist.github.com/kyo-takano/c662c1bfa1e7fe440511b11f62521a7e
	- ①トークンの生成確率が全部見れる。これを応用するとハルシネーションや誤字脱字の検出もできるかも。というのはどのワード生成時に自信が無かったかが確率を見れば分かるから。②回答の冒頭部分を強制できる。
- X、生成AIでニュースの要約を開始　一部の有料会員に
	- https://www.nikkei.com/article/DGXZQOGN0406N0U4A500C2000000/
	- 「新機能「ストーリーズ」を始めた。米xAI（エックスエーアイ）の対話AI「Grok（グロック）」がX上で話題のニュースなどについて情報を要約」
- How LLMs work, clearly explained with visuals:
	- https://x.com/Sumanth_077/status/1786404341735444731
- Build a RAG system with Llama 3B-Instruct for your PDFs
	- https://colab.research.google.com/drive/1BJYYyrPVe0_9EGyXqeNyzmVZDrCRZwsg?usp=sharing#scrollTo=Y2m2l-vt_RSp
-  TAIS 2024 | Insights from two years of AI safety field-building at MATS — Ryan Kidd
	- https://www.youtube.com/watch?v=tA9K8JqyhP4
	- Don't miss @jesse_hoogland captivating talk at TAIS2024 on the structure of neural networks and the links between learning theory and interpretability! Watch now:
	- 特異学習理論（渡辺ベイズ理論）を発展させて局所学習係数という新しい概念を創出し，①transformerの学習ダイナミクスの解析，②機械論的解釈可能性の基盤理論としての可能性，③AIアライメント理論の展望を力説した2人の研究者のTAIS2024講演
- 「確率変数」の正体は米田埋め込み
	- https://m-hiyama.hatenablog.com/entry/20170228/1488276250
- ChatGPT、東大入試に挑む　英語8割超も数学1点で「不合格」
	- https://www.nikkei.com/article/DGXZQOUC2103E0R20C24A3000000/?n_cid=SNSTW005
	- 「この計算は手作業では困難。数学の専門書をおすすめする」。人ごとのような答案もありました。古文も文脈を理解できず0点。一方、英作文や英訳は満点でした
- 2024年東大入試数学の第1問の(1)をプロンプトを工夫して解いてみたら、一発で解けた。これだけで5点くらい取れているはず
	- https://x.com/itnavi2022/status/1787121446445326816
- 第2問の(1)は、プロンプトを工夫しなくても、ChatGPTで普通に正解できた。
	- https://x.com/itnavi2022/status/1787448789693059176
- Nvidia が出した、Llama3-ChatQA-1.5の微調整でRAG＆対話性能爆上がり。
	- https://x.com/hokazuya/status/1786901364213416356
- LangChainのllama.cpp統合
	- https://x.com/yuiseki_/status/1787091439408816479
- 【vLLM on Hugging Face Interface】
	- https://x.com/hokazuya/status/1787060961570127973
	- 便利すぎ。爆速でLlama 3 -8BのLLMを動かす＋OpenAIのAPIを呼び出す形式でLlama 3と会話できちゃう。

## 4/29

マイクロソフトからPhi-3-miniが発表され、3.8BのモデルがMixtral 8x7BやGPT-3.5とためをはるとのこと、Phi-3-mini 4k instruct モデルはColab T4でも動くし、huggingfaceにも公開。さっそくOllamaが対応し、Llama-3 & Phi-3もRAGでの比較とかも。Llama3も、日本語向けにLoRaされたり、Llama3-70Bを42Bパラメータに枝刈りしたモデルが公開されたり、4bitに量子化して評価されたりとか、コミュニティの活動が一気に盛り上がる。なお量子化に関してはどのＬＬＭも4bit量子化しても精度がほとんど低下しないとのことだが本当か？AppleがiPhoneでも稼働するオープンな言語モデル「OpenELM」を発表、さっそくMLX LMで評価した結果が公開された、Macbook AirでPhi 3の量子化されたやつを動かして劇速といってる例とか、実は、LLMプロダクト開発者はMac 進化的を買ってローカルLLMを触るべきとの意見も見られたが、反論もぼちぼち、さても６月のWWDC24が楽しみだ。それにしても、NVIDIA CEOジェンスン・ファン氏がショッピングモールからの歌配信に混ざる動画、かわいいなあ（いやＣＥＯがだよ）。Groq(LPUによる高速化のほう）のAPIをStreamlitで使う方法の紹介など、Groqの利用をちらほら見るようになった、速さは最強。LLMエージェントに関するニュースを毎週まとめてくださるサイト、頭が下がる、このアプデ更新もそうありたいものだ。LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いているというのは、アライメント問題を表面上の課題ではなくアーキテクチャまで落とすところが面白い。LLMの性能評価やベンチマークに関する活動もElyzaTasks100やRAG、Query PlanningなどのタスクにおけるローカルLLMの実力が検証なんかがあった。

- モデル進化マージについて by sakana.aiの秋葉さん
	- https://speakerdeck.com/iwiwi/17-nlpkorokiumu
	- 日本語LLMのマージはあまりない、継続学習されて、元の重みからずれてしまっている。
	- そこで、進化的計算によるマージ。
-  「AI事業者ガイドライン（第1.0版）」
	- https://www.meti.go.jp/press/2024/04/20240419004/20240419004.html
	- これまでMLPdM的な人が一般的に留意すべきと言われていたようなことに加え、より広い社会的な観点や、AIの利用者の観点なども踏まえた上でうまくまとめられている有益なガイドラインだと感じました。
	- https://x.com/yu__ya4/status/1782037184079683916
- Command R+はどこまで量子化するとアホになってしまうのか？ by npakaさん？
	- https://soysoftware.sakura.ne.jp/archives/3834
	- ローカルでCommand R+を動かすとなると、手元の環境のRTX4090が１台ではハッキリ言って1bitまで圧縮してもVRAMに載りきらない。
	- 今回はCommand R+の各量子化モデル、Q6_K、Q5_K_S、Q4_K_S、iq4_xs、Q3_K_S、iq3_xxs、Q2_K、iq2_xxs、iq1_sのそれぞれについて、ElyzaTasks100を解かせてみる。
	- API～3bitまではぶっちゃけ大差ないというか誤差の範囲だという事だろう
	- 1bitの3点というのはこれはもう完全に劣化してるというのは確実に言えそうだ。
	- まず、今回の結果だけで言えば、実用上は4bitまでの量子化なら性能劣化は見当たらないように見える。
- Fully local RAG with Llama 3 on ollama & streamlit
	- https://x.com/ashpreetbedi/status/1782079131103932647
-   LLMモデル "Llama3" を 4bit 量子化して実行してみた
	- https://qiita.com/akasakat/items/0855b5f05467cc8cbbf4
	- 一昨日発表された  [Llama3](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)  を4bit量子化 してつかってみました
	-  GPUの VRAM は 6GB 程度消費します
	- Llama3の 語彙数は 32000(Llama2) => 128256 へと大幅に増えました
- LoRA fine-tuning of embedding models using LlamaIndex
	- https://medium.com/@diagnosta/lora-fine-tuning-of-embedding-models-using-llamaindex-a60b823a2c94
	- In this blog post, we’ll explore how to fine-tune black-box embedding models using low-rank adaptation (LoRA) with the LlamaIndex library. LoRA is a technique that trains a small number of rank-decomposed weights to adapt a pre-trained model to a new task or domain. 
- 自宅PCでクラスターを構築：コンシューマーGPUの枠を超え、大型LLMをローカルで動かす！ by AIサトシ
	- https://note.com/aisatoshi/n/nd4969fc42602?sub_rt=share_h
	- Command-r-Plusは、4bitに量子化しても60GB程度のVRAMが必要となります。
	- 複数PCでのモデル並列が自宅で可能となったので、理論的には、デスクトップを増やすことで巨大なLLMの推論が可能となります。
- alfredplpl/Llama-3-8B-Instruct-Ja　 by あるふさん
	- https://huggingface.co/alfredplpl/Llama-3-8B-Instruct-Ja
	- 日本語向け Llama 3 8Bを公開してみました。LoRAで表面を学習しただけなので、性能はありません。ただ、普通のLlama 3よりかは日本語が強くなっているはずです。よろしくお願いします
- Groqの値段調べ、llama3など
	- https://x.com/webbigdata/status/1782240169879601540
	- GroqはLPU(Language Processing Unit)という独自ハードウェアを開発している会社です
	- Llama 3 70BがAnthropic Claude 3 Sonnet($3.00/$15.00)相当の性能であれば、GroqのLlama 3 70B APIの価格設定($0.59/$0.79)は非常に競争力があります
- Llama 3 70b layer pruned from 70b -> 42b by Charles Goddard
	- https://www.reddit.com/r/LocalLLaMA/comments/1c9u2jd/llama_3_70b_layer_pruned_from_70b_42b_by_charles/
	- chargoddard/llama3-42b-v0
	- Llama3-70Bを枝刈りしてパラ数42Bにしちゃったというブツらしい。
-  Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
	- https://arxiv.org/abs/2404.14219
	- Microsoft announces phi-3-mini, a 3.8B model trained on 3.3T tokens that rivals Mixtral 8x7B and GPT-3.5
	- パラメータ数、学習トークン数
		- ①Phi-3-mini (38億、3兆3000億)
		- ②Phi-3-small (70億、4兆8000億) 
		- ③Phi-3-medium (140億、4兆8000億）
- は？Phi3-small-7BはMMLUが75.3点？Llama3-8Bでも66点だというのに。
	- https://x.com/umiyuki_ai/status/1782622321704079652
-  Weekly AI Agents News!
	- https://speakerdeck.com/masatoto/weekly-ai-agents-news
	- このLLMブクマアプデのように毎週、Agent関係の情報を収集している人
	- LLMエージェントに関するニュースを毎週まとめてくださる
-  From  r  to  Q∗: Your Language Model is Secretly a Q-Function
	- https://arxiv.org/abs/2404.12358
	- LLMのアライメントであるDPOは実はトークン単位の逆Q学習を実現し、最適なアドバンテージ関数を推定し、トークン単位の信用割当問題を解いている。例えばある対話の結果につながった原因のトークンを特定できたり、尤度最大化のビーム探索はそのまま収益最大化とみなせる by 岡野原さん
- Llama.cpp で Llama 3 70Bをお試し中。by npakaさん
	- https://x.com/npaka123/status/1782556559589212399
	- 8.42 tokens per second 
	- Meta-Llama-3-70B-Instruct-IQ4_XS.gguf 
	- M3 Max (128GB)
-  llama.cpp による transformersモデル の量子化 by npakaさん
	- https://note.com/npaka/n/nbd1348500a28?sub_rt=share_b
	- 今回は練習用に「meta-llama/Meta-Llama-3-8B-Instruct」を準備します。
	- transformersモデルをggufに変換
	- imatrix量子化
- Llama3-70BはElyzaTasks100（Command R+による自動評価）においてCommand R+超えてます
	- https://x.com/umiyuki_ai/status/1782690199677641164
- CodeQwen1.5
	- https://x.com/Alibaba_Qwen/status/1782426698279272742
	- Last week, we released a CodeQwen1.5 and received a lot of positive feedback! Thank you for your support! 
- 手元のMacbook AirでPhi 3の量子化されたやつを動かしているのだが、これGPT-3.5こえてるよね。ノートパソコンで普通に動くってどういうことだ
	- https://x.com/alfredplpl/status/1782808427129114796
- phi3 local RAG using LlamaIndex and Ollama:
	- https://x.com/llama_index/status/1782893301214986593
	- https://colab.research.google.com/drive/1RoZzbL8WYaAp4b3sazYHVI8TA2AkrtRJ#scrollTo=9AtRxaqD94mZ
- 様々なタスクでのlocal LLMの実力のベンチマーク
	- RAG, Query Planning, Text2SQL, and Pydantic Program but struggles with Routing and Agentic tasks. 
-  Feature Test for Phi-3-mini-4k-instruct
	- https://docs.llamaindex.ai/en/latest/examples/benchmarks/phi-3-mini-4k-instruct/
- Phi-3 mini 128k instruct の Colab T4 で動作確認の取れた　 by ぬこぬこさん
	- https://gist.github.com/schroneko/f4fac4c4dd541f4c5ee61c44c90c4a85
	- サンプルの方程式を解く問題は難なくクリア。日本語でもクリア。3.8B にしてはかなり日本語をナチュラルに話せているのでは？
- HuggingChatにphi3-mini-4k登場
	- https://huggingface.co/chat/
-  Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches
	- https://arxiv.org/abs/2404.14779
	- 医療ドメインでLLMをfine tuningする際、フルパラメータのチューニングをするかLoRAで効率的にチューニングするべきかをLlama-2ベースのモデルで検証した論文。
	- モデルサイズが小さいほどfine tuningの効果が大きい
	- モデルが大きいほどLoRAのパフォーマンスは古パラメータのチューニングに接近しそう
- LLMの継続学習における論文紹介
	- https://note.com/sergicalsix_/n/ndbd5b29451c9
	- LLMの継続学習においてドメインの内容や順序などについて調査。ドメインを類似度順で継続学習した方がドメイン特化させやすく、ドメインをランダムな順序で継続学習した方がLLMの性能・知識の蓄積が改善する。
-  Command R+はトークナイザーもすごかった
	- https://qiita.com/sergicalsix/items/5ceb9a3a0d11affb4b9a
	- 今回はCommand R+の日本語の応答速度が本当に速いのか、なぜ速いのかについてトークナイザー観点で述べたいと思います。
	- CohereのAyaとCommand R+のトークナイザーは他のトークナイザーと比べてトークン数が削減できていることがわかりました。
- Apple、iPhoneでも稼働するオープンな言語モデル「OpenELM」を公開
	- https://www.itmedia.co.jp/news/articles/2404/25/news103.html
	- パラメータ数の異なる4つのモデルがある。小さいものから、2億7000万、4億5000万、11億、30億
	- OpenELMは、レイヤーごとのスケーリング戦略を用いて、Transformerモデルの各レイヤー内でパラメータをefficient（効率的）に割り当てることで精度を向上させているという。
- Let's compare Llama-3 & Phi-3 using RAG:
	- https://lightning.ai/lightning-ai/進化的s/compare-llama-3-and-phi-3-using-rag?utm_source=akshay
	- https://x.com/akshay_pachaar/status/1783114329199718558
-  Cohere Toolkit
	- https://github.com/cohere-ai/cohere-toolkit
	- Yesterday, we open sourced the Cohere Toolkit. We think this will be a major accelerant for getting LLMs into production within enterprise.
-  LLMにとって「質の良い学習用データ」
	- https://x.com/imos/status/1783494307959513522
	- LLMにとって「質の良い学習用データ」は「正しい日本語に/倫理的に絞られたデータ」ではないと思うので整理して布教したい（FineWeb曰くアダルトサイトを抜くと性能劣化するらしい）。言語能力、知識、論理能力、応答形式など、用途を満たすのに必要な軸を欠かさず含むことが大事だと思われる。
- Llama 3 Establishes Meta as the Leader in “Open” AI  by IEEE Spectrum
	- https://spectrum.ieee.org/meta-llama-3?share_id=8224093&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- 『統計的テキストモデル』(岩波書店 確率と情報の科学)の執筆がついに最後まで到達しましたので、「文書の統計モデル」の章を公開しました
	- http://chasen.org/~daiti-m/textmodel/textmodel-chapter5.pdf
-  Graph Machine Learning in the Era of Large Language Models (LLMs)
	- https://arxiv.org/abs/2404.14928
	- グラフと言語モデルに関するレビュー論文
	- グラブ系機械学習モデルとLLMの組み合わせによる研究例や展望がまとまっています。MI分野だけでなく他分野の事例もあり参考になります。
- Two new AI releases by Apple today
	- https://x.com/pcuenq/status/1783032344104026372
	- OpenELM, a set of small (270M-3B) efficient language models. Weights on the Hub:
	- CoreNet, a training library used to train OpenELM:
-  [Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge](https://aclanthology.org/2024.eacl-long.127.pdf)
	- 多言語言語モデルが獲得している事実に関する知識を53言語で検証。どのような原因によって言語ごとに差が出るのか、データ量や地理的観点・活性化されたニューロンの類似性などから分析している。
-  LLMプロダクト開発者がMac 進化的を買ってローカルLLMを触るべき理由
	- https://note.com/erukiti/n/n58a8180ea9fb
- [torchtitan](https://github.com/pytorch/torchtitan)
	- a library for large model training called torchtitan
	- They have scripts to train Llama-3 from scratch
	- The library went public today on GitHub but it is still in pre-release state & active development
- LangChainを用いた4種類のRAG質問応答chainの実装と性能比較
	- https://zenn.dev/aidemy/articles/97d5fb6ac03a4f
	-  **stuff chain**、 **map reduce chain**、**map rerank chain**、 **refine chain**
	-  **適している文書特徴**
		-  **stuff・map reduce**  : 文書全体を1段階または2段階でLLMに入力するため, 文書全体に重要な情報が含まれる場合に特に有効です。
		- **map rerank**  : 文書の一部のみの回答から最良の回答を選ぶため, 一部のみに重要な情報が含まれる場合に特に有効です。
		- **refine**  : 一部のみの回答を複数回再起的に呼び出すため, 重要な情報が文書の全体でも一部でも対応することが可能です。
- 「Japanese-Starling-ChatV-7B」
	- https://x.com/AIBizNavigator/status/1783667625802994164
	- 7Bクラスとは思えない超高性能なんだ
	- 英語の最強7BモデルStarling-LM-7B-betaから抽出したChat Vectorを、 日本語モデルのChatNTQ-JA-v1.0-7bに掛け合わせただけ。 追加の日本語学習は一切なし
	- https://huggingface.co/TFMC/Japanese-Starling-ChatV-7B-GGUF
- Mergekit-Evolveのテストで試しに作ったモデル、Japanese-Chat-Umievo-itr001-7b
	- https://x.com/umiyuki_ai/status/1783867934542303666
	- https://huggingface.co/umiyuki/Japanese-Chat-Umievo-itr001-7b
	- ElyzaTasks100で評価してみたら平均3.57点を叩き出した！7Bモデルなのに35BパラのCommand Rを超えてます！進化的アルゴリズムの威力恐るべし！！とりまHuggingFaceに上げました！
- Swallow instruction tuning models
	- https://huggingface.co/collections/tokyotech-llm/swallow-instruct-65e559f4d52e7c9d197697c2
	- wallow 7B, 13B, 70B、およびSwallow-MS 7Bの新しいinstructモデル（Swallow-*-instruct-v0.1）を公開しました。あまり重視してこなかった指示追従能力やマルチターン応答の改善に取り組み、MT-Benchで過去のモデルを上回る性能を確認しました。
- tokyotech-llm/Swallow-MS-7b-instruct-v0.1
	- https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1
	- swallow 7B, 13B, 70B、およびSwallow-MS 7Bのインストラクション・チューニングを改良し、指示追従性やマルチターン応答を向上させたモデルをHugging Face上で公開しました。以前に公開したモデルと比べて、MT-Benchのスコアで大幅に改善しています
- Swallow-MS-7B-Instruct-V0.1をElyzaTasks100で評価したら平均2.82点だった。現環境ではもはや大した事ないと言わざるを得ない。でもChatNTQよりはかなり強いという事はChatVectorを足すベースモデルとして有能かもしれない
	- https://x.com/umiyuki_ai/status/1783911959789969816
- 【Appleの新しいOpenELMモデルをMLX LMで】
	- https://x.com/hokazuya/status/1783808939773304957
	- 512トークン、340Token/S
	- M3 Pro Mac (64GB)で16ビットの270Mモデルで超高速ローカルLLMが実現。
-  Weave と Elyza-tasks-100 で ローカルLLMを評価する by npakaさん	
	- https://note.com/npaka/n/nc0c8d5beacff?sub_rt=share_h
	- 「**Weave**」は、LLMアプリケーションの記録、実験、評価のためのツールです
	- 「**Elyza-tasks-100**」はElyzaが提供する指示チューニングモデル用の評価用データセットです。
- Domingos氏、AIの能力が人間レベルで飽和しているように見えていることを指摘しているが、、
	- https://x.com/rmaruy/status/1784154638390104188
	- むしろこれらのタスクで120%や200%を有意味に議論できるのかという方が気になる。という意味で、Domingos氏の意図と異なる意味で超知能到来ビジョンへの疑義になっている。
- ベイズ推論を使ってみよう
	- https://x.com/makaishi2/status/1784115819791913065
	- 『Pythonでスラスラわかるベイズ推論「超」入門』著者
- 【随時更新】主要な大規模言語モデル比較表
	- https://zenn.dev/ml_bear/articles/3c5e7975f1620a
- 居合わせた歌配信に混ざる NVIDIA $NVDA CEO ジェンスン・ファン
	- https://x.com/woodstockclub/status/1784179786082128351
	- 配信者の2人「ジェンスン？誰？？」
-  高速AIチップで話題のGroqのAPIをStreamlitで使う方法
	- https://note.com/masayuki_abe/n/n336721e355e6?sub_rt=share_pb
	- 高速AIチップで話題のGroqのAPIをStreamlitのコードの記事を書いてみました。OpenAIのAPIと表記が似ているので書きやすいですね。
- Swallow-MS-7BやRakutenAI-7Bはトークンの語彙が拡張されてる事に気付いたが、これって拡張されてない他のモデルとマージしたらアカンのだろうか
	- https://x.com/umiyuki_ai/status/1784274430816034898
- 【Whisper.cpp-CLI】
	- https://x.com/hokazuya/status/1784554378118246440
	- ローカルで高精度の音声文字起こしができるWhisper環境が、ものの200msで作れてしまうとのPyplパッケージがOSSで
- 


## 4/21

今週は、最大３倍高速という日本語GPT-4の開発の発表もあったけど、なんといってもメタからllama3の待望の公開。最初は8bと70bが公開され、さらなる大規模モデルも開発中とのこと。lllama3のファインチューニングに用いたPyTorchの新機能tochtuneも公開。早速、量子化、MoE化、ファイチューニングの実行例が公開され、MXで8GB M2 miniでの動作確認!、ollamaの対応、さらにはGroqに乗っかってデモサイトでLlama3-70Bが300t/sの超絶爆速推論を見せたなどの一通りが１週間で進む。RAGでのllama3の利用例もLangChainから紹介があったが、CommandR＋もllama3も、プロンプトに与えるテンプレートが独特なので、LLMをネイティブに使う人は要注意だ。1bitのLLMも、shi3zさんの自作評価や、椎橋さんによるGPUではないオーダーメイドによるAIソリューション「カスタムAI」の可能性など、いい記事がでてきた。ChatVectorによるLLM性能向上も、先週に引き続き、Bakuさんの、ChatNTQ 7B と LightChatAssistant 2x7B の日本語能力を試す記事が神記事として話題に。LightChatAssistantってのはそんなにすごいのか。作ってみたら性能が高かったというJapanese-Starling-ChatV-7B-GGUFなども出たり、ChatVector紹介の先駆者はちさんからSwallow-MS-7b-v0.1-ChatSkill-LABが出たり、能力加算の組み合わせの最適解をoptuneをつかって実行・評価とか、、LLMの能力の足し算引き算しつつ性能を評価するという一段メタな世界が開けた。PFNの丸山さんが紹介された、LLMをつかって言葉だけで、線形回帰をさせるという論文、どんなモデルを内部に持っているんだという意味で面白い。 Cambridge大学のU. Anwar, D. Krueger氏ら40名!による、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文はすごい、AIガバナンスのオックスフォードハンドブックもあり、UKではアライメントとガバナンスの大きな拠点になっているのか。マイクロソフトから、WizardLM-2 の7bと8x22bが発表、Evolve Instructという新しいファインチューニング手法の能力やいかに、エージェント機能も持っているとか、嵐の予感。Qwen1.5-7B-Chat-GGUFも出た、来週あたりQwen1.5ベースの日本語LLMが出てくるのでは。DeepMindの「Many-shot」多数例示学習の有効性や、RAGのMiniCheck、複数の知識を組み合わせるChain-of-Abstraction (CoA) ReasoningなどのLLM推論での進展もあった。丸山隆一さん、AI科学の何が“哲学”という問い（スライド）も良いし、「AI協働時代に研究者はどう生きるか」というイベントも面白い。AIが（従来の）研究ができるようになるならば、AI研究者はなにをするのかみたいな感じ。さきほどのUKと比べるとこのあたりの研究者層が薄いのかな。その他としては、Swallow-MXを使ったQ&AデータセットであるAutoWikiQAとか、MiniCPM-V-2のデモの公開、商用利用可能なマルチモーダルLLM、idefics-8bなども出てきた。

- openbmb/MiniCPM-V-2
	- MiniCPMのデモが公開
	- https://huggingface.co/spaces/openbmb/MiniCPM-V-2
- OpenAI Japanの発足とまさかの日本語GPT-4の発表。
	- https://openai.com/blog/introducing-openai-japan
	- 「日本語のテキストの翻訳と要約のパフォーマンス、およびコスト効率を向上させ、前モデルと比較して、最大3倍高速に動作します。」
- ChatNTQ 7B と LightChatAssistant 2x7B の日本語性能を測定する
	- https://sc-bakushu.hatenablog.com/entry/2024/04/10/191420
	- 「[ChatNTQ-JA-7B-v0.1](https://huggingface.co/NTQAI/chatntq-ja-7b-v1.0)」と、そのMoEモデル「[LightChatAssistant 2x7B](https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B)（改称あり）」について、かなり性能が良さそうな感触が得られたので、追加でテストしてみました。
	- LightChatAssistantはChatNTQとAntlerがジョグレス進化して奇跡のシナジーを起こして、ELYZATasks100ベンチで35BのCommand Rに匹敵する性能を出してしまう
	- LightChatAssistantではMistral 7B v0.2 InstructからChatVectorを抽出してたけど、もっと性能高そうなStarling-LM-7B-betaから抽出した方がいんじゃね？という事で抽出してChatNTQに足してみたら、MoEにもしてない単なる7Bモデルの時点でElyzaTasks100ベンチでLightChatAssistant超えの性能が出てしまった！Command R-35Bと同点のスコア！
- Heron-Bench: 日本語Vision＆Languageモデルの性能評価ベンチマークの公開
	- https://arxiv.org/abs/2404.07824
	- https://huggingface.co/datasets/turing-motors/Japanese-Heron-Bench
	- 日本語のVision-Langugeモデルのベンチマークがなかったので作成し、Turingで開発したheronを含めてモデルの比較を行いました~!!
- CS159: LLMs for reasoning lecture slides from Caltech
	- https://sites.google.com/view/cs-159-2024/lectures
- RTX4090+A6000(24+48GB VRAM)でcommand-r-plus-Q4_K_Mを65/65 layer GPUに載せても6.5t/sくらいが限度だった。 おそらく、96GBではメインメモリが足りないから遅い。
	- https://x.com/Meteor_Eternal/status/1779807643668013534
- an introduction to agents and tools
	- https://x.com/llama_index/status/1779898403239125198
	- This short course is the perfect beginner sequence for anyone looking to get an overview of agent implementations, how to equip them with tools to perform tasks like advanced QA/RAG or anything else, and also some neat extensions (tool retrieval, step-wise execution).
- From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples
	- https://arxiv.org/pdf/2404.07544.pdf
	- LLMに、「この入力の場合出力はこれ」という例示を入れて「ではこの入力の場合の出力は？」と推論させると線形回帰・非線形回帰ができてしまう、という論文。
- TFMC/Japanese-Starling-ChatV-7B-GGUF
	- https://note.com/bakushu/n/ne95340f04b41
	- LightChatAssistant-2x7Bの日本語チャット性能がとても良いため、モデル作者さんが用いた手法（Chat Vector+MoEマージ）を後追いで検証しているなかで、発見。
	- 7Bクラスとしてはベンチマークスコアがやたら高いモデルが出てきたので「Japanese-Starling-ChatV-7B」として公開してみました。
- HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatSkill-LAB
	- ChatVectorを使って新しいApache2.0のChatモデルを作りました。 ChatVector抽出元のモデルもMixtral-8x7B-Instructによる人工データ(Synthetic Data)で学習されたものなので、隠れたライセンス汚染の心配はありません
-  進化的アルゴリズムをもちいたChatVector加算の最適化 by　はちさん
	- https://note.com/hatti8/n/na593650d688b
	- 進化的アルゴリズムを使用するために、optunaとcmaes
	- 進化的アルゴリズムを使って、この関数のoutputであるscoreを最適化（最小化）します
		1. merging_ratio（ChatVectorの加算比率を各layer毎に持つ辞書）の定義
		2. merging_ratioにしたがって、ChatVectorのマージ
		3. ELYZA tasks 10の実施とGPT4による評価
- Foundational Challenges in Assuring Alignment and Safety of Large Language Models
	- https://llm-safety-challenges.github.io/
	- 2024.4.15 Cambridge大学のU. Anwar, D. Krueger氏ら40名弱の国際チームによる、LLMのアライメントと安全性の未解決問題に関する175ページの総説論文。
	- 1）LLMの科学的理解、
	- 2）訓練手法や実装場面の課題、
	- 3）社会における課題に分け、
	- 広範な文献調査に基づき200超のリサーチクエスチョンを同定。
	- このAnwar+2024論文はすごい。「LLMの何が技術的・社会的な問題になるのか？」を包括的に洗い出し、かつリサーチクエンションのリストに落とし込んでいる。by maruyamaｓあｎ
- Running WizardLM-2 8x22B Q4_0 locally via ollama
	- https://x.com/ivanfioravanti/status/1780133719707197643
	- On an M2 Ultra I get: ~19.5 tokens/s
	- 80Gb??
- MaziyarPanahi/WizardLM-2-8x22B-GGUF(Q4_K_M)
	- https://x.com/alfredplpl/status/1780110628864274576
	- うーん日本語がやはりイマイチだな
- WizardLMの作り方
	- https://x.com/WizardLM_AI/status/1779937307690471834
	- 新しいWizardLM-2 7BのサイズでMT-BenchがClaude-2より高いってすごい by はち
- WizardLM: Empowering Large Language Models to Follow Complex Instructions
	- https://arxiv.org/pdf/2304.12244.pdf
	- 課題：様々なレベルの複雑さを持つ大量の指示データを作成することは、時間と労力がかかる。
	- 解決：Evolve Instruct方法を使用して、LLM自体が指示データを生成する新しいファインチューニング
- Introducing the Batch API: save costs and get higher rate limits on async tasks
	- https://platform.openai.com/docs/api-reference/batch
- Introducing Idefics 2
	- https://huggingface.co/collections/HuggingFaceM4/idefics2-661d1971b7c50831dd3ce0fe
	- An 8B Vision-Language Model - literally punching above its weight.
- Pytorchからファインチューニング用の機能torchtuneが公開
	- https://pytorch.org/blog/torchtune-fine-tune-llms/?utm_content=289842551&utm_medium=social&utm_source=twitter&hss_channel=tw-776585502606721024
	- llama3のファインチューニングをこれでやったんだと
-  AI科学の何が“哲学”の問題になるのか　～問いマッピングの試み～
	- https://speakerdeck.com/rmaruy/aike-xue-nohe-ga-zhe-xue-nowen-ti-ninarunoka-wen-imatupingunoshi-mi
	- まるやまさん
-  「AI協働時代に研究者はどう生きるか」(4/26)
	- https://share.hsforms.com/1NFOzzuNBSZq3K20gtPZ30wdxf90
	- 本イベントでは、研究の自動化・自律化が益々加速していく未来において、研究という営みがどのように変化していくのか、その中で研究者はどう生きるべきか、ということについて議論します。  
	- AIロボット駆動科学を牽引する一杉太郎さんと、AI科学を俯瞰的に考える丸山隆一さんによる特別パネルディスカッションや、「AI × ◯◯学」をテーマに月額支援型クラウドファンディングに挑戦中の若手研究者8名のプレゼンを通して、「AI協働時代に研究者はどう生きるか」、皆さんも一緒に考えてみませんか？
- 生成AIでGPUがいらなくなる？　業界を揺るがす「1ビットLLM」とは何か、識者に聞いた
	- https://www.itmedia.co.jp/aiplus/articles/2404/16/news064.html
	- ではそもそも“1bit”とは何が1bitなのか、どうして1bitになるとGPUが不要になるのか。LLMでGPUが不要になるとどんな世界が訪れるのか。オーダーメイドによるAIソリューション「カスタムAI」の開発・提供を行うLaboro.AIの椎橋徹夫CEOに聞いた。
	- **椎橋：**今回の結果から、LLMの推論において、GPUではなく別の半導体の機構が最適になって、劇的に計算が軽く早くなる可能性が開けてくるんです。
	- 論文中でも、GroqというLLMの推論に特化したLPU（Language Processing Unit）の登場に触れられています。次世代半導体での復活を狙う日本の産業にとっても、注視していくべきトピックではないかと思います
- この前調合した改造Swallow-MX（継続日本語学習+instructionベルトル強化）とMixtral 8x22Bを比較すると短時間使用では差異捉えにくいな それだけ8x22Bの日本語能力アップしてるのは間違いない
	- https://x.com/AiXsatoshi/status/1778630270486552619
- Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行
	- https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_AI-Index-Report-2024.pdf
	- 2024.4.16 Stanford人間中心AI研究所（HAI）から恒例の「AI Index Report 2024」を発行。昨年から大幅に増量した500ページ超の紙幅にて、AI研究の論文数・特許・先端モデルの開発動向・投資額・経済的インパクト・科学や教育への影響・ガバナンス・社会受容など包括的に報告。
	- 「AIは人間より高性能だが一部のテストでは人間の方が優秀」「高性能AIの学習コストは数百億円」など
- HuggingFaceM4/idefics-8b
	- https://huggingface.co/spaces/HuggingFaceM4/idefics-8b
	- 明確に商用利用可能なマルチモーダルモデルのデモ
-  Google Colab で idefics2 を試す by npakaさん
	- https://note.com/npaka/n/n032c2bbaadb4?sub_rt=share_h
	- 「Idefics2」は、テキストと画像を入力し、テキストを出力するマルチモーダルモデルです。画像の質問応答、視覚的コンテンツの説明、複数画像をもとに物語作成、文書からの情報抽出などを実行できます
- AIの処理能力､1年で25倍　死蔵の｢知能資本｣が競争力に by shi3zさん
	- https://www.nikkei.com/prime/digital-governance/article/DGXZQOUC092UR0Z00C24A4000000
	- そのような世界で価値を高めるのは、死蔵された書籍や動画などの「知能資本」という。「AI資本主義」という新たな経済の姿を提唱する、
-  MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents
	- https://arxiv.org/abs/2404.10774
	- RAGなどエビデンスに基づいて LLM に生成させる場合にそもそも生成したものがエビデンスに基づいて生成できているのか（ファクトチェック）が課題になりますが、それを効率的に行うモデルを学習するシステム MiniCheck の提案。
	- GPT-3.5/4を用いて、人が書いた文章をもとにFACTを抽出したり要約生成をしたりしながらファクトチェックタスクに特化した高品質な合成データを生成し、それを用いて小さなモデルを学習することで、GPT-4と同等の性能で400分の1以下のコストでファクトチェックができるようになったそうです。
- RAGを複雑な質問に強くする手法「CoA」について
	- https://zenn.dev/knowledgesense/articles/508187f1c616e3
	- 「Chain-of-Abstraction (CoA) Reasoning」
	- CoAが従来のRAGよりも力を発揮できるシーンは、ユーザーの質問が「複数の知識を組み合わせなければ正答できない」ような質問だった場合です。通常のRAGでは1回のドキュメント検索で回答に使えるドキュメントを見つけようとしますが、CoAでは、問題（ユーザーからの質問）を複数の問題に分解し、複数回のドキュメント検索を行った上で総合的な回答を生成できます
- Qwen/Qwen1.5-7B-Chat-GGUF
	- https://huggingface.co/Qwen/Qwen1.5-7B-Chat-GGUF
	- 7 billion parameters coding chat model (~5GB RAM needed)
-  1BitLLMの実力を見る by shi3zさん
	- https://note.com/shi3zblog/n/ndd1f27fff31c?sub_rt=share_pb
	- 普通のHuggingFaceのお作法とはかなり違うので注意が必要。  まず、このHuggingFaceリポジトリを丸ごとgit cloneする
	- これをやらずにいつもの凡例みたいにいきなりpipelineに読み込もうとすると謎のエラーが出て悩まされることになる。海外でも悩んでる人が何人もいるみたいだ。まあ個人的には「こんな説明で誰がわかる?」と思うが。
- mistralai/Mixtral-8x22B-Instruct-v0.1
	- https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1
	- Mixtral-8x22B Instract きたわ〜
- Build RAG, Function Calling, and Agents with llama_index and  MistralAI8x22b 
	- https://docs.llamaindex.ai/en/latest/examples/cookbooks/mistralai/
- 24/04/18 ローカルでCommand RやCommand R+を動かす時の作法
	- https://six-loganberry-ba7.notion.site/24-04-18-Command-R-Command-R-ff8455f1dba543168d5a7768705e0043
	- 実はCommand Rはプロンプトにチャットテンプレートを使用しないと正しく回答が返ってこないらしい
	- <|START_OF_TURN_TOKEN|><|USER_TOKEN|>Who are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>
	- チャットテンプレートのあるなしで回答のクオリティは天と地ほど違ってくるから注意しよう。
- Introducing Meta Llama 3:
	- https://ai.meta.com/blog/meta-llama-3/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=llama3
	- the most capable openly available LLM to date.
	- Llama3のリリース第一弾は8Bモデルと70Bモデル！それぞれベースモデルと指示チューニング版があり！HuggingFaceからＤＬできる！8BモデルはベンチでMistral-7BやGemma-7Bを撃墜！70BモデルはGeminiPro1.5やClaude3Sonnetを撃墜！人間による評価でもSonnet、MistralMedium、GPT-3.5に勝利！
	- Context長は8kTokenでパラメータ数は80億と700億パラメータ。なんと4000億パラメータを超えるモデルも学習中！700億のほうは現在のフロンティアModelに性能的に肉薄しつつある状態。
- LangChain x Mistral RAG Agent Cookbooks + Video
	- https://x.com/LangChainAI/status/1780994907903263159
	- With the release of new Mixtral 8x22B, there's high interest in building agents with open source LLMs.
- VARIATIONAL BAYESIAN LAST LAYERS
	- https://arxiv.org/pdf/2404.11599.pdf
	- Neural Networksの最終層以外は固定されていると思って、最終層のみの 1-layer な Bayesian Neural Network としてモデル化し最終層の最適化をしつつ変分ベイズ推定する枠組み Variational Bayesian Last Layers （VBLL）の提案。
- Reliable, fully local RAG agents with Llama3
	- Here, we show to how build reliable local agents using LangGraph and Llama3-8b from scratch.
	- https://github.com/langchain-ai/langgraph/blob/main/examples/rag/langgraph_rag_agent_llama3_local.ipynb
- 例のSRAMメモリのAIチップを山盛りに積みまくった構成のGroqのサイトでLlama3-70Bが300t/sの超絶爆速推論
	- https://x.com/umiyuki_ai/status/1781529537102352827
-  Many-Shot In-Context Learning
	- https://arxiv.org/abs/2404.11018
	- プロンプトに数百〜数千の例を含めてLLMにタスクを行わせる『Many-shot（多ショット）』がDeepMindにより検証されています
	- 結果、基本的に例が多くなるほど性能が上がるとのこと。事前学習による思い込みを覆すことも。人間製の例がなければモデル生成の例でも効果あり
-  [llama.cpp：iMatrix量子化は日本語性能にどう影響するか？](https://sc-bakushu.hatenablog.com/entry/2024/04/20/050213)
	- 量子化時のモデル劣化を抑制する重要度行列（iMatrix; Importance Matrix）計算の話題です。
	- 最近はHuggingFaceにアップされるGGUFも多くがiMatrix版となっていますがこれらの量子化でよく使われているiMatrix計算用データセットは以下の2種類のようです。
- MLX で Llama 3 を試す
	- https://note.com/npaka/n/n21fa74396545?sub_rt=share_h
- Llama 3がGroqに登場
	- https://x.com/kyo_takano/status/1781595042840559908
	- Groqがなぜこんなに速いのか？それはGPUではなくLLMに最適化されたASICを使っているからです。Groqは最近新しいデータセンターを作ったばかりで、そこで何個ASICを使っているのか直接聞いたら700個以上と答えてくれました、今後リアルタイム性需要が高まるとGroqはさらに急成長してくると思います。
- 小さい計算コストでスマートにLLMをチューニング!-Hugging Face PEFT入門(前編)
	- https://zenn.dev/elith/articles/3ec1d319c8a40f
	- パラメータ効率の良いFine Tuning手法(Parameter-Efficient Fine Tuning、 PEFT)について、サーベイを行いました。
- With the latest MLX, 4-bit Llama 3 8B runs nicely on an 8GB M2 mini.
	- https://x.com/awnihannun/status/1781345824611680596
	- 512 tokens at 18.8 toks-per-sec
- cl-nagoya/auto-wiki-qa
	- https://huggingface.co/datasets/cl-nagoya/auto-wiki-qa
	- 東工大のSwallow-MXを用いてWikipediaのテキストに基づく質問と回答を生成させたデータセット AutoWikiQA をHuggingFace上に公開しました！
	- 約240万事例と日本語QAデータセットの中でも最大規模かつ高多様性なデータセットです
- The Oxford Handbook of AI Governance
	- https://global.oup.com/academic/product/the-oxford-handbook-of-ai-governance-9780197579329?cc=jp&lang=en&
	- AIガバナンスのオックスフォードハンドブック。49本通読する人出る　by 生貝先生
- lama-3-8b's in-context learning is unbelievable.
	- https://www.reddit.com/r/LocalLLaMA/comments/1c7r2jw/wow_llama38bs_incontext_learning_is_unbelievable/
- いちばんやさしいローカル LLM
	- https://note.com/schroneko/n/n8b1a5bbc740b#57403f33-7b40-444e-9342-c8bf11458d18
	- ローカル LLM 初めましての方でも動かせるチュートリアル
	- Ollama を使えば簡単に LLM をローカル環境で動かせる
- Crystalcareai/llama-3-4x8b
	- https://huggingface.co/Crystalcareai/llama-3-4x8b
	- This is an MOE of Llama-3-8b with 4 experts. This does not use semantic routing, as this utilizes the deepseek-moe architecture. There is no routing, and there is no gate - all experts are active on every token.
	- 予想はしてたけど、もうLlama3のMoEができてる　by はち さん
-  Google Colab で Llama 3 のファインチューニングを試す
	- https://note.com/npaka/n/n315c0bdbbf00?sub_rt=share_h
	- 今回は、ござるデータセットで学習します。AIが「我、りんえもんは思う。◯◯でござる。知らんけど。」的な口調になります。
	- 練習として500ステップだけ学習します。指示に応じて、wandbのAPIを入力してください。8分ほどで学習完了します。
	- 我、りんえもんは思う。 マミは一番かわいい。知らんけど。
	-  HuggingFace Hubへのアップロード
		- (1) LoRAアダプタをベースモデルにマージ
		- (2) 「HuggingFace Hub」のメニュー「New Model」を選択。
		- (3) HuggingFace Hubのリポジトリの作成。
		- (4) HuggingFace Hubへのアップロード
-  統計学を哲学する
	- https://www.unp.or.jp/ISBN/ISBN978-4-8158-1003-0.html
	- 書評（丸山隆一）
		- “…… 科学の最も基本的なツールである統計学を哲学的に分析する。ベイズ統計、仮説検定、機械学習、因果推論などの統計学的手法を科学者が使うとき、何が暗黙の前提となり、何が正当化の根拠になっているのか。哲学的認識論の道具立てによる本書の整理は鮮やかだ。深層学習に関する議論は、どのような意味で AI に科学ができるのかという大問題にもつながる。「AI 科学の哲学」の始動を感じる。……”


## 4/15

今週も強烈だった。頭がくらくらするが、気のせいか重み転移系が多い気がする。MiniCPM-2B、「μトランスファー」という手法で小規模LLMで最適化されたパラメータを大規模LLMに転移する技術で（２段階トレーニングと呼ばれてる？）、2.4Bパラメータという小さなサイズでMistral-7Bと肩を並べるとか。Command R+も量子化されたものが評価されて、Mac(M3、128G)や、A100(80G)で結構サクサクうごくらしい。特に、 「Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作」ってのは、A100持っている人はぜひ試してみるべき。 Command R+に影響されたのか、MistralもMixtral-8x22Bをオープンソースとして発表、さっそくこれをベースにexpertsをマージしてmistralにした勝手版Mistral-22Bが出て、双方量子化版が出て、、、とあっという間に広まって何が何だか。LLM同士の機能のベクトル演算であるChat Vector、まねしてMath強化版をつくって、これらを融合した結果、数学能力をある程度維持しつつ、Chat能力も強化することができるという話もあった。LightChatAssistant 2x7BてのもMistral7Bモデルをベースとした日本語対応モデル 2をChatVector手法で対話能力強化してmergekitでMoE化したもの。32kのContextSize対応、iQ3_XXS量子化でVRAM12GBでフルロード可能、RTX3060でも動くとか。JetMoEという新しいアーキテクチャ、MoEであることに加え、MiniCPMに倣った2段階トレーニングの効率が極めて高くそれでいて性能はLlama-7B並みとか。Googleの新しいリカレントアーキテクチャRecurrentGemma、リカレントニューラルネットワークとローカルアテンションを活用してメモリ効率を向上さているらしい、今後もGemmaとパラレルにリリースするのか。GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」てのもあった、Gemma-2Bに追加学習して「Function Calling」を強化したとのこと。それから、今週はGoogle Cloud Next24があったので、最大100万トークンのGemini 1.5 Proのリリースや、DeepMindのImagen 2、TPU v5pの発表、GoogleDocにGeminiの統合とか、geminiでRCカーを制御とか面白い出し物があった。日本語LLM 9種を量子化して回答内容を比較ってのも面白かった、ELYZAは偉いぞ。LangChain の Tool Calling 標準インタフェース ってLLMに依存しないということなので、エージェントとかの活用が加速しそう。QR分解でカルマンフィルターってのは目からうろこだ、一見異なる枝がエレガントにつながる、これぞサイエンスの醍醐味だ。

- MiniCPM: Unveiling the Potential of End-side Large Language Models
	- https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20
	- 既存7B LLMより強いと話題の2B LMMのMiniCPM
	- μP使って小さいモデルで効率的にハイパーパラメータ探索
	- MiniCPM is a series of edge-side large language models, with the base model, MiniCPM-2B, having 2.4B non-embedding parameters. 
	- It ranks closely with Mistral-7B on comprehensive benchmarks
- 現状のLLM選択肢 by urawazakun
	- https://x.com/urawazakun/status/1777130873844040046
	- commandRplus　108B →Mac 進化的（988000円）
	- commandR　35B →RTX4090（PC + 40万円～）
	- LightChatAssistant2x7B →RTX3060（PC + 3万円～）
-  EasyLightChatAssistant
	- https://github.com/Zuntan03/EasyLightChatAssistant?tab=readme-ov-file
	- EasyLightChatAssistant は軽量で検閲や規制のないローカル日本語モデルの LightChatAssistant を、KoboldCpp で簡単にお試しする環境です。
- ｢LLMはコモディティー｣　米データブリックスCEOが語る
	- https://www.nikkei.com/article/DGXZQOGN252JK0V20C24A3000000/
	- LLM単体ではなくLLMやその他のモジュールを組み合わせて問題を解く「複合AI」の考え方がとても大事
-  Octopus v2: On-device language model for super agent
	- https://arxiv.org/abs/2404.01744
	- https://huggingface.co/NexaAIDev/Octopus-v2
	- GPT-4超え精度でスマホ上実行できるオンデバイス生成AI「Octopus v2」
	- 20億パラメータを持つエッジデバイス上で機能するオンデバイスAIモデル「Octopus v2」
- Google Colab で Octopus V2 を試す by npakaさん、
	- https://note.com/npaka/n/n706bde979ed8
	- Gemma-2Bを追加学習したモデルで、学習ステージと推論ステージの両方に独自のFunctionトークン戦略を導入することで、「Function Calling」において「GPT-4」に匹敵する性能を達成したとのことです。
	- ユースケースとしては、「カレンダーにリマインダー追加」「メッセージ送信」「Youtube検索」の指示などが挙げられています
- Chat VectorとMath Vectorは併用できるのか by はちさｎ
	- https://note.com/hatti8/n/n2d6d86d6f05a?sub_rt=share_h
	- Chat+Math能力の両方を日本語ベースモデルに付与したら、どちらの効果も得られるのか
	- Math強化モデルに先ほど作ったChat Vectorを重ねがけしていきます
	- Math強化モデル：Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vector：SkillTree-Chat-Mistral-7B-v0.1
	- Math+Chat強化モデル
		- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-ChatMathSkill
	- 結論
		-  **モデルが壊れることはない**
		- **数学能力をある程度維持しつつ、Chat能力も強化することができる**
		-  **一方、英語で回答しやすくなる傾向が出てくる**
- Chat VectorならぬMath Vectorは作れるのか
	- https://note.com/hatti8/n/n0000353355cb
- LangChain x DSPy
	- https://www.youtube.com/watch?v=4EXOmWeqXRc
- JetMoEってなんじゃ？ by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777014403197788280
	- Mixture of Attention heads（MoA）とMixture of MLP Experts（MoE）の二つのレイヤーに、それぞれ４人ずつエキスパートがいて、推論時は各レイヤー２人ずつが活性化する。
	- 活性化パラ数は2.2Bで、合計パラ数は8Bだって。何だか知らんけどこのアーキテクチャによってトレーニング効率が爆上がって、H100が96台で２週間、1200万円しかトレーニング費用かけてないのに、数千億かけたはずのLlama-7BやLlama-13にベンチで勝利した
- μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_b&d=s4cpuSjMMAw
	- μP（Maximal Update Parametrization）というのは、 Tensor Programs (TP)というフレームワークにおいて理論的に導出されたパラメータ付け（パラメータのスケーリングなど）の方法です
	- TP は、 Neural Networks （NN）の解析をするために、線形変換や非線形活性化関数などの NN の構築で頻出する操作をリストアップし、その枠組みで成立する事象や性質を追求するフレームワークです。
	- https://www.microsoft.com/en-us/research/blog/%C2%B5transfer-a-technique-for-hyperparameter-tuning-of-enormous-neural-networks/
- Leveraging language representation for materials exploration and discovery
	- https://www.nature.com/articles/s41524-024-01231-8
	- 言語モデルによる材料探索の論文。
	- 結晶材料をテキスト表現にし言語モデルにより既存材料に似た新熱電材料を探索
	- 特に、GPTのようなデコーダ専用モデルより、BERTのようなエンコーダ専用モデルのほうが汎用性が高くMIタスクに向いている、という点が興味深かったで
- μトランスファーとは by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777204816059711692
	- MiniCPMはミュートランスファーというテクニックが使われてるらしい。これが何か？というと、でかいLLMをトレーニングする時の最適パラメータを探るテクらしい。
	- でかいLLMを学習する時に、ハイパーパラメータをどう弄れば最強になるのか、イチイチ色々試して最適解を試行錯誤するのはメチャクチャ大変だ。そこで、同じアーキテクチャのちっちゃい版で実験すればサクサクと最適なパラメータを試行錯誤できる。で、ちっちゃいモデルで見つけた最強パラメータが、でかいLLMにそんままコピペしてもちゃんと最強になる事が判明したらしい！
- JetMoEのトレーニング効率上がったのは　 by うみゆきさん、
	- https://x.com/umiyuki_ai/status/1777023943121256637
	- Komatsuzaki氏の見解によれば、JetMoEのトレーニング効率上がったのは、たしかにMoEアーキテクチャによって２～３倍に効率化したけど、それより何よりMiniCPMに倣った2段階トレーニングの手法のおかげでバキバキに効率化したとの事。
	- 1万倍の内、MoEの貢献が３倍なら残りの3333倍はMiniCPMトレーニングのおかげなのか
- The Physics of Language Models
	- https://arxiv.org/abs/2404.05405
	- 「言語モデルは、int8 に量子化された場合でも、パラメータごとに 2 ビットの知識しか保存できません。また、そのような知識は、下流のアプリケーション用に柔軟に抽出できます。その結果、7B モデルは 14B ビットの知識を保存でき、これは私たちの推定に基づくと、英語版 Wikipedia と教科書を合わせた量を超えます。」
	- 回転埋め込みを備えた GPT-2 アーキテクチャは、知識の保存において LLaMA/Mistral アーキテクチャに匹敵するか、それを上回ります。
- Gemini 1.5 Pro
	- https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html
	- 180カ国サポート、「統一モデル」音声・動画認識、ファイルAPI、System Instructionカスタマイズ機能、 JSONモードなどが加わりました、以下で試せる
	- https://ai進化的.google.com/app/prompts/new_chat
- Imagen 2 by DeepMind
	- https://x.com/GoogleDeepMind/status/1777747320945234422
	- Imagen 2 can now create short, 4-second live images from a single prompt.
- GPT-4 Turbo launch
	- https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4
	- previewが取れた
- UNESCOがAI Ethicで人集めしている by　神嶌さん
	- https://careers.unesco.org/job/Other-cities-Consultant/791818302/d
- Llama.cpp で Command R+ をお試し中 by npakaさん
	- https://x.com/npaka123/status/1777802956571889969
	- Q4_K_M・M3 Max (128GB) 5.22 tokens per second
- mmnga/codegemma-7b-it-gguf
	- https://huggingface.co/mmnga/codegemma-7b-it-gguf
	- gemma-1.1-7bとcodegemma-7b-itのgguf
- 【LangChainゆる勉強会#3】LangChainのAgentはどれを使う？
	- https://www.youtube.com/watch?v=07TuBmm67sU
	- LangChainを使ったAgent実装を概説してくださってる勉強会のアーカイブ動画。
	- 最近はLCELで組んでAgent Excutorに投げる以外の実装しないので、なんか色々あるんだなと勉強になりました
	- XML Agentとか誰が使うん？って思ってたけど、Claudeと相性良いらしい。へぇ〜！
- rinna/youri-7b-chat-gptqとintfloat/multilingual-e5-largeでRAGするだけでもcolabよりrtx3060の方がかなり速い
	- https://x.com/rsimd_/status/1747614320878555175
	- vramが足りればって話だけど，一応faiss-cpuを使えばメモリ足りてる．
- Command R+の量子化PPLを計測してくれてる
	- https://github.com/ggerganov/llama.cpp/pull/6491#issuecomment-2043633791
	- Q3_XXSは38GBだけど、ここまでなら精度的にも全然大丈夫ちゃうか？って予感はする。IQ2_XXSなら26.6GBで、ちょっとアホになってそう。IQ1_Sなら21.6GBだけど、さすがに実用性ヤバそう。
- Perplexity Proに課金してGoogleのGemini UltraやGenerative Experienceと比較してみると、何かとんでもないことが起こっている気がする by 楠さん
	- https://x.com/masanork/status/1777478951465779344
- 完全ローカルでRAGも使えるAIチャットアプリOpenWebUIを日本語LLMでセットアップする
	- https://zenn.dev/firstautomation/articles/0b7a4b1bb2daf0
- Command R+はちゃんと強かった訳だが、Command RもこれまでのOpen-source最強のQwen1.5-72bに匹敵する訳なのですごい
	- https://x.com/Meteor_Eternal/status/1777635899204874704
- Gemini 1.5 Proの新機能 - Native Audio Understanding、System Instructions、JSON Mode、新Embeddingモデル　 by npakaさん
	- https://note.com/npaka/n/n0254081ebc23?sub_rt=share_h
- Stable LM 2 12B
	- https://stability.ai/news/introducing-stable-lm-2-12b
	- Stable LM 2 12B は、英語、スペイン語、ドイツ語、イタリア語、フランス語、ポルトガル語、オランダ語の多言語データでトレーニングされされた、120億パラメータを持つ強力な言語モデルです。 ベースモデルと指示学習済みモデルを備えています。
- GoogleDocにgeminiが統合される？
	- https://x.com/GoogleWorkspace/status/1777807449652662508
- TPU v5p, our most powerful and scalable TPU, is now generally available
	- https://x.com/GoogleCloudTech/status/1777732890471625162
- Gemma-1.1 also shows great improvement in terms of reduced hallucinations in the updated HHEM leaderbod
	- https://x.com/ofermend/status/1777695633455108478
- LLaMA 3's will start to drop next week.
	- https://x.com/mattshumer_/status/1777465835834970189
- Ride with GeminiというLLM＋RCカーのデモ
	- https://x.com/kazunori_279/status/1777846216950456658
-  Gemini 1.5 Proで文字起こしを試してみた
	- https://note.com/nyosubro/n/n07afba435ef6
	- 個人的な感想としては、Whisperレベル（あるいはそれ以上？）の文字起こし品質と論文ではありましたが、確かにそうかも！と言う感じでした。
	- またWhisperとは異なり、プロンプトレベルで様々な文字起こしタスクに柔軟に対応できる点で、結構面白さを感じてます。
- Llama.cpp で Command R+ を試す by npakaさん
	- https://note.com/npaka/n/n9136a2ebc7f9?sub_rt=share_h
	- M3 Max (128GB)
	- 「Command R+」は、「RAG」や「Tool」などの長いコンテキストタスク向けに最適化された104BのLLMです。CohereのEmbeddingおよびRerankと連携して動作するように設計されており、RAGアプリケーションに最高クラスの統合を提供し、エンタープライズユースケースで優れています。
- Wikipediaの日本語記事を元に、ユーザの質問に回答するGradioベースのRAGのサンプル。
	- https://github.com/lawofcycles/wikipedia-japanese-open-rag/tree/master
	- 使ったもの
		-   [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)
		-   [elyza/ELYZA-japanese-Llama-2-13b-instruct](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-13b-instruct)
- Command R plus推論速度、知見まとめ by AIXさとし
	- https://x.com/AiXsatoshi/status/1777867323552190876
- Amazon、「Claude 3」のAnthropicに27億5000万ドルの追加投資
	- https://www.itmedia.co.jp/news/articles/2403/28/news105.html#utm_term=share_sp
- A Generative Symbolic Music Pretrained Transformer
	- https://huggingface.co/papers/2404.06393
	- In this paper, we explore the application of Large Language Models (LLMs) to the pre-training of music. While the prevalent use of MIDI in music modeling is well-established, our findings suggest that LLMs are
- We just released Mixtral 8x22B. Super excited for this release
	- https://x.com/sophiamyang/status/1777945947764297845
- 日本語LLM 9種を量子化して回答内容を比較調査してみた
	- https://qiita.com/wayama_ryousuke/items/50e36d0dcb37f8fb7dd8
	- 量子化しても成績が下がりにくいモデルと、大きく下がるモデルがある
	- 一部のモデルは量子化すると回答が極端に短くなる
	- 量子化によって回答が短くなる度合いは、量子化前モデルの回答の長さと相関がある可能性がある
	- 個別：
		- **ELYZA-japanese-Llama-2-7B**は、量子化後もほぼ同等の性能を維持し、0.10点のスコア低下に留まりました。
		-  **Swallow-7B**では、量子化前後で成績に変化はなかった一方、**Swallow-13B**では平均スコアが 0.28 点低下しました。
		- **CALM2**  や  **StableLM-Beta**  は、量子化後のスコアが高い結果（それぞれ 0.28 点/ 0.21 点向上）となりました。
		-   **Xwin**  モデル同士を比較すると、**Xwin 7B**は0.36点の低下を示している一方、**Xwin 13B**では0.11点の向上が見られ、同じモデルファミリー内でも異なる振る舞いが確認されました。
-  Command R+ GPTQをローカルLLMとしてvllmでOpenAI API互換サーバ動作させてみた話
	- https://note.com/junzokamahara/n/n9235af7a6dc1?sub_rt=share_h
	- vllmもCommand Rに対応しているとのことで、vllmで動かしてみることにしました。なお、動かすのはGPUメモリの関係でGPTQで量子化されたモデル。
	- 使用するモデルのはHugging FaceにあるGPTQに変換したCommand R+
		- client = OpenAI(base_url="http://<仮想マシンのIP>:8888/v1")
		- response = client.chat.completions.create(model='alpindale/c4ai-command-r-plus-GPTQ',
	- Command R plus GPTQのA100 80GBでの実行例
		- 18.3 tokens/sと出ている
- Geminiの新機能「System Instructions」を使ってみる。 
	- https://x.com/npaka123/status/1777969149651906927
	- ChatGPTではおなじみな機能だけど、今までGeminiにはシステムメッセージもなかったのでうれしい。
- 『すずめの戸締まり』に登場する3本脚の椅子を再現したロボット設計
	- https://x.com/shin0805__/status/1777992583396131246
	- 強化学習による歩容生成の論文を公開しました！ 来週アメリカで開催されるRoboSoft2024にて発表します！
	- https://shin0805.github.io/chair-type-tripedal-robot/
- mistral-community/Mixtral-8x22B-v0.1
	- The Mixtral-8x22B Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts.
	- おい、これApache-2.0だぞ！GPT-4クラスが商用利用可能らしい
- MLX with LangChain
	- https://python.langchain.com/docs/integrations/chat/mlx/
	- This notebook shows how to get started using MLX LLM’s as chat models.
- Google Colab で RecurrentGemma を試す
	- https://note.com/npaka/n/n0018d60fb8b7?sub_rt=share_h
	- 「RecurrentGemma」は、Google で開発された新しいリカレントアーキテクチャに基づいて構築されたオープンモデルです。 事前学習済みモデルと指示チューニングモデルの両方が英語で利用可能です
	- 新しいアーキテクチャにより、「Gemma」よりも必要なメモリが少なく、長いシーケンスを生成する際に高速な推論を実現します。
	- 今回は、「**google/recurrentgemma-2b-it**」を使います
- LightChatAssistant-2x7Bで行われている最適化をOptuneで
	- https://github.com/Aratako/Task-Vector-Merge-Optimzier
	- Sdff-Ltba/LightChatAssistant-2x7Bで行われているようなLLMにおけるTask Vectorの加算によるマージにおいて、その加算割合の最適化をOptunaを用いて行うスクリプトです
- Infini-attention
	https://x.com/umiyuki_ai/status/1778459568424784194
	- Googleが出した論文なんだね。で、「この技術のおかげでGemini1.5では100万コンテキストウインドウが可能になったのか！」
- Safeguarded AI: 
	- https://www.aria.org.uk/wp-content/uploads/2024/04/ARIA-Safeguarded-AI-TA1.1-Theory-Call-for-proposals.pdf
	- ARIAのDavidad氏の安全保証付きAIの研究プログラムの全貌が見えてきた。彼が何をしようとしているのか、それにどれほどのfeasiblityがあるのか、誰かに解説してほしい。形式証明とか、ソフトウェア工学、計算機理論のバックグランドが必要そう。
	- 今回の公募では土台となるセマンティクス、「言語」づくりを目指すとのことで、その方法論として圏論が名指しされています
- Mixtral8x22チューニング版
	- HuggingFaceH4/zephyr-orpo-141b-A35b-v0.1
	- ORPOという新しいアライメントアルゴリズムを使用
	- ORPOは、SFTステップを必要としないため、DPOやPPOのような方法よりも計算効率が良い 
	- オープン、合成、マルチターン、LLMを介して採点さたDPOデータセット使用
- LLMによる視覚読解技術を確立～グラフィカルな文書を理解する「tsuzumi」実現に向けて～
	- https://group.ntt/jp/newsrelease/2024/04/12/240412b.html
- Embeddingsを使ってローカルでテキストをクラスタリングする（Multilingual-E5）
	- https://zenn.dev/libratech/articles/afe9c5b30668bb
- Mixtral-8x22B、LightblueさんのkarasuチューニングモデルとAWQ
	- https://huggingface.co/lightblue/Karasu-Mixtral-8x22B-v0.1
	- 強い！これは間違いなくエース級　 by AIXさとし
		- https://x.com/AiXsatoshi/status/1778489953279951132
- Introducing Mistral-22b-V.01 A breakthrough in AI
	- https://huggingface.co/Vezora/Mistral-22B-v0.1
	- First-ever MOE to Dense model conversion
	- This model is not an moe, it is infact a 22B parameter dense model!
	- mixtralのexpertsをマージしてmistralにしたやつ
- Vezoraさんが公開されているMistral-22B-v0.1のggufあります
	- https://huggingface.co/mmnga/Vezora-Mistral-22B-v0.1-gguf
- Swallowシリーズのinstruct改良版ですが、本当は2023年度中を目指していたのですが、もろもろ多忙で遅れてしまっています。
	- https://x.com/okoge_kaz/status/1778396705156943985
- mixtral 8x22bを軽くloraでファインチューニングしたら、少し、会話しやすくなりました
	- https://x.com/kanhatakeyama/status/1778417221100028061
	- 現状､mixtral 8x22bは事前学習のみのモデルですが､わりと会話できそうです｡
-  Tool Calling with LangChain
	- https://blog.langchain.dev/tool-calling-with-langchain/
	- 最近はChatGPT以外にも Function Calling (最近は Tool Calling と呼ばれることが多い) に対応するLLMが増えてきました。選択肢が増えて便利ではあるものの、各社で少しづつインターフェースが違うので実装が面倒という課題がありました。
	- そのため、LangChainは各LLMのTool Callingを統一的に扱えるインターフェースを準備しており、先日、最後のピースがハマって遂に完成したという話です。
- LangChain の Tool Calling 標準インタフェース の概要　by npakaさん
	- https://note.com/npaka/n/ne6fd5929bfa1?sub_rt=share_h
	- 「Tool Calling」の標準インターフェイスの構成は、次のとおりです。
		- ChatModel.bind_tools()ツール定義をモデルにアタッチするメソッド
		- AIMessage.tool_callsモデルが決定したツールの情報を伝えるプロパティ
		- create_tool_calling_agent()Tool Callingを利用するエージェントのコンストラクタ
- OpenEQA (オープン語彙の具体化された質問応答ベンチマーク)
	- https://ai.meta.com/blog/openeqa-embodied-question-answering-robotics-ar-glasses/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=dataset
	- バッジをどこに置いたか?」などのオープン語彙の質問
	- 物理環境に対する AI エージェントの理解度を測定
- A Square-Root Kalman Filter Using Only QR Decompositions
	- https://arxiv.org/abs/2208.06452
	- QR分解でカルマンフィルター？
	- 正定値行列の和の平方根が平方根のブロック行列のQR分解で計算できることを利用して、数値的安定性の高いカルマンフィルタ（平方根フィルタ）のアルゴリズムをQR分解でシンプルに書けるのか
- Premise Order Matters in Reasoning with Large Language Models
	- LLMにプロンプトを与える際、「推論ステップの流れに沿う順序」で文脈を与えないと30%以上精度が落ちる恐れがあることをDeepMindが報告しています。
-  Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese
	- https://arxiv.org/abs/2404.07824
	- 画像-言語モデルの日本語ベンチマークとして、新しく「Heron-Bench」を公開しました！日本の画像で、日本に関する知識を総合的に問います
- Rho-1: Not All Tokens Are What You Need
	- https://arxiv.org/abs/2404.07965
	- Microsoftお得意の高品質テキストで効率よく事前学習するアプローチの最新論文、トークン単位のlossの推移を高いまま・低いまま・減少傾向・増加傾向の4タイプに分類していて面白そう。実際に学習トークンを選ぶ部分を勉強しよう。
	- https://huggingface.co/microsoft/rho-math-7b-v0.1
- GeminiによるRAGの実践例
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/use-cases/retrieval-augmented-generation
- Gemini API の ファインチューニング を試す by npakaさん
	- https://note.com/npaka/n/n6609bcbbdd30?sub_rt=share_h
- 「カルマンフィルターをQR分解で解く手法」
	- https://github.com/kevin-tracy/QRKalmanFilter
	- Square root Kalman Filter using only QR decompositions.
	- related paper: Differentiable Collision Detection for a Set of Convex Primitives
	- https://arxiv.org/abs/2207.00669
- Can Gemini 1.5 actually read all the Harry Potter books at once?
	- https://x.com/deedydas/status/1778621375592485076
	- All the books have ~1M words (1.6M tokens). Gemini fits about 5.7 books out of 7. I used it to generate a graph of the characters and it CRUSHED it.

## 4/8

今週も情報が早すぎて大過ぎて、もやは追いつけません。RAG向けのベクトルDBのベンダーかと思っていたCohereから、オープンソースのCommand R+ がリリース、まあ成り立ちから当然、RAGとかロングコンテキストに最適化さている。104Bでパラメータも公開、テスト版がhuggingfaceで試すこともできる、GPT-4並みの性能でOSSってやばくないか。早速量子化したり、MLXで動かしたりと、やばくないか。ある性能以上のLLMのオープンソース化禁止みたいな傾向に拍車がかかるのでは。AppleからはReALM発表、どうもSiriの代わりにiPhoneでも動く軽量なモデル、そういえばSiriの人員が解雇されたというニュースもあった。スタンフォードやCMUの一流大学でもCSの修士の就職率が２割とのこと、まあ10年でCS修士取得者が10倍になったという要因もあるようだが、LLMをコンパイラとして使うっていう時代、普通のCS修士程度ではもやは、お呼びではないということか。OpenAIは、日本にアジア初の拠点を開設、なぜか住所は西新橋の雑居ビル。Gemmaの1.1のリリースとかQwen1.5-32B のリリースなど、重要な改良リリースも進む。RAGではReranker が話題に、類似度の高いチャンクを選択したはずなのに、そのあとにRerankするのか。。対応するLLMもいくつか出てる。日本語モデルでは、Swallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルという話もあったが、Mistral 7Bベースの２つの日本語LLMをChat Vector法で強化したものをMoEした、とても長い名前のモデルが話題に、寿限無か。大規模言語モデル開発のための日本語 Instruction データセット作成とか、NLP2024のチュートリアルから、作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコードの公開とか、日本のLLM層の底上げも進む。 アマゾンのBezos氏も投資していると話題となったPerplexity、AI検索が次のビッグウエーブということらしい、GoogleのAI検索も確かにPerplexity風になっているし、GoogleのAI検索は有料化という報道も。もともとBingってPerplexityのような仕組みじゃなかったか。Mixture-of-Depthsとか、ファインチューニングのReFTとか、GRIFFIN とか、新しいLLM最適化の知見が次々にでてきたが、なんといっても、今週はChat VectorというLLMの足し算引き算ができる技術、word2vecのようなベクトル計算がLLMでもできるなんてすごすぎる。Chat Vectorで強化してMoEで、、みたいなのが主流になるかも。Claude3でfunction callingがサポート、さっそくlangchainから、Claude3をつかったエージェント実装が出た、まあ能力からしてそうなるわな。BAAIのMetaWorm論文、線虫を研究して、身体性の謎を解決？Reranker でもBAAI出てきたし、もう中国も、力任せで優れたLLMを出すだけではなく、理論でも、ということか。三値のBitNetの情処の解説、「精度の逆転」というのがあるのか、もし本当ならば、たしかにこれはゲームチェンジャーだな。


- ビジネスの実務で「因果」を推測するということ by TJOさん
	- https://tjo.hatenablog.com/entry/2024/02/28/174811
	- 「とりあえずマーケットの中にふんわりと存在する」系の指標に対して、そのようなきちんとした因果推論を行うのは結構難しい印象があります。
	- 一つの考え方として「時系列的な因果性」をふわっとした代用品として用いるという方法もあり得ると思っています。そう、VARモデルです
	- 即ち実際の因果は「落雷→雷鳴」だが、時系列的には「（落雷→）稲光→雷鳴」が成立するので代用品になり得る、という
- 翻訳モデルHonyaku-7b by AIXサトシ
	- aixsatoshi/Honyaku-Multi-Translator-Swallow-ms7b
	- 数百〜数千tokenの文章翻訳 
	- 英日、日英翻訳機能がメイン
	- XML like instruction
	- 一部の多言語も対応
	- Swallow-ms-7b baseで日本語堪能
- 大規模言語モデル開発のための日本語 Instruction データセット作成の取り組み
	- https://speakerdeck.com/kunishou/da-gui-mo-yan-yu-moderukai-fa-notamenori-ben-yu-instruction-detasetutozuo-cheng-noqu-rizu-mi
- 【OpenAI】日本にアジア初の拠点を開設、法人向けサービス提供へ
	- https://www.nikkei.com/article/DGXZQOUC29A7U0Z20C24A3000000/?n_cid=SNSTW001&n_tw=1711923970
	- OpenAIが4月中に東京都内にアジア初の拠点を立ち上げ、日本での事業活動を本格化させる
	- 事務所は西新橋の雑居ビル？？
-  Mechanistic Design and Scaling of Hybrid Architectures
	- https://arxiv.org/abs/2403.17844
	- LLMのモデル設計は時間とコストがかかる。これを解決するため人工的なベンチマークタスク MAD（in-context recall, compression等）を設計。小規模MADで評価した結果を元に有望な手法を絞りスケールさせる。多くが小規模MADの性能とスケール後の性能に相関がみられた
- LLMの現在
	- https://speakerdeck.com/pfn/llmnoxian-zai
-  MetaWorm: A Complete Model Bridging Brain, Body and Environment of  _C. elegans_
	- https://www.biorxiv.org/content/10.1101/2024.02.22.581686v1
	- BAAIの研究、生物の脳、身体、環境の間の複雑な相互作用を線虫（C. elegan）を材料に解析
- 「Babylon.js 7.0」正式リリース。
	- https://www.publickey1.jp/blog/24/web3dbabylonjs_70mmdmikumikudanceapple_vision_pro.html
	- マイクロソフトは、Webブラウザ上で2Dや3Dモデルの高速なレンダリングなどを可能にするオープンソースのJavaScriptライブラリ「Babylon.js」の最新版「Babylon.js 7.0」正式版をリリースしました。
	- MMD（MikuMikuDance）のインポートと利用を可能にするMMDローダーとランタイムが追加されました。IKソルバ、オーディオ同期再生、プレイヤーコントロールなどの機能も用意されています。
- CMUもStanfordもColumbiaもCS修士のインターン内定率2割
	- https://x.com/fzw1212/status/1774218929100988506
-  LLaMA Now Goes Faster on CPUs
	- https://justine.lol/matmul/
	- 84 new matrix multiplication kernels for llamafile
	- between 30% and 500% faster when using F16 and Q8_0 weights on CPU. 
- Gecko: Versatile Text Embeddings Distilled from Large Language Models
	- https://huggingface.co/papers/2403.20327
	- Googleから、Gecko組み込みモデル、LLMを蒸留した？？謎
	- LLMを使って学習用のペアデータを作ってEmbedding Modelの学習をした後、このモデルに寄り得られた関連パッセージに同じLLMでPositive/Hard Negativeのラベルを振り直して追加学習しているらしい。
- LMFlowでLlama2-70BのLISAファインチューニングがあっさり動いた by shi3zさん
	- https://x.com/shi3z/status/1774710763007119735
	- 大体30GBあれば学習できるとすればA6000でも可能ということか?
-  Google Colab で BAAI/bge-reranker-v2-m3 を試す by npakaさん
	- https://note.com/npaka/n/n7d251f76ce25?sub_rt=share_h
	- 「BAAI/bge-reranker-v2-m3」は、「bge-m3」ベースの「Reranker」モデルです。「Reranker」モデルは、従来の「埋め込み」モデルとは異なり、質問とドキュメントを入力として受け取り、類似度を出力します。
	- 「パンダとは？」の質問には「パンダは中国南西部の山岳地帯に生息する哺乳類の一種です。」のドキュメントが関連していることがわかります。
- Building a RAG application using open-source models by langchain
	- https://x.com/LangChainAI/status/1774821270900629950
	- https://github.com/svpino/llm/blob/main/local.ipynb
	- https://www.youtube.com/watch?v=HRvyei7vFSM
- Claudeだと本当に一瞬で以下のようなアーキテクチャ図を作ってくれる。
	- https://x.com/ai_syacho/status/1774677348807483788
- Octree-GS: Towards Consistent Real-time Rendering with LOD-Structured 3D Gaussians
	- https://github.com/city-super/Octree-GS
	- https://x.com/janusch_patas/status/1774717184238883237
- 『Google検索を超える衝撃の生成AI型新検索エンジン：Perplexity Proが情報収集を変える！』
	- https://x.com/tetumemo/status/1774632484648730889
	- Perplexity のようなAI検索が、つぎのビッグウエーブというか、active personal noteだよな。AI検索を有料にするという動きもある。
- BItNet-Transformerの学習済みモデルが公開されている
	- 1bitLLM/bitnet_b1_58-large
- NLP2024 チュートリアル３: 作って学ぶ日本語大規模言語モデル - 環境構築手順と実験ソースコード
	- https://github.com/hiroshi-matsuda-rit/NLP2024-tutorial-3
	- 日本語LLMの学習・評価に用いられる技術とデータセットについて広く取り上げています。是非ご覧ください。
	- 講演スライドと実験環境構築手順・ソースコードはGitHubリポジトリで公開しています
	- リクルートの松田寛さん
- 東工大のSwallow MX 8x7bは現状ローカルLLMでは日本語最高のモデルだろうね…
	- https://x.com/Meteor_Eternal/status/1775096408435216766
- OSS Models + LangGraph.js
	- LangGraph helps you create LLM apps that closely match the logical flows used to solve a problem.
	- https://github.com/langchain-ai/langgraphjs/blob/main/examples/chatbots/customer_support_mistral.ipynb
-  Mamba Explained
	- https://thegradient.pub/mamba-explained/
	- Mambaの選択機構を注意機構との比較やアナロジーを用いながら直感的に説明した記事。 
	- 文脈内学習ではTransformerのようにプロンプトに全ての情報を入れる必要がなく、状態（システムプロンプトなどを圧縮したもの）と質問を渡すだけで良い。
- Bigger is not Always Better: Scaling Properties of Latent Diffusion Models by Google
	- https://huggingface.co/papers/2404.01367
- Prompt-prompted Mixture of Experts for Efficient LLM Generation
	- https://arxiv.org/abs/2404.01365
	- LLM への入力ごとに、LLMの各レイヤーでのアクティベーションの相対的な大きさが、トークン位置によらず一部の次元に偏る flocking という現象を発見し、これをもとに、
	-  (1) prompt 入力次点でアクティベーションが相対的に大きい次元を特定
	-  (2) その次元のみを使って近似的/効率的に Decode を行う、
	- GRIFFIN (Gating by Repetition In Feedf orward Intermediate Neurons) を提案。 タスクに依存するが、学習不要な方法で精度をあまり落とさず生成を高速化できる。
-  Are large language models superhuman chemists?
	- https://arxiv.org/abs/2404.01475
	- 「化学分野の幅広い 7,000 以上の質問と回答のペアを厳選し、主要なLLM を評価しました。その結果、私たちの研究では、最良のモデルが平均して最良の人間の化学者を上回るパフォーマンスを示した」
-  LlamaIndex の Reranker を試す by npakaさん
	- https://note.com/npaka/n/n8f9ee8533896?sub_rt=share_h
	- RAGにおける「Reranker」は、取得したチャンクの中から、質問に対して最も関連性の高い情報を持つチャンクを選択する役割を担っています。
	- 今回は、多言語のRerankerモデル「**BAAI/bge-reranker-v2-m3**」を使います。top_n=5で関連性の高い5件に絞ります。
-  Semantic Routerを試す
	- https://zenn.dev/kun432/scraps/73b098e774bd21
	- LLMやエージェントの意思決定のルーティングを行うSemantic Routerを試してみた。ルーティングだけじゃなく、セマンティックなチャンク分割にも使える。 ベクトル検索の使い方はいろいろな可能性がありそう。
	- クエリで処理を分岐させたいようなケースは、Function Callingを使ってLLMにルーティングさせるとかがあると思うのだけど、事前にクエリのサンプルを用意しておいてベクトル検索でルーティングさせるというようなもの。
	- LangChainのエージェントと組み合わせた例。
- 4/23(火)に、Sakana AI初のイベントやります！Grow-AI、Arayaの方々と我々のトークがあります
	- https://x.com/iwiwi/status/1775367258040410519
- 2x7Bの日本語チャット・ノベル専用高性能モデル。
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Antler-7Bとchatntq-ja-7b-v1.0という、Japanese Stable LM Base Gamma 7B（Mistral 7Bベース）をinstructionチューニングしたモデルを各々ChatVector法で強化し、MoEでマージしたのだそうだ
- RankZephyr is a nice 7B model 
	- https://arxiv.org/pdf/2312.02724.pdf
	- that is optimized for list-wise zero-shot reranking
	- https://docs.llamaindex.ai/en/stable/examples/node_postprocessor/rankLLM/?h=rankllm
- intelligent notetaking by https://iki.ai/
	- https://iki.ai/
	- a cool example of an AI-enabled notetaking interface that epitomizes the core value prop of RAG - dump in a ton of your messy, unstructured data (files, links, notes), and have the application organize and surface information for you instead of you having to do it yourself.
-  Google Colab で japanese-reranker-cross-encoder-large-v1 を試す by npakaさん
	- https://note.com/npaka/n/n906b23636ac8?sub_rt=share_h
	- 「 japanese-reranker-cross-encoder-large-v1」は、日本語に特化した形で学習した「Reranker」です。xsmallからlargeまで複数のサイズが提供されており、「large」は多言語Rerankerで最も人気のある「bge-reranker-v2-m3」をベンチマークで上回っています。
	- クエリと文章の準備と、スコアの計算。
- Anthropic Messages API
	- https://x.com/AnthropicAI/status/1775979799644934281
	-  Claude3にfunction callが来たという話
- Cohereのパラメータ公開LLMのCommand R+
	- https://x.com/_kaiinui/status/1775920565720949090
	- たしかにGPT4-Turboと比較してもよいレベルのLLMに見える
	- サイズは104B、CC-BY-NCだがパラメータはHFで公開 104B動かせるマシンがあれば、だれでも知能(らしきもの)を保有できるってやばいな
- Command R+ by Cohere
	- https://txt.cohere.com/command-r-plus-microsoft-azure/
	- https://huggingface.co/spaces/CohereForAI/c4ai-command-r-plus
	- だだものではない。
-  LlamaIndex <> MistralAI Cookbooks
	- https://github.com/mistralai/cookbook/tree/main/third_party/LlamaIndex
	- Here’s a definitive set of cookbooks to build simple-to-advanced RAG, agentic RAG, and agents in general with MistralAI
- Groq tool calling + structured output by langchain
	- https://python.langchain.com/docs/modules/model_io/chat/structured_output/#groq
	- GroqInc just dropped tool calling!
	- We've added LangChain support (including the popular `withStructuredOutput` method!) so you can try it in your favorite chains and apps.
	- It supports MistralAI, Mixtral, Llama 70B, and Google Gemma.
-  Chat Vectorを使って日本語LLMをチャットモデルに改造する
	- https://qiita.com/jovyan/items/ee6affa5ee5bdaada6b4
	- Chat Vector: A Simple Approach to Equip LLMs with Instruction Following and Model Alignment in New Languages
	- LLMの学習済み重みパラメータの足し引きによって、事前学習済みモデルに対話能力を与えることができるという結果が示されています。
	- 具体的には、英語で事前学習されたモデル（以下ではベースモデルと呼びます）と、ベースモデルを指示チューニング (instruction tuning)してチャット形式の対話ができるようにしたモデル（英語チャットモデル）、ベースモデルを英語以外の言語で継続事前学習したモデルの３つのモデルを用います。
	- 英語チャットモデルの重みからベースモデルの重みを引いたものは、チャット形式で対話ができる能力を表したベクトルであり、そのベクトルを他言語の継続事前学習モデルの重みに加えることで他言語のモデルにチャット形式の対話能力を付与できるという
- Microsoft Encarta '97 (including MindMaze) has been open-sourced on
	- https://ia902707.us.archive.org/view_archive.php?archive=/2/items/enc-97-enc/ENC97ENC.iso
-  JetMoE: Reaching LLaMA2 Performance with 0.1M Dollars
	- https://research.myshell.ai/jetmoe
	- JetMoE-8B is trained with less than $ 0.1 million cost but outperforms LLaMA2-7B from Meta AI, who has multi-billion-dollar training resources. LLM training can be much cheaper than people generally thought.
-  ReALM: Reference Resolution As Language Modeling
	- https://arxiv.org/abs/2403.20329
	- Apple's 3B LLM(ReALM ) Outperforms GPT-4
	- ReALM significantly improves how conversational assistants like Siri or Alexa can understand the way humans naturally talk. Imagine you're looking at a list of restaurants on your smartphone and you say "direct me to the one on Main Street" -
	-  ReALM is able to understand which restaurant you're referring to, even though you didn't specify the exact name.
-  Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models
	- https://huggingface.co/papers/2404.02575
	- This paper presents Think-and-Execute, a novel framework that decomposes the reasoning process of language models into two steps.
	- (1) In Think, we discover a task-level logic that is shared across all instances for solving a given task and then express the logic with pseudocode; 
	- (2) In Execute, we further tailor the generated pseudocode to each instance and simulate the execution of the code.
- Mixture-of-Depths: Dynamically allocating compute in transformer-based language models
	- https://arxiv.org/abs/2404.02258
	- Dynamically allocating compute in transformer-based language models
	- Same performance w/ a fraction of the FLOPs per forward pass
-  1bit LLM の時代は来るのか，来ないのか，どっちなんだい？
	- https://note.com/ipsj/n/ncbe5746f71fb
	- 三値のBitNetについて、情報処理学会の会誌に解説を書かせていただきました
	- 「モデルを大きくすると精度の逆転現象が起こるのだとすると，量子化というのはこれまで想定されていたよりもかなり優れたアイディアなのではないか？」
	- b1.58論文の中身について解説してきましたが，いかがでしたでしょうか．個人的には，この論文には賛否両論があると考えています．
	- 肯定的な見地からは，精度の逆転現象が本当ならば大きな発見であり，自然言語処理分野への大きな貢献となり得る
- Cohere's latest LLM, Command R+ がAzureにのる by Nadera
	- https://x.com/satyanadella/status/1775988939079450886
- Anthropic Tool Calling by langchain
	- https://python.langchain.com/docs/integrations/chat/anthropic/#beta-tool-calling
- Command R+オープン系としては洒落にならんほど知性を感じる
	- https://x.com/_kaiinui/status/1775928745775534189
-  OpenAI の ファイチューニングAPI の新機能 by npakaさん
	- https://note.com/npaka/n/ne41cba4111a0?sub_rt=share_h
	- 2024年4月4日、ファインチューニングAPIに新機能が導入されました。
	- OpenAIを利用すると、ほとんどの組織はセルフサービスのファインチューニングAPI を使用して、有意義な結果をすぐに確認できます。
- Appleが開発、スマホのスクリーンを理解してユーザーと対話できる『ReALM』端末上で動く軽量モデル
	- https://ai-data-base.com/archives/66828
	- Appleは、ユーザーとの対話やスマホ画面を高度に理解する言語モデル『ReALM』を発表しています。Siriなどのアシスタントを進化させる技術としての位置付けです
- Command Rはローカル実行ては初めて文章クリーニングできたかもしれん
	- https://x.com/Meteor_Eternal/status/1775877913952518608
- Claude Function Calling Agent by langchain
	- https://github.com/run-llama/llama_index/blob/main/docs/docs/examples/agent/anthropic_agent.ipynb
- Generating text with 4-bit 104B ⌘R+ in MLX on an M2 Ultra. Runs pretty well:
	- https://x.com/awnihannun/status/1776081238467768493
- Command R の 概要 by npakaさん
	- https://note.com/npaka/n/naa6add7a892f?sub_rt=share_h
	- 「Command R」は、「RAG」や「Tool」などの長いコンテキストタスク向けに最適化されたLLMです。CohereのEmbeddingおよびRerankと連携して動作するように設計されており、RAGアプリケーションに最高クラスの統合を提供し、エンタープライズユース ケースで優れています。
	- ・RAGとToolの使用に関する高い精度
	- ・低遅延、高スループット
	- ・128Kコンテキスト長、価格が安い
	- ・10の主要言語に対応 (日本語含む)
	- ・研究・評価のためにHuggingFaceでウェイトを公開
	- https://huggingface.co/CohereForAI
- Mistral 7Bベースの日本語チャットモデル ChatNTQ-JA-7B を試す
	- https://sc-bakushu.hatenablog.com/entry/2024/04/04/091521
	- 「chatntq_chatvector-MoE-Antler_chatvector-2x7Bchatntq_chatvector-MoE-Antler_chatvector-2x7B」という呪文のような日本語MoEモデル
	- https://huggingface.co/Sdff-Ltba/LightChatAssistant-2x7B
	- Mistral 7Bベースの「Japanese Stable LM Base Gamma」をファインチューンした2つの異なるモデル（Antler 7B, ChatNTQ-JA-7B）を2x7BのMoEにしたモデルだそうです。
	- このMoEモデルを早速試してみたところ、確かに賢そうな印象を受けました。ただ、そもそもベースにされている2つのモデルを聞いたことがありませんでした。
- pfnet/nekomata-14b-pfn-qfin
	- https://huggingface.co/pfnet/nekomata-14b-pfn-qfin
	- rinna社のnekomata-14bを金融向けにチューニングしたLLMを公開しました！ これは、まだまだ金融分野へのLLM応用につながる第一歩でしかないと思うので、もっと研究開発を進めていきたいと思います。
- Qwen1.5-32B release
	- https://github.com/QwenLM/Qwen1.5
	- Qwen1.5 72B has been the best open model on Chatbot Arena leaderboard. Very excited to see how the 32B performs!
- ジェフ・ベゾスがPerplexityに投資
	- https://x.com/npaka123/status/1776352622704042408
- llama.cpp量子化：重要度行列(Importance Matrix)計算に使うテキストについて
	- https://sc-bakushu.hatenablog.com/entry/2024/03/30/195557
	- 現在のllama.cppでは重要度行列(Importance Matrix)計算を利用することで[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)精度が改善できます。
	- 特に4bit以下の低bit[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)を行う場合は、このiMatrix版の[量子化](https://d.hatena.ne.jp/keyword/%CE%CC%BB%D2%B2%BD)が推奨されます
- Apple MLX: Qwen-32B is out and now converted for MLX in 4 and 8 bits flavors.
	- https://x.com/ivanfioravanti/status/1776327090452738315
- ReFT: Representation Finetuning for Language Model
	- https://arxiv.org/abs/2404.03592
	- LoRAのようにweightに介入する fine tuning ではなく、潜在（中間）表現に介入する fine tuning である、ReFT (Representation Finetuning) というフレームワークとその一つの実現例である Low-rank Linear Subspace ReFT (LoReFT) の提案。
- google/gemma-1.1-7b-it
	- https://huggingface.co/google/gemma-1.1-7b-it
	- This is Gemma 1.1 7B (IT), an update over the original instruction-tuned Gemma release.
- HachiML/Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- https://huggingface.co/HachiML/Swallow-MS-7b-v0.1-MathSkill-OpenMath
	- Chat Vectorの理論で作ったMath強化モデル、HuggingFaceに置きました
- 

.



## 4/1

今週は年度末、日本企業のLLMが年度末工事よろしく次々発表。先週取りこぼした、RakuteのMistral AIベースのRakutenAI 7B等に加え、今週はNTTが開発した「tsuzumi」は日本語と英語に対応する70億パラメータのLLM。LLMの日本語処理能力を評価するベンチマーク「Rakuda Benchmark」において、GPT-3.5やその他の国産LLMを上回る性能で、図表や画像の解析にも対応とのこと、NTT comが生成AIサービスを展開ということなので、生成AIのビジネス応用元年になるのか。Databricksから公開された「DBRX」は、132億パラメータを持つ大規模なMoE(Mixture of Experts)モデルで、既存のオープンソースモデルを上回る性能を発揮。LLaMA2-70Bよりも高速な推論が可能で、Grok-1よりもコンパクトなモデルサイズながら高い性能を実現。NTTのtsuzumiの資料によると、AWSで7Bモデルを300Bトークン学習させると1900万円かかとのことであるが、そもそもLLMのスケール測からすると、投資に対するリターン（精度向上）が見合わなくなるともっぱら話題に。とはいえ、OpenAIとMicrosoftが最大1000億ドルを投じて「Stargate」というスーパーコンピューターを2028年までにつくるとか、パワープレイは続く。一方、推論の効率化では、Intel Neural Compressorは4ビット量子化技術で、LLMの高速推論と効率的な計算資源利用が可能に。LoRAに代わる「LISA」が出てきた。LISAはメモリ使用量を大幅に削減しながら、従来手法と同等以上のパフォーマンスを実現できる。OpenAIが「Voice Engine」を限定ユーザーに発表、安全性と性能を鑑みると、オープンソースでLLMというのも、限定されてくるのかもしれない。個別の話題では、Googleの「CRAG(Corrective Retrieval Augmented Generation)」、従来の検索拡張生成(RAG)手法を改良し、RAGシステムで取得したドキュメントをLLMに渡す前に、そのドキュメントの内容が正しいかどうかを自動でチェックする機能つけることでハルシネーションを抑制。BGE-M3というEmbedding用モデルが、検索タスクの評価はmE5よりかなり良い数値とか、日本語RAGに使えるとか、中華LLMは日本語が得意。Mambaを採用したLLMで初めての大きなモデルであるJamba、評価が待たれる。SD3の論文では、拡散モデルから Flow ベースモデル へということだが、Reflective Flowというノイズとデータのつなぎ方の話が興味深い。なおBenjio先生のGenerative Flow Networkとは別物らしい。行政系で華々しく登場した行政手続きＱ＆ＡサービスであるGovBot、使い物にならないという評価が次々に、人の死体をゴミと認識？、どうも担当者が正しくAIを理解してないという悲しい事情も、ひろみちゅ先生により明らかに。8,525万でデジ庁からNECが受注したんだよね、ここまでハリボテとは。

- RAGの新しい手法「CRAG」を3分で理解する
	- https://zenn.dev/knowledgesense/articles/bb5e15abb3c547
	- 「Corrective Retrieval Augmented Generation (CRAG)」
	- RAGの性能を高めるための新しい手法です。Googleなどの研究者によって2024年2月に提案されました。CRAG（日本語にすると「修正型検索拡張生成」）という手法を使うメリットは、ハルシネーション（幻覚）を減らせることです。CRAGが従来の「RAG」よりもハルシネーションを減らせる理由は、RAGシステムで取得してきたドキュメントをLLMに渡す前に、「そのドキュメントの内容が正しいものなのか」自動でチェックするという機能を取り入れているからです。
-  AIセーフティ技術学会
	- https://tais2024.cc/ja-jp/
	- AI Safety，AI Alignment，特異学習理論，自由エネルギー原理，AIの自律性（エージェント性）等々のトークとポスター発表．ほとんど自分が聞きたいテーマだけで構成された魅力的な国際学会
- 日本語版：AIOS LLM Agent Operating System
	- https://hamaruki.com/japanese-version-aios-llm-agent-operating-system/
	- この論文では、LLMをオペレーティングシステム(OS)に組み込んだ「LLMエージェントオペレーティングシステム(AIOS)」を提案しています。 AISOは、エージェントのリソース割り当て最適化、コンテキストスイッチ、並列実行、ツールサービス提供、アクセス制御などの機能を持っています。
-  RAFT: Adapting Language Model to Domain Specific RAG
	- https://arxiv.org/abs/2403.10131
	- RAFT offers a method to fine-tune pre-trained LLMs for specific domain RAG settings.
	- Conventional RAG is like an open-book exam, retrieving documents from an index to provide context for answering queries. This makes it more effective than the closed-book exam setting where LLMs rely solely on their pre-training and fine-tuning to respond to prompts, but doesn't allow the LLM to learn the domain beforehand.
- NatCom誌【ビールの風味とおいしさ（飲んだ人の評価）を決定する物質を250のビールに対する18万のレビューから機械学習で解明。
	- https://www.nature.com/articles/s41467-024-46346-0
	- 複雑な心理現象について、大規模データと機械学習を用いて仮説フリーで当たりをつけ、それを「仮説」として実験室で検証実験を行う。うらやましいほどお手本のような現代的研究。ビールを対象としているところも粋でオモロいし！
- NTTのTsuzumi、7Bパラのマルチモーダルで、RakudaベンチマークでGPT-3.5を上回るんだと。
	- https://x.com/umiyuki_ai/status/1772588308537000101?s=20
- OpenAIが「VOICE ENGINE」の名前で商標を出願
	- https://x.com/ctgptlb/status/1771005259948986562?s=20
-  RakutenAI-7B: Extending Large Language Models for Japanese
	- https://huggingface.co/papers/2403.15484
- MSのエンジニアがGPT-6クラスタの構築に取り組んでる
	- https://x.com/_kaiinui/status/1772455514489672080?s=20
	- H100を10万台以上配備しているらしく、電力的に一つのDCに収まらなくなってきている (※10万台 = 70メガワット)
- The Unreasonable Ineffectiveness of the Deeper Layers
	- https://huggingface.co/papers/2403.17887
	- We empirically study a simple layer-pruning strategy for popular families of open-weight pretrained LLMs, finding minimal degradation of performance on different question-answering benchmarks until after a large fraction
	- 岡野原さん、学習済みのLLMから、層毎に入力と出力間のcos類似度が大きい層（変化が少ない層）を間引いても精度は落ちない。特に最後の層だけ除いて深い側の層を2~4割間引いても質問応答などの精度は変わらず、知識の大部分が低い層にあることを示唆する。学習手法やモデル設計の参考にも
	- まあ有名な映画、小説の題名のもじり
- DeepLearningAIから、新しいRAGのコースが
	- https://www.deeplearning.ai/short-courses/javascript-rag-web-apps-with-llamaindex/
	- JavaScript RAG Web Apps with LlamaIndex,
- LoRaより優れたLISA
	- https://x.com/Rui45898440/status/1772996453557997924?s=20
	- Excited to share LISA, which enables
	- 7B tuning on a 24GB GPU 
	- 70B tuning on 4x80GB GPUs
- Databricks introduces DBRX, a new 132B parameter open LLM
	- https://huggingface.co/databricks/dbrx-base
	- fine-grained mixture-of-experts (MoE) with 132B of which 36B active 
	- a larger number of smaller experts. DBRX has 16 experts and chooses 4 
	- It was pre-trained on 12T tokens of text and code data
	- DBRX outperforms all the established open-source models on common benchmarks like MMLU and GSM8K.
	- Its inference is up to 2x faster than LLaMA2-70B and is about 40% of the size of Grok-1 in terms of both total and active parameter counts.
	- While DBRX is trained as a general-purpose LLM, it still surpasses CodeLLaMa-70 Instruct, a model built explicitly for code generation.
- DBRX is super cool, but research and reading too! Especially if you can combine RAG + COT.
	- https://x.com/_philschmid/status/1773024623589736949?s=20
- we're connecting Adobe Experience Cloud with Microsoft Copilot to reimagine how marketers approach their daily work
	- https://x.com/satyanadella/status/1773063169138671984?s=20
-  LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning
	- https://arxiv.org/abs/2403.17919
	- LISA algorithm in two lines: 
		- always activate embedding and linear head layer 
		- randomly sample intermediate layers to unfreeze
	- 岡野原さん、LISAはLLMのファインチューニングの際に、各層を確率的にサンプリングし、選択された層のみ更新する。全パラメータ更新しながらLoRAよりもメモリ使用量、計算量とも効率的に計算できる（通常学習でもできそう）。最初の層と最後の層のみ採択する確率は高くしておく
- DBRXまとめ
	- https://x.com/webbigdata/status/1772981844839207206?s=20
	- ・Databricks社が新たに公開したオープンなMoEモデル 
	- ・自社調べでGPT-3.5 を上回り、Gemini 1.0 Pro と競合 
	- ・コード能力で特化モデルCodeLLaMA-70Bを上回る 
	- ・推論は LLaMA2-70B よりも最大 2 倍高速 
	- ・16人のエキスパートの中で4 人を選択して推論を実行 
	- ・パラメータ数はGrok-1の約40%だが性能は上回る 
	- ・テキスト データとコード データを合計した12Tトークンで事前トレーニング 
	- ・3072 台の NVIDIA H100を使って約3か月でトレーニング 
	- ・ファイルサイズは 263.07(約4.4 GB x 61safetensors)
- Exploration—not work—could be key to a vibrant local economy
	- https://phys.org/news/2024-03-exploration-key-vibrant-local-economy.html
	- Cities and the surprising finding from mobility data analysis that it's more in how we spend and explore in our free time that drives the economic vibrancy of cities, over where we work and go to school.
- Monitoring AI-Modified Content at Scale:A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews
	- https://arxiv.org/pdf/2403.07183.pdf
-  Intel® Neural Compressor
	- https://github.com/intel/neural-compressor
	- All your need is Intel Neural Compressor (INC) for INT4 LLMs. INC v2.5 released with SOTA INT4 LLM quantization (AutoRound) across platforms incl. Intel Gaudi2, Xeon, and GPU.
	- Models: Llama2, Mistral, Mixtral-MOE, Gemma, Mistral-v0.2, Phi2, Qwen,
- Masked Autoencoders are PDE Learners
	- https://arxiv.org/abs/2403.17728
	- Masked autoencoders can learn useful latent representations for PDEs through self-supervised pretraining on unlabeled spatiotemporal data. This allows them to improve
- 4-bit quantized DBRX runs nicely in MLX on an M2 Ultra
	- https://github.com/ml-explore/mlx-examples/pull/628
- 国・地方共通相談チャットボット「Govbot（ガボット）」があまりにひどいと、、
	- https://x.com/HiromitsuTakagi/status/1772918656210743594?s=20
- Google presents Long-form factuality in large language models
	- https://arxiv.org/abs/2403.18802
	- Proposes that LLM agents can be used as automated evaluators for longform factuality
	- Shows that **LLM agents can achieve superhuman rating performance**
- GovBot担当者はなにも理解してないとの疑惑が、、by ひろみちゅ先生
	- https://x.com/HiromitsuTakagi/status/1773148382820778280?s=20
	- それ、GovBotはAIではないので学習と呼ぶのは異常だし、ここで人間が学習するなんて話をするのは滑稽と言う他ないですね
- DBRXは試せる模様
	- https://huggingface.co/spaces/databricks/dbrx-instruct
	- 「風の谷のナウシカ」は、宮崎駿監督による日本のアニメ映画です。ナウシカは、風の谷の王女であり、森と深い関係性を持っています。森の人は、森に住む原始的な部族のことです。ナウシカは、森とその住人を尊重し、森と共存することを望んでいます。彼女は、森とその住人が持つ力を理解しており、それを使って、風の谷と森の間の紛争を解決しようとします。しかし、森の人は、風の谷や他の王国との関係性について、より懐疑的であり、ナウシカの考えに反対することもあります。
- PFN初のゲーム『Omega Crafter』
	- https://x.com/imos/status/1773254326003139023?s=20
	- ほにゃらら回路で自動化するみたいななんちゃってプログラミングではなく、ちゃんとした構造を持つプログラミングができる珍しい(?)ゲームなので、特にエンジニアの方にはオススメしたいです。是非買ってプレイしてください！
- Scaling Rectified Flow Transformers for High-Resolution Image Synthesis
	- https://speakerdeck.com/shunk031/stable-diffusion-3
	- Stable Diffusion 3 の元論文を読みました！拡散モデルから Flow ベースモデル (Rectified Flow)、UNet から DiT へ切り替え、CLIP x 2 と T5-XXL を使ったてんこ盛りモデルで、生成画像の品質・プロンプトに対する生成画像の忠実性・文字の描画性能が飛躍的に向上しています
-  Perplexityをもとに､複数の大規模言語モデルを切り替えて推論するシステムの簡単なコード実装
	- https://note.com/kan_hatakeyama/n/nb5625d6411a8?sub_rt=share_pw
	- モデルの事前訓練をする余裕がないので、今回は試しに、英語が得意なLLama2-7bと、日本語でファインチューニングしたElyza-7bを統合（merge）したシステムを作ってみようと思います。
	- 英語の質問にはllama、日本語の質問にはelyzaで答えることができればコンセプト実証に成功です。
- Generative Flow Networks by Yoshua Bengio
	- https://mila.quebec/en/article/generative-flow-networks/
	- https://www.youtube.com/watch?v=ggYoJp0b3Oo
-  Introducing Jamba: AI21's Groundbreaking SSM-Transformer Model
	- https://www.ai21.com/blog/announcing-jamba
	- 岡野原さん、JambaはMambaとTransformerをあわせた52B LLM。MoEで有効パラメータは12B、1GPUでコンテキスト長140Kまで扱え、複数GPUでは256Kまで扱える。コンテキストが長くなった時は3倍近いスループット。1/8の割合でTransformerを使う。Mambaを採用したLLMで初めての大きなモデル。
-   LMFlowによる日本語LISAトレーニング　 by shi3zさん
	- https://www.free-ai.ltd/post/lmflow-ja-lisa
	- メモリ消費がLoRAと同等に低く、なおかつパフォーマンスはフルパラメータのファインチューニングに匹敵もしくは上回る効果を持つと言われています。
-  LoRAよりいいらしいLISA by shi3zさん
	- https://note.com/shi3zblog/n/ndf165df51f04?sub_rt=share_pb
	- 学習も速いし推論も速い。  こんないいことずくめのことがあっていいのか。  しかしそんないいことずくめのことが時々起きるのがこの業界の面白いところである。
-  Accelerating Scientific Discovery with Generative Knowledge Extraction, Graph-Based Representation, and Multimodal Intelligent Graph Reasoning
	- https://arxiv.org/abs/2403.11996
	- 言語モデルによる科学知識抽出の論文
	- 1000件の論文のデータを言語モデルにより抽出し知識グラフに変換、グラフ解析によりバイオ材料とベートーベンの第 9 交響曲の構造的類似点など分野を超えた関係性を明らかにできたそうです。
- Transformerのスケーリング則は線形じゃなくてべき乗則だから、トレーニングの計算量を10倍にしてもLossは12%しか減らない（性能が10倍になるわけじゃない）
	- https://x.com/umiyuki_ai/status/1773917004464103563?s=20
- a small-scale preview of Voice Engine
	- https://x.com/OpenAI/status/1773760852153299024?s=20
- OpenAIとMicrosoftが最大1000億ドルを投じて「Stargate」というスーパーコンピューターを2028年までに建設予定。AI開発加速のため、数100万のAI専用チップを搭載。
	- https://qz.com/microsoft-openai-stargate-supercomputer-1851375309
-  langchainとDatabricksで(私が)学ぶRAG : BGE-M3を使った埋め込み
	- https://qiita.com/isanakamishiro2/items/e4f67586b4cb5f171ea9
	- BAAI(Beijing Academy of Artificial Intelligence)から、BGE-M3というEmbedding用のモデルが公開されました。
	- 日本語RAGにおける新たな埋め込みのスタンダードモデルになるかもしれないなと思い、このモデルを使った検索を試してみました。
	- LangChainには`HuggingFaceBgeEmbeddings`というBAAIのBGE系埋め込みモデルを利用するための専用クラスた用意されており、そちらを利用します。
	- RAGの性能を高める上で埋め込みに関する工夫は重要であり、今後もこういった高性能なモデルが公開されていくと（素人的に使う側にとっては）ありがたいですね。
-  NTTが独自LLMのtsuzumiを提供開始、日本語性能で「GPT-3.5超え」(2024年3月25日)
	- https://xtech.nikkei.com/atcl/nxt/news/24/00458/
	- NTTは2024年3月25日、独自LLM（大規模言語モデル）である「tsuzumi」のサービス提供を始めた
	- tsuzumiは日本語と英語に対応し、パラメーター数は70億とOpenAIの「GPT-3」の1750億と比べて25分の1と軽量だ。LLMの日本語処理性能に関するベンチマークテスト「Rakuda Benchmark」の結果では、GPT-3.5や同規模の国産LLMを上回ったという。tsuzumiは言語に加え、図表や画像の解析などにも対応する。
	- うみゆきさん、LLMの学習コスト感ってよく知らんけど、Tsuzumiの資料によればAWSで7Bモデルを300Bトークン学習させると1900万円かかるらしい。300Bじゃ少ないから1.2Tくらいは学習させたいよね。そしたら7600万円か。
-  NTTが開発したLLM「tsuzumi」、NTT Comより商用生成AIサービスとして提供開始
	- https://internet.watch.impress.co.jp/docs/news/1578961.html
- 楽天が日本語に最適化したMistralベースのLLMを公開、商用目的で使用可能(2023年3月21日)
	- https://xtech.nikkei.com/atcl/nxt/news/24/00440/
	- 公開したのは基盤モデルの「Rakuten AI 7B」、同モデルを基にしたインストラクションチューニング済みモデルの「Rakuten AI 7B Instruct」、Rakuten AI 7B Instructを基にファインチューニングしたチャットモデル「Rakuten AI 7B Chat」の3種である。
	- 文章の要約や質問応答、一般的な文章の理解、対話システムの構築などに商用目的で使用でき、Rakuten AI 7Bは他のモデルの基盤としても使えるという。
	- Rakuten AI 7BはフランスのAI（人工知能）スタートアップMistral AIのオープンモデル「Mistral-7B-v0.1」を基に、継続的に大規模なデータを学習させて開発した日本語基盤モデル。
- govbotをとりあえず試してみたら死んだ人間を『ゴミ』と認識している説が出てきた
	- https://x.com/judo5001/status/1773196373686411292?s=20
- GovBotの開発に8525万かかったと聞いて調べたら本当だった🤯！しかも、調達機関はデジタル庁で開発業者は日本電気
	- https://x.com/gijigae/status/1773557153317437824?s=20

## 3/25

先週xAIより公開されたgrok-1、gpt-3.5を上回るが、Claude 2やGPT-4は下回るという性能らしい。さて生成AIでは出遅れ感もあるApple、geminiをiPhoneに入れるとのうわさが出たり、30BのMM1を論文発表したりと、にわかに活発化。Stability AIのアニメ業界向け生成系AI、ついに現場にAIが入りだすのか。KDDI、ELYZAを連結子会社化ってのも驚いた、「生成AIを活用したDX支援・AI SaaS」ってのが春以降でるらしい。NVIDIA がGTC2024で発表した、ヒューマノイド開発プラットフォーム「GR00T」、 H100の５倍の性能！新GPUであるB200、DGX GB200 NVL72とか、NIMの発表とか、一人勝ちってこういうこと。早速llamaindexがNVIDIA NIMで動くようになった。ひろみちゅ先生、Claude 3を用いた新規提出法案の立法技術上の矛盾点チェック、法制局も真っ青レベルとのこと。DeepMindのTacticAI、「コーナーキックについてアドバイスできる完全なAIシステム」。500程度のサンプルで数分学習させてLLMの出力を方向付ける事が出来る制御ベクトルってのは面白い、キャラ分けなんかが簡単になるのか。「Google Scholar PDF Reader」、こういう応用がどんどん出てほしい。Sakana.aiの進化的計算による基盤モデル構築って、複数のLLMをマージするという新たな方向性を示した。日本語画像言語モデルEvoVLM-JPはすぐに試すことができる。LLMのマージでは、Arcee's MergeKitってのも忘れてはいけない。Embedding の量子化というのがあるのか、高速化の工夫の余地はまだまだある。[huggingface](https://github.com/huggingface)からPEFT 0.10.0のリリース、70B Llama 2モデルを24GBメモリを搭載したGPU2基でQLoRA可能になるとのこと。huggingfaceはTransformers 4.39もリリース、GaLoreをサポートしてるらしい。「GaLore」、「NVIDIA RTX 4090」などの家庭用GPU上で、Llamaなどの最大7Bパラメータを持つモデルの学習を容易にする技術、元論文は2023年の5月にMetaが発表。Artificial muscleというのもすごいな、NVIDIAのロボットに組み込むと、いよいよ人間らしいロボットが実現するのか。Lightblue、国内最高水準の日本語LLMモデル「ao-Karasu」リリース、７２Bだそうだ、もう何が何だか。LINEの「japanese-large-lm-1.7b-instruction-sft」から派生したLLMがたくさんリリース、ローカルAIハッカソンの成果らしい。『微分可能プログラミング』、プログラムのパラメータを微分可能な方法で最適化することにより、機械学習タスクを解決するプログラミングパラダイムなんだけど、”プログラムを微分可能にすることは本質的に確率分布によってその出力の不確実性を定量化すること”とはUQ、Uncertainty Quantification;不確かさの定量化、に通じて面白い

- grok-1まとめ
	- https://x.com/webbigdata/status/1769503166528458822?s=20
	- リリースされたモデルは314Bパラメーター 
	- ファイルサイズでいえば318.24GB 
	- MoE(2/8 experts)でactiveパラメーターだけでも86B 
	- 2023/10月時点で学習を完了していたベースモデルのみ公開 
	- githubのxai-orgで推論コードも公開(JAX) 
	- ダウンロードはacademictorrentsかhuggingfaceのxai-org/grok-1 
	- ライセンスはApache 2.0 ライセンス 
	- 公表済みベンチマークによればgpt-3.5を上回るが、Claude 2やGPT-4は下回る
- Apple in talks with Google for using Gemini to bring generative AI features to iPhones
	- https://www.livemint.com/technology/tech-news/googles-gemini-could-power-generative-ai-features-on-iphone-16-tim-cook-heres-what-we-know-11710739843784.html
- アップル、高度な言語理解を持つ新型AIモデル「MM1」を発表
	- https://ascii.jp/elem/000/004/189/4189761/
	- https://arxiv.org/pdf/2403.09611.pdf
	- 複数（30億、70億、300億）のパラメータサイズを備えるMM1は、10億以上の画像および30兆語以上のテキスト、GitHubのコード例などの多様なデータセットを用い、教師なし学習と教師あり学習を組み合わせる独自の方法で学習され、多様なタスクに対して高い精度を示す
	- MM1はすべてのコンポーネントに関して、そのアーキテクチャーから、データセットの内容、事前学習・ファインチューニングの詳細、モデルサイズに至るまで、詳細な情報（MLLMsの開発レシピ）を公開している。
-  Stability AIとアニメチェーンがアニメ業界向け生成系AIの共同研究を検討開始
	- https://prtimes.jp/main/html/rd/p/000000003.000135092.html
	-  既存のアニメ制作工程をそのままに「協議会」を通じて制作現場の声を伺いながらアニメ作品の品質向上を目標とした支援ツールの共同研究を目指す
-  Fully  Client-Side  Chat Over Documents
	- https://webml-demo.vercel.app/
	- So I revisited WebLLM and was able to add browser-only mode!
- KDDI、東大発AIベンチャー・ELYZAを連結子会社化　春以降、生成AI関連サービスを提供
	- https://www.itmedia.co.jp/news/articles/2403/18/news140.html
	- 生成AIを活用したDX支援・AI SaaS
- NVIDIA GTC2024で次世代のロボティクスはヒューマノイド
	- https://www.youtube.com/watch?v=Y2F8yisiS6E
- NVIDIA、GPUプラットフォーム「Blackwell」発表　「兆パラメータ規模のAIモデル実現」
	- https://www.itmedia.co.jp/news/articles/2403/19/news092.html
	- プラットフォームに搭載する「GB200 Grace Blackwell Superchip」は、新GPU「B200」（2080億個のトランジスタを搭載し、現行の「H100」と比較して、AI向けの作業で5倍の処理能力を発揮するGPU）を2基と1基のGrace CPUを組み合わせたもの。
	- NVIDIAによると、1兆8000億パラメータのAIモデルをトレーニングするには、Hopper GPUでは8000個のGPUで15メガワットの電力が必要だったが、新スーパーチップであれば2000個で可能で、消費電力は4メガワットで済むという。
- DGX GB200 NVL72は、GB200 Superchipを72基NVLinkで接続したクラスタ
	- https://x.com/_ksasaki/status/1769829822946001353?s=20
- 生成AIアプリの展開を数分に、NVIDIAが新マイクロサービス「NIM」を発表
	- https://xtech.nikkei.com/atcl/nxt/news/24/00424/
	- NIMは、生成AIの推論に必要となる各種ソフトウエアがインストール済みのコンテナ（マイクロサービス）を提供する仕組みである。具体的には、エヌビディアが開発した推論ワークフローを最適化するフレームワークである「Triton Inference Server」やツールキット「TensorRT-LLM」などがインストールされ、エヌビディアやパートナー企業が提供する20以上のAIモデルに最適化されている。
-  LlamaIndex Accelerates Enterprise Generative AI with NVIDIA NIM
	- https://www.llamaindex.ai/blog/llamaindex-accelerates-enterprise-generative-ai-with-nvidia-nim
	- LlamaIndex  is integrated with NVIDIA NIM inference microservices to help enterprises seamlessly deploy generative AI at scale
- 1x GPU Blackwell - 192GB VRAM 2x GPU 
	- Blackwell with CPU - 384 GB VRAM
	- https://x.com/migtissera/status/1769824889102348366?s=20
-  NVIDIAがヒューマノイド開発プラットフォーム提供を発表　ディズニーの二足歩行ロボットが登壇　Jetson Orinから次世代Thorへ
	- https://robotstart.info/2024/03/19/nvidia-humanoid-jetson-thor.html
	- NVIDIAは「GTC 2024」の創業者/CEOのジェンスン・フアン氏による基調講演で、ヒューマノイドロボット(ヒト型ロボット)を開発するためのプラットフォーム「GR00T」(ジーアールゼロゼロティー)を発表した。NVIDIAは新世代GPUと生成AIを含むヒューマノイド開発用のSDKやライブラリ、プラットフォームを提供し、全面的に支援していく。
- 法制局も真っ青？Claude 3を用いた新規提出法案の立法技術上の矛盾点チェック
	- https://takagi-hiromitsu.jp/diary/20240319.html
	- Claude 3に聞いてみた。微妙にけっこう間違うが、そこはスルーして、大変参考になる。ここまでわずか1時間程度の作業だった
- TacticAI: an AI assistant for football tactics
	- https://deepmind.google/discover/blog/tacticai-ai-assistant-for-football-tactics/?utm_source=twitter&utm_medium=social&utm_campaign=TacticAI/
	- We're announcing TacticAI: an AI assistant capable of offering insights to football experts on corner kicks.
	- it can help teams sample alternative player setups to evaluate possible outcomes, and achieves state-of-the-art results.
	- TacticAIはGoogleとリヴァプールの複数年にわたる協力関係の一環として開発されたもので、「コーナーキックについてアドバイスできる完全なAIシステム」としてアピールされています
- 500程度のサンプルで数分学習させてLLMの出力を方向付ける事が出来る制御ベクトル(control vectors)用ライブラリ
	- https://github.com/vgel/repeng
	- LoRAのように特定タスクに特化するのではなく例えば 「陽キャなチャットボット」ｖｓ「陰キャなチャットボット」 など、モデルの出力に全体的な方向性を与える感じですね
- Google、PDF論文を劇的に読みやすくするChrome拡張「Google Scholar PDF Reader」
	- https://news.mynavi.jp/techplus/article/20240321-2911097/
- GaLore - 家庭用ハードウェアでの大規模モデルの学習
	- https://note.com/npaka/n/n8e4537502e3e?sub_rt=share_h
	- 「GaLore」は、「NVIDIA RTX 4090」などの家庭用GPU上で、Llamaなどの最大7Bパラメータを持つモデルの学習を容易にします。これは、学習プロセス中のオプティマイザの状態と勾配に従来関連付けられていたメモリ要件を大幅に削減することによって実現されます。
	- 「GaLore」と「8bitオプティマイザ」を組み合わせることで、学習プロセスの整合性とパフォーマンスを維持しながらメモリ効率を最大化する相乗効果が得られます。
- GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection
	- https://arxiv.org/abs/2403.03507v1
- StanfordのFei-Fei Li教授らのチームから、ロボットのシミュレーションのためのベンチマーク「BEHAVIOR-1K」がリリース
	- https://x.com/drfeifei/status/17710132915083798大規模言語モデル「Grok-1」について by 今井
	- https://x.com/ImAI_Eruel/status/1769487625994506294?s=20
- 進化的アルゴリズムによる基盤モデルの構築 by sakana ai
	- Sakana AIの最初の研究成果である、進化的計算による基盤モデル構築に関する論文を公開しました。多様な既存モデルを自動的に融合し優れた基盤モデルを構築するための方法を提案すると共に、それにより試作したモデルを公開しました。
		- **EvoLLM-JP**：数学的推論が可能な日本語の大規模言語モデル（LLM）
		- **EvoVLM-JP**：日本語で対話可能な画像言語モデル（VLM）
		- **EvoSDXL-JP**：高速な日本語画像生成モデル
	- _既存のモデルをマージして新しい基盤モデルを作成する過程の可視化。進化的アプローチは、モデルを組み合わせる際に、人間の直感だけでは見落とされがちな、効果的かつ時に非直感的な方法を自動的に発見することができます_
-  Evolutionary Optimization of Model Merging Recipes
	- Sakana Aiの論文
	- https://arxiv.org/abs/2403.13187
-  WSL2でSakana AIを試してみる
	- https://note.com/ngc_shj/n/na9b41adb9131
	- 「進化的モデルマージにより日本語数学LLMとして構築したEvoLLM-JPは、数学のみならず、日本語の全般的な能力に長けている」らしいEvoLLM-JPを試してみます
	- 10Bのモデルですが、torch_dtypeを"auto"からtorch.bfloat16に変更すると、推論のスピードが改善しました。
- RAG for long context LLMs: Video
	- https://www.youtube.com/watch?v=SsHUNfhF32s
	- https://docs.google.com/presentation/d/1mJUiPBdtf58NfuSEQ7pVSEQ2Oqmek7F1i4gBwR6JDss/edit#slide=id.g26c0cb8dc66_0_0
- NVIDIAのフリーオンラインAIコース
	- https://courses.nvidia.com/courses/course-v1:DLI+T-FX-01+V1/
- Claude 3 Opusより60倍安いHaikuをOpusの品質で運用する方法。
	- https://github.com/mshumer/gpt-prompt-engineer
	- gpt-prompt-engineerを使えば、プロンプトエンジニアリングの実験を自動化できる。自動で複数プロンプトを生成して、LLM別に評価も可能。
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
	- 25x speedup in retrieval; 32x reduction in memory usage; 4x reduction in disk space; 99.3% preservation of performance
- LLM4Decompile: Decompiling Binary Code with Large Language Models
	- https://arxiv.org/abs/2403.05286v1
	- バイナリからリバースエンジニアリングできると
- Suno AI unveiled V3
	- https://x.com/heyBarsee/status/1771190753957470604?s=20
- Doing In-Context Learning Without Leaking Private Data
	- https://github.com/run-llama/llama_index/tree/main/llama-index-packs/llama-index-packs-diff-private-simple-dataset/examples/symptom_2_disease
	- Few-shot demonstrations are crucial to improve the performance of any LLM/RAG app. But the issue with very private datasets (e.g. patient clinical reports), is that they can easily be leaked/jailbroken by malicious users.
- 内閣府「AI時代の知的財産権検討会（第６回）」の資料が公開
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/gijisidai/dai6/index.html
-  GitHub、脆弱性のあるコードの自動修正機能発表。AIボットが修正済みコードと解説をプルリクエスト
	- https://www.publickey1.jp/blog/24/githubai.html
	- GitHubは、脆弱性のあるコードをAIボットが自動的に発見、修正したコードとその解説をプルリクエストしてくれる「code scanning autofix」（コードスキャン自動修正機能）を発表しました
- 音声基盤モデルKotoba-Speech v0.1の学習・推論コードをリリースしました！
	- https://x.com/kotoba_tech/status/1771165553882964291?s=20
	- https://github.com/kotoba-tech/kotoba-speech-release
	- End-to-EndのTransformerアプローチで、カスタマイズも簡単です。例として、関西弁モデルも公開しました。既存のText-to-Speechよりも、さらに自然で流暢であることが実感できるかと思います！
- The AI Mirror Test
	- https://x.com/joshwhiton/status/1770870738863415500?s=20
	- The "mirror test" is a classic test used to gauge whether animals are self-aware. I devised a version of it to test for self-awareness in multimodal AI. 4 of 5 AI that I tested passed, exhibiting apparent self-awareness as the test unfolded.
	- Claude Opus passed the mirror test immediately. Like the other AI, it hardly identifies with its brand-name (Claude) and distinguishes itself from the interface’s stock elements. However it does identify with the prompt, which it knows is
- PEFT 0.10.0 is out
	- https://github.com/huggingface/peft/releases/tag/v0.10.0
	- Fine-tune larger QLoRA models with DeepSpeed and FSDP, layer replication, enhance DoRA
	- This allows you to fine-tune a 70B Llama model on two GPUs with 24GB memory each.
	- 以前、ツイートした70B Llama 2モデルを24GBメモリを搭載したGPU2基でQLoRA可能になるお話が正式採用
	- 加えて、DoRA(工夫したLoRA。ただしトレーニング時間は増える)が量子化済のモデルに対しても使えるようになって使いやすくなった模様
	- LoftQ(量子化誤差を最小化するようにLoRAを初期化してトレーニングできるようにする)もより使いやすくなったとの事
- OpenAI Voice Engine. This is big
	- https://x.com/SmokeAwayyy/status/1771052612051468668?s=20
	- VOICE ENGINE™ trademark registration is intended to cover: - voice and speech recognition, processing voice commands, and converting between text and speech
- Introducing the Chatbot Guardrails Arena
	- https://huggingface.co/blog/arena-lighthouz
	- Our vision behind the Chatbot Guardrails Arena is to establish the trusted benchmark for AI chatbot security, privacy, and guardrails. With a large-scale blind stress test by the community, this arena will offer an unbiased and practical assessment of the reliability of current privacy guardrails.
- 昨日SakanaAILabsからリリースした日本語画像言語モデルEvoVLM-JPは、誰でもすぐにお試しいただけます。
	- https://huggingface.co/spaces/SakanaAI/EvoVLM-JP
- Starling-LM-7B, has now upgraded to Beta
	- https://huggingface.co/Nexusflow/Starling-LM-7B-beta
	- It shows promising potential in our coming next generation benchmark.
	- https://x.com/lmsysorg/status/1771252185205981426?s=20
-  Debates on the nature of artificial general intelligence by nature
	- https://www.science.org/doi/10.1126/science.ado7069
	- "The history of AI has repeatedly disproved our intuitions about intelligence....At each step in the evolution of AI, human-level intelligence turned out to be more complex than researchers expected."
- lightblue/ao-karasu-72B
	- https://huggingface.co/lightblue/ao-karasu-72B
- Artificial muscle has arrived.
	- https://x.com/BrianRoemmele/status/1770959817815019857?s=20
	- 昨年知的業務は終わりだ。人間は筋肉を鍛えるしかない。 とか言ってたけど、人工筋肉出来ちゃったよ
	- https://www.youtube.com/watch?v=guDIwspRGJ8
-  Arcee's MergeKit: A Toolkit for Merging Large Language Models
	- https://huggingface.co/papers/2403.13257
	- Model Merging allows us to blend/stack multiple open LLMs into one—bigger or the same size—without extra training to extend skills and performance!
- データセンター廃熱でプールを加温🏊 環境に優しくコストも節減 英国
	- https://x.com/afpbbcom/status/1770586117449953488?s=20
	- 敷地内に設置された装置がコンピューター群が放出する熱を取り込み、25ｍプールを設定温度まで温める。約65％をカバーしており、ガスボイラーの使用は抑えられている。
- O1 LightはOpen Interpreterを搭載した小型デバイスです
	- https://x.com/tegnike/status/1770851466665750758?s=20
-  WSL2でRakutenAI-7B-chatを試してみる
	- https://note.com/ngc_shj/n/n413ababd3105?sub_rt=share_crp
	- 「Mistral AI社のオープンモデル「Mistral-7B-v0.1」を基に、継続的に大規模なデータを学習させて開発された70億パラメータの日本語基盤モデル」であるRakuten AI 7Bモデル
	- 「インストラクションチューニング済モデルを基にファインチューニングを行ったチャットモデル」であるRakuten AI 7B Chatを試してみます。
- Swallow-MX-8x7b-NVE-chatvector-Mixtral-instructのv2アップロードしました by AI さとし
	- https://huggingface.co/aixsatoshi/Swallow-MX-8x7b-NVE-chatvector-Mixtral-instruct-v2
	- 元モデルとinstructionベクトルのバランス調整で、日本語流暢性改善しています
- Margaret Mitchel
	- This Women's History Month, we celebrate Margaret Mitchell, the Chief AI Ethics Scientist at huggingface, an open source data science and machine learning platform and hub for AI experts. 
- Transformers 4.39 is out,
	- https://github.com/huggingface/transformers/releases/tag/v4.39.0
	- New models: Mamba, Command-R, LLaVA-NeXT, MusicGen Melody, StarCoder2, SegGPT, ...
	- GaLore optimizer for accessible pre-training
	- Quanto integration and Exllama+AWQ
	- MLX support
-  A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
	- https://arxiv.org/abs/2302.13425
	- ついにUQも深層学習の時代か
- Estimating Causal Effects with Double Machine Learning -- A Method Evaluation
	- https://arxiv.org/abs/2403.14385
- Meta introduces SceneScript
	- https://x.com/AiBreakfast/status/1771195019585597836?s=20
	- You will be able to upload your own environment to the metaverse:
- マジか(NLP2024の岡崎先生、Knight先生の発表概要をSwallow-MXを翻訳タスクでQLoRA tuningしたモデルで日英/英日翻訳)
	- https://x.com/hpp_ricecake/status/1771138490589487602?s=20
-  Googleが洪水を1週間前に予測し世界80カ国4億6000万人を水害から救えるAIを発表
	- https://gigazine.net/news/20240322-google-ai-global-flood-forecasting/
	- Google Researchのグレイ・ニアリング氏らの研究チームは、世界各国の流量計5680個が1980～2023年の間に集積したデータを用いてAIモデルをトレーニングしました。
	- 洪水ナウキャストによる洪水の予測を0日前、つまり当日から平均5日前まで延ばし、最大で7日前まで予測することができます。
- 立体言語
	- 永田亮『立体言語』（自然言語処理31巻1号巻頭言）
	- https://www.jstage.jst.go.jp/article/jnlp/31/1/31_1/_pdf/-char/ja
	- 言語の線状性（一つづつ順番に並べる制約）を超える、これまでとは異なった情報伝達の可能性。そして、そこにNLP技術が活かせるのではないかというお話。
- Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval
	- https://huggingface.co/blog/embedding-quantization
- Excited for MistralAI+ llama_index collabs (and Colabs)
	- https://x.com/jerryjliu0/status/1771262080944857469?s=20
-  Lightblue、国内最高水準の日本語LLMモデル「ao-Karasu」を公開
	- https://prtimes.jp/main/html/rd/p/000000057.000038247.html
	- 東京大学発、最先端アルゴリズムの現場実装に取り組むAIスタートアップ 株式会社Lightblue（代表取締役：園田亜斗夢、本社：東京都千代田区、以下「Lightblue」）は720億パラメーターの日本語LLMモデル「ao-Karasu」を公開したことをお知らせします。「ao-Karasu」はStability AI社が提供する日本語性能のベンチマーク、Japanese MT-Benchの自動評価で国内最高水準の評価となっています。
- 【Swin Transformer】今こそ押さえたいTransformer系画像認識モデル
	- https://ai-scholar.tech/articles/image-recognition/swin-transformer
	- 近年コンピュータビジョンの研究でベースラインとしてよく用いられているSwin Transformerを解説  
	- すべてのパッチと関連性(Attention)を計算するVision Transformerとは異なり，近傍のパッチをまとめたwindow内でAttentionを計算する  
	- 異なるパッチサイズでAttentionの計算を行うため，様々なスケールの特徴が得られる
-  [進化的アルゴリズムによる基盤モデルの構築](https://sakana.ai/evolutionary-model-merge-jp/)
	- Sakana AIは進化や集合知などの自然界の原理を応用して基盤モデルを開発することを目指しています。私達の目標は、モデルを自ら訓練し開発することだけではありません。基盤モデルの開発を効率化、高度化、自動化するための新たな手法を生み出すことに挑戦しています。この目標に向けた第一歩として、私たちはプレプリント「Evolutionary Optimization of Model Merging Recipes （モデルマージの進化的最適化）」を公開しました。
	- 複数のNNを重み・層レベルでマージする際の最適な組合せをEAで探索する進化的モデルマージを提案。数学と日本語など異なる領域に特化したLLMをうまくマージすることで性能を向上できる。
- team DataPilot2つ目のモデルとして、「ArrowSmartPlus_3.6B_instant_sft_JSHVer」をリリースいたします
	- https://huggingface.co/DataPilot/ArrowSmartPlus_3.6B_instant_sft_JHSVer
	- Line社が開発した「japanese-large-lm-3.6b-instruction-sft」をウィキブックの内容をもとに中学範囲にてファインチューニングを行いました。
- 「LOCAL AI HACKATHON」における、チームDataPilotの成果品第一弾である「ArrowSmart_1.7b_instant_sft」をリリースしました
	- https://huggingface.co/DataPilot/ArrowSmart_1.7b_instant_sft
	- Line社が開発した「japanese-large-lm-1.7b-instruction-sft」をウィキブックの内容をもとに地理、化学の分野でファインチューニングを行いました。
-  The Elements of Differentiable Programming
	- https://arxiv.org/abs/2403.14606
	- 新しいパラダイムである『微分可能プログラミング』の基本概念について Google DeepMind の研究者が383ページに渡るPDFを公開。論文より本という方が正しそう
	- プログラムを微分可能にすることは本質的に確率分布によってその出力の不確実性を定量化すること、とは面白い
	- **微分可能プログラミングとは**: プログラムのパラメータを微分可能な方法で最適化することにより、機械学習タスクを解決するプログラミングパラダイムです
	- **目標と範囲**: 本書は、微分可能プログラミングの基礎を説明し、その理論と実践の両方をカバーすることを目指しています。
- Sakana AIが、モデルマージを自動化・高度化する進化的モデルマージ（Evolutionary Model Merge）
	- https://huggingface.co/SakanaAI

## 3/18

今週もいろいろありすぎて、目が回ります。東工大からSwallow-MS 7BとSwallow-MX 8x7Bのリリース、前者は日本語最高性能とのこと。 量子化版も出て、Llama.cpp でSwallow-MX 8x7Bを動かした例も紹介された。Swallow-MS-7b-v0.1 を ichikara instruction で指示チューニングして、500ステップぐらいでいい感じとの報告も。「ELYZA-japanese-Llama-2-70b」が出たー、NHKでも紹介された、ABCIを12月から部分占有？、ようやくスタートラインというCEOの言葉が刺さる。Shi3zさんによると、Claude-3と比べると百人一首の知識が足りずまだ頑張れという感じだが従来のモデルと比べると格段の進歩があるとのこと。「JPX Market Explorer」、NISAで個別投資を考えているひとは必見。自社ビジネス＝株取引を活発にするための、生成AIの活用として面白い。256k token が扱えるGPT-4.5 Turbo が６月ごろにリリースといううわさが持ち上がる、リークなのか？。一般copilotからもGPT-4 Turboが使えるようになったらしい、OpenAI＋マイクロオフト陣営も遅れるわけには行けない。企業が期待する今風の「主体性」って、思考力と協調・協働できる力という話だけど、この分野、生成AIが苦手とも言えなくなった気がするな。AIによるソフトウエアエンジニアDevin、なんかすごい、駆逐される人たちがたくさんいそうだ。どうもVC界隈では、AI従業員の開発の風が吹いているとのこと。JSTの「自律駆動による研究革新」は研究そのものをAIで自動化という話、ひえ！。Claude 3 Opusを使って世界経済を分析するデモ動画も、エージェント（AI従業員）をつくって調査を加速できるという話。ああ、人はいらなくなるのか？。Claude3の性能評価は続く、ひろみちゅ先生が、様々なな事例を試して絶賛、Coinhive事件最高裁判決の解釈など、使い方の参考にもなる。Claude3 × Googleスプレッドシート、スプレッドシートから普通にClaude3を使える、なんかちがうな。松田先生の考察のように、LLMって十分疎なのではないか、まだまだ量子化とか軽量化の余地がある。世田谷区のAI bot、非エンジニアがノーコードで開発と。NLP2024も開催、岡野原さんの「大規模言語モデル開発の展望と今後の課題」、話題としては本LLMアプデ読者にはなじみの深い話題。AIは科学を促進するが、『理解の錯覚』を生み出す危険性がある、と記事は新しい視点で興味深い。カーツワイルさん、大脳皮質と計算機がつながるのが2030年代初頭といって話題に。OpenAIとロボット開発のFigureの提携の結果の第１段Figure01、いやこれってなんかの映画（パッセンジャー）で見た世界。NatureのAll of usのサマリーデータ、117個の疾患に関連する3724個の変異を同定され、データも公開とのこと。最後に、Xが予告お降り Grok-1のオープンソースリリース。直前に、OpenAIがGrokの別実装をOSSで公開してたりして、こういう競争、いや共創？って面白いな。


- 大規模言語モデルSwallow-MS 7BとSwallow-MX 8x7Bを公開しました
	- https://tokyotech-llm.github.io/swallow-mistral
	- Swallow-MS 7Bはオープンな7BのLLMの中で日本語最高性能を達成しました。
-  Yi: Open Foundation Models by 01.AI
	- https://arxiv.org/abs/2403.04652
	- Super interesting paper - 10k data is all you need for finetuning LLM
	- ファインチューニングには1万件のデータで充分なんだという論文。
- Claude 3に例の「読了目安2時間」記事を解説させてみた - 高木浩光＠自宅の日記（2024年3月11日）
	- https://takagi-hiromitsu.jp/diary/20240311.html
	- ひろみちゅ先生絶賛
	- 「Anthropicの先日出たばかりのClaude 3（Opus）が、ChatGPTのGPT-4を超えてきたと聞いて、自分の原稿を解説させてみたところ、確かに革新的な進歩が見られる。もはや内容…」
-  Is Cosine-Similarity of Embeddings Really About Similarity?
	- https://arxiv.org/abs/2403.05440
	- コサイン類似度を疑っていけ！！
- Swallow-MX-8x7b-NVE-v0.1のggufあります
	- https://huggingface.co/mmnga/tokyotech-llm-Swallow-MX-8x7b-NVE-v0.1-gguf
- 人工言語による事前学習を用いた言語間転移可能な知識の分析
	- https://www.jstage.jst.go.jp/article/jnlp/30/2/30_664/_article/-char/ja/
	- Transformerの事前学習に人工言語を使ったらどうなるか、どの要素が事前学習に効くのか、という研究 係り受け関係に入れ子構造が含まれることが重要らしい
- Llama.cpp で Swallow MX 8x7B をお試し中　by npakaさん
	- https://x.com/npaka123/status/1767380241520173408?s=20
- Stealing Part of a Production Language Model
	- https://arxiv.org/abs/2403.06634
	- GPT-4のようなClosedなブラックボックス大規模言語モデルでも,APIアクセスのみでモデルの一部の層のパラメータを特定できるModel-stealing attackを提案
	- GoogleのOpenAIに対する逆襲の一手的な論文
	- API経由でOpenAIのモデルにおける隠れ次元数を特定できることを示し、OpenAIがそれを受け対策を施したことを論文で報告しました。
- 700億パラメータの日本語LLM「ELYZA-japanese-Llama-2-70b」を開発し、デモを公開しました
	- https://note.com/elyza/n/n0ea755ca3e7b
	- https://elyza.ai/lp/elyza-llm-for-jp
	- 日本語特化モデルの中では最大級です.大きさが正義のLLMということで,実際報告されている性能もかなり抜けています
- ELYZA-japanese-Llama-2-70b をお試し中 by npakaさん
	- https://x.com/npaka123/status/1767439590502326514?s=20
	- デフォルトテンプレートの指示も効いてる
-  東大発のスタートアップ企業 “国内最大規模 国産生成AI完成”
	- https://www3.nhk.or.jp/news/html/20240312/k10014388011000.html
	- オープンソースと呼ばれる公開技術をベースに、産業技術総合研究所が運営するデータセンター「ABCI」などを活用し、去年12月から短期間で開発を実現しました。
	- イライザの曽根岡侑也社長は「昨年末時点ではオープンAIやグーグルなどのグローバルモデルと比べて日本のAIモデルは及ばない状態だった。今回ようやくスタートラインに立つことができ、日本が存在感を示せるようにしたい」と話していました。
-  松尾研LLM開発プロジェクトのキックオフを開催しました
	- https://weblab.t.u-tokyo.ac.jp/2024-03-12/
	- 当研究室が提供する講座の修了生および一般公募によって集まった有志の開発者のメンバーが500億パラメータサイズの大規模言語モデル開発を進めるものです。
	- NEDOによる、国内の生成AIの開発力を強化するためのプロジェクト「GENIAC（Generative AI Accelerator Challenge）」において、基盤モデル開発に必要な計算資源の提供支援を受けています。
	- 松尾教授からは「このプロジェクトの中で、試行錯誤しながら重要であるノウハウを共有することで良いモデルを作り、開発経験を積んでもらいたい。また、このプロジェクトを通して、より多くのLLM開発者を生み出し、参加者の皆さんが様々なところで活躍してもらうのが望みだ」とのコメントがありました。
- Elyza70B、Claude-3と比べると百人一首の知識が足りずまだ頑張れという感じだが従来のモデルと比べると格段の進歩がある by shi3zさん
	- https://x.com/shi3z/status/1767464684373082223?s=20
-  G-Retriever: Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering
	- https://arxiv.org/abs/2402.07630
- ＪＰＸ総研は、生成AIプロバイダであるBridgewiseの技術を活用し、日本市場にかかる情報を発信する新サービス「JPX Market Explorer」のPoCを開始します。
	- https://www.jpx.co.jp/corporate/news/news-releases/6020/20240312-01.html
	- 東証に上場する会社について、個社のビジネス概要や直近の決算のサマリーを簡単に調べたり、財務状況についての分析や競合他社との比較を行うことができます。
	- コンテンツや分析はBridgewiseの生成AIテクノロジーを利用して作成されます
	- 生成AIを用いて各企業の概要、直近の決算サマリ、財務状況の簡単な分析や競合他社との比較を行うことができる
-  Integrating Phenotypic and Chemoproteomic Approaches to Identify Covalent Targets of Dietary Electrophiles in Platelets
	- https://pubs.acs.org/doi/full/10.1021/acscentsci.3c00822
	- ブロッコリーには強力な抗がん作用があることは知られているけれど、シドニー大学らの研究によれば、ブロッコリーは癌だけでなく、脳卒中を引き起こす可能性のある血栓症を予防し、血栓症の治療を補助する効果もあると示された。
- Llama.cpp で Swallow MX 8x7B を試す
	- https://note.com/npaka/n/n0a9b514756ae?sub_rt=share_b
	- 「Swallow MX 8x7B」は、「Mixtral 8x7B」の日本語能力を強化した大規模言語モデルです
-  Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU
	- https://arxiv.org/abs/2403.06504
	- 本論文中で紹介されているFuyouを使うと、なんと一般消費者向けのGPUであるRTX 4090上で175Bパラメーター、つまりGPT-3 を微調整可能なんですって！
- Claude3の公式promptライブラリの英文校正prompt
	- https://note.com/genkaijokyo/n/n3f82b191dfda
	- Your task is to take the text provided and rewrite it into a clear, grammatically correct version while preserving the original meaning as closely as possible. Correct any spelling mistakes, punctuation errors, verb tense issues, word choice problems, and other grammatical mistakes. Use bold formatting in markdown to emphasize the edited portions of the English text.
- Raspberry Pi 5に日本語LLM(ELYZA-Japanese-Llama-2-7b-fast-Instruct)を入れてみた
	- https://arkouji.cocolog-nifty.com/blog/2024/03/post-e248e6.html
-  RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems
	- https://arxiv.org/abs/2403.06465
	- Microsoft presents a toolkit to integrate LLMs into recommender systems for explainability, conversation, and user control.
-  臨床予測モデル検証の要点
	- https://note.com/tadahiro_goto/n/n90128159a7fb?sub_rt=share_pb
	- 2024年1月にBMJのResearch Methods & Reportingで予測モデルの評価と外的検証に関するreview
	- Evaluation of clinical prediction models (part 1): from development to external validation.
	- ポイント
		- 臨床予測モデルは、**モデルがターゲットとなる対象集団を代表するデータセットで評価**すべき
		- 開発用データセットでは優れているように見えたモデルも、別のデータセットで評価すると、（仮に同じ母集団からのデータであっても）性能が低くなることがほとんど。
		-   **モデルを開発する時点でデータを分割(split)することは、信頼性の低いモデルにつながるため避けるべき**。
		- 利用可能なすべてのデータを活用する努力をすべき（内的検証におけるresamplingや、内的-外的交差検証など）
- Accelerate v0.28.0 has been released!
	- From XLA GPU support to FSDP + QLORA, and more, let's dive into what's new!
- 音声認識に使えるモデルは様々ありますが、現状最も使いやすいものの一つが faster-whispe
	- https://github.com/SYSTRAN/faster-whisper
- shioriha-large-pt
	- https://huggingface.co/cl-nagoya/shioriha-large-pt
	- 東北大BERT-largeに対し、batch size 8192, 系列長 256で、日本語WikipediaやMMARCOといった弱教師データによる対照事前学習を行ったモデルであるshioriha-large-ptを公開しました
- Tour of Modern LLMs
	- https://phontron.com/class/anlp2024/assets/slides/anlp-15-tourofllms.pdf
	- CMUの講義資料、
	- I made some new class slides on “a tour of modern LMs” that has some observations about characteristics of recent LLMs, mostly focusing on open LLMs where we know their details
-  Algorithmic progress in language models
	- https://arxiv.org/abs/2403.05812
	- How quickly have the algorithms behind language models like GPT-4 been improving over time?
- Talk like a graph: Encoding graphs for large language models
	- https://blog.research.google/2024/03/talk-like-graph-encoding-graphs-for.html
	- Graphs, structures that describe connections between objects, are everywhere — imagine the tools in a kitchen, parts of a bike, or a group of friends. Learn about our latest work that explores how to encode graphs in a format that an LLM can understand:
- GPT-4.5 Turbo possible release in June, 256k token context window
	- https://x.com/AiBreakfast/status/1767612026925277424?s=20
	- This OpenAI blog search result shows up in a DuckDuckGo search of “OpenAI GPT-4.5 Turbo” link, then goes to an OpenAI Error 404 page.
- 企業が求める主体性とはなにか？
	- https://www.amazon.co.jp/dp/4798918431/ref=cm_sw_r_as_gl_api_gl_i_294DJF3GFDESXD5WSRBV?linkCode=ml1&tag=regista13-22
	- 企業が期待する「主体性」はかつては行動力だったのが今は思考力と協調・協働できる力になってるとのこと。コミュ力の時代の反映。
-  いま「新しい数学」が必要だ。助けて数学者! by shi3z さん
	- https://note.com/shi3zblog/n/nafa1cee6ada2?sub_rt=share_pw
	- たぶんAI以後の世界で最も価値を持つのは「数学者」である。しかも「高次元幾何学」ないし、それを上回るくらいの概念を発明する数学者だろう
- Devin, the first AI software engineer.
	- https://x.com/cognition_labs/status/1767548763134964000?s=20
	- Devin is the new state-of-the-art on the SWE-Bench coding benchmark, has successfully passed practical engineering interviews from leading AI companies, and has even completed real jobs on Upwork.
	- AIのソフトウェアエンジニア（Devin）が人間レベルに達した初めてのデモだと思う。AIの導入で課題となってたのが長期的な推論と計画。ところが、Devinは計画→実行→評価→再計画を繰り返し、目標達成へと導くシステムを実現している
-  速報：Claude 3に判例評釈を自動生成させてみた（Coinhive事件最高裁判決の巻）
	- https://takagi-hiromitsu.jp/diary/20240313.html
	- 「これだけLLMが長文の意味内容を「理解」するようになったとなると、もはや、書評や論文紹介、判例批評など、定形的なスタイルを持つ学術記事は、…」
	- ひろみちゅ先生絶賛
- Swallow-MS-7b-v0.1 を ichikara instruction で指示チューニングの練習。500ステップ(0.2エポック : 20分) のお試しだけど、きれいに回答してくれてる
	- https://x.com/npaka123/status/1767807910925545892?s=20
- Claude 3 Haiku, the fastest and most affordable model in its intelligence class.
	- https://x.com/AnthropicAI/status/1768018310615151002?s=20
- With OpenAI, Figure 01 can now have full conversations with people
	- https://x.com/Figure_robot/status/1767913661253984474?s=20
	- ChatGPT、ついにロボットに宿る
	- 2週間前、OpenAIとロボット開発のFigureが提携を発表しました。
	- 今回、Figureは、ChatGPTの技術をロボットに搭載したことを発表しました。
	- 遠隔操作なしの100%エンドツーエンドのシステム 
	- OpenAIのモデルが高レベルの視覚と言語の知性を提供
	- Figureのニューラルネットワークが動画のようなロボットの動作を実現しています
-  Claude 3 Haiku の概要 by npakaさん
	- https://note.com/npaka/n/n71f1ef5f5e06?sub_rt=share_h
	- 本日 (2024年3月14日)、最速かつ最も低価格なモデル「Claude 3 Haiku」がリリースされました。「Claude API」および「claude.ai」のClaude Proサブスクリプションで利用可能です。
	- 速度
		- 「Claude 3 Haiku」 は、32,000トークン未満のプロンプトに対して1秒あたり 21,000 トークン (約 30 ページ) [1] を処理します
	- 低価格、
		- 「Claude 3 Haiku」の価格の**入出力トークンの比率は 1:5** です。わずか**1ドル**で **400 件の最高裁判例** [2] または **2,500 枚の画像** [3] を処理および分析できます。
- Claude3 × Googleスプレッドシート
	- Claude-in-Sheets guide
	- どうやら、AnthropicとGoogleが協力して、Google SheetsからClaude3を呼べるらしい。
-  Data Interpreter: An LLM Agent For Data Science
	- https://arxiv.org/abs/2402.18679
	- Data Interpreter has achieved state-of-the-art scores in machine learning, mathematical reasoning, and open-ended tasks, and can analyze stocks, imitate websites, and train models.
	- https://docs.deepwisdom.ai/main/en/DataInterpreter/
- 松田先生が、なぜ1.58bitのbitnetが上手く行くのか考えた話
	- https://x.com/umiyuki_ai/status/1768109605148848322?s=20
	- まず、LLMが何を計算してるか？というと、広大な言語空間の中から次の単語を当てるゲーム。最近のLLMの言語空間は4096次元とかあって、我々の物理空間が3次元しかないのに比べて有り得ん広さ。その中にトークナイザのトークン語彙はたったの3万種類とかしかないわけで、つまり一つの単語あたりに割り当てられた空間もメチャクチャ広い。だから1.58bitに量子化されて計算が雑になってもちゃんと当たる。
-  Artificial intelligence and illusions of understanding in scientific research
	- https://www.nature.com/articles/s41586-024-07146-0
	- 「AIは科学を促進するが、『理解の錯覚』を生み出す危険性がある」、というパースペクティブ論文。
- すべての無料版CopilotユーザーがOpenAIの「**[GPT-4 Turbo](https://gigazine.net/news/20231107-openai-gpt-4-turbo/)**」にアクセスできるようになったことが、Microsoftの広報担当責任者から発表されました。
	- https://gigazine.net/news/20240314-copilot-gpt-4-turbo-free/
-  Artificial Intelligence Controller Interface (AICI)
	- https://github.com/microsoft/aici
	- 大規模言語モデルの出力制御をカンタンにするオープンソースのインターフェース。Microsoft 製。開発者はコントローラーと呼ばれるカスタムロジックを用いて、LLM の生成プロセスをリアルタイムで制御可能。…
- 国産LLMが抱える“開発コスト”の課題　海外勢に安さで勝てるか、ELYZA代表の危機感
	- https://www.itmedia.co.jp/aiplus/articles/2403/13/news167.html
	- 国産随一の精度のLLMを開発したELYZA 。マイクロソフトやAWSが後押しする競合とどう棲み分けていくのか。曽根岡代表の発言をまとめました。
- alfredplpl/suzume-poc
	- https://huggingface.co/alfredplpl/suzume-poc
	- GoogleのGemma-2Bを日本語で使えるように継続事前学習を施した、商用利用可能なベースモデルSuzumeを公開しました。 小型なのでスマホや家電などに向いています
- 世田谷区がAI botを内製　非エンジニア職員がローコードで開発　ChatGPT活用「ヒデキ」
	- https://www.itmedia.co.jp/news/articles/2403/13/news123.html
	- 非エンジニアの職員チームが、ローコードツールなどを駆使して3カ月で完成させたという。
	- 職員が普段から使っているTeamsのチャットツールでヒデキに質問でき、ChatGPTを業務に活用できる
- Cappy: Outperforming and boosting large multi-task language models with a small scorer
	- https://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html
	- Cappy, a small pre-trained scorer model that enhances and surpasses the performance of large multi-task language models.
-  BitNet&BitNet b158の実装 by はち さん
	- https://note.com/hatti8/n/nc6890e79a19a
	- 一旦自身の理解のためにもBitNetの処理やBitNet b158の想像される実装、不明瞭な点を色々な方々の実装をもとに文字に書き起こしていこうと思います
- 岡野原さんの、「大規模言語モデル開発の展望と今後の課題」
	- https://hillbig.github.io/NLP2024_WS_okanohara.pdf
	- 様々なトピック（学習データ整備、MoE、Mamba、LongContext、推論効率化）などを紹介
-  MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training
	- https://arxiv.org/abs/2403.09611
	- Apple presents MM1, a family of multimodal LLMs up to 30B parameters, that are SoTA in pre-training metrics and perform competitively after fine-tuning
- Google Cloud Vertex AI に Anthropic の Claude 3 モデルが登場
	- https://cloud.google.com/blog/ja/products/ai-machine-learning/announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai/?utm_source=twitter&utm_medium=unpaidsoc&utm_campaign=fy24q1-googlecloud_jp-blog-ai-in_feed-no-brand-regional-apac&utm_content=announcing-anthropics-claude-3-models-in-google-cloud-vertex-ai&utm_term=-
	- Google は #Anthropic とのパートナーシップを通じ、包括的な #AI 開発プラットフォームである #VertexAI で Anthropic の最新モデルを提供していきます。これにより、エンタープライズ グレードのセキュリティや、パフォーマンスと費用の最適化に活用いただけま
- 清水れみお氏のGenerate Project Summary（プロジェクト要約生成）を使ってみる
	- https://six-loganberry-ba7.notion.site/24-03-15-Generate-Project-Summary-fa20870dfe66426d9e68b730e1f51f11
- Claude3にプロジェクト全体をぶち込むためのプロジェクトの構造とファイル内容を自動でまとめるPythonスクリプト
	- https://zenn.dev/olemi/articles/7b7992c055c64a
	- このPythonスクリプトを使えば、プロジェクトのフォルダ構造とファイルの内容を簡単にまとめることができます。
- Prompt Tuning から Fine Tuning への移行時期推定
	- https://speakerdeck.com/icoxfog417/prompt-tuning-kara-fine-tuning-henoyi-xing-shi-qi-tui-ding
	- ChatGPT や Claude のようなモデルに対し公開されている日本語言語モデルの利用は精度・コスト共に割に合わないと感じている方にとってパンチある内容かと思いま
- JST戦略的創造研究推進事業「自律駆動による研究革新」が来年度から始まります
	- https://www.mext.go.jp/b_menu/houdou/2023/mext_000010.html
	- 研究プロセスそのものを AI やロボット で加速する自律駆動型の研究アプローチ
-  LocalMamba: Visual State Space Model with Windowed Selective Scan
	- https://huggingface.co/papers/2403.09338
-  AI escape velocity: A conversation with Ray Kurzweil
	- https://www.bvp.com/atlas/ai-escape-velocity-a-conversation-with-ray-kurzweil
	- インタビュアー「私たちの大脳新皮質を、十分に高い帯域幅で計算機につなぐことができるようになるのはいつでしょうか？」 
	- カーツワイル「2030年代初頭です。その時点で、大規模言語モデルの全容量を脳内に持つ人間が存在することになるでしょう」
- ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- https://huggingface.co/ryota39/bilingual-gpt-neox-4b-instruction-sft-en-ja-84k
	- rinna/bilingual-gpt-neox-4b-instruction-sftに英日翻訳データセット84,300件をフルパラメータチューニングしました。商用利用可能なライセンス(cc-by-sa-4.0)ですので皆様お気軽にお試しください
- Researcher2Vec: ニューラル線形モデル による自然言語処理研究者の可視化と推薦
	- http://chasen.org/~daiti-m/paper/nlp2021researcher2vec-slides.pdf
	- 学振の後ろで動いてるらしい
-  日本語も理解できたCohereForAIのオープンソースのLLMモデルを試してみる。
	- https://note.com/masayuki_abe/n/n0e5e48fc4cc3?sub_rt=share_pb
	- CohereForAIのLLMをGoogle ColabのA100で実行したので紹介していきます
	- フリーのLLMなのに文章生成、数値計算、英訳、日本語理解力がChatGPTみたく回答されているのに驚きました。
-  第2回　AIと人間の未来を決める鍵「アライメント」――ちょっとだけマニアックなAIの話
	- https://bcg-jp.com/article/2230/
	- 今年はAIの発展がさらに加速すると予想されます。AIアライメントはAIと人間との未来を決める鍵となるでしょう。次回もお楽しみに
-  Genomic data in the All of Us Research Program
	- https://www.nature.com/articles/s41586-023-06957-x
	- 今週のNatureにAll of usのサマリーデータが出ている。約25万人（半数近くがマイノリティ）のゲノム解読で、10億もの多様体を検出、117個の疾患に関連する3724個の変異を同定、まとめデータも公開されているらしい
-  OpenAI Grok Curve Experiments
	- https://twitter.com/i/bookmarks
	- This is the code for the paper [Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets](https://arxiv.org/abs/2201.02177) by Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra
	- XからGroqがオープンソース化とのアナウンスが出たが、なんかOpenAIが別実装を公開！
- Claude 3 Opusを使って世界経済を分析するデモ動画
	- https://twitter.com/i/bookmarks?post_id=1769351991665594465
	- Claude 3デモの何が凄いかというと国別の経済動向を調べさせるため、
		- ①10個のSub-agentを作る 
		- ②必要なプロンプトを生成 
		- ③仕事を外注（笑） 
		- ④結果を集めレポートを書く と、
	- 自分の仕事をSub-agentにデリゲート（委任）できたこと。仕事を与えると一番効率のいい方法で進められるのがホント凄い。
- VCの後押しを受け、AI従業員を開発するスタートアップが流行の兆し
	- https://x.com/gijigae/status/1767836153053618465?s=20
-  Open Release  of Grok-1
	- https://x.ai/blog/grok-os
	- ついに本家のGrokリリース(3/17)
	- Base model trained on a large amount of text data, not fine-tuned for any particular task. 
	- 314B parameter Mixture-of-Experts model with 25% of the weights active on a given token. 
	- Trained from scratch by xAI using a custom training stack on top of JAX and Rust in October 2023.

## 3/11

今週は、AnthropicAIがリリースしたClaude3、GPT-4越えとか、自然な回答、エージェントなどの能力もありとか、落合氏やshi3z氏などLLMのプロもうならせる性能、レシート解析マルチモーダル性能、謎のアニメタグ付与性能、様々な能力で旋風を巻き起こしている。大学院レベルのGPQAベンチマークで最高性能さらには、IQ100相当であるという評価も出てきて、日本のプロのライターももはやClaude3でいいのではないかという話に。Langchain、llmaindexも激速でClaude3対応。Claude3の回答を観察すると、人の知識とか、聞きたいことをおもんばかって、人の心に差し込むように答えを入れてくる感じで、まさにLLM版の「不気味の谷」、これは(humanityの)終わりの始まりか。Groqは、gemma-7bベースのデモを公開、リアルタイムに、打鍵に合わせて、いや打ち込みの予測もしながら即回答、これは経験しないとすごさがわからない。Claude3が示した高い能力と合わせて見ると、人の心の状態をリアルタイムに推定して、それに応じた回答をする、場合によっては状態を変更するかもしれない、それってやばいよね。来日した、Benjio氏がやたらalignmentを強調するわけもわかるわ。分割統治式でタスクを分解するNVIDIAのAgent、Qwen-AgentとかAgent周りも当然進む。一方、日本のサブカルに強いgemma-7bベースの日英・英日翻訳モデルとか日本語モデルやデータセットの進展もある。 「はじめての統計的因果推論」、ゆるめの表紙の割には辛口なのが面白い。「統計学の極意」の邦訳版、日本のAIリテラシー向上に寄与できるか。Benjoさんの東大講演、Hintonさんの日経インタビュー、いづれもAIが人を超えることによる脅威について語っている感じなのは興味深い。さて、Appleが生成AIに注力と発表、M3 MacBook Airを突然発表し、なんか不気味な感じがしますね。

- Apple、パワフルなM3チップを搭載した新しい13インチと15インチMacBook Airを発表
	- https://www.apple.com/jp/newsroom/2024/03/apple-unveils-the-new-13-and-15-inch-macbook-air-with-the-powerful-m3-chip/
-  WSL2でSwallow-7b-plus-hfを試してみる
	- https://note.com/ngc_shj/n/n80871f8e4e24?sub_rt=share_h
	- 使用するPCはドスパラさんの「GALLERIA UL9C-R49」
	- chat(instruct)モデルではないので、--no-chatとして起動します
	- これは、なかなかいい感じである。いままで最高かもしれない
- Awesome-Graph-LLM
	- https://github.com/XiaoxinHe/Awesome-Graph-LLM
	- グラフベースの手法とLLMの双方が関連している研究論文のキュレーションリストレポジトリ
- Jurafsky-MartのSpeech and Language Processing  (3rd ed. draft)
	- https://web.stanford.edu/~jurafsky/slp3/
	- In-Context LearningやInstruction Tuningの章も追加
- Toolformer: Language Models Can Teach Themselves to Use Tools
	- https://arxiv.org/abs/2302.04761
	- Metaがツールの使い方を覚える言語モデルToolformerを開発
	- 要点
		- 大規模言語モデルはわずかな例示や指示だけから課題解決を行う驚くべき能力を持つ
		- 一方で、計算や事実チェックはより単純なツールの方が優れた性能を発揮する
		- 両者の長所を生かすため、ツールの呼び出し指示をテキスト化し外部ツールの使い方を自己学習する言語モデルToolformerを提案
-  Learning and Leveraging World Models in Visual Representation Learning
	- https://arxiv.org/abs/2403.00504
	- MetaのJEPAの論文、Meta presents Image World Model
- Build an LLM-Powered API Agent for Task Execution
	- https://developer.nvidia.com/blog/build-an-llm-powered-api-agent-for-task-execution/
	- NVIDIAより。LLM使ったAPI Agent
	- ユーザーのクエリに対して、LLMがあらかじめ定義しておいたテンプレを使って子モジュールのLLM用のプロンプトを生成し、子モジュールLLMがそれぞれのタスクをこなして結果を返す
- AnthropicAI、Claude3をリリース
	- https://x.com/AnthropicAI/status/1764653830468428150?s=20
- llamaindex、さっそく Claude3サポート
	- https://docs.llamaindex.ai/en/latest/examples/llm/anthropic.html
	- Like Gemini and Mistral's latest offerings, Claude 3 comes in 3 "flavors" with the largest, Claude Opus, claiming better performance than GPT-4 across a wide range of benchmarks.
- ZETA editing
	- https://huggingface.co/spaces/hilamanor/audioEditing
	- ZEro Shot Audio editing using DDPM inversion
	- Edit Audio with Nothing but Prompts!
- Meta’s AI Watermarking Plan Is Flimsy, at Best Watermarks are too easy to remove to offer any protection against disinformation
	- https://spectrum.ieee.org/meta-ai-watermarks?share_id=8133421&utm_campaign=RebelMouse&utm_content=IEEE+Spectrum&utm_medium=social&utm_source=twitter
- Claude3の評判
	- Claude 3 Sonnet 、とにかく生成が早い！！！！！
	- https://x.com/izutorishima/status/1764702243520208962?s=20
	- Sonnet でも一部ベンチマークは GPT-4 と同等かそれ以上に達していて、この速さを無料アカウントで使えるのは普通に OpenAI さんピンチじゃないですか？
	- Claude が賢くなって目もついた！モデルは三つで、Haiku / Sonnet / Opus の順に賢く、値段があがる
	- 最高性能の Opus は 10 個のベンチマークで GPT-4 を 10 個とも超えている。Haiku のレスポンスはウェブ版で試してみたけどマルチモーダル（ここでは画像入力だけですが）については GPT-4-V より上で Gemini 1.0 Ultra と同程度。
	- 200k トークンの長文入力は健在で、さらにすべてのモデルで 1 million トークンも入力できるモデルのよう。ただしこちらは一部のクライアントにのみ提供。
	- 大量の文章の中から重要な情報を抜き出せるかの評価に用いる「Needle In A Haystack」では、精巧性能の Opus をもってすれば精度 99% を達成。今までの Claude 2.1 と比べてめちゃはやい。公称 2 倍。
	- また、JSON 出力など構造化データの出力が得意になり、自然言語による分類や感情分析などもできるように。使ってみたのですが、かなり良い感じに構造化データに変換できました
	- API は現時点で Opus と Sonnet は公開。Haiku は近日公開予定。
- 今まで ChatGPT で書かせた文書って「それっぽさ」があったけど、Claude 3 は非常に丁寧な日本語でもう AI 製かどうかわからん
	- https://x.com/izutorishima/status/1764890317302727114?s=20
- LangchainのClaude3サポート
	- https://python.langchain.com/docs/integrations/chat/anthropic
- img2table
	- https://github.com/xavctn/img2table
	- 画像から表を抽出するPythonライブラリなんだけど、めっちゃいい。セル結合にも対応してて大変素晴らしい
- 大規模言語モデルを用いたゼロショットテキスト分類によるTCFD推奨開示項目の自動判定」
	- https://www.jpx.co.jp/corporate/research-study/working-paper/Summary_JPXWP_Vol43.pdf
	- GPT-4により、92.8%のAccuracyで上場会社の有価証券報告書のテキストを判別できるという結果に
- gemma-7bベースの日英・英日翻訳モデルをQLoRAアダプターの形式で公開しました
	- https://huggingface.co/webbigdata/C3TR-Adapter
	- 翻訳ベンチマークで多言語翻訳モデルであるGoogleのMadlad400やmetaのSeamless m4t v2 large、ALMA-Ja-V2 (私の以前のモデル)よりも大幅に優れており、サブカルチャー文脈に一部対応可能な事が特徴です
- RAGでの回答精度向上のためのテクニック集（応用編-A）
	- https://zenn.dev/knowledgesense/articles/cec1cd43244524
	- 「応用編-A」では、特に1つ目の「ユーザーの質問に回答するために最も必要な（最も関連している）ドキュメント群を抽出する」ための具体的なテクニックについて見ていきます。
- Claude 3 Opus、Danbooru Taggerの機能もある
	- https://x.com/alfredplpl/status/1764951315636158535?s=20
	- アニメの話らしい
- BASED: Simple linear attention language models balance the recall-throughput tradeoff
	- https://www.together.ai/blog/based
	- Transformerの24倍のスループットを持つLLM
- Claudeの文字起こしやばいな　領収書、形式も含めて完璧に読み取れた
	- https://x.com/SuguruKun_ai/status/1764918827769606393?s=20
- Wikipedia で雑なQAデータセットを作りました。
	- https://huggingface.co/datasets/alfredplpl/wikipedia-qa-ja-500k
	- 50万件以上あります。Instruction tuning用では日本で一番件数があるので適当に使ってください
- 野村総研による生成AIレポート
	- https://www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/publication/chitekishisan/2024/01/cs20240104.pdf?la=ja-JP&hash=ED42BFF77381C8AD102B7792B56D2654AD7BC6D5
	- 生成AIで影響を受ける職種のリストが載ってるのは最近よく見るけれど、一位が水族館飼育員なのが斬新さを感じた。あとファンドマネージャーが上位にいるのも面白い
- Claude 3の技術レポートによれば、大学院レベルの物理学・化学・生物学の知識と推論に焦点を当てたGPQAベンチマークで最高性能（0 shot CoTで50.4%、多数決利用で59.5%）
	- https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf
- Build a Large Language Model (From Scratch)
	- https://github.com/rasbt/LLMs-from-scratch
	- Manning社（日本だとよくオライリーの皮を被る出版社）からフルスクラッチで大規模言語モデルを作る本が出る模様。GitHubに公開あり
- Tokanizer playgroundがClaude3に対応
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- If you want to calculate how many tokens you're sending to the API, check out The Tokenizer Playground, which we recently updated to include the Claude 3 tokenizer!
- Claude 3 is impressively good at OCR and structured extraction
	- https://x.com/jerryjliu0/status/1765101841535336929?s=20
	- We fed it this complex Excalidraw diagram about the Prometheus model - contains subsections, and interleaving text and diagrams
	- Claude 3 is able to provide a summary of each section and also determine the positions of the diagrams!
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/anthropic_multi_modal.ipynb
- AnthropicのClaude Proまとめ
	- 月額$20(USドル)で最高モデルのClaude Opusとチャット出来るサブスクサービス 
	- chatGPT Proが40メッセージ/3時間の制限があるのと同様に使用量制限はあるが目安しか明記されていない 
	- 無料版と比較して少なくとも5倍の利用枠。短めの(約200単語の英語の文章)であれば8時間ごとに少なくとも100のメッセージを送信可との事 
	- 無料版は1日あたりのメッセージ枠制限だが、有料版は8時間毎に枠がリセット 
	- 『華麗なるギャツビー』のコピーをアップロードした場合(訳注：おそらく1MB未満)8時間以内に送信できるメッセージは20件になるとの事 
	- アップロードできるファイルは文章(doc)か画像(image)で最大5ファイル各10MBまで ・zipはアップロードできないのでソースコード一式をアップロードして解析みたいな事は難しそう 
	- 2023年8月までのデータでトレーニングされている
	- デフォルトではClaude Proに入力された会話はモデルのトレーニングに使用されない(親指アップ/ダウン機能を通じてフィードバックを送信すると使われる) 
	- 無料版については微妙な書き方なので良く分からない(当社の消費者サービスまたはベータ/評価サービスを使用する場合、当社は、お客様のプロンプトや会話を使用して、モデルをより安全にするための利用規約の監視と強制など、信頼性と安全性の作業に関連するモデルをトレーニングすることもあります、との事) 
	- アップロードしたPDFを要約して貰おうとしたら出力は一気にされず「続きを」と促す必要があった
- Claude3はよい、by　落合陽一
	- Claude 3を使いまくってみて，コードレビューが秀逸，日本語性能が良い（gpt4-0613も良いが），pdfなどの扱いが便利．この辺りすでにchatGPTからの移行が起こっている．快適すぎる
	- https://x.com/ochyai/status/1765209291517210816?s=20
- LLMの能力について語る人間の思考力が問われているのではないか　by shi3zさん
	- https://x.com/shi3z/status/1765310307994611798?s=20
- Claude 3 Opus structured query agent
	- https://colab.research.google.com/drive/1hkwipueVyi2Jzo58Z8jfdZ_9rSscfGxd
	- How good is AnthropicAI's Claude 3 Opus at being an agent? Pretty darn good! Check out this quick notebook in which Claude answers a complex, multi-source question by reading a PDF table and using the answer to do math on the contents of a CSV!
- Knowledge-Augmented Planning for LLM Agents
	- https://arxiv.org/abs/2403.03101
	- Proposes an approach to enhance the planning capabilities of LLMs through explicit action knowledge.
- 大学・MetaAIからハルシネーション低減に有効なグラフ拡張したRAG"G-Retriever"の提案
	- https://arxiv.org/abs/2402.07630
	- 部分グラフ抽出を賞金集めSteiner木問題(PCST)で解いている。
- スクショからコード生成！MicrosoftとDeepMindが共著した論文
	- https://github.com/NoviScl/Design2Code
	- -The Design2Code benchmark dataset for the task of converting visual design (screenshot) into code implementation, which consists of 484 real-world webpages from C4 (examples shown below).
- Claude3の開発者が示した、システムプロンプト、シンプル
	- https://x.com/AmandaAskell/status/1765207842993434880?s=20
- はじめての統計的因果推論
	- https://x.com/takehikohayashi/status/1765268689367265668?s=20
	- 開始3ページ目で「統計的因果推論最強論」にいきなり冷や水をぶっかける
- Qwen-Agent
	- https://github.com/QwenLM/Qwen-Agent
	- Agent framework and applications built upon Qwen1.5, featuring Function Calling, Code Interpreter, RAG, and Chrome extension
- Yoshua Benjio氏の来日東大講演
	- https://www.youtube.com/watch?v=8aTkuvbd_jU
	- 思いっきりAIのもたらす壊滅的なリスクやアライメントの話をコアにしている
- toshi456/llava-bench-in-the-wild-ja
	- multilingual-llava-bench-in-the-wildの日本語データの翻訳ミスや未翻訳のデータをDeepL+手動で修正したデータを公開しました。 
	- 先日Turingさんが公開したLLaVA-Bench-JA(COCO)と合わせて日本語VLMの評価にご活用ください。
- Claude-3がAIで初めてIQ100超えを達成したと主張
	- https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq
	- 「現在の成長率を単純に外挿すると、4～10年後にはClaude-6がIQの質問にすべて正解し、誰よりも賢くなることが示唆された」
- 対話系はClaudeが抜きん出て強い
	- https://x.com/reasan_mirasan/status/1765513422504890417?s=20
- LangChain Text Splitters
	- https://x.com/LangChainAI/status/1765418125569491233?s=20
	- One of the most popular parts of LangChain is our text splitters - simple yet necessary for any RAG app
-  Large language models surpass human experts in predicting neuroscience results
	- https://arxiv.org/abs/2403.03230
	- 神経科学の実験結果をLLM (Llama2・Mistral・Falcon・Galactica) で予測する研究
	- 論文アブストの背景と方法部分から二択で結果を予想する問題セット「BrainBench」を作り，LLM vs 専門家で比較
	- 基本的に専門家よりLLMが強い LoRAで神経科学用にfine-tuningすると性能がさらに上がる
- Claude 3 Cookbook by llamaindex
	- https://colab.research.google.com/drive/11HzzDd6fAiH2s8nDjZMRY5nx2Licl_tF?usp=sharing
	- we go through a comprehensive cookbook to show how Claude 3 can be used in a variety of different application use cases with
- GaLoreってのは事前学習がメッチャ省メモリでできるテクノロジーらしい
	- https://x.com/umiyuki_ai/status/1765927780263633236?s=20
	- VRAM24GBで7BモデルのLLMの事前学習ができてしまうらしい
- Meta announces Teaching Large Language Models to Reason with Reinforcement Learning
	- https://huggingface.co/papers/2403.04642
- WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- https://huggingface.co/WhiteRabbitNeo/WhiteRabbitNeo-7B-v1.5a
	- At the request of the open source community, we're now releasing a 7B model for offensive and defensive cybersecurity. This can be run locally in most computers with less GPU VRAM.
- プロのライターが「仕事には、GPT-4は言うほど大して使えないけどClaude3はそこそこ使える」
	- https://x.com/umiyuki_ai/status/1766284320208212472?s=20
	- たぶん、https://x.com/yukatan/status/1766610634832306408?s=20
	- ようやっとclaude3を試しましたが、たしかに「リリース起こし」については「え、私の仕事やばいかも」と思うレベルに近づいている。
- cyzgab/catch-me-if-you-can
	- https://huggingface.co/spaces/cyzgab/catch-me-if-you-can
	- GroqInc just added support for Gemma 7B. 
	- なんかリアルタイムに質問に答えて（打鍵毎に予測して回答を生成している）
	- まさに、catch me if you canとは。
- ヒントン氏、AIは言葉を理解していると、、、（日経）
	- https://www.nikkei.com/article/DGXZQOGN143CZ0U4A210C2000000/?n_cid=nk_chart_qr
	- 「…大規模言語モデルは、我々と同じように言葉を理解していると思う。…AIが言葉を理解していないという人の大半は、人間がどう理解しているかという理論を持っていない」
	- ポイント
		- 人類存続の危機をもたらす恐れがAIにある  
		- 自律的に人を殺すロボット兵器が10年以内に登場  
		- 大規模言語モデルは脳より効率的に学習できる
- 「統計学の極意」
	- https://www.soshisha.com/book_wadai/books/2692.html
	- 数式は最小限、面白い実例は満載。統計学入門書最新決定版
	- 本書は、入門者が知るべき統計学の現代的論点を網羅しており、まさに待ち望まれた「統計学入門書最新決定版」と言えるでしょう

## 3/4

今週は、1ビットLLMの衝撃!マイクロソフトの発表(The Era of 1-bit LLMs)、 70Bで8.9倍高速ということで、勝手実装、追試も続々、200Mでそれなりに動くというshi3zさんの評価も、shi3zさんによると、「プログラマーなら全員BitNet試してみるべき」だそうだ。小さく試すという意味では、250MのMixtralをpretrainingからfinetuningを試した事例も。てっぺんが高いところにあると周辺も拾うところがたくさんあるという、LLM界隈でのトリクルダウン現象が起きているのか。さて、先週公開されたgemma、ollamaでサポート、やれ周辺モジュールにバグが多いとか、いやファインチューニングで使えたとか、いろいろ評価がある、2bのほうが7bより性能よいと謎の報告も、ちょっとリリース急ぎすぎたか。一方Qwenは、Qwen1.5最高とか、もはやQwen-72Bでいいのではないのか、という評価も出ているが、実は出力をデータセットようには使えないなどの縛りがあるとのこと。マネフォOBが立ち上げたスタートアップstarleyの音声会話型おしゃべりAIアプリ「Cotomo」、UXを考えてちゃんと使える商品に落とすこむことの大切がよくわかる。Mistral Large、「Gemini Proなどのクローズドモデルよりも高いベンチマークスコアを獲得」って本当か？LLMには自然言語よりも最適な形式があるのでは？という野心的な『AutoForm（オートフォーム）』、そういえば先輩の三つ子ちゃんは、独自の言語でコミュニケーションしていたって言ってたな。東工大の、『論文の結論を学習させたら性能が下がった。』という話、イントロのほうがよいというのは不思議だ。μTransfer、転移学習のマイクロ版？大規模モデルの学習をおそらく圧倒的に効率化できるのはよい。Gemini 1.5 Proも使える人が少しずつ拡大している模様、来週あたりはいろいろ評価がでるかも。Gemini 1.5 Proの長コンテキスト性を利用し、Long-context LLMs がRAGの代わりになるかならないかを評価して長コンテキスト時代の新しいRAGアーキテクチャの提案とかあった。Function Calling、色々なLLMで使えるライブラリが出てきて、当たり前の技術になりつつあるな。LlamaParseのPDF読み取り評価とか、RAGでの回答精度向上のためのテクニック集とか、そのあたりの地道な進みもあった。 NVIDIAがノートパソコン用のGPUを新発表とか、まさにwinner takes allの世界。さて日本の優秀な頭脳はどうよ？ということで先週、がっちりマンデーで、東大出身の若者が多いベンチャー「燈」が紹介されたが、あれって、「建築×AI」のテーマで、LLMをがっつり活用するという話。若い人の意識が基盤というより社会実装というかそっち系に流れてる？

- 画像生成AI、安いPCでも高速に　衝撃の「Stable Diffusion WebUI Forge」
	- https://weekly.ascii.jp/elem/000/004/185/4185940/
-  μTransfer: 小規模モデルでのハイパラ探索を大規模モデルに転移し学習を効率化する
	- https://note.com/tatsuyashirakawa/n/n9f5b57ce1aa6?sub_rt=share_pb
	- μTransfer は、μP （Maximal Update Parametrization）という理論的に導出された NN のパラメータ付けにより実現される、サイズの異なる NN 間のハイパーパラメータ転移です。
	- （知らなかった読者にとって）大規模モデルの学習をおそらく圧倒的に効率化できる汎用的かつシンプルなパラメータ付け μP の存在と使い方を知ることができる。
	- Neural Networks に対してかなり一貫性のある理解が得られそうな気分になる。学習率やパラメータの初期化のスケールに関する話がなんでも TP/μP で取り扱うべき事項に見えてくる。
- ウェブの日本語テキストをクリーニングするための基本的な処理コードと課題
	- https://note.com/kan_hatakeyama/n/n331bda7d77c1?sub_rt=share_pb
		- 文字列の正規化　(変な文字コードを消す)
		- ルールベースでの、不要な文字列の削除
		- 機械学習ベースでの、不要な文字列の削除
		- 重複の削除
- 【最強になった】Googleの最大1000万トークン入力可能なGemini 1.5 Proがヤバすぎる。《概要、他LLMとの比較、ビジネスシーンでの活用方法5選を徹底解説》
	- https://note.com/chaen_channel/n/necaf27db79ae
-  LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens
	- https://arxiv.org/abs/2402.13753
	- It looks like the problem of long contexts in open LLMs is close to being solved.
- ​”話したいことも、話せないことも。” 音声会話型おしゃべりAIアプリ「Cotomo」を提供開始
	- https://prtimes.jp/main/html/rd/p/000000007.000123714.html
- たくさんのお客様がCotomoとおしゃべりしていることで、動作が不安定になる事象が発生しております
	- https://x.com/starley_jp/status/1761753632788357611?s=20
- Qwen1.5 速いし日本語完璧だしすごい by shi3z
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ku-nlp/gpt2-large-japanese-char
	- 弊研のhuggingfaceリポジトリで charcter vocabulary の日本語 gpt2-large（A100 1枚で訓練8か月!）が公開されているので、何かの興味で日本語の文字レベルの言語モデルが欲しい方は是非使ってみてください
- ローカルで気軽にRAGを使って会話することが簡単すぎてビビった。
	- https://qiita.com/mitsumizo/items/469d79c5e81d9189a9e4
- 日本のオープンデータ情報一覧・まとめ
	- https://github.com/japan-opendata/awesome-japan-opendata
	- PLATEAU AWARD 2023でグランプリを受賞した方のGitHubらしい
-  AITuberのブレイクスルーは音声雑談から始まった Cotomo
	- https://note.com/o_ob/n/n27edbebf17af?sub_rt=share_h
	- ・敬意を持って接する  、「話すの楽しい」設定 、過去の会話をキャッシュする  、相手の速度に合わせて早口になる  、一度言った話は2回目は早口  、お別れを名残惜しむ
- Mistral announces Mistral Large, a new flagship model.
	- https://x.com/omarsar0/status/1762140818654064721?s=20
		- 32K tokens context window
		- has native multilingual capacities
		- strong abilities in reasoning, knowledge, maths, and coding benchmarks
		- function calling and JSON format natively supported
		- available through Microsoft Azure
		- a low-latency model called Mistral Small was also released
- Qwen1.5-72B-Chatをお試し中。
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
	- もう全部Qwen-72Bでいいんじゃないかな
	- https://x.com/alfredplpl/status/1762277261435347424?s=20
- Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models
	- https://arxiv.org/abs/2402.14848
	- プロンプトの入力が長くなるにつれて、推論性能に顕著な低下が見られることが示唆
	- ■実験結果
		- 入力が長くなると推論の精度が低くなる
		- 失敗モードは主に4つで、入力が長くなるほど顕著になる 
			- 1. 回答拒否 
			- 2. 偏った判断 
			- 3. 頭から答えを言う（推論ステップを辿らない）、 
			- 4. 入力テキストを適切に使わない
- RAGでの回答精度向上のためのテクニック集（基礎編）
	- https://zenn.dev/knowledgesense/articles/47de9ead8029ba
- NVIDIAがノートパソコン用のGPUを新たに発表
	- https://x.com/webbigdata/status/1762645658266468393?s=20
	- RTX 500 GPUは4GBのGPUメモリ 
	- RTX 1000 GPUは6GBのGPUメモ
- LangChainに便利な機能が誕生してまし
	- https://x.com/MLBear2/status/1762623474034790886?s=20
	- Pydanticで構造体を定義した上で `with_structrured_output` を図のように使えば、Function Callingを簡単に呼べるようになりました。 
	- ChatGPTだけではなく、GeminiなどFunction Callingに対応する他のLLMでももちろん使えるとのこと。
- Function Calling Cookbook with Open-source models (LlamaIndex+FIREWORKS)
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/fireworks_cookbook.ipynb
	- We’re excited to present a series of cookbooks showing you how to use LlamaIndex with Fireworks, including function calling and RAG with FireFunction-v1.
- PDFがスルスル読める！話題のLlamaParseとは
	- https://zenn.dev/yokina_kaoto/articles/563f7d75673c2e
	- LlamaParseはLlamaIndexの新しい製品で、再帰検索を実行することで複雑なPDFのテーブルをきれいに抽出することができ、しばしば悩まされる複雑なドキュメントのより正確な解析を約束します
	- LlamaParseでPDFをパースし、AstraDBで**非構造化データ**を検索することで精度が向上するとのこと。
- 新Kaggleコンペ： LLMで生成された文章からプロンプトを復元するタスク
	- https://www.kaggle.com/competitions/llm-prompt-recovery
	- LLMで生成された文章からプロンプトを復元するタスク。
	- データはGoogle Gemmaで作成。評価がsentence-t5-baseの埋め込みベクタとのコサイン類似度なのが時代を感じる。もうJaccardスコアとかの時代じゃないらしい
- iOS17.4のソースコードにOpenAIの何かを含む部分が見つかっていて、おそらく数ヶ月以内にSiriが強力にアップデートされます。
	- https://x.com/1amageek/status/1762422935376302226?s=20
-  The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits
	- https://huggingface.co/papers/2402.17764
	- Microsoft presents The Era of 1-bit LLMs 
	- All Large Language Models are in 1.58 Bits
	- これ本当ならタイトル通り生成AIの新時代かもしれない
-  1ビットLLMの衝撃! 70Bで8.9倍高速　全ての推論を加算のみで!GPU不要になる可能性も by shi3zさｎ
	- https://wirelesswire.jp/2024/02/86094/
	- いずれにせよ、　この論文が本当だとしたら、とんでもないことが起きることになる。
- Microsoftが「1ビットLLM時代の到来」という衝撃的なタイトルで論文を公開し、GPUが不要になるかもしれないとの話も出てきているので従来の手法との違いをまとめました
	- https://x.com/webbigdata/status/1763021292696170917?s=20
-  驚異の1ビットLLMを試す。果たして本当に学習できるのか? by shi3zさん
	- https://note.com/shi3zblog/n/n58b0a2252727?sub_rt=share_pb
	- 試したのはこちら
		- https://github.com/Beomi/BitNet-Transformers/tree/main
	- なんかそれっぽいこと言ってる!!!!!!  しかも小さいから当たり前なのだが推論は超速いのである。
	- モデルサイズは200MB。GBじゃないよ。  僕は小さい言語モデルも大きい言語モデルもそこそこ触って来た方だと思うが、このサイズ
- Mixtral 250MのpretrainingからInstruction Tuningまで
	- https://zenn.dev/if001/articles/9bb90e0d8c201f
	- MoEを持つMixtralがhuggingface/transformersで公開されているので、これを利用しつつ、250Mの小さいサイズとして日本語と英語でpretraining、finetuningを行います。
	- 250MのMixtralをpretrainingからfinetuningまでを行いました。小さいサイズなりにうっすら日本語を理解してそう。入力から正確に情報を抽出とそれらを使った出力はさすがに難しそう。あとは、推論時のexpertの選択のされかたや同サイズのモデルとの比較をしてみたいところ
- プログラマーなら全員BitNet試してみるべき by shi3zさん、
	- https://github.com/kyegomez/BitNet
- gemma-7b、英日翻訳タスクに関しては微調整に成功すると私の翻訳モデルALMA-7B-Ja-V2より一段階レベルが上の性能でした
	- https://x.com/webbigdata/status/1762791697212375111?s=20
	- 周辺モジュールにバグが残っていて、英語圏ではあきらめる勢が多いみたい。
- LlamaIndexとGroqの統合
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/groq.ipynb
- Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication
	- https://arxiv.org/abs/2402.18439
	- 「自然言語を超えて」と題して、LLMにタスク実行時の思考を人間の自然言語とは異なるフォーマットで行わせるプロンプト手法『AutoForm（オートフォーム）』が考案されました。
	- LLMの思考は必ずしも人間と同じフォーマットに沿う必要はない、といった結論になります。LLMエージェント同士でコミュニケーションする際にはこの方が効率的かもしれないとのこと。
	- 自然言語に固有の曖昧さを排除し、明確性を高めるために、ステップバイステップの解決策には、より構造化されて簡潔なコミュニケーションの形式を検討してください。適切なフォーマットには、コード、擬似コード、JSON、マークダウン表、論理演算子、または数学方程式が含まれます。回答の最後には、〜〜という形式で答えを示さなければなりません。簡潔かつ正確であることを忘れないでください。
- ChatGPTは数学を解く時に厳密に計算するためにADA（Advanced Data Analitics, Code Interpreter）をデフォルトで使用する様に変わってます
	- https://x.com/ai_syacho/status/1763308074503422008?s=20
	- しかも数学計算の計画も立てる事ができる。
- オリジナルのBitNetを1.58bの論文に従って3値にするように修正しました
	- https://github.com/frodo821/BitNet-Transformers
- Beyond Disciplines「Beyond Disciplines ～CRDSが注目する研究開発の潮流2024～」
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-06.html
	- 所属組織が発行している数十冊・計数千ページの報告書を40ページくらいに圧縮したレポート作成にかかわりました。
- Qwen1.5-72B 日本語能力も高くて良いが生成物でデータセットは作れない規約で残念。
	- https://x.com/alexweberk/status/1763905106674954324?s=20
- 『論文の結論を学習させたら性能が下がった。』
	- https://newswitch.jp/p/40657
	- ６万５０００報の論文データセットを構築した。学習データでは、論文の要約よりもイントロダクションが性能向上に役立った。論文の結論の学習は、性能面でネガティブに働いた。小さなＬＬＭにとっては結論の内容が専門的過ぎた可能性がある。専門知識を備えたＬＬＭを構築するための知見になる。
- 【論文丁寧解説】BitNet b1.58とは一体何者なのか
	- https://qiita.com/tech-Mira/items/67dec9c5a5f025d2727a?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- BitNet b1.58は、その名の通り、各パラメータが、、[−1、0、1]という3つの値での動作を実現した1bitのLLMです。つまり、膨大な計算リソースを必要とする従来のモデルとは異なり、非常に効率的に動作します。加えて、この記事で示されている結果では驚くべきことに、性能は従来の高精度モデルを上回ります。
	- BitNet b1.58とFP16 LLaMA LLMを様々なサイズで比較しました。公平な比較を保証するために、モデルをRedPajamaデータセットで1000億トークンに対して事前学習しました。
- Google AI 進化的 で つくよみちゃんの会話テキストデータセット による Gemini の チューニングを試す by npakaさん
	- https://note.com/npaka/n/n8b03a58abb2c?sub_rt=share_h
	- 「Google AI 進化的」で「つくよみちゃんの会話テキストデータセット」による「Gemini」のチューニングを試したので、まとめました。
-  Towards Long Context RAG by llamaindex
	- https://www.llamaindex.ai/blog/towards-long-context-rag
	- We did a deep dive into Gemini, and consolidated our thinking about long-context LLM benefits, challenges, and new architectures
	- Long-context LLMs will help alleviate the need to do precise chunking and retrieval, and RAG over small sets of documents
	- Long-context LLMs still don’t resolve the issue of RAG over big knowledge bases (present in most organizations/enterprises)
- Gemini 1.5 Proが遂にきました！！！！
	- https://x.com/masahirochaen/status/1763639557457899963?s=20
- GoogleのGemma、2Bの方が7Bより性能が良いとかおかしな事が報告されている
	- https://x.com/webbigdata/status/1763730996455973098?s=20
	- Jeremyさんの言っている通り、fine tuningはHugging Faceに掲載されているTransformers実装ではなくて、githubのgoogle-deepmind/gemmaを参考にした方が良いのかもしれません
	- https://x.com/jeremyphoward/status/1763679390968455185?s=20
-  ロングコンテキストLLMに対応したRAGの新アーキテクチャ by npakaさん
	- https://note.com/npaka/n/n0b17244bae47?sub_rt=share_h
	- 「Gemini 1.5 Pro」の機能をプレビューすることができ、それを試してみることで、ロングコンテキストLLMを適切に使用するには、RAGがどのように進化するのかについてのまとめました。
	- **Gemini は特定の詳細を見事に思い出すことができる**
	- **Gemini は素晴らしい要約能力を持つ**
	- **10Mトークンは大規模な文書コーパスには十分ではない**
	- **埋め込みモデルはコンテキスト長の点で遅れている**
	- RAGの新アーキテクチャ
		- 「**Small-to-Big Retrieval**」
		-  レイテンシーとコストのトレードオフを実現するルーティング

## 2/26

先週、soraの発表で少し霞んだGemini 1.5 pro 、402ページの文書、44分間の映画、10万行のコードに対する推論など、その能力の一旦が垣間見れてきた。Googleは引き続きGemini 1.5 proベースのOSSであるGemma(“貴重な石”、ラテン語)をリリース、同パラメーターサイズであればLlama2やMistralより優れているとの事。Gemmaは軽量であるとともに、embeddingの工夫、安全なAIアプリケーションを作成するためのガイダンスと必須ツールの提供、Kera3.0サポートなど、かなりの量と質のソフトウエアスタックが一気に公開されたことになる。OSS戦略として、安全性に関するコミュニティとの共創という意味でも、MetaのOSS戦略と丸被り。早速、量子化gguf版や、KaggleでGemmaをつかったコンペの開催、embeddingの解析（日本語語彙は貧弱？）、npakaさんによるファインチューニング試行、MLXを使ったファインチューニングなど、コミュニティの活動が盛んに。LPU（Language Processing Unit）を引っ提げるGroq、推論時の高速さが半端ない、専用チップ開発でも戦いは続く、日本のMN-core早く！llamaindexもLlamaCloudとLlamaParseをリリース、テーブルや図表などの埋め込まれたオブジェクトを含む複雑な文書のための独自のパーシングや、RAGの構築がより高性能に、かつ容易になった。日本語LLMでは、 KARAKURI LM (70B)のELYZA-tasks-100による性能評価や、東工大と東北大によるKotomambaの構築等。フレームワークでは、BCGXからagentkitのOSSリリース、DXの手段としてのAIというシナリオでのコンサル系の新たなビジネスモデル。基礎研究では、プロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』や、Mambaとtransformerとのcolabを使った速度比較とか、そもそも状態空間モデルの解説とか。DeepMindとCMUによる、LLMをつかった数値回帰OmniPred論文も面白い、その性能の理論的解析が待たれる。Stable Diffusion 3のリリースやsentencepiece v0.2.0リリースなどの基盤ソフトの重要な更新も進んだ。

- BCGXから、agentkit
	- https://agentkit.infra.x.bcg.com/
	- BCG Xから大規模言語モデルを使ったAgentを楽に作るためのフレームワークAgentKitがOSSとして出ました〜。 Nextjs, FastAPI, Langchainのモダンなテックスタックです
-  Hyena Hierarchy: Towards Larger Convolutional Language Models
	- https://speakerdeck.com/hpprc/hyena-hierarchy-towards-larger-convolutional-language-models
	- Hyena Hierarchyについて、状態空間モデル（SSM）の基礎から解説したスライド
- GroqのLPUについて
	- https://x.com/umiyuki_ai/status/1759740311335739784?s=20
	- Groqとか言う会社のLPU（Language Processing Unit）って新しいチップはLLM推論速度が爆速なんだと。NVidiaとかのGPUと違って高品質なVRAMが要らんから低コストらしい。70BのLLMを動かす時に300tpsという超爆速で推論できる。
	- M3Maxだと6tps、RTX4090+PowerInferだと4tpsしか出ないから50～100倍の速度差。GPUがオワコンの時代来たか？
- The Shift from Models to Compound AI Systems
	- https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/
	- Berkeleyの人々による、「コンパウンドAI」のレビュー記事。
	- LLM単体で勝負するよりも、LLMを含む各種AI／非AIモジュールを組み合わせて作る「コンパウンドAI」の方がより良いシステムを作りやすい、
- Introducing LlamaCloud  and　LlamaParse
	- https://blog.llamaindex.ai/introducing-llamacloud-and-llamaparse-af8cedf9006b
	- Today is a big day for the LlamaIndex ecosystem: we are announcing LlamaCloud, a new generation of managed parsing, ingestion, and retrieval services, designed to bring **production-grade**  **context-augmentation** to your LLM and RAG applications.
- MolTailor: Tailoring Chemical Molecular Representation to Specific Tasks via Text Prompts
	- https://arxiv.org/abs/2401.11403
	- 機械学習応用には分子の物性予測から分類までさまざまなタスクがありますが、LLMによりそれぞれのタスクごとに最適な分子表現へと調整することで、予測性能が向上したそうです。
- 超高速な対話AIサービスのGroq
	- https://groq.com/
-  Learning to Learn Faster from Human Feedback with Language Model Predictive Control
	- https://huggingface.co/papers/2402.11450
	- Google presents Learning to Learn Faster from Human Feedback with Language Model Predictive Control
- SLANG: New Concept Comprehension of Large Language Models
	- https://arxiv.org/abs/2401.12585
	- GPT-4などに対してプロンプトのみから「新しい言葉の概念」を学習させるためのフレームワーク『FOCUS』をカリフォルニア大学などの研究者らが考案
	- ■メソッド 
		- 1. 使用例（コンテキスト）とフレーズを直接入力する 
		- 2. フレーズをコンテキスト内で隠して、意味を評価させる 
		- 3. コンテキスト内のエンティティ（固有名詞や出来事など）を変更し、異なるエンティティがフレーズの解釈に与える影響を調べる 
		- 4. 上記の結果、モデルが新しい言葉の理解に至ったのかを評価する 
	- ■実験と結果 
		- 1. GPT-4/3.5で検証 
		- 2. モデルが知らないインターネットミームを教え込ませた 
		- 3. GPT-4で88.2%、GPT-3.5でも84.5%の正確さを達成した
-  GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements
	- https://huggingface.co/papers/2402.10963
	- 結果ベースの報酬モデル (ORM) をリランカーとして使用して、グローバルとローカルの改良を組み合わせると、いずれか 1 つを個別に使用した場合や、3 つのサンプル ベースラインの中で最も優れたものを大幅に上回るパフォーマンスが得られることがわかりました。
- The Tokenizer Playground
	- https://huggingface.co/spaces/Xenova/the-tokenizer-playground
	- After watching, if you want to learn more about how different models (e.g., GPT4, Llama, T5, BERT) tokenize text, check out "The Tokenizer Playground": a web-app I built a few months ago with Transformer.js
- Gemini AdvancedでAIによって提案されたpythonコードを直接実行して動作確認できるインタフェースが追加された
	- https://x.com/webbigdata/status/1760129585994432916?s=20
	- Gemini 1.5 proで「githubから直接全コードと全issuesを取得させる事」と「最も緊急度の高いissuesを特定し、修正を実装させる事」が出来た
- Kotomamba: mamba-2.8B 学習知見
	- https://zenn.dev/kotoba_tech/articles/f15b2495d44c4f
	- Kotoba TechnologiesはNLPと分散並列学習に関する技術を用いて、日本及び非英語圏におけるLLMやマルチモーダルモデルの実運用に向けた研究開発を行っています。
	- from scratchから日本語と英語のコーパスにて学習を行ったkotomamba-2.8B-v1.0、
	- もう１つはstate-spaces/mamba-2.8b-slimpjから日本語と英語で継続事前学習を行ったkotomamba-2.8b-CL-v1.0です。
- sentencepiece v0.2.0
	- https://github.com/google/sentencepiece/releases/tag/v0.2.0
- Gemini 1.5 ProのYoutube３本セット
	- Reasoning across a 402-page transcript
	- https://www.youtube.com/watch?v=LHKL_210CcU
	- Multimodal prompting with a 44-minute movie
	- https://www.youtube.com/watch?v=wa0MT8OwHuk
	- Problem solving across 100,633 lines of code
	- https://www.youtube.com/watch?v=SSnsmqIj1MI
- KARAKURI LM を ELYZA-tasks-100 で評価してみた
	- https://qiita.com/wayama_ryousuke/items/f4f384b89e9b40a2d794
	- 実際にどの程度の性能があるのか、[ELYZA](https://elyza.ai/) が公開しているベンチマーク用データセット **ELYZA-tasks-100** で評価してみました。
	- 前回記事で最高スコアをマークした Xwin-LM-70B (4bit 量子化) を上回り、平均得点2.98点をマークして**1位**となりました。
	- 日本発の 70B モデルは [Japanese-StableLM](https://huggingface.co/collections/stabilityai/japanese-stable-lm-654063a381a8731a1c0f13cc) などごく一部に限られ、ELYZA-tasks-100 での平均スコアも海外モデルが優位に立っている状況でした。  KARAKURI LM の公開により、その状況が大きく変わったと言えそうです。
- Mambaを動かして速度をtransformerと比較するメモ
	- https://note.com/kan_hatakeyama/n/na911120f4ffb?sub_rt=share_pb
	- 話題のmambaをcolabで動かしてみました｡ 同等サイズのtransformerよりも､2倍くらいは推論が早そうです｡
- Googleのオープンモデル Gemma の概要  by npakaさん
	- https://note.com/npaka/n/na47e13dae482?sub_rt=share_h
	- 「[**Gemma**](https://ai.google.dev/gemma)」は、「**Gemini**」と同じ技術を基に構築された、軽量で最先端のオープンモデル
	- 「Gemma 2B」「Gemma 7B」の2つのサイズのモデルウェイトをリリースします。各サイズは、事前学習および指示チューニングされたバリアントでリリースします。
	- 「Responsible Generative AI Toolkit」は、「Gemma」を使用してより安全なAIアプリケーションを作成するためのガイダンスと必須ツールを提供します。
	- 「Keras 3.0」を介して、JAX、PyTorch、TensorFlow など、すべての主要なフレームワークにわたって推論と教師ありファインチューニング (SFT) のためのツールチェーンを提供しています
	- 事前学習、指示チューニングされた「Gemma」は、ノートパソコン、ワークステーション、Google Cloud 上で実行でき
	- 「Gemma」のリスクプロファイルを理解して軽減するために、手動のレッドチーム化、自動化された敵対的テスト、危険なアクティビティに対するモデルの機能の評価など、堅牢な評価を実施しました。 
	- ai.google.dev/gemma、では、「Gemma」の詳細やクイックスタートガイドを参照できます。
- Gemma Tokenizer が面白い
	- https://x.com/AiXsatoshi/status/1760437059066695976?s=20
	- Llama tokenizerと共通点
		- SentencePieceベース
		- バイトレベルエンコーディングで未知トークン対応
	- 違い
		- 語彙サイズ: Gemma 256K、Llama 32K 
		- Gemmaは`add_dummy_prefix` False → 先頭に空白追加なし（GPTと同じ）
		- Gemmaには特別なtoken多数（例: HTML要素、謎）
- google/gemma-7bのtokenizerはBPEでvocabは256k
	- https://huggingface.co/google/gemma-7b
	- ひらがなカタカナを含むvocabは7039件 
	- 京都 大阪 兵庫 奈良 滋賀 はあれど 和歌山 は登録なし 
	- 他では見ないタイプのトークンが多数 コードもmergeされたてホヤホヤ
- gemma-7b
	- https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf
	- https://huggingface.co/chat/settings/google/gemma-7b-it
	- Geminiモデルと同様のアーキテクチャ、データ、学習レシピを使用して、最大6兆個のテキストトークンで学習（主に英語）。サイズは2つで、パラメータ数がそれぞれ20億個と70億個。TPUv5eを使用して学習
	- 日本語モデルではないのに日本語でも答えてくれる
	- Hugging Face に 2B と 7Bの二種類（それぞれベース・インストラクション）があがっている
	- Context Length は 8k
	- 4bit で推論するコードも HF page にそのまま記載ある
	- ライセンスは Gemma license
	- llamaより緩いライセンスでリリース
	- 同パラメーターサイズであればLlama2やMistralより優れているとの事
- kaggle新コンペ Google Gemmaを使ってData Scienceのタスクがどの様に解けるかをデモするノートブックを作成するAnalyticsコンペ。
	- https://www.kaggle.com/competitions/data-assistants-with-gemma/
	- LLM大喜利。各タスク毎に賞金$10k。
- gemma-2bを試す by npakaさん
	- https://x.com/npaka123/status/1760432810811400204?s=20
	- https://huggingface.co/google/gemma-2b-it
- gemma-7b-it-gguf
	- https://huggingface.co/mmnga/gemma-7b-it-gguf
	- Googleさんが公開されているgemma-7b-itのggufあります
	- **現在量子化された出力が不安定な問題があるらしくQ8_0を推奨します。**
	- ご利用前にgemma利用規約をご確認下さい
- side-by-side comparison of the GPT-4, Gemma, and Llama tokenizer
	- https://x.com/xenovacom/status/1760384978360074460?s=20
	- the Gemma and Llama tokenizers are very similar, with the main difference being vocabulary size. One interesting thing to see is that even with an 8x larger vocabulary (256k vs 32k), Gemma only produces ~13% fewer tokens than Llama.
- Google Colab で Gemma のファインチューニングを試す
	- https://note.com/npaka/n/nc55e44e407ff?sub_rt=share_h
	- 今回は、ござるデータセットで学習します。AIが「我、りんえもんは思う。◯◯でござる。知らんけど。」的な口調になります
- OmniPred: Language Models as Universal Regressors
	- https://huggingface.co/papers/2402.14547
	- 広範な実験により、数学的なパラメーターと値のテキスト表現のみを通じて、言語モデルが非常に正確な数値回帰が可能であることが実証され、トレーニングの機会が与えられれば、複数のタスクにわたって、従来の回帰モデルを大幅に上回る可能性があります
- Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping
	- https://huggingface.co/papers/2402.14083
- Stable Diffusion 3リリース
	- https://stability.ai/news/stable-diffusion-3?utm_source=twitter&utm_medium=website&utm_campaign=blog
	- 学習データから15億件も弾いたらしい。すごいな
- Colbert Rerank
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/node_postprocessor/ColbertRerank.ipynb
	- ColBERT  is a great model for reranking. It’s ~100x faster than BERT-based/cross-encoder models, letting you rerank large amounts of documents without worrying about latency. And of course it does better than standard dense retrieval.
- The prompting guide for Gemma 7B Instruct is live!
	- https://www.promptingguide.ai/models/gemma
-  最新の Google Gemma モデルを MLX を使ってローカルでファインチューニング
	- https://note.com/alexweberk/n/n96cc4c8ac174?sub_rt=share_h
	- M3 Max 128GB で約 50 分かかりました。npaka さんの記事だと 20 分ほどで完了するそうなので、やはり NVIDIA A100 などの GPU と比べてしまうと時間がかかってしまいますね…。
	- https://gist.github.com/alexweberk/1434c95c05463866491677aac6ce19ba#file-mlx_finetuning_gemma-ipynb
-  Introducing Pebblo — Data Visibility & Governance for Gen-AI apps
	- https://medium.com/@sridhar_ramaswamy/introducing-pebblo-data-visibility-governance-for-gen-ai-apps-086ca8a62d10
	- Pebblo enables developers to safely load data and promote their Gen AI app to deployment without worrying about the organization’s compliance and security requirements. The project identifies semantic topics and entities in the loaded data and summarizes them on the UI or a PDF report.
- 

## 2/19

今週は、なんといっても、sora、sora、sora。これってOpenAIが意図してリリース時期を計算している気がする。GoogleのGemini 1.5のリリース直後だし、MetaのLecun先生が、当面できないという講演の数日後に出すとか、OpenAIは配球を選ぶだけの持ち球のストックがあるといううわさは本当なのかも。外部からのsoraの技術解析も進み、既存の技術の組み合わせではあるが、その性能・精度とスケールが違うととのことで、つまり、OpenAIが圧倒的な横綱相撲を見せつけただけだった。soraのおかげで霞んででしまったGemini 1.5、なんとMoEを採用し、長大トークンに対応、RAGっていらね？みたいな勢いだが、ブラックボックスをガラポンで利用してよいわけがない。RAGもCollective RAGとか、embeddingの工夫とか、説明性のある生成AIの方向に進んでる気がする。一方MetaはLeCun先生のいう世界モデルに近くためのV-JEPA（動画の予測）を発表。ここにきて、世界モデルやシミュレーションが一気に現実味が帯びてきた。なぜかLlamaindexとLangchainが同時期にそれぞれ大きなバージョンの代替わり、肥大化しすぎたのをモジュラー化したという話だが、LangChainには後方互換性があるって本当？LLMのサーベイ論文、今後の研究の進む方向を正しく見据えててよい。小さいLLMとかTransfomerに代わる次世代アーキテクチャ(Mambaとか）とか、本LLMアプデでも追ってた話題が満載、まあ誰が見てもそうなるわな。natureの、ChatGPTを利用してデータから論文を生成ってのは、自分がというわけではなく、そういう人や論文と世界で競争しなければいけないという意味で、研究者なら必読だろう。ローカルLLMでは、Ollamaの日本語出力が改良されたということで、npakaさんのElyza-7Bを動かした記事は、日本語でローカルLLMしたい勢には参考になるだろう。元木さんの分析のように、Transformerベースの潜在拡散モデルをつかったLLMでは、資金とリソースの戦いなので、横綱相撲を見せつけらて戦闘意欲をそがれる発表が多いが、だからこそ、LLMサーベイ論文がいうように、アーキテクチャのパラダイムを変える必要があるし、そういう人たちが出てくるに違いない。歩みを止めるわけにはいかない。

-  LlamaIndex v0.10
	- https://blog.llamaindex.ai/llamaindex-v0-10-838e735948f8
	- https://x.com/llama_index/status/1757121818115322076?s=20
	- our biggest open-source release to date, and a massive step towards production-readiness.
	- Create a core package, split off every integration/template into separate PyPi packages.
	- Refactor LlamaHub to become a central hub of all integrations (WIP)
	- Deprecate ServiceContext: Your dev UX is now way better without this object.
- Chat with RTX from NVIDIA
	- https://x.com/NVIDIAAIDev/status/1757447655674819053?s=20
- Deepreneur-blue-lizard
	- https://huggingface.co/Deepreneur/blue-lizard
	- 東京大学松尾研究室発のAIスタートアップ、株式会社Deepreneur(ディープレナー
	- MetaのLlama-2-7bに対して、Wikipediaや書籍等の日本語の学習データを用いて追加事前学習と独自データによるファインチューニングを実施したモデルです。  
	- 70億パラメータと非常に軽量なモデルであるにも関わらず、JGLUE（日本語タスクにおける評価ベンチマーク）を用いた評価では、ChatGPT-3.5を超えるスコアが算出されており、公開されている日本語モデルの中では最高性能になります。
	-  株式会社Deepreneur、ChatGPT-3.5を上回る日本語LLM「blue-lizard」を開発。各社独自の高精度オンプレ型のLLMの構築サービスを開始
- ChemLLM: A Chemical LLM
	- https://arxiv.org/abs/2402.06852
	- We don't see too much research around LLMs for science so it's exciting to find this one. 
	- It's a dedicated LLM trained for chemistry-related tasks. Claims to outperform GPT-3.5 on principal tasks such as name conversion, molecular caption, and reaction…
- Large Language Models: A Survey
	- https://arxiv.org/abs/2402.06196
	- 大規模言語モデル（LLM）これまでとこれからを包括的に整理したサーベイ論文が公開されています。
	- ■小さくて効率的なモデルを開発する 
		- 大きなモデルは高コストで非効率的である
		- そのためタスク特化の小型モデルへの関心が高まっている 
		- パラメータ効率の良いファインチューニングや、教師あり学習、蒸留法などの技術が活用される 
	- ■アーキテクチャのパラダイムを変える 
		- トランスフォーマーの"次"に関心が高まっている
		- アテンションモデルに変わる状態空間モデル（Mambaなど）が筆頭候補 
		- 新アーキテクチャは長いコンテキストを効率よく扱うなどの優位性が確認されている 
	- ■マルチモーダルモデルに進化させる
		- テキスト、画像、動画、音声など様々なデータタイプを統一的に扱うようになっていく
		- アプリケーションの幅が広がる
		- すでに優秀なモデルが出現し始めており、この流れは続いてくだろう 
	- ■実用性を向上させる 
		- LLMの短所（幻覚など）はプロンプトエンジニアリングや外部ツール、RAGなどで対処できることが分かり始めている
		- 従来の機械学習システムを代替していく流れが起きている
		- 個人の好みにパーソナライズするような設計が人気を集めている 
	- ■セキュリティ対策を強化する
		- 敵対的攻撃からモデルを守るのが重要になっている
		- 倫理的な懸念やバイアスに対処するための研究も活発化している 
		- 機密情報を責任を持って扱うように努力されている
- 実践！大規模言語モデル / 1000億パラメータ越えモデルを動かすには？
	- https://zenn.dev/turing_motors/articles/26e1f1be50c0b5
	- BLOOM-1Bを動かしてみる
		- 10億パラメータ数程度のモデルであれば、GPUメモリが12GB以上のGPUであれば推論することが可能です。Google Colaboratoryで提供されているGPUインスタンスで動かすことができます
	- BLOOM-176Bを動かしてみる？
		- では実際1000億パラメータを超えるBLOOMを動かすにはどうすればいいでしょうか？
		- 単純な解決策として、その大規模モデルが乗る計算環境を構築することができますが、もしそのレベルのスペックをオンプレミスのサーバーで整える場合は数千万円規模になってしまいます。また、AWSやGCPなどのクラウドコンピューティングサービスで大規模実験環境を整えることもできます。
		- 例えば、AWSのEC2 P4dインスタンスであれば8枚のA100のGPUメモリが計320GBと640GBの環境を1時間あたり30~40ドル程度で扱うことができます。
- RAG Fusionが思ってたより凄そう
	- https://zenn.dev/ozro/articles/abfdadd0bfdd7a
	- RAG Fusionは単なる「新たな手法」ではなく「革新的な手法」です。  
	- RAG Fusionは、従来の検索技術の制約を克服し、ユーザーのクエリに対してより豊かで文脈に即した結果を生成するために、RAG、Reciprocal Rank Fusion、生成されたクエリを組み合わせた新しいシステムになっています。  
	- このシステムは、検索結果のリランキングと複数のユーザークエリ生成により、検索の正確性とユーザーの意図との一致を向上させることを目指した手法となっていま
- Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning
	- https://huggingface.co/papers/2402.06619
	- 合計で114言語をカバーする5億1300万ペアのプロンプトと補完文を含んでおり、Apache 2.0ライセンスとの事
-  LlamaIndex v0.10 の概要 by npakaさん
	- https://note.com/npaka/n/nb8acc1f63312?sub_rt=share_h
	- 「**LlamaIndex v0.10**」は、過去最大のアップデート
	- 「ServiceContext」を非推奨にして、「LlamaIndex」の開発者エクスペリエンスを向上させます。
	- 時間が経つにつれて、このオブジェクトは使いにくくなりました。 service_context コンテナ全体を任意のモジュールに渡すと、どのコンポーネントが実際に使用されているかを推論するのが困難になりました。 すべてのモジュールがデフォルトで OpenAI を使用するため、ユーザーはローカルモデルを使用したい場合でも、不必要にOpenAIキーを指定するように求められていました。 インポートして入力するのも大変でした
-  LongMamba
	- https://github.com/jzhang38/LongMamba
	- We present LongMamba, an early exploration of Mamba's **longer context extrapolation ability**. Our #LongMamba manages to retrieve *nearly perfectly* on a window context of 16384
- AutoMathText: A 200GB dataset of mathematical texts open sourced
	- https://huggingface.co/papers/2402.07625
	- Multi-source : arXiv/programming code/web pages  
	- Filtered and processed to adapte Math reasoning  
	- Selected by Qwen 72B
-  科学者がChatGPTを利用してデータから論文を生成 by nature
	- https://www.natureasia.com/ja-jp/ndigest/v20/n10/%E7%A7%91%E5%AD%A6%E8%80%85%E3%81%8CChatGPT%E3%82%92%E5%88%A9%E7%94%A8%E3%81%97%E3%81%A6%E3%83%87%E3%83%BC%E3%82%BF%E3%81%8B%E3%82%89%E8%AB%96%E6%96%87%E3%82%92%E7%94%9F%E6%88%90/122873
	- Nature Japanから生成AIで論文を書いた際の実証結果と限界
	- テクニオン・イスラエル工科大学（ハイファ）の生物学者でデータサイエンティストであるRoy Kishonyらは独自の自律的なdata to paperシステムを構築し検証。
		- 1時間足らずで研究論文作成 
		- 文章は流暢で洞察に富む
		- 厳密なデータ分析にも基づく としたが、
		- 論文でよく使われる表現で誤魔化す 
		- P値ハッキング（P hacking）
		- 論文生成が簡単になり質の悪い論文が増加するリスク など懸念点を挙げた。
- Code-Llama-70B-FW is now available on Poe! H
	- https://x.com/poe_platform/status/1757080840012804511?s=20
-  音声入出力でLLM on Google Colab
	- https://colab.research.google.com/drive/1WCiUth855jXjzaNh8Ap5lFLEGX8aMtiU
	- マイク入力→音声認識(Faster Whisper)→LLM回答生成(ELYZA)→音声合成(Style-Bert-VITS2)→再生
	- Google Colabの無料枠で動く 音声認識(Whisper)→LLM(Swallow-13B)→音声合成(Style-Bert-VITS2) を作ってみました。音声合成は事前に学習モデルの作成が必要ですが、押しのキャラ音声と会話できると楽しいかも。(LLMを13Bにしたので回答生成に1分くらい掛かります)
- RAG From Scratch: Query Translation (Multi-Query)
	- https://x.com/LangChainAI/status/1757817056865718432?s=20
-  Masked Audio Generation using a Single Non-Autoregressive Transformer
	- https://arxiv.org/abs/2401.04577?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=thread
	- Researchers at Meta recently shared MAGNeT, a single non-autoregressive transformer model for text-to-music & text-to-sound generation capable of generating audio on-par with the quality of SOTA models — at 7x the speed.
	- https://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT/?utm_source=twitter&utm_medium=organic_social&utm_campaign=research&utm_content=video
- Nomic Embed v1.5
	- Nomic Embed v1.5 is out, the first open model with variable-sized Matryoshka embeddings and 8192 context!
	- https://huggingface.co/spaces/Xenova/adaptive-retrieval-web
-  LLM Agents
	- https://www.promptingguide.ai/research/llm-agents
-  Mixtures of Experts Unlock Parameter Scaling for Deep RL
	- https://huggingface.co/papers/2402.08609
	- Google Deepmind presents Mixtures of Experts Unlock Parameter Scaling for Deep RL
-  Google Colabでの日本語Mambaの事前学習
	- https://note.com/hatti8/n/na9782b7fa437?sub_rt=share_pb
	- 日本語モデルがないので、日本語Mambaの事前学習のコードを作成しました。Google colabで動くことは確認したもののA100(40B)でも**15時間近くかかるので実質最後までは実行できないです。**
-  GraphRAG: Unlocking LLM discovery on narrative private data by Microsoft
	- https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/
	- Microsoft is transforming retrieval-augmented generation with GraphRAG, using LLM-generated knowledge graphs to significantly improve Q&A when analyzing complex information and consistently outperforming baseline RAG
-  In-Context Language Learning: Architectures and Algorithms
	- https://arxiv.org/abs/2401.12973
	- Transformer の代替としての Mamba 含む SSMs や他の subquadratic なアーキテクチャ (e.g, RetNet, RKWV) を「入力に依存した推論を許すか」・「線形/非線形か」で整理するとめちゃくちゃ見通しが良くなる．
- OpenAIがMicrosoftと強力し国家関連の脅威アクターによるAIの悪意あるサイバー活動に関する利用をしていたアカウントを停止。
	- https://x.com/bioshok3/status/1757834888705945971?s=20
- Open AI 動画生成AI 『Sora』をリリース
	- https://openai.com/sora
	- Googleが切り札的に電撃公開したGemini 1.5の数時間後に、OpenAIが世界の話題を掻っ攫うレベルの動画生成AIのSoraをぶつけてきた
- META がVideo Joint Embedding Predictive Architecture (V-JEPA) モデルをCC BY-NC ライセンスの下で一般公開
	- https://x.com/bioshok3/status/1758182170135576590?s=20
	- V-JEPA は、抽象表現空間内のビデオの欠落部分またはマスクされた部分を予測することによって学習する非生成モデル
-  LangChain v0.1 クイックスタートガイド - Python版  by npakaさん
	- https://note.com/npaka/n/n1d771995c3aa?sub_rt=share_h
	- **v0.1** ではlangchainパッケージが次の3つのパッケージに分割されました。すべて**下位互換性のある方法**で行われました
- 軽量・高速・高性能と三拍子揃った日本語対応のAI(Orion-14B)で指示データセットを自動生成するメモ
	- https://note.com/kan_hatakeyama/n/n0c58733b39bd?sub_rt=share_pb
	- shi3zさんの、「Orion14B-ChatとWikipediaデータセットを使って日本語マルチターン会話データセットを作りました」を参考にして
	- Yahoo!知恵袋の質疑からデータを作ってみます
		- と、わりといい感じでした。
	- ローカルな大規模言語モデルでも、それなりに高品質なデータ合成ができる時代がやってきたようです。今後はいい感じに(公開)データセットを作っていきたいと思います。
- Corrective RAG with LangGraph
	- https://github.com/langchain-ai/langgraph/tree/main/examples/rag
	- We’ve just implemented 4 new notebooks outlining different RAG and CRAG techniques in LangChainAI　PY & JS! These show off different RAG flows, using OSS and hosted LLMs. See the links below for the notebooks:
-  【Gemini 1.5 Pro】100万トークン入力できる最強LLMの性能をGPT-4と比較してみた
	- https://weel.co.jp/media/gemini-1-5-pro
	- ● 性能テストで先代の大型モデル・Ultra 1.0と互角  
		- 性能比較全32項目のうち30項目で、GPT-4に勝利
		- 理数&人文全57科目の問題集「MMLU」にて専門家に勝利
	- ● Transformerの進化系、MoEアーキテクチャを搭載 
	- ● LLM史上最大、100万トークンもの入力に対応
		- MoEアーキテクチャを採用した結果、Gemini 1.5 Proでは入力できるトークン数が大幅にUP！一回に100万トークンの入力が実現しました。
- 教科書：確率過程
	- 確率過程に興味があるB4・M1が読むべき教科書について説明する．
	- [速習版](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/04/stochasticProcessShort.pdf)
	-  [詳細版](https://kanazawa.scphys.kyoto-u.ac.jp/wpkzdb/wp-content/uploads/2023/10/StochasticProcess2023_long.pdf)
- 【AI動画生成】Sora 要素技術解説
	- https://zenn.dev/mattyamonaca/articles/e234e57834d7ad
	- すごく簡単にまとめると以下の4つの要素が主軸です
		- 動画データを潜在空間に圧縮した後、Transformerがトークンとして利用できる「時空潜在パッチ」に変換する技術
		- Transoformerベースのビデオ拡散モデル
		- DALLE3を用いた高精度なビデオキャプショニングによるデータセット作成
	- こうして要素要素を見ていくと特段新しい技術を使っているわけではなく、今まで有効とされた技術を愚直に積み重ね、莫大な資本力と計算力でモデルを訓練すれば強いモデルが作れるという、当たり前の結果が見えてきます。
-  ChatGPTを社内に配ってもあまり使われない本当の理由
	- https://qiita.com/jw-automation/items/cf8ffc7a0edab512d917
	- 社内情報というコンテキストが必要な業務がほとんどである人達に、素のChatGPTを配っても、特に使える所がないというのはいわば当たり前の話です。
- Build Knowledge Graph From TextData using LangChain
	- https://medium.com/@mahimairaja/build-knowledge-graph-from-textdata-using-langchain-under-2min-ce0d0d0e44e8
	- Converting text to knowledge graphs can be helpful for both visualizing the data and allowing for structured querying later on 
	- This blog goes through how to use LLMs to extract knowledge triplets
-  minbpe
	- https://github.com/karpathy/minbpe
	- Minimal, clean, educational code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization."
-  Video generation models as world simulators by OpenAI
	- https://openai.com/research/video-generation-models-as-world-simulators
	- SoraはTransformerベースの潜在拡散モデルで、テキスト指示から1分間の高画質動画を生成できる。時間・空間の両方で一貫性を維持でき、現実の物理法則をある程度反映させることができる。モデルやデータに関する詳細は非公開だが、大規模化により性能が上がる模様。
	- 今後やるべき事はおそらく単純で、全力でOpenAIやGeminiの成長にしがみ付けば良いのでは。という気がしている。 by 元木
	- https://x.com/ai_syacho/status/1758845719988117759?s=20
	- 彼らは拡散トランスフォーマーモデルという、マシンと札束を入れれば入れるほど能力の上がるAIを持っていて、その資金体力も段違い。…
- iPhoneにGeminiきてた
	- https://x.com/npaka123/status/1758656487399014521?s=20
	- ?? Advance???
- Ollama で Elyza-7B を試す by npakaさん
	- https://note.com/npaka/n/ndadbae6c6be5?sub_rt=share_h
	- 「Ollama」の日本語表示が改善されたとのことなので、「Elyza-7B」で試してみました
	- Ollamaのサイトに載っていないモデルは、自分で「**Modelfile**」を作成して、追加する必要があります。
	- 「Llama2」のManifestを参考にさせてもらいます
	- 今回は、「**ELYZA-japanese-Llama-2-7b-instruct-q4_K_M.gguf**」をダウンロードします。
- Lecun先生、soar発表直前に、テキストからリアルなビデオを生成するのは当面先だと講演したことに対して言い訳を。。。
	- https://x.com/ylecun/status/1758740106955952191?s=20
	- いや世界モデルを持つのがむつかしいというのが真意である。。。
	- きっと過ちは繰り返す。
- soraの生成した画像についての分析が進む
	- https://x.com/anand_bhattad/status/1758632768597328202?s=20
	- こいつ射影幾何わかってないよね？
	- DALE3と同じ画像じゃん等
- 

## 2/13

今週は、ほぼ予定通り（１日おくれ？）BardがGemini（ジェマナイと読む）に改名された。一方、新たにGemini Advancedという名前でGemini Ultraが有償でスタート。何気ないファミマの写真から画像から認識した情報片をつなげて店舗を特定したりと、コナン君なみの推理をしているのが何気にすごい。OSSのLLMでは、アリババのQwen1.5がリリースされたのが最大の話題、75B-chatのデモなどでもGPT-4に迫る性能を示すと評判、Huggingfaceのデモ試すとたしかにレべチかも。基本性能が高いのか、0.5BをTransfomer.jsで使った例でもそれなりの性能がでるという話。早速、量子化とか、Ollamaの対応が発表されたりされてる。たぶん、日本語LLMもrinna当たりからQwen-1.5ベースの日本語LLMの発表が続くと思うぞ。Style-Bert-VITS2、なんて自然な日本語を話すんだ、コンテキストを考慮した話しっぷりにびっくり、どこかの職業が丸ごとなくなる性能だ。 Open AIは、ソフトウエアの間をつないでタスクをこなすエージェントの開発を宣言、これってAppleScriptとかPowerShellのスクリプトを自動生成するみたいな話だから、Microsoftとも連携してるんだろうけど、RPA（すでに死語？）にとどめを刺すだろうな。「小さなLLM」、英語でも"Smaller LLM"と呼ばれるらしい、小さなLLMでいいんだな、LLMのLargeはモデルの大小ではないとうこと、評価によるとFlan-T5がぶっちぎり？ MoE関係では、Mixtral-8x7Bの日本語向けのLoRaとか、MoEを単純化してExpertの切り替えを試してみる例とか面白い。基盤面では、探索なしでTransfomerだけでチェスマスタークラスのＡＩが作れるらしい。一方、Transformerの次世代基盤の一つとされるMamba、日本語での詳細な解説や、MoEでもあるBlackMambaとか、いろいろ出てきたな。理論面では、岡野さんの解説、The Consensus Game、RAGの改良を生成AIと識別AIの間のゲームとしてとらえるとは。NVIDIAも自らcanary-1bとか、Audio Flamingoとか音声や対話関係のモデルをリリース、自動運転では運転手との対話が必要なのはそのとおりなんだろう。RAG関係も、Self RAGとか、Guardrailsとか、GPT-4と組みあせた医療分野での評価とかいろいろ進んでいるが、評価フレームワークのragas 0.1がでたのは大きい。日本語LLMも、日本語のデータセットの整理や「LLM-jp 13B v1.1」のリリースとか着実に進んでいるのが心強い、はよNEDOの成果を！。知識グラフとのLLMの融合、Wikidata とかロードマップとか、Research Insightとか話題は続いている。

-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Next to RoBERTa, FLAN-T5 is also a great go-to model for training text classifiers
	- Flan-T5頑張るなあ
-  大規模言語モデルが科学的発見に与える影響：GPT-4を用いた予備的研究
	- https://ai-scholar.tech/articles/large-language-models/impact_of_LLM
	- GPT-4は科学的発見活動にも大きく寄与しつつあります。  
	- 創薬、生物学、計算化学、材料設計、偏微分方程式と幅広く、GPT-4の応用が紹介されています。また、それぞれの応用でのテクニックを紹介しています。  
	- 現時点でのGPT-4を用いるうえでの不足点を整理し、将来への展望をまとめています。
	- 知見
		- 全体的に言えば、GPT-4は創薬の全プロセスと個々のステップに関する知識を持っています。
		- GPT-4は逆合成の予測精度が20.
		- GPT-4が創薬におけるデータ処理のための正しいスクリプトを生成するのに役立つ
		- 定量計算： GPT-4は生物学的な言語理解と処理に優れていますが、定量的な計算には限界があります。信頼できる結論を得るためには、手動で検証するか、別の計算ツールで検証することをお勧めします
- Qwen2-14BのMTBenchが7.99でClaude-1超えてるのはマジやばい by うみゆき
	- https://x.com/umiyuki_ai/status/1754435534511050870?s=20
	- Qwen2としてウワサになってたモデルがQwen1.5としてリリースされた！Mistral-Mediumに匹敵する性能がオープンソースで！今回は最初からTransformerで使える上に、AWQモデル、GPTQモデル、GGUFも全部公式で最初からリリース！vLLMやOllamaもOK！
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- We have finalized our 𝐋𝐋𝐌𝐬 𝐨𝐧 𝐆𝐫𝐚𝐩𝐡𝐬 survey by adding more insightful discussions. If you are interested in LLMs on structure data, don't miss this paper (with a resource repo)!
- Home Credit - Credit Risk Model Stability
	- https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/
	- Kaggle新コンペ クレジットカード利用者の外部及び内部データによる長期の貸倒れ予測タスク。久方ぶりの正統派テーブルデータコンペ
- Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
	- Nvidia presents Audio Flamingo
	- https://huggingface.co/papers/2402.01831
-  A Survey of Constraint Formulations in Safe Reinforcement Learning
	- https://arxiv.org/abs/2402.02025
	- 強化学習における安全性制約の記述方法に関するサーベイ論文を arXiv にて公開しました 。主要な定式化の理論的な関係性を議論しているのが面白いと思います
-  BlackMamba: Mixture of Experts for State-Space Models
	- https://huggingface.co/papers/2402.01771
- 英国AI Safety Instituteより3rd Progress Repoert。
	- https://www.gov.uk/government/publications/uk-ai-safety-institute-third-progress-report/ai-safety-institute-third-progress-report
	- Google DeepMindのGeoffrey Irving氏、Oxford大の神経科学者Chris Summerfield氏参画。コアKPIの「メンバーの、先端AIモデルに関する累積経験年数」が11月の150年から168年に増加。
-  Stable Diffusion WebUI Forge
	- https://github.com/lllyasviel/stable-diffusion-webui-forge
	- Stable-Diffusion-WebUI-Forge is a new platform to 
		- (1) completely solve the speed and VRAM problem and 
		- (2) adding UNet Patcher System to webui so that many new features can be implemented in about 100 lines of codes
-  Unifying Large Language Models and Knowledge Graphs: A Roadmap
	- https://arxiv.org/abs/2306.08302v3
	- この Knowledge Graph とLLMの関係について纏めた論文すごい。 
	- Knowledge GraphとLLMが相互成長する仕組みが非常に分かりやすくフレームワーク化して纏められている。 論文というより現状の整理に近い
-  Wikidata from LangChain
	- https://python.langchain.com/docs/integrations/tools/wikidata
	- WikiData allows you to easily connect to a free and open knowledge base
-  Qwen1.5
	- https://qwenlm.github.io/blog/qwen1.5/
	- https://huggingface.co/collections/Qwen/qwen15-65c0a2f577b1ecb76d786524
	- Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.
- OllamaでもQwin1.5をサポート
	- https://ollama.com/library/qwen
-  Repeat After Me: Transformers are Better than State Space Models at Copying
	- https://arxiv.org/abs/2402.01032
	- Our recent work on the comparison between Transformers and State Space Models for sequence modeling now on arxiv! TLDR - we find a key disadvantage of SSMs compared to Transformers: they cannot copy from their input
-  Self RAG
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/self_rag/self_rag.ipynb
	- We’re excited to feature Self-RAG, a special RAG technique where an LLM can do self-reflection for dynamic retrieval, critique, and generation
- The Majority of AI Compute Spend is Not on Training but on Inference
	- https://x.com/rohanpaul_ai/status/1754843805507887477?s=20
	- As per report - "2023: The State of Generative AI in the Enterprise"
- Qwen1.5-0.5B-chat with Transformer.js
	- Qwen1.5 is out: a collection of powerful LLMs with sizes ranging from 0.5B to 72B parameters.
	- https://x.com/xenovacom/status/1754873501536645292?s=20
	- Even at 8-bit quantization, the smallest one (0.5B) is surprisingly good for its size! Here's a demo I made with Transformers.js (v2.15), running 100% locally in the browser w/ WASM!
	- https://github.com/xenova/transformers.js	
- Gradio demo of Qwen1.5-72B-Chat
	- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat
- ollamaでMixtralを動かしてLangChainのagentで neo4jする
	- Managed to get Mixtral on @ollama working as an function calling @LangChainAI agent that interacts with @neo4j  through a semantic layer. Needs some tidying up and I'll be able to share it.
	- https://x.com/tb_tomaz/status/1754861855929958488?s=20
- Style-Bert-VITS2が即座に日本語特化モデル JP-Extraを取り込んでくれて、日本語発音がエグいです
	- https://github.com/litagin02/Style-Bert-VITS2/releases/tag/2.0
	- 「Style-Bert-VITS2」は、自動で文脈が把握され、感情表現が調整される
	- https://huggingface.co/spaces/litagin/Style-Bert-VITS2-JVNV
	- いやこれはすごい
- NVIDIAがデータセンター向けGPU市場で98％のシェアを独占していることが判明、AI性能が明暗を分ける結果に - GIGAZINE
	- https://gigazine.net/news/20240205-nvidia-gpu-market/
- だめ。絶対。 by キムワイプ
	- https://x.com/kimwipes_crecia/status/1754757418595336404?s=20
-  OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models
	- https://huggingface.co/papers/2402.01739
	- To help the open-source community have a better understanding of Mixture-of-Experts (MoE) based large language models (LLMs), we train and release OpenMoE,
- Development and Testing of Retrieval Augmented Generation in Large Language Models - A Case Study Report
	- https://arxiv.org/abs/2402.01733
	- GPT-4にRAG（検索拡張生成）を適用することで、臨床医学の問題において、人間の医師よりも高い精度が達成できたと報告
	- 適切なRAGシステム設計により、GPT-4単体よりも10%以上精度が向上し、人間医師よりも5%以上高いスコアを出
	- 研究者らはこの結果は注目に値するとしつつ、より広範な分野で実験を重ねていくべきとしています。 
	- また、ハルシネーションが低いとはいえ、医学における自動化は慎重であるべきとも述べています。
- Open AI shifts its battleground to Software
	- https://x.com/bioshok3/status/1755376649816953209?s=20
	- Open AIは現在2種類のエージェントAIを構築中
	- 1つはわりと自由にデバイスを操作可能なエージェント 
		- 顧客は ChatGPT エージェントに、分析のためにドキュメントからスプレッドシートにデータを転送したり、経費報告書を自動的に記入して会計ソフトウェアに入力したりするよう依頼できます
	- もう一つはWEB上で様々な操作可能なエージェント （1つ目はセキュリティやプライバシー懸念する人もいるのでもう一つのタイプを開発しているとのこと）
- Fully local RAG using @Teknium1 OpenHermes, @ollama and @streamlit
	- GPT4 level performance at 0% of the cost
	- https://github.com/phidatahq/phidata/tree/main/cookbook/local_rag
- 海外高性能言語モデルの日本語化研究の一環としてMixtral-8x7Bの日本語出力を安定させるLora作成、公開   
	- https://huggingface.co/aixsatoshi/Mixtral-8x7B-ja-Lora-sft-ChatbotArenaJAcalm2
	- Mixtral-8x7Bは高性能な言語モデルですが、日本語出力に多言語が混入するcode-switchingがよく見られます。 元の性能を維持しながら、日本語生成を安定させる方法として、Loraの効果を検証しました
	- 日本語が流暢なcalm2の合成データセットを利用してます Baseモデルより低パラメーターの言語モデルで作成したデータセットでも、一定の性能確保して日本語化できました
-  Apple Vision ProはHoloLensの完成形。現時点での限界値 by shi3zさん
	- https://note.com/shi3zblog/n/nd36c04f9133a?sub_rt=share_h
	- 「ついにここまで来たか」
-  Step-wise Queries by llamaindes
	- https://docs.llamaindex.ai/en/stable/examples/agent/custom_agent.html#step-wise-queries
	- In our brand-new cookbook, learn how to build a custom agent that can execute complex queries over your data, and can also be interrupted in the middle of execution with user inputs!
- Ollama OpenAI compatibility is here!
	- https://ollama.com/blog/openai-compatibility
	- つまり、ollamaでopenaiのAPIつかってURLをollamaエンドポイントに変えるだけで動くということ
-  RAG Research Insights
	- https://www.promptingguide.ai/research/rag#rag-research-insights
	- So we have created a new section in the RAG overview to summarize and help you keep track of insights into the latest RAG techniques.
- Nvidia releases canary-1b
	- https://huggingface.co/spaces/nvidia/canary-1b
	- With 1 billion parameters, Canary-1B supports automatic speech-to-text recognition (ASR) in 4 languages (English, German, French, Spanish) and translation from English to German/French/Spanish and from…
- Bard は Gemini（ジェミニ）になります！
	- https://x.com/googlejapan/status/1755607418103587148?s=20
	- Gemini は Bard に搭載されている AI モデルですが、この高度なテクノロジーが反映されていることをわかりやすく伝えるために、名前を変えました
	- https://gemini.google.com/app
- The Consensus Game: Language Model Generation via Equilibrium Search by 岡野さん
	- https://openreview.net/forum?id=n9xeGcI4Yg
	- LLMで質問応答等のタスクをこなす場合、生成的に解く場合（p(y|x,v=真)) と識別的に解く場合（p(v=真|x, y)）で得意/不得意が異なり結果が異なる。ゲーム理論に基づいて二つが合意する解を求められる均衡順位付けを提案。多くのタスクで再学習なく、性能を大きく改善できる
- OpenAnimateAnyone
	- https://github.com/fenghan0430/Open-AnimateAnyone
	- アリババはAIの研究結果をオープンで出してくれてたけど、いざAnimateAnyoneみたいな有望な成果物ができたらスッとクローズにしてシュッと自社アプリに組み込む。つまり今までは自社サービスには使えんクオリティだから不用品リサイクルとしてオープンにしてただけ？
-  Grandmaster-Level Chess Without Search
	- https://arxiv.org/abs/2402.04494
	- チェスでどの手が良いかをTransformerで教師あり学習したモデルは探索を使わなくても人より強くなる（探索ありAIよりは弱い）。教師ありデータはStockfish 16で作成しており、科学分野でよく使われるサロゲートモデルの一種とみなせる。
- ragas 0.1 release
	- https://github.com/explodinggradients/ragas
	- We are releasing version 0.1 of Ragas today, the open-source standard for evaluating RAG applications.
-  Perplexityをもとに､複数の大規模言語モデルを切り替えて推論するシステムの簡単なコード実装
	- https://note.com/kan_hatakeyama/n/nb5625d6411a8?sub_rt=share_pb
	- モデルを統合するための簡単な実装コードを書いてみます。  最近は､普通にmergekitもあるようですが､勉強も兼ねた実装です
	- 与えられた入力文章に対するPerplexity（困惑さ）を指標に、使用するモデルを切り替えるシステムを作ります
	- 今回は試しに、英語が得意なLLama2-7bと、日本語でファインチューニングしたElyza-7bを統合（merge）したシステムを作ってみようと思います。
- 日本語データセットのクリーニングスクリプト
	- https://github.com/lighttransport/japanese-llama-experiment
-  Real-World Robot Applications of Foundation Models: A Review
	- https://arxiv.org/abs/2402.05741
	- 基盤モデルの実ロボット応用に関するサーベイ論文を公開しました！Meta AI ResearchのChrisさん@chris_j_paxton , Google DeepmindのAndyさん @andyzeng_ という，この分野で最先端を進むお二人からのフィードバックを受けながら執筆
-  OpenAIアルトマン氏、半導体の資金調達で交渉　米報道
	- https://www.nikkei.com/article/DGXZQOGN095R00Z00C24A2000000/
	- 必要資金750兆円
-  Multilingual E5 Text Embeddings: A Technical Report
	- https://huggingface.co/papers/2402.05672
	- MicrosoftのE5エンベディングの実装ペーパー、今頃でるものなのか・
- Editable Scene Simulation for Autonomous Driving via Collaborative LLM-Agents
	- https://github.com/yifanlu0227/ChatSim
	- 生成AIの出現でシミュレータの世界も大きく変化。 昨日出たChatSimでは自然言語を入力してドライビングシミュレータを自由に編集することができる
-  LangChain 101: Part 3a. Talking to Documents: Load, Split, and simple RAG with LCEL
	- https://pub.towardsai.net/langchain-101-part-3a-talking-to-documents-load-split-and-simple-rag-with-lcel-26b005ccb30a
	- Loading documents and splitting them are a key part of RAG
- mambaの理論を理解する①：HiPPOフレームワークとLSSL
	- https://zenn.dev/izmyon/articles/8374a11d272602
	- mambaの理論を理解するための解説記事を書き始めました。かなり数式の導出など丁寧に書いてるのでよろしくお願いいたします。何か訂正や補足があれば優しく教えてくださ
-  Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization?
	- https://arxiv.org/abs/2402.00841
	- Can "small" finetuned LLMs with less than 2B parameters outperform larger openly available LLMs (Mixtral, Llama 2 Chat) and proprietary LLMs (ChatGPT)? Here's a closer look at the Tiny Titans paper
	- Flan-T5が最強らしい、
-  GPTは他者の心の状態を推測できる？AI×心理学のすゝめ
	- https://ai-scholar.tech/articles/computation-and-language/Theory-of-Mind
	- GPTは他者の心を読めるのか？ 実験において、GPT-3.5とGPT-4は高い正答率をマークしました。 
	- 著者は、GPTが心の状態を推測できる理由として「言語能力の向上によって自発的に出現したのでは」と指摘。 AI研究における心理学的な視点の重要性を解
- In-Context Principle Learning from Mistakes
	- https://arxiv.org/abs/2402.05403
	- LLMに敢えて間違わせてルールを覚えさせ同じミスを避けるようにする新しいプロンプト手法が提案されています。
	- ■新アプローチ 
		- 1. モデルが間違いを犯すように促す 
		- 2. モデル自身に、間違いに対する説明を生成させ、まずは低レベルの原則を形成。 
		- 3. 低レベルの原則をまとめ、約5つのキーポイントに圧縮して高レベルの原則を生成 
		- 4. 高レベルの原則を未見の例に対する応答を生成する際に利用 
	- ■実験と結果 実験と結果の要約: 
		- GPT-3.5-TurboとGPT-4の質問応答性能が一貫して改善され、GPT-4が7.5%の改善を見せた
		- 数学推論タスクでもGPT-3.5-turboとGPT-4で基準を上回る結果を示した
		- Big-Bench Hardタスクでもスコアが一定程度上昇した
- Step-by-step guide to build AI agents for structured and unstructured data.
	- https://x.com/Saboo_Shubham_/status/1756123156400546251?s=20
	- Step 1: Define the Chunking Strategy
	- Step 2: Apply an Embedding Strategy
	- Step 3: Implement a Document Retriever for Text
	- Step 4: Use a Large Language Model (LLM)
	- Step 5: Extract Metadata
	- Step 6: Implement a Document Retriever for Metadata
	- Step 7: Integrate SQL Querying with a Data Warehouse
	- Step 8: Develop a Prompt Refinement Engine
	- Step 9: Create a Response Post-processor
	- Step 10: Deliver the Response
- Buffer Overflow in Mixture of Experts
	- https://arxiv.org/abs/2402.05526
	- "Mixture of Experts (MoE) has become a key ingredient for scaling large foundation models while keeping inference costs steady. We show that expert routing strategies that have cross-batch dependencies are vulnerable to attacks. Malicious
- WolframEngine+JupyterNotebookで疑似Mathematica
	- https://x.com/blkcatman/status/1756219896026067052?s=20
- 【Mamba】Transformerを凌駕しうるアーキテクチャを徹底解説（ソースコードあり）
	- https://qiita.com/peony_snow/items/649ecb307cd3b5c10aa7
	- １．MambaはAttentionやMLPBlockを持たない簡素化されたアーキテクチャを有します。選択的状態空間モデル（Selective SSM：Selective State Space Model）という新しい構造を用いることで、必要な情報のみに注目し、計算効率の大幅な向上を達成しています。
	- ２．高速な推論（Transformerの約5倍）を可能にするとともに、シーケンス長（トークン数などのこと）の増大に対して、推論コストが線形に増大するという特徴を有します（これまでのモデルでは非線形的な増大がありました）。この性能向上は実データにおける検証で、シーケンス長が1000k（１００万）においてまで確認されました。
	- ３．GPUメモリ階層間の移動を最小限化するとともに、ハードウェアに最適化された並列アルゴリズムにより高速な計算が可能になり、要求されるメモリ容量も軽減されます
	- ４．パラメータ数2.8B以上の場合においてMambaは機能するのか、ハイパーパラメータのチューニング方法はTransformerなどと同じなのか、学習の不安定性はどうなのかといった点に関してはまだ不明であり、今後の研究が待たれます。
	- ５．まだ不明な点も多いですが、様々な角度からの研究によって、Transformerを代替しうる有望なアーキテクチャであるというエビデンスも取得されつつあり、今後Mambaを知らなければ最先端の研究から取り残される可能性があります。
-  栗田工業、機械学習使った材料探索で低環境負荷の防食剤開発へ
	- https://xtech.nikkei.com/atcl/nxt/news/24/00208/?n_cid=nbpnxt_twbn
	- 栗田工業さんらは冷却水の防食剤の開発のため、機械学習により数百万の分子から有望材料を抽出
- NeMo Guardrails, the Ultimate Open-Source LLM Security Toolkit
	- https://towardsdatascience.com/nemo-guardrails-the-ultimate-open-source-llm-security-toolkit-0a34648713ef
	- Advanced RAG with Guardrails
	- If you want to build user-facing RAG, you not only need to setup advanced retrieval, but also need to apply requisite layers of input/output filters for the following:
- pandas-ai
	- https://github.com/gventuri/pandas-ai
	- 機能としてはpandasのデータフレームに対して直接自然言語で処理できるようにしたもので、軽く見た感じアルゴリズム的に新しいものはなさそうなもののhttp://df.chat(プロンプト)という形式での操作は斬新
- LLM-jp 13B v1.1リリース
	- https://llm-jp.nii.ac.jp/blog/2024/02/09/v1.1-tuning.html
	- 各種チューニングですごい流暢になってる。学習詳細も公開されてて参考になる。
- The biggest Collection of Colab Based LLMs Fine tuning Notebooks
	- https://github.com/ashishpatel26/LLM-Finetuning
-  Google Colab で LLM-jp 13B v1.1 を試す by nakaさん
	- https://note.com/npaka/n/n2c272727d95a?sub_rt=share_h
	- 「LLM-jp 13B v1.1」は、「LLM-jp 13B」の最新版です。日英両データセットによるSFT、ichikaraデータセットの追加+DPOで対話応答性能が向上しています。
- OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models
	- https://arxiv.org/abs/2402.06044
	- A wild Theory of Mind Benchmark has appeared:
- 



## 2/5

今週も盛りだくさん。まずは、MetaのCodeLlamaの70B版リリース。早速SQLの変換SQLCoder-70Bがリリースされたり、4bit化されてMLX経由でMacで動かしたりと一気ににぎやかに。Metaは、35万個の H100を整備し、OSSの基盤モデルに取り組むということで、株価は20%アップ。一方Googleは、BardのbackendのGemini Proの国際対応をリリース。日本語なんかまだ変（例、バイクを自転車と認知）ですが、画像認識機能などGemini Proを手元で試せる。OSS版のマルチモーダルLLM代表的なLLaVA-1.6がリリースされ、Gemini Pro越えとの評価も。LLMの軽量化の新星SliceGPT、軽くて精度が落ちないのは大歓迎。miqu-70BというMixtral 8x7Bの量子化版らしきものが、EQ-benchで突然上位に登場、次の大きなリリースの斥候か、なおmiqueってミクだったのか？。Phixtralの論文で紹介されたMoEの実装、本家とはアルゴリズムが違うみたいだがMoEの実装にもいろいろあるものだ。ICRA2024での採択論文・技術の話題もちらほら。国産LLMでは、700億パラメーターLLM「KARAKURI LM」が登場、Llama 2を日本語データセットで事前学習、ファインチューニングしたらしいがやたら性能が高いと話題に。gguf版や、MLXをつかってM2 Macでの動作確認等が行われ、これは基礎能力が高そう。小さき言語モデルも、Allen.AIのOLMoや、Kaggle関連のH2O-Danube-1.8Bなどが登場。RAG関係だと、またファインチューニングとの比較論文、どうもまだＲＡＧのほうが利がある。クエリ変換ってのも重要な技術。しかし、赤ちゃんの頭にビデオを装着して得られた61 時間分の画像から、マルチモーダル言語モデルをつくるという途方もない研究にはびっくりした。Hugging FaceがGPT Storeのオープンソース版（Assistant）を開始、Googleとの提携でリソースが強化された？。東京藝大の卒業展示に“AIアニメ”が出たことが話題になったが、Making情報を見ると、じつは相当ＬＬＭを使いこなしていて、シナリオのChatGPTでの作成ログ等、アプローチが参考になるという話に。Googleのあらゆる時系列データをDecoder-onlyのモデルにぶっ込んで時系列予測の基盤モデル作る話、長期時系列予測でどうしてそんなに性能が高いのか、気象予測にも適用するのか？。NEDOの国内生成AIの基盤モデル開発支援、さすがと思われる会社や研究機関が並ぶ。参加機関の１つNIIでは、国会図書館のもつ国内のウェブサイトのアーカイブ事業の成果が活用されるということだ。一方民間ではRicor-13BのようなカスタマイズしたLLM提供ビジネスもはじまった。材料系の研究へのLLMの応用も着実に進む。ローカルLLM実行環境ももollamaがvision対応とか、function call対応とか着実に進んでる。さて来週も、Gemini Ultra が2/7にリリースとのうわさもあり、人型ロボットスタートアップFigureに出資したMicrosoft/OpenAIの次の手や、Vison Proを出したAppleのＡＩ戦略も気になるところ。

- google/siglip-base-patch16-256-multilingual を使って、ローカルの画像を日本語で検索してみる
	- https://note.com/eurekachan/n/n9d4f62b80ad6?sub_rt=share_pb
	- 1月に、Googleから、SigLIPという、画像とテキストの両方をベクトルとして扱うことができるモデルのmultilingual版（多言語対応版）が公開されました。transformers 4.37以降で対応しています。日本語も対応しています。
	- CUDAを使いましたが、GPUへの負荷も低かったので、案外CPUでも動かせるかもしれません。
-  Are Transformers Effective for Time Series Forecasting?
	- decisively highlighting the shortcomings and deficiencies in research surrounding the use of transformers for
	- This paper effectively exposes the deceptive practices employed by various authors in their papers, such as inadequate benchmarking and other tactics, which have previously led to inflated claims regarding the performance of transformers in this domain.
- Googleなど米IT、1月1万人削減　組織スリム化でAI集中
	- https://www.nikkei.com/article/DGXZQOGN1757C0X10C24A1000000/
- DSPy lets you prototype LLM Programs like AlphaCodium
	- https://x.com/CShorten30/status/1751656468879708496?s=20
- LangGraph Financial Agent w/ Polygon
	- https://gist.github.com/virattt/4d764c427892ce9fdf4534209edfb1f4
	- LangGraphでエージェントを作って株価をとってくる簡単な例
- Ollamaで、 Mistral-7B finetuned for function calling　をサポート
	- https://ollama.ai/calebfahlgren/natural-functions
-  知識0でローカルLLMモデルを試してみる！垂れ流し配信【ゴリラジ】
	- https://www.youtube.com/watch?v=C1yFEMDLddc
- MetaがコーディングLLMのCodeLlamaの70B版をオープンソースでリリース。
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/?utm_source=twitter&utm_medium=organic_social&utm_campaign=codellama&utm_content=reply
	- HumanEvalでGPT-4超えしたらしい。入力コンテキスト長も100kまで行けるらしい
	- Metaは以前から「GPT-4並のLLMをオープンにする」と予告していましたが，年明け早々，まずはコード生成領域でやってきました
	- https://labs.perplexity.ai/ でためせるらしい
-  Inverse Molecular Design with Multi-Conditional Diffusion Guidance
	- https://arxiv.org/abs/2401.13858
	- 複数の制約下での分子生成の論文
	- 従来は合成可能性とガス透過性など２つ以上の制約を満たすような分子を１つのモデルから生成できませんでしたが 
	- 制約をエンコードしたTransformerモデルにより低分子・高分子共にうまく生成できたそうです。
- アリババがマルチモーダルLLM使って作ったスマホを操作するエージェント、Mobile-Agentを発表
	- https://x.com/umiyuki_ai/status/1752183108873687439?s=20
- SliceGPT: Compress Large Language Models by Deleting Rows and Columns
	- https://arxiv.org/abs/2401.15024
	- Microsoftとチューリッヒ工科大の研究者により、LLMをスライス（行や列を削除）して軽くする効果的な手法
	- 実験では最大30%のパラメータを削減しつつ性能の90%以上を保つことができたと
	- ■提案手法 
		- 1. 主成分分析を用いて重要な情報を抽出 
		- 2. 重要でない情報を取り除くために行や列を削減 →より少ない計算リソースで動作できるようにする
	- ■実験と結果 
		- 1. OPT, LLAMA-2, Phi-2を実験対象モデルに設定 
		- 2. HuggingFace TransformersとPyTorchで実装 
		- 3. いくつかのスライスレベルを分けて実験 
		- 4. 最大30%のモデルパラメータ削減が実現した 
		- 5. Llama 2とPhi-2モデルは90%以上の性能を維持
- Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs
	- https://arxiv.org/abs/2312.05934
	- Microsoftより「Fine TuningとRAGのどちらが高精度か？」に答えた論文
	- 既存/新規知識の両方においてRAGが良好な結果に。Fine Tuningは継続事前学習、評価はMMLUをLM-Evaluation-Harnessで実施。
- The Power of Noise: Redefining Retrieval for RAG System
	- https://arxiv.org/abs/2401.14887
	- LLMにおけるRAG（外部データを取り込ませる）システムを構築する際には、データベースに「無関係な」文書を混ぜたほうが検索精度が上がる可能性が示唆されています。
	- ■なぜそんなことが起こるのか 
		- 1. 関連性が高い文書ばかりだと過剰適合が起こる 
		- 2. 無関係情報をフィルタリングする能力が上が
- 一昨日くらいからmistralの有料版であるmistral-medium(70B、MoEではない)の重みがリークしたという噂がある
	- https://x.com/webbigdata/status/1752304557336801408?s=20
-  Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery
	- https://arxiv.org/abs/2309.14425
	- 松尾研のRAで学部2年生の白坂翠萌さんが主著した，基盤モデルを活用して，オンラインにプロンプトを生成しながら失敗にも柔軟に対応する家庭内サービスロボットシステムに関する研究がICRA2024に採択されました
- 突如として現れたmiqu-70BがEQ-Bench では 83.5 を獲得し (ローカルで評価)、GPT-4系に次ぐ性能であることが判明
	- https://x.com/N8Programs/status/1752441060133892503?s=20
	- どうも、Mixtral 8x7Bの量子化版のリークだったらしい
-  LangGraphで始めるマルチエージェントシステム
	- https://speakerdeck.com/peisuke/langgraphdeshi-merumarutiezientosisutemu
	- Function Callingだけで割とよく動いてるとこあるんだけど、もう少し統合したくてSupervisorが必要そうなフローから試してみようかな
- Mixtral8x7Bの日本語対応Loraの学習完了しました
	- https://x.com/AiXsatoshi/status/1752509354849546417?s=20
	- 標準のMixtral8x7Bでは、応答に多言語間を行き来するswitchingが発生しますが、改善しています
	- 汎用性能が落ちている可能性あるので、もう少し検証します
- 学習済みの LLM を束ねて Mixture of Experts を作るテク
	- https://zenn.dev/zaburo_ch/articles/88e35e5c80f974
	- Phixtralの話の紹介
	- 「Phi-2 ベースのモデルをいくつか使って Mixture of Experts (MoE) を作ったら単体よりも良い性能が達成できました」
	- **Few-shot で Gating のパラメータを決める手法**が使われていて面白かった
	- Gating の話を忘れれば「ベースのモデルを決めて MLP 以外のパラメータは全部ベースモデルのものを、MLP は MoE Layer に置き換えて各モデルの MLP のパラメータを使う」という方法で MoE モデルが作れそうです
	- 各 Expert について、その Expert を使うと有利になりそうな Prompt (例えば Code で Fine-Tuning された Expert なら Code の Prompt) をいくつか用意して、その Prompt を forward したときの hidden_state を使って we​ を作ろう
	- Domain ごとに Expert を使い分けてくれることを期待する感じですね
- CodeLlama-70BをPostgreSQLの生成に特化させたバージョン、SQLCoder-70B
	- https://huggingface.co/defog/sqlcoder-70b-alpha
	- 性能評価もGPT-4に10ポイント以上差をつける圧倒的な勝利で、特化型のコード生成LLMの台頭を予感させるようなポテンシャルを秘めている
- LLaVA-1.6のリリース、Gemini Pro越え？
	- https://x.com/imhaotian/status/1752621754273472927?s=20
	- https://llava-vl.github.io/blog/2024-01-30-llava-1-6/
	- improved reasoning, OCR, and world knowledge. It supports higher-res inputs, more tasks, and exceeds Gemini Pro on several benchmarks!
	- LLaVA-1.6、普通に画像中の吹き出しを日本語で喋っているとか認識できて、Gemini Pro超えは伊達ではないなとなる
- 700億パラメーターLLM「KARAKURI LM」を一般公開
	- https://karakuri.ai/seminar/news/karakuri-lm/
	- GPT-4を評価者とするベンチマーク(MT-Bench-jp)で、国産LLMとしては1位の性能を達成しました
	- https://lm.karakuri.cc/ でお試し
- 論文「RAG VS Fine-tuning」を読む
	- https://zenn.dev/neoai/articles/e75b6f033a4fd9
- 普通の人が資産運用で99点を取る方法
	- https://hayatoito.github.io/2020/investing/
		- 1.  確定拠出年金 (iDeCo または 企業型 DC）を始めます。
		- 2.  新 NISA でつみたての設定をします。
		- 3.  さらに余裕がある方は、特定口座でつみたての設定をします。
		- 4.  資産運用を始めた直後や、まとまった資金を一時的に入手したときなど、十分な余剰資金（現金）をもっているのであれば、自分のリスク許容度の範囲内で、適切な割合の資産を  _一括_  で投資します。詳しくは後述の「アセットアロケーション」を参照してください。
		- 5.  定期的に（年に 1 回、あるいは数年に 1 回）、アセットアロケーションについて見直しましょう。
-  Self-supervised Learning: Generative or Contrastive
	- https://arxiv.org/abs/2006.08218
- Proactive Detection of Voice Cloning with Localized Watermarking
	- https://huggingface.co/papers/2401.17264
	- Meta presents Proactive Detection of Voice Cloning with Localized Watermarking
- オークションサイトなどから中古のRTX 3090を8台かき集めてマシンを構築した人のお話
	- https://www.kyleboddy.com/2024/01/28/building-deep-learning-machines-unorthodox-gpus/
- Google's AI Makes Stunning Progress with Logical Reasoning
	- https://www.youtube.com/watch?v=NrNjvIrCqII
- Microsoft and OpenAI are in talks to invest $100 million into Figure
	- https://x.com/AndrewCurran_/status/1752463084550262805?s=20
	- Figureは、人型ロボットを開発するスタートアップ
-  ReGAL: Refactoring Programs to Discover Generalizable Abstractions
	- https://huggingface.co/papers/2401.16467
- miqudev/miqu-1-70b
	- https://huggingface.co/miqudev/miqu-1-70b
	- えっ！、miquってミクのことだったのか。
- H2O-Danube-1.8B Technical Report
	- https://arxiv.org/abs/2401.16818
	- Open-sources a high-competitive 1.8B LM trained on 1T tokens following the core principles of LLama 2 and Mistral
	- long context small LLM trained by a team of some of the best Kagglers in the world
	- どうも小規模LLMでKagglerによりtrainigされたもｎ
-  Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
	- https://arxiv.org/abs/2401.17263
	- Significantly improves robustness to held-out jailbreaks, reducing the attack success rate from 84% to 8.66% across 20 jailbreaks
- quantized CodeLlama 70b base model to 4-bit with MLX
	- https://huggingface.co/mlx-community/CodeLlama-70b-hf-4bit-MLX
	- you can now run this model on your Apple Silicon.
- StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis
	- https://arxiv.org/abs/2401.17093
- Memphis-CoT 3B
	- https://huggingface.co/euclaise/Memphis-CoT-3B
	- A small reasoning-focused model using a novel iterative contrastive finetuning procedure, trained on only human data, outperforming much larger human data models and similarly sized SFT models.
-  RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank
	- ICLR24 Spotlight: To train general-purpose SSL models, it's important to measure the quality of representations during training. But how can we do this w/o downstream labels? 
	- We propose a new label-free metric to eval SSL models, called Linear Discrimination Analysis Rank(LiDAR)
-  [The False Promise of Imitating Proprietary LLMs](https://arxiv.org/abs/2305.15717v1)
	- 言語モデルの「模倣」は有用か？
	- https://ai-scholar.tech/articles/chatgpt/Imitating-Proprietary-LLMs
	- 最新研究によれば、新しく開発された言語モデルの模倣は非常に難しいことが示唆されています。微調整による改善が有効でなく、モデルの基本的な知識はあまり変わらないことが発見されました。  
	- 中小企業や大企業が同じ利点を得ることが難しくなり、特に新しいデータやアルゴリズムを活かして能力差を生かす企業が競争上の優位性を築ける可能性があります。
	- 新しい手法やデータの導入が重要であり、技術的な制約にも留意することが持続的な発展に寄与するでしょう。
- Accelerating the Science of Language Models
	- https://allenai.org/olmo/olmo-paper.pdf
	- AllenAIによるOpen Language Model (OLMo), a 7B parameter model.
	- There is also a smaller version of it, OLMo 1B.
- ブラウザでRubyを動かす夢
	- https://mametter.hatenablog.com/entry/2024/02/01/105413
	- 元同僚の遠藤さん、頑張ってるな、みんな使ってあげて！
- SEMSCORE: Automated Evaluation of Instruction-Tuned LLMs based on Semantic Textual Similarity
	- https://arxiv.org/pdf/2401.17072.pdf
	- これでJapanese MT-benchやElyza-tasksが毎回GPT-4を使わずに評価できるようになれば割と安価で日本語LLM leaderboardが作れそう
- llamaindexを使った、使用したクエリ変換の解説記事
	- https://akash-mathur.medium.com/advanced-rag-query-augmentation-for-next-level-search-using-llamaindex-d362fed7ecc3
	-  Advanced RAG: Query Augmentation for Next-Level Search using LlamaIndex
	- クエリ変換は「LLM への入力（クエリ）をより良い情報抽出を可能とする表現へ変換する」ことで，RAG の質を高める手法
	- 記事内では，代表的な 5 つの手法を code つきで解説
- Build Long-context RAG from scratch: Nomic Embeddings + Mistral
	- https://x.com/LangChainAI/status/1753149741599428926?s=20
	- nomic_ai has launched a new open source, long context embedding model:
		- 8k token context window (using RoPE)
		- Strong performance on several benchmarks 
		- API (and local support coming soon)
	- そしてlong contexのRAGをつくるには、
		- nomic_ai:new 8k context window embeddings
		- trychroma:vectorstore　MistralAI-instruct 32k context window via  ollama
- Apple presents Can Large Language Models Understand Context
	- https://huggingface.co/papers/2402.0085
	- We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.
-  Grounded language acquisition through the eyes and ears of a single child
	- 
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTExMTMzMTc5OTYsMTY2MDQwNjg2NSw0MT
Q4ODAxMTMsLTc4NzgwOTU3OSwtMTY3NzI5MDMwMSwtMTE4MDE4
MjkzNSwxMDM0MzIwMjUzLC0xMDY1NzY2MDE5LC0zMjYxNDYzMT
csLTE2ODU4NDQ2ODcsLTE2MDQ4NTg1NDQsNjc4NTA3MTI5LC00
NDEwMzg4MjIsNjk1Mzc1MTM2LDU4NzI2MDQ4MywtMTgwNTQ4Nz
UyNSwxMzI4MTUzMzI3LC0xMTI4MDA0MjExLC0xNDg3NzUwOTc0
LDE5NDk0MzYxNDNdfQ==
-->