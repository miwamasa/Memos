# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。

## 12/11

今週はなんといっても、GoogleのGemini。GPT-4越えとか、すぐにBard(英語版）で試せるとか、研究アシスタントして使うデモとか、それから子供向けのお遊びデモとかなかなか衝撃的であったが、なんとお遊びデモが紙芝居（部分をつなげてそれらしく見えるようにした、部分部分は本物）との報道があり、間に合わなかったんだろうなー。Mambaというトランスフォーマの代替技術よさそう。 DeepMindの『GNoME』は科学の発展をLLMが明らかに加速することを示している。

１週間分のブクマ整理するだけで２時間かかるんだけど。。。GPT4にやらせるか。。

- 今月のNature誌は面白かった
	- https://x.com/ykfrs1217/status/1731287315459490165?s=20
	- ① 大都市ほど、異なる社会ステータスのひとたちは混じわらない（[https://doi.org/10.1038/s41586-023-06757-3…](https://t.co/tEkbdQOPG3)） 
	- ② 同じ町（≃学内）の研究者だけで行われた研究の方が、異なる地域間の共同研究よりも革新的な成果がでやすい（[https://doi.org/10.1038/s41586-023-06767-1…](https://t.co/jrBRV4Gxtk)）
-  Phantom oscillations in principal component analysis
	- https://www.pnas.org/doi/10.1073/pnas.2311420120?utm_source=TOC&utm_medium=ealert&TOC_v120_i48=&ref=d4140497
	- 時間的・空間的にスムーズなデータ (ほとんどの生理データ…) 等を主成分分析 PCA すると、偽のオシレーションが出現する
-  Refactoring Programs Using Large Language Models with Few-Shot Examples
	- https://arxiv.org/abs/2311.11690
	- リファクタリングにLLMを使う
- "On Bringing Robots Home" Nur Muhammad Mahi Shafiullah et al., New York University
	- https://arxiv.org/abs/2311.16098
	- 家庭用ロボットの普及に向けて、一般のロボットを各家庭に適用させるためのフレームワーク『Dobb·E』が開発され、オープンソースで公開
	- 一般のロボットを家庭用ロボットにアップデートするための一連の流れをカバーするフレームワークが『Dobb·E』
	- ① 合計109のタスクを実際の家庭で実施し、ロボットの成功率が81％に達した 
	- ② 調理家電を閉める／クッションをひっくり返すタスクは100％、6軸で物を移動するタスクは56% 
	- ③ データ収集時にカバーされていた照明や影の条件下ではロボットは安定して稼働する
- Introducing Llama Datasets 
	- https://blog.llamaindex.ai/introducing-llama-datasets-aadb9994ad9e
	- llamaindexより、RAG向けの評価用データセットの公開
	- history of alexanetとか、origin of covid19などのpdfを含む、多分正解値は？
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
	- https://arxiv.org/abs/2311.16079
	- llama2を医療に特化してチューニングしたLLM
	- Compared to closed-source LLMs, MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2.
	- webuiで試せる！
	- https://github.com/epfLLM/meditron/blob/main/deployment/README.md#serving-with-web-gui
- RAG用途に使える、Wikipedia 日本語の embeddings とベクトル検索用の faiss index を作った
	- https://secon.dev/entry/2023/12/04/080000-wikipedia-ja-embeddings/
	- Wikipedia日本語550万文でベクトル検索できるembeddingsと検索用faiss index作りました。20行ぐらいコード書くだけで簡単に利用できます！RAGしてもデータが少ないと面白みが少ないのですが、Wikipedia突っ込むと面白さが増えてくるので、興味ある方はお試しください！
	- huggingface spaceで試せる
	- https://huggingface.co/spaces/hotchpotch/wikipedia-japanese-rag-qa
	- 「ナウシカと森の人との関係は？」には全く答えられない。
- Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift
	- https://arxiv.org/abs/2311.15961
	- 共変量シフトのネタで"All you need"的な流行りのタイトルの論文なんだけど，内容はしっかり数理やってるっぽい．がっつりShimodaira (2000)も参照されてました．共著者に数理統計の大御所のJianqing Fan先生とか，機械学習の理論系のChi Jin先生など
- Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation
	- https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2
	- Check out this fantastic blog covering the basics of RAG, the theory behind it, and how to use it in practice
- Mamba: Linear-Time Sequence Modeling with Selective State Spaces
	- https://arxiv.org/abs/2312.00752
	- トランスフォーマーや注意機構に頼らない、線形時間のシーケンスモデリングのための新しいニューラルネットワークアーキテクチャ
	- 2倍サイズのTransformersに匹敵したり、5倍の高速推論が出来たりと、Transformerを代替しうる可能性
	- 2.8Bが出てるらしい、
	- https://huggingface.co/state-spaces/mamba-2.8b
-  Instruction-tuning Aligns LLMs to the Human Brain
	- https://arxiv.org/abs/2312.00575
	- Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain.
- マルチモーダルLLMの応用動向の論文調査
	- https://speakerdeck.com/masatoto/marutimodarullmnoying-yong-dong-xiang
- 生成文法研究者の中で「言語の本質」（今井先生）の評判が良くなかった
	- https://x.com/kkling51/status/1731543891348996466?s=20
	- (i) アブダクション推論は適切な推論ではないからそれに頼るべきではない 
	- (ii) 言語とは何かという定義がないため，本質が何なのか分からない．
	- プラトンの問題も未解決のママ
- Amil Merchant et al., "Scaling deep learning for materials discovery", nature
	- https://www.nature.com/articles/s41586-023-06735-9
	- DeepMindの『GNoME』が「人間の直感を超えた220万の材料を発見し」うち736は既に人間が実験室で再現したとの報告
	- 大規模なデータセットと先進的な機械学習モデルを組み合わせる手法による、マテリアルズインフォマティクスの発展事例です
	- 方法
		- ① GNNを用いて素材の特性を構造や組成に基づいてモデル化
		-  ② 材料発見の効率が大幅に向上し、人間の直感を超えた220万の構造が発見された 
		- ③ 結晶構造内の原子を置換する手法やランダムな探索を含む、多様な候補生成アプローチを確立
	- 結果
		- ① 220万の新たな安定構造を特定し、それらの多くは既存の化学的直感を超えていた 
		- ② 発見された安定構造のうち736は、独立した実験で実現されている （シミュレーション上での検証ではなく、実験室で物理的に材料を作成し、実証できた）
- NVIDIAのH100をどこに出荷したかの図。MS,Metaが圧倒的に多い、GPT4を7日で訓練できる規模？
	- https://x.com/Lauramaywendel/status/1731698695853244849?s=20
	- GPT4 was presumably trained for around 90 days using 25k A100 GPUs. Microsoft and Meta having reportedly bought 150k H100 GPUs each this year, can now train a GPT4 class model in only 7 days from scratch
- Google Geminiの提供を１月まで延期
	- https://x.com/rowancheung/status/1731531903193219260?s=20
	- いくつかの分野ではGPT-4を上回るも、英語以外での性能が出ない。
	- これって、後から続くイベントの予兆かしらん、
- ある物理学の本で、ギリシャ語の説明表でゼータのところが、、
	- https://x.com/yori_Alphard/status/1731663363737026586?s=20
	- "Zガンダム"になっている。。
- GIVT: Generative Infinite-Vocabulary Transformers
	- https://huggingface.co/papers/2312.02116
	- 本当にトークンが離散でなくて、無限なのだろうか？
- ファインチューニングは不要、プロンプトだけでどうにかなる？
	- https://x.com/IntuitMachine/status/1732089266883141856?s=20
	- A recent research paper provides compelling evidence that the extensive fine-tuning used to "align" large language models into helpful assistants may be largely unnecessary.
	- Allenインスティテュートの仕業か、https://allenai.org/
- llamaindexでもマルチモーダルが盛り上がっている、Webinerなど
	- https://x.com/llama_index/status/1732081850246627547?s=20
	- https://lu.ma/350wf7v7
- 安全で責任あるAIの開発向けて、MetaとIBMが提携
	- https://ai.meta.com/blog/ai-alliance/
	- IBM とメタは、*オープン*で信頼性の高い AI を推進するために AI Alliance を立ち上げています。 産業界、政府機関、学界からの 50 を超える設立メンバーのリストには、AMD、Anyscale、CERN、Hugging Face、Linux Foundation、NASA が含まれます。
	- 日経にかかるとタイトルは、「メタとIBM、生成AI「オープン型」へ　50社・団体と連携」
- Prompting vs RAGs vs Fine-tuning:
	- https://x.com/akshay_pachaar/status/1732014719794585684?s=20
	- よくある４象限の絵、
	- So finetuning is more about changing structure (behaviour) than knowledge, while it's other way round for RAGs.
	- You use RAGs when you want to generate outputs grounded to a custom knowledge base while the vocabulary & writing style of the LLM remains same.
	- If you don't need either of them, prompt engineering is the way to go.
	- And if your application need both custom knowledge & change in the behaviour of model a hybrid (RAGs + Finetuning) is preferred.
- OpenAIのSafety System Teamsから
	- https://openai.com/safety/safety-systems
	- 協力のお願い
- PyTorchが出した、gpt-fastはすごいらしい
	- https://x.com/AlphaSignalAI/status/1732116360162050099?s=20
	- Pytorch just released GPT-Fast, an implementation of transformer text generation with everything you need in <1000 lines of code.
	- https://github.com/pytorch-labs/gpt-fast
- Windows11にcopilotが降臨？
	- https://www.microsoft.com/en-us/windows/copilot-ai-features?r=1
- JWT(Json Web Token)
	- https://x.com/alexxubyte/status/1732077250626179578?s=20
- Jellyfish: A Large Language Model for Data Preprocessing
	- https://arxiv.org/abs/2312.01678
	- データの前処理を得意とするLLM『Jellyfish（クラゲ）』が公開されました。 未知のタスクにも対応でき、比較的軽量であり1GPUでも動作するとのことです。 
	- 大阪大学、NEC、名古屋大学の研究者らによる発表です
	- ① データベースタスク特化モデルが進化 （GPT-4と同等の性能でデータ処理を行う） 
	- ② ゼロショットでデータ前処理タスクを実行 
	- ③ 多様な前処理タスクに対応 
	- ④ サイズが小さいため、1GPUでも動作する
- GooglがGemini(ジェマナイと読む）を発表
	- https://blog.google/technology/ai/google-gemini-ai/
	- 1. Geminiは3種類のモデル(Ultra, Pro, Nano)が存在。Ultraが最も賢く、Nanoはモバイルデバイス向け。
	- 2. Ultraは数々のベンチマークでGPT-4超えの性能を発揮 (ﾄﾞﾔｧ)
	- 3. Geminiはマルチモーダルに強い。動画デモのようにリアルタイム推論も可能。 
	- 4. 本日よりBardはGemini ProのFine-tuningバージョンを利用して公開する。その他にもGoogle製品への導入を進める。 
	- 5. Gemini APIは12月13日からGoogle AI Studioを通じて提供される。
	- https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
- Google AlphaCode 2 を発表
	- AlphaCode 2 Technical Report
	- https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf
	- Geminiを競技プログラミング用にカスタマイズしたAlphaCode2は、競技プログラミング人口の上位15%の性能
- MetaのStreamingの翻訳性能はすごいらしい、	
	- https://x.com/hokazuya/status/1732374854027132940?s=20
	- 翻訳こんにゃくレベル
- Bardの生成記事はChatGPTより優れている？
	- https://x.com/kajikent/status/1732237182126129578?s=20
	- コンテンツマーケティングの領域で有名なNeil Patel氏が約250ずつのChatGPT生成の記事とGoogle Bard生成の記事で読者にどちらが好きか聞いたところ、Bardが圧勝する結果に
- 人間レベルのAI(AGI)に到達すするには、常に10年以上必要
	- https://x.com/ylecun/status/1732391273611370931?s=20
	- 3～5年は常に必要（永遠に達成できない）との記事にLecan先生の反応
- Apple製品Mシリーズに最適化された深層学習フレームワークmlx
	- https://x.com/goto_yuta_/status/1732287555599741103?s=20
	-  Macに搭載されてるGPU(MPS)がより有効活用されてローカルLLMの高速推論が可能になったら嬉しいな。
- GeminiのTechnical reportを日本語で解説している人が登場
	- https://x.com/bioshok3/status/1732421662619140551?s=20
	- Gemini Ultraは、MMLU で人間の専門家の性能を達成した最初のモデルでありスコアは90%以上。やばすぎる。人間のエキスパートのパフォーマンスはベンチマーク著者によって89.8%と評価され、Gemini Ul traはこの閾値を超えた最初のモデル!時代が変わった。
	- 教師がスキーヤーが坂道を下りるという物理問題を描き、生徒がその解決策を練る。Geminiのマルチモーダル推論機能を用いて、モデルは 乱雑な手書きを理解し、生徒が問題の解決を間違えた推論の特定のステップを特定し、問題の正しい解決を通し て作業を与えることができる。
	- Google がGeminiのデモ動画を出しているけど、これほんとにこの推論速度なら凄すぎると言うかもう株価数倍くらいになるんじゃないの？ってレベルだけど？？
	- デモについては「このデモの目的のため、レイテンシーは短縮され、ジェミニの出力は簡潔にまとめられている。」と書かれてる
	- 多言語性能はGPT-4より良い
	- コンテキストトークン数は32768。98%の精度で正しい値を取得可能！98%?まじかよ。
- Googleアカウントの言語設定を英語にすると、BardのバックがGemimi Proが使える
	- https://x.com/npaka123/status/1732504570218283340?s=20
- Bard(Gemini Pro)が霞が関パワポを解析して説明してくれると、、	by ゆな先生
	- https://x.com/JapanTank/status/1732689643928445164?s=20
- Gemini論文の最後の、"Core Contributors"の最初の６人の頭文字をとると、"GEMINI"になる
	- https://x.com/nearcyan/status/1732532560029172142?s=20
- Metaより、安全なAIのための、Purple Llama（ツールセット、フレームワークみたいなもの）を発表
	- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=image
	- CyberSec Evalとか、Llama Guardが最初に出る
	- なんでpurpleかというと攻撃側（赤）と、防御側（青）が協力して構築したから
	- attack (red team) and defensive (blue team) postures.
	- Colabで試せるらしい
	- https://colab.research.google.com/drive/16s0tlCSEDtczjPzdIK3jq0Le5LlnSYGf?usp=sharing
- Evaluating and Mitigating Discrimination in Language Model Decisions
	- https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions
	- Anthropicより、（LLMの出力における）差別を検知するためのデータセットを公開
-  AMD、生成AIでNVIDIA H100を上回る性能のGPU「Instinct MI300」
	- https://pc.watch.impress.co.jp/docs/news/1552583.html
	- TDP 750WのMI300Xは、TDP 700WのNVIDIA H100と比較し、FP64,32で約2.4倍、AIで利用のTF32、FP16、BF16、FP8、INT8などでは1.3倍スループット実現。
- 赤石先生のベイズ推論本がわかりやすいと評判に
	- https://x.com/kenken26679105/status/1732977179485757744?s=20
	- 少ないデータ量でも、こんな風に、色んな実務の場面にすぐに活用できちゃう
	- Pythonでスラスラわかる ベイズ推論「超」入門 (KS情報科学専門書)
- チョムスキーの「生成文法」は死んだという論文
	- Modern language models refute Chomsky’s approach to language
	- https://lingbuzz.net/lingbuzz/007180/v1.pdf
	- 最近の生成AIてうか大言語モデルLLMの驚くべき成功から見て、チョムスキー流の生得的統語法規則があるという説は維持しづらい
- llamaindexより、知識グラフ(KG)を使う、７つのパターンを表にまとめてくれた
	- https://x.com/llama_index/status/1733190430760845673?s=20
	-  A Simpler Way to Query Neo4j Knowledge Graphs
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/neo4j_query_engine/llama_packs_neo4j.ipynb
- 欧州AI法の最終トリローグが終了、妥結へ
	- https://x.com/WIRED/status/1733268732309332398?s=20
	- https://www.reuters.com/technology/eu-clinches-deal-landmark-ai-act-2023-12-09/?taid=65745dd360152800018aaf1c&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter
	- https://twitter.com/SabrinaKuespert/status/1733311752941515135/photo/1
	- https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?xtor=AD-78-[Social_share_buttons]-[twitter]-[en]-[news]-[pressroom]-[artificial-intelligence-act-possible-deal]-
	- 基盤モデルで規制されるのは、計算量が10^25FLOPsを超えるモデル。
	- 該当するのは今んとこGPT-4とGeminiあたり。
	- それらのモデルはシステミックリスクに応じて分類される。
	- システミックリスクはモデルがどんだけ強力か、どんだけの人が使うかで決まる。
	- 規制の内容は
		- ①リスクの軽減を行う　
		- ②モデルの評価、敵対的テストを実施する　
		- ③インシデントの監視をする　
		- ④サイバーセキュリティを確保させる　
		- ⑤ドキュメントを作らせる
-  Generative AI for Everyoneから、古のNLPエンジニアの心に刺さったこと8選
	- https://note.com/csstudyabroad/n/n5aba3a708f3a
- "Purple Llama CyberSecEval: A benchmark for evaluating the cybersecurity risks of large language models"
	- LLama Purple関連の CyberSecEvalの論文
	- https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/
	- Metaの研究者らは、LLMが生成するコードにおける不安定性や乱用リスクを評価するためのツールを作成しました。
	-  実験の結果、現在は、能力が高いモデルほど不安全なコードを提案する傾向が強いという逆説的な結果も出てきました。
	- ① 全体的にLLMは、30%のケースで不安全なコードを提案した 
	- ② 53%のケースで、サイバー攻撃の手伝いをするリクエストに対してLLMが応じた
	-  ③ コーディング能力が高いモデルほど、不安全なコードを提案する傾向が強かった
- "Sequential Modeling Enables Scalable Learning for Large Vision Models"
	- https://arxiv.org/abs/2312.00785
	- 「視覚は本来、言語に依存しない」と考えたUCバークレーとジョンスホプキンス大学の研究者らは、言語データなしで大規模ビジョンモデル（LVM）を構築するアプローチ
	- ■アプローチの詳細 
		- ① 画像や動画を表現する「ビジュアル文」を定義 （ピクセル以外のメタ情報はない） 
		- ② 視覚データをトークン化 
		- ③ 自己回帰型トランスフォーマーモデルを訓練
	- ■実験の結果わかったこと 
		- ① モデルは大量データを処理し学習する能力が高い
		-  ② 様々なビジョンタスクで有効 
		- ③ モデルサイズが大きくなるにつれて、下流タスクのパフォーマンス向上する
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- Scenarios of adopting LLMs, techniques for utilizing LLMs on graphs, applications, #opensource code repositories, benchmark datasets
- 「2030 日本デジタル 改革」 by マッキンゼー
	- https://www.digitaljapan2030.com/_files/ugd/c01657_fcaed21f58bb4c429cb460ce788b82c4.pdf
	- マッキンゼーのレポート（全140ページ）
	- 日本のデジタル化がなぜ遅れたのか、それに対してどのような打ち手が取れるのか、ということが分かりやすく整理されています。 
	- 日本の総労働時間の56%が自動化可能
- ollama + stablelm-zephyr 試す。 M1でもはやい。
	- https://ollama.ai/library/stablelm-zephyr
- Ollama : ローカル環境で容易にllamaを利用可能にるするAIチャットプログラム
	- https://note.com/astropomeai/n/nbcdfd3b38490?sub_rt=share_b
	- https://github.com/jmorganca/ollama
	- コマンドラインインターフェースを通じて大規模言語モデル（LLM）とやり取り可能なAIチャットプログラム
	- LlamaやCode Llamaなど、さまざまなオープンソースモデルをサポート
	- モデルのパラメーターやサイズが異なり、計算リソースに応じたAIモデルの実行を柔軟に対応
	- Dockerがインストールされたシステムで利用可能で、Nvidia GPUのGPUアクセラレーションをサポート（CPU上でも実行可能）
	- パフォーマンスはハードウェアに依存し、例えばLlama 2の7Bモデルを実行するには最低15GBのRAMと4つのCPUコアが必要
	- MacOSとLinux用のデスクトップアプリケーションがあり、Windows版が開発中
-  Ollama Llama Pack Example
	- https://docs.llamaindex.ai/en/latest/examples/llama_hub/llama_pack_ollama.html#
	- llamaindexより、さっそくOllama対応のRAGの例
	- https://llamahub.ai/l/llama_packs-ollama_query_engine
- ollama web-ui is amazing
	- https://github.com/ollama-webui/ollama-webui
- ClimateXのデータセットが公開されている
	- https://huggingface.co/datasets/rlacombe/ClimateX
- Mistralより、新しい mixtral-8x7b-32kseqlenを発表
	- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
	- 「我々はMistral MoE (7Bx32experts) を 2 か月間使用しており、それは24GBで動作しています。」
- What is Mixture-of-Experts (MoE)?
	- mixtral-8x7b-32kseqlenの裏にあるmoe技術とは
	- https://x.com/sophiamyang/status/1733505991600148892?s=20
	- MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block.
- たった87GのweightでAGIが来るから、AI規制必要だねという
	- https://x.com/abacaj/status/1733561182504587652?s=20
	- mixtral-8x7b-32kseqlenのことらしい
- MoEのMixtral-7bx8のGPTQきとる！
	- https://huggingface.co/TheBloke/mixtral-7B-8expert-GPTQ
- Geminiのお遊びデモは、紙芝居だ
	- https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/

## 12/4

先週までのOpenAIのお家騒動も落ち着き、今週は通常運転。日常能力を試すテスト『GAIA』、プロンプトの良例にもなっているし、現状のLLMの限界を図るのにちょうどよい。A*の可視化、こういうのを待ってた。異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』というのは、フリーアドレスの執務環境の研究活動の活性化にヒントがあるかも。選択バイアス問題がなぜか着目される。清水さん、ついに、A100 80GBx8のマシンが完成、日本語のマルチターン会話データセットもそろえてくれて、日本発のトップクラスLLM開発に大いなる期待。Intel® のトランスフォーマ拡張、量子化の新たなる段階？Googleからdebateを基にした安全なLLM利用についての理論論文公開。カーネマン教授とルカン先生の対話も必聴、system1とsystem2と深層学習の関係は、あるよな。BERTopicや、AlphaFold、googleの翻訳トランスフォーマーも着実に改良が進んで実用フェーズにまた一歩進んだ。Google Colabについにtransformerがデフォルトで含まれるようになる、つまりそういうことだ。強化学習系のアルゴリズムは、スパースな対象には不適切なのか。プロンプトを逆推論したり、サロゲート（代理）モデルにおける逆問題の研究も注目。llamapackってのができているのか、試してみよう。Agentをよく使ってるけどもっと種類がある、認知アーキテクチャってのはちゃんと理解したい。「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」というのは続編を望む。LLMをPytorchだけでどれだけ高速化できるかとか、GPT-fastとか、小規模言語モデルの開発とか、そういうのがもっと出てくるはず。OSSのLLMについての論文「ChatGPTの1周年を記念して」もいいね、OSSのLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示しているとな。アメリカの医学試験「US (4-option)」で90.2％という高い正解率をだしたGPT-4評価論文、下手なファインチューニングよりもという話か。


-  An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
- GAIA: a benchmark for General AI Assistants
	- https://arxiv.org/abs/2311.12983
- Q*ではないですが、A*探索の様子を可視化した
	- https://x.com/GregKamradt/status/1728480680127148480?s=20
- Kevin Dunnell et al., "Latent Lab: Large Language Models for Knowledge Exploration"
	- https://arxiv.org/abs/2311.13051
	- LLMベースで、異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』
	- ①対話と視覚化を通してデータを探索 
	- ② プロジェクトのクラスタリングとラベル付けを自動化
	-  ③ 新しい研究プロジェクトのアイデア合成も可能
-  Google Colab で LCM LoRA を試す　 by npakaさん
	- https://note.com/npaka/n/n940ee84ca5b6?sub_rt=share_h
	- 「LCM」 (Latent Consistency Model) は、元モデルを別モデルに蒸留することで、画像生成に必要なステップ数を減らす手法です。25～50ステップかかっていた処理を4～8ステップで可能にします。
- Multi-modal Foundation Model for Material Design
	- https://openreview.net/forum?id=EiT2bLsfM9
	- 分子を表現するマルチモーダル基盤モデルの研究。SELFIES、DFT物性、スペクトルについてそれぞれencoder-decoderを学習し、各モダリティの潜在空間を共通の潜在空間にencode, decodeするモデルを学習。
	-  欠損が多くても学習可能かつ、後から異なるモダリティを追加しやすい
- 選択バイアスの式、tweedle
	- https://x.com/docmilanfar/status/1728680465928958055?s=20
- llamaindexより、RAG評価ツールragsのv2リリース
	- https://github.com/run-llama/rags
-  Simplifying Transformer Blocks 
	- https://arxiv.org/abs/2311.01906
	- many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:
- llamaindexから、RAGの新モジュール、fuzzy citationを発表
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/fuzzy_citation/fuzzy_citation_example.ipynb
	- https://llamahub.ai/l/llama_packs-fuzzy_citation
	- 部分的な検索結果から１つの回答を合成？？
- ＲＡＧ 101 for enterpirze
	- https://gradient.ai/blog/rag-101-for-enterprise
	- 絵が素敵
-  AIスーパーコンピュータ「継之助」爆誕!とりあえずRAID0で12TBのディスクをインストールする
	- https://note.com/shi3zblog/n/n77e8ad3ed779?sub_rt=share_pb
	- ついにA100 80GBx8のマシンが稼働した。ここまで長かった。
	- ここまで揃ったら日本最大規模のLLMを個人で作れるようになる。
-  A population-level digital histologic biomarker for enhanced prognosis of invasive breast cancer
	- https://www.nature.com/articles/s41591-023-02643-7
	- An important AI report for breast cancer leading to the potential of sparing chemotherapy for many. 
	- The 1st comprehensive analysis of both cancerous and non-cancerous tissue in hundreds of thousands of patient tissues-
- BERTopicの新しいバージョン
	- https://github.com/MaartenGr/BERTopic
	- Merge pre-trained models, apply zero-shot topic modeling, seed domain-specific words, and much more in this HUGE update!
- Intel® Extension for Transformers
	- https://github.com/intel/intel-extension-for-transformers
	- An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere
	- Intel Extension for Transformers supports INT4 model quantized by GPTQ on Intel platforms (Xeon & PC) !
	- https://github.com/intel/intel-extension-for-transformers/tree/1.2.1#int4-inference
-  ラプラス変換とフーリエ変換の関係
	- https://qiita.com/kaityo256/items/aa5b24904577de40016e
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
- Google Colab、Huggingfacesの協力で、transformerを最初から使えるようになった
	- https://x.com/GoogleColab/status/1729217098977845590?s=20
- A Llama-2-based model finetuned for function calling:
	- https://huggingface.co/Trelis/Llama-2-7b-chat-hf-function-calling-v2
- 日本語Wikipediaのマルチターン会話データセット10万個を作りました	
	- https://note.com/shi3zblog/n/na10eed9270f8?sub_rt=share_pb
	- GPT-3.5-Turboを使って、約一ヶ月かけて日本語のWikipediaの項目をもとに先生と生徒が会話するマルチターンデータセットを作りました
	- GPT-4でもやってみようかなと思っていますが、GPT-3.5でも一ヶ月でかなりの出費があり、GPT-4で同じ分量のデータセットを作るとなると数十万円から数百万円かかりそうです
- llamaindexからRAGに有効なllamapackを７種類公開
	- https://x.com/llama_index/status/1729303619760259463?s=20
- Compositional Generative Inverse Design
	- https://openreview.net/forum?id=5ueXRkKMMg&referrer=%5Bthe%20profile%20of%20Yilun%20Du%5D(%2Fprofile%3Fid%3D~Yilun_Du1
	- シミュレーションを深層学習モデルで近似した代理シミュレータと、拡散モデルを使った逆問題解法は、しばしば学習データ分布外にいったり局所解に陥ることがある。それを防ぐために、学習済みモデルを使って拡散モデルの各ステップで解を誘導し、不適切な解を防ぐCinDMを提案
- mlc-llm on WSLでモデルの変換を行う
	- 「WebGPUを用いたローカルLLMモデルのブラウザ推論」
	- https://zenn.dev/saldra/articles/356f470e730d1c
- ＮＴＴコムのＡＩ学習教材
	- https://gochikika.ntt.com/index.html
	- データの前処理からモデリングや評価までPythonコードと合わせて一通り学べる
- マルチモーダルのＬＬＭでも出力の成型が大事
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb
- John X. Morris et al., "Language Model Inversion"
	- https://arxiv.org/abs/2311.13647
	- 言語モデルは次の単語の確率を出すが、その「確率」を利用して元の文章（プロンプト）を何とかして見つけ出す手法を開発。
- OpenAIのcookbookにllamaindexをつかたRAGが掲載
	- https://blog.llamaindex.ai/openai-cookbook-evaluating-rag-systems-fe393c61fb93
- Minimizing Factual Inconsistency and Hallucination in Large Language Models
	- https://arxiv.org/abs/2311.13878
	- LLMのハルシネーションを抑制するフレームワークが提案されました。 ユーザーの質問に対して、多段階で情報を取得させることで、信頼性の高い応答を取得可能です。
- Relational Deep Learning
	- https://drive.google.com/file/d/1Uk1y6c8z265G0wiRPpGT1cd5lts5lnKq/view
	- Relational Deep Learning is brings the power of Graph Representation Learning to a Relational Database.
- NeurIPA2023の論文検索サービス
	- https://www.ai-driven-life.com/neurips-papers
- 強化学習はベルマン最適性原理から来る動的計画法に支えられてます。しかし、情報がrandomSamplingされる中で実は各時刻隣合うデータの列がほとんど情報（報酬）を持たないとなると、間に推定器が挟まってるのもあってスパースどころか最後にしか報酬が得られない問題への妥当性は怪しいかもですね。
	- https://x.com/ML_deep/status/1729249503683969037?s=20
- DeepMind has formalized a theoretical result related to AI safety in Lean. 
	- https://github.com/google-deepmind/debate
	- "Monadic syntax is excellent for expressing stochastic algorithms, and working over finitely supported distributions avoids the need for integrability side conditions during proofs."
	- But I’m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think “not killing lots of people” is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and that’s where this type of method might shine.
	- https://x.com/davidad/status/1729461156618637502?s=20
- Azure OpenAI Serviceの日本語記事まとめ
	- https://zenn.dev/microsoft/articles/azure-openai-japanese-blogs
- カーネマン教授とルカン先生の対話
	- https://www.youtube.com/watch?v=oy9FhisFTmI
	- Video of Daniel Kahneman and Yann LeCun discussing Dual Process Theory (i.e., System 1 and 2) in relation to Deep Learning.
-  ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search
	- https://arxiv.org/abs/2310.13227
	- uses algorithms like A* to improve LLM answers, improving sota on both planning and reasoning tasks
- Qualcomm Snapdragon 8gen 3 already supported 10b language model running locally on your smartphone.
	- https://x.com/Francis_YAO_/status/1727861621110779941?s=20
	- LLM is the new smartphone OS!
- Domingos先生がなんか言っている
	- https://x.com/pmddomingos/status/1729303707387658284?s=20
	- Why AI isn't going to taking over (from "The Master Algorithm").
- MistralChameli_7B_v01
	- https://huggingface.co/TokenBender/MistralChameli_7B_v01
	- First version of DPO-ed roleplay/smart version of Mistral. Now to conduct some experiments with reward model and see if this is any good.
- ベイジアンモデルへの経験ベイズ修正
	- https://www.jstage.jst.go.jp/article/keidaironshu/68/4/68_161/_article/-char/ja/
	- Robbins (1956) が Tweedie (1947) に言及してることに基づき，Efron が Tweedie's formula と名付けて広まっているが，Koenker & Gu (2016) では Dyson (1926) で既に得られていることが指摘されている。
-  A glimpse of the next generation of AlphaFold
	- https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/
	- AlphaFoldは最近大きなアップデートがあり、精度が大幅に向上し、タンパクだけでなくPDBにあるほぼすべての分子について予測可能です。創薬や新型CRISPR探索にも(一定程度は)使えます。
- EMNLP2023 の採択論文リストが見えるようになってた．来週シンガポールで開催される自然言語処理の国際会議です．タイトルに"Language Model"はいってる論文が219本って，どんだけ言語モデル好きなんだよ
	- https://2023.emnlp.org/program/accepted_main_conference/
-  OpenAI と LangChain の認知アーキテクチャ by npakaさん
	- https://note.com/npaka/n/n650532ce289a?sub_rt=share_h
	- 「**認知アーキテクチャ**」(cognitive architecture) とは、LLMどのように情報を処理し、応答を生成するかを理解するための枠組みです。「Flo Crivello」（自律エージェントスタートアップのLindyの創設者）が使用したこの用語を初めて聞き、素晴らしい用語だと思いました。
	- 「LangChain」では、「LLM」が真に変革的なエージェントのようなシステムに電力を供給する世界を信じています。しかし、そこにたどり着くルートは、**企業が「認知アーキテクチャ」を制御できるルート**であると信じています。
	- **(1) Code**  LLMを利用しないパターン。  
	- **(2) LLM Call** アプリの出力のみを決定する単一のLLMコール。 
	- **(3) Chain**  アプリの出力のみを決定する複数のLLMコール。  
	- **(4) Router**  LLMをルーターとして使用し、使用するアクション (Tool、Retrieval、Prompt) を選択。 
	- **(5) State Machine**  LLMを使用してある種のループでステップ間をルーティングするが、コードが許可された遷移先にのみ遷移  
	- **(6) Agent**  利用可能なステップのシーケンスを決定もLLMが行う。
- TextからSQLを生成するQuerypls
	- https://github.com/samadpls/Querypls/
- われらが、 @jerryjliu0がdeeplearningaiコースに登場
	- https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/
	- We also have LlamaPacks for every technique mentioned in this course to help you jumpstart your advanced LLM app:
- Deconstructing RAG
	- https://blog.langchain.dev/deconstructing-rag/
	- Given the importance of RAG and the fast pace of development, we've grouped popular RAG concepts into a few categories and created guides for each one.
- Running Starling-7B LLM model on local CPU with @Ollama_ai and getting great results for invoice data extraction, even better than Zephyr, Mistral or Llama2.
	- https://github.com/katanaml/llm-ollama-invoice-cpu
- 円城塔を近似する？
	- https://colab.research.google.com/drive/1oXxBIYJvvUYsVZP6WYAUCb3QK09zTJtO?usp=sharing
	- 円城塔さんの文章で学ぶ、大規模言語モデルのファインチューニングチュートリアル
- 「長コンテキストをLLM(GPT, Claude)に食わせた際に、ちゃんとRetrivalされるか？」を検証しているGithub。
	- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
	-  総じてCalude-2に比べてGPT-4 Turboのほうが正確に引用しているようで面白い。
- Qwen/Qwen-7B-Chat-Int4をGoogle Colobで動かす
	- https://ayousanz.hatenadiary.jp/entry/2023/11/30/182017
	- なんか日本の文化はちゃんと学んでいないみたいですね
-  Accelerating Generative AI with PyTorch II: GPT, Fast
	- https://pytorch.org/blog/accelerating-generative-ai-2/?utm_content=273712248
	- GPT-fastというのがすごらいしい、３倍？
- LiLM 小規模言語モデル TinyLlama 1.1B の日本語追加事前学習(incremental pretrain) を試したメモ
	- https://zenn.dev/syoyo/articles/52f1d0d62fcad5
	- 生成される日本語はまあまあであるが, 構文やコンテキストがおかしい...
	- ファインチューンしても間違えたり...
	- まあでも 1B 規模なら妥当なのかもしれません
- 今号の『日本語の研究』で「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」と題して、OpenAIのtext-embeddingを使って、『万葉集』と『古今集』の意味構造の差を解析してみました。
	- https://www.musashinoshoin.co.jp/shoseki/view/2976/
- Energy and entropy: Path from game theory to statistical mechanics
	- https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.043055
	- エネルギーを低くするのが目標のプレーヤーと，エントロピーを上げるのが目標のプレーヤーの交渉ゲームにおける最適な戦略を通して熱平衡化を議論するらしい
- gpt-fast
	- https://github.com/pytorch-labs/gpt-fast
	- LLMをPytorchだけでどれだけ高速化できるかチャレンジしたリポジトリ Llama-7Bが10倍速くなっている 
	- Pytorchで使える高速化技術をいろいろ盛り込んでるぽっくて、中身見るのも勉強になりそう
- 日本語LLMでLLaVAの学習を行ってみた
	- https://qiita.com/toshi_456/items/248005a842725f9406e3
- googleから新しい翻訳トランスフォーマーを発表
	- Unsupervised speech-to-speech translation from monolingual data
	- https://blog.research.google/2023/12/unsupervised-speech-to-speech.html
-  業界別生成AI活用のすゝめ
	- https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/about-deloitte-japan/ai-dossier-2023.html?id=jp:2pm:3tw:4daii-genaidossier:5:6abt:20231201::
	- デロイトトーマツ
-  Microsoft Copilot is now generally available
	- https://blogs.bing.com/search/december-2023/Microsoft-Copilot-is-now-generally-available?ocid=aid_soc_usoc_edu_cons_bing_eng_tw_12.1
- C言語でWASMインタプリタを実装した話
	- https://zenn.dev/ri5255/articles/845ef3dab5ab47
	- この自作WASMランタイムの目的は、できるだけ仕様に従った実装を与えることで、仕様の理解を助けることである。早さや効率性よりも分かりやすさを優先しているため、実用には向かない。仕様書を読んで、実装に困った際に参照してほしい。
-  データ不足に数理モデルで立ち向かう / Japan.R 2023
	- https://speakerdeck.com/dropout009/japan-dot-r-2023
- Harsha Nori et al., "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
	- https://arxiv.org/abs/2311.16452
	- これまでGPT-4などの基盤モデルは、医学などの専門分野で特化モデルには敵わないと考えられてきました。 しかし、「実際はどうなのか？」と考えた研究者らは、特別なトレーニングなしのGPT-4が、プロンプトの工夫のみでどこまで性能を示すのかを検証しました。
	- ① アメリカの医学試験「US (4-option)」で90.2％という高い正解率を出した
	-  ② 理由付けが必要なタイプの問題データセットPubMedQAで82.0％の正解率を達成
-  日常能力を試すテスト『GAIA』正答率、人間92%に対してGPT-4は15%　一般的なニーズに応えるAI開発の指針に
	- https://aiboom.net/archives/59440
- Langchain102
	- https://www.youtube.com/watch?v=haad3i9VROs
	- Mistral 7b User Showcase + LangServe & LangSmith
- METAのAI研究者が何らかの大きなブレイクスルーがあったと示唆。 近日中に共有予定とのこと
	- https://x.com/ArmenAgha/status/1731076069170835720?s=20
-  「ChatGPTの1周年を記念して」、オープンソースLLMがChatGPTにどこまで追いついているか体系的調査報告
	- https://aiboom.net/archives/59713
	- https://arxiv.org/abs/2311.16989
	- オープンソースLLMとしてはLlama-2（およびMentalLlama）、Palm、Vicuna、Falcon、Wizard、Lemurなどのモデルに焦点を当て、それらの進歩のスピードと特定のタスクでの優れた性能について詳しく分析されています。調査結果からは、オープンソースLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示していることが明らかになりまし
- MRS2023(materials research society)でLLMが多い 2023 MRS Fall Meeting & Exhibit
	- https://x.com/yoko_materialDX/status/1731267042810962256?s=20
	- MIセッションが常時4つあり回るのが大変
	- 機械学習ポテンシャルと自動合成の発表が大量
	- 結晶構造予測の発表が思ったより多かった
	- LLMの発表は材料データ抽出が中心
	- 日本企業からのMI発表が多かった 
	- 世界情勢ゆえ？）中国本土の方がほぼいなかった

## 11/27

アルトマン氏解任劇は、マイクロソフトがアルトマン氏の受け入れを表明するも、OpenAIの主要メンバがアルトマン氏に追従すると表明したのでボードが復帰を懇願、結局OpenAIのCEOとして戻ることで幕引き。解任劇の背後には、OpenAIでAGI（スーパーAI)を達成する見込みが立った、それがQ*というLLMで、従来のLLMが苦手だった数の推論が可能になった、Q*の取り扱いを巡り解任騒動が起きた、といううわさで持ち切りに。Q*-learningがそれでは？みたなことになって様々なところで盛り上がっている。それ以外では、intelが満を持してneural-chat-7b-v3-1を公開、Mistral 7Bベースなんだけど、様々なチューニングにより相当性能が良いみたい、しかしFalcon 180B越えということはないと思うぞ。AnthropicAIが200kのコンテキストを扱えるClaude2.1を発表、デモ版が利用可能で、さっそく結構長文の日本語のPDFをそのまま投入できるとか、エバンゲリオン世界のシミュレーションを動かしてみたとか話題に。「３D世界の中で身体性をもった汎用エージェント」の論文、いや 「未来の二つの顔」（ホーガン）のAI（仮想３D空間シミュレーションで身体性を学習させる）を彷彿させる世界が現実になったような気がする。データベースに対するQ&Aにおいて、SQL文を生成される方法と、データベースの内容をいったん知識グラフにしてQ&Aする方法を比較し、後者のほうが高性能との報告も。まあコンテキストというかそういうのを与えたほうがいいに決まっているのだが。RAGにおいても、コンテキストをフィルタリングするのが有効らしい、そのあたりにまだ人の工夫の余地が残っている。Llemmaは、LLMで数学の問題を解くのに、定理証明器を使うことを前提にしたPythonコードを出力することで実現、LLMを活用して問題を解くメタなアプローチ（直接解くのではなくて、解く手順・方案を生成する）の１つ。LLMベースの新しい言語『SUQL』もいい感じで非構造データを扱えるらしいが、例題がレストランの会話とは第２世代AIにおけるフレーム問題ぽくていいね！AIが人間が思いつかないような「異質な」仮説を生成することで、科学が進化する、かも。ChatGPTをつかって、部屋を片付けている人がいた、これはすごい応用だ！OECDのAIの定義も生成AIや基盤モデルを鑑み４年ぶりに改定、人の指示に従わずとも、入力に対して自らのとるべき動作を推測するメタ能力についも暗示、もはやAIに対するソフトウエア的な品質保証は不可能な事態へ。

-  Banach-Tarski Embeddings and Transformers
	- https://arxiv.org/abs/2311.09387
	- 再帰的なデータ構造の線型空間での表現（バナッハタルスキ埋め込み）を考えるとその表現上のアルゴリズム（復号）がTransformerとして自然に実装できるらしい
- 大規模言語モデルを用いた意味分析による辞書記述への応用
	- https://speakerdeck.com/yhkondo/da-gui-mo-yan-yu-moderuwoyong-itayi-wei-fen-xi-niyoruci-shu-ji-shu-henoying-yong
	- 埋め込み（ベクトル化）の辞書作成への応用とか、枕草子を題材に埋め込みをつかたｔ類似検索してみる例が、英語による検索、絵文字による検索、クリエーティブな検索など事例があって面白い
- Shicheng Liu et al., "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models"
	- https://arxiv.org/abs/2311.09818
	- LLMベースの新しい言語『SUQL』が開発されました。SQLを拡張して「非構造化データのクエリ」を処理するパラダイムを導入
	- 『SUQL（Structured and Unstructured Query Language）』
	- ① 構造化データと非構造化データの両方を扱う 
	- ② SQLに、非構造化データをクエリするための新しいプリミティブを追加 
	- ③ 会話型検索エージェントでユーザーの質問を処理 
	- ④ クエリに関連するデータを構造化および非構造化データソースから抽出する
	- 従来の線形化テクニックや多段階検索および推論モジュールに比べて、SUQLは回収精度が大幅に高い
	- 実際のレストランに関するクラウドソースされた質問と会話を含むデータセットで実用性が確認された
-  Meta disbanded its Responsible AI team
	- https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence
	- metaが責任あるAIのチームを解散させた
- 状態空間モデリング入門
	- https://www.no-spare.com/store/products/seminar-20231129
	- 本講座では、金融時系列データへの応用を題材に、動的線形モデル・ボラティリティモデル・最新の研究を解説します。
-  Hypotheses devised by AI could find ‘blind spots’ in research
	- https://www.nature.com/articles/d41586-023-03596-0
	- AIが仮説を生成する際に直面する課題として、データの不足、物理的な法則の理解、仮説の一般性と解釈性などが挙げられています。
	- AIが仮説を生成する可能性として、人間が思いつかないような「異質な」仮説や、実験を自動化する「ロボット科学者」などが紹介されています
-  Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild
	- https://arxiv.org/abs/2311.06237
	- 大規模言語モデル(LLM)をしばき倒して、異常な振る舞いをさせようとしている人達（野良のLLMレッドチーム）へのインタビュー論文。攻撃方法やそもそも何のためにやっているのか？等の調査。
- アルトマン氏、ゲストカードを使って、OpanAIを訪問
	- https://x.com/sama/status/1726345564059832609?s=20
	- first and last time i ever wear one of these
-  ChipNeMo: Domain-Adapted LLMs for Chip Design
	- https://arxiv.org/abs/2311.00176
	- ChipNeMoはチップ設計支援向けにドメイン適応したLLM。開発支援Chatbot、EDAスクリプト生成、バグ要約と分析を行う。既存LLMに、専用トークンを追加した後、ドメイン適応事前事前学習（DAPT 230億トークン）、指示学習（1000例）をし、ドメイン適応検索補強を行う
- マイクロソフトのナデラ氏、アルトマン氏たちがマイクロソフトにJoinすると、、
	- https://x.com/satyanadella/status/1726509045803336122?s=20
- マイクロソフトによる生成AIのチュートリアル
	- https://github.com/microsoft/generative-ai-for-beginners
	- The free 12 lesson course is available on Github and will teach you everything you need to know to start building Generative AI applications.
-  Learning to Filter Context for Retrieval-Augmented Generation
	- https://arxiv.org/abs/2311.08377
	- RAGにおいて、コンテキストをフィルタリングする方法を学習する
	- 語彙および情報理論的なアプローチを通じて有用なコンテキストを特定し、テスト中にコンテキストをフィルターするためのモデルをトレーニングすることが含まれます。
	- FILCO は、コンテキスト フィルタリングに String Inclusion (STRINC)、Lexical Overlap、Conditional Cross-Mutual Information (CXMI) などの技術を使用
- 日本語対応 LLM(13B 規模)の, 行間を読むようなかしこさがあるか試したメモ(現状 Qwen 14B がベスト)
	- https://zenn.dev/syoyo/articles/59a5ccbbb5660e
	- 7B 以下(10B 未満)も試しましたが, 行間を読むほどのかしこさはなく, 13B 規模で飛躍的にかしこさが上がる感じだったので, 13 B 規模のを選んでいます.
	- qwen.cpp(llama.cpp variant)で f16 量子化版を動かしました.
	- q4 あたりに量子化だといくらかかしこさ落ちました(それでもほかの日本語 LLM よりよい結果をえられる)  また, Qwen7B もあまりかしこくはありませんでした.
	- Qwen 14B(Chat) ちゃんが行間を読むほどのかしこさを見せました!
- OpenAIがNPO+であるようなことが、今回のアルトマン氏解任につながったとの絵柄
	- https://x.com/GOROman/status/1726701627468546511?s=20
-  Azure OpenAI Service 入門 by npakaさｎ
	- https://note.com/npaka/n/n46e6ad252ce1?sub_rt=share_h
	- 「Azure OpenAI Service」で「gpt-3.5-turbo」を使用する手順をまとめました。
-  Orca 2: Teaching Small Language Models How to Reason
	- https://huggingface.co/papers/2311.11045
	- 小さいことはいいことだ
-  Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data
	- https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1
	- llamaindexのJerryが放つ、streamlitをつかった、RAGアプリ生成ツールRAGs
	- “ChatGPT over your data” without needing to code.
- Large-scale pancreatic cancer detection via non-contrast CT and deep learning
	- https://www.nature.com/articles/s41591-023-02640-w
	- ｢単純CTの膵臓がん検出AI｣
	- 単純CTでの膵臓がん検は不可能と考えられてきた 
	- そのAIを開発 
	- 現実世界のマルチシナリオ検証の病変検出で、92.9%の感度と 99.9% の特異度を達成 
	- 膵臓がんスクリーニングの新しいツールの可能性
-  RAG評価ツールの "RAGAS" を使って、RAGパイプラインの性能を測定する
	- https://qiita.com/s3kzk/items/44b8780c656b4f747403
	- 今回触れたチャンク分割時の設定以外にも、システムプロンプトの決定、Embeddingおよび応答の生成に使用するLLMの選定、ベクターストア/検索アルゴリズムの選定など、パフォーマンスに影響を与える要素は数多く存在します。
- アルトマン氏OpenAIに復帰すると
	- https://x.com/OpenAI/status/1727206187077370115?s=20
-  2週間使い倒してわかった｢GPT-4-Turboの衝撃｣。OpenAIの｢お家騒動｣で見逃してる場合じゃない
	- https://www.businessinsider.jp/post-278766
- AnthropicAIよりClaude2.1の発表
	- https://x.com/AnthropicAI/status/1727001773888659753?s=20
	- コンテキスト長はなんと 200k と 2 倍に拡大。ハルシネーションの低減、システムプロンプトへの対応、価格の引き下げ、外部APIとの連携機能(ベータ版) など
	- https://claude.ai/　でお試し可能
- ChatGPTで部屋の片づけをしている人がいいる
	- https://x.com/fjtn_c/status/1727216371711586402?s=20
	- （部屋の写真送って片付けタスクを分解してもらって、それを実行して写真撮ってまた進捗を送る→同じことを繰り返し）
- 愛新覚羅の孫（大井町の眼科医）の驚愕エピソード
	- https://x.com/aishinkakura_i/status/1727477535234248712?s=20
	- 学会でアメリカを訪れた際、イミグレーションで「清朝の子孫か」って尋問を受け、しばらく足を止められ…
- metaから、Getting started  with Llama
	- https://ai.meta.com/llama/get-started/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama2&utm_content=image
-  単行本が入るClaude 200kで僕と「エヴァンゲリオン」
	- https://note.com/shoty/n/n03bff29f683f
	- 日本語だと150ページいかないくらいが調理できるのではないかと思う。つまり**単行本一冊が入ってしまう**
	- エバンゲリオンの物語をシミュレートできるかという挑戦らしい
- 【DSにKaggleが必ずしも必要ではない話】
	- https://x.com/Nurruttan/status/1727495591905858016?s=20
	- データサイエンティストと言っても、 「①データアナリスト型」 「④データエンジニア型」 のキャリアプランではKaggle実績の重要性は低い
	-  一方で、 「②サービスグロース型」 「③製品開発型」 「⑤AI開発型」 は重要度は高い。
- Google BardでYoutubeとチャットできるように
	- https://bard.google.com/chat
-  「Paper Interpreter」を使って論文を読もう！
	- https://note.com/daichi_konno/n/nb1f1ac368a30
	- 東大の、紺野大地先生作成
	- **「論文をアップロードするだけで、内容を日本語で分かりやすく説明してくれるAI」**
- アルトマン氏電撃解任劇の裏に、OpenAIが、AGIを開発するめどがついたからという
	- Q*-learningという手法により、数値計算などLLMが苦手としていた課題も解けるようになった。
	- https://x.com/hbouammar/status/1727683545852768295?s=20
	- A*ってのは探索のアルゴリズムだけど、それのQ-learning版という話
- Intel謹製の、LLMが、リーダーボードで上位の性能をはじき出す
	- https://x.com/Yampeleg/status/1727679553714217421?s=20
	- https://huggingface.co/Intel/neural-chat-7b-v3-1
	- A 7B model from Intel almost as capable as Falcon 180B:これは本当か！！！
	- Base model: Mistral 7B. 
	- Fine Tuned on: SlimOrca 
	- DPO: LLaMA-13B vs ChatGPT Gens (Prefer ChatGPT)
- An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
	- ３D世界の中で身体性をもった汎用エージェント
	- 3D世界に対して、いわば記号接地するような訓練をすることで身体性(embodiment)を取得、自然言語処理、コンピュータビジョン、ロボティクスなどの多様なドメインで汎用的なタスクを解決できる汎用エージェントが構築できたという
	- 手段としては、3D世界の理解と相互作用を必要とする、オブジェクトレベルとシーンレベルの多モーダルなタスクを含む、規模と複雑さに優れたデータセットを慎重に作成
-  大規模言語モデル(LLM)をLoRAで強化する際に役立つ情報を研究者が公開
	- https://gigazine.net/news/20231123-llm-lora/
	- LoRAは画像生成モデルや大規模言語モデル(LLM)に追加の情報を学習させてモデルを微調整できる仕組
	- **◆LoRAの効果には一貫性がある**
	- **◆QLoRAを使えば追加学習時のVRAM使用量を大幅に節約可能**
	- **◆最適化アルゴリズムはAdamでもSGDでも大差ない**
	- **◆LoRAによる追加学習を繰り返すと性能が低下する**
	- **◆LoRAによる追加学習は単一のGPUで実行可能**
- Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall
	- Claude2.1の長コンテキスト能力に対する、ストレステスト
	- https://x.com/GregKamradt/status/1727018183608193393?s=20
	- 200K トークン (約 470 ページ) で、Claude 2.1 はドキュメントの一部の深さで事実を思い出すことができました。 
	- 文書の一番上と一番下にある事実はほぼ 100% の精度で再現されました 
	- 文書の上部にある事実は下部よりも低いパフォーマンスでリコールされました (GPT-4 と同様) 
	- ~90,000 トークン以降、ドキュメントの下部にあるリコールのパフォーマンスがますます悪化し始めました 
	- コンテキスト長が短い場合のパフォーマンスは保証されませんでした
- Why do tree-based models still outperform deep learning on typical tabular data?
	- https://hal.science/hal-03723551
	- Why do tree-based models still outperform deep learning on tabular data?” confirms tree-based models outperform deep learning and explain some of the reasons why.
	- When it comes to #tabulardata and #timeseries (by far the most important majority of data for almost any real company), deep learning is not one needs. 
- Pythonによるフェーズフィールド法入門: 基礎理論からデータ同化の実装まで
	- https://www.amazon.co.jp/dp/4621308882?_encoding=UTF8&psc=1&ref_=cm_sw_r_tw_ud_dp_RW79QAZKZRQ7K9N885XB
	- フェーズフィールド法においても,実験データを活用して物性値やパラメータを推定しつつ,シミュレーション精度を高められるような,データ同化と融合した手法の開発が進んでいる.そこで本書でも,データ同化の基礎からフェーズフィールドモデルへの実装方法まであわせて紹介する.
	- フェーズフィールド法では、秩序変数の拡散方程式と反応方程式を同時に解くことで、組織形成過程を計算します。拡散方程式は、秩序変数が拡散する際の挙動を記述する方程式です。反応方程式は、相の変化を記述する方程式です。
	- フェーズフィールド法は、金属の凝固、多結晶粒成長、拡散相変態など、さまざまな材料組織形成過程の計算に用いられています。また、応力場や電磁場における組織形成やナノスケールにおけるモデル化など、マルチスケール・マルチフィジックスを対象とした種々の工学分野にも応用されています。
- 「マスターアルゴリズム」の著者、Domingos氏、Q*-learningの効果をみて、人類の終焉を叫ぶ
	- https://x.com/pmddomingos/status/1727562239060656339?s=20
	- Q* can solve simple math problems that symbolic AI could solve 50 years ago. Panic! AGI is here! Humanity is over!
- A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases
	- https://arxiv.org/abs/2311.07509
	- impact of KGs for question answering on SQL databases: 54% accuracy vs. 16% with instructions directly on SQL databases.
	- SQL DBを参照して質問応答を行うシステムでは、LLMに直接SQLを参照させると16%の正解率しか出なかったがLLMをナレッジグラフにマッピングしてそれを参照させると54%に改善したという研究。
	- 本質的に持っている情報が同じでもデータ構造によってRAGの精度が変わることの一例ともみなせる
- うみゆき氏、Claude2.1の性能に舌を巻く
	- https://x.com/umiyuki_ai/status/1727875985167790529?s=20
	- Claude無料版試してみたけど、結構長文の日本語pdf入力して要約してってお願いしたら、ちゃんと内容読んで要約箇条書き出してくれた（目次丸写しではない）　３章の内容説明してって言ったらちゃんと説明してくれた。つまりちゃんと最後まで読んで答えてる。かなり的確な応答を返してくれる。それでタダ。これ相当スゴイね
- Yuhan Sun et al., "To be or not to be? an exploration of continuously controllable prompt engineering"
	- https://arxiv.org/abs/2311.09773
	- これまで「LLMの動きを観察して"プロンプトを調節"する」手法が追究されてきましたが、限界があるため「プロンプトによる"LLMの動きをダイレクトに調整"する」手法『ControlPE』
	- 自動運転システムなどを手掛けるセンスタイム社による
	- ControlPEは競合技術と比較してもプロンプトの影響をこまかく調整できる手法
	- ① LoRAを利用するアプローチ ② プロンプトの影響を連続的に微調整 ③ 従来のプロンプトエンジニアリングを補完する
- Q*のもともとのアイデアを出した論文著者が自論文を宣伝
	- https://x.com/McaleerStephen/status/1727524295377596645?s=20
	-  A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks
	- https://arxiv.org/abs/2102.04518
- Q*について著名なデータサイエンティストErnest Okumuraさんのコメント
	- https://x.com/pacocat/status/1728052432016470281?s=20
	- Q*がQ-learningから来ているかは知らないけれども、制作者にとって好ましい出力を得るために方策空間を探索する技術は今後さらに求められていくと思うし、RLHFみたいな分かりやすいアラインメントを超えてAGIみたいな文脈でも野心的な試みは増えてくるんじゃないでしょうか。
- Sparse Transformers：入力シーケンスの長さによる計算量増加問題への革新的なアプローチ
	- https://ai-scholar.tech/articles/transformer/sparseTransformer
	- Attentionのレイヤー毎の特徴を再現することで，計算量の削減を達成  
	- Sliding Window Attenion、Dilated Sliding Window Attention、Global Attentionという3つのAttentionを使ってTransformernの計算量を削減した  
	- 計算量を削減しただけではなくて，当時のSOTAを達成している．
-  Llemma: An Open Language Model For Mathematics
	- https://arxiv.org/abs/2310.10631
	- どうも、LLMをつかって、定理証明器をつかうpythonコードを生成するらしい。実際に説くのはpythonインタープリター＋定理証明器の組み合わせ。
	- The AlgebraicStack dataset of 11B tokensが提供される
	- Llema can solve mathematical problems using a Python interpreter and a formal theorem prover.
- LlamaIndex vs. OpenAI Assistants API
	-  RAG Evaluation Series: Validating the RAG Performance of OpenAI vs LlamaIndex
	- https://www.tonic.ai/blog/rag-evaluation-series-validating-rag-performance-openai-vs-llamaindex
- ChatGPTアプリの音声会話が無料ユーザーにも開放
	- https://x.com/IELTS_expert/status/1728326991676670222?s=20
	- 英語学習ソフトや有料レッスンが不要に
- JARVIS-1は本当はすごい、
	- https://x.com/ai_database/status/1728257353852797143?s=20
	- マインクラフト（広大なバーチャル世界で採掘や建設を行うゲーム）を上手にプレイするAI『JARVIS-1』が開発されました。 非常に複雑な動作を含む200種類以上の行動が可能とのこと。
	-  このような技術を応用すると、ロボットが現実世界でもさまざまな重要タスクを達成できるようになる可能性があります。…
- 最終的にすべての統計はベイズに行き着くしかないと思っています（統計数理研究所、鎌谷氏）
	- https://www.ism.ac.jp/ism_info_j/labo/project/162.html
- ルカン先生によるQ*に対する表明
	- https://x.com/ylecun/status/1728126868342145481?s=20
	- 「Q*に関する完全なナンセンスの洪水は無視してね。LLMの信頼性を向上させる主な課題の1つは、自己回帰的トークン予測をプランニングに置き換えることです」
- Macでllama2を試すためのswift-chat
	- https://github.com/huggingface/swift-chat
	- Llama 2 7B chat, running 100% private on Mac, powered by CoreML!
	- Pedro Cuencaさんは現地時間2023年08月08日、Apple Silicon MacなどAppleデバイス上で大規模言語モデル(LLM)を実行するためのSwiftパッケージとDemoアプリを公開
	- SwiftでTransformersライクなAPIを実装するために開発したSwiftパッケージ”swift-transformers”と、Demoアプリ”swift-chat”、加えてTransformersモデルをCoreMLへ変換するコンバーター”transformers-to-coreml”で、
	- CoreMLが役に立ったと、、
- OECD、生成AIや基盤モデルを考慮しつつAIの定義を改定、
	- https://www.euractiv.com/section/artificial-intelligence/news/oecd-updates-definition-of-artificial-intelligence-to-inform-eus-ai-act/
	- 欧州AI法などの他の規制との整合性も考慮したアライメントととった
	- 目標を人間が定義する必要があるという事実への言及を削除、
	- 「出力の生成方法を推測する」という文言も、AI モデルが環境から入力を受け取り、1 つ以上のアルゴリズムを通じて適切な出力を思いつくときを説明するために導入

## 11/20

今週は、OpenAIのCEOアルトマン氏の電撃解任が全てを持って行った。先週OpenAI dev dayで雄姿を、そして人類の未来を垣間見たのに。。ボードから復帰の要請もあるというし、まだまだ現在進行形。さて、RAGもembeddingをつかった類似検索よりも構造を加味した検索とか、多様性をもつ検索結果の利用とか、だんだん、推薦技術などで確立されたノウハウが活用され始めた。LlamaIndexの新機能、text-to-SQL+semanticってのがいいね。LLMのファインチューニング関係もにぎやか、単に論理ソルバーを外部にもってて、自然言語からソルバーに渡す論理式を生成するよりも、ソルバーのログをそのままファインチューニングに使って、解く行為そのものを模擬するというLoGiPTとか、結晶構造をシンプルなテキストで表現しLLaMA-2をファインチューニングして、VAEを上回ったという事例とかがある。そもそもですわね、新しいOpenAIのファインチューニング、200個程度のデータでも、お嬢様LLMぐらいはできるみたいでございますです。LLMはそのメタな能力も重要な要素。プロンプトエンジニアを作るメタなプロンプトをつくったり、ユーザーのプロンプトをLLMが理解やすいように書き換えるプロンプトとか、こっち方面のメタな世界もいい感じで発展している。（ちょっと視点を変えた）ファインチューニングとLLMのメタ能力を利用するのがLLM活用の次のステージか。create-llamaとか、OpenGPTとか、LLMA Factoryと、自動的にアプリを作る仕組みがたくさん出てきた。 わずか1分で10日間の天気を予測可能なAI「GraphCast」、お茶の水大学の神山先生の解説が、従来の手法が不得意なところにGraph transformerがぴったり合ったというところが腹落ちします。Microsoftの発表したCopilot、つまりGPTsのＭＳ版。こういう世界観になるよな。早速OpenCopilotとか、WebCoPilotとか、あっというまに、似たようなOSSが、、、。Yahoo知恵袋、ついにGPT-4をつかった自動回答をテスト中。人の衆知はChatGPTに敗れたのか。。ＭＣ業の紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される、ＭＣ業もＡＩに代替される？されない？まあ、ChatGPTで仕事がなくなったのは、ChatGPTのCEOも例外ではないというのはブラックジョークかも。

- Adding Structure-Aware Retrieval to GenAI Stack
	- https://medium.com/@yu-joshua/adding-structure-aware-retrieval-to-genai-stack-373976de14d6
	- 単なるembeddingをつかった類似検索のRAGではなくて、構造を抽出したうえでの、RAGっての有効であることを、neo4j+LangChainの実例で示した良例
	- This stack is (1) fully local, (2) uses advanced retrieval methods that encode relationships between different chunks of texts
- LlamaIndex によるOpenAIの新機能を使用・理解するためのガイド by npakaさん
	- https://note.com/npaka/n/n728fdb8f76da?sub_rt=share_sb
	- Parallel Function Calling、Assistant API Agent、Function Callingによる高度なRAG、マルチモーダルRAG
	- GPT Builder、プロンプトを自動性生成することで、GPTを生成するmetaなツール
	- 「text-to-SQL と semantic search のジョイント」なんかは興味深い
- 日本の女性が先進国の中で長命なのは、社会進出が進まなかったから？
	- 旭リサーチ
	- https://arc.asahi-kasei.co.jp/report/arc_report/pdf/rs-824.pdf
	- 「先進国の中では女性の社会進出が進まなかったことが、 世界一の女性長寿に結びついたと思われる。」 
	- 「均等法は女性の平均寿命を短縮させる要因である。」
- gpt-3.5-turbo-1106を使った、新しいOpenAIのファインチューニング
	- https://x.com/matsu_vr/status/1723688378795958670?s=20
	- でお嬢様チューニングしてみました。200例の会話で十分お嬢様になった！
- Boosting RAG: Picking the Best Embedding & Reranker models
	- https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
	- RAGをやるにあたってどれを使えばよいかを調べたブログ。OpenAI ChatGPTやGoogle PaLMなどで作った embeddings と BAAI 等が提供している reranker で、どの組み合わせが精度が良いか
- OpenAI Dev dayを受けた、llamaindexのハイレベルAPIのアプデまとめ
	- https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p
	- 大変だー
-  Prompt Engineering a Prompt Engineer
	- https://huggingface.co/papers/2311.05661
	- プロンプトエンジニアを作るメタなプロンプトを作るという話、LLMってメタ能力があるので、こういう試みが可能。CoT越えというのは本当か？
- ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』
	- https://aiboom.net/archives/51160
	- 例えば「GPT-4で言い換えてGPT-3.5で入力する」も有効とのことです。 実行テンプレートや性能等を詳しく紹介する記事を公開しました
-  Language Models can be Logical Solvers
	- https://huggingface.co/papers/2311.06158
	- 従来SOTAは、solver-augmented language modelsをつかって、自然言語からシンボリックなロジックを取り出して、外部ソルバーで説いていたが、、文法があってないとかそういう下らないエラーに悩まされてきた
	- LoGiPTは、直接論理的な導出をエミュレートする、既存ソルバーのログをデータセットとして、ファインチューニングした。問題は解決された
	- https://x.com/IntuitMachine/status/1724104506185580589?s=20
-  JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models
	- https://arxiv.org/abs/2311.05997
	- JARVISって確か、アイアンマンのサポートAIの名前では？？
- 人間の情報処理にとって「ちょうどいい塩梅」の速度を超えとる気がする by 谷チュー
	- https://x.com/rmaruy/status/1724044250286108818?s=20
	- Buonomano『脳と時間』によれば、脳には単一のクロックはない（多重時計原理）。が、進化の過程で生物が相手にしてきた時間スケールより大幅に速い情報処理はできないだろう。一方、情報の「量」に関してはまだ工夫できるかもしれない。
- DPOでcalm2の物語生成能力を向上させる試み、
	- https://x.com/_oshizo_/status/1724039980463657130?s=20
- リアルタイムでLLMが文字を生成する様子のデモ、
	- https://x.com/dylfreed/status/1723927399857901724?s=20
	- llamacppをつかって8GB RAM MacBook Airで動くんだとさ
- LLMって結局何かをシンプルに説明する
	- https://x.com/davidad/status/1723990400682148124?s=20
	- ディープ ニューラル ネットワークは、各層間に要素ごとの非線形性を持つ線形回帰のサンドイッチ構造です。LLM/GPT の爆発的な増加に直接つながった「Attending is All You Need」の核となる貢献、そこに *ロジスティック* 回帰を非線形層に投げ込むことですまた、ドロップアウトについては@geoffreyhinton 、活性化正規化については@ChrSzegedy 、および勾配正規化については@dpkingmaによるものです (Adam)。
- ローカルLLMを動かすPCを自作
	- https://note.com/ai_meg/n/n8855a8dd4bbd?sub_rt=share_pb
	- マザーボード：Asrok　B760 PRO RS/DS  
	- CPU：i5-13400F  
	- GPU:PALIT　GFORCE-RTX4060ti-16G
- RETOOLのState of AIレポート
	- https://retool.com/reports/state-of-ai-2023
	- 66% of companies have at least one AI use case live
	- Accuracy is #1 concern
	- RAG is 2nd most popular use case (1st is code)
	- @llama_index is one of the leading frameworks for enterprises 
- OpenGPTはどんどん進化する
	- https://github.com/langchain-ai/opengpts
-  The Alignment Handbook
	- https://github.com/huggingface/alignment-handbook
	- Robust recipes to align language models with human and AI preferences
- EditGPT
	- https://chat.openai.com/g/g-zpuYfzV7k-editgpt
	- Grammeryのような機能を持つGPTsが、、
- 岡野原さんの、「拡散モデル」が今年度の大川出版賞に選出
	- https://hillbig.github.io/diffusion-models/
	- http://www.okawa-foundation.or.jp/activities/publications_prize/list.html
- これは衝撃!1.5Bで超高性能LLM!RWKV-5-World-v2 by shi3zさん
	- https://note.com/shi3zblog/n/nfc8dd1abf494?sub_rt=share_pb
	- まだ生きてたのか、RWKV
- The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4
	- https://arxiv.org/abs/2311.07361
	- Evaluates GPT-4’s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilitie
	- MSからの論文、製薬とかの話が多いが、なんかつまらん
- Open AI主任科学者のIlya Sutskever氏は昨日のインタビューにて、AGIにたどり着くためにはTransformerアーキテクチャ＋αで「明らかに」問題ないと
	- https://www.youtube.com/watch?v=Ft0gTO2K85A
- 大規模言語モデルのFine-tuningによるドメイン知識獲得の検討
	- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/
	- 英語で主に学習されたLLaMA2に対して日本語データを用いたInstruciton Tuningや追加事前学習がどの程度可能かの検証
	- 不可思議な結果が出がちなので、いろんな設定で試さないといけないことがわかった
- LangChainから、Query Construction Guide、text-to-SQL+semantic最強節
	- https://blog.langchain.dev/query-construction/
	- 1. Structure+unstructured data:  Text-to-SQL+semantic (w/ PostgresSQL with the Pgvector 
	- 2. Unstructured w/ metadata: Text-to-metadata filters (w/ new docs + a template for self-query retriever)
	- "Text-to-SQL+semantic" is an interesting recent addition to LangChain that extends "Text-to-SQL" w/ semantic queries on an embedding column.
	- そうか、やっぱり text-to-SQL+semantiが最強なのか
- 『Chain of Empathy（共感の連鎖）』
	- Yoon Kyung Lee et al., "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"
	- 心理療法のセオリーを反映したプロンプト手法『Chain of Empathy：CoE』を開発し、その性能を検証
-  Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
	- https://openreview.net/forum?id=0r5DE2ZSwJ
	- 言語モデルによる結晶構造予測
	- 結晶構造をシンプルなテキストで表現しLLaMA-2を微調整することで、VAEの従来手法よりも安定な結晶構造を生成できた
	- この手の手法はモデル構築にお金と時間がかかるところが課題
- create-llama, a command line tool to generate LlamaIndex apps
	- https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191
	- コマンドラインでllamaindexをつかたたアプリを生成する仕組みの公開！！！
- GPT4などが、常識をもっているかどうかのテストデータセットによる評価
	- https://github.com/allenai/everyday-things
	- The LLMs have poor accuracy (54-59%) on commonsense spatial/functional relationships in ParRoT dataset.
	- This suggests the LMs do not have fully coherent conceptual pictures of everyday objects.
- LLMA Factory
	- https://github.com/hiyouga/LLaMA-Factory
	- Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- WebPilot
	- https://chat.openai.com/g/g-pNWGgUYqS-webpilot
	- 記事や論文、PDF などの抽出系の便利 GPTs を作ったけれど、すべて WebPilot で十分だった(めこめこさん)
- beさん、毎日ベルマン方程式を解いて日常を過ごしていると、
	- https://x.com/behemuhemulove/status/1724408454348194303?s=20
- 【HELP ME】Assistants APIで破産しそうになった話
	- https://note.com/nike_cha_n/n/n65a6101d59d7
	- ちゃんと計算しないとあっという間に上限に達するかも、
- Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion
	- https://arxiv.org/abs/2311.06318
	- MSより
	- Microsoft Research presents a method to personalize LLMs for search via entity-based user knowledge stores derived from logs.
- Yahoo知恵袋、GPT-4を用いた、自動回答をテスト中
	- https://chiebukuro.yahoo.co.jp/topic/ai/answer.html
	- 人知は不要になったのか。。
-  Trusted Source Alignment in Large Language Models
	- https://huggingface.co/papers/2311.06697
- GPT paper asistantのソース
	- https://github.com/tatsu-lab/gpt_paper_assistant
	- スタンフォード大学の橋本先生謹製
- Licheng Wen et al., "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving"
	- https://arxiv.org/abs/2311.05332
	- 視覚を手にしたLLMが自動運転にどれほど役立つのかを探るため、GPT-4Vの能力が検証されました。 
	- さまざまなタスクで実験したところ、「因果関係の推論」や「シーン（景色）の理解」に長けていると結論づけられました。
- うるさいやつ、技術を理解しないと、ビジネス展開のきっかけが出てこない、エンジニアを蔑視して、それを商売にしているのが嫌い。
	- https://x.com/toukatsujin/status/1724196831109017964?s=20
	- 「技術力を磨かないと生き残れないと思っているエンジニアがほとんど。でも技術は日々進化・変化しており、これを学べば一生安泰ということはない。むしろビジネス理解力を磨いたほうが一生安泰なのに、エンジニアの多くは分かっていない」
- Rapidly build an application in Gradio power by a Generative AI Agent
	- https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent?hl=en
	- Gradio の作者の初めての論文といううわさも
- ChatGPTとDeepLの字幕翻訳の比較
	- https://x.com/gijigae/status/1724345403234193540?s=20
	- ChatGPTは、①英語字幕を繋ぎ直す ②日本語に訳す ③訳したテキストを自然な流れになるように分け、元のタイムスタンプへ戻す といった一連の作業を全部やってくれる。
- GPTsとAsistant APIの違い
	- https://x.com/gijigae/status/1724428173905989945?s=20
	- GPTsとAssistants APIはカスタマイズしたChatGPTが作れる点で似ている。ただ、ChatGPT Plusへの加入やステート管理を含め、違いも多い↓。忙しくて一つしか試せないという方には後者をお勧めしたい。特に、カスタマイズしたChatGPTを生徒に公開する際、ChatGPT Plusへの加入が不要となるのは大きい。
- 「表象（representation）」概念を分析するRPPFプロジェクト
	- 神経科学などで多用されるが曖昧で問題含みの「表象（representation）」概念を、20～30名の哲学者と神経科学者で分析する「Representation: Past, Present and Future (RPPF) project」
	- https://www.thetransmitter.org/representation/what-are-we-talking-about-clarifying-the-fuzzy-concept-of-representation-in-neuroscience-and-beyond/
- コード生成・補完に特化した日本語LLM「ELYZA-japanese-CodeLlama-7b」を公開しました（商用利用可）
	- https://note.com/elyza/n/n5bce23d7c9c8
	- https://zenn.dev/elyza/articles/fcbf103e0a05b1
- わずか1分で10日間の天気を予測可能なAI「GraphCast」をGoogle DeepMindが発表、スパコンで数時間かけた予測より高精度
	- https://gigazine.net/news/20231115-google-graphcast-global-weather-forecasting/
	- https://github.com/google-deepmind/graphcast
- RAG over Governments Document
	- https://github.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Chatting%20with%20your%20Docs.ipynb
- GGUF 版の 5 bit 量子化された Llama 2 を WasmEdge で。7B が 24 token / sec で動作しました↓
	- https://www.secondstate.io/articles/fast-llm-inference/
	- Mac ユーザは見たらとりあえず試して。コマンド４行叩くだけなので！Rust x Wasm で Llama 2 推論がローカルで動きます
- ELYZA-japanese-CodeLlama-7b-instructのggufフォーマット変換版
	- https://huggingface.co/mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf
- マイクロソフトは Copilot Studio を発表
	- Igniteの中で最後に発表、GPTsみたいなものになる
	- 
- お茶大、神山先生による、Googleの気象予測の気象学者からの解題
	- https://x.com/kohyama_met/status/1724986380546408878?s=20
	- 「AI気象予報論文」の感想を投稿したら思いのほか反響が大きかったので、気象学者かつ情報科学科教員として、いくらか真面目に解説します。
	- アーキテクチャが従来型モデルの不得手にうまくハマっている
- Research Assistantのテンプレートが公開される
	- https://github.com/langchain-ai/langchain/tree/master/templates/research-assistant
	- With this template you can easily plug in an arbitrary retriever, allowing you to do research over a knowledge base of your choice.
- 東大 松尾研のPRML（パターン認識と機械学習）輪読会スライド集
	- https://www.slideshare.net/matsuolab/
	- 黄色い本はやっぱり、聖典
- OpenCopilot
	- https://github.com/openchatai/OpenCopilot
- tldrawが洒落にならないぐらい優れている
	- https://makereal.tldraw.com/
	- ラフなUIの図解や説明をつくるだけで、GPT-4Vで認識して良い感じに仕様を解釈して実際に動くモックアップを作ってくれる
- 紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される
	- https://x.com/03sasa03/status/1725479562094755951?s=20
-  OpenAI announces leadership transition
	- https://openai.com/blog/openai-announces-leadership-transition
	- えっ！
	- 「取締役会とのコミュニケーションにおいて一貫して率直さを欠き、取締役会の責任遂行を妨げている」
- OpenAIから追い出された直後の、Sam Altomanのツイート
	- https://x.com/sama/status/1725742088317534446?s=20
	- i love you all.
- 西浦先生の論文に、筑波大の掛谷氏がかみつくも、統計の専門化から返り討ちに
	- https://x.com/behemuhemulove/status/1725749314000175387?s=20
	- 主な問題点 (1) クロスバリデーションの評価なし (2) 短期予想モデルの結果を繋ぎ合わせて長期のシナリオを作っている 明日の天気を高確率で当てるモデルを作っても、その予想を繋ぎ合わせ、、、
	- be氏より、（2）は例えば1年後の予測するとして1ヶ月ずつ予測してくのか、年単位で予測してくか位の違いしかなく、統計学やMLでは全く問題ないと思うので、この点叩いてる方が統計学の観点から無知にみえる
-  create-llama によるLlamaIndexアプリの作成 by npakaさん
	- https://note.com/npaka/n/neafa42455864?sub_rt=share_h
- 体軸が直立した時点が人類が自己を認識した分岐点かもしれない
	- https://x.com/daijapan/status/1725841037086892358?s=20
	- 認知科学講座より、
- Building Research Assistant	
	- https://www.youtube.com/watch?v=DjuXACWYkkU
	- YouTube tutorial on building one from scratch. Covers LCEL, LangSmith, parallelization, retrievers
- Ilya Sutskeverって誰ぞ？
	- https://x.com/mr_bay_area/status/1725808417376473167?s=20
	- 「自然言語処理業界が深層学習一色になる流れを決定づけた人」ですね。それくらい彼が作ったseq2seqは衝撃だったし
- :smile:、:ikanai:
	
## 11/13

今週は、OpenAI Dev Day(11/6)が全てあり、LLM周りの風景が一変した。GPT-4 TurboやAssistant APIや、価格の改定（安くなった）、最後に独自のGPTをつくれるGPT Builderと、OpenAI まわりのOSSエコシステムを破壊するがごときの怒涛のリリース。対応するOSS側のLangChainやllamaindexも新機能の取り込みや対案実装で忙しい週だった。Assistant APIって、**Code Interpreter**、**Retrieval**、**Function Calling**　が呼び出せ、APIからも作れるけども、playgroundからも作って簡単に試せる。Assistant APIに実装された機能(Assistants/Theads/Run )を組み合わせれば、エージェントも簡単に作れる。詳しくはNakajimaさんのGPTvsGPTが良い例。無限に環境問題についてエージェント同士が討論するというデモはちょと地獄絵。早速、LangChainも、LlamaIndexも、Assistant APIをつくってエージェントを作る機能を公開、もともとあるエージェントと組み合わせてみたいな発展も。OpenAI のRetreive機能は、pdfやdocやpptやmarkdown等多彩なデータを読んで、コンテキストとしてChatできる機能。まさに、RAGつぶしなんだけども、llamaindexの人Jerry Liuによると、コンテキスト長の限界を超えると普通のtop-k式の単純なRAGが動いているのではということ。試しにナウシカ(Wikipedia、57kトークン)をGPT-4でやってみたら、確かに性能よかった。RAGについては自ら（ベクトル化の方法などの）細かいチューニングに走るか、それとも入り口だけ用意してあとは、別のOSS等にという戦略のどちらだろう？GPT-4もファインチューニングできるようになったが、$3M(５億円弱)の[Submit]ボタンは押せない。。GPT-4を半端にファインチューニングしても性能は向上しないというのもすごいな。エージェントの作成支援も、llamaindexからbuilder agent、Langchainからも、OpenGTPが発表。OpenAI本家もGPTsで、好みのGPTを作って公開という機能が公開、Plusユーザーなら他人のGPTを使うこともできる。タイムラインに、どんどん、独自のGPTが公開されて、まさに百花繚乱、これに利用料を還流する仕組み整えば、まさにマーケットプレース経済圏に一直線。マルチモーダルのRAGというのも出てきた。PFNのPLaMo-13B-Instructの公開や、日本語向けのベンチマークデータの改定や、shi3zさんによるマルチターン日本語会話データセットの整備など、日本語対応の改良も着実に進んでいる。「アナロジア AIの次に来るもの」のダイソンによると、LLMは、（デジタル・コンピューターによるAIの限界を超えることができる）アナログコンピュータに近いものらしい。ダイソンの本を読みなおすと、AGIの可能性についても、デジタルでは到達できないが、アナログならば可能性は排除できないみたいな主張だった。最後に、ChatGPTの登場は、デザイナやコピーライターの職を奪うだけでなく、単価も下げた、特に高収入の層を、というFTの記事が怖すぎる。

- ALMA-7B-Ja-V2
	- https://huggingface.co/webbigdata/ALMA-7B-Ja-V2
	- 翻訳タスク特化のALMA-jaのV2来とる！!GPTQもある
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT
	- Microsoftから発表されたテーブルタスクのトレーニングデータを用いて「テーブルチューニング」するモデルTable-GPT
	- 多様なテーブルタスクにてGPT-3.5やChatGPTより高性能、高い汎用性を示す
	- https://arxiv.org/abs/2307.08674
- OpenAI dev day
	- GPT-4 Turbo 発表 
	- コンテキスト長128k
	- JSON Mode 
	- ナレッジカットオフ 2023/04
	- DALL E-3 / Text to Speech 
	- Whisper v3 
	- GPT-4 Fine-tuning可能に
	- GPT-3.5 Turbo はもう 16K がデフォレベルでさらに安くなり、GPT-4 Turbo は価格が入力 1/3, 出力 1/2 になった
	- 「従来の16倍となる300ページを超える長い文書を扱えるようになり、2023年4月までの情報を反映」
	- functionsとfunction_callが非推奨になってtoolsとtool_choiceになったんだ
- ノーコードで「ChatGPT」のカスタム版を作れる「GPTs」、有料会員に提供へ
	- https://www.itmedia.co.jp/news/articles/2311/07/news074.html
	- プロンプトからの指示で対話しながらオリジナルのChatGPTを構築できる。「Web検索や画像作成、データ分析などと同じくらい簡単」としている
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
	- https://huggingface.co/papers/2311.02303
	- MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, CodeFuse-CodeLLama-34B, achieves an impressive pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\%, zero-shot).
- Assistants API の解説と動作確認（Google Colab）
	- https://note.com/schroneko/n/nd04c46242171
- llamaindexから、OpenAI dev dayをうけGPT builderを模擬するBuilder Agentの例を公表
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb
	- https://x.com/jerryjliu0/status/1721639447207583882?s=20
	- 例：「トロントのことをよくわかるエージェントを作成」→エージェントができる。。
- LangChainから、OpenGPTの発表、
	- https://github.com/langchain-ai/opengpts
	- builds upon LangChain, LangServe and LangSmith This gives you more control over the LLM you us
- OpenGTPは、 LangSmithに連携するだけで利用ログが取れるので、あとはエージェントのToolsを充実させれば、それなりのものが提供できる
	- https://x.com/mah_lab/status/1721684588874055764?s=20
- Levels of AGI: Operationalizing Progress on the Path to AGI
	- https://arxiv.org/pdf/2311.02462.pdf
	- DeepMindから、AGIにいたるLevel0からLevel5までの段階を示す、レベル分けのOntologyを提案といっている
	-  AGI by considering generality (either Narrow or General) in tandem with five levels of performance (Emerging, Competent, Expert, Virtuoso, and Superhuman).
-  OpenAI Python API Library v1.0 入門　by npakaさん
	- https://note.com/npaka/n/n27b94df96179?sub_rt=share_sb
	- 「OpenAI Python API Library」のインタフェースが一新された、らしい
- GPT-4のfine-tuningで有効なgainを得ることが3.5-turboより難しい
	- パートナーを選ぶ形でCustom Models programを提供する戦略へ転換か、
	- GPT-4がすごすぎるので、中途半端なファインチューニングはかえって性能を劣化させる。。。。
	- https://openai.com/blog/new-models-and-developer-products-announced-at-devday
- Assistants APIを利用すれば、TOEICやTOEFL、英検、IELTSに特化した家庭教師も一瞬で作れる
	- https://x.com/gijigae/status/1721737796724183504?s=20
	- いままで、OpenAI Plus(3k円/月)で実現していたものが、Assistans APIで、月1,500円程度の半額になるというお話、なるほど
- OpenAI APIのRetrievalた多種ファイルに対応
	- OpenAI API の今回のアップデートに含まれていた Knowledge Retrieval (ファイル内検索を可能にする機能) は PDF はもちろん Word やパワポ、ソースコードも対応してるようだ。 RAG 関連のサービスはホント要らない子になっちゃったね
- OpenAI Assistantsで試しに英語論文を要約するアシスタント作成例
	- 今回新たにAPIが発表されたRetrieval機能を使ってPDFファイル添付をしてみてます。
	- https://x.com/alexweberk/status/1721705504228192373?s=20
	- DPOの論文26ページ分くらいの要約で$0.80くらい
-  GPT-3.5-Turbo / GPT-4-Turbo 1106のJSONモードの使い方 by [shi3z](https://note.com/shi3zblog)さん
	- https://note.com/shi3zblog/n/nd72e0269dc3f?sub_rt=share_pb
- OpenAI DevDay で発表された新モデルと新開発ツール まとめ by  [npaka](https://note.com/npaka)さん
	- https://note.com/npaka/n/n9cd206d96f85?sub_rt=share_sb
	- 「Function Calling」に、単一メッセージから複数のFunction (「車の窓を開けてエアコンをオフにする」など) を呼び出す機能などが追加されました。精度も向上しています
	- 16Kコンテキストウィンドウをサポートする新しい「GPT-3.5 Turbo」もリリースします。指示追従、 JSONモード、並列 Function Callingをサポート
	- 「Assistant API」は、特定の指示を持ち、追加の知識を活用し、モデルやツールを呼び出してタスクを実行できる専用のAIです。
	- アシスタントは、必要に応じて、**Code Interpreter**、**Retrieval**、**Function Calling**を呼び出せる
- Google Colab で OpenAI API の Retrieval を試す by npakaさん
	- https://note.com/npaka/n/ndcacbefb2ef7
	- APIからAssistantを作る方法、結果はplaygroundでも確認できるというか、playgroundでassistant作成の別のやり方
- Putting numbers into a better perspective and classifying them according to their level of complexity
	- https://thinkzone.wlonk.com/Numbers/NumberSets.htm?platform=hootsuite
- GLaMM: Pixel Grounding Large Multimodal Model
	- https://huggingface.co/papers/2311.03356
-  GPT-4VのAPIをサクッと使ってみる！
	- https://note.com/peisuke/n/nef0616b8d7fc?sub_rt=share_sb
	- 早稲田大学の講義のページを使わせてもらいます。制約条件付き最適化の問題を解かす→解ける。
	- "画像の数式の応用例を一つ挙げ、何らかの適当な数値を設定し、それを解くためのプログラムを作成してください"
- Google Colab で OpenAI API の Text-to-Speech を試す by npakaさん
	- https://note.com/npaka/n/nba4af88eb3cf?sub_rt=share_sb
	- 6つの内蔵ボイスが付属しており、次の目的で使用できます。
		- 書かれたブログ投稿のナレーション
		- 複数言語の音声を生成
		- ストリーミングを使用したリアルタイムオーディオ出力
- Bayesian Optimization of Function Networks with Partial Evaluations
	- https://arxiv.org/abs/2311.02146
- Assistance APIについて
	- これまでなら自力 or LangChain でやってきたことが、それなりに Assistants/Theads/Run などでできるようになっちまったぜ
	- OpenAIの [#AIアシスタント](https://twitter.com/hashtag/AI%E3%82%A2%E3%82%B7%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%88?src=hashtag_click) は面白いけど、またお金が飛んでいく
- Assistances APIをつかって、GPTvsGPTを作る例
	- https://x.com/yoheinakajima/status/1721769833212281231?s=20
	- https://github.com/yoheinakajima/GPTvsGPT
	- 例として、地球温暖化テーマに対する、海賊vs人魚の論争をシミュレーション！
- Langchainから、OpenAIの assistance APIのサポートを発表
	- https://github.com/langchain-ai/langchain/blob/master/cookbook/openai_v1_cookbook.ipynb
	- Spin up OpenAI assistants and run them as any other LangChain agent!
	- LangChainのAgentと同じように、OpenAIのagentを使える、らしい
	- OpenAIAssistantRunnable.create_assistan
- Contrastive Error Attribution for Finetuned Language Models
	- https://arxiv.org/abs/2212.10722v2
	- 文書生成においてハルシネーションを引き起こすデータセット内のデータを高精度で特定する手法の提案。
- Tokyo Digital Twinが、
	- https://info.tokyo-digitaltwin.metro.tokyo.lg.jp/
	- 調布市の3次元 [#点群](https://twitter.com/hashtag/%E7%82%B9%E7%BE%A4?src=hashtag_click) をダウンロードしました! さらに独自の手法にて建物・植物・地表面の自動分類を行いました
- GPT-4のファインチューニングには、５億円かかる？？？
	- It costs $2-3 million to train a custom GPT-4 model with your own dataset.
	- https://x.com/tdinh_me/status/1721835213121265840?s=20
	- いや、この「Submit」ボタンは押せない。。。
- GPT4 Turbo はPyllms ベンチマークでGPT4を凌駕
	- https://github.com/kagisearch/pyllms
	- https://aider.chat/docs/benchmarks-1106.html
- CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding
	- https://huggingface.co/papers/2311.03354
- QGIS 3.34で3DTilesが表示できるようになったので、3D都市モデルPLATEAUの3DTilesをQGISで表示してみました
	- https://x.com/shi__works/status/1721808786393121197?s=20
	- https://north-road.com/2023/11/07/qgis-3d-tiles-thanks-to-cesium-ecosystem-grant/
- OpenAI Assistants API(Playground)を使ってコーディングのアドバイスをしてくれるアシスタントを作る
	- https://zenn.dev/karaage0703/articles/66949a39643557
	- 今まででも、Custom InstructionsとAdvanced Data Analysis（Code Interpreter）でできていたことを、手軽に切り替えられて便利になった。API経由でできるようになったということなので、本質的な変化というよりは順当なアップデート
- 自分の癖にあったファインチューニング用データセットをLLMで作ろう！【Calm2】
	- https://zenn.dev/saldra/articles/090c120b49e38c
	- LLMのファインチューニングにおいて、データセットは重要なものとなりつつある
	- 以前までは人力で作る必要があったが、プロンプトが効く7Bモデル（Calm2-chat）を用いることで、LLMでファインチューニング用データセットを作ることができる
	- データセットを作成しつつ、動的にプロンプトを修正していく手法が相当よかった
- HuggingFace Diffusers v0.22.0の新機能 by npakaさん
	- https://note.com/npaka/n/n5aebfc60408a?sub_rt=share_sb
- OpenAI Assistants APIに拙著「エンジニアの知的生産術」を入れて質問。これこそ「書籍を読む方法の効率化」だな感
	- https://x.com/nishio/status/1721857526990586203?s=20
- OpenAIの AIアシスタント に子猫の絵を描いてもらいました
	- https://x.com/itnavi2022/status/1721945299713941944?s=20
- 日本語対応13BモデルのPLaMo-13B、インストラクションチューニングされた
	- 対話性能を向上させた指示学習（instruction tuning）済み大規模言語モデルPLaMo-13B-Instructを公開しました
	- https://tech.preferred.jp/ja/blog/llm-plamo-instruct/
- llamaindexもOpenAIのAssistanceに対応
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb
	- OpenAIのRetrievalとllamaindexのRetrievalを組み合わせることが可能！！！
- OpenAIのRetrieval APIは、コンテキスト長が長い場合、簡易なtokp-k RAGに切り替えている模様
	- The OpenAI retrieval API seems to be doing basic top-k RAG on limited context if there's context overflows.
	- https://x.com/jerryjliu0/status/1721987237771133219?s=20
- GPT-4 Turbo vs GPT-4 tests
	- GPT-4 Turbo has record accuracy (87% vs 52% of GPT-4 on PyLLMs benchmark), it is almost 5x faster with 48 vs 10 tokens/sec). 
	- And it is also 30% cheaper in practice (would be more, but it is 2x wordier in output compared to GPT-4)
	- https://x.com/vladquant/status/1721674365211738269?s=20
-  Google Colab で OpenAI API の Function Calling を試す by npakaさん
	- https://note.com/npaka/n/nc3713dba5df6?sub_rt=share_sb
	- 群馬県の気温を教えてください
-  Re-evaluating Retrosynthesis Algorithms with Syntheseus
	- https://arxiv.org/abs/2310.19796v1
	- 逆合成のベンチマーク論文。
	- 狙いの材料から原料を予測する逆合成予測では各論文で評価方法が異なっていましたが、Microsoftさんらはベンチマークライブラリを構築、これによりモデルのランキングが従来と変わることが分かったそうです。
-  Google Colab で OpenAI API の Code Interpreter を試す by npakaさｎ
	- https://note.com/npaka/n/nb90306341d41?sub_rt=share_sb
- GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベル
	- どうも今回の OpenAI の価格改定で、GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベルまで掛かっているらしく、OSS LLM が普及しないのは結局 OpenAI の API がクソ安すぎるからでは？という指摘
- OpenAI API の Assistant API のしくみ
	- https://note.com/npaka/n/n9fa7204e4af4?sub_rt=share_sb
- mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration
	- https://huggingface.co/papers/2311.04257
- llamaindexより、parallel function callingによる効率化の例
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb
- OpenAI API で提供されている モデル まとめ by npakaさｎ
	- https://note.com/npaka/n/n5d0a76b149f1?sub_rt=share_sb
- 『生成AIのパラドックス』
	- https://aiboom.net/archives/58414
	-  LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説
	- AIが人間のような出力を生成する能力を持ちながら、それを理解する能力は必ずしも伴わないという仮説です（仮説を立てるに至った背景は、前章を参照）。
- Streamlit+GPT4-Vision+TTSで動画ナレーション自動生成ツールをつくった
	- https://zenn.dev/olemi/articles/752d205987cb87
	-  動画からフレーム画像を抽出し、Base64形式に変換する
	- GPT4-Visionに動画のナレーションを生成させる
	- 生成されたテキストから、TTS APIで音声ファイルを生成する
	- Streamlitで、テキストと音声ファイルを表示・ダウンロード可能にする
-  Google Colab で PLaMo-13B-Instruct を試す by npakaさん
	- https://note.com/npaka/n/n97a1ac080f76?sub_rt=share_sb
- 日本語に対応した Embedding Model のベクトル検索での精度比較｜Tatsuya Shirakawa
	- https://github.com/nouu-me/document_vector_search_benchmark
	- 日本語Text Embeddingでのベクトル検索の精度をいろんなモデルで検証してみました。e5良いですね
-  Extracting List of  `Album`  (with Parallel Function Calling)
	- https://docs.llamaindex.ai/en/latest/examples/output_parsing/openai_pydantic_program.html#extracting-list-of-album-with-parallel-function-calling
- 複数のアシスタントに討論させる例
	- https://x.com/npaka123/status/1722761636937900541?s=20
- Zhenjie Yang et al., "A Survey of Large Language Models for Autonomous Driving"
	- LLMが得意とする「計画、認識、質問応答、生成」の能力が自動運転システムに効果的に使えると主張
	- https://arxiv.org/abs/2311.01043
- Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach
	- https://arxiv.org/abs/2209.06995
	- 良質なデータを収集し少量で高い性能を獲得する試み。
	- LLMにプロンプトを与え疑似ラベルを予測、分布が一様で不確実性が高い=学習効果が高いとみなす。
	- ベクトル空間上の距離から周辺も不確実性が高い、かつ採用データ間の距離を空ける。
	- 128サンプルでフル学習の 90% 超の精度。
- A.R.I.A. (Aria) - Your AI Research Assistant
	- https://github.com/lifan0127/ai-research-assistant
-  OpenAI の Assistant Playuground の Function Calling を試す
	- https://note.com/npaka/n/n6bf08e93840d?sub_rt=share_sb
- GPTs 作成第二弾として arXiv Reader を作りました。論文は PDF 入力か URL 手渡しか選べます。
	- https://chat.openai.com/g/g-qrOeOjLX6-arxiv-reader
- Tokenizerの分割を可視化しながらトークン数を数えてくれるページがOpenAIのサイトにある
	- https://platform.openai.com/tokenizer
- GPTsで、Kaggleのチュートリアル第6版を読み込ませてみて、質問してみました。
	- https://chat.openai.com/g/g-Z3a4iOzGR-kagglenotiyutoriarudi-6ban
- 弊社のカスタマーサポートをGPTsで作成してみました。
	- https://chat.openai.com/g/g-uINwYG4Ja-trippy-kasutamasapoto
- LangChainの# OpenAI Assistant、js版
	- https://js.langchain.com/docs/modules/agents/agent_types/openai_assistant
-  Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models
	- https://arxiv.org/abs/2305.17446
	- 事前学習済モデルの転移学習がモデル内の副空間で行われている可能性を示唆した研究。
	- 重みをFlatten しエポックごとスタックして SVD にかけ、 Fine Tuning 中のパラメーター変動を説明する軸を発見。
	- この軸上で外れ値になるパラメーターを無効化し著しい性能劣化を確認
- 山内志朗『小さな倫理学入門』
	- 「人間は欲望を自分で生産できず、他の人からこっそり盗んできます。もしかすると、人間は欲望が欠如していて、それを隠すために欲望まみれの姿を取りたがります。やりたいことが見つからない人の方が圧倒的に多いのです。」
- スタンフォード大のAI研究者Fei-Fei Liさんの新刊”The Worlds I See”は、想像を超える面白さ。強さとしての好奇心。
	- https://www.amazon.com/dp/1250897939?ref_=cm_sw_r_cp_ud_dp_QG23D73KJFT6GCP6GNVP
	- After 3+ years, today is the day that my book “The Worlds I See” gets to see the world itself. It is a science memoir of the intertwining histories of me becoming an #AI scientist, and the making of the modern AI itself. 
- 日本語言語モデルのベンチマークテストが更新
	- 日本語言語モデルのベンチマークテストである Stability-AI/lm-evaluation-harness がアップデートされたため、Youri 7B シリーズのスコアを算出し直しました。 GPTQによる 4bit 量子化モデルのスコアも算出しています。
	- https://rinnakk.github.io/research/benchmarks/lm/
- 生成AIエコシステムについて
	- 生成AIまわりがすごい楽しいのは、技術そのものはもちろん、理論に詳しい人、いち早く実装に落とすのが得意な人、きれいなアーキテクチャーに落とすのが得意な人、面白いプロダクトに仕立てる人の協力関係がバッチリ噛み合ってるみたいなところがすき
	- https://x.com/uezochan/status/1722604877644497292?s=20
- GPT3.5を用いてマルチターン日本語会話データセット(16K)を作りました
	- https://note.com/shi3zblog/n/nfc07c53d61a8?sub_rt=share_b
	- Wikipedia日本版データセット(izumi-lab/wikipedia-ja-20230720)とGPT-3.5-Turboでマルチターン会話データセットを作りました。
-  Google Colab で Japanese Wikipedia Conversation による Llama 2 のLoRAファインチューニングを試す
	- https://note.com/npaka/n/n723766f96cbc?sub_rt=share_sb
	- **<s> [INST]** 日本の首都は？ **[/INST]** 東京です。**</s><s> [INST]** その場所の観光名所を教えて。 **[/INST]** 東京ドームシティ、サンシャイン60（六万分一）があります。 **</s>**
- llamaindexからRAGのベンチマーク
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb
	- OpenAIのRAGが、llamaindexの5行のコードに劣っていると、、、
- LLM OS
	- https://x.com/karpathy/status/1723140519554105733?s=20
	- Specs:
		- LLM: OpenAI GPT-4 Turbo 256 core (batch size) processor @ 20Hz (tok/s)
		- RAM: 128Ktok
		- Filesystem: Ada002
- ChatGPTは、コピーライターやデザイナーの雇用を奪うとともに、単価も下げている
	- 米国の最新研究は、ChatGPTの立ち上げから数カ月で、主要なオンラインフリーランスのコピーライターやデザイナーの仕事の数が大幅に減少し、収入も急激に減ったと報じている
	- https://www.ft.com/content/b2928076-5c52-43e9-8872-08fda2aa2fcf
	- 「6桁稼ぐ人は30000ドルしか稼がない人の3倍ダメージを受ける」
- Pattern Language for Generative AI book!
	- https://x.com/IntuitMachine/status/1722931733866143754?s=20
- ニューラルネットは経験した言語を一般化する能力があるか（１０月２５日 Nature オンライン掲載論文） - Lab BRAINS
	- https://lab-brains.as-1.co.jp/enjoy-learn/2023/11/55788/
- Jochen Wulf and Juerg Meierhofer, "Towards a Taxonomy of Large Language Model based Business Model Transformations"
	- https://arxiv.org/abs/2311.05288
	- LLMを利用したビジネスモデルについて実際のケースをもとに調査報告が発表されました。
		- 「新しい顧客メリットの創造」、「新しい販売チャネルの開拓」、
		- 「ビジネスプロセス自動化の加速」、「情報リソース利用の改善」
-  LlamaIndex の マルチモーダルRAG のしくみ by npakaさん
	- https://note.com/npaka/n/n53e8aabed0f2?sub_rt=share_sb
	- 「GPT-4V API」の導入により、「RAG」の概念をテキスト/画像のハイブリッドに拡張し、さらに大量の(画像を含む) データコーパスから価値を引き出す
	- SimpleDirectoryReaderの画像拡張
	- **MultiModalVectorIndex**の導入
- RAGにおけるドキュメント検索精度向上について(概要編)
	- https://zenn.dev/sompojapan_dx/articles/eb755a18e893ce
	- 損害保険ジャパン株式会社 DX推進部
	- ドキュメントに手を加える
		- **ドキュメント整形/chunking**、**要約生成**、**質問文の拡張**、**Knowledge Graphの活用**
	- 検索モデルに手を加える
		- **検索モデルのfine-tune**、**Re-rankingモデルの活用**
-  PromptNER: Prompt Locating and Typing for Named Entity Recognition
	- https://arxiv.org/abs/2305.17104v1
- 「アナロジア」のジョージ・ダイソンがLLMについて語る
	- https://www.hayakawabooks.com/n/n6b8cf31a9472
	- 大規模言語モデルはいわゆる言語の地図とも言えるものであり、いろいろなAIは、その地図を辿って有用な目的地までデジタル方式のアルゴリズムでナビゲーションをしているだけです。
	- こうした地図はまだ市販の画像処理用チップGPUでシミュレーションされただけのものですが、いずれこうした（言語ばかりかイメージやありとあらゆる事象を重みづけする）巨大なモデル専用のアナログチップが利用されるようになり、徐々に浸透していき現行のシステムに代わっていくと思います。
- 「アナロジア」ジョージ・ダイソンより
	- 連続体仮設はデジタル・コンピューティングも、アナログ・コンピューティングもどちらも無限の力を持つが、それぞれがどれだけ進化しても発揮する力が異なることを示唆している(P292)
	- アナログ・コンピューティングでは複雑性はコードでなくアーキテクチャに宿る。
	- デジタル・コンピュータは硬直化してノイズをに対する耐性を失ってしまった、アナログ・コンピュータである
	- アナログ・コンピュータはノイズを受け入れるばかりか、＜略＞機能するために一定の背景ノイズを必要とさえしている。(P295)
- 人工知能の三つの法則からみるAIの次にくるもの（ダイソン）(P299)
	- 「アシュビーの必要多様性の法則」、実効的な制御システムは対象と同じ程度複雑でなければならない
	- 「複雑なシステムの特徴を規定するのは、それ自身の最も単純な動作の記述だ」（ノイマン）、
	- 「理解可能な単純なシステムは、知的な振る舞いをするには複雑さが足らず、知的な振る舞いができるくらい複雑などんなシステムでも、理解するには複雑すぎる」
	- →自ら思考する人工知能は、人間の知性を理解するまでは、マシンが超人的な知能を持つことを心配する必要はないともいえるが、理解をせずに何かを作っていけないという道理もない。

## 11/6

今週は、RinnaのYouri 7Bの発表(10/31)、Japanese Stable LM Beta 70Bの発表(11/2)、同日CyberAgentLM2-7B（CALM2 -7B）の公開(11/2)等、日本語LLMの発表・公開が相次ぐ。あっという間に4bit 量子化モデルも公開されて手元で試せるように。。。70Bもびっくりするが、特にCalm2は3万2000トークン（日本語で約5万字）に対応していて、RAG不要かも。ColabでもA100ならば動かせるらしい。ソフトバンクのLLM開発始動や、NTTの日本語対応言語モデルのtsuzumiの発表、牧野先生が、MM-core専任？になるとの話題もあり、日本でもLLMのインフラが今後そろってくるのは楽しみ。日本語事前学習済みモデルをSimCSEって、LLM本(大規模言語モデル入門)で紹介されていたやつ。説明可能AIによるペロブスカイト太陽電池開発って、AIに説明させて人間が次を考えるという、AIと人との協調の新しい未来の形。LLM評価のサーベイ論文、後で読もう。 TinyLLaMa、どこまで小さくできるか、こういうアプローチいいなあ、本当に1.1Bでどこまでいける？LLMを利用したFAQ検索の評価データセット作成の工夫とか、LangChainのアプリテンプレートの公開とか、実用面に近い開発も進展あり。npakaさんの、LangChain、LLamaIndexの紹介記事、コンパクトで最新の情報なのでお得。ちょうど日経新聞で紹介された、岩波新書の『言語哲学がはじまる』、フレーゲ、ラッセル、ヴィトゲンシュタイン、もし彼らが今生きていたらLLMをどう研究したのか。XのGrok-1は次週に続くだな。

- FP8-LM: Training FP8 Large Language Model
	- https://arxiv.org/abs/2310.18313
	- Microsoftの研究チームによる論文。
	-  FP8自動混合精度フレームワークで、性能低下を抑えつつ ・BF16よりも64%速く ・メモリ使用量を42%削減し GPT-175Bをトレーニングできた
- ControlLLM: Augment Language Models with Tools by Searching on Graphs
	- https://huggingface.co/papers/2310.17796
	- (1) a task decomposer that breaks down a complex task into clear subtasks with well-defined inputs and outputs; 
	- (2) a Thoughts-on-Graph (ToG) paradigm that searches the optimal solution path on a pre-built tool graph, which specifies the parameter and dependency relations among different tools; and
	-  (3) an execution engine with a rich toolbox that interprets the solution path and runs the tools efficiently on different computational devices.
- ハーバード大学とBCGの研究によるとGPT-4の活用で仕事の精度は40%向上し、スピードも25%早くなったとのこと。この結果を見てもAIの使い方は益々、知的差別化の重要な要素となる。知的さはもはやAIと切り離しが困難な状態。こうした変化についていくためにも最新のAIを使いこなせる努力をしてほしい。
	- https://x.com/gijigae/status/1718851299524096284?s=20
- ChatGPT のアプリ版に Retrieval Augmented Generation (RAG)機能が追加？
	- https://x.com/yi_ding/status/1719028284548382901?s=20
- シリコンバレー銀行の破綻を、シンプルに解析するnotebookが公開。スタンフォード大学Professor Ashwin Raoによる
	- https://colab.research.google.com/drive/15uxrAeCCL327kWH9N0X-ogKwf2zErjP5
- Microsoft うっかりgpt-3.5が20b相当だと漏らす、
	- CodeFusion: A Pre-trained Diffusion Model for Code Generation
	- https://arxiv.org/abs/2310.17680
	- Microsoft paper claims ChatGPT 3.5 has ~20 billion parameters
- BlokeニキがStability AI Japan のモデルを4bit量子化
	- https://huggingface.co/TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ
- rinnaはLlama 2の日本語継続事前学習モデル「Youri 7B」シリーズを公開しました。 
	- https://rinna.co.jp/news/2023/10/20231031.html
	- ①Youri 7B：日英40Bトークンで継続事前学習 
	- ②Youri 7B Instruction：高いベンチマークスコア 
	- ③Youri 7B Chat：複数ターンの対話に強い 
	- GPTQ 4bit 量子化モデルも公開しています。
-  Google Colab で Youri-7B を試す by npakaさん
	- https://note.com/npaka/n/nccadcbcfe37e?sub_rt=share_sb
	- 複数ターンの対話モデル (GPTQ版)である「rinna/youri-7b-chat-gptq」を使います
- 多様な日本語事前学習済みモデルをSimCSEで文埋め込みモデルにfine-tuning
	- https://arxiv.org/abs/2310.19349
	- かなりいい感じの文埋め込みモデルができたと思うので、ぜひお使いください...！！
	- https://github.com/hppRC/simple-simcse-ja
- Youri 7B InstructionのGPTQモデルつかえば、GPUメモリ8GBでもローカルでLLM翻訳ができそうな気配
	- https://x.com/kis/status/1719284609761108462?s=20
- ソフトバンク、 国産大規模言語モデル（LLM）の開発を本格開始
	- https://www.softbank.jp/corp/news/press/sbkk/2023/20231031_01/
	- 2024年内に3,500億パラメーターの国産LLMの構築を目指します
-  Evaluating Large Language Models: A Comprehensive Survey
	- https://arxiv.org/abs/2310.19736
	- A comprehensive survey (100+ pages) on evaluating LLMs. 
	- ■「知識と能力」の評価 
		- ① タスク中心の評価から能力中心の評価へと移行している 
		- ② 評価ベンチマークはますます拡張されている
		- ③ ダウンストリームタスク間の区別があいまい 
		- ④ モデルの能力を総合的に評価する新しいアプローチが必要 
	- ■アライメント（ガイドライン）の評価 
		- ① 人間の価値観との一致を評価する研究が増えている 
		- ② 倫理的な面も含めたモデルの進歩と応用が目指されている 
	- ■安全性の評価 
		- ① LLMの発展によるリスクに厳格な評価が必要 
		- ② 例えばバイアスの増幅、誤情報の拡散、プライバシーの侵害など 
		- ③ リスク評価と、対処アプローチが求められている 
	- ■特化型LLMの評価 
		- ① 特定ドメインやタスクに特化したLLMも存在 
		- ② 特化型モデルの評価には専門的アプローチが必要 
		- ③ 高度な知識や専門的な推論能力を持つモデルが期待されている
- LanChainから、様々なタスクにアプリテンプレが公開
	- https://blog.langchain.dev/langserve-hub/
	- LangChain Templates offers a collection of easily deployable reference architectures that anyone can use.
	- https://github.com/langchain-ai/langchain/tree/master/templates
- LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery
	- https://huggingface.co/papers/2310.18356
	- LoRAShear meticulously studies and proposes a dynamic fine-tuning schemes with dynamic data adaptors to effectively narrow down the performance gap to the full models.
- gguf版、japanese-stablelm-instruct-gamma-7b　実用 API サーバ・クライアント例
	- https://note.com/ai_meg/n/n0c449a877c6f?sub_rt=share_pb
	- 会話ログ、requestボディ-簡略化のためのデフォルト設定。llm()への生成時パラメータ追加など。
- Youri 7BをFastChatでChatGPT互換APIサーバとして動かして遊ぶ
	- https://qiita.com/takaaki_inada/items/fcb63da369b5bfd8a3cf?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- youri-7b-chatをfastchatでChatGPT互換APIでホストしてChatVRMでサクッと遊ぼう。prompt engineeringが効くのでsystem prompt設定画面で語尾やキャラクター設定できます
- Google Colab で Japanese Stable LM Beta 7B を試す by npakaさん
	- https://note.com/npaka/n/n49387d8a8af4?sub_rt=share_sb
	- 語彙拡張済み指示モデル「stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b 」を使います
- Generative AI for everyone	by Andrew Ng先生
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- Google Colabに、API keyを登録できる新機能が公開
	- https://x.com/GoogleColab/status/1719798406195867814?s=20
- 説明可能AIによるペロブスカイト太陽電池開発
	-  Discovering Process Dynamics for Scalable Perovskite Solar Cell Manufacturing with Explainable AI
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202307160
	- 成膜過程の動画やスペクトルデータからNNにより変換効率を予測、それに基づき解釈する手法を適用することで、プロセスと特性の新しい洞察につながったそうです。
- Efficient LLM inference on CPUs! 
	- https://huggingface.co/papers/2311.00502
	- NeurIPS'23の論文
	- Compatible with GGML yet better performance up to 1.5x over llama.cpp!
	- https://github.com/intel/intel-extension-for-transformers
- The Computational Lens: from Quantum Physics to Neuroscience
	- 計算機的な視点を用いて、量子物理学から神経科学に至るまでの分野を研究したハーバード大学の博士論文
	- https://arxiv.org/abs/2310.20539
- Japanese TinyLLaMa 1.1 B, llama.cpp で wasm でブラウザでも動く
	- https://github.com/lighttransport/japanese-normalizer-cpp
	- https://x.com/syoyo/status/1719646103891845438?s=20
-  LLMを利用したFAQ検索の評価データセットの作成〜その２〜
	- https://www.ai-shift.co.jp/techblog/3761
	- 「1.  FAQの回答内容から質問内容を抽出」をベースに、生成時のpromptの工夫について取り組んだ
- calm2で議事録をまとめてみました。AI時代の知的財産権検討会（第１回）
	- https://x.com/alfredplpl/status/1720005676829970472?s=20
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/kaisai/index.html
	- 主張1: AIによって生成されたコンテンツも含まれるべきである。 
	- 主張2: AIによって生成されたコンテンツは、人間によって創作されたコンテンツと同等に保護されるべきである。 
	- 主張3: 著作権を侵害する行為には、AIによって生成されたコンテンツも含まれるべきである。 
	- 主張4: 収益還元法については、AIによって生成されたコンテンツも適用範囲に含まれるべきである。
-  Google Colab で CALM2 を試す by npakaさん
	- https://note.com/npaka/n/n443e3ea8d0b8?sub_rt=share_sb
	- チャットモデル「cyberagent/calm2-7b-chat」を使います。
- CALM2-7B-chatのSpaceを作りました
	- https://huggingface.co/spaces/hayas/CALM2-7B-chat
- llamaとllama2の違い by NTT 西田さん
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
- 日本語DeBERTaV2モデルを公開しました！
	- 形態素解析器の事前の単語分割なしで使えるbase, smallモデルになっています
	- https://huggingface.co/izumi-lab/deberta-v2-base-japanese
- なんと、japanese-stablelm-instruct-beta-70B-GGUF
	- TheBloke/japanese-stablelm-instruct-beta-70B-GGUF
	- ggufのくせに40Gもあるよ、まったく
- OpenChat3.5
	- https://huggingface.co/openchat/openchat_3.5
	- gpt-3.5に迫る？？
- マルチモーダルのKOSMOS-2を取り込んだtransformerの更新！ by huggingface
	- KOSMOSのでもはこちら
		- https://huggingface.co/spaces/ydshieh/Kosmos-2
- Text generation web UIをつかって、cyberagent_calm2-7b-chat
	- https://x.com/StelsRay/status/1720137767857029444?s=20
	- モデルのLoad時にuse_fastがONじゃないと動かない点が罠だった！
-  LangChain クイックスタートガイド - Python版　 by npakaさん
	- https://note.com/npaka/n/n0fd7bd3ed27b?sub_rt=share_sb
	- 11/4版なので、整理されているし、「**LCEL**」(LangChain Expression Language)なんかよく分かった
- Idempotent Generative Network
	- https://assafshocher.github.io/IGN/
	- 拡散モデルではない新しい生成モデルがGoogleとUC Berkeleyから出たようだ。ノイズ除去というよりか分布を1stepで変換できるモデルことを仮定するらしい
- CALM2のGPTQ版が正常動作するようになりました。VRAMが少ない方は是非お使いください。
	- https://huggingface.co/mmnga/cyberagent-calm2-7b-chat-GPTQ-calib-ja-1k
-  CALM2で長い文章をまるごと取り扱う
	- https://note.com/alfredplpl/n/n5ed2ea2b78ec?sub_rt=share_sb
- 『責任あるAI: 「AI倫理」戦略ハンドブック』
	- https://x.com/abenben/status/1720750416361877680?s=20
- 【Calm2-7b】サイバーエージェントの最新LLMが優秀すぎたので、ChatGPTと比較レビューしてみた
	- https://weel.co.jp/media/cyberagentlm2-7b
-  Othello is Solved
	- https://arxiv.org/abs/2310.19387
	- PFNから、弱問題として解けたという話、双方最善手の結果は引き分け
-  LlamaIndex v0.8 クイックスタートガイド - Python版
	- https://note.com/npaka/n/nd449d5190431?sub_rt=share_b
	- 「LlamaIndex」は、プライベートやドメイン固有の知識を必要とする専門知識を必要とする質問応答チャットボットを簡単に作成できるライブラリです。
- シンガポールの首相は、C++で数独ソルバーを公開している	
	- https://t.co/rWig2ugILa
- CALM2-7Bをベンチマークする(11/5追記)
	- https://note.com/shi3zblog/n/n8b9ff5ea62bf?sub_rt=share_sb
- 今の高校では『情報Ⅰ』という科目ができて、ITパスポート相当のことを学んでいる→”高卒相当”のレベルが上がっているという話
	- https://togetter.com/li/2253207
- ＢＸストラテジー　実践行動経済学2.0 人を動かす心のツボ
	- https://www.amazon.co.jp/dp/4296115758?ref_=cm_sw_r_cp_ud_dp_BM2H3QZ9AHNCYW8F2ZY7
	- 企業経営の現場でどのように行動変容を促せばよいのかという知見が体系的に整理されており、法則や理論を寄せ集めたこれまでの事例集的な行動経済学本とは一線を画す良書でした。
- Xから、Grok発表, Elon’s new LLM.
	- https://x.com/xai/status/1721027348970238035?s=20
	- 330億パラメータGrok-0（LLaMA 2 (70B) の機能に近づき、トレーニングリソースの半分しか使用しない）を元にGrok-1を開発。
	- Grok-1 は GPT3.5や Inflection-1を標準的なベンチマークで超える。
- CALM2-7Bの性能を他の日本語LLMと比較してみた
	- https://note.com/it_navi/n/n35e5fac2b3d3?sub_rt=share_pb
	- CALM2-7B-Chatは、一度に**3万2000トークン（日本語で約5万字）**の長文の入出力に対応
	- **CALM2-7B-Chat**の回答を**ELYZA-japanese-Llama-2-7b-instruct**及び**Youri-7B-chat**の回答と比較
	- 論理的思考力については、**3種類の日本語モデルの回答は五十歩百歩**で大差ありません。ChatGPT（GPT-3.5）の性能とは、まだ相当差があるようです
- 『言語哲学がはじまる』野矢茂樹著
	- https://www.iwanami.co.jp/book/b633363.html
	- 日経の書評(11/4朝刊)掲載
	- 言葉とは何か。この問いにフレーゲ、ラッセル、ウィトゲンシュタインはどう挑んだのか。とびきりたのしい言語哲学の説き語り
	- 単語単独で意味を持つのか、文章の中の関係性として意味を持つのか、LLMは何を見ている？
- 牧野先生、PFN開発のMN-core開発に注力
	- https://jun-makino.sakura.ne.jp/articles/future_sc/note161.html
	- 神戸大とPFNのクロスアポイントメントだそうだ、
	- 「今後は社員として直接MN-Core の 開発に関わる」、「普及といったことを含めてMn-Core の 開発が本格化している」

## 10/30

新しいLLMがどんどん発表される。「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」、7BのLLMの覇者は、Mistral 7Bという話題もあったが、ReActをこなせる7bは、Zephyr-7b-betaということらしい、日本語はどうか？OSSのLLMで構造的な出力(Pydantic)を出すにはファインチューニングが有効らしい。text-to-SQLもファインチューニングが有効とのこと。心の理論(TOM)も、心理学のVoE理論の応用とかがあった。LLM の ベンチマーク、いろいろ紹介されるが、自動評価の結果がレーダーチャートで可視化されるMT-Benchが良いかも。既存の概念を組み合わせるsystematic compositionalityの能力をニューラルネットが持つことができるってのは、これはメタファー理論による認知の仕組みの解明が一歩現実に近づいたのか。Prompt によるLLMへの指示を超えるという、LLM programはは、分割統治というか、アンサンブルというかそういう感じ。MicrosoftのAgent Frameworkって前からあったような気もするが、なぜ注目？Hinton先生とLecum先生の議論がLLMの次を見据えた議論で面白い。限界は、ひょんなことから超えられてゆくという歴史もあるよな。FastChatで様々なLLMを試せて評価の幅が広がる、M-BenchもFastChat利用を想定しているのか。

- 7bのフルファインチューニングがcolabで動く？VRAM 32G程度で行けると
	- https://x.com/Sakkusakumura/status/1716158933319246289?s=20
- Character-LLM: A Trainable Agent for Role-Playing
	- https://aiboom.net/archives/57223
	- 特定の人物、例えばベートーヴェンやクレオパトラなどの行動や感情を模倣させるよう訓練する新しいフレームワーク『Character-LLM（キャラクターLLM）』
	- 訓練されたLLMは、特定の人物としての行動や感情を効果的に模倣できることが確認されました。
-  Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts
	- https://cxh0519.github.io/projects/Progressive3D/?ref=aiartweekly
	- Progressive3D brings region specific object manipulation through text with a DALL-E 3 like level of prompt understanding to the table.
	- ３Dモデルに対して、様々な加工を言語で行う
- Courtland Leer et al., "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models"
	- https://arxiv.org/abs/2310.06983
	- 「心の理論（Theory of Mind）」をメタ認知能力をつかって向上できる。
	- 心理学における「Violation of Expectation（期待違反）：VoE」理論を適用
- llamaindexがつかう、すべてのプロンプトを表示・カスタマイズできるI/Fが公開
	-  Accessing/Customizing Prompts within Higher-Level Modules
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompt_mixin.ipynb
- LangChainから、アドバンスなRAGでもある、"Query Transformation"
	- https://blog.langchain.dev/query-transformations/
	- 質問のほうを変換するとな？
- llamaindexで、HuggingFaceのLLMを活用するライブラリが拡張された(会話、テキスト生成、など）
	- you can now plug any `conversational`, `text_generation`, `feature_extraction` endpoints 
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/huggingface.ipynb
- Finetuning LLaMa + Text-to-SQL
	- https://github.com/run-llama/modal_finetune_sql
	- how to fine-tune Llama2 for better text-to-SQL + easily plug into your LLM app, ordered from easy to hard:
	- text-to-SQLで最も性能が良いのは、GPT-4/3.5でも、llamaでもファインチューニングすればどうにかなる。このファインチューニングの手法の様々を紹介、
- State of Open Source AI Book - 2023 Edition
	- https://book.premai.io/state-of-open-source-ai/
	- 当然本自身もOpenSoruce
	- https://github.com/premAI-io/state-of-open-source-ai
-  ComfyUI-LCMによるVid2Vidの高速変換を試す(Latent Consistency Models)
	- https://note.com/bakushu/n/nec4cee4f4f37
	- Latent Consistency Models（LCM）は、最小限のステップ数で迅速に推論できる新たな画像生成モデル
	- Google Colabの標準GPU（VRAM 16GB）で試したところ、512x512サイズの120フレームの動画変換で1分弱。1024x1024サイズの120フレームの動画変換だと12-13分ほどでした。
-  AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation
	- https://arxiv.org/abs/2308.08155
	- https://microsoft.github.io/autogen/
	- マイクロソフト謹製のAgentフレームワーク、前からあったような気もするが。
- Top AI Shops Fail Transparency Test
	- https://spectrum.ieee.org/ai-ethics#toggle-gdpr
	- Stanford transparency index rates Meta, OpenAI, and others on 100 indicators
	- The highest total score goes to Meta’s Llama 2, with 54 out of 100.
-  llm-jpをColabで試す
	- https://note.com/alexweberk/n/n6b26b324904c?sub_rt=share_pw
	- 「jaster を含むものは回答がそっけない」らしいので、それを除いたテスト
	- 流石日本語特化のモデルだけあって日本語は自然な形で生成できました。日本に関する基本的な知識も備えているのは嬉しい
-  LLM の ベンチマーク まとめ by npakaさん
	- https://note.com/npaka/n/ndec10f78fe2f
	- 人間を評価者としたベンチマーク、 GPT-4を評価者としたベンチマーク、QAデータセットによるベンチマーク、コード生成のベンチマーク、埋め込みのベンチマーク、 ロールプレイのベンチマーク
	- 現状で自動評価可能な最良のアプローチはGPT-4を評価者とする方法。ただしコストなど課題がある
- MiniGPT-V
	- https://note.com/ai_meg/n/n748acc8e824b
	- MiniGPT-4のAPIを実装する。　プログラムでマルチモーダルを自由に操作する。
-  Google Colab で Japanese Stable LM Gamma 7B を試す by npakaさん
	- https://note.com/npaka/n/n4f2d6e6c11f7?sub_rt=share_b
- 日本語大規模言語モデル「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」
	- https://ja.stability.ai/blog/japanese-stable-lm-3b-4e1tjapanese-stable-lm-gamma-7b
	- 約30億と70億のパラメータを持つこれらのモデルは、日本語タスクの性能評価でトップクラス
	- 3Bと7Bのサイズでそれぞれ圧倒的性能を誇る英語LLM「Stable LM 3B-4E1T」「Mistral-7B-v0.1」に継続事前学習を適用することでサクッとめちゃツヨ日本語LLM
-  Japanese research is no longer world class — here’s why
	- https://www.nature.com/articles/d41586-023-03290-1?error=cookies_not_supported&code=dd59d16e-8d54-49a4-95a3-8fcded36917f&utm_medium=Social&utm_campaign=nature&utm_source=Twitter#Echobox=1698226936
	- nature記事より
	- **資金不足と時間不足**、**若手研究者の不満と減少**　が指摘されている。
-  Branch-Solve-Merge Improves Large Language Model Evaluation and Generation
	- https://arxiv.org/abs/2310.15123
	- Promptを超えた？LLM自身をアルゴリズムの一部に埋め込んで使うような、LLM programと呼ばれるような手法
- Large Language Model Programs
	- https://arxiv.org/pdf/2305.05364.pdf
	- LLMをアルゴリズムに埋め込むことをLLM Programとと呼ぶらしい、分割統治なんかそうなんだけど、メタなLLMみたいな感じ
-  LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions
	- https://arxiv.org/abs/2310.14029v1
	- 結晶構造をテキスト化して言語モデルで学習、そのエンコーダを使って物性予測を行うと従来のSOTAであるGNNモデルより高精度な予測
-  LangChain の Step-back Prompting を試す by npakaさん
	- https://note.com/npaka/n/n55f276ad2988?sub_rt=share_sb
	- (1) ユーザーの元の質問に基づいて、ステップバック質問を生成  
	- (2) 元の質問とステップバック質問の両方を情報収集  
	- (3) 取得した両方の情報に基づいて回答を生成
- mmnga/japanese-stablelm-instruct-gamma-7b-gguf
	- stabilityAIさんが公開されているjapanese-stablelm-instruct-gamma-7bのgguf
	- Mistral-7bの日本語版で、AIのべりすとさんから提供された高品質なデータが入っている
- フィールズ賞受賞者のテレンス・タオさんが、証明支援系Leanを使うことで自分の論文の中のバグ（ミス）に気づいたという話
	- https://mathstodon.xyz/@tao/111287749336059662
	- 定理証明系が実数学者のためになっているのか。。。
-  KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval
	- https://huggingface.co/papers/2310.15511
	-  (e.g., 'a list of ice cream shops in San Diego')
-  LLMのプロンプト技術まとめ
	- https://qiita.com/fuyu_quant/items/157086987bd1b4e52e80
-  Zephyr: Direct Distillation of LM Alignment
	- https://arxiv.org/abs/2310.16944
	- なんかすごい性能らしい。
-  Human-like systematic generalization through a meta-learning neural network
	- https://www.nature.com/articles/s41586-023-06668-3
	- 既存の概念を組み合わせるsystematic compositionalityの能力を、メタ学習を施したニューラルネットで実現。35年前のFodor＆Pylyshynの「ニューラルネットはcompositionalityを持てない」との主張への応答として書いている
-  MT-Bench の使い方 by npakaさん
	- https://note.com/npaka/n/na28f31e96599?sub_rt=share_b
	- 「[**MT-Bench**](https://chat.lmsys.org/?leaderboard)」は、80の高品質でマルチターンの質問を含む、慎重にキュレーションされたLLMのベンチマークです。
	- レーダーチャートででるのがよい。
-  7BのLLMの覇者は、Mistral 7B ？？
	- https://www.promptingguide.ai/models/mistral-7b
- Getting started  with Llama by Meta
	- Meta謹製のLlmaガイド
	- https://ai.meta.com/llama/get-started/
	- Yann LeCun先生のおすすめでもある。
- bakLLaVA vision AI can read xrays with only 6Gb of RAM
	- https://github.com/SkunkworksAI/BakLLaVA
	- OSSのLLMでがん画像検診ができる？
- Zephyr-7b-betaって無敵かも
	- https://colab.research.google.com/drive/1UoPcoiA5EOBghxWKWduQhChliMHxla7U?usp=sharing
	- found it’s the only 7B LLM that can handle ReAct agent tasks over data
	- つまり、dataに対して、ReActするAgentを実装できる唯一の7B LLMということらしい
	- Jelly Liuさん(llamaindex作者)も激賞
	- https://x.com/jerryjliu0/status/1718054817640390840?s=20
-  Evaluating RAG pipelines with Ragas + LangSmith
	- https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/
	- RAGの性能評価をRagasとLangSmithで行う方法を紹介した記事
	- RagasはLLMによるRAGの自動評価を支援するOSS、試したけどお金かかるんだよな。
- llama2 7bをファインチューニングすることで、出力を特定フォーマットにすることができる
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/gradient/gradient_structured.ipynb
	- structured Pydantic objectsを出力する
- 帝人の統合報告書2023に掲載されている特許情報分析。ポートフォリオの変化について、テキストマイニングによる全体俯瞰と特許価値評価の2つのアプローチで可視化
	- https://ssl4.eir-parts.net/doc/3401/ir_material_for_fiscal_ym1/141477/00.pdf
- Hinton先生の、新しいLLMの開発（たぶんOpenAI)に対する危惧に対して、Lecum先生は、どうせ今のAuto-Regressive LLMの延長線上の開発なので、限界は自明い。真に必要なAIは、、と反論。
	- https://x.com/ylecun/status/1718263303485501784?s=20
	- Objective-Driven AI architecturesが必要とのこと
- Advanced Prompt Engineering for RAG by llamaindex
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompts_rag.ipynb
	- 基本的なRAGから、few-shot追加したり、context変換したりという話題
- Stability AI の Japanese MT-Bench を試した
	- https://x.com/npaka123/status/1718403656725483961?s=20
- Demystifying Advanced RAG Pipelines
	- https://github.com/pchunduri6/rag-demystified
-  Chatting With Your Data Ultimate Guide
	- https://medium.com/aimonks/chatting-with-your-data-ultimate-guide-a4e909591436
-  MT-Bench による日本語LLMの評価 by npakaさん
	- https://note.com/npaka/n/n0530f6f9123f?sub_rt=share_sb
	- 「Stability AI」が提供する**「Japanese MT-Bench」の質問ファイル**と**参照回答ファイル**を使う
	- 評価するモデルは、FastChatが対応している必要があります。

## 10/23

今週は、NIIからllm-jp-13b-v1.0が公開されたのが話題でした、さっそくcolabで使った例が公開されたり、4bit量子化版がhuggingfaceで公開されたりと、盛り上がってます。関係者の努力とABCIの活躍に頭が下がります。LLM活用アプリの性能を考えるときに、RAGでもそうなんだけど、LLMとembeddingの組み合わせをちゃんと評価するってのが最初にあるべきなのかも。使ったことないけどもReplicateはそこんところうまくついたサービス展開といえる。LLMをソフトウエアエンジニアリングで活用できるという論文が話題に。OpenAI、限りなくAGIに近いとうわさのArrakisの開発断念？映画Dune２(Arrakisという星が部隊）の公開も春にずれ込んだから、似たような運命をたどるのか？マッキンゼーのレポート、生成AIにより、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しというのは驚いた、つまり我々は25年先の技術を今見ていることになる、そりゃ（多くの人にはLLMの凄さが）分らんわな。スタンフォード大の「科学論文の査読」に、大規模言語モデル（LLM）が有用であるという論文、これは朗報だ（誰得？）。「kaggle LLMコンペ　上位解法のまとめ」はこれはLLMプラクティショナーには必読だ。ちゃんとコンテキストを適切に与えることが重要。あたりまえだけど、それを行うのは難し。「世界モデル」に対するOpenAI共同設立者のIlya Sutskever氏の対談、大規模深層学習モデルは言葉を生成する何等かの表現（つまり世界モデル）を学習し、これから漏れ出るものがテキストであると言っている（ナウシカの「墓所の主」みたいなものか）。LLMの因果推論能力のベンチーマーク、fine-tuningすると性能はあがるが、少し表現を変えると性能が爆下がりって！、それがLLMなのよ！最新の言語理論である「ジェスチャーゲーム」で人間の言語能力が身についたとすると、LLMが示すテキスト生成能力は何？？Ilya Sutskever氏の対談の話と真っ向から対立する感じ。「言語ゲーム」といえばヴィトゲンシュタイン、ウィトゲンシュタイン研究を専門とする大谷先生の対話記事によると。LLMと言語ゲームって似たところがあるそうだ。なんか、楽しくなってきた。

- Ilya Sutskever氏LLMと世界モデルについて語る with Jensen Huang, CEO of Nvidia:
	- https://twitter.com/i/status/1713368556618887670
	- OpenAIの共同設立者であるIlya Sutskever氏とNvidiaのensen Huang社長との対談より
	- （巨大な）ニューラルネットが学んでいるのは、テキストを生成する「何か」に対する表現を学んでいる。その「何か」とは世界モデルであり、それが射影されたものが生成されたテキストなのである。
- Jonas Belouadi et al., "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"
	- https://arxiv.org/abs/2310.00367
	- LLMを活用し人間のように科学的な図を生成するツール『AutomaTikZ』
	- テキストから科学的なベクターグラフィックスを生成する 
	- LLaMAをDaTikZデータセットで微調整
-  Can Large Language Models Infer Causation from Correlation?
	- https://arxiv.org/abs/2306.05836
	- https://ai-scholar.tech/articles/large-language-models/llm_causal_inference_skill
	-  LLMに因果推論能力はあるか？
	- 大規模言語モデルの因果推論能力をテストするベンチマークデータセットを提案  
	- 17の既存の大規模言語モデルを評価  
	- 現状のモデルは因果推論能力が低いことがわかった
	- fine-tuningにより性能向上が見られる一方で，少し表現を変えただけで性能が下がる現象も見られる
- Yijun Tian et al., "Graph Neural Prompting with Large Language Models"
	- https://arxiv.org/abs/2309.15427
	- LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』
	- GNPは、LLMに有益な知識を効果的にエンコードし、パフォーマンスを大幅に向上させることができる
- 大規模言語モデルがどのように動いてるかを視覚的に説明するインフォグラフィックが素晴らしいと
	- https://ig.ft.com/generative-ai/
	- Fanatical Timesのインフォグラフィック
- Large Language Models for Software Engineering: Survey and Open Problems
	- https://arxiv.org/abs/2310.03533
	- LLMをソフトウエアエンジニアリング(SE)にどうやって適用するか？
	- 要求エンジニアリング/デザイン、コード生成、テスト、運用/デプロイ、ドキュメント生成。またリサーチ領域での活用なども
	- 伝統的なSEとLLMを融合したはハイブリッドにより信頼ある効率的なLLMベースのSEが実現できた
- JapaneseEmbeddingEval　日本語におけるembeddingの評価
	-  https://github.com/oshizo/JapaneseEmbeddingEval
	- multilingual-e5っていい線いってるのか。。
- PaLI-3 Vision Language Models: Smaller, Faster, Stronger
	- https://huggingface.co/papers/2310.09199
	- Googleによる、高性能で小さいvision language model (VLM)
- マッキンゼーから発表されたAI動向に関するレポートがなかなか衝撃的
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-AI-the-next-productivity-frontier#introduction
	- 生成AI（というかChatGPTに代表されるLLM)の登場により、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しになった
		- 2017年の予測：2050年 ・2023年の予測：2024〜2025年 
- Xinyun Chen et al, "Teaching Large Language Models to Self-Debug"
	- https://arxiv.org/abs/2304.05128
	- GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』
	- LLMに自己デバッグの能力を教えることで、コード生成の性能が向上する
- ChatGPTを用いてコーディングを学ぶ方法について（慶応義塾大学）
	- https://speakerdeck.com/keio_smilab/keio-univ-intro-to-ml-02-coding
	- なんと、学生向けに、ChatGPTを用いてPythonなどのコーディングを学ぶという授業が、、
	- ChatGPTネイティブな学生は、ChatGPTでコーディングを学ぶのか。。
- Andrew Ng先生から、deeplearning.aiの「生成AI」の講義の宣伝
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- OpenAI、次世代LLMである、Arrakisの開発を断念？
	-  OpenAI Dropped Work on New ‘Arrakis’ AI Model in Rare Setback
	- 限りなくAGIに近いとうわさされる次世代のLLM、
	- どううも開発中（学習中）の性能評価で思ったほど性能が出なかったため。
	- https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback
- llamaindexのLiuさんより、“Evaluation Driven Development” (EDD)の提案
	- https://x.com/jerryjliu0/status/1713936561480610104?s=20
	- まずは、LLM＋Embeddingの組み合わせをちゃんと評価するところから始めようみたいな。
- Replicateを利用すると、任意のLLMとembeddingの組み合わせを簡単に評価できる
	- https://replicate.com/explore
	- つまりhuggingfaceのモデルをダウンロードして動かす手間を、少し省くサービスを提供、
	- ナイスだな。
- NIIから、LLM-jp-13B が公開される
	- LLM-jp （LLM 勉強会）は、日本語と英語を中心に事前学習した130億パラメータの大規模言語モデルをオープンなライセンスで公開
	- https://llm-jp.nii.ac.jp/release/
	- インストラクションデータでチューニングしたモデルや訓練・チューニングに用いたソフトウェアも公開
- データでできることのレベル感を理解する（デジタル庁の人のスライドより）
	- https://speakerdeck.com/hik0107/data-design-and-government?slide=10
	- 現状の把握(lv.1)、分解と差異の把握(Lv.2)、原因の把握(Lv.3)、対策の把握(Lv4)
-  Google Colab で LLM-jp-13B を試す by npakaさん
	- https://note.com/npaka/n/n60b0abf54ed5?sub_rt=share_sb
	- T4 ハイメモリで動作確認
	- 早速試されている
- BEYOND MEMORIZATION: VIOLATING PRIVACY VIA INFERENCE WITH LARGE LANGUAGE MODELS
	- https://arxiv.org/pdf/2310.07298v1.pdf
	- Redditの匿名ポストのテキストから、GPT-4はその人のプロファイル（収入、性別、住所）を85%の正確さで、かつ人間の1%のコストで当てた。。
	- A paper that really illustrates both the unexpected power, and unexpected risks, that come from LLMs.
-  InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
	- https://arxiv.org/abs/2310.07713
	- pre-train LLMs with Retrieval Augmentation
-  An Emulator for Fine-Tuning Large Language Models using Small Language Models
	- https://huggingface.co/papers/2310.12962
	- Emulator for Fine-Tuning(EFT)は、大規模な事前学習済みモデルを小規模な微調整済みモデルとアンサンブルすることで、大規模な事前学習済みモデルを微調整した結果をエミュレートするという、アップスケーリングが可能になった
-  Can large language models provide useful feedback on research papers? A large-scale empirical analysis
	- https://arxiv.org/abs/2310.01783
	- 「科学論文の査読」に、大規模言語モデル（LLM）が有用な可能性がある
	- 米スタンフォード大らが検証　参加者の80％以上「AI査読は有益」
	- https://www.itmedia.co.jp/news/articles/2310/19/news072.html
	- Nature系列のジャーナルにおけるフィードバックの結果、GPT-4が提供したコメントの57.55％は、全体の査読者の中で少なくとも1人の人間の査読者が記載していた
- A quantized version of the mistral that is instruction following over 32k tokens.
	- https://huggingface.co/TheBloke/MistralLite-7B-AWQ
	- mistralって性能がよいと先週評判になってたやつの、4bit量子化版が公開？
- llm-jp-13b-v1.0も早速GPTQ版が公開される
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-4bit-g128-GPTQ-calib-ja-1k
	- llm-jp-13b-v1.0を、 日本語のキャリブレーションセットで生成したGPTQモデル
-  言語はこうして生まれる―「即興する脳」とジェスチャーゲーム―
	- https://www.shinchosha.co.jp/book/507311/
	- 言語の生得性を否定し、文化進化や語用論的な観点から言語獲得を論じています
	- 歴史：ノーム・チョムスキーは「普遍文法」という概念を導入し、「人間の遺伝的青写真には、言語を支配する抽象的な数学的原理が内包」しているといった
	- 歴史：心理学者スティーブン・ピンカーがさらに『言語を生みだす本能』（NHKブックス）へと発展させる
	- 主張：「ジェスチャーゲーム」。言語は遺伝的に決定されたものなどではなく、身振り手振り、発声、あるいはその両方で自分の意思を双方向的に伝え合うジェスチャーゲームのようなものが起源なのではないかという斬新なアイデアだ。そこには普遍文法が入り込む余地などない。
- LLM（大規模言語モデル）は「言語ゲーム」的か  東京女子大学現代教養学部准教授・大谷弘氏に聞く（１）
	- [IT批評の記事](https://it-hihyou.com/recommended/llm%EF%BC%88%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%89%E3%81%AF%E3%80%8C%E8%A8%80%E8%AA%9E%E3%82%B2%E3%83%BC%E3%83%A0%E3%80%8D%E7%9A%84%E3%81%8B-%E2%80%95/)より
	- LLMって、パターンから学び、その背後には人間があるから、ヴィトゲンシュタインのいう「言語ゲーム」に似ている、らしい。記号接地してないという批判にも、学習データの背後の人間のあたりで接地しているのかもともいう。
- 多様体上の最適化理論
	- https://www.amazon.co.jp/exec/obidos/ASIN/4274231186?&linkCode=sl1&tag=mathlang09-22&linkId=bd145734052442298eb01413d823ca91&language=ja_JP&ref_=as_li_ss_tl
	- 多様体上の最適化理論について、基礎となる数理から応用例までを解説
-  Introducing CliffordLayers: Neural Network layers inspired by Clifford / Geometric Algebras.
	- https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/articles/introducing-cliffordlayers-neural-network-layers-inspired-by-clifford-geometric-algebras/
	- MS研究所から、クリフォード代数にインスパイアされた新しいNNレイヤの発明
-  OpenAgents: An Open Platform for Language Agents in the Wild
	- https://arxiv.org/abs/2310.10634v1
- llamaindexより、Unifying Text-to-SQL and RAG with our SQLRetrieve
	- https://docs.llamaindex.ai/en/latest/examples/index_structs/struct_indices/SQLIndexDemo.html
	- SQLデータベースに対して、RAGを行うRetriverについて、動いたぞ、役に立つぞ。
- kaggle LLMコンペ　上位解法まとめ
	- https://zenn.dev/yume_neko/articles/7347ba6b081e93
	- 科学分野の5択問題を解くLLMの精度を規則コンペのべスプラ
	- 今回のコンペで上位に行くにはRetrievalが最もキーだったように思います。やはり正解情報を直接参照できるので、contextをより良くすることが重要だったのではないかと思います。
- llama2のpretrainingを試す
	- https://zenn.dev/if001/articles/6c507e15cd958b
	- 小さいサイズのllama2を日本語でpre_trainingしてみます
	- pre_trainingからhuggingfaceへのuploadまでを行ってみました。
	- 小さいサイズであればgoogle colabで学習できる
- llm-jp-13b-v1.0-gguf
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-gguf
	- llm-jpさんが公開しているllm-jp-13b-v1.0のggufフォーマット変換版
	- ブランチらしい、LLama.cppが、なんかの変更を行うとggufが動かなくなるらしい、怖っ

## 10/16

RAGシステムの性能向上は依然もりあがっている。StanfordのDSpy、どうもLLMのプロンプト利用を別の次元に引き上げる画期的な開発のように見えるが追いつけない。RAGとFinetuningを組み合わせることによる性能向上がいままで抜けていたとは。LLMの心の理論(ToM)についての論文では、他人の心の状態の推定というのが肝なのか。zephyr-7b-alphaとか、Japanese StableLM Instruct Alpha v2 とか、ローカルで使いものになるLLMもどんどん出てきた。スタンフォードAIの、State of AI Report 2023、 KaggleのAI Report 2023、それぞれの立場で最新のAIを取り巻く様々な視点をまとめてくれている。アナロジー（類推）でプロンプトを生成する「アナロジカル・プロンプティング」は、人間の手間を省けるか？組み込み(embeding)の違いによるRAG性能の違いの検証から、やっぱe5(intfloat/multilingual-e5-large)が当面最強なのか？PFNのインターン生の成果などがいくつか公開。それにしてもPFNのインターン生つよつよだろう、ちょっとうらやましい。DeepMindのYasunagaさんやエジンバラ大学のMatsubaraさんなどの日本人の活躍もちらほら。


- Large Language Models (in 2023)
	- https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0
	- OpenAIのHyung Won ChungさんによるLLMの現状をまとめたスライド
	- The biggest progress in the past 10 years (or even more) can be summarized as
		- Create weaker inductive biases and scale up
		- Do not teach machines how we think we think. Let it learn in a machine’s way
- Masking PII Data in RAG Pipeline
	- https://betterprogramming.pub/masking-pii-data-in-rag-pipeline-326d2d330336
	- PII(Personal Identification Information)をマスキングする方法を、RAGにおいて行う方法
	-  LlamaIndexの NERPIINodePostprocessorを活用するのがみそ
- Jerryより、RAGシステムの性能向上に関する、様々な手法のブックマーク集
	- Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex
		- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5
	- Building Performant RAG Applications for Production
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/production_rag.html
	- Multi-Document Agents
		- https://docs.llamaindex.ai/en/stable/examples/agent/multi_document_agents.html
	- Finetuning
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/finetuning.html
- Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models
	- https://arxiv.org/abs/2310.04406
	- Substantially improving over the existing prompting methods such as Reflexion, e.g., 68.1% -> 86.9% on HumanEval with GPT-3.5
- Ida Momennejad et al., "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval"
	- https://arxiv.org/abs/2309.15129
	- 人間の測定法と似たフレームワークでLLMの認知機能を調査した論文
	- LLMの「認知マップ」と「計画能力」を評価。
		- 認知マップ：外部環境を内部に表現する機能 
		- 計画能力：目標に向かって計画を立てて遂行する能力
	- GPT-3.5、GPT-4、Bard、LLaMA-13Bなど
	- 結果
		- ① 認知マップの理解や計画能力は「箱から出してすぐに」は持っていない 
		- ② 認知マップの欠如が理由で計画タスクに失敗する可能性が高い 
		- ③ 新しい評価プロトコル（CogEval）は有望である 
		- ④ LLMのアーキテクチャやトレーニングには工夫の余地がある 
		- ⑤ LLMの認知機能を向上させるには、メモリ（記憶容量）の拡張などが有効
- FireAct: Toward Language Agent Fine-tuning
	- https://fireact-agent.github.io/
	- LLM AgentとFintuningの合わせ技についての検証、ReActの性能をfine-tuningで向上できた
	- FireAct is a novel way to finetune LMs w/ agent trajectories of a mix of tasks & prompting methods.
	- Fine-tuning >> Prompting:
		- Notably, small LMs benefit most --- Llama2-7B improves 77% after fine-tuning!
- Pei Zhou et al., "How FaR Are Large Language Models From Agents with Theory-of-Mind?"
	- https://arxiv.org/abs/2310.03051
	- LLMの「心の理論(ToM:Theory of Mind)」における能力を評価するフレームワーク『Thinking for Doing (T4D)』
		- ① 他者の心の状態（信念、願望、意図など）についてどれだけ効果的に推論できるか
		- ② 推論した上でいかに行動に移せるか
	- 従来の心理学的テストではLLMのToM能力の評価は十分には出来ないとされています。
	- 「Foresee and Reflect (FaR)」という新しいフレームワーク
		- ① 将来のイベントを予測（Foresee） 
		- ② それに対する行動を考慮（Reflect）
	- 「FaR」フレームワークと評価パラダイム「Thinking for Doing (T4D)」の組み合わせによって、効率的にLLMのToM能力を評価することができる
- 7 Query Strategies for Navigating Knowledge Graphs With NebulaGraph and LlamaIndex
	- https://www.nebula-graph.io/posts/Knowledge-Graph-and-LlamaIndex
	- NebulaGraph を使ってグラフ構造に対する、Q&Aを実現する方法について via Llamaindex
- StanfordのDSpyを用いることによる、Q&Aのファインチューニングが簡単になる？
	- https://x.com/lateinteraction/status/1712135660797317577?s=20
- KaggleのAI Report 2023
	- https://www.kaggle.com/AI-Report-2023
	- これはAIの現状に関するエッセイコンペの結果をまとめたもの、最新のAIを取り巻く様々な視点からの見方がわかる。
- HuggingFaceにおけるLLM評価で、zephyr-7b-alphaがChatLlama 70Bを上回る性能をだしたらしいのでllamaindexで確かめてみた
	- https://colab.research.google.com/drive/16Ygf2IyGNkb725ZqtRmFQjwWBuzFX_kl?usp=sharing#scrollTo=lMNaHDzPM68f
	- We found that it is the ONLY open 7B model atm that does well on advanced RAG/agentic task
- DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation
	- https://huggingface.co/papers/2309.16653
	- ここで３Dモデル作成を試せる、なんかすごいぞ。
		- https://huggingface.co/spaces/jiawei011/dreamgaussian
-  Multimodality and Large Multimodal Models (LMMs)
	- https://huyenchip.com/2023/10/10/multimodal.html
	- マルチモーダルモデルに関するサーベイ。重要論文としてCLIPとFlamingoを解説した上で、今後の方向性として他のモダリティの追加、出力のマルチモーダル化、ベンチマークの整備などを挙げている
- LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression
	- https://arxiv.org/abs/2310.06839
	- Gains a performance boost of up to 17.1% on NaturalQuestions over the original prompt with ~4x fewer tokens
- MatGPT: A Vane of Materials Informatics from Past, Present, to Future
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202306733?af=R
	- **GPT AI**の出現は、科学研究分野が「データ」を基本要素とし、「アルゴリズム + 計算能力」を核心生産力とする知能文明時代に入ったことを示している。
	- 事前学習モデル、指向性設計モデル、協調学習、実験ロボットなど
- PFNのインターン発表： 遺伝⼦に関するグラフを利⽤したモデルの開発
	- https://tech.preferred.jp/ja/blog/model-learning-using-gene-graph/
	- RNAからProteinを予測するタスクにおいては、学習サンプル数が限られ、かつ使用できる特徴量が少ない状況においては、予測対象モダリティの制御に関与する特定のグラフ構造を用いることで性能の改善が認められました。
- サイバーエージェントがOpenCaml2を開発中らしい
	- https://aws.amazon.com/jp/blogs/news/open-calm-and-openai-chatgpt-accuracy-on-jaqket-experiment-in-amazon-sagemaker/
- RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation
	- https://arxiv.org/abs/2310.04408
	- LLMでのRAGの性能向上のために、2つの圧縮器(重要部分抽出・複数文書要約)を使うRECOMP法の提案。各圧縮器は学習させる必要有
- 機械学習波動関数？？
	- https://www.nature.com/articles/s41524-023-01130-4
	- 従来は1種類の構造しか訓練に使えませんでしたが、ハミルトニアンを対称性に基づくパラメータで記述することで様々な構造を訓練でき、転位がある約5000原子セルの電子状態予測を実現した
- Google Colab で Japanese StableLM Instruct Alpha v2 を試す by npakaさん
	- https://note.com/npaka/n/n0e463dbbce11?sub_rt=share_sb
	- 「Stability AI Japan」が開発した7Bパラメータの日本語LLM
	- 商用利用を制限しないデータセットのみを利用することで、同等レベルの性能を持つ**商用利用が可能**
	- Colab無料枠(T4)で動作する模様
- StanfordAIによる、 State of AI Report 2023
	- https://www.stateof.ai/2023-report-launch
	- OpenAIの**GPT-4**は、すべてのベンチマークや人間向けの試験において他のLLMを凌駕している。
	- Meta AIはオープン（な）AIのチャンピオンとして登場し、LLaMaモデルファミリーを最も強力な公開アクセス可能なOpenAI代替品となっている
	- LLMや拡散モデルは、特にライフサイエンス分野で実用的なブレイクスルーをもたらしてお
	- 生成AIが、低迷している、テック界隈のVCを救う。
	- 安全性はAI研究界で中心的なテーマとなり、世界中の政府や規制機関が対策を講じ始めた。
	- 標準的なLLMは頑健性に問題があり、最先端モデルの評価が困難になっている
- Michihiro Yasunaga et al., "Large Language Models as Analogical Reasoners"
	- https://arxiv.org/abs/2310.01714
	- 人間の「過去の類似事例」と「自らの知見」を組み合わせるアプローチに倣った、LLMの優れたプロンプトフレームワーク
	- LLMの推論能力を向上させるCoTは有用ですが、手間がかかります。 手動のプロンプト作業を少しでも軽減することが求められています。 
	- そこで研究者らは、人間のように自動的に知識を生成する「アナロジカル・プロンプティング」を発明しました。
- Hamiltonian Dynamics of Bayesian Inference Formalised by Arc Hamiltonian Systems
	- https://arxiv.org/pdf/2310.07680.pdf
	- エジンバラ大学の松原さんの論文
	- infinite-dimensional Hamiltonian system behind Bayesian inference.
	- ベイズ推論の裏に、無限次元のハミルトニアンシステムがあるという、、
- Zijun Liu et al., "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization"
	- https://arxiv.org/abs/2310.02170
	- 複数のエージェントに協力して仕事を開始させ、タスクの進行に応じて重要なエージェントを取捨選択する『Dynamic LLM-Agent Network（DyLAN）』フレームワーク
	- タスクに応じて動的にエージェントを選択する方式を考えました。
- LangChain を使った RAG における埋め込みモデルの比較
	- https://note.com/alexweberk/n/ncccfdab3f4bb
	- Wikipedia 記事を LangChain の CharacterTextSplitter を使って、４種類の埋め込みモデルを使ってベクトル化し、RAG による質問応答を試行
	- `intfloat/multilingual-e5-large` >= `pkshatech/GLuCoSE-base-jap` > `cl-nagoya/sup-simcse-ja-large` >= `openai/text-embedding-ada-002` というような感触
	- 4つの埋め込みモデルを使ったRAGを試してみました: 
		- intfloat/multilingual-e5-large 
		- cl-nagoya/sup-simcse-ja-large 
		- pkshatech/GLuCoSE-base-ja 
		- openai/text-embedding-ada-002
- OpenAI gpt-3.5-turbo と gpt-3.5-turbo-instruct モデルの違いについて
	- https://corp.langcore.org/media/chatgpt-instruct
	- gpt-3.5-turbo モデルは会話に秀でているので対話をさせるのであればこちらを使う方がよいです。
	- 会話以外のタスクの場合だと**一問一答のような単純な課題を解くケースでは gpt-3.5-turbo-instruct の方が期待する出力になる可能性**があります。
- Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction
	- https://arxiv.org/abs/2310.05627
	- IJCAIでLLM(chatGPT)使った株価リターン予測の論文
	- LLMによるテキストの埋め込みと株式の特徴を同じsemantic spaceで配置させる強化学習の枠組みを導入している。
- Zhiyu Chen et al., "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting"
	- https://arxiv.org/abs/2310.07146
	- GPT-4をセラピストとして実行し、人々の「認知の歪み」を診断させるためのフレームワーク『Diagnosis of Thought (DoT)』
	- ① DoTは、「認知の歪み」評価と分類で高性能を示した 
	- ② GPT-4は、「認知の歪み」分類で特に高い性能を示した 
	- ③ 専門家によってGPT-4による本診断方法は「包括的である」と評価された（84.5%）
-  Large Language Models can Learn Rules
	- LLMがルールを学習できる？
	- https://arxiv.org/abs/2310.07064
	- LLMs can learn (sometimes uncommon) rules with 2 stages: (1) induction: generate and verify rules from exemplars; (2) deduction: utilize the rule library for new problems. 11-27% gain on reasoning tasks that require rule learning.

## 10/10

function callを含むLLMのファインチューニングをOpenAIが導入されたり、LLMのRAGに対するファインチューニングについての考察があったりと、性能面での評価を含めRAG関係は成熟してきた感じ。LLMがどれだけ論理的かという検証も「逆転の呪い」を例に行われているが、LLMが「物事がどのように位置づけられ、時間がどのように進行するかを理解」しているという実験はこれからのLLMを用いた複雑なタスクの開発に弾みでもある。マルチモーダルでは、早速GPT-4Vに対抗するOSSであるLLaVAが登場した、LLaVA-1.5はすでに試せる模様。スタンフォード大学がAIに関する多角的なデータのレポートすばらしい。OpenAIは、GPT-4Vに引き続き、DALL·E 3に対する品質カード(System Card)を公開、安全な画像生成をアピール。MSのDeepSpeedチームの科学的基盤モデルっても頑張ってるな、気象予想に使えそう。MicrosoftのH100 GPU対抗チップのATHENA、本当にやる気があるのか？


- 『逆転の呪い』:「AはBである」と学習したLLMは、「BはAである」と学習しづらくなる。
	- https://arxiv.org/abs/2309.12288
	- LLMがどれだけ論理的か？という問いに対して、LLMの苦手な点を挙げる
	- 『逆転の呪い』LLMは、知識を構造化し、”帰結を主語にして同じことを言う”のが自動的にはできない
	- LLMの「逆転の呪い」を認識した上ですべきことの考察
-  Knowledge Graph Construction w/ WikiData Filtering  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/knowledge_graph2.html
	- REBELを用いて、文章あから知識グラフを抽出する方法において、Wikipediaをフィルタとして用いることで、春市ネーションを抑えれる
- Ronen Eldan et al., "Who's Harry Potter? Approximate Unlearning in LLMs"
	- https://arxiv.org/abs/2310.02238
	- LLMの記憶の一部を意図的に忘却させる
	- 約1GPU時間の微調整で、モデルはHarry Potter関連のコンテンツを生成または回想する能力を効果的に消去
-  Fine-tuning with Retrieval Augmentation  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_retrieval_aug.html
	- https://arxiv.org/abs/2310.01352
	- gpt-4とDatasetGeneratorをつかって、正解qaデータを生成
	- gpt-3.5-turboを正解qaデータをつかて、RAGのコンテキストでファインチューニング
	- 結果correctnesは、素のLLM＝3.2、ファインチューニング後＝3.65、
- 非侵襲の脳活動センシングによる、音声のデーコーディング
	- Decoding speech from non-invasive recordings of brain activity
	- https://huggingface.co/papers/2208.12266
	- contrastive learningというのをつかって、脳波からスピーチを推定
- OpenAIが、function calling fine-tuning機能を新たに追加　by llamaindex
	-  Fine Tuning with Function Calling
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/openai_fine_tuning_functions.html
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/openai_fine_tuning_functions.ipynb
	- 構造化されたデータ出力をLLMから得たいときに、functio/n callをつかうらしいが、この機能をfine-tuneすることができる
- LLMは世界モデルをもっているか？
	-  Language Models Represent Space and Time
	- https://arxiv.org/abs/2310.02207
	- LLMはシンプルに統計（確率）から次のテキストを生成しているのではなく、「物事がどのように位置づけられ、時間がどのように進行するかを理解」している可能性が示唆されました。 つまり、LLMが"世界モデル"を形成しているかもしれないという報告
	- 世界、米国、NYCの地名、歴史的人物、芸術作品、ニュースヘッドラインなどを含む6つのデータセットを用意
	- 空間と時間の理解度は、LLMのニューラルネットワークにおける階層を半分まで進んだところで品質が向上し、そのあと限界点に達する
	- LLMが「世界モデル」を形成している可能性が高いのであれば、LLMがより高度な認知タスクに対応できることに繋がります。 例えば自動運転車のソフトウェアにLLMを活用するのは優れた戦略である可能性があります
- huggingface/transformers v4.34の更新はかなりagressive
	- https://github.com/huggingface/transformers/releases/tag/v4.34.0
	- tokenizerの挙動を細かく制御していた人たちにとってはうれしいかも
- ModuLoRA is the first method to finetune 3-bit LLMs
	- 3-bitや2-bitに量子化したLLMの話題の裏にあるアルゴリズムModulLoRAが公開
	- https://browse.arxiv.org/pdf/2309.16119.pdf
- RETRIEVAL MEETS LONG CONTEXT LARGE LANGUAGE MODELS
	- https://arxiv.org/abs/2310.03025
	- NVIDIAよりRAGとContext Window (CW)のパフォーマンス比較論文。4K CWのLLM＋RAGは、16K CWのLLMと同等、32K CWのLLaMA2-70B＋RAGは長いContextのタスクにおいてGPT-3.5-turbo-16kより優れていると事を実証分析 
- llama.cpp 単体で LoRA 作れる機能が追加
	- https://github.com/ggerganov/llama.cpp/pull/2632
- Why you should build RAG from scratch - with Jerry Liu from LlamaIndex
	- LlamaIndexの中の人に聞く回。ファインチューン、RAG、ReAct、ベクトル検索やハイブリッド検索等々についてJerryがどう考えてるか聴ける。RAGはハックだと言い切ってて面白い。
	- https://www.latent.space/p/llamaindex?utm_campaign=post&utm_medium=web
-  Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study
	- https://arxiv.org/abs/2307.08072
	- 量子化されたLLMについて、一般的にLLMで発現するとされているin-context learning、chain-of-thought, instruction-followingといった能力がどの程度保てているかを検証した研究。結果として4-bitまでの量子化であれば性能の劣化が見られないことを確認
- OpenAIのSuper aligment
	- https://openai.com/blog/introducing-superalignment
	- “Superintelligence will be the most impactful technology humanity has ever invented.”
	- Superintelligence "could lead to ... human extinction. ... We believe [superintelligence] could arrive this decade."
- 早速GPT-4Vに対抗するOSSであるLLaVAが登場
	-  LLaVA: Large Language and Vision Assistant
	- https://llava-vl.github.io/
	- Haotian Liu et al., "Improved Baselines with Visual Instruction Tuning"
	- https://arxiv.org/abs/2310.03744
	- お試しできる、https://llava.hliu.cc/
- How to build ChatGPT for your company data? by ABACUS AI
	- llama2を使うのが良いみたい　
	- https://x.com/Saboo_Shubham_/status/1710505571072278932?s=20
- 正則化項付き線形回帰は真の偏回帰係数を推定しているのか？
	- https://bob3.hatenablog.com/entry/2023/10/06/224133
	- 正則化項付き線形回帰（Ridge、LASSO、Elastic net）で真の偏回帰係数を推定できるのか？を実験してみました。
- RAGにおけるchankサイズについて
	- https://docs.google.com/presentation/d/18Z7H3WSncPzLOTHKZAj36w0E7HSGY78VkDooSzvvySE/edit#slide=id.g286c47b4bb8_1_0
	- More chunks ≠ better (lost in the middle problems / context overflows)
	- Reranking retrieved chunks doesn’t necessarily improve results, in fact can worsen them.
- Science Behind Why LLMs Can Easily Be Tricked And Are Predictably Gullible
	- https://x.com/bindureddy/status/1710504584496779675?s=20
	- while large language models exhibit impressive linguistic abilities, their lack of true understanding, combined with the intricacies of data-driven learning, makes them susceptible to errors and easy to fool.
- 新しいOSSのembeddingモデルgte-tinyが登場、OpenAIのtext-embedding-ada-002なみの能力をもちつつ、小さくて軽い
	- https://huggingface.co/TaylorAI/gte-tiny/tree/main
- OpenAI, "DALL·E 3 System Card"
	- https://openai.com/research/dall-e-3-system-card
	- DALL·E 3での安全対策
	- OpenAIは、DALL·E 3の論文を通して「画像生成AIの安全性は前進した」ことを報告
- Artificial Intelligence Index Report 2023
	- https://arxiv.org/abs/2310.03715
	- スタンフォード大学がAIに関する技術・法律・経済・環境・世論などの多角的なデータを収集してまとめた報告書「AI index Report 2023」をarxivに公開
- MSのDeepSpeedチームの基盤モデルの科学応用を目指したDeepSpeed4Scienceプロジェクト
	- https://deepspeed4science.ai/
	- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed4science/japanese/README.md
	- 科学的基盤モデル(SFM)とよぶらしい
	- ClimaXは、さまざまな気象および気候モデリングタスクを実行するために設計された最初の基盤モデルです
	- 分子動力学と機械学習型力場
	- 天気 from Microsoft Start
- Google ColabについにAI機能が来てる？
	- Proにしか来てないもよう。
- Best Practices for LLM Evaluation of RAG Applications A Case Study on the Databricks Documentation Bot
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- RAG（Retrieval Augmented Geneneration）の評価、特に"LLMを使った時代評価の観点"からベストプラクティス
- 様々なLLMが何ができるかの比較表 by llamaindex
	- https://docs.llamaindex.ai/en/latest/core_modules/model_modules/llms/root.html#llm-compatibility-tracking
	- ちょっと、llama2-7b-4bitが悲しい結果に。。
		- OpenAI models (gpt-3.5-turbo, gpt-3.5-turbo-instruct, gpt-4)
		-  Anthropic models (claude-2, Claude-instant-2)
		- llama2-chat-7b 4bit
		- Mistral-7b
- Microsoft、Nvidia GPU依存へのコスト削減につながるAIチップを来月デビューへ
	- https://texal.jp/2023/10/08/microsoft-is-developing-its-own-ai-chip-and-working-with-amd-to-stop-nvidias-monopoly/
	- 「**Athena**」１１月の開発者会議で発表予定？
	- NVIDIAのH100 GPUと同等に設計されている


## 10/2

今週は、いや、今週もいろいろありすぎて、消化しきれない。GPT-4V(ision) デビュー、画像理解とか、ついにLLMが眼を持った（カンブリア紀）、これってAGIの前触れ？　GPT-4V初期ユーザーからは、霞が関パワポを入力したり、天一のマークも「侵入禁止」標識と誤認識はしない、サイゼリアの「間違え探し」は苦手、という報告も。ChatGPTにもvisionや音声対話機能が来週からロールアウトする(Plus以上のユーザー）。Amazonは、生成AIのAnthropicに5900億円出資。Quoraが提供する [poe.com](http://poe.com) で試用できる。GoogleのGPT-4超えのGeminiは水曜(10/4)に発表される。LLMでLLMを評価するLLM-as-a-judge がはやり。一方OpenAIの次世代LLMであるArrakisはAGIだといううわさも（コードネームは「砂の惑星」からきている？？）。特許検索だけからウイルス薬を発見したり、過去データから安定な準結晶の化学組成をあきらかにしたりと、バイオ・材料系でLLMは大活躍。PFN の PLaMo-13B 、4 bit 量子化するとColab 無料版で動くぞ。機械学習により偏微分方程式を解く話、データから逆設計できるならば画期的すぎる。 Gaussian Splatをつかった三次元生成の論文とGitHub公開が同時に２か所で！。LINEのインターン生による量子化による大規模言語モデル軽量化の効果測定、ここまで６週間でできるのか。ChatGPTの検索プラグイン復活、どうも本来ペイウォールで守られている記事であっても全文が表示されてしまうという報告で停止してものに対策が打たれた模様。RAG関係の進捗も、時系列データやMergeRetrieverなど進展がある。

- Agents: LLMをつかった新しいagentフレームワークとツール軍
	- https://github.com/aiwaves-cn/agents
	- **Agents** is an open-source library/framework for building autonomous language agents. The library is carefully engineered to support important features including **long-short term memory**, **tool usage**, **web navigation**, **multi-agent communication**, and brand new features including **human-agent interaction** and **symbolic control**.
- llamaindexからneo4jを使ったグラフagent
	- https://llamahub.ai/l/tools-neo4j_db
	- The `Neo4jQueryToolSpec` class provides a way to query a Neo4j graph database based on a provided schema definition.
-  LLM Fine-Tuning (東大松尾研LLM講座 Day5資料)
	- https://speakerdeck.com/schulta/llm-fine-tuning-dong-da-song-wei-yan-llmjiang-zuo-day5zi-liao
- OSSのLLMはだGAFAMのLLMに勝ち目がいないかあるか？
	- https://x.com/bindureddy/status/1706092114063639035?s=20
	- OSSのLLMは、AIの民主化と透明性のためには必要という話
-  LLMを用いたLLMの自動評価について 〜可能性と注意点
	- https://engineers.ntt.com/entry/2023/09/25/091245
	- LLM-as-a-judge では、**人手評価に匹敵するクオリティの評価を、お金や時間、労力をかけずに機械的に行える**ことが期待できます。
-  Community-developed checklists for publishing images and image analyses(Nature)
	- https://www.nature.com/articles/s41592-023-01987-9
	- 画像や画像解析結果を報告する際のベストプラクティスに関するNature Methods誌の記事
	- 画像のフォーマットや注釈、色の選択、データの利用可能性、画像解析ワークフローの報告に関する重要な推奨事項が提供されています。
- OpenAIからGPT-4V(ision) が発表、ついでに品質カードSystem Cardも公開
	- https://cdn.openai.com/papers/GPTV_System_Card.pdf
	- GPT-4 with vision (GPT-4V) enables users to instruct GPT-4 to analyze image inputs provided by the user, and is the latest capability we are making broadly available. Incorporating additional modalities
	- 複雑な標識を読み取る、https://x.com/petergyang/status/1707169696049668472?s=20
	- サイゼリアの「間違えさがし」の正答率は１割、https://x.com/cumulo_autumn/status/1707574932153282728?s=20
	- GPT-4V vs. 霞が関　https://x.com/horromary/status/1707373718534824305?s=20
- 外部知識によりパーソナライズされた対話システム
	- https://www.jstage.jst.go.jp/article/jjske/22/2/22_TJSKE-D-22-00053/_article/-char/ja/
	- 様々な概念に対するユーザーの関心を推定し，知識グラフをパーソナライズする手法を用いて，雑談における共感性や情報提供を目指す
- ChatGPT(Pllusユーザー以上）に、来週から新機能をroll-outするとの発表
	- Voice Capabilities:
	- Image Interaction
	- New Text-to-Speech Model:
	- Collaboration with Spotify
-  Amazon、生成AI新興に5900億円出資　Microsoftに対抗
	-  Claude-2-100kは、Anthropicの最も強力なモデルで、コンテキストウィンドウが10万トークン（約75,000語）
	- ばっちり日本語にも対応しQuoraが提供する [poe.com](http://poe.com)  で実際に使ってみることができます。
- llamaindexのAuto Merging Retriever
	- https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_merging_retriever.html
	- 木構造で整理されたドキュメントに対して類似する枝から順にマージして見せるらしい。
	- RAGを評価する教師データをGPT4で生成する、DatasetGeneratorもついでに紹介。いわゆる、 LLM-as-a-judge の一種をlllamaindexがnativeサポートした
- 特許から分子データを抽出
	-  Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures
	- https://arxiv.org/abs/2309.08765v1
	- ChatGPTを使って特許から10万件の分子と関連するキーワードを高精度に抽出、このデータベースを学習したモデルからウイルス薬を逆探索するとそれっぽい分子を抽出できた
	- 特許分析だけから、、、
- ChatGPT-4V公開、iOSやAndroid版にも搭載、様々な評価が報告される
	- デモの画像と言語を交えたインタラクションは未来感ある。構造化文書を画像で見せてもある程度理解できる模様。
	- 人の見た目に対する言及など新たなリスクも評価・対策済みとのこと
	- 英語のほうがOCR精度が良いし色々試してるけど、シンプルな図表のReasoningはかなりできる。図表に含まれない背景情報も、GPT内部の知識で補えるのが強力。
- Calibrating LLM-Based Evaluator
	- https://huggingface.co/papers/2309.13308
	-  LLMベースの評価器の校正: 大規模言語モデル（LLM）を自然言語生成の品質評価に利用する方法を提案し，人間の評価との一致度を高めるための校正手法を提案する．
- Sam Altman氏、「社内内部的には、AGIは完成した」とtweet。
	- am Altman says "agi has been achieved internally" at OpenAI.
	- 噂ではOpenAIはArrakisという限りなくAGIに近いany-to-any modelを開発しており、サムアルトマンらしきアカウントがAGIの開発に成功した(追記: まぁ落ち着こうや) みたいなことを言ったという報告もある。
	- サンフランシスコで予定されている開発者会議（11/6）に何かしらの発表がある。
- 【続】Flash Attentionを使ってLLMの推論を高速・軽量化できるか？
	- https://qiita.com/jovyan/items/5716cd83e246df4a158e
	- 最近公開されたhuggingfaceから直接公式実装のFlash Attention2を使える機能（from_pretrainedでuse_flash_attention_2=Trueを指定）についても実験
- 『LogiCoT』GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク
	- "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"
	- 前提（Premise）、考え（Thought）、検証（Verification）について明確に指示する
- 統語的評価データセット JCoLA が https://huggingface.co/datasets/shunk031/JGLUEに追加
	- JGLUE の全てのデータセットがそろったらしい
- ChatGPT の検索プラグイン(Plus用？）が復活
-  Pair Programming with a Large Language Model
	- https://www.deeplearning.ai/short-courses/pair-programming-llm/
	- DeepLearningAIより、ショートコースが公開。LLMとペアプロとは
- llamaindexのTimescaleDBとの連携
	- https://medium.com/llamaindex-blog/timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0
- 大学における数理・データサイエンス・AI 教育 の中での統計科学の教育について（日本学術会議）
	- https://www.scj.go.jp/ja/info/kohyo/pdf/kohyo-25-k230926-24.pdf
	- (1) 数理・データサイエンス・AI 分野の理論的基礎としての統計科学の位置付け
	- (2) 数理・データサイエンス・AI 分野の再教育(リスキリング)の推進
	- (3) 学士課程及び大学院教育が必要とする統計教員の育成
	- (4) 初等・中等教育における教材、ソフトウェア、デジタル環境の整備と統計教育の さらなる充実
	- きっと、データサイエンティストが主人公のアニメが必要だと思うぞ。
- RAGをOSSだけで構築する方法(llamaindex)
	-  Building RAG from Scratch (Open-source only!)
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/oss_ingestion_retrieval.html
	- Sentence Transformers as the embedding model
	- Postgres as the vector store (we support many other vector stores too!)
	- Llama 2 as the LLM (through llama.cpp)
- Google Colab で Preferred Networks の PLaMo-13B を試すby npaka
	- https://note.com/npaka/n/n19ff9dd4a537?sub_rt=share_sb
-  機械学習アルゴリズムが発見した初めての準結晶(統計数理研究所）
	- https://www.ism.ac.jp/ura/press/ISM2023-05.html
	- これまでに合成されてきた準結晶や関連物質のパターンを読み解き、熱的に安定な準結晶を形成する化学組成を予測する機械学習技術を開発
- PFN の PLaMo-13B を 4 bit 量子化するとColab 無料版の T4 15GB でも推論できるらしい
	- https://colab.research.google.com/drive/1vgHInjIL5dJYoaIXL-s6ickbp3cwIQti?usp=sharing
- DreamGaussianが 無料Colabで試せる。5分ほどで完成
	- https://github.com/camenduru/dreamgaussian-colab
-  Mastering Customer Segmentation with LLM
	- https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41
	- テーブルデータをLLMのembeddingで数値化し、k-meansやt-SNEでクラスタの特徴を探る流れの良い解説記事
- デジタル庁のITコンサル/PM/週5日/一部リモート/デジタル庁IT支援の求人が話題に
	- 単価は、1,54万円/万
	- 体調が安定しており病欠が少ない方
- 機械学習により偏微分方程式を解く論文
	-  Neural Operators for Accelerating Scientific Simulations and Design
	- https://arxiv.org/abs/2309.15325v1
	- 入出力のマッピング演算子を学習するニューラル演算子。数値計算を高速化できるだけでなく、実験データからの学習や逆設計までできるそうです。
- ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning
	- https://huggingface.co/papers/2309.16650
	- ３Dの状況を概念モデルとして理解するための語彙を提供、これはメタファーの世界か。。
- Gaussian Splat＋三次元生成の論文が一つどころか二つ同時に出ているのが戦国時代っぽいところ
	- https://gsgen3d.github.io/
	- https://dreamgaussian.github.io/
	- Gaussian Splatting は、3D シーンを、ガウシアン関数で表された点群の集合として表現します。この点群の集合を、レンダリング時に、光線に沿ってサンプリングすることで、シーンをレンダリングします。
- lama_indexの AutoMergingRetrieverを図解した絵が素晴らしい
	- https://x.com/clusteredbytes/status/1707864519433736305?s=20
- OpenAPIの新しいinstructモデルでは、なにか機能が落ちた模様
	- OpenAI is removing the ability to evaluate P(completion | prompt) for user-provided completions to the `gpt-3.5-turbo-instruct` model.
- Google、新LLM　Geminiを 10月4日に発表か、
	- Gemini might be coming out on Wednesday
	- "plus few more surprizes"とinvitationに書いてあるらしい
-  7 Query Strategies for Navigating Knowledge Graphs With LlamaIndex
	- https://betterprogramming.pub/7-query-strategies-for-navigating-knowledge-graphs-with-llamaindex-ed551863d416
- 【インターンレポート】量子化による大規模言語モデル軽量化の効果測定
	- https://engineering.linecorp.com/ja/blog/quantization-lightweighting-llms
	- LINEの技術職 就業型コースのインターンシップ生の発表
	- 6週間程度のインターン期間らしい
	- FP8による影響まとめ
		-  大きなモデルで最大1.2倍の推論高速化
	- GPTQによる量子化モデルの効果測定
- StreamlitとGithub CodespacesでブラウザのみでChatGPT API開発をする
	- https://corp.langcore.org/media/codespaces

## 9/25

相も合わらず、RAG(Retrieval Augmented Generation)関係が多いのはご容赦。上位のLLM(GPT-4とか）をつかって正解をつくって、RAGを評価する仕組みとか、この評価の仕組みをつかって別のLLＭ(gpt-3.5-turboとか)をRAG向けにfine-tuningするなんてのが、e2e(end-to-end)の手法として当たり前になりつつある。「知識は樹木のようなもの」とのたまうスクエニの三宅さんの話はいつも面白い。SOPをつかったAgentsというのはagentの可制御性という意味で面白い。Transformers.jsをつかったWeb LLMの新手が登場。Xwin-LM-70BがGPT-4超えか？というのがもっぱらの話題。LLMが創造性を持つか？の論文での創造性の３つの基準（価値、新規性、驚き）って、特許提案と同じだよね、LLMが特許提案できるか？に置き換えても同じ。instructorというopenai function callingにpydanticを組み合わせられるライブラリ使ってみたい。RAGでもメタ情報抽出にpydantic使ったりとか、この辺りも定番化か。ChatGPTの知識が、2022年1月までの知識までアプデされた。LLMの利用サーベイ、「５位：ビジネス戦略立案」ってのは笑ったね。gpt-3.5-turbo-instructというのが出てるのね、コンパクトで、言語生成に適したモデル（チャット用ではない）、これはfine-tuning用なのか？？、LLM向けAI半導体「SN40L」ってのも期待。

- ちょっとした気配りで皆を幸せにする GitHub の使い方
	- https://qiita.com/squid-cat/items/7166317e60d3ff96ccb7
	- PR がレビューされない環境を作らない
- 米国のAI企業公聴会より、Nvidiaの証言が素晴らしい
	- https://x.com/Yampeleg/status/1703774531771363738?s=20
	- OpenAI: AI will kill us. 
	- Anthropic: AI will kill us. 
	- InflectionAI: AI will kill us. 
	- Nvidia: Fortunately uncontrollable Artificial General Intelligence is Science Fiction not reality.
- 知識と技術の継承としてのAI by スクエニ三宅さん
	- https://togetter.com/li/2226417
	- その分野の専門家が持つそういった知識体系が、その教授なり専門家の価値なわけであるが、実際のところ、近くにいて話しかけなければ、自分にとって価値あるものを引き出せない。だからこそ、研究室があり学生がある。しかし、そういった知の体系は、万人に開かれるべきだ
	- AIによって日々積み重なる論文や発表資料、講演録を吸収し、知の系統樹を作らせる。我々はそれが巨大な樹木となっていくのを見ながら、欠けているピースや来るべき枝葉を準備する
- Intel/Llama-2-70b-chat-hf-onnx-int4
	- https://huggingface.co/Intel/Llama-2-70b-chat-hf-onnx-int4
	- high-quality, INT4, ONNX models for all LLama2 variants (base vs. chat, 7B to 70B).
- Best Practices for LLM Evaluation of RAG Applications by DataBricks
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- Human and GPT-4 judges can reach above 80% agreement on the correctness and readability score. And if we lower the requirement to be smaller or equal than 1 score difference, the agreement level can reach above 95%.
-  Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?
	- https://arxiv.org/abs/2309.08963
	- structure-aware fine-tuning method, applied to Llama-7B, which significantly outperform other model like GPT-3.5/4 and Vicuna-13B.
- Azure Cognitive Search のハイブリッド+セマンティックランキングは、純粋なベクターサーチよりもパフォーマンス良かったそうで！
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/azure-cognitive-search-outperforming-vector-search-with-hybrid/ba-p/3929167
- "Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality"
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321
	- ① GPT-4ありの集団は以下のように優れていた ・タスクの完了数が平均で12.2%多い ・タスクの完了速度が平均で25.1%早い ・タスクの品質が平均で40%高い 
	- ② もともと成績のよくない人が目覚ましく向上した
- GPT-3.5-turbo を Fine-tuning して GPT-4 相当の性能を獲得する
	- https://tech.drobe.co.jp/entry/2023/09/19/140000
	- Lambda で GPT-4 を叩きつつ、入力と出力のペアを json 形式で Cloudwatch に落とします。
	- データをダウンロードしたらここを参考に Fine-tuning のデータの準備と validation を行います。
	- Fine-tuning の実施は簡単です。OpenAI の API を利用して以下を実施します。
		- 1.  トレーニングデータをアップロード
		- 2.  アップロードしたデータを指定しつつトレーニングを開始
	- Fine-tuning すると結果が GPT-4 に近づく事が観測できた
- Let's Verify Step by Step
	- https://arxiv.org/abs/2305.20050
	- LLMが複雑な問題を推論できるのは、学習中に推論方法（解き方）にアクセスし、その解き方を学んでいるからといえる
- 自律言語エージェントを構築するためのフレームワーク Agents を試す by npakaさん
	- https://note.com/npaka/n/n089614881df8
	- 「**Agents**」は、**自律言語エージェントを構築するためのフレームワーク**
	- 「**SOP**」(Standard Operation Process) を通じて言語エージェントにきめ細かい制御とガイダンスを提供できることです。「SOP」は**タスク全体のサブゴール / サブタスクを定義**し、ユーザーが言語エージェントのきめ細かいワークフローをカスタマイズできるようにします。
-  Benchmarking `gpt-3.5-turbo-instruct` on agents doing question-answering over tabular data
	- https://github.com/langchain-ai/langchain-benchmarks/blob/main/csv-qa/pandas_agent_instruct.py
	- It performed roughly the same as gpt-3.5-turbo (the chat model) with roughly ~67% accuracy
	- It errored twice due to misformatted output - without function prompting for output format becomes much more important
- StableDiffusionで生成した画像から3Dモデルを"AIで"作成し、Unity上でキャラクターを動かすまで【CSM AIの使い方】
	- https://note.com/okp_/n/n89b96384e0cb?sub_rt=share_b
- llamaindexのチュートリアル、“building RAG from scratch” -
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
- SambaNova、最大5兆個のパラメータモデルを実行可能なLLM向けAI半導体「SN40L」を発表
	- https://news.mynavi.jp/techplus/article/20230920-2775419/
	- Ceruleanアーキテクチャ。NVIDIA H100の24台分の性能で、GPUに搭載されてる様な高速メモリが不要でメモリ大容量化が可能！DDRが使える
- sam altman氏、DALE 3のデモ画像を自慢する
	- https://x.com/sama/status/1704561613070893428?s=20
- OpenAI本家で、Fine-tuning用のweb pageが公開された
	- https://x.com/OfficialLoganK/status/1704181284036300970?s=20
	- 誰でも簡単にモデルの微調整ができ
- JSONの可視化ツール jsoncrack
	- https://jsoncrack.com/
- GPT-4などの大規模言語モデルで化学研究を行うにあたっての､現状・課題・展望を整理した論文
	- Prompt engineering of GPT-4 for chemical research: what can/cannot be done?
	- https://www.tandfonline.com/doi/full/10.1080/27660400.2023.2260300
	- GPT-4は、化学研究における言語処理やドメイン知識の組み込みに有効なツールとなり得ます。
	- 以下が必要
		- 分子構造や実験データを扱えるようにするためのプラグイン
		- マルチモーダルモデルの開発最新の化学情報を学習できるようにするためのローカルモデル
		- 推論や計画能力を向上させるためのアルゴリズムやハードウェアの革新
- llamaindexにて、RAGにおいて、カスタムプロンプトをつかったQueryを使う方法、
		- RAGStringQueryEngineというので、任意のpromptを投入できる？！
		- なるほどこれは役に立つ
		- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/custom_query_engine.html
- An in-browser version of ChatGPT (or HF Chat), built with HuggingFace Transformers.js!
		- https://huggingface.co/spaces/mithril-security/blind_chat
		- webllmとは違ったブラウザベースのlocal LLM実装、transformer.jsかあ、そっちからHF使うんだ。
- RSJ2023「基盤モデルの実ロボット応用」チュートリアル2（松尾研）
	- https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa
	- 日本ロボット学会 [#RSJ2023](https://twitter.com/hashtag/RSJ2023?src=hashtag_click) の「基盤モデルの実ロボット応用」セッションのチュートリアル（後半）の資料
	- 基盤モデルの特徴を整理したあと，ロボティクス領域での基盤モデルを構築し活用する方法に関してサーベイ
- **Building RAG with LLMs and Prompts**　by **Jerry Liu, LlamaIndex**
	-  @FlowGPTOfficial workshop today I gave talks on how to build RAG response generation and a simple router module using only LLMs and prompt
- llamaindexのRAGにおける、類似検索語のpost processing様々、順番変えるとかありなのか・
	- https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/node_postprocessors/modules.html#longcontextreorder
-  LLMが持つ/持たない/持ちうる創造性についての論文
	- On the Creativity of Large Language Models
	- https://arxiv.org/abs/2304.00008
	- ボーデンの３つの基準（価値、新規性、驚き）や他の哲学的理論に基づいて、LLMの創造性を検証
	- LLMは価値を持つ作品やアイデアを生成することができますが、新規性や驚きについては弱い
	- LLMは人間と同じような創造性を持っているとは言えません
	- 異なる学習方法や適応能力を持つモデルを開発することで、探索的や変革的な創造性を実現することができるかもしれません
	- LLMは人間と協働することで、人間の創造性を補完したり刺激したりすることができます
-  RAG is more than just embedding search
	- https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/
	- シンプルなベクトルサーチベースの課題を述べながら、instructorというopenai function callingにpydanticを組み合わせられるライブラリを紹介している記事
	- 課題の一つ、-   **Query-Document Mismatch**:ドキュメントと質問のembbedingって同じ空間でないと意味ないよね（地産地消の場合を除く）
- Xwin-LM-70BがGPT-4超え？
	- https://www.itmedia.co.jp/news/articles/2309/21/news085.html
	- Xwin-LMは米Metaが公開したAI「Llama2」をベースにしており、教師ありファインチューニング、報酬モデル、リジェクトサンプリング、強化学習などを使って調整したものという。パラメータ数はLlama2と同じく70億、130億、700億の3つのモデルを用意。中でも最大である700億の「Xwin-LM-70B-V0.1」は、AlpacaEvalの評価基準である「Text-Davinci-003」（GPT-3のモデルの一つ）に対する勝率で95.57％を記録。勝率95.28％のGPT-4を追い抜いたとしている。
- ChatGPTの知識が、2022年1月までの知識も反映した模様
	- https://old.reddit.com/r/ChatGPT/comments/16m6yc7/gpt4_training_cutoff_date_is_now_january_2022/
- e2e(end-to-end) LLM/RAG、RAG評価を含めてLLMでやるという話、について
	- raysummit2023でのチュートリアル、jupyternotebookあるよ
	- https://github.com/anyscale/ray-summit-2023-training/blob/main/Ray-LlamaIndex/notebooks/02_evaluation.ipynb
- RAGを構成するときに、メタデータを与えるってのは役に立つわけだが、それをPydantic ＋LLMで一発でできるという話、
	- extract a full Pydantic object from any doc with 1 LLM call.
	- https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/PydanticExtractor.html
- Text generation web UI で Xwin-LM-13B をロードして色々推論して遊んでみます。
	- https://note.com/sa1p/n/n51170c4d1a1f
	- 「Text generation web UI」は、oobabooga氏による**大規模言語モデル用の無料のWeb UI**
	- ただし、ローカルに、GPUなどが必要**Windowsの場合NVIDIA製のグラボでのみ動作する**
- Exploring ReAct Agent for Better Prompting in RAG Pipeline
	- https://betterprogramming.pub/exploring-react-agent-for-better-prompting-in-rag-pipeline-b231aae0ca7c
	- use ReAct Agent to analyze Amazon's recent disclosures and attitudes towards LLMs in their SEC Exhibits 99.1 filings
- RAGの評価、正解と答えとの比較評価で、従来のBLEU/ROUGEとかでなくて、単に類似性評価でよいという簡易は方法を提示
	- https://gpt-index.readthedocs.io/en/latest/examples/evaluation/semantic_similarity_eval.html
- OpenAI謹製の、RAG(Q&A)のチュートリアル
	- https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
- BQMLの時系列分析、ARiMAを適当なラグ設定のもとで40モデルほどぺぺっと推定してくれて、かつAICも推定してくれるので鬼便利
	- https://x.com/behemuhemulove/status/1705629318439907451?s=20
- LLMって何に使われているかのサーベイ
	- https://x.com/dmvaldman/status/1705350469177295273?s=20
	- １位：プログラムのエラーと解消法について、２位：AIのソフトウエアについての質問、３位：旅行関係、４位：テキスト要約とか改善、５位：ビジネス戦略立案
- GPT-3.5-Turbo-Instruct
	- https://chatgpt-lab.com/n/n2ed70597dfbf
	- 既存の「GPT-3.5-Turbo」とは違ってチャットに特化したモデルではないため、モデルが広範な自然言語処理タスクを扱うことを可能にします
	- OpenAIのテストでは、175Bのパラメータを持つGPTモデルよりも、1.3Bのパラメータを持つInstructGPTモデルの方が、100倍小さいにもかかわらず、人々に好まれることが示されている

## 9/19

GPT-4を活用して、データセットをつくって、他のＬＬＭをファインチューニングするとか、色々出ているが、MetaやAppleがGPT-4越えのLLMを来年に向け開発中。Appleが出遅れているのは、自動運転とかそっちにリソースを割かれているかとも、でもM2もっているし、ポテンシャルはある。あほなSiriの代わりになるのか？。RestGPTは、ReActの発展形、「APIの理解」ってのができるらしい。やっぱり企業利用ならば、RAG(Retrieval Augmented Generation)関係で、元となるテキストのチャンキングの仕方とか、ベクトルＤＢの選び方とか、スクラッチからのRAGの作成とか、地道活動も拾ってます。AstroLLaMA、今後様々なタスクや分野に特化したLLMがどんどんできてくるかも。LiteLLMっていうLLMの抽象化を使うと、アプリコードが再利用できるのか、作った人天才。GPT4による生産性向上にういての定量評価、資料として色々使えるな。仏教対話AIって、聖人をどれだけ復活させても幸せになれない気がする。きっと故人のChatBot作成サービスって葬儀業界ですぐにでも出てきそうだ。いや、2021年にマイクロソフトが[特許化していた](https://edition.cnn.com/2021/01/27/tech/microsoft-chat-bot-patent/index.html)。。


- Meta、GPT-4と同程度の性能を目指すモデルの学習を計画
	- https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple
	- AIトレーニングチップを買い集め、データセンターを構築
	- 2024年の早い時期に新しい大規模言語モデルの学習を開始する予定
	- 企業がAIツールを作成するために、再びこのモデルを無料にするよう働きかけている
- Fine-tuning to Memorize Knowledge
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_knowledge.html
	- GPT4で、内部ドキュメントに対する、Q&Aを生成させてこれをつかって、LLMをファイチューニングする話。
	- “bake in knowledge”と呼ぶらしい。
- OpenIntepreterを使っていると、OpenAIのAPIコールで10ドルが一瞬で溶ける。（デジタル庁楠さん）
	- https://x.com/masanork/status/1701381113506329083?s=20
	- つまり、ChatGPT Plusの月額課金が気前いいことになっている。
-  RestGPT: Connecting Large Language Models with Real-World RESTful APIs
	- https://restgpt.github.io/
	- ReActの発展形か、、
	- https://zenn.dev/carnot/articles/7f87b613a0a637
		- **言語のみの指示から複数のAPIを呼び出すことが可能**
		- RestGPTではプランニング・APIの理解・APIの選択をそれぞれのモジュールが独立で行うため、複雑なユーザ要求にも柔軟に対応することが可能になっています。
- 来年にはGPT-4を上回る能力を持つとされる３つのモデル
	- ① OpenAI: GPT-4.5/GPT5 
	- ② Google: Gemini 
	- ③ Apple: Ajax
	- Apple is reportedly spending ‘millions of dollars a day’ training AI
	- https://www.theverge.com/2023/9/6/23861763/apple-ai-language-models-ajax-gpt-training-spending
- 仏教対話AIの多様化に成功―親鸞ボットと菩薩ボットの増産―(京大）
	- https://www.kyoto-u.ac.jp/ja/research-news/2023-09-12-0
	- 生成系AI「ChatGPT 4」と宗教を掛け合わせた新型チャットボット「親鸞ボット」と「世親ボット」を共同開発し、仏教対話AIの多様化に成功しました。
	- [会話事例](https://www.itmedia.co.jp/news/articles/2309/14/news083.html)が、地獄にしか見えないのは気のせい？
- リクルートにおける数理最適化の 活用事例と産学連携の取り組み
	- https://speakerdeck.com/recruitengineers/rikurutoniokerushu-li-zui-shi-hua-no-huo-yong-shi-li-tochan-xue-lian-xi-noqu-rizu-mi
	- 企業における数理最適化専門グループって、大変なのよね。
-  生成AIブームで多発の可能性　「PoC貧乏」
	- https://forbesjapan.com/articles/detail/65744/page2
	- 「生成AIで何かビジネスを作ってみて」と上層部が丸投げし、成果が出ないまま人件費がかさむ、ゆるやかなPoC貧乏が頻発することが考えられます。
	- まあ、生成AIに限らないわけだが。。
- Calls out of chaos: the adaptive significance of nonlinear phenomena in mammalian vocal production
	- https://www.sciencedirect.com/science/article/abs/pii/S0003347201919128
	- 赤子の泣き声がカオス的なダイナミクスで、複雑さと予測不可能性によって親に無視させないようにする適応的意義があるらしい
- 自然言語処理で扱うテキストのchunkingについて
	- https://zenn.dev/hijikix/articles/f414b067e29a57
	- Adjacent Sequence Clustering
	- 全体の文章をセンテンスに分割した後、チャンクに詰めていくのだが、その際に直前のセンテンスと処理中のセンテンスの意味的類似度を比較して、意味が離れているものは次のチャンクに詰める
- llamaindexのRAG作成チュートリアル（ローレベル）
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
	- ローレベルというのは、プリミティブな処理で構成するという意味。
- llamaindexのResponseの作り方
	- Building Response Synthesis from Scratch
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/response_synthesis.html
	- promptをカスタマイズできるのが素敵。
- Vector databases (Part 4): Analyzing the trade-offs
	- https://thedataquarry.com/posts/vector-db-4/
	- ベクトルDBのトレードオフを分析した記事。挿入vs読取速度、取りこぼし（Recall）vsレイテンシー、インメモリvsオンディスク、全文検索vsベクトルハイブリッド検索等の観点から比較・分析を実質
- AstroLLaMA: Towards Specialized Foundation Models in Astronomy
	- https://arxiv.org/abs/2309.06126
	- 特定分野に特化したLLMが大量発生する予感。
- 東京都の 「文章生成AI利活用ガイドライン」
	- https://www.metro.tokyo.lg.jp/tosei/hodohappyo/press/2023/08/23/14.html
	- プロンプトの具体例も豊富でわかりやすい
- llamaindexがLiteLLMをサポート、＋１００のLLｍが利用可能に？？
	- https://gpt-index.readthedocs.io/en/stable/examples/llm/litellm.html
	-  (OpenAI, Cohere, AnthropicAI, huggingface, etc.)に対して同じインターフェイスを提供。
	- というか、LiteLLMすごいな。
- Announcing the Preview of OpenAI Whisper in Azure OpenAI service and Azure AI Speech
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/announcing-the-preview-of-openai-whisper-in-azure-openai-service/ba-p/3928388
	- Azure OpenAIサービスおよびAzure AI SpeechでのOpenAI Whisperのプレビューを発表しました
- Discover the LLMs
	- https://llm.extractum.io/
	- LLM の VRAM や Context Len が一覧表示できて便利
- BCGとハーバードやMIT等によるGPT4を使用したタスク実験
	-  Centaurs and Cyborgs on the Jagged Frontier
	- https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged
	- BCGのコンサルティング758名で実験 
	- 18種類のコンサルタスクが対象 
	- AIを使用したコンサルは 、12.2％多く仕事を終え、 25.1％早く仕事を完了し、 40％高い品質
-  Optimizing LLMs From a Dataset Perspective
	- https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html
	- LLMsの最適化について、データセットの側面からまとめたブログ。人手で高品質なデータセットを作るグループや、LLMから大量のデータセットを生成するグループなど、いくつかの側面が簡潔にまとまっている
- InstaGraph
	- https://github.com/yoheinakajima/instagraph
	- 任意のドキュメントから知識グラフ作れるらしい。
	- 例：https://x.com/yoheinakajima/status/1701351068817301922?s=20

## 9/11

8/23に公開されたGPT-3.5-turboのfine-tuning API、RAGとの比較、証券報告書のQ&Aアプリの具体例、など、面白い記事がたくさん出てきた。Open Interpreterも相も変わらず熱い。デジタル庁のChatGPTの業務利用ハンズオン、いいな、こういうリテラシーを持てる人が増えないと。。大規模コンテンツ・行動モデル（LCBM）って、記号接地問題にさらに近づこうとしているのか？LLMをつかった様々なエージェントの作り方、いろんなデータ専門のエージェントがたくさんそろってくると、そろそろOrchestratorが必要かな。**Production-Ready LLM Applications**ってのは必読なスライドですね。ICML2023のまとめもあった。RAGを対象としたLLMの比較、フレームワークになってありがたい。ChatGPTの複数出力とか、性能が落ちたのでは？という疑惑など、何が起きているのか、起こそうとしているのか。

-  東京大学理学部オープンキャンパス2023 講演「生成型AIの数理と倫理」佐藤一誠教授
	- https://www.youtube.com/watch?v=n6NDlgJVug8&t=5s
-  Mustafa Suleyman on getting Washington and Silicon Valley to tame AI
	- https://80000hours.org/podcast/episodes/mustafa-suleyman-getting-washington-and-silicon-valley-to-tame-ai/
	- DeepMindの共同創業者で、世界最高水準のAIスパコンを構築中のAI開発会社「Inflection AI」の設立者でもあるスレイマン氏によれば、今後18ヶ月程度でGPT-4の学習に使用された計算回数の10倍〜100倍がAIモデルの学習に使用され、次の3年程度でGPT-4の1000倍の計算回数が学習に使われるだろう、とのこと
- LangChain Cheat Sheet
	- https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html
- llamaindexより、Summary Index(旧List Index)の紹介
	- https://gpt-index.readthedocs.io/en/stable/core_modules/data_modules/index/index_guide.html#summary-index-formerly-list-index
- AI Agents – Build and Host LLM Apps At Scale
	- LLMを活用さいた様々なエージェントの作り方についての記事、なるほど
	- https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/
- Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior
	- https://huggingface.co/papers/2309.00359
	-  **大規模コンテンツ・行動モデル（LCBM）とコンテンツ・行動コーパス（CBC）**：本文書では、行動トークンをLLMの訓練に再導入する初期的な試みを行う。LCBMと呼ばれる新しいモデルは、コンテンツ理解タスクにおいてLLMと同等の性能を示すとともに、行動シミュレーション、コンテンツシミュレーション、行動理解、行動ドメイン適応といった能力も持つ。さらに、LCBMの研究を促進するために、コミュニケーター、メッセージ、受信者行動を含む新しいコーパスであるCBCを公開する。
- ChatGPTを業務に組み込むためのハンズオン
	- デジタル庁が一般公開しているChatGPTの入門
	- https://www.digital.go.jp/assets/contents/node/information/field_ref_resources/5896883b-cc5a-4c5a-b610-eb32b0f4c175/82ccd074/20230725_resources_ai_outline.pdf
	- なかなかのやり手が書いている、ここまで試行できる人は少ないのでは？？
	- プロンプトの書き方のコツ
		- できる限りコンテキストを明確にして書くこと
		- GPTの理解度(?)を確認しながら進める
		- 最初はマニュアルを読むより、まず自分でやってみて感覚をつかみことを推奨
- 最近のLLMの学習法のまとめ - SFT・RLHF・RAG　by npakaさん、
	- https://note.com/npaka/n/n862786604dc3
	- とりあえず、どれだけ知ってる？だけでもリトマス試験紙になる、むろん私はRAG派
	- SFT : Supervised Fine-Tuning
	- RLHF : Reinforcement Learning from Human Feedback
	- RAG : Retrieval Augmented Generation
- LangChain を使ったRAGを Elyza 7b instruct モデル
	- https://note.com/alexweberk/n/n3cffc010e9e9
	- 無料のT4ではメモリーオーバーで動かないんだが。。。
- SEC Insights
	- llamaindexを活用して、米国証券取引委員会への報告書(SEC-10)にたいするQ&Aアプリを作る例
	- https://github.com/run-llama/sec-insights
	- https://www.secinsights.ai/
-  Streamlit 入門  by npakaさん
	- https://note.com/npaka/n/n29b5e8088fe5
	- 「Streamlit」は、機械学習およびデータサイエンスのためのWebアプリケーションフレームを簡単に作成して共有できるPythonライブラリ
	- もうちょっとどうにかならんのか？
- **Production-Ready LLM Applications**
	- llamaindexのCEOより、
	- https://docs.google.com/presentation/d/1uzhz1aFWbyXSrWBzQ1FPQWtVjMgJqAYGoGoVzEnNmAg/edit#slide=id.p
		-  Fine-tuning: LLMs + embeddings
		-  Better Data + Retrieval Techniques for Production RAG
- ELYZA-7bは、M1 MacBook Airでもサクサク動くらしい
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf/blob/main/README.md
- やっぱりOpenInterpreterが熱い
	- https://github.com/KillianLucas/open-interpreter
- LLMをホストするAnyScaleのllamaindexでの利用例
	- https://gpt-index.readthedocs.io/en/latest/examples/llm/anyscale.html
	- run + finetune open-source LLMs through an API
	- そういうビジネスができるのか。。
-  Fine-Tuning GPT-3.5 RAG Pipeline with GPT-4 Training Data
	- https://betterprogramming.pub/fine-tuning-gpt-3-5-rag-pipeline-with-gpt-4-training-data-49ac0c099919
	- どうも、8/23にOpenAIがGPT-3.5-turboのfine-tuning APIを公開して、即座にllmaindexがこれに対応したらしい
	- じゃあ、Q&Aアプリを作るのに、RAGとFine-tuningどちらが高性能か？ということへの考察記事
	- こちらは、llamaindexをつかったGPT-3.5-turboのfine-tuningのcolab
		- https://colab.research.google.com/drive/1NgyCJVyrC2xcZ5lxt2frTU862v6eJHlc?usp=sharing
- Hierachical Agent	
	- 対象ドキュメントの内容が階層構造であるような場合のQ&Aの作り方。
	- https://colab.research.google.com/drive/1qIb09SyuLeiwGy_FGcRcQpM78yQ2p0_3?usp=sharing
- Discover LlamaIndex: Custom Tools for Data Agent
	- https://www.youtube.com/watch?v=lcuL6Gqw_-g
- 【速報】OpenAI APIでGPT-3.5-turboがfine-tuningできるようになりました！
	- https://dev.classmethod.jp/articles/openai-gpt35turbo-fine-tuning/
	- 学習するサンプルは最小10個必要で、50～100個で明確な改善が見られる
	- gpt-3.5-turboでfine-tuningが利用可能に
	- gpt-3のモデルであるbabbage-002とdavinci-002も新しいfine-tuningでサポート（モデルもGPT baseという扱い）
- グラフニューラルネットの 2023年まとめ (ICML2023)
	- 軽量 Transformer の介入や Diffusion for Molecules などの実世界利用、幾何学的な利用が記載されている
	- https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc
- Open Inerpreterの利用例、「nikkei225の10年分をプロットして」と滅入れすればあとは自動で、、、
	- https://twitter.com/NuCode/status/1700679106814501132?s=20
- ChatGPTが、可能性のある答えを複数ていじするようになった、RLHFやらせようとしているのかと話題に
	- https://twitter.com/GrantSlatton/status/1700662574315090351?s=20
- LLMの評価、特にRetrieval Augmented Generation (RAG) パイプラインを評価するためのOSSフレームワークragas
	- https://github.com/explodinggradients/ragas
- Agent deconstructedに、llmaindex agentが統合された？
	- https://github.com/shoggoth13/agents-deconstructed/blob/main/notebooks/react_chat.ipynb
	- ReActができるようになったのか。。、いろんなindexをもつLLM同士が会話して問題解決。。
- 【デモ付き】Embeddingsで独自データをChatGPTに理解させる
	- https://corp.langcore.org/media/embeddings
	- LangCore SaaSを使ってインフラ不要で手軽にEmbeddingsを活用した独自データの活用、らしい

## 9/4

GoogeからGPT-4対抗のGeminiが発表、GPT-4 の 2023 倍の計算能力を持つ？。LLMのファインチューニング関係で、様々な紹介がある。llamaindex周りの記事が多いが、それだけRAG(Retrieval-Augmented Generation)って需要があるということか。Embeddingもしっかり性能評価やファインチューニングすると性能があたる。llamaindexでQ&Aの性能を上げるためのTipsが詳しく書いてある、これは役立つ。ローカルLLMの試行も熱い、なんとCode interpreterもどきも動くという。最近のLLMでは、ELYZAが一番の模様(by shi3z)。理論関係では、transformerにおける自己注意はSVMと等価なのか？、確率過程の新刊も気になる。

- LLMのファインチューニング で 何ができて 何ができないのか
	- https://note.com/npaka/n/nec63c01f7ee8
- code llama がhuggingfaceのchatに登場
	- https://huggingface.co/chat/
- Llamaで、出力を指定するためのgrammar-based sampling
	- https://python.langchain.com/docs/integrations/llms/llamacpp#grammars
- Google 「Gemini」は、ChatGPT-4 Enterprise プラットフォームの直接の競合相手
	- https://www.theinformation.com/articles/the-forced-marriage-at-the-heart-of-googles-ai-race
	- GPT-4 の 2023 倍の計算能力を持つ
- llamainexでembeddingをファインチューニングする
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html
-  論文紹介 / Llama 2: Open Foundation and Fine-Tuned Chat Models　by NTT西田さん
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
-  ご家庭用LLMでストリーミングする方法
	- https://note.com/shi3zblog/n/n66ae41af7c64
	- "elyza/ELYZA-japanese-Llama-2-7b-instruct"　利用
-  LlamaIndexの性能向上のためのテクニックガイド by npaka
	- https://note.com/npaka/n/n33e28a9e1409
-  Discover LlamaIndex: Introduction to Data Agents for Developers
	- https://www.youtube.com/watch?v=GkIEEdIErm8
	- first-ever video tutorial on LlamaIndex Data Agents
-  ChatGPT vs BERT：どちらが日本語をより理解できるのか？
	- https://fintan.jp/page/9126/
-  LlamaIndex の QAプロンプト と Refineプロンプト のカスタマイズ
	- https://note.com/npaka/n/ne878095d5bda
- llama2-13b-128k、論文を全部理解して要約を吐き出す方法
	- https://gist.github.com/alfredplpl/33fd6dd6d623d4da959f1ca8aabc88fe
- 「データ分析のための統計学入門」
	- http://www.kunitomo-lab.sakura.ne.jp/2021-3-3Open(S).pdf
- 【ローカルLLM】text-generation-webUIのAPI機能を試す
	- https://note.com/bakushu/n/na4e51d377ae7
	- LLM用のウェブUIであるtext-generation-webUIにAPI機能が付属しているので、これを使ってExllama＋GPTQのAPIを試してみた。
- 最近のLLMの性格 by shi3z
	- https://twitter.com/madyagi/status/1697949115190255951?s=20
	- ELYZAが良いみたい。
-  Transformers as Support Vector Machines
	- https://arxiv.org/abs/2308.16898
- fine-tuned a gpt-3.5 ReAct agent to be better at chain-of-thought
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/react_agent/react_agent_finetune.html
-  機械学習のための確率過程入門
	- https://www.ohmsha.co.jp/book/9784274231087/
-  ローカルPCのターミナル上でLLM生成コードを実行できるOpen Interpreterを試す
	- https://note.com/hamachi_jp/n/n05ae28b76d9d
	- ChatGPTのコードインタープリター（Advanced Data Analysis）と同様な機能をローカル環境で実行可能な Open Interpreter 
	- llamaに差し替えることも可能
- 

## 8/28

先週発表された、松尾研の“Weblab-10B”に対する量子化やローカル環境での実行も花開くが、やっぱり今週はメタによるCode Llamaの発表がポイントになっている。
「LLM によるプログラムベース推論」的な考え方ってLLMをつかったアプリ作成には絶対必須な考え方になると思う。品質保証では、ガードレールとか、推論過程のガイドが必要だったり、得手不得手をちゃんと理解したうえでガイドするみたいな感じ。emergent機能とはLLMを動かしていて、予測していたのとは違う機能が創発するという話、欧州ＡＩ規制でも言及される、仕組みの解明と対策が急務。llamaindexから、外部検索と組み合わせる新しい、Metaphor機能がリリース。なんかどこのURLを見ればよいかのDBをつかってやるみたいな感じ。。HuggingFaceでは、LLMをWebベースで、ファインチューニングできる機能が公開されたらしい。結果はそのままHuggingFaceに乗るみたいなノリ。LLMをつかったQ&AであるRAGフレームワークで、類似データをtop-kでとってくる仕組みがうまくいかないときの工夫など、納得感ある。メタからCode Llamaが発表、コード生成ができる。さっそく、量子化されたり、llama.cppでローカルに動かしたりと、あっというまに、誰でも使えるようになる。コミュニティはすごいな。理論面では、emergentスキルに関して、通常の汎化理論に反する「スリングショット汎化」の提唱、ＬＬＭをつかった帰納的学習法というのも、従来の予測を書き換えるか。ＡＩ規制に対するパブコメをＡＩで分析など面白いかも。。

- 言語モデルにおける複雑なスキルの創発に関する理論　A Theory for Emergence of Complex Skills in Language Models
	- https://note.com/daichi_mu/n/n72b6265b09f6
	- 言語モデルのスケールアップに伴う新たなスキルの出現について、統計的枠組みと数学的分析を用いて分析する。能力レベルが通常の汎化理論に反する「スリングショット汎化」の概念を導入
- LLM によるプログラムベース推論
	- https://speakerdeck.com/smiyawaki0820/2023-dot-08-dot-07-geography-and-language-mian-qiang-hui-number-4
	- LLM 開発における評価・品質担保に関係、ガードレールや、推論過程のガイドなど最後はVisProg紹介
	- 東北大の宮脇さん、地理空間情報をLLMをつかいながら推論する仕組みについて。
- AIが「理解」するから、API仕様書のコピペでアプリができあがるローコード開発環境「Flowise」
	- https://internet.watch.impress.co.jp/docs/column/shimizu/1523766.html
- **[chatux-server-llm](https://github.com/sotokisehiro/chatux-server-llm)**
	- ローカル環境で動作する文章生成 AI チャットボットです。 CPU だけで動作します。
	- LINE の japanese-large-lm-3.6b-instruction-sft を CTranslate2 化
- Vicuna 13B v1.5 、text-generation-webui じゃなくて以前試作した llama.cpp の HTTP サーバー機能を使ってみたら普通に LLaMA 2 13B と遜色ない結果出してくれた
	- https://twitter.com/izutorishima/status/1693468524222861589?s=20
- Metaの大規模言語モデル「LLaMA」のトレーニングにも使用されたAIの学習用データセット「Books3」が削除される
	- https://gigazine.net/news/20230821-books-3-ai-data-set/
	- 知的財産権や著作権に対する侵害の疑いが指摘されていたらしい
- LlamaIndex + Metaphor: Towards Automating Knowledge Work with LLMs
	- https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f
	- Metaphor was trained to predict links on the internet, given how people talk about things on the Internet
	- インターネット検索とllamaindexの融合？結合の新たな形としてのメタファー？
- 【ローカルLLM】Gradio+CTranslate2で日本語LLMのチャットUIをつくる
	- https://note.com/bakushu/n/nba6e9c353ee4
	- [line-corp-japanese-large-lm-3.6b](https://huggingface.co/line-corporation/japanese-large-lm-3.6b-instruction-sft)を利用
	- CTranslate2で量子化
	- あとはgradioでWebUI生成！
- Generally Intelligence社、米国商務省国家電気通信情報庁（NTIA）が実施したAI規制に関するパブリックコメントの約1450件の回答の分析を開始。
	- https://generallyintelligent.com/perspectives/ntia-rfc-analysis/
	- https://twitter.com/kanjun/status/1693819078866354376?s=20
- llamaindexのMetaphorサーチのお試しができるらしい。
	- https://twitter.com/jerryjliu0/status/1693773766797746649?s=20
	- https://colab.research.google.com/drive/1PTnJTVmLAI-V8JJu8GsbUvbk8vs203kA?usp=sharing
- Stanford大学のHAIから、Create AI Actを連邦政府が法案をとおすべきである、米国のため
	-  We Must Pass the Create AI Act
	- https://hai.stanford.edu/news/we-must-pass-create-ai-act?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202308220803_sf181078680&utm_campaign=&sf181078680=1
- Open AI でスーパーアライメントを4年以内に完了させることを目標として率いているJan Leike氏の対談
	- https://80000hours.org/podcast/episodes/jan-leike-superalignment/
-  Inductive-bias Learning: Generating Code Models with Large Language Model
	-  **帰納的学習法**：大規模言語モデル（LLM）を用いて、説明変数から目的変数を予測するモデルを生成する新しい学習法。この学習法は、教師あり学習とメタラーニングの要素を持つ。
	- https://arxiv.org/abs/2308.09890
-  日本語が使えるようになったGoogle PaLM2を試す
	- https://note.com/eurekachan/n/n62b15394b5dc
	- BigQuery のSQLなんかも日本語で生成をお願いすることが出来ます。
	- LangChainからも呼び出したりできるようです
- ANYONE can fine-tune (almost) any LLM available on Hugging Face
	- Hugging Faceで簡単にLLMをファインチューニングできるAPIが公開
	- https://twitter.com/abhi1thakur/status/1693619860050153958?s=20
- RAGシステムで、top-k 抽出がうまくいかないときの工夫について
	- https://twitter.com/jerryjliu0/status/1694013501323563101?s=20
	- Metadata Filters + Auto Retrieval:
	- Store Document Hierarchies (summaries -> raw chunks) + Recursive Retrieval
- 今村・松井の『ベイズ最適化』
	- 第4章までよめらば、ベイズ最適化が理解できるらしい。
	- https://www.kindaikagaku.co.jp/book_list/detail/9784764906631/
- メタが、Code Llamaを公表
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/
	- Foundation base models (Code Llama) 
	- Python specializations (Code Llama - Python), 
	- Instruction-following models (Code Llama - Instruct)
- 【ローカルLLM】Colabの標準GPUで「CodeLlama-34B-GGUF」を動かす
	- https://note.com/bakushu/n/n21cb30a15f27
	- 量子化は「GPTQ」ではなくて、CPU＋GPUで実行できる「GGUF(旧GGML)」
	- 標準GPU（Tesla T4）で動くのがみそ
- Weblab-10Bを量子化(GPTQ)して簡単に動かすことがhugging faceでできる
	- transformersにGPTQが統合されたおかげで、無料Colabでそのままでは動かなかったWeblab-10Bもらくらく動くようになってた。
	- dahara1/weblab-10b-instruction-sft-GPTQ
	- https://github.com/webbigdata-jp/python_sample/blob/main/weblab_10b_instruction_sft_GPTQ_sample.ipynb
- 【まとめ】Google Colab で Code Llama を試す
	- https://note.com/npaka/n/n51ed424b2943
- CodeLlama model now work w/ llama-cpp-python
	- [@TheBlokeAI](https://twitter.com/TheBlokeAI)さんによる
	- llama.cpp GGUFの組み合わせで動くということ
	- https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-GGUF/tree/main
	- https://github.com/abetlen/llama-cpp-python
- CodeLamaの、colabでの実行とビデオ
	- https://colab.research.google.com/drive/1lyEj1SRw0B9I2UUI2HOrtiJ_fjvbXtA2?usp=sharing
	- https://www.youtube.com/watch?v=rlCe_lG4uhk

## 8/21
暑くて溶けそうなのに、電力はどうにかもっている夏です。松尾研からの国産LLMである“Weblab-10B”の発表。なお、松尾研には夏休み中の総理も訪問され講座を受講（なにか修了証書をもらってたな）、もっと国としてのサポートが期待できるかも。GPT-4は、暗号化されたプロンプトも理解できるぐらい優れているらしいが、特定の「脱獄プロンプト」に弱い面も。Trustworthy LLM、LLMの信頼性などの研究も進む、社会規範への整合とかそういう側面もある。スタンフォード大学のLLMの安全性のベンチマークとの比較も気になる。あいもかわらず知識グラフ系のLLM応用がちらほら、知識グラフ抽出や知識グラフをつかったRAG(Retrieval-Augmented Generation)などもあるが、知識の活用かそれともファインチューニングか？みたいな第２世代(エキスパートシステム）と第３世代（データがすべて）のAIの対比みたいな絵面だなあ。MRIスペクトルから分子を予想みたいな素朴な応用がもっとあっていい気もする。TRL(Transformer Reinforcement Learning)は、強化学習を用いたLLMの最適化を簡単にできるようになるらしい、DPO(Direct Preference Optimization)なんか斬新じゃん。元Googleトップ研究者による「Sakana AI」にはびっくり、めざす「自然からインスピレーションを得たインテリジェンスに基づいた新しいタイプの基礎モデル」とはどんなものになるのか？日本はコンテンツだけでなくて、人材リソースとしてもまだ魅力がある？？

- ローカルデータに対するQ&Aなどするときに、知識を活用したRAGで構成するのがよいのか、いや、目的に対してLLMをファインチューニングするがいいのかというはなし
	- Knowledge Graphs & LLMs: Fine-Tuning vs. Retrieval-Augmented Generation
	- https://neo4j.com/developer-blog/fine-tuning-retrieval-augmented-generation/
- LLMをつかったsemantic searchのDeeplearning.aiの無料コース
	- Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
- GPT-4のセーフガードを故意に突破する脱獄プロンプトに関する研究
	-  "Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models
	- https://jailbreak-llms.xinyueshen.me/
- 「汎用的なAIってやつ」を作ったところで、それで十分なレベルまで収益化を実現させるのはそれなりに難しいという話(TJO
	- https://twitter.com/TJO_datasci/status/1691112696685719553
- GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher
	- https://arxiv.org/abs/2308.06463
	- GPT-4 can understand ciphertext, which introduces the risk of generating unsafe content.
- CSVにたいするQ&Aエージェントのベンチマーク
	- https://github.com/langchain-ai/langchain-benchmarks/tree/main/csv-qa
-  Knowledge Graph RAG Query Engine (RAG: Retrieval-Augmented Generation)
	- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_rag_query_engine.html
	- augmenting LLMs with context from a graph database
-  Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
	- Deeplearing.aiからのsemantic searchの無料コース、Cohereの人がでている？
- 知識グラフ抽出のデモ
	- text to graph playground
	- https://auto-graph.streamlit.app/
-  Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment
	- LLMの信頼性に関するサーベイ論文
	- 用語や概念を整理し，実際に8つの観点からLLMの信頼性を検証
	- https://arxiv.org/abs/2308.05374
	- reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness.
	- 目的は：reliable and ethically sound deployment of LLMs in various applications.
- RWKVについて解説
	- https://agirobots.com/rwkv/
	- RNNの利点である高速な推論と処理可能なシーケンス長を大幅に向上
- LLMに関して起きている訴訟について
	- https://twitter.com/srush_nlp/status/1691845245074620915?s=20
- LLMでMRIスペクトルから分子を予測
	- https://chemrxiv.org/engage/chemrxiv/article-details/64d5e4ccdfabaf06ff1763ef
	- NMRスペクトルを文字列で表現、これを言語モデルへ入力し分子を予測することで67%の精度
- 松尾研究室100億パラメータサイズ・日英2ヶ国語対応の大規模言語モデル“Weblab-10B”をオープンソースで公開
	- https://weblab.t.u-tokyo.ac.jp/100%E5%84%84%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%BA%E3%83%BB%E6%97%A5%E8%8B%B12%E3%83%B6%E5%9B%BD%E8%AA%9E%E5%AF%BE%E5%BF%9C%E3%81%AE%E5%A4%A7%E8%A6%8F%E6%A8%A1/
	- https://huggingface.co/matsuo-lab/weblab-10b
	- 日本語のベンチマークであるJGLUE評価値が事前学習時と比べて大幅に改善（66→78%
	- 早速オープンソース警察が、商用に使えないのにオープンソースとは言わないとの突っ込みが。。
- 岸田首相、東京大で生成AIの講座受ける　「百聞は一見にしかず」
	- https://www.asahi.com/articles/ASR8G6X84R8GUTFK002.html
	- 松尾豊・東大大学院教授の講座を受けた。AIを学習させるプログラミングも体験し、受講
- LLMをつかった文書検索では、メタデータを入れることで性能が改善する
	-  Building Production-Ready LLM Apps with LlamaIndex: Document Metadata for Higher Accuracy Retrieval
	- https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-document-metadata-for-higher-accuracy-retrieval-a8ceca641fb5
- GoogleのトップAI研究者2人が東京でAI企業立ち上げを発表
	- 「自然からインスピレーションを得たインテリジェンスに基づいた新しいタイプの基礎モデルを開発する」
	- ジョーンズ氏とハー氏が新AI企業「Sakana AI」を東京に設立
	- うち1人は、生成AI革命のきっかけとなった論文の著者の一人
	- 日本で研究者を募り、生成AIの基盤モデル開発を目指す
	- https://www.nikkei.com/article/DGXZQOUC186TM0Y3A810C2000000/?n_cid=SNSTW001&n_tw=1692351448
	- 起業の地に日本を選んだ理由として、米国で生成AIの人材獲得競争が過熱している点をあげた。
-  TRL - 強化学習によるLLMの学習のためのライブラリ
	- TRL - Transformer Reinforcement Learning
	- https://note.com/npaka/n/nbb974324d6e1
	- 強化学習を使用してTransformer言語モデルを学習できます。このライブラリはHuggingFace Transformersと統合されています。
-  DPO による Llama 2 のファインチューニング(npaka)
	- https://note.com/npaka/n/nfe7391a1d28d
	- 「Direct Preference Optimization」では、既存の手法で使用されているRLベースの目標を、単純なバイナリクロスエントロピー損失を介して直接最適化できる目標に切り替える
	- LMを改良するこのプロセスが大幅に簡素化

## 8/14
お盆ですが、膨大にならないうちに更新します。ところで、「大規模言語モデル入門」(技術評論社ISBN 978-4-297-13633-8）いいですね、Huggingfacesをつかって、日本語データセットをつかった、ファインチューニングなど見所が多い。
さて今週は、先週に引き続き vicuna-v1.5関係の記事が多かったわけですが、stability.aiから日本語のStableLLMがリリースされたがのが大きなニュースでした。LLMベンチマークもColab環境でできるらしい。Metaの公表した生成AIのガイドとか、FacToolなんか、AIの安全性やリスクなんかに対してちゃんと取り組んでいる。日FR本のAI戦略の、開発促進に偏った姿勢とは一線を画している（つまり余裕がないということ）。FacToolによる分析の結果、GPT-4はやっぱりすごいんだな。Llmaindexのllmがgpt-3.5-turboにやっと変更されたらしい、そんなに使いにくかったのか。。LLMをプロダクションで使うための色々なTipsが公表されてたり、一方Andrew Ngさんは、LLMが世界を理解しているというブログを開陳。LLM時代の医療へのAI利用のベネフィットとリスクについてのランサー記事とか、数学者Terence Taoさんの、LLMをつかったAIが数学論文の共著者になりうるという興味深い予測も。産総研のAIセミナー、あっという間に満杯に。興味だけは大きいのに、手が動かない人が多すぎないか。。まあ、LLMでいくら頑張てもChatGPTでよくない？みたいな意見もある。様々な面で、日本はLLM開発で遅れてきていて、もはや以前のような横綱相撲をするような感じではないのに政府はそうは言えないのか、しかし民間は頑張っている。

- LlamaIndexでAutoGPTQモデルを使う（vicuna-13B-v1.5-GPTQ）
	- https://zenn.dev/libratech/articles/1979874b223895
	- 4bit化など軽量化されたllmをllamaindexで使う方法、ローカル環境とか
	- Colabの無料版(T4インスタンス)でも動作する
- LLama2公開にあわせて、Metaから"responsible generative AI"に関するガイドが出ている.、
	- https://ai.meta.com/static-resource/responsible-use-guide/
- text-generation-webui で TheBloke/vicuna-13B-v1.5-GPTQが動く
	- https://twitter.com/smorce1/status/1688250856129646592?s=20
- llama2をつかって、ローカルにQ&Aを実行する手法について via llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SimpleIndexDemoLlama-Local.html
- LLMを試すのに、「ガンダムテスト」というのがあるらしい、vicuna-13b-v1.5-16kは優秀らしい
	- https://twitter.com/NuCode/status/1688455649091608576?s=20
- 内閣府AI戦略会議(8/4)の資料が一部公開、AI関連施策は開発振興一本足に近くリスク対応が申し訳程度
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/4kai/shisaku.pdf
-  IPA「ITパスポート試験 シラバス」に、生成AIの仕組み、活用例、留意事項等に関する項目・用語例を追加
	- https://www.ipa.go.jp/shiken/syllabus/henkou/2023/20230807.html
- 「JP Language Model Evaluation Harness」によるLLM性能評価 by stabilityAI
	- https://note.com/npaka/n/nedf4dacd4037
	- Colab(T4)で12時間もかかる、できるらしい
- llama-2-13bのJGLUE、言語モデルの評価と関係
	- https://huggingface.co/HachiML/Llama-2-13b-hf-qlora-dolly-ja-2ep/blob/main/benchmark_jglue/JGLUE_Llama-2-13b-hf-qlora-dolly-ja-2ep.ipynb
- GPTQの元論文はこちら、
	- https://arxiv.org/pdf/2210.17323.pdf
	- GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS
- ストックマークは最近の話題にも詳しいGPT-NeoXをベースとした14億パラメータの日本語のLLMをOSS公開
	- https://stockmark.co.jp/news/20230808
- HuggingFacesとNVIDIAが提携、企業向けのサービスを展開？
	- https://www.nvidia.com/ja-jp/about-nvidia/press-releases/2023/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing/
	- HuggingFaceにあるAIモデルのトレーニングとか微調整ができる企業向けのサービスで、GPUとしてNVidiaのクラウドGPUが選べるようになるらしい。
- 悲報？：産総研、LLMのセミナー「シミュレーションとAIの融合技術とその最新事例」、すぐに定員いっぱいになる
	- https://www.airc.aist.go.jp/seminar_detail/seminar_069.html
- Stability.ai、 日本語言語モデル「Japanese StableLM Alpha」をリリース(8/10)
	- https://ja.stability.ai/blog/japanese-stablelm-alpha
- 早速Japanese Stable LLMを、Colab無料環境から利用するnotebookが公開
	- https://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb
	- huggingfacesにログインしないといけない、、が動くぞ！
	- ガンダムテストしてみたが、なんか、学習時につかったデータが表示される。
- 生成AIによって生成されたテキストを判別する方法についての論文
	- https://arxiv.org/abs/2306.15666
	- Testing of Detection Tools for AI-Generated Text
	- ■文章のスタイルを変化させられている場合（例えば子供っぽくなど）、識別が困難になる 
	- ■言い換えや書き換えによって段階的に文章を変更されると、識別がかなり困難になる
	-  ■AI生成コードの検出はAI生成テキストの検出よりもさらに困難になる
- Langchainのテキスト分割の様子を目視できる、playgroundが爆誕
	- https://langchain-text-splitter.streamlit.app/
- Google Colab で Japanese StableLM Alpha + LlamaIndex の QA を試す
	- https://note.com/npaka/n/n5c80ca661357
- 「とっきょ」広報誌で、こち亀の内容が、拒絶通知の理由になった事例が紹介。。
	- https://www.jpo.go.jp/news/koho/kohoshi/vol57/07_page1.html
	- 拒絶を避けるべく、特許出願する前にはこち亀を全巻読破する必要があるのか、、、
	- 審査官の趣味という気もするが、、
-  ChatGPTの新機能カスタム指示の面白い使い方
	- https://note.com/it_navi/n/nca4643390969
	- カスタム指示は、ChatGPTの**役割、回答方針、出力形式など**を予め設定することができます。
- LLMは世界を理解しているか？by Andrew Ng
	- https://www.deeplearning.ai/the-batch/issue-209/
	- Othelo-GPTの例から、答えは YESらしい。
- 生成AIの文章やコード、論文が“事実か”チェックする技術　米Meta含む研究者らが開発
	- https://www.itmedia.co.jp/news/articles/2308/09/news064.html
	-  FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
	- https://arxiv.org/abs/2307.13528v2
		- 研究者らはベンチマークを開発し、知識ベースのQA、コード生成、数学の問題解決、科学論文のレビュー執筆の4つのタスクで実験を行った。その結果、GPT-4はChatGPT、Bard、Claude-v1、Vicunaと比較して、事実精度が最も優れていた。Vicuna-13Bは、知識ベースのQAではそれなりに良好な事実性を示したが、コード生成、数学の問題解決、科学論文のレビュー執筆など、より困難なシナリオではパフォーマンスが低い結果となった。
- llamaindexのv0.8がリリース
	- https://github.com/jerryjliu/llama_index/blob/main/CHANGELOG.md
	- [1] The default LLM is now gpt-3.5-turbo
	- [2] Speaking of changing prompts, we’ve changed the default question-answering templates for both our create and refine strategy as well as tree_summarize.
	- [3] Our default text splitter is now our brand-new sentence text splitter.
	- [4] Added llama.cpp and @huggingface as fallbacks if openai key is not set.
	- [5] Some new features: a `SentenceWindowNodeParser` and `MetadataReplacementNodPostProcessor` 
- チュートリアル、Create a CustomGPT And Supercharge your Company with AI – Pick the Best LLM
	- https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/
-  Building LLM applications for production
	- https://huyenchip.com/2023/04/11/llm-engineering.html
	- LLMをプロダクションで使うための色々なTipsがまとまった記事
- いろいろLLMをいじってみても、結局ChatGPTでよくない？みたいな
	- https://twitter.com/mr_bay_area/status/1689868431900975104?s=20
-  AI in medicine: creating a safe and equitable future
	- Lancerの記事、LLM時代における、医療分野へのAI適用のメリットとリスクについてまとめ
	- https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)01668-9/fulltext
-  Embracing change and resetting expectations by Terence Tao@microsoft
	- https://unlocked.microsoft.com/ai-anthology/terence-tao/
	- He predicts that AI will be a trustworthy co-author in mathematical research by 2026, when combined with search and symbolic math tools.
	- 2026年までには、数学研究において、AIが信頼できる共著者になりうるとの予測


## 8/7

llama2ベースのVicuna v1.5で盛り上がっている、langchainやllamaindexとの組み合わせでも動く模様。ReActなどのAgent機能もちゃんとうごくらしい。llama2を手ごろに試せるcolab noteもたくさん公開、ローカルGPUで動かす報告も。なおllama2本家も申請すればを直接使うこともできる。マイクロソフトはwindows上でのllama2というネタでメタとパートナーとのこと、二股かけてる？マイクロソフトがAzure OpenAIをつかったChatGPTもどきのサンプル実装を公開、カニばってない？文章から知識を抽出する方法、llamaindexでも知識グラフ(KG)を抽出するKnowledgeGraphIndexがあったが、REBELという外部のtransformerを利用する方法もあるのか。用途に合わせて選択、細かい調整が必要かな。UCバークレーのDynalang、AIエージェントと紹介されているが、論文タイトルからするとLLMで世界モデルを構築しようとしている（「二重過程モデル」の真ん中に出てくるやつ？記号接地モデルというかそういうやつ）。自コンテンツをつかったChatBotの作り方についてわかりやすい説明があった。JSTの生成AIのまとめ、日本の生きる道は、「第4世代AI」「信頼されるAI」「AI・データ駆動科学」ということらしい。「第４世代AI」とはSystem1とSystem2が連動する、「二重過程モデル」のことらしい、Dynalangの話ともつながった！

> NeurIPS2019で、Bengioの基調講演の「二重過程モデル」（即時的なSystem1と熟考的なSystem2の二重モデル、間に、世界モデルが入る）。知覚系の深層学習(System1)によって眼前の状況に対する世界モデル（World Model）が得られるが、それを使って言語・知識系が適切な手順を組み立てるのがSystem2。カーネマンのFast & Slowとも関連がありそう。。

- Google Colab で Vicuna-v1.5 + LlamaIndex の QA を試す
	- npakaさんより、ハイメモリでないと動かないのか。。
	- https://note.com/npaka/n/n931319f17b34
-  Google Colab で Llama 2 + LlamaIndex の QA を試す
	- npakaさんより、llma2利用には申請が必要なのか、
	- Q&Aテンプレに修正が必要なもよう
	- https://note.com/npaka/n/n3e1b59d1ac9e
- vicuna-7b-v1.5の一番簡単な利用方法by npakaさｎ
	- https://huggingface.co/lmsys/vicuna-7b-v1.5
	- https://twitter.com/npaka123/status/1686872443305295878?s=20
- ChatGPTの小改良が順次リリースされるとの告知
	- https://twitter.com/OpenAI/status/1687159114047291392?s=20
	- prompt exampleとか、Plus会員にはGPT-4がデフォルトになるとか、そういうｙつ
- UCバークレー、アルファ碁とChatGPTを混ぜて強くしたようなAIエージェント「Dynalang」
	- https://arxiv.org/abs/2308.01399
	- Learning to Model the World with Language
- マイクロソフト社、Azure OpenAIで、ChatGPTもどきを作るサンプル実装を公開
	- https://github.com/microsoft/azurechatgpt
	- 企業利用が加速するか。。いやplaygroundで十分？
- 人工知能研究の新潮流2　～基盤モデル・生成AIのインパクト～
	- JSTのまとめ、生成AI研究の動向報告書
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-02.html?fbclid=IwAR0KQ7bg5BRLIblzI154AHYheNrF1SPPzm-xn4z1PuQBUPK2Kia2qT4PMxU
	- 「第4世代AI」「信頼されるAI」「AI・データ駆動科学」
- 雇用判断にAIを使うのは、EU規制上禁止？
	- 禁止ではなくて、ハイリスクAIに相当するから、守るべきことを守らないといけないということ
	- https://twitter.com/umiyuki_ai/status/1687639267273748480?s=20
- 南極の氷が、今年は急激にとけているらしい　via 安宅さん
	- https://www.economist.com/graphic-detail/2023/08/02/the-rapid-loss-of-antarctic-sea-ice-brings-grim-scenarios-into-view
- REBELという関係抽出トランスフォーマーをつかって知識グラフを抽出して推論する例
	- https://twitter.com/jerryjliu0/status/1687607838539927553?s=20
	- llamaindexの人による紹介、なんか抽出する知識の密度を調整したいところ
- Google Colab で LangChain + Vicuna-v1.5 のエージェント機能を試す
	- https://note.com/npaka/n/nb3c02ce2d4c5
	- npakaさんより、serpAIとmathをツールとして、ReActが試せるらしい。ハイメモリが必要。。
-  Google Colab で Llama.cpp + Vicuna-v1.5 を試す
	- npakaさんより、Colabでこんなこともできるのか？
	- https://note.com/npaka/n/n280ffc0d5ff0
- llama-2-7bをつかって、colabでchatbodを作る例、
	- 動くんだ、、、というか動くぞ！
	- https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-7b-chat.ipynb
- 自分のコンテンツを学習したカスタムChatBotを作る方法
	- https://zenn.dev/karaage0703/articles/c8baa66c40f9b7
	- そうか、いつもやってるやつは、Retrieval-Augmented Generation（RAG）ってよばれているのか？
-  LLMがローカルで動くパラメータ数どこまで？Metaの「Llama 2」を試してみた
	- https://pc.watch.impress.co.jp/docs/column/nishikawa/1519390.html
	- 西川さんが組むとは、だいぶ民主化が進んだのか。
	- Colabでも結構簡単にうごくが、ローカルなGeForce RTX 4070 Ti(12GB)でも動かす事例が(西川 和久)
-  Llama 2ベースのLLM FastChat/Vicuna v1.5をローカルで動作
	- https://jweb.asia/26-it/ai/91-fastchat-vicuna-v1-5-on-llama-2.html

## 7/31

いやあ、暑くなって１週間さぼったら、それなりにまとめるのがつらい。メタのLLaMa2リリースが大きな話題、岡野原さんの解説が良いかも。さっそくggml化、webui対応、LanChain組み込みが行われる。LangChainの統合開発環境LangSmith、よくLangChainの紹介動画に出てきてやつが正式リリースか。メタはマイクロソフトと組んでOSS化するとのこと、マイクロソフト無敵だな。OpanAI x Azureの人は、マイクロソフトの「ChatGPT - Azure OpenAI 大全」は参考になるか。ChatGPTの性能が初期に比べて劣化しているとの報告も。「生成AIと著作権に関する論点整理」の図は素晴らしい。OpenAIのCEOであるSam Altman氏が共同創業したWorldCoinプロジェクトが7/24に仮想通貨WLDをローンチした、日本にも虹彩認証Orbが複数設置されるも認知度は今一歩か、AIで得られた利益を配る、BIプロジェクトの一旦とのこと。

- LLaMa2をリリース、商用利用が可能に
	- https://ai.meta.com/llama/
- LLaMa2を早速ggmlに変換された
	- https://huggingface.co/TheBloke
- メタ社LLaMa2を、Microsoftと組んでOSS化すると発表
	- https://twitter.com/alex_valaitis/status/1681348531834044426?s=20
- Llama2-70B-Chatモデルは、なんと有用性評価でGPT-3.5TurboのChatGPTを打倒！
	- https://twitter.com/umiyuki_ai/status/1681361453838929923?s=20
- LangChaiの統合開発環境LangSmith正式版発表
	- https://blog.langchain.dev/announcing-langsmith/
	- おっと、正式発表されたのか
- Llama2は学習データを2Tトークンに増やしコンテキスト長を4KにしGQAを採用。報告書では有用性と安全性の向上に向けたSFTとRLHFの詳細が充実している。
	- 岡野原さんの解説
	- https://twitter.com/hillbig/status/1681436336451125257?s=20
- BigChat Enterpriseを発表
	- https://blogs.microsoft.com/blog/2023/07/18/furthering-our-ai-ambitions-announcing-bing-chat-enterprise-and-microsoft-365-copilot-pricing/
	- ユーザーとビジネスデータは暗号化され、組織外に流れることはありません。またチャット履歴は保存されずMicrosoftから見れません
- LLaMA2、ネット上のデモだとあんま日本語強くない印象だけど、ローカルでggml 4bit版の13B chat動かした感じ想像以上にまともに会話できるな、という印象
	- https://twitter.com/RosaRugosaBeach/status/1681554704701194240?s=20
- 東大の大規模言語モデルサマースクール
	- https://deeplearning.jp/llm2023/
- ChatGPTの性能が、初期リリースに比べて最近低下しているとの論文が
	- https://arxiv.org/pdf/2307.09009.pdf
- GitHubのcopilotがVSCodeから可能に
	- https://twitter.com/code/status/1682435342610079761?s=20
- TypeChat、マイクロソフトによる、プロンプトの代わりにType(型）をつかったChat、スキーマエンジニアリングともよぶらしい。
	- https://github.com/microsoft/TypeChat
- LLaMa2は、洞察とメタ認知に優れている
	- https://arxiv.org/pdf/2307.10928.pdf
- LangChainのLLaMa2インターフェイス
	- https://python.langchain.com/docs/integrations/chat/llama_api
- llama2 13B chat 4bit
	- https://twitter.com/manjiroukeigo/status/1683047350141599744?s=20
- 京大、仏典をGPT-４で学習した、ブッダポッドプラスを発表
	- https://ledge.ai/articles/buddha_bot_plus_kyoto_university
	- GPT-4で仏典を解釈 わかりやすく回答
- TheBloke/Llama-2-70B-Chat-GGML
	- https://huggingface.co/TheBloke/Llama-2-70B-Chat-GGML
- 生成AIによるコード生成とCode Interpreter活用ハンズオン with PLATEAU
	- https://connpass.com/event/290745/
- Abstraction and Analogy: The Keys to Robust Artificial Intelligence
	- https://www.eventbrite.co.uk/e/abstraction-and-analogy-the-keys-to-robust-artificial-intelligence-tickets-675075728677?aff=oddtdtcreator
- MicrosoftによるOpenAI　Azure大全
	- https://speakerdeck.com/hirosatogamo/chatgpt-azure-openai-da-quan
	- GPTの全体像、MicrosoftとOpenAIの関係、プロンプトエンジニアリングなど全て学べます
- llama2-webui
	- https://github.com/liltom-eth/llama2-webui
	- Run Llama 2 locally with gradio UI on GPU or CPU from anywhere
- DeepMindから強化学習で核融合炉（トカマク）を制御する話
	- https://arxiv.org/abs/2307.11546
- Google Colab で Llama 2 + LangChain の RetrievalQA を試す
	- https://note.com/npaka/n/n6d33c2181050
- 医療のあらゆるタスクで最優秀スコアを獲得する医療特化の大規模言語モデル「Med-PaLM M」
	- https://arxiv.org/pdf/2307.14334.pdf
- 「生成AIと著作権に関する論点整理」
	- なんと詳細な図が、、
	- https://www.bunka.go.jp/seisaku/bunkashingikai/chosakuken/hoseido/r05_01/?fbclid=IwAR06f_2GFjUTlVn6Ofot52SfMhcJuyjTtkzF-D7DczgB75d0d5iCC9ucGnQ
- World Coinの発表（Sam Altmanが関係している）、日本でも認証Orbが設置
	- 代官山のサイトに行ってみたが、人はぼちぼち、日本では今一歩の認知度か。暑かった
	- https://twitter.com/umiyuki_ai/status/1685323501069299713?s=20
	- 200万人がオーブ認証済みとか言ってたのに、予約者さえまだ32万人

## 7/18

暑くてすでに夏バテです。あいも変わらずcode interpreterの事例が続々、来年度の講義資料もこれで作るか。LLM時代のリテラシーって何という問い、教育もそうだし、リカレントもそう。Promptflowみたいな、（一見）思い付きのスタートアップがタケノコのように出てくるだろう。AlphaFoldがFoldItというゲームから名前がきているとは知らなかった、集合知ね。GoogleのNotebookLLM、エンジニアノートバッドという従来からの夢が、一歩実現に近づくか。普通に使っているEmbeddingなんかも、もちゃんと振り返って、カスタマイズの余地がある。

- ChatGPTのcode interpreterをつかて、講義の一部を作成（東大、強化学習、今井先生）
	- https://twitter.com/ImAI_Eruel/status/1678378444441387010?s=20
- What Should Data Science Education Do with Large Language Models?
	- https://arxiv.org/abs/2307.02792v2
	- LLMにより教育の変革、LLM-informed creativity, critical thinking, AI-guided programming.
- AlpacaEvalなるLLMベンチマークがあった、OSS系では、Vicuna-33Bがトップ
	- https://tatsu-lab.github.io/alpaca_eval/
-  AI tools are designing entirely new proteins that could transform medicine
	- https://www.nature.com/articles/d41586-023-02227-y
	- RFdiffusionという拡散モデルによるタンパク質の合成が、AlphaFoldなどのハルシーネーションベース？の手法より優れているとの論文
- GPT-4でワークフロー自動化「Promptflow」開発、Carnot（カルノー）が8,500万円をプレシード調達
	- https://thebridge.jp/2023/07/carnot-pre-seed-round-funding
	- 雨後のタケノコのようにスタートアップが立ち上がるか？？
- LLamaindexにおける、RAGの説明 by npakaさん
	- https://note.com/npaka/n/n27a36f784fb3
	- LLMとカスタムデータを組み合わせるための「RAG」(Retrieval Augmented Generation) パラダイム
- ストラング先生の線形代数講義のグラフィカルなノート、行列演算を極める。
	- https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra
- DeepMindのHasabisさんのインタビュー
	- AlphaGoのあとにAlphaFoldに着手したのは、FoldIt（集合知で折り畳み問題を解くゲーム）に着想を得たとのこと
	- https://podcasts.apple.com/us/podcast/a-i-could-solve-some-of-humanitys-hardest-problems/id1548604447?i=1000620748039
- OpenAIから、embeddingのカスタマイズする、ノートブック。デフォルトでは使えない？
	- https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb
- Google Labs、言語モデル「NotebookLM」の提供開始を発表--まず米国から
	- https://japan.zdnet.com/article/35206577/
	- NotebookLMではユーザーのノートや情報源を『土台にして』言語モデルが稼働
- Bardにマルチモーダル機能が。。	
	- https://twitter.com/i/status/1680237703676190722
- 

## 7/10

OpenAIからGPT plusユーザー向けに、code interpreterが開放された。これで、データサイエンティストの仕事がなくなる？Plusじゃない人も、まずは手始めにLangChainのビデオをみて、データとのチャットを体感してみるといいかも。楔文字の翻訳など、様々な学問領域にLLMが侵食してゆく。OpenAIはアラインメント問題をAIで解くみたいなそっちの方向（結果としてAIの基盤整備が進む）。LLMのベンチマークとして、性格診断(Big5)というのは面白いアプローチ。使う人の性格判断と合わせるとマッチングが取れたりして。

- llamaindexにてtext-to-SQLの大幅なアップデート
	- https://twitter.com/llama_index/status/1676002583381692421?s=20
- 大規模言語モデルの"性格"特性を分析＆調整するフレームワーク、DeepMind、ケンブリッジ大学、慶応大学
	- Personality Traits in Large Language Models
	- https://arxiv.org/abs/2307.00184
- タスクの複雑さが増すとLLMの性能が急速に低下する現象を丁寧に検証
	- Faith and Fate: Limits of Transformers on Compositionality
	- https://arxiv.org/abs/2305.18654
- LangChainにおけるSpacy Embeddingの利用例
	- OpenAIやHuggingFace以外、
	- https://python.langchain.com/docs/modules/data_connection/text_embedding/integrations/spacy_embedding
- EUのAI規制の、最終案の一つ前の和訳が、総務省の「AIネットワーク社会推進会議」で公開
	- https://www.aplawjapan.com/publications/20220725
- IPAに「デジタル基盤センター」新設、デジタル庁と協力して基盤整備
	- https://xtech.nikkei.com/atcl/nxt/news/18/15517/
	- 古巣の社会基盤センターが改組されて、「デジタル基盤センター」になり、デジタル庁の影響を受けるようになった。。。悲しい。
- CAMEL-5B と SentenceTransformers で LlamaIndex を試す
	- https://note.com/npaka/n/n2e408cded4ac
- DeepLearningAIから、新コース、LangChain: Chat with Your Dataを無償リリース
	- https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/
- OpenAI、計算リソース利用の２０％をアライメント問題に割くことを表明
	- アラインメント問題自体をAIで自動化するようにも見える（つまり目には目を、AIにはAIを）
	- https://openai.com/blog/introducing-superalignment
- NP困難といわれる、3次元パッキング問題を、MITが解く？
	- https://news.mit.edu/2023/chore-packing-just-got-faster-and-easier-0706
	- FFTを利用しているとのこと
- 楔形文字の解読にトランスフォーマを駆使して成功
	- https://academic.oup.com/pnasnexus/article/2/5/pgad096/7147349?login=false
- OpenAI Code Interpreterを、GPT plusユーザーに解放。
- 

## 7/4

暑くてバテてました。LLMって、人間の知能を模擬するならば、Agentが実装できるというが、実装が近づいてきた。計画問題も直接解かせるよりも、計画問題を生成させるという組み合わせも面白い。形式言語なんか振り返ってみるのも面白いかも。LLMをComputer Visonへの応用、言語と画像の区別はなくなるのか？GoogleのKaggleチャレンジって、LLMの品質保証では重要な要素。ノン・セミパラメトリック統計ってのがあるのか？ 岡野原さんの『大規模言語モデルは新たな知能か』はおすすめ。記号接地って、LLMで実現できてんじゃない？みたいなのがじわじわと語られつつある(MLSE2023合宿より）。DeepMindのGemini、本当に出るのか？

- OpenAIのilian WengによるLLMをつかった、Agentの良解説記事
	- https://lilianweng.github.io/posts/2023-06-23-agent/
- LLMを使ってプランニング問題を解く、PDDLと呼ばれるプランニング言語に変換させた上でソルバーに解かせる。LLM単独より正確。
	- https://arxiv.org/abs/2304.11477
- Relicの社内勉強会での生成AI解説７０P資料
	- https://qiita.com/hedgehog051/items/b1308e8baf7b0f551548
- 形式言語とは何か（現代思想）
	- http://www.seidosha.co.jp/book/index.php?id=3821&status=published
	- 「正しい文とは何だろうか。。。」から始まる
- Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language
	- https://huggingface.co/papers/2306.16410
- 学習済みモデルから特定のデータの影響を消すKaggleチャレンジ by Google
	- https://ai.googleblog.com/2023/06/announcing-first-machine-unlearning.html
- 研究者の資質と教員の仕事 by 谷中教授
	- https://twitter.com/verypluming/status/1674445457463062534?s=20
- コンテキストを気にした文書分割
	- https://twitter.com/RLanceMartin/status/1674817117475188737?s=20
- ノン・セミパラメトリック統計
	- https://www.kyoritsu-pub.co.jp/book/b10031225.html
	- 分布関数、密度関数や回帰関数について、一定の滑らかさのみを仮定して、ノンパラメトリックな推定と検定を行う方法を紹介する
- DeepMindの次世代AI「Gemini」はChatGPTを凌駕する？
	- https://wired.jp/article/google-deepmind-demis-hassabis-chatgpt/?utm_medium=social&utm_source=twitter
	- 「GeminiはAlphaGoのようなシステムの強みと大規模言語モデルの卓越した言語能力を組み合わせたもの」
- 岡野原『大規模言語モデルは新たな知能か』の個人的着目ポイントは、transformerで交互に積層する自己注意機構とパーセプトロンについて、前者が「短期記憶」、後者が長期記憶として機能するとの解説（p.108）
- 言語モデルに物理化学特徴量を取り入れた物性予測 by IBM
	- 分子の物理化学的特徴量を選定し、言語モデルを微調整する　
	- https://arxiv.org/abs/2306.14919v1
- VARモデル ＋ グレンジャー因果性の統計的仮説検定による、時系列データの因果探索
	- https://twitter.com/kenken26679105/status/1675281986917900288?s=20
	- 非ガウスモデル・VAR-LiNGAMであれば、同時刻も分析可能
	- https://twitter.com/kenken26679105/status/1675306307849699328?s=20
- Chains vs Agents" webinar by LangChain
	- https://www.youtube.com/watch?v=bYLHklxEd_k
- 結局記号接地ってなんだったけ？ by 丸山＠MLSE
	- https://twitter.com/maruyama/status/1675813852947308544?s=20
	- 実世界への参照なしで、言語空間内での埋め込みだけで意味を操作

## 6/26

あいもかわらずOpenAIのFunction APIの利用について、具体例が増える、Pydatanicと組み合わせればほぼ無滝の情報抽出ができそうだし、抽出した情報をつかったQ&Aなど、ちょっと説明性もあがるか？ヘルスケア分野でのGoogleAIの発表は衝撃的、眼科検診で様々な病気が見つかる。。。OpenLLAMaがでてきて、あっというまにFlanのデータでファインチューニングしたものが、商用利用できるのか？生成AIの研究や仕事への影響についてまとまった資料がぼちぼちでてきた。世界モデルに基づくプランニングなんかもLLMならではの研究か。LLMのコンパクト化も引き続き、マイクロソフトの取り組みがある。MITの試験問題をGPT4に解かせる話が不正という記事が、ちょっと悲しいが、オープンサイエンスの成果か。。


- OpenLLaMAは、LLaMaのオープン版（商用利用が可能？）GPU RAMは26.5GBで動作の模様
	- https://huggingface.co/openlm-research/open_llama_13b
	- https://github.com/openlm-research/open_llama
- Google	 ピーチャイ氏の講演、ヘルスケア分野で、AIがCTとかMRIとかを代替するかも（眼底検査で代替できる？）
	- https://twitter.com/alvinfoo/status/1670599368930656257?s=20
- OpenAIのFunction callとpydantic 	を組み合わせた例や再帰構造への対応など、情報抽出がこんなに便利に
	- https://twitter.com/jxnlco/status/1670764386447953921?s=20
	- https://twitter.com/matchaman11/status/1670799349004083200?s=20
	- https://gpt-index.readthedocs.io/en/latest/examples/output_parsing/openai_pydantic_program.html
- エンコーダーとデコーダについてわかりやすい解説
	- https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder
- LangChainで、	**MarkdownHeaderTextSplitter**を使えば、引用元つきのQ&Aが簡単に
	- https://note.com/hamachi_jp/n/nf23b75d14068
- マッキンゼーによる、生成AIの生産性への影響レポート
	- 生成AIで従業員の時間を6~7割節約可能 
	- 生成AIのビジネスインパクトが高いのは2枚目画像の右上の領域
	- 産業×用途別のインパクト評価(3枚目) 
	- 特定領域の具体的な用途と経済価値(4枚目)
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#key-insights
- GPT４ALLベースのcopilotが登場？
	- https://morph.so/
- Debate　Tree、議論の構造をビジュアライズする
	- https://debatetreeofthoughts.streamlit.app/
- 基盤モデル・生成AIの科学研究への影響に関する資料、文科省 基礎研究振興部会(第11回)
	- https://www.mext.go.jp/b_menu/shingi/gijyutu/gijyutu27/siryo/mext_00007.html
- LlamaIndex	で、function call+pydatnicを組み合わせて、	query planningが可能に、
	- https://gpt-index.readthedocs.io/en/latest/examples/agent/openai_agent_query_plan.html
- 水口画伯なくなる、合掌
	- https://twitter.com/AKZ161/status/1671498721287352320?s=20
- PyRCA、Pythonをつかった、ルート原因分析
	- https://github.com/salesforce/PyRCA
- OpenAIのFunction APIの解説
	- https://every.to/chain-of-thought/gpt-4-can-use-tools-now-that-s-a-big-deal
- Flan-Open-Llama-7b、OpenLLaMaを、Flanのデータセットでチューニングした？
	- https://huggingface.co/conceptofmind/Flan-Open-Llama-7b
- 第2回LLM勉強会
	- https://llm-jp.nii.ac.jp/llm/2023/06/20/study-group-2.html
- local llmでsentence embeddingどれ使えば良いんだっけ
	- https://note.com/if001/n/n25d795afe571
- OpenAIのEmbbedingをつかって文章の類似度を計算
	- https://techblog.gmo-ap.jp/2023/06/22/embeddings_api_calc_sentence_similarity/
- CVPR2023より、疑似確率が確率になるという問題への回答
	- https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Class_Adaptive_Network_Calibration_CVPR_2023_paper.pdf
- マイクロソフトから小規模LLMに関する論文 Textbooks Are All You Need
	- 13億パラメータ"しか”ないモデル(phi-1)を、The StackとStackOverflowのデータを教科書品質にした60億トークンとGPT-3.5で生成した10億トークンをNVIDIA A100 8台・4日間で学習
	- https://arxiv.org/abs/2306.11644
- Flan-Open-Llama-3b
	- https://huggingface.co/conceptofmind/Flan-Open-Llama-3b
- Reasoning with Language Model is Planning with World Model
	- LLMを使ってプランニングを必要とするタスクを解く際、現在の状態をLLMを使って把握するようにして(「世界モデル」)、取るべき行動に対する報酬をLLMを使って見積もった上でモンテカルロ木探索によって行動を決定する手法(RAP; Reasoning via Planning)
	- https://arxiv.org/abs/2305.14992
- OpenAIのCookbookにllama_indexをつかった、文書分析の例が載る
	- https://github.com/openai/openai-cookbook/blob/main/examples/third_party_examples/financial_document_analysis_with_llamaindex.ipynb
- GPT-4がMITの試験問題を正しく解いたという論文が手続き的にも本質的内容面でも不正との指摘
	- 正解がでるまで何度も聞いた等の不正があった模様。。
	- http://people.csail.mit.edu/asolar/CoursesPaperStatement.pdf

## 6/19

今週は、6/12日にCEOの慶応大学での講演。OpenAIのAPIのアップデートの話題がありました。トークン数の拡大（青空文庫の短編クラスなら取り扱える）とか、Function callの追加。これで、LangChainのReActエージェントを使わなくても、OpenAI Agentで外部ツールとLLMが連携したソリューションが手軽に作れるようになるのは恐ろしいこと。品質評価の視点では、OpenAI Evalとかの話題も。欧州ＡＩ規制が、欧州議会の投票で採択され、次の段階（トリローグ）を経て年内に成立か。さっそくスタンフォード大学のHAIチームが、既存LLMの規制への対応状況をベンチマーク。データサイエンス系の型は、関数データ解析などは目からうろこではないか。ベイズ派と頻度派の争いには巻き込まれたくないもの。知識グラフとLLMの融合も、整理された論文が出てきた。

- 「OpenAI CEO Sam Altman氏と塾生との対話」開催(6/12)
	- https://www.keio.ac.jp/ja/news/2023/6/15/27-139184/
	- 会場となった西校舎ホールには約700名の学生が集まり、約40分にわたり活発な質疑応答が行われました。またその様子は519教室にも配信され、1,000名以上の学生にとって貴重な機会となりました。
- 「二つの分散:不偏推定量と最尤推定量のどち らを使うべきか」井手さん(IBM)
	- 頻度派に対する執拗な攻撃は続く。。
	- https://ide-research.net/book/Which_variance_should_I_use.pdf
	-  データサイエンスの本質をひと言で答えろと言われたら、「観 測データに対してもっとも当てはまりの良いモデルをつくるために、最尤推 定を使ってパラメターを決めること」と答えればよい」
-  Evaluating the Social Impact of Generative AI Systems in Systems and Society
	- https://huggingface.co/papers/2306.05949
- 「見たくないものをみる」（PFNの丸山さん）
	- https://note.com/hiroshi_maruyama/n/n7890a1fb7aef
	- 新たな倫理規範の確立について
	- 「人間中心のAI」に違和感を抱き、「人間が（知能の面で）万物の霊長でないかもしれない」という「都合の悪い真実」を直視すべきという話
- 「デジタル庁のサイトやばすぎる」
	- https://qiita.com/mu_tomoya/items/f78f1fad3a8b57ac7dc3
	- やばいくらい参考になるらしい。
-  米OpenAIのCEO「AIはさらに賢く」　慶大で意見交換（日経）
	- OpenAIの強みはresearch culture  
	- コーディング or 理論解析に強い人が成功している
	- AI技術は急速に進歩・応用されており、このような時代にAIに関われる今の学生はlucky generation
	- https://www.nikkei.com/article/DGXZQOUC1037N0Q3A610C2000000/
- 平均・分散・相関が変わらない、X,Yの様々な事例。。
	- まあ有名な奴だけどゴジラはよく考えたな。
	- https://twitter.com/docmilanfar/status/1668093023895568386?s=20
- ヒントン先生にたいするルカンの所感
	- 人間並みのAIを実現するには、２つが必須で、（今はたらない）
		- (1) learning world models from sensory inputs like video, 
		- (2) an architecture that can reason and plan (not just auto-regress).
- Dockerコンテナをwebassemblyに変換して実行できるツール？
	- https://www.publickey1.jp/blog/23/dockerwebassemblywebcontainer2wasm03.html
- 欧州のデータスペースに関する、JRCのレポート
	- European Data Spaces - Scientific Insights into Data Sharing and Utilisation at Scale
	- https://publications.jrc.ec.europa.eu/repository/handle/JRC129900
- GPTにFunction Callが追加
	- 出力の整形とか、あるいは、自然言語から、関数のAPI呼び出しを作ったりとか、つまり、LangChainでいうところのAgentが簡単にできるようになる。。
	- https://openai.com/blog/function-calling-and-other-api-updates
- CV（コンピュータビジョン）の最新刊は、生成AI、巻頭言がよかったとのこと
	- https://www.amazon.co.jp/dp/B0C6JW6T6B?ref_=cm_sw_r_cp_ud_dp_Q44X6Q8W7NPXKP46168A
	- イマドキノ拡散モデル：拡散モデルに関する最近の研究動向を紹介。基本技術、条件付き生成への拡張、生成の高速化について述べ、拡散モデルを学ぶうえで役立つリソースを紹介。
- OpenAIのモデルを評価するフレームワークEval
	- https://github.com/openai/evals
	- **特定の課題に対してどれぐらい高精度で生成できているかを評価**できます。
- DADCのスマートビルガイドラインの補足資料が公開、
	- 補足資料って、最初から説明が足らなかっただろうに。
	- https://www.ipa.go.jp/digital/architecture/Individual-link/ps6vr7000001x8o0-att/smartbuilding_guideline_appendix.pdf
- 最近引退されたMITのストラング先生の、"Ther Art of Linear Algebra"の和訳、たった１４P、全理系は涙して読むべし
	- 「行列5分解」「行列の世界」「固有値地図」の視覚的解説
	- https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra/blob/main/The-Art-of-Linear-Algebra-j.pdf
- GTP-calls:コールセンターの会話を分析するアプリ、マイクロソフト
	- https://arxiv.org/abs/2306.07941
- シンボリック回帰と深層学習を組み合わせることで、データから方程式を見つける。
	- https://arxiv.org/abs/2207.00529
- GPT3.5 APIのアプデで使えるようになった16kトークンで何ができるか？
	- 青空文庫のちょっとした短編ならば、分析が可能になったレベルらしい
	- https://note.com/mahlab/n/n99577fabf16e
- GPTでのfunction callの良例
	- https://gist.github.com/hotchpotch/364cb8ae188e40f4e9ff1273232bc918
- OpenAI API の 関数呼び出し を試す、npakaさんの記事
	- **外部APIを呼び出して質問に答えるチャットボットの作成**
	- **自然言語をAPI呼び出しに変換**
	- **テキストから構造化データを抽出**
	- https://note.com/npaka/n/n917463f55b8a
- 欧州AI規制における、生成モデル、一般目的AIに対する義務事項
	- https://www.europarl.europa.eu/news/en/press-room/20230609IPR96212/meps-ready-to-negotiate-first-ever-rules-for-safe-and-transparent-ai
	- ban on AI for biometric surveillance, emotion recognition, predictive policing 
	- registration of models with EU 
	- detailed summary of training data 
	- requirement to identify deepfakes
-  第6回LangChainもくもく会開催レポート
	- https://note.com/mahlab/n/nc6ec4a9bd3c5
	- Grounded GenerationサービスVectara、LLMホスティングサービスBeam、SQLiteでベクトルDB検索が可能になるsqlite-vss、PostgreSQLのベクトル検索拡張pgvector、LangChain AI Handbookの話
- OpenAIのFunction Callをつかうと、LangChainのReAct Agentのようなこともできるという話（すげー、というか、エコシステム壊してないか？？？）
	- https://github.com/jerryjliu/llama_index/blob/main/docs/examples/agent/openai_agent.ipynb
	- llma_indexには、openai agentが組み込まれる予定らしい。
	- https://twitter.com/llama_index/status/1668995628146257921?s=20
- 「関数データ解析の概要とその方法」滋賀大学、松井先生
	- https://speakerdeck.com/hidetoshimatsui/guan-shu-detajie-xi-nogai-yao-tosonofang-fa
	- デーサイエンスで習う、回帰、クラスタリング、などのすべてが、データを関数として取り扱う枠組みで、再構成されている。なんともすがすがしいスライド。夏休みのお供に！
- 機械学習サービスにおけるONNXの活用と応用　〜ONNXテキスト形式の拡張〜
	- https://www.sportip.jp/blogs/onnx
	- やっぱり、ONNXにして、WebGPUつかって、ブラウザで動か用になるのね、
- Rinna-3.6B で 文脈付きの質問応答 を試す npakaさん記事より
	- https://note.com/npaka/n/n3bb60c61ef94
	- 「JSQuAD」は文脈付きの質問応答タスクで、53.42と半分以上正解
- 欧州AI規制に、現状のLLMはどれぐらい対応できているかのベンチマーク(スタンフォード題）
	- https://crfm.stanford.edu/2023/06/15/eu-ai-act.html
	- 現状特に著作権保護学習データ開示等が行われていないこと、DSA的透明性確保の非対称規制提言など
	- すごすぎでしょう。
- 知識グラフのLLMの統合についてのロードマップ論文
	- Unifying Large Language Models and Knowledge Graphs: A Roadmap
	- https://arxiv.org/abs/2306.08302
	- Combining the advantages of LLMs and knowledge graphs (KGs) is a promising direction.
- 欧州でEV電池規制　リチウムは8割再資源化、31年までに
	- 6/14日に欧州議会の投票を通過したという話、
	- EV,主要材料のリチウムは使用済み電池から2027年までに50%、31年までに80%を再資源化する必要がある。
	- 「電池パスポート」の導入も決まった
	- https://www.nikkei.com/article/DGXZQOGR1706S0X10C23A6000000/
- レヴィ＝ストロースの70年来の謎を進化シミュレーションで解明- 文化人類学の基礎「親族の構造」を数理モデルで生成 -
	- https://www.u-tokyo.ac.jp/focus/ja/press/z0109_00325.html
	- これって、LLMで同じことが多分1年以内のできるようになる。
- 　応用行動分析「死人テスト」死人にもできることを行動目標にしたいという話
	- https://twitter.com/81I6VVboj7h2Bqy/status/1667893285883621376?s=20
	- 「会議で余計な発言しない」、「廊下で走らない」、などは死人にもできる目標なので、それはまちがえであるということ。。その行動、死人にもできるのでは？

## 6/12

熊本で開かれた人工知能学会全国大会の話題もちらほら。偉い先生のまとめスライドが役に立つ。ローカルでLLMを動かす動きも相も変わらず活発。ggML形式のLLMならば、gpt4allのチャット用のソフトでllmを入れ替えて動くらしい。npaka氏のローカルＬＬＭのまとめは良記事。それにしても、4.75bitのSpQRって本当か？タンパク質やプロプロテインなどの研究対象の操作などができるチャットシステムも登場、そういう応用はこれからもたくさんでそう。データサイエンス界隈は、自らの存在意義的に、Noteableプラグインがよほど応えたらしい。ついにMSからChatでOffice製品を制御できる技術が発表、パワポも作ってくれるのか？その間googleのBardは、裏でコード実行する仕組みを取り入れ、苦手な計算とか論理などの精度が向上。今度はＧＡＳとの連携か。東芝福本氏の製造業における生成ＡＩの活用は一読の価値あり。倫理とか公平性という、上から目線より、「卵のためのＡＩ」に、わたしはなりたい。

- データ分析の効率が10倍上がるデータサイエンティストのためのChatGPTの活用術
	- https://qiita.com/ot12/items/96b5783568196d3320fe
	- さいごはNoteableなのか。。
- ChatGPTのように狙いの分子やタンパク質を編集できるChatDrug
	- https://arxiv.org/abs/2305.18090v1
- 「rinna」の日本語言語モデルを試用、メモリ32GBあればCPUだけでも動くぞ！
	- https://internet.watch.impress.co.jp/docs/column/shimizu/1503707.html
- GPT4ALL周りのソフトは、ggML準拠のモデルならば、gpt4allでなくても動くようになった！
	- The GPT4All Chat UI supports models from all newer versions of `ggML`, `llama.cpp` including the `LLaMA`, `MPT` and `GPT-J` architectures. T
	- https://docs.gpt4all.io/gpt4all_chat.html
- どうやらパラメータ数130億(13B)でChatGPT(GPT-3.5)クラスの性能が出せることがMSから発表
	- https://huggingface.co/papers/2306.02707
- こんどはProteinChat、構造があれば何でもよいのか。。
	- ProteinChat: Towards Achieving ChatGPT-Like Functionalities on Protein 3D Structures
	- https://www.techrxiv.org/articles/preprint/ProteinChat_Towards_Achieving_ChatGPT-Like_Functionalities_on_Protein_3D_Structures/23120606/1
- 確率的熱力学に経済学のツールを用いることで、熱力学と情報理論の間の相互作用について定量的に調べた
	- https://arxiv.org/abs/2306.00449
- 「大規模言語モデル入門」７月２９日発売予定
	- https://www.amazon.co.jp/dp/4297136333
- Microsoftの研究者らが新たに開発したAIシステム「Semantic Interpreter」は、Officeを操作、パワポが作れる。。
	- https://arxiv.org/abs/2306.03460
- DeepMindのAlphaDev、人の作りしソートアルゴリズムよりも高速なアルゴリズムを生成。
	- https://www.nature.com/articles/s41586-023-06004-9
	- といっても最適化しているだけだとか、ChatGPTでも同様な最適化ができたとの報告が続く。
	- https://chat.openai.com/share/95693df4-36cd-4241-9cae-2173e8fb760c
- 医療現場での、構造化されてない医療メモをつかったLLM
	- https://www.nature.com/articles/s41586-023-06160-y
- LlamaIndexの、JSON Query Engineの紹介ビデオ
	- https://www.youtube.com/watch?v=4tDyfAaIqEw
- 前篇　AIは「ジェスチャーゲーム」を知らない
	- 今井むつみ先生と、高野秀行の対談
	- 『言語の本質　ことばはどう生まれ、進化したか』の今井先生の対談
	- https://kangaeruhito.jp/interview/756531
- Googleの「Bard」が「暗黙的なコード実行」を導入、文字列の操作や論理・推論を含む複雑なタスクに対する回答精度が向上
	- やっぱBardやるね。
	- https://gigazine.net/news/20230608-google-bard-implicit-code-execution/
- Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners
	- https://arxiv.org/abs/2305.14825
- 東芝福本氏による、製造業で生成AIはどんな役割を果たすのか？ ドイツで見たMSやシーメンスらの取り組み
	- ハノーバーメッセでの展示の現地報告は貴重だ
	- https://www.sbbit.jp/article/st/115632
- 壁のためのAIと卵のためのAI
	- JSAI2023での学生企画、卵のためのAIになりたい。
	- https://speakerdeck.com/yukinobaba/ai-for-wall-and-ai-for-egg
- 松尾研による、「基盤モデルの技術と展望」
	- GPT-3など基盤モデルの技術的な動向について、数多くの文献をもとに整理されている
	- https://speakerdeck.com/yusuke0519/jsai2023-tutorial-ji-pan-moderunoji-shu-tozhan-wang
- 状態空間モデルを活用した時系列データのCausalImpact分析
	- https://speakerdeck.com/stakaya/zhuang-tai-kong-jian-moderuwohuo-yong-sita-shi-xi-lie-detafalsecausalimpactfen-xi
	- まあ、Rでなくても再現できそうだ。
- llamaindexのKnowledge Graphインデクス機能が大幅にパワーアップ？
- https://github.com/jerryjliu/llama_index/blob/main/docs/examples/index_structs/knowledge_graph/NebulaGraphKGIndexDemo.ipynb
- 欠損値を平均値を代入するというプラクティスが議論に、
	- 問題ないという人もいるが、問題ないならそもそも除外しても同じなのでは？
	- https://twitter.com/kenken26679105/status/1667288891949453312?s=20
- JSAI2023、人の位置情報の時系列をトークン列に置き換えてGPT-2で学習、人の移動軌道を生成する研究
	- https://confit.atlas.jp/guide/event/jsai2023/subject/2H5-OS-8a-02/tables?cryptoId=
- ローカルでlangchain経由で簡単につかえてそこそこ日本語も喋れるのwizard-vicuna-13 q8_0
	- https://twitter.com/if_004/status/1667474091564204033?s=20
- ローカルLLMのまとめ
	- https://note.com/npaka/n/nd95fba328b65
- 表形式データの行を1文と見て，差分プライベートに言語モデルを学習させ，そこから合成データを生成する手法を提案．複数のデータセットで既存のグラフィカルモデルベースのものと同等の性能
	- https://arxiv.org/abs/2306.04803
- 4.75bit 相当の量子化で、16fp と比べ損失ゼロの推論が可能
	- SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression
	- https://arxiv.org/abs/2306.03078
## 6/5
相も変わらず、4bit化とか、Rinna-3.6BのLoRaとか、ローカルでLLMを動かす、作る可能性が広がっている。まあ現状のLLMって実は疎なのではという特異値分解の結果も。じゃらんでChatGPT活用サービス試行開始。DeepLearningAIより、LangChainのショートコース無料開始、作者登場で豪華なことに。DeepAI OpenAIのLLMの苦手な計算問題での、「プロセス監視報酬モデル(PRM)」による改良。数値シミュレーションの世界でもLLM活用が。OpenAIのsecurity Portal発表。Grokking「過学習してしばらく経ってから、急に汎化誤差が下がり始める（正解率が上がり始める）」という現象への手がかりも。。言語学会からもLLMに対する元気のよい発信や出版が多数。ドイツ連邦データ保護当局（BfDI）の生成AIについての声明、これは読むべきか。日本のAI戦略会議の議論との温度差はいかんともしがたい。新聞記事の本論の前段の記事間違えを鬼の首を取ったように叩く、狭量な日本のDSメンタリティも興味深い。この政府にしてこの国民アリという感じか、逆か。

- DeepLearningAIより、LangChainのショートコースが、無料
	- 作者自身の登場で、豪華な構成に、
	-  LangChain for LLM Application Development
	- https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/
- biomedGPT: マルチモーダルな医療用のGPT
	- https://arxiv.org/abs/2305.17100
- AI戦略会議による、暫定的論点整理、日本はノーローなのか？これでいいの？
	- https://www8.cao.go.jp/cstp/ai/index.html
- LLM自身がPythonによるツール作成？Large Language Models as Tool Makers
	- https://arxiv.org/abs/2305.17126
- Google Colabで、ローカルランタイムでの実行ができるようになった。。
	- https://research.google.com/colaboratory/local-runtimes.html
- Transcendental Style in Film(映画における超越的様式)
	- https://twitter.com/routemopsy/status/1663396967417024513?s=20
	- ホウ・シャオシェンがタルコフスキー領域にあるのは解せない。
- 「 Google Colab で Rinna-3.6B のLoRAファインチューニングを試す」
	-  なんと14Gでできるなら、無料枠？
	- https://note.com/npaka/n/nc387b639e50e
- Large Language Models are not Fair Evaluators
	- https://arxiv.org/pdf/2305.17926.pdf
-  How To Finetune GPT Like Large Language Models on a Custom Dataset
	- Macbookでも簡単にfinetuneできるようになった
	- https://lightning.ai/pages/blog/how-to-finetune-gpt-like-large-language-models-on-a-custom-dataset/
- 「ChatGPTの仕組みと社会への影響」、京大黒橋先生のわかりやすいといわれる講義、１９分でさくっと
	- https://www.youtube.com/watch?v=aKqIPlDyWhs
- 「ChatGPTとNoteableによる科学技術情報分析」
	- https://speakerdeck.com/hayataka88/chatgpttonoteableniyoruke-xue-ji-shu-qing-bao-fen-xi
	- 噂のNoteable。ついに、お話しするだけで、EDAから回帰まで、、
- Let's Verify Step by Step by OpenAI
	- LLMが苦手な計算問題をとかせるために、process supervisionというのをどうにゅ
	- 「プロセス監視報酬モデル(PRM)」というらしい。
	- https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf
- NIIのオープンハウス(6/1-6/3)、ChatGPTネタ大杉。
	- https://www.nii.ac.jp/event/openhouse/2023/
- 因果推論のコースマテリアル
	- https://arxiv.org/abs/2305.18793
- Rinnaすごいかも。japanese-gpt-neox-3.6b-instruction-ppo
	- https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo
- 局所詳細釣り合い、ゆらぎの定理、Jarzynski等式と拡散モデルの関係
	- https://zenn.dev/xiangze/articles/6e8ce8b8d43d08
	- そういうものらしい
- rinna/japanese-gpt-neox-3.6b について、ベース、SFT、RLHFで動かした例 on colab
	- https://note.com/npaka/n/ne4a38239f420
	- ベースなら無料枠で動く？
- じゃらんでAIチャットサービス開始
	- https://note.com/npaka/n/ne4a38239f420
- Rinna-3.6B を llama.cpp で CPU 動作のメモ
	- https://zenn.dev/syoyo/articles/946c17666e10fb
	- CPUだけでも十分動くのか。。。
- Berry: A code for the differentiation of Bloch wavefunctions from DFT calculations
	- https://arxiv.org/abs/2006.02744
	- DFT計算で得た波動関数を微分するためのオープンソース
- What Is ChatGPT Doing … and Why Does It Work?
	- https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
	- Wolfman AlphaのWolfmanさんの記事、
	- 「現在のChatGPTの場合，事態はもっと極端で，各トークンの出力を生成するためのニューラルネットはループのない純粋な「フィードフォワード」ネットワークであるため，自明でない「制御フロー」を持ついかなる計算も行うことができない
- Googleによる図式を理解するLLM
	- Foundation models for reasoning on charts
	- https://ai.googleblog.com/2023/05/foundation-models-for-reasoning-on.html
-  Physics-constrained machine learning for scientific computing
	- https://www.amazon.science/blog/physics-constrained-machine-learning-for-scientific-computing?_amp=true
	- 保存則と境界条件の制約を守りつつ偏微分方程式の解を求めるディープラーニングモデル。Amazon ScienceからICMLとICLRで発表
- LLMでドメイン特化言語を作りまくり？
	- https://huggingface.co/papers/2305.19234
	- Grammar Prompting for Domain-Specific Language Generation with Large Language Models
- OpenAI のCEOのインタビュー、GPUリソースが世界的に足らないのはGPT-4のマルチモーダル学習中のため？
	- https://humanloop.com/blog/openai-plans
- 「AIに脅かされる「個人」　情報を断ち切る規制必要」　政治季評
	- https://www.asahi.com/articles/ASR5065XLR5YUSPT006.html
	- 中身は議論されず、最初のChatGPTはオープンソースのところに、鬼首をとったようにかみつくDS界隈
- QCDの１方程式から多様な世界が作り出されるチャート
	- http://suganuma-hideo.o.oo7.jp/hideo/index.files/main.files/HQCD.pdf
- “According to . . . ” Prompting Language Models Improves Quoting from Pre-Training Data
	- Wikipediaによると、、、を付け加えるプロンプトテクニック？
	- LLMが事前学習データから直接引用するように誘導し、生成される情報の信頼性を向上
	- https://arxiv.org/pdf/2305.13252.pdf
- inna-3.6b-instruction-oppのggml 4q_2を作って、LangChainのsummarize chainで使ってみました…
	- https://twitter.com/8hmVmEGJ6nFyUE5/status/1663936372363898880?s=20
	- やっぱりggmlと4bitが最強なのか。。モデルサイズが2Gって、あーた
- LLMをつかって、微分方程式から保存則を抽出する？？
	- Discovering New Interpretable Conservation Laws as Sparse Invariants
	- https://arxiv.org/abs/2305.19525
- OpenAIがsecurity portalを公開
	- https://trust.openai.com/
- つい最近引退された、ストラング教授（線形代数他）のインタビュー記事
	- https://news.mit.edu/2023/gilbert-strang-made-linear-algebra-fun-0531
- GPT4ALLをつかって、GPUなしで、ローカルPCでLLMを動かす
	- https://gpt4all.io/index.html
	- A free-to-use, locally running, privacy-aware chatbot. **No GPU or internet required.**
- ChatGPTプラグイン「Notable」だけでデータ分析コンペに挑戦してみた話
	- https://qiita.com/ot12/items/ba74fa150e160d94a71f
	- やっぱりNoteableは最強の件、来年のデータサイエンス特論のネタにしよう！
- A Mechanistic Interpretability Analysis of Grokking
	- 学習が進むと突然、未見のデータに一般化するように学習する現象のメカニズムの解明だそうだ
	- https://www.alignmentforum.org/posts/N6WM6hs7RQMKDhYjB/a-mechanistic-interpretability-analysis-of-grokking
- カモシカ-LoRaから、OpenCALM 7B, 3Bをファインチューニングして作成したアダプタを公開
	- https://twitter.com/kam0shika/status/1663906516276051969?s=20
- Transformer.js、ブラウザやnodejsからhuggingfaceのtransformerが使える
	- https://github.com/xenova/transformers.js
- 特異値分解で30%もLLMを圧縮しても性能が変わらなかった
	- LLMってやっぱり疎なのね
	- ~30% Compression Of LLM (Flan-T5-Base) With Low Rank Decomposition Of Attention Weight Matrices
	- https://smashinggradient.com/2023/05/23/30-compression-of-llms-with-low-rank-decomposition-of-attention-weight-matrices/
- LQML;
	- LMQL (Language Model Query Language) is a programming language for large language model (LM) interaction. 
	- https://docs.lmql.ai/en/stable/
- Andrew Ngさんによる米軍AIドローンシミュレーション（操作者を殺すという結論）への反駁
	- https://twitter.com/AndrewYNg/status/1664694504476102680?s=20
- スタンフォード大学による、機械学習もろもろチートシート
	- https://github.com/afshinea/stanford-cs-229-machine-learning
- LangChainをサポートするvicuna-13bモデルをrinnaが公開
	- https://huggingface.co/rinna/vicuna-13b-delta-finetuned-langchain-MRKL 
	- https://note.com/hamachi_jp/n/n97d368a617ac
- A Survey on Large Language Models for Recommendation
	- https://arxiv.org/abs/2305.19860v2
- 分子生物学にLLMが最適な件
	- https://towardsdatascience.com/large-language-models-in-molecular-biology-9eb6b65d8a30
- GPT4ALLとLangChainとChromaをつかった、ローカルに動く最小限のQ&A
	- https://twitter.com/AssemblyAI/status/1661747770108305409?s=20
- 「ChatGPTの出現は自然言語処理の専門家に何を問いかけているか」
	- 言語学会の乾先生の巻頭言
	- 「では，これで自然言語処理は終わるのか？ もちろん，終わらない．解くべき課題，新たに生まれる問いは山ほどある．」
	- https://www.anlp.jp/topics/topic230601.html
- 「言語の本質　ことばはどう生まれ、進化したか (中公新書)」
	- 今井むつみ, 秋田喜美の本、
	- https://www.amazon.co.jp/dp/B0C4XF523T?ref_=k4w_ss_dp_lp
-  Langchain・Semantic Kernel・guidanceでエージェント機能を実装して比較してみた
	- https://qiita.com/sakue_103/items/6ffee0bc267e71eafd60
- 時系列データにおける特徴量エンジニアリング by NRI
	- https://datascience.nri.com/entry/2022/10/12/155350
- ドイツ連邦データ保護当局（BfDI）の生成AIについての声明（5月22日）、 by 生貝先生
	- https://www.bfdi.bund.de/SharedDocs/Downloads/DE/DokumenteBfDI/Stellungnahmen/2023/StgN_Generative-K%C3%BCnstliche-Intelligenz.pdf?__blob=publicationFile&v=2
	- GDPR的なリスクベースアプローチとDSA的なシステミックリスクアプローチの対比など興味深い。青少年学習データのフィルタリングやAI規則の川上川下問題なども
- Jupyter AIが出た！試した！！すごい！！！
	- https://qiita.com/moritalous/items/a270d5932ebee18d0ba8?utm_content=buffer352b5&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer
	- すごいらしい
- 

## 5/29
Microsoft BuildでWindowsとGPTとの統合とか、BingでもChatGPTのプラグインが使えるようになるとか、相も変わらずMicrosoftはどうやって投資を回収できるのか不明。Adamを超えるSophiaの登場や、4bit化のQLoRaの登場など、個人や企業でのLLM作成には朗報であるが、LLMの民主化って危険もあるよね。なので、DeepMindやMicrosoftは倫理性やリスクに関する研究をちゃんと続けて公開している。Voyagerすごい、研究開発のタスクももGPT-4でできるのでは？WebGPUを使ったwebllm、nodejs版でも動く模様。microsoftはguidanceでモデル利用の効率化の工夫を行っているとの報告も。アブダビから謎の巨大LLMであるFalcon-40Bが発表されるも、OSSとうたいつつ実は謎ライセンスであっというまに叩かれる。SQLとかNotableとかデータサイエンス系のChatGPTの活用が本格的に。祝！SIAMの賞の受賞、蔵本先生！！！。欧州AI規制の最終投票を目前に、OpenAI、欧州AI規制遵守が困難と判断されれば、欧州からサービス引き上げとの記事。ChatGPTアプリが日本でもiPhoneに登場、似たような名前のアプリがたくさんあって、、、。

- MicorsoftのAIが倫理的であるかどうかを評価するツールキット
	- https://github.com/microsoft/responsible-ai-toolbox
- 知識グラフのneo4jと、LangChainからの利用、Cypher問い合わせを自動生成する
	- https://python.langchain.com/en/latest/modules/chains/examples/graph_cypher_qa.html
- LIMA: Less Is More for Alignment
	- Lucan先生によると、LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance
	- https://arxiv.org/abs/2305.11206
- scikit-llm: scikit-learnとLLMをシームレスつにつなげる
	- https://github.com/iryna-kondr/scikit-llm
- LangChainからAzure OpenAI を使うメモ
	- https://qiita.com/tmiyata25/items/7a04096342241d8a2b4c
- Textually Pretrained Speech Language Models：なんか音声をいれると音声を出力するLLM!!
	- https://pages.cs.huji.ac.il/adiyoss-lab/twist/
- ImageBind　by Meta、マルチモーダルな学習
	- https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=blog&utm_content=card
- open-calm-7b を databricks-dolly-15k-ja で LoRA したのをマージして ggml にして 4bit 量子化して redpajama.cpp で MacBook ローカルで動く日本語高速チャットボット
	- https://twitter.com/niw/status/1660894493867134976?s=20
-  LLaMAベースの日本語大規模言語モデル(LoRaした)公開
	- https://llm.msuzuki.me/
- Microsoft Build開催、OSとLLMが融合？
	- https://blogs.microsoft.com/blog/2023/05/23/microsoft-build-brings-ai-tools-to-the-forefront-for-developers/
- LLM向けの学習最適化エンジンSophia、アダムを超えるか
	-  Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training
	- https://arxiv.org/abs/2305.14342
- QLoRa: HuggingFaceのモデルが、4bit化されたものが使えるようになる？
	- https://huggingface.co/blog/4bit-transformers-bitsandbytes
- Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks
	- https://huggingface.co/papers/2305.14201
- 自然言語のpromptによるLLMの利用は、LLMの本来の能力を生かしきれてない
	- https://arxiv.org/abs/2305.13264v1
- QLoRaを使えば、普通のcolabにて、数時間でLLMができるという報告。4bit最強。
	- 33B-parameter LLM on Google Colab in a few hour
	- https://twitter.com/ItakGol/status/1661714548594823174?s=20
- OpenCALM-7BをLoRAでFine tuningして対話ができるようにする
	- https://note.com/masuidrive/n/n0e2a11fc5bfa
- Reasoning with Language Model is Planning with World Model
	- CoT on GPT-4との比較で勝るとのこと
	- https://arxiv.org/abs/2305.14992
- Voyager: 長期的な探索をGPT-4でやらせる例。Minecraftをやらせたら、、（研究開発も。。。）
	- https://github.com/MineDojo/Voyager
- 祝！蔵本先生、SIAMでJürgen Moser Lecture賞受賞！受賞講演
	- https://www.youtube.com/watch?v=2P-EgTSa-E4&feature=youtu.be
- DeepMindから、一般的なAIモデルが潜在的に持ちうる有害なリスクを評価するフレームワーク
	- https://www.deepmind.com/blog/an-early-warning-system-for-novel-ai-risks?utm_source=twitter&utm_medium=social&utm_campaign=ModelEval
- WebGPUをつかってLLMを動かす仕組み、WebLLMが、nodejsでも動く？？
	- https://github.com/mlc-ai/web-llm
- LangChainからDatabricksを使う
	- https://python.langchain.com/en/latest/modules/models/llms/integrations/databricks.html
- アブダビの研究所からFalcon-40Bが発表、オープンソースなのに、ライセンス料が必要みたいな罠が見つかる。
	- https://huggingface.co/tiiuae/falcon-40b
	- 「売上の10%をロイヤリティとして12ヶ月毎に支払わなければならない」
- microsoft/guidance(LangChainのようなもの）をつかって、Agentを定義して、動かす
	- https://note.com/explaza_inc/n/n7cb8043506bd
- OpenAIがgptサービスの５月の速度低下をレポートするものが
	- https://twitter.com/helicone_ai/status/1662325356563496961?s=20
- Googleが生成AIの無料講座を公開
	- https://www.cloudskillsboost.google/journeys/118
- SQLを活用したデータ分析におけるChatGPTの活用法
	- https://speakerdeck.com/hikarut/sqlwohuo-yong-sitadetafen-xi-niokeruchatgptnohuo-yong-fa
- ChatGPTのデータサイエンス向けのプラグインNotableが便利との記事
	- https://secon.dev/entry/2023/05/27/170000-noteable-iris/
- Lucan先生、GAFAMの代わりに、MAGMAを造語。 Meta, Amazon, Google, Microsoft, App
	- https://twitter.com/ylecun/status/1662375684612685825?s=20
- OpenAIのアルトマンCEO、「EU AI Act順守が困難ならEUでの事業は停止する
	- https://www.itmedia.co.jp/news/articles/2305/26/news106.html

## 5/22
ChatGPT以外のOSSのLLMでは、googleのFLAN-20B with UL2 ぐらいならば、なんとか同等の性能がでるという報告も(A100が必要)。privateGPTや、GPT4ALLなどの、ローカル環境で動かせるOSSのLLMもだいぶそろってきました。PyTorchをブラウザ環境'(TypeScriptで）動かす仕組みも登場。しかし本命は、WebGPUをつかって、ブラウザ以外からもLLMをローカルで高速に動かす試みには期待したいところ。いっぽうTinyStoriesなど、どれだけLLMを小さくできるかな？的なアプローチも続く。Tramnsformerも偏微方程式を解くなど、物理モデルの領域に広げる試みも。日本からは日本語版LLMが複数出現、実力のほどは？？LLMの説明性やバイアス対策なども。ChatGPTがついにIPhoneに乗る（USのみ）。MicrosoftはLLMを使いやすくするフレームワークGuidanceを発表、SemanticKernelの立場は？？Marvinのような、LLMとプログラミングの融合パラダイムには可能性がありそうです。

- LLMのバイアスをあぶりだす、Constructive Input Decoding(CID) by google
	- https://arxiv.org/abs/2305.07378
- privateGPT:ローカル環境で動く最小限のGPT、LangChain, GPT4All, LlamaCpp, Chroma and SentenceTransformersを活用
	- https://github.com/imartinez/privateGPT
- TinyStories:３～４才ぐらいが理解できる短い文書のデータセット、どれだけLLMを小さくできるかを評価するためのもの by Microsoft
	- https://arxiv.org/abs/2305.07759
- Google/OpenAIがオープンソースのLLMを開発している。
	- https://www.theinformation.com/articles/open-source-ai-is-gaining-on-google-and-chatgpt
- Marvin:プログラミングとLLMの補助を組み合わせた新しいパラダイム、LMQLみたいな感じ？スキーマに従ってデータ抽出など
	- https://note.com/hamachi_jp/n/na1960fc9d6d3
	- https://www.askmarvin.ai/
- Excelとチャットする、titnanicの例で、前処理のところをチャットで実現
	- https://github.com/Anil-matcha/Chat-With-Excel/blob/main/Data_analysis_with_langchain.ipynb
- Physics Informed Token Transformer(PITT)：偏微分方程式(PDE)をトークン化してエンベディングし、PDEの解を求める機械学習手法として有名なFourier Neural Operator(FNO)の補正として利用
	- https://arxiv.org/abs/2305.08757v1
- Abbeel教授によるHinton教授へのインタビュー、NYTimesの記事依頼、全世界から２分毎ｎ取材依頼が来たらしい
	- https://www.youtube.com/watch?v=rLG68k2blOc
- 医療分野に特化した言語モデル「Med-PaLM2」の論文、現役の医者もPaLM2の回答のほうを評価
	- https://arxiv.org/abs/2305.09617
- rinna、日本語に特化した36億パラメータのGPT言語モデルを公開
	- https://rinna.co.jp/news/2023/05/20230507.html
- MicrosoftがLangchainみたいな、Guidanceを発表
	- https://github.com/microsoft/guidance
- CyberAgentが日本語版ローカルLLMを発表
	- https://huggingface.co/cyberagent
- Google の FLAN-20B with UL2 レベルならば、ChatGPT APIのように使えるらしい	
	- https://qiita.com/sakasegawa/items/7394fe68eb0087b3c4a5
- Google、自社のcolabratoryに、コード生成機能を搭載するらしい
	- https://blog.google/technology/developers/google-colab-ai-coding-features/
- Transformer.js: Hugging Faceのtransformerを、ブラウザで動かすことができる、ONIX runtimeを利用、WebGPU対応は不明
	- https://github.com/xenova/transformers.js
- Graph Neural Network(GNN)で、巡回セールスマン問題を解く、スタンフォード大学の講義での事例、CS224W
	- https://medium.com/stanford-cs224w/tackling-the-traveling-salesman-problem-with-graph-neural-networks-b86ef4300c6e
- OpenCALM-7Bをdolly-15k-jaでLoRAしたら、ある程度会話できるようになった
	- https://twitter.com/masuidrive/status/1659089478781227008?s=20
- LLMの出力の説明に関する論文らしい、Explaining black box text modules in natural language with language models by microsoft
	- https://huggingface.co/papers/2305.09863
- TokenHawk、WebGPUを活用して、ローカルで、WebでLLMを動かすことができる仕組み、GoogleのDawnエンジン利用
	- https://github.com/kayvr/token-hawk
-  ChatGPTがiPhoneで動くようになる(米国)
	- https://openai.com/blog/introducing-the-chatgpt-app-for-ios
- Trasnformerを制御に用いる、# A Generalist Dynamics Model for Control、by DeepMind
	- https://huggingface.co/papers/2305.10912
- LangChainから、Spark SQL Agent
	- https://python.langchain.com/en/latest/modules/agents/toolkits/examples/spark_sql.html
- LangChainから、ローカルにダウンロードしたGPT4ALLの使い方改善
	- https://python.langchain.com/en/latest/modules/models/llms/integrations/gpt4all.html
- Language Models Meet World Models: Embodied Experiences Enhance Language Models
	- https://arxiv.org/abs/2305.10626
- WebGPU-pytorch、pytorchが、webGPUの上で動く（学習、推論とも）
	- https://github.com/praeclarum/webgpu-torch
-  Hugging FaceのモデルをLangChainで使う方法を調べた、Hubを使うか、ローカルにダウンロードして使うか、
	- https://www.mattari-benkyo-note.com/2023/05/19/langchain_hugging_face/
- Stanford大学のTransformerの事業CS２５が最強の件
	- https://web.stanford.edu/class/cs25/
- Stanford大学、文字列のアライメントライブラリstring2string
	- https://github.com/stanfordnlp/string2string
- Self-Queringという手法、による文書検索Weaviate、スキーマを与えると、検索結果に、情報抽出の結果も出してくれる（曲のratingとかgeneとかのメタデータなど）もやってくれる。おおすごい
	- https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/weaviate_self_query.html
- BCGがまとめた日本企業の変革を阻む「チェンジモンスター」資料、ポケモン的なキャラクター付け
	- https://web-assets.bcg.com/img-src/japan%20tembo-146-change%20monster_1oct2002_tcm9-169992.pdf


## 5/15
最新のLLMに関する情報は、Transformer論文のアーキテクチャの議論や応用プロンプトエンジニアリングの探求、アッセンブリ理論の応用、AGIの悲観論、Shap-Eのデモサイト、LLamaindexの要約機能追加、GPT-4のニューロン説明試み、分子生成モデル改良、医師国家試験合格報道、WebGPUでのLLM実行、PaLM 2の発表、Q&A向けretreaver、BardとGPT-4性能比較、フォント問題、HumanML3Dデータセット、DeepL日本拠点計画、3D Tilesプロジェクト、日本語T5モデル、LeCun講演、ChatGPT Plugin提供、分子励起状態予測、機械学習理論発展、GTモデル作成、推薦システム研究、量子機械学習研究者転向、Helion Energyへの電力購入契約、牧野先生の不偏分散解説、Scikit-learnデータセット変更、Vicuna-13B-4bit実行方法、LangChainのretriever追加など多岐にわたります。

- オリジナルのTransformer論文のアーキテクチャ構成の絵が、本文と合ってないと記事が、
	- https://arxiv.org/abs/2002.04745
- few-shot learningで満足できない人の応用プロンプト集
	- https://cameronrwolfe.substack.com/p/advanced-prompt-engineering
- アッセンブリ理論、有機化合物で分子の結合の複雑さの評価、LLMの評価にも使える？
	- https://www.quantamagazine.org/a-new-theory-for-the-assembly-of-life-in-the-universe-20230504/
- AGIが人類を壊滅させる可能性はほぼ100%といった強い悲観論、AI Alignment Centerの人の話によると、
	- https://note.com/bioshok/n/n43041a52a529
- OpenAIが公開した、プロンプトから3Dモデルを作るShap-Eのデモサイトがhuggingfaceに。
	- https://huggingface.co/spaces/hysts/Shap-E
- LLamaindexに新しいドキュメント要約の仕組みが導入？
	- https://medium.com/llamaindex-blog/a-new-document-summary-index-for-llm-powered-qa-systems-9a32ece2f9ec
- OpenAI: GPT-4で、GPT-2の個々のニューロンの働きの説明というか、意味づけを行う？？	
	- https://openai.com/research/language-models-can-explain-neurons-in-language-models
- VAEによる分子生成のモデルの改良の話
	- https://arxiv.org/abs/2305.03041v1
- GTP-4日本の医師国家試験で合格？
	- https://news.yahoo.co.jp/articles/60da4c733c2a03a9829bc598f8dcc246e4d10b00
- LLamaindexにて、正式にhuggingfaceの LLM support　される
	- https://github.com/jerryjliu/llama_index
- WebGPUで、LLMをローカルに動かす動きが活発に、LaMA, Alpaca, Vicuna, and Dol
	- https://github.com/mlc-ai/web-llm
- Google I/OでPaLM 2を発表
	- https://ai.google/static/documents/palm2techreport.pdf
- Wikipediaに対するQ&Aを可能にするretreaverを提供するCoheare?
	- https://github.com/menloparklab/cohere-weaviate-wikipedia-retrieval
	- https://github.com/weaviate/weaviate
- Google I/Oが大収穫だった模様、Bardは日本語、韓国語対応、 Bard、PaLM 2
	- https://www.gizmodo.jp/2023/05/google-io23-ai-outline.html
- BardとGPT-4の性能比較、結構GPT-4に肉薄している模様。
	- https://qiita.com/kumag0r0/items/77dbe743643183ae3e98
- Bard発表のプレゼンで、「日本語」のフォントが残念と話題に、、、
	- https://www.itmedia.co.jp/news/articles/2305/11/news178.html
- HumanML3D:Human motion language Dataset
	- https://github.com/EricGuo5513/HumanML3D
- DeepL日本に拠点を置く？
	- https://newsdig.tbs.co.jp/articles/-/480597?display=1
- GoogleのPhotorealistic 3D Tilesを[http://deck.gl](https://t.co/j5x1oduUK1)で表示、軽いらしい
	- https://twitter.com/syanseto/status/1656586481094520838?s=20
	- deck.lg(TerrainExtension) + Google Photorealistic 3D Tiles 
	-  Google 3D tileで読み込んだ3Dモデルの上にTerrainExtensionを使ってGeoJSONポリゴンをオーバーレイ
- 日本語T5モデルの公開 by レトリバ
	- https://note.com/retrieva/n/n7b4186dc5ada
- LeCun先生の講演、LeCun: Towards Machines That Can Understand, Reason, & Plan
	- https://www.youtube.com/watch?v=_JfEScYyVCE
- OpenAI、ChatGPT Plusユーザー全体に、5/12よりPluginが使えるようなるとアナウンス
	- https://help.openai.com/en/articles/6825453-chatgpt-release-notes
- 拡散モデルを用いることで２次元の分子グラフからでも同等の励起状態の予測精度が得られるという話らしい
	- https://arxiv.org/abs/2304.12233v2
- 機械学習理論発展、Hyperbolic Poincaré distributions = Probability distributions with support the Poincaré disk
	- https://arxiv.org/abs/2205.13984
- Graph Transformer (GT)を作る例題
	- https://arxiv.org/pdf/2012.09699.pdf
- 推薦において、ユーザーの嗜好って、LLMは本当に理解してるんだったけ論文。
	- https://arxiv.org/abs/2305.06474
- 量子機械学習の研究者が、軒並み量子をやめて機械学習にいってるという、組合せ最適化の大家である湊先生の嘆き
	- https://twitter.com/MinatoYuichiro/status/1657243184064499712?s=20
- GoogleのPhotorealistic 3D Tiles（左）と国交省の3D都市モデルPLATEAUの3D Tiles（右）の比較
	- https://twitter.com/syanseto/status/1656964913913540608?s=20
- ChatGPTとOSSのLLM達とガチタスクでの比較、いい線言ってるらしい。Vicuna-13B, ChatGPT (3.5), MPT-7B-Chat
	- https://medium.com/@marcotcr/exploring-chatgpt-vs-open-source-models-on-slightly-harder-tasks-aa0395c31610
- PrivateGPT:単にOSSのLLMをダウンロードしてチャットに仕立てる、LangChain and GPT4All and LlamaCpp
	- https://github.com/imartinez/privateGPT
- OpenAIの Sam Altman氏の、謎のツイート"summer is coming"
	- https://twitter.com/sama/status/1657405294354518017?s=20
- 東大吉田塁（酒場の人ではない）先生の、「教員向けChatGPT講座」が分かりやすいと評判に、
	- https://www.youtube.com/live/lwccHzqfuvc?feature=share
- Pluginを開発するOSSである、PlugnPlai and LangChainの例
	- https://github.com/edreisMD/plugnplai/blob/master/examples/plugins_step_by_step.ipynb
- HuggingFaceから、自然言語でAgentに指示を出したら画像でも文章でも音声でも出力してくれるモデルを勝手に選んで出力してくれるTransformers  Agent発表、
	- https://huggingface.co/docs/transformers/transformers_agents
- Microsoft社、Sam Altman氏が出資する核融合スタートアップであるHelion Energyと2028に電力購入契約
	- https://www.businessinsider.jp/post-269773
	- 加速器で、重水素とHe-3を加速させて衝突時に、磁場で圧縮して、融合させて、膨張の力による磁場の変化から直接電力を（水とか蒸気とかを使わずに）得るという仕組み。
	- OpenAIはますます、Microsoftと一蓮托生に、、、、
- 神戸大学、「牧野」先生、不偏分散の自由度がn-1である理由を失念。
	- https://twitter.com/jun_makino/status/1657229042121314304?s=20
	- 牧野先生ご紹介の「美しい導出」https://manabitimes.jp/math/1205
- Scikit-learnの組み込みデータセットから、ボストン住宅価格が、ポリコレのため削除されてた
	- https://twitter.com/tokoroten/status/1394192087453638662?s=20
	- （授業で使っている人要注意）
- Stable Vicuna-13B-4bitがcolabで動作する、ローカルにダウンロードしてWebUIを上げる
	- https://zenn.dev/tatsuromurata/articles/8e523cf2d0c2bc
	- https://note.com/it_navi/n/nceffc6e8df35
- LangChainに、arxiv用のretrieverが追加、Q&Aなどができる
	- https://python.langchain.com/en/latest/modules/indexes/retrievers/examples/arxiv.html

## 5/8
LLamaIndex 0.6.0がリリースされ、データに対する新しいクエリインターフェイスが導入されました。ChatGPT Code Interpreterが登場し、プログラムの解釈と実行が可能になりました。
Andrew Ngのプロンプトエンジニアリングの講義が提供され、開発者向けにプロンプトエンジニアリングのスキルが教授されます。Transformerのenc-dec間にinformation bottleneckを導入したVAE的な表現の正則化に関する研究が行われました。"Are Emergent Abilities of Large Language Models a Mirage?"と題された論文が公開され、LLMの新たな能力に関する議論が提起されました。
JDLAでは、生成AIの利用ガイドラインが提供され、AIの利用に関する指針が提案されましたLangChainとOpenAIのGymnasiumが連携し、エージェントシミュレーションに関する利用事例が紹介されました。ディープラーニングによる自然言語処理に関する書籍が出版され、NLPに興味を持つ方に向けたリソースが提供されます。"Causal Reasoning and Large Language Models: Opening a New Frontier for Causality"という論文が公開され、因果推論とLLMの関連についての研究が行われました。自己アテンション機構を使用して多電子系のシュレディンガー方程式を第一原理的に解く研究が行われOpenLLAMAが公開され、LLMを活用したデータクエリエンジンが提供されます。G.HintonによるGAI（General Artificial Intelligence）に関するインタビューがCNNで公開され、AIの未来についての議論が展開されました。"Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings"という記事が公開され、LLMの性能評価に関する情報が提供されました。"TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis"と題された研究が行われ、テキストからヒューマンモーションを生成する技術が提案されました。

- LlamaIndex 0.6.0 - データに対する新しいクエリインターフェイス
	- https://note.com/npaka/n/n4254fc549dc0
- ChatGPT Code Interpreter
- Andrew Ngのプロンプトエンジニアリングの講義
	- https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/
- Transformerのenc-dec間にinformation bottleneckを入れてVAE的に表現の正則化
	- https://openreview.net/forum?id=6QkjC_cs03X
- Are Emergent Abilities of Large Language Models a Mirage?
	- https://arxiv.org/abs/2304.15004
- JDLAでは、「生成AIの利用ガイドライン」
	- https://www.jdla.org/document/?utm_source=prtimes&utm_medium=referral
- LangChainとOpenAIのGymunasiumの連携
	- https://python.langchain.com/en/latest/use_cases/agent_simulations/gymnasium.html
- ディープラーニングによる自然言語処理
	- https://www.amazon.co.jp/dp/4320125029/
- Causal Reasoning and Large Language Models: Opening a New Frontier for Causality
	- https://arxiv.org/abs/2305.00050
- 自己アテンション機構をつかって多電子系のシュレディンガー方程式を第一原理的に解く
	- https://arxiv.org/abs/2211.13672
- OpenLLAMA
	- https://github.com/openlm-research/open_llama
- G.Hintonによる、GAIインタビュー @CNN
	- https://www.youtube.com/watch?v=FAbsoxQtUwM
-  Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings
	- https://lmsys.org/blog/2023-05-03-arena/
- TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis
	- https://mathis.petrovich.fr/tmr/
- LLMs & Causal Reasoning
	- https://arxiv.org/abs/2305.00050
- LangChainのv0.0.139からv0.0.151までの差分を整理（もくもく会向け）
	- https://note.com/mahlab/n/ne29d4bfb1d45
- LLAMAindexの新しい抽象化API,brand new “router” abstraction in order to build powerful, generalizable, LLM-powered query engines over your data.
	- https://colab.research.google.com/drive/1KH8XtRiO5spa8CT7UrXN54IWdZk3DDxl?usp=sharing
- ホワイトハウスNew Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and  Safety
	- https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/
- OpenAlpaca, an instruction-following model based on OpenLLaMA
	- https://github.com/yxuansu/OpenAlpaca
- 「LlamaIndex」が0.6.0で大きな変更があったので更新しました。
	- https://note.com/npaka/n/n50475d6c3118
- ChromaDB Self-Querying Retriever
	- https://github.com/hwchase17/langchain/blob/master/docs/modules/indexes/retrievers/examples/chroma_self_query_retriever.ipynb
- experimental CodeChain、LangChainの上でPythonを実行できるらしい。
	- https://langchain-ai.github.io/kork/
- Unifying LLM-powered QA Techniques with Routing Abstractions
	- https://betterprogramming.pub/unifying-llm-powered-qa-techniques-with-routing-abstractions-438e2499a0d0
- PandasAI、またまたpandaベースのチャット解析ツール、OpenAI以外のLLMの使えそう。
	- https://github.com/gventuri/pandas-ai

## 4/10
LLMの倫理的なふるまいを評価するためのマキャベリベンチマークが発表されました。LLaMA-Adapterと呼ばれる、軽量なLoRAのようなシステムが紹介されました。DeepMindからは、Transformersのための形式的なアルゴリズムに関する研究が発表されました。LLMに対する心理学的な評価やセラピーを行うための枠組みが提案されました。リーガルなGPT-4ベースのサービスであるHarveyが公開されました。京大2回生の統計力学の期末試験の問題が論文になった話があります。AzureのOpenAIがEmbeddingのバージョン2をリリースし、トークン数が2,048から8,191に増加しました。MatChaと呼ばれるシステムが、グラフなどの入力から推論やQ&Aを行うことができるようになりました。gpt4allの公式チャットUIがリリースされました。Microsoft ResearchのSparks of AGI: early experiments with GPT-4に関する説明がYouTubeで提供されています。

-   LLMの倫理的なふるまいをさせるための、マキャベリベンチマーク
    -   [https://arxiv.org/abs/2304.03279](https://arxiv.org/abs/2304.03279 "https://arxiv.org/abs/2304.03279")
-   LLaMA-Adapter:軽量なLoRAみたいなしくみらしい。
    -   [https://arxiv.org/abs/2303.16199](https://arxiv.org/abs/2303.16199 "https://arxiv.org/abs/2303.16199")
-   DeepMindから "Formal Algorithms for Transformers"
    -   [https://arxiv.org/abs/2207.09238](https://arxiv.org/abs/2207.09238 "https://arxiv.org/abs/2207.09238")
-   LLMに対して心理学的な評価（セラピー？）を行う枠組み
    -   [https://arxiv.org/abs/2207.09238](https://arxiv.org/abs/2207.09238 "https://arxiv.org/abs/2207.09238")
-   リーガルなGPT-4ベースのサービス、Harvey（米ドラマのSUITSの主人公の一人がハーベイ）
    -   [https://harvey-ai.notion.site/Careers-Harvey-c9e804fe422e4316bdfde9fe74ed6b06](https://harvey-ai.notion.site/Careers-Harvey-c9e804fe422e4316bdfde9fe74ed6b06 "https://harvey-ai.notion.site/careers-harvey-c9e804fe422e4316bdfde9fe74ed6b06")
-   京大２回生の統計力学の期末試験の問題が、論文になった話、
    -   [https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001](https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001 "https://www.t.u-tokyo.ac.jp/press/pr2023-04-05-001")
-   AzureのOpenAI、Embeddingのバージョン２が登場、トークン数が2,048→8,191と激増
    -   [https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1 "https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/models#embeddings-models-1")
-   MatCha: グラフとかの入力、からも推論やQ&Aができる。 by GoogleAI
    -   [https://arxiv.org/abs/2212.09662](https://arxiv.org/abs/2212.09662 "https://arxiv.org/abs/2212.09662")
-   gpt4allの公式チャットUIがリリース
    -   [https://github.com/nomic-ai/gpt4all-ui](https://github.com/nomic-ai/gpt4all-ui "https://github.com/nomic-ai/gpt4all-ui")
-   MS ResearchのSparks of AGI: early experiments with GPT-4の著者による説明。。
    -   [https://www.youtube.com/watch?v=qbIk7-JPB2c&t=1023s](https://www.youtube.com/watch?v=qbIk7-JPB2c&t=1023s "https://www.youtube.com/watch?v=qbik7-jpb2c&t=1023s")

## 4/17
今井むつみ先生の講演「AI時代に必要な学びと教育ー認知科学からの視点」が2023年3月29日にYouTubeで配信されます
DatabricksからDoly2.0がリリースされました。Doly2.0はオープンソースであり、商用利用も可能なインストラクション調整型LLMです。
CMUの化学者による、LLMを使った合成実験の危険性に関する論文が公開されました。
OpenAIの研究者[@ilyasu](https://twitter.com/ilyasut)による、LLMにおけるビジョンの重要性に関するツイートとGPT-4にビジョンが含まれていることを示すビデオがTwitterで公開されています。
GPT4ALLを使用したApatch2ライセンスのチャットボットOSSが公開されました。
触媒開発にGPTを活用する研究が行われており、ベイズ最適化とLLMを組み合わせて合成条件を見つける方法が紹介されています。さらに、in context learningを使用することでチューニングが不要とされ、ガウス過程回帰と同等の性能を実現しています。
    
-   AlpacaにCoT（Commonsense Transformers）とStorytellingを強化したモデルAlpacino30bが公開されました。詳細は[こちら](https://huggingface.co/digitous/Alpacino30b/tree/main)からアクセスできます。
-   今井むつみ先生の講演「AI時代に必要な学びと教育ー認知科学からの視点」(2023年3月29日)がyoutube配信される
    -   [https://www.youtube.com/playlist?list=PLMITB-DRUs7N10WLl_4zDUWfBkLd6z_Em](https://www.youtube.com/playlist?list=PLMITB-DRUs7N10WLl_4zDUWfBkLd6z_Em "https://www.youtube.com/playlist?list=plmitb-drus7n10wll_4zduwfbkld6z_em")
-   DatabircksからDoly2.0がリリース(OSSかつ商用利用可)
    -   [https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm "https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm")
-   CMUの化学者による、LLMを使った合成実験に係る危険性についての露文
    -   [https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm "https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm")
-   [@OpenAI](https://twitter.com/OpenAI "https://twitter.com/openai")の大天才研究者[@ilyasu](https://twitter.com/ilyasut "https://twitter.com/ilyasut")による、LLMにおけるvisonの重要性と、GPT-4にはvisonも入っているよビデオ
    -   [https://twitter.com/i/status/1645752089140957187](https://twitter.com/i/status/1645752089140957187 "https://twitter.com/i/status/1645752089140957187")
-   GPT4ALLを使ったApatch2ライセンスのチャットボッドOSSが公開
    -   [https://github.com/nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all "https://github.com/nomic-ai/gpt4all")
-   GPTを用いた触媒開発。ベイズ最適化とLLMを組み合わせて、合成条件を見つける。しかもin context learningを使うので、チューニングも不要！！！（素のGPTでOKということ）。ガウス過程回帰と同程度の性能。逆設計も可能
    -   [https://arxiv.org/abs/2304.05341v1](https://arxiv.org/abs/2304.05341v1 "https://arxiv.org/abs/2304.05341v1")
-   AlpacaにCoTとStorytellingを強化した、Alpacino30b公開
    -   [https://huggingface.co/digitous/Alpacino30b/tree/main](https://huggingface.co/digitous/Alpacino30b/tree/main "https://huggingface.co/digitous/alpacino30b/tree/main")

## 4/24
最近、MicrosoftはSemantic KernelのPythonバインディングを発表し、これによりSemantic KernelをPythonで使用できるようになりました。また、gist tokenを使用してプロンプトを効果的に圧縮する方法を示した論文も登場しており、26倍の効果があるとされています。
さらに、新しいプロジェクト「LLaVA」が登場し、これは言語とビジョンを組み合わせたもので、画像とビデオを操作するための新しいアシスタントです。Google ColabでDolly2.0を試す方法や、自律エージェントに関する詳細なガイドも公開されています。
CMUからは大規模言語モデル（LLM）に関する興味深い論文が登場し、自律的な科学研究能力について探究しています。また、数学のワードプロブレムを解決するためにシンボリックソルバとLLMを組み合わせる方法に関する研究も進行中です。
テキストから人間のビデオを生成する新しい技術であるText2Performerも注目されています。さらに、Transformerを超える可能性があるとされる新しい系列モデルS4とその発展形であるH3に関する情報もあります。
一方、Stability AIはオープンソースのLLMであるStableLMのスイートを導入し、LLMの安定性に関する議論が進行中です。MicrosoftはビジュアルなLLMを使用したアプリ開発環境を提案し、LLMを使用したアプリ開発に関するベストプラクティスについての記事も公開されています。
Googleは長期間の時系列予測に特化したTime-Series Dense Encoderを紹介し、プログラミング言語生成ツールであるBardを発表しました。化学の分野でも、生成モデルが進化し、新たなパラダイムとして取り上げられています。
また、大規模言語モデルの驚異と脅威についての特別講演が東京工業大学の岡崎直観教授によって行われ、SQLクエリ生成など、ChatGPTの新しい応用例も紹介されています。
最後に、LLM向けのプログラミング言語であるLMQL（Language Model Query Language）やLangChainの新機能であるContextual Compression Retrieverについても言及されています。これらの情報は、LLM技術の最新動向を把握するのに役立つでしょう。


- Microsoft のSemantic KernelのPythonバインディングが発表
	- https://github.com/microsoft/semantic-kernel/blob/main/python/README.md
- gist tokenによりプロンプトを圧縮する論文(26倍?)
	-  https://arxiv.org/abs/2304.08467
- LLaVA:　Language-and-Vision Asistant、 画像とvicunaをくっつけた
	- https://llava.hliu.cc/
- Google ColabでDolly2.0を試す方法
	- https://note.com/npaka/n/nac386bf799b6
- The Complete Beginners Guide To Autonomous Agents
	- https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents
- 例のCMUの論文：Emergent autonomous scientific research capabilities of large language models
	- https://arxiv.org/abs/2304.05332v1
- シンボリックソルバとLLMを組み合わせるSolving Math Word Problems by Combining Language Models With Symbolic Solvers
	- https://arxiv.org/abs/2304.09102
- Text2Performer: Text-Driven Human Video Generation
	- https://yumingj.github.io/projects/Text2Performer.html
- Transformerを超えるんじゃないかと言われてる新たな系列モデル（と理解してる）S4とその更なる発展であるH3
	- https://techblog.morphoinc.com/entry/2022/05/24/102648
- Stability AI	真のOSSのLLM?
	- https://ja.stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models
- Bing ChatがLaTeXの式を成型できるように進化
- Neo4jの知識をエージェントとして、LLMに組み込む話(LangChainの話）
	- https://towardsdatascience.com/implementing-a-sales-support-agent-with-langchain-63c4761193e7
- MicrosoftのLow-code LLM、ビジュアルなLLMを使ったアプリ開発環境？
	- https://arxiv.org/abs/2304.08103
- LLMを使ったアプリ開発で気を付けること（良記事）Building LLM applications for production
	- https://huyenchip.com/2023/04/11/llm-engineering.html
- GoogleのTime-Series Dense Encoder、長いスケールの時系列予測ができるのか？
	- https://ai.googleblog.com/2023/04/recent-advances-in-deep-long-horizon.html
- GoogleのBardがPythonなどのコード生成ができるようになった
	- https://blog.google/technology/ai/code-with-bard/
- 化学における生成モデルの活用サーベイ？# Generative Models as an Emerging Paradigm in the Chemical Sciences
	- https://pubs.acs.org/doi/10.1021/jacs.2c13467
- 特別講演「大規模言語モデルの驚異と脅威」、岡崎 直観（東京工業大学情報理工学院 教授）
	- https://youtu.be/PUuk4Cv-ycg
- ChatGPTでSQL queryを生成する例
	- https://www.promptingguide.ai/applications/coding
- LMQL(Language Model Query Language)とLlamaIndexを接続してみる
	- https://note.com/mahlab/n/n34ac7ebf0387
- **LMQL（Language Model Query Language）**はこのような問題を解決するために開発されている大規模言語モデル（LLM）向けのプログラミング言語です。
	- https://note.com/mahlab/n/n11b15b323c87
-  ChatGPT + LangChain で、膨大な PDF ドキュメントの内容を爆速で把握する
	- https://qiita.com/hiroki_okuhata_int/items/7102bab7d96eb2574e7d
- Generative Agents: Interactive Simulacra of Human Behavior
	- https://arxiv.org/abs/2304.03442
- 物性予測モデルの悪意ある使用を防ぐための論文。Censoring chemical data to mitigate dual use risk
	- https://arxiv.org/abs/2304.10510v1
- LangChainの新機能Contextual Compression Retriever
	- https://note.com/mahlab/n/n7d72e83904cc

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTEwMjc3MzM0NSwtOTM5NTY3NjEzLDEzMT
EwNjI5OTgsLTUyOTIxNjY0MiwyMTA5MDAzNjMwLC0xNTEyNzQy
MTA5LDExODQ1MDc4MTEsLTE2MTcxNDYwNjIsNjQyMTE2OTU4LC
03OTQ5OTA0LDIyNzgxNTk4MSwxNTg4NDc2NzQ5LC0yNzEzMDAy
NjksLTE3NjE0NjE2NTEsMjAzMzY0NTIzMCw1MTgwNzQ5LC0xOD
I1NjU2MTgxLC05NTc4NjkxMzYsMTYwMTExMDIyNCwtMTU5ODI0
MDg2NF19
-->