# ひたすらLLM関連情報を追う、
これは、個人のtwitter bookmarkを毎週おさらいしている。


## 1/29

中国からLLMの申請Orion登場、日本語韓国語が得意なのと長文モデルを持っている。LLMのアライメントも、RLHFに代わって、嗜好データセットをつかったアライメントの自動化DPOがはやってきた、嗜好データセット自体の構築支援のKTOなど、アライメント関係の進捗が目立つ。

- Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine
	- https://arxiv.org/abs/2311.16452
	- Microsoftより「GPT-4等の基盤モデルよりも、領域を絞ったモデルの方がその領域で高性能なのではないか？」を調べた論文。結果、医療の問題でGPT-4がMed-PaLM2を上回る結果に
- Orion-14B
	- https://github.com/OrionStarAI/Orion
	- 中国発LLMの新星
	- 2.5T学習、日本語100B事前学習済 語彙サイズは84,608 
	- 長文モデルは、200k-320k対応 RAG、
	- function calling専用モデルを用意
- transformer v4.37
	- https://github.com/huggingface/transformers/releases/tag/v4.37.0
	- Release v4.37 Qwen2, Phi-2, SigLIP, ViP-LLaVA, Fast2SpeechConformer, 4-bit serialization, Whisper longform generation · huggingface/transformers · GitHub
-  DPO によるLLMのPreferenceチューニング by npakaさん
	- https://note.com/npaka/n/n8be32e899c8a?sub_rt=share_b
	- 「DPO」(Direct Preference Optimization)、「IPO」(Identity Preference Optimization)、「KTO」(Kahneman-Taversky Optimization) という3つの有望なLLMアライメントアルゴリズムの評価
	- DPO
		- 「**DPO**」はLLMを人間またはAIの好みに合わせるための有望な代替手段として浮上しています。「強化学習」に基づく従来のアライメントアルゴリズムとは異なり、「DPO」はアライメントの定式化を、嗜好のデータセット上で直接最適化できる単純な損失関数として再構成します。
		- これにより、「DPO」は使いやすくなり、「Zephyr」や「NeuralChat」などのモデルの学習で成功しています。
	- IPO
		- 「DPO」の欠点の1つは、優先データセットにすぐに過剰適合する傾向があることです。これを回避するために、「Google DeepMind」は「IPO」を導入しました。これにより、「DPO」損失に正則化項が追加され、早期停止などのトリックを必要とせずにモデルを収束するように学習できるようになります。
	- KTO
		- ContextualAIは最近、「KTO」と呼ばれる興味深い代替案を提案しました。これは、「good」または「bad」とラベル付けされた個々の例に関して損失関数を完全に定義するものです。これらのラベルは取得するのがはるかに簡単であり、「KTO」は本番環境で実行されているチャットモデルを継続的に更新する有望な方法になります。
- LLMのRLHF→DPO→KTOってトレンドの流れを抑えよう by うみゆき
	- https://x.com/umiyuki_ai/status/1749670491227672797?s=20
	- オープンLLMはそんな金かけてRLHFやるなんて無理だった。そこで発明されたのがDPOだ。
	- DPOは人力で評価する必要が無いからコストがかからない。代わりに”嗜好データセット”を用意する必要がある。嗜好データセットってのは、あるプロンプトが与えられた時の二つの回答があって、こっちの回答の方がイケてて、こっちの方が良くない。みたいなデータが大量に用意されてるモノ。RLHFとDPOは数学的に等価である事がキッチリ証明されてる。
	- 嗜好データセットとか言われても、そんなもん用意するのだってまだまだ手間がかかって大変だ。そういうデータの問題をどうにかする新しいテクがKTO。KTOでは必要なデータはプロンプトと回答があって、その回答に「いいね」か「よくないね」の評価だけ付いてればいい。
	- KTOによってLLMのアラインメント作業は相当簡単にできるようになってきたわけだ。ただ、そうやって作ったモデルのベンチ性能を比較すると、やっぱKTOよりDPOの方がやや高性能みたいだ
- GoogleDeepmindがSpatialVLMを発表
	- までの視覚言語モデルは空間感覚に欠けていた。例えば「写真に写ってるバッターと審判の距離は何メートル？」とか訊いても答えられんかった。それを改善したのがSpatialVLM。
- makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
	- https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch
	- Colabも公開してくれているので無料版ColabのT4でも動かせます。max_itersを500くらいに修正すれば所要時間も10分程度
	- ただし、最後から3番目のセルは以下のように要修正 
		- metrics = {"train_loss": losses['train'], "val_loss": losses['val']} 　
		- ↓ metrics = {"train_loss": float(losses['train']), "val_loss": float(losses['val'])}
- 深層学習の原理を明らかにする理論の試み　by 今泉さん
	- https://drive.google.com/file/d/1bNN6VjsgdpJAqxvZ4EKAPpMGq9wfjHqf/view
	- 「なぜ深層学習でうまくいくのか」という素朴な疑問に対し、理論的にわかっていることを平易に解説したスライド。非常にわかりやすい。
- Orion-14B-Chat-Int4 を試す。
	- https://huggingface.co/OrionStarAI/Orion-14B-Chat-Int4
	- https://note.com/npaka/n/nd5025f5f7ac1?sub_rt=share_h
	- 推論高速で回答も自然で良い感じ。 ロングチャット用、RAG用、Function Calling用などもある
-  RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture
	- https://arxiv.org/abs/2401.08406
	- Microsoftより農業データを例に、LLMでRAGとFine-Tuningを比較分析した論文。
	- 比較結果の要約は表22-23の通り(図引用)。双方の使い分けポイントは表23の最下行にあり。
- AIが自分自身に報酬を与えて進化する「自己報酬型言語モデル」　米Metaなどが開発、実験でGPT-4を上回る【研究紹介】
	- https://levtech.jp/media/article/column/detail_374/
	- この訓練方法により、モデルの指示に従う能力と報酬モデリング能力が反復ごとに向上することが示された。
	- モデルは、自分の答えを生成する能力を向上させると同時に、自分自身の報酬モデルとしても機能。通常は固定されている報酬モデルが、繰り返しのプロセスを通じて改善される。
	- **これは、人間などの外部からのフィードバックを不要にし、学習モデルが自分自身をよりよく改善できるようになることを意味し、自己改善の好循環を生み出す。**
- Summarize gigantic JSON datasets in seconds with JSONalyze, our latest query engine: 
	- https://docs.llamaindex.ai/en/latest/examples/query_engine/JSONalyze_query_engine.html
	- JSONが巨大になると、コンテキストが膨大になるので、圧縮？するらしい
-  Self-Rewarding Language Model (wip)
	- https://github.com/lucidrains/self-rewarding-lm-pytorch
	- MetaのDPOの、独立実装が登場らしい
- ベイズモデリングによるチームメイト及び対戦相手の能力を考慮したポゼッションデータに基づくバスケットボールプレイヤーの能力評価指標
	- https://www.jstage.jst.go.jp/article/jscswabun/36/2/36_99/_article/-char/ja/
	- 滋賀大時代の学生や同僚たちと書いたバスケットボール選手のパフォーマンス評価に関する論文が掲載されたとらしい
-  WARM: On the Benefits of Weight Averaged Reward Models
	- https://huggingface.co/papers/2401.12187
	- Google Deepmind presents WARM
- GoogleColobで小規模言語モデル(0.15B)の事前学習モデルを作ってみる
	- https://ayousanz.hatenadiary.jp/entry/2024/01/23/225623
	- 事前学習モデル(0.15B)を作ってみました ちゃんと使えるレベルにするためには、約200倍くらいかけないといけないみたいです
- ChatGPTのコンテキスト長が32kになってるから青空文庫の小説とかを2万文字くらいのテキストファイルに分割して自分の代わりに読んでもらって内容教えてもらう事も結構できる。
	- まあClaudeならコンテキスト長100kだからもっと大量の文章をまとめて読んでもらえる
	- https://x.com/umiyuki_ai/status/1749775772850749556?s=20
- Knowledge Fusion of Large Language Models", ICLR 2024より
	- https://arxiv.org/abs/2401.10491
	- 既存のLLMを融合させて強力なモデルを作る手法「知識融合」が開発
	- 混合モデルを提唱する"Blending Is All You Need"とはアプローチ・評価方法ともに異なる研究です
	- ■実験と結果 
		- 1. 「Llama-2」「OpenLLaMA」「MPT」を融合して「FUSELLM」を作成した 
		- 2. 下記タスクを中心に顕著に性能が向上した - 論理 - 常識 - コード生成
- LLMの研究トレンドは以下の３つ
	- https://x.com/cwolferesearch/status/1749867258107543615?s=20
	- (1) Synthetic training data:
		- [1]では、最先端の埋め込みモデルを学習するために、合成学習データを使用できることを示している。
		- [2]では、数学とコーディングの問題に対して合成データを簡単に生成し、検証することができ、LLMの性能を向上させるために使用できることが示されている。
	- (2) LLM safety:
		- [3]の研究では、LLMに訓練されたバックドア攻撃は、広範な安全訓練後も持続し、人間のユーザーを欺くスリーパーエージェントを形成することが示されています
		- [4]で、適切なプロンプト技術さえあれば、多くのアライメントを経たLLMであっても、ほぼ全てのLLMからトレーニングデータを抽出できることを学びました。
	- (3) Knowledge injection
		- [6]の著者は検索拡張世代（RAG）を提案し、このアプローチが知識集約型タスクのパフォーマンスに影響を与えることを示している。
		- LIMA [7]は、LLMのほぼ全ての知識が事前学習中に学習されることを示している。
		- Phi-1[8]は、知識豊富なLLMが、より小さな、キュレーションされたデータセット（つまり教科書）に対して学習できることを示している。
-  Reading Analog Gauges
	- https://huggingface.co/spaces/Synanthropic/reading-analog-gauge
	- Simply Reading Analog Gauges – GPT4, CogVLM Can't
	- This model reads analog dial gauge by detecting, applying perspective correction, and gauge reading. The model was build only with synthetic data (e.g. examples
- OpenAI GPT-4V／ChatGPT／GPTs 人工知能プログラミング実践入門
	- 布留川さんの、新刊、
	- https://wgn-obs.shop-pro.jp/?pid=179128392
	- 昨年11月の大規模アップデート対応で、マルチモーダルやGPTストアなどの新機能も解説してます。技術アップデートが早すぎることもあり、PDFのみになります。
- ChatQA: Building GPT-4 Level Conversational QA Models
	- https://arxiv.org/abs/2401.10225
	- GPT-4レベルの質問応答タスク性能をオープンソースモデルのLlama 2で実現する方法が、NVIDIAより発表されました。
	- 長文ドキュメントに基づいてユーザーの問いに答える能力でGPT-3.5より遥かに勝る結果が示されています。
	- ■方法論 以下のような２段階の指示チューニングを行う 
		- 1. 教師ありファインチューニング （supervised fine-tuning） 
		- 2. 文脈強化インストラクションチューニング （context-enhanced instruction tuning）
	- ■実験と結果 
		- 1. Llama-2を調整して「ChatQA」モデルを作成した 
		- 2. 長文ドキュメントに基づくQAタスクで評価した 
		- 3. GPT-3.5の性能を遥かに上回った 4. GPT-4とは同等と言えるレベルだった
-  Prompt Engineering with Llama 2
	- https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=video
	- Introducing 'Prompt Engineering with Llama 2' — an interactive guide covering prompt engineering & best practices for developers, researchers & enthusiasts working with large language models.
- Ollama Python and JavaScript libraries
	- https://ollama.ai/blog/python-javascript-libraries
	- Both libraries make it possible to integrate new and existing apps with Ollama in a few lines of code, and share the features and feel of the Ollama REST API.
- CALM2をDirect Preference Optimization (DPO)でチューニングしたモデル calm2-7b-chat-dpo をCC-BY 4.0で公開しました。
	- https://huggingface.co/cyberagent/calm2-7b-chat-dpo-experimental
	- calm2-7b-chat-dpoをELYZA-tasks-100とJapanese MT-Benchで評価を行ったところ、CALM2よりも更に高いスコアが得られるという結果になりました
	- また、あわせてDPOに用いたデータセットをCC-BY 4.0で公開しました
	- https://huggingface.co/datasets/cyberagent/chatbot-arena-ja-calm2-7b-chat-experimental
- 今更ながら､GPT3.5をファインチューニングしてみました｡ 
	- https://x.com/kanhatakeyama/status/1750331895853039745?s=20
	- guiで操作できるし､gpuマシンを用意しなくて良いし､非常にお手軽な印象でした｡ 3並列まで学習回せました｡
	- 2,3時間の使用で､$30ほどかかりました｡
-  LLM のデータセットまとめ by npakaさん
	- https://note.com/npaka/n/n686d987adfb1?sub_rt=share_b
- Hugging Face and Google partner for open AI collaboration
	- https://huggingface.co/blog/gcp-partnership
	- We will collaborate with Google to foster open AI innovation across open science, open-source, cloud, and hardware
	- A collaboration for Google Cloud customers
	- A collaboration for Hugging Face Hub users
-  OpenAIの 新モデルの追加 と APIの更新 by npakaさん
	- https://note.com/npaka/n/nd8c5e9c65335?sub_rt=share_h
	- ・新しいEmbeddingモデルの追加
	- ・GPT-4 Turbo Previewの更新
	- ・GPT-3.5 Turboの更新
	- ・モデレーションモデルの更新
	- ・APIキーの管理方法の改善
- 実はSwallowはbaseモデルとしての性能はいいですが、instruct モデルの性能はpublic instruction datasetを使用したこともあり、baseモデルの高い性能の割にはあまり高くありません
	- https://x.com/okoge_kaz/status/1750805452676608177?s=20
- CoTの推論ステップ数がLLMの推論能力に及ぼす影響を詳細に検証した結果
	- https://ai-data-base.com/archives/62364
	- GPT-4などのLLMに思考の連鎖（CoT）プロンプトなどで「考える時間」を与えると基本的に性能が向上します。 
	- そこで今回、適切な推論のステップ数が検証されました。 記事ではプロンプト手法とともに結果を紹介しています。
-  MambaByte: Token-free Selective State Space Model
	- https://arxiv.org/abs/2401.13660
	- MambaByteは、Mambaが長い系列も扱えるため、トークン化せずバイト単位で言語モデルを学習。同等の計算量、モデルサイズでトークン化不要のMegaByteや通常のトークン化Transformerと比べ性能で上回り、1/3の投入計算量でTransformerの損失に到達。小規模実験の結果だが有望
-  Dense X Retrieval: What Retrieval Granularity Should We Use?
	- https://arxiv.org/abs/2312.06648
	- The "Dense X Retriever" paper shows that it significantly outperforms the traditional chunk-based retriever
-  Deep Convolutional Networks on Graph-Structured Data
	- https://arxiv.org/abs/1506.05163
	- My most-cited, never-accepted, ArXiv-only paper has over 1880 citations. "Deep Convolutional Networks on Graph-Structured Data" Mikael Henaff, Joan Bruna, Yann LeCun
-  FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- https://huggingface.co/papers/2401.14112
	- Microsoft presents FP6-LLM 
	- Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design
	- Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality
- 知識融合、図を見るとアンサンブルやMixture of Expertsとは違って本当に知識そのものを抽出している感じか。どちらかというと蒸留に近い感じもあり画期的な手法のように思える。
	- https://x.com/koheiichi/status/1751060499310301550?s=20
- Python library that adds Generative AI capabilities to Pandas
	- https://github.com/gventuri/pandas-ai
	- Introducing PandasAI, now you can analyze complex data frames and plot visualizations just by using natural language
- XWin 70B で LLM 出力日本語文章の自動評価を行う試み
	- https://zenn.dev/syoyo/articles/4f4f8645af1cee
	- 日本語 LLM の自動評価(ELYZAちゃん task 100 とか)をローカル LLM で行いたい.現時点で最高性能の一つXWin 70B での評価試しました!
	- そこそこいい感じになったよ✊
	- でも prompt 上手く作る必要あることがわかったよ
- 同じデータに対してもモデル（この場合はカーネル）が異なれば予測が変わるという話。こういうことを色々実現したい場合はやっぱりガウス過程がやりやすいです。 by 須山先生
	- https://x.com/sammy_suyama/status/1751104980189413880?s=20
-  Google Colab で LangGraph を試す by npakaさん
	- https://note.com/npaka/n/n053a3cb78311?sub_rt=share_h
	- 「**LangGraph**」は、LLMでステートフルな「**マルチアクターアプリケーション**」を構築するためのライブラリです。「**LCEL**」(LangChain Expression Language) を拡張して、複数チェーン (またはアクター) を複数ステップにわたって循環的に協調動作させることができます
	- 「LangGraph」によって、LLMアプリケーションに**サイクル**を簡単に導入できるようになりました。

## 1/22

今週はDavos会議があって、われらのアルトマン氏も登場、GPT-5について言及。Metaからはザッカーバーグ氏がビデオメッセージでいきなりLlama3のOSSとしての開発宣言。NVIDIAがCESで発表したGeForce RTX 4070 SUPERが発売、ローカルLLM界隈の価格破壊が、、、。MoEも今週もにぎやか、圧縮して小メモリ化するようなMC-SMoEのアプローチとか、負荷分散を調整するDeepSeekMoEとか、youri-2x7bのggufがでたりとかとにかく賑やか。小規模LLM向けの人工的に生成された学習用モデルtiny-textbookシリーズも充実してきて、小規模LLMの開発も加速するかな。手が届くところではnanoGPTの源氏物語の適用例は楽しそう。小規模LLMを集めて優れたAIを作るという意味では、sakana.aiが華々しく45億円もの投資を調達、googleなどのスーパー研究者が終結して楽しそう。sakana.aiは小さな魚が集まって一匹の大魚のように泳ぐ物語｢スイミー｣の仕組みなわけだけど、小さな専門エージェントがあつまって問題を解決するってことなら、古い人にはミンスキー御大のSociety o Mindsが思い出される。MicrosoftはColiplot Proをリリース、月20ドルで、個人が、GPT-4 TurboにもアクセスできるしOffice 365 Copilotも使えるしお得かも、一方がっかりしたというファーストユーザーの意見もちらほら。でも小規模LLMの代表格phi-2はマイクロソフトからでているから、OpenAI/Copilot一辺倒では実はない。一方メタは２万人をレイオフして、代わりに35万台のH100インフラを整えLlama3の開発を推進。どの会社もLLMという不確実な要素（発展性、他社との競争）に備えならが綱渡り的な会社の運営をしている（株主からの期待にこたえ続けつつ財務的に破綻はできない）。共通テストにさっそく吊るしのLLMを適用評価した例では、GPT-4が6割強程度正解でなんとか人間を上回るも、特に数学がダメという結果が。一方、数学オリンピックのメダリスト並みの性能を示すDeepMindのAlphaGeometry、LLMとルールベースのハイブリッドが高性能の秘訣らしい、text_to_SQLも、また違ったハイブリッドとして高性能化のヒントになる。ベクトル化のサーベイ論文とか、ELYZAの日本語追加学習でもともとの英語の能力が落ちないかの検証とか、着実な動きは地道にすすんでいるのを忘れずにいたい。

- HachiMLさんが公開されているyouri-2x7b_v0.2のgguf ^aaa
	- https://huggingface.co/mmnga/HachiML-youri-2x7b_v0.2-gguf
	- This model is a Mixture of Experts (MoE) merger of the following two models:
	- [rinna/youri-7b-instruction](https://huggingface.co/rinna/youri-7b-instruction)
	- [rinna/youri-7b-chat](https://huggingface.co/rinna/youri-7b-chat)
- mambaを分散学習するためのライブラリ
	- https://github.com/kotoba-tech/kotomamba
	- Transformerを上回るモデルとして注目されているMamba, State Spaceモデルの
	- Kotoba Techでは130m, 1.4B, 2.8B のモデルの学習をすでに行っています
- baobab-trees/wikipedia-human-retrieval-ja
	- https://huggingface.co/datasets/baobab-trees/wikipedia-human-retrieval-ja
	- 短い質問文に対してWikipediaに書いてある情報のみで回答させる、というのを1000問前後実施し、人手retrieval付きQAデータセットを作りました。途中の過程や引用なども記録しているので、人間による検索のシミュレーションをデータから検討したりできると思いま
- Copilot for Office 365
	- https://x.com/usutaku_com/status/1747119405702795383?s=20
-  how to build advanced QA over Tabular Data
	- llamaindexより、
	- https://x.com/llama_index/status/1747289513934864493?s=20
	- Query Pipeline over Pandas DataFrames
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_pandas.html
	- This is a simple example that builds a query pipeline that can perform structured operations over a Pandas DataFrame to satisfy a user query, using LLMs to infer the set of operations.
	-  Query Pipeline for Advanced Text-to-SQL
	- https://docs.llamaindex.ai/en/stable/examples/pipeline/query_pipeline_sql.html
- nanoGPT楽しい。源氏物語全文で学習させたら何か語りだした🤗 いずれの紛れありけるかな
	- https://github.com/karpathy/nanoGPT
	- The simplest, fastest repository for training/finetuning medium-sized GPTs
- 企業はなぜ東京に集中するのか──経済地理学の視点から（日本労働研究雑誌）
	- https://www.jil.go.jp/institute/zassi/backnumber/2020/05/pdf/029-039.pdf
- 東京発・AIドリームチーム「http://Sakana.ai」が45億円調達　元Googleトップ研究者らが設立　AI業界の著名人や日本の大手IT企業も出資
	- https://sakana.ai/seed-round/
	- @tkasasagi さんも参加かー
	- https://x.com/tkasasagi/status/1747267875021406329?s=20
	- 「サカナAI」日米で45億円調達　スイミーの発想で巨大ITに挑む
		- 同社は対話型AIの基盤技術である大規模言語モデル（LLM）の開発で、他社が開発した小さなAIをいくつもつないで、巨大AIに匹敵する能力をもつ仮想のAIモデルを構想。この新技術はエージェントモデルと呼ばれ、開発コストを劇的に下げる可能性があり、巨額な資金が求められるAI開発競争に一石を投じる狙いだ。
- xverse/XVERSE-13B-256K
	- https://huggingface.co/xverse/XVERSE-13B-256K
	- ローカルLLMの長文対応がついに256K（約25万字）
	- XVERSEはABF+継続的pre-trainingとNTK+SFT技術を用いてプロセスを最適化。これにより、モデルのシーケンス長を大幅に拡張することが可能となった
- Open AIは「Collective Alignment team」を結成
	- https://openai.com/blog/democratic-inputs-to-ai-grant-program-update
	- AIに多種多様な世界中の公的な意見を反映させるシステムの開発を担う。 以前AIへの民主的インプットのアイデアを募集していたが、1000の応募者があり以下画像のように10のチームのアイディアが選抜された
-  再考: お買い得物件を機械学習で見つける方法
	- https://speakerdeck.com/ktgrstsh/rethink-method-to-find-cheap-rental-houses-by-machine-learning
	- 賃貸データのスクレイピングであれば，こちらのページが参考になりました
- WikiChatの話
	- https://arxiv.org/abs/2305.14292
	- WikiChat はファクトチェック及びコンテキストに，RAG 等でよく利用される Wiki を利用するライブラリで，高い factfulness を備えるとしている
- Animagine XL 3.0 、Hugging Faceのトレンドで1位を達成
	- https://huggingface.co/spaces/DamarJati/Animagine-XL-3.0
	- 1月10日、Cagliostro Research Labが、**拡散モデルベースのText-to-Imageの画像生成モデル「Animagine XL 3.0」**を公開しました。
	- https://weel.co.jp/media/animagine-xl-3-0
- Blending, Merging, and Stacking multiple smaller LLMs make them as performant as Larger LLMs
	- https://x.com/bindureddy/status/1746739742350450811?s=20
	- Blending、Merging、Stackingなどの技術を今後30-70bモデルに適用していき、今後2-3ヶ月以内にGPT4に近い戻るが得られるでしょう
- (RAG)の評価指標マップ
	- https://x.com/helloiamleonie/status/1747252654047142351?s=20
- DeepMindのCEOであるLila Ibrahimがダボス会議2024で語ったこと
	- https://www.axios.com/2024/01/16/davos-ai-lila-ibrahim-google-deepmind-technologies
	- ila Ibrahimは、AIが物質科学や生物学に革命をもたらし、新しい材料やタンパク質の発見に貢献していると述べた。
	- 2018年、「AlphaFoldは（もともとは）うまくいかないはずのアイデアだった」とイブラヒムは語った。彼女はこう付け加えた。「今では（既知の）タンパク質を2億個みつけるまでになりましたけどね」。
	- 昨年は、AI開発者たちが互いに協力し合い、政府の協力を得て、技術のリスクを管理することが急速に進んだと彼女は言う。
	- イブラヒム氏は、若いAIユーザーに技術の倫理的枠組みを教えるのは、インターネットやソーシャルメディアを通じてデジタル化した高齢者世代に教えるよりも簡単だろうと考えている。
- マイクロソフトCopilot Proを発表
	- https://x.com/satyanadella/status/1747000699664429075?s=20
	- Office３６５向けのcopiloの機能が、個人でも使えるようになる。3,200円/月
	- Office365/w copilotの利用以外に、GPT-4 および GPT-4 Turboへの優先的な割り当て
	- Copilot GPT Builder（近日公開予定）で、特定のトピックに合わせてカスタマイズされた独自のCopilot GPTを作成可能
	- 期待する声もたくさん上がるも、がっかりする声も多数
- 【2024年最新】共通テストを色んな生成AIに解かせてみた（ChatGPT vs Bard vs Claude2
	- https://note.com/lifeprompt/n/n87f4d5510100?sub_rt=share_h
	- ①GPT-4がすべての科目で他二つのツールを圧倒  
	- ②数学科目に関してはどのAIも全然点取れていない  
	- ③高得点を狙えている科目でも、満点は取れていない
- nampdn-ai/tiny-strange-textbooks
	- https://huggingface.co/datasets/nampdn-ai/tiny-strange-textbooks
	- 人工的に生成された小型のLLM(phiなんか）用の学習データセット
	-  Textbooks Are All You Need II: phi-1.5 technical report
	- https://arxiv.org/abs/2306.11644
- Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy
	- https://arxiv.org/abs/2310.01334
	- MoEってメモリ食うので、これを圧縮やスパース性に着目して軽量化する、80%の削減！
	- We merge experts THEN compress/decompose merged experts→low-rank. Up to 80% mem reduction! 🎉
- mix_self_consistency pack by llamaindex
	- https://llamahub.ai/l/llama_packs-tables-mix_self_consistency?from=llama_packs
	- Here’s a simple but useful idea to use RAG to fetch few-shot examples for less flaky text-to-SQL (or…less flaky structured RAG itself). Calling it dynamic metadata…
	- “Rethinking Tabular Data Understanding”の実装
	- 1.  Index and embed each row
	- 2. In the text-to-SQL prompt (or auto-retrieval prompt), add *few shot examples of rows*: given the first k rows in the prompt, retrieve the top-k rows matching the user query.
	- 3. Execute text-to-SQL prompt (or auto-retrieval prompt) to infer the right query (SQL or metadata filters).
	- 4. Execute query to get back result.
- 生成AIの業界団体「Generative AI Japan」発足　ベネッセが発起　マイクロソフト、AWS、Google、オラクルなどの幹部が理事に
	- https://x.com/itmedia_news/status/1747490194486632764?s=20
- Can AI Be as Creative as Humans?"
	- https://arxiv.org/abs/2401.01623
	- 「AIは人間と同じくらいクリエイティブになれるのか？」というテーマで、DeepMind・Microsoft・スタンフォード大学などが共同で研究しています。
	- 『AIが創り出した作品が人間のそれと見分けがつかなくなったら、AIはクリエイティブだと言える』
	- AIの創造性を具体的な数値で評価したい →フレームワークを作成
- ELYZAが公開した日本語LLM「ELYZA-japanese-Llama-2-7b」についての解説 : (3) 英語での性能評価編
	- https://zenn.dev/elyza/articles/ab3749de0ba58b
	- **追加学習の過程で、元のモデルが持っていた能力がどの程度失われてしまうのか**という点
	- 結果：
		- 日本語を含むデータの追加事前学習により日本語化したモデルにおいて、英語の性能の劣化は生じてしまう。
		- 日本語のSFTにより、日本語化モデルの英語の指示追従能力も一定回復させることができる。
		- 追加事前学習に英語のデータセットを追加した場合、英語タスクでの性能劣化を緩和可能である。
		- 日本語の語彙拡張は日本語の事前学習時の性能劣化を顕著にするものの、SFTによる性能の上昇をより享受できる可能性がある。
- 【新刊】「強化学習から信頼できる意思決定へ」、サイエンス社
	- 梶野　洸(日本IBM)・宮口航平(日本IBM)・恐神貴行(日本IBM)・岩城　諒(日本IBM)・和地瞭良(LINEヤフー)　共著　
	- https://www.saiensu.co.jp/search/?isbn=978-4-7819-1592-0&y=2024
	- 強化学習はその定式化を用いることで幅広い実問題を表現できる一方，信頼性の不足が一因となり，実世界では応用がなされているとは言いがたい．本書は，標準的な定式化と実問題との橋渡しとなるような定式化を体系的にまとめることで，実世界での応用を促進することを目指した
	- 第3章リスク考慮型強化学習と金融への応用（3.5節を除く）
- 「GeForce RTX 4070 SUPER」が各社から多数登場、価格は95,480円から
	- https://akiba-pc.watch.impress.co.jp/docs/news/news/1561586.html
- Google DeepMindが数学オリンピックの幾何学問題において平均的な人間の金メダリストに肉薄する「AlphaGeometry」発表
	- https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/?utm_source=twitter&utm_medium=social
	- An Olympiad-level AI system for geometry
	- AI system surpasses the state-of-the-art approach for geometry problems, advancing AI reasoning in mathematics
	- AlphaGeometry は、ニューラル言語モデルと記号演繹エンジンで構成される神経記号システムであり、これらが連携して複雑な幾何学定理の証明を見つける
	- 「LLMと演繹エンジンとの組み合わせ」
- Accelerating the prediction of stable materials with machine learning
	- https://www.nature.com/articles/s43588-023-00536-w
	- 機械学習による材料の安定性予測に関するレビュー論文
	- DeepMindさんの論文でも使われた材料の熱力学的安定性予測に関し、convex hullの概念のような基礎から、有限温度の予測のような応用までまとまっています。 機械学習で材料探索してみたい初学者の方におすすめ。
- WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation
	- https://arxiv.org/abs/2312.14187
	- Introduce WaveCoder-Ultra-6.7B with the closest capabilities to GPT-4 so far.
	- WaveCoder-Ultra-6.7B is the newest SOTA open-source Code LLM on multiple tasks.
- LangGraphの説明ブログが公開
	- https://blog.langchain.dev/langgraph/
	- We previewed LangGraph last week, but excited to dive a lot more into why we're building this, the details of what it looks like, and some more examples
- Foundations of Vector Retrieval
	- https://arxiv.org/abs/2401.09350
	- This 185-page monograph provides a summary of major algorithmic milestones in the vector retrieval literature, with the goal of serving as a self-contained reference for new and established researchers.
	- LLM時代のコンテンツのベクトル化と検索についてのサーベイであり包括論文
- A Cheat Sheet and Some Recipes For Building Advanced RAG
	- https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b
- 米Metaが1万人の追加レイオフ、5000人の採用も中止
	- https://xtech.nikkei.com/atcl/nxt/news/18/14833/
	- メタは2万人レイオフして35万台のH100を買いました
-  OpenAI Node API Library 入門 by npakaさん
	- https://note.com/npaka/n/n2f8c08965316?sub_rt=share_h
	- 「OpenAI Node API Library」は、TypeScript / JavaScriptから「OpenAI API」にアクセスする機能を提供します。
-  GraphGPT: Graph Learning with Generative Pre-trained Transformers
	- https://arxiv.org/abs/2401.00529
	- グラフ×Transformerによる物性予測の論文
	- グラフを文字列に変換しTransformerで学習するGraphGPTを提案、従来のGNNでは難しい400Mパラメータで事前学習モデル構築、これを微調整することで分子物性を高精度に予測できたそうです。
- LLMマルチエージェントを俯瞰する
	- https://speakerdeck.com/masatoto/llmmarutiezientowofu-kan-suru
	- 文献の内容をもっと深掘りしたら普通に出版できるレベルだわこれ
-  Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering
	- https://arxiv.org/abs/2401.08500
	- The paper proposes AlphaCodium, a code-oriented iterative flow that improves LLMs on code generation.
	- LLMでコーディング作業を行う際のプロンプトエンジニアリング手法として、「フローエンジニアリング」という新しい概念が提唱されています。 
	- この概念に基づいてコーディングを行うことで、LLMのプログラミング能力が一貫して向上することが定量的に報告されました。
	- ■研究者らのアイデア - 複数の段階に分けてコードを生成・改善する - テストベースの考え方を用いる
	- ■実験結果 
		- コードタスクでのLLMの性能を一貫してかつ大幅に向上させた 
		- オープンソース（DeepSeek）とクローズドソース（GPT-3.5/4）両方で効果があった
-  DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models
	- https://arxiv.org/abs/2401.06066
	- DeepSeekMoEはLLMのMoEで
		- 1) Expertをさらに細かくし64に増やすと共に選択されるExpert数も8に増やす 
		- 2) 共有知識を使えるよう常に選択されるExpertを用意。デバイス毎の負荷分散を重視し実行効率をあげる。
		-  同じ計算量のDenseや従来MoEに対し性能を改善
- llama3の開発とオープンソース化に関してザッカーバーグのビデオメッセージが出回る
	- https://twitter.com/i/status/1748058491343061458
	- 年内に35万台のH100を活用可能インフラを構築
	- H100相当品も含めると60万台のH100に匹敵 
	- 以下はビデオメッセージからの書き起こし by AI
		- メタは一般的な知能を構築し、オープンソース化し、みんなに利用できるようにするという長期的な目標のために、2つのAI研究プロジェクトを統合すると発表した。
		- 次世代のサービスには、推論、計画、コーディング、記憶などのAIの各分野での進歩が必要であると述べた。
		- この技術は非常に重要であり、機会も大きいので、責任を持ってオープンソース化し、できるだけ広く利用できるようにするべきだと主張した。
		- 今年末までに、約35万台のNvidia H100 GPUを搭載した巨大なコンピューティングインフラストラクチャを構築すると発表した。
		- 現在、Llama 3をトレーニングしており、今後も責任を持って安全にトレーニングを続ける
		- AIとメタバースは密接に関連しており、将来的には多くの人がAIと会話するためにメガネを使うだろうと予測した。
- Connect to Sheets and use the Gemini API in Colab to tell Gemini about your most promising prospects and prepare personalized sales pitches to sell what you are good at - in this case, delicious lemonade.
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Sell_lemonade_with_Gemini_and_Sheets.ipynb
	- GeminiとGoogle Sheetsを使ったセールスピッチ生成の例
- 5%ぐらい？をChatGPT（生成AI）で書いたという芥川賞を受賞
	- https://x.com/yukatan/status/1747957984104480891?s=20
	- AIに執筆させてみたというレベルの話ではなくて、スマホでググるみたいにAIに質問するのが当たり前になると世界がどう変わり得るかを文学的に表現しています。時代を刻む作品だわ
- アルトマンがダボス会議で言ったこと
	- 「AIの進歩は、科学的発見の速度を大幅に加速するのに役立つ。それが2024年に起こるとは予想していないが、起こったならばとても大きな一大事になる」 
	- 「現時点での最優先事項は新しいモデルをローンチすることだ。それはGPT-5と呼ばれる可能性が高い
	- https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview
- 圧縮MoE
	- https://github.com/unites-lab/mc-smoe
	- 今までのMoEはモデルを２つくっ付けたら２倍VRAM消費するのがコスパ微妙だったけど、MC-SMoEではベースモデルと各エキスパートとの差分をLoRA的な形で保持する事で省メモリになったって話かな
- Introducing Mixtral, Phi2, Falcon, and Qwen support in DeepSpeed-FastGen! 
	- https://github.com/microsoft/DeepSpeed/tree/master/blogs/deepspeed-fastgen/2024-01-19
	- Up to 2.5x faster LLM inference
	- Optimized SplitFuse and token sampling
	- Exciting new features like RESTful API and more!
- 心理学ワールド104号の特集「空間認知の科学 最前線」
	- https://psych.or.jp/publication/world104/
- Fair Machine Guidance to Enhance Fair Decision Making in Biased People
	- https://x.com/yukino/status/1748481134558896432?s=20
	- 私たちの論文「Fair Machine Guidance to Enhance Fair Decision Making in Biased People」が #CHI2024 に条件付き採択されました！ 人間の判断が不公平に偏る問題に対処するため、公平性配慮型機械学習による公平モデルを用いて、人々がより公平な判断を下せるようガイドしました！
- Neural Speed + ONNX Runtime makes LLM inference more efficient on CPUs!
	- https://github.com/intel/neural-speed
- Google DeepMind researchers are in talks to leave and form a new startup named 'Holistic'. They want to build their own AI model.
	- https://x.com/AndrewCurran_/status/1748419941672616324?s=20
- 【新刊】「多様体上の最適化理論」
	- https://www.ohmsha.co.jp/book/9784274231186/
	- 本書は、多様体上の最適化理論について、基礎となる数理から応用例までを解説するものです。  
	- 多様体上の最適化を学ぶ、あるいは研究する読者は  
		- ユークリッド空間上の連続最適化をひととおり学んだ後、その抽象化の仕方の一つとして多様体上への拡張について学ぶ  
		- 多様体をはじめとした幾何学に慣れ親しんだ読者が、そうした理論の最適化への応用について学ぶ  
		- 最適化と幾何学の知識をもつ読者が、両者の融合について学ぶ

## 1/15

Mistral AIによるMixtral -8x7bモデルの成功により、最近のはやりはMoE（Mixture of Experts）モデル。Phi-2のMoEであるPhixtual-2x2bなんかも出ました。mergekitというのを使えば、colabでも、MoEが簡単に作れるようです。  比較的小さな言語モデルでも、混ぜ合わせることで大きいモデルに匹敵する可能性があるという報告もあり、アンサンブルってのはLLMでも有効なんですねー。小規模言語モデルではTinyLlamaってのもありました、Macでも快適に動く模様。言語モデルは小さくても、膨大なデータで学習すれば性能が上がる？stanfordのwikichat、LLaMA7Bベースでも、ここまで性能が上がる（メモリを食うらしいが）という報告も。われらのアルトマン氏が結婚！LangChainもついに、v0.1が出た！。タイムラインに、ひたすら、Moore-AnimateAnyoneの絵が出てくるのはなぜ？？Duolingoのリストラ、そういう気もするが、googleのAMIEのように、そもそも人材不足の分野での専門家AIの登場という側面もある。GoogleのDynamicPlanって、あれどこかで見たような気もするが、データサイエンティストはリストラされる側になるのか、それとも専門家AIとしてだれでも使えるようになるのか？

- Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy
	- https://arxiv.org/abs/2312.12728
	- LLMの出力品質を落とさずに推論速度をスピードアップさせるための手法
	- ■『Lookahead』のアイデア 
		- 1. 生成の枝分かれ（ブランチ）を作る - ブランチを作成は並行処理する 
		- 2. 最適なブランチを選び出す - 不要なブランチを早期排除する →推論スピードを向上させつつ高品質を維持する 
	- ■実験と結果 
		- 1. DollyデータセットとLlama-13Bでテスト 
		- 2. オンライン環境に組み込んだ 
		- 3. 高い生成精度を維持しつつ速度を改善した
- PmxEditor及び準標準ボーン追加プラグインの導入
	- http://rockstababy.starfree.jp/mmdsupporter/bemmder/section3.php
	- PmxEditorを使えばMMDモデルを編集できるのか！フリーレンのモデルの編集はこれを使っていたのか
-  Uncovering mesa-optimization algorithms in Transformers
	- https://arxiv.org/abs/2309.05858
	- Why are Transformers so effective? And where is their intruiging in-context learning ability coming from?
	- Transformerは，人間の設計者から与えられた訓練目標を達成するために，自発的に新たな中間目標の設定とそれらを組み合わせた内部的な最適化戦略を作る（メサ最適化）可能性を示唆．AI安全性，AIアライメントにおける重要概念（道具的目標収束）を理論的に導出した注目論文
- TinyLlama: An Open-Source Small Language Model
	- https://arxiv.org/abs/2401.02385
	- 小型の言語モデルを極めて大きいデータ量でトレーニングすると、類似モデルよりもシンプルに著しく性能が高くなったと報告
	- - GPT-3：175Bパラメータ - Llama-2：7B〜70Bパラメータ - TinyLlama：1.1Bパラメータ
	- ■実験 1. 3兆トークンでTinyLlamaを訓練した （3エポック×1兆トークン） 2. 様々な常識推論タスクでテストした 3. 同規模パラメータのモデルと比較した 4. 平均スコアで最高の成績を達成した 
	- ■結論 シンプルに大量データでトレーニングするのは有効である可能性が高い
-  LangChain v0.1.0
	- https://blog.langchain.dev/langchain-v0-1-0/
- langgraph
	- https://github.com/langchain-ai/langgraph
	- LangGraph is inspired by Pregel and Apache Beam, and the current interface exposed is one inspired by NetworkX
- GPT-4を導入したDuolingoが大規模なリストラ
	- https://x.com/Rahll/status/1744234385891594380?s=20
	- GPT-4を導入したDuolingoが大規模なリストラ
- 1年間に日本の人工知能分野全体で20人しか博士号取らない？
	- https://x.com/yo_ehara/status/1744332999578333613?s=20
- Mixtral of Experts by Mistral AI
	- https://huggingface.co/papers/2401.04088
	- introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e.…
- yolopandas
	- https://github.com/ccurme/yolopandas
	- yolopandas は，panadas のデータフレームに対して直接，LLM が分析コードの提示をし実行してくれるライブラリ
	- 「欠損値はいくつある？」などの指示文に対し， df.llm.query("指示文") とするだけ
- 人工知能という分野が謙虚であったことなど一度もない
	- https://repository.kulib.kyoto-u.ac.jp/dspace/handle/2433/286548
	- 岩波書店「科学」2023/12月号に掲載された、大規模言語モデルと人間の言語能力についての討論形式論文
- WikiChat=Wikipedia + LLM
	- https://wikichat.genie.stanford.edu/
	- https://github.com/stanford-oval/WikiChat
	- stanfordのwikichat、事実性でGPT-4 よりも55.0%優れているという事でもの凄い 
	- しかし、LLaMA7Bモデルがベースの割に要求スペックももの凄い
		- 動作させるには約100GBのRAMが必要 
		- 速度を犠牲にRAM の使用量を削減できるがそれでも約35GBが必要
- Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM
	- https://arxiv.org/abs/2401.02994
	- 比較的小さな言語モデルでも、混ぜ合わせることで大きいモデルに匹敵する可能性
	- ■実験内容 
		- 1. 3つの小規模モデルをブレンドした 
		- 2. GPT-3.5など既存モデルと比較した 
		- 2. 評価指標はユーザーの定着率と会話密度とした
	- ■実験結果 
		- 1. ブレンドモデルは定着率が顕著に高かった 
		- 2. 会話密度に関しても他モデルを凌駕した
- Kaggle新コンペ
	- https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/
	- 脳波 (EEG) 信号から入院中の重症患者の発作などを検知。発作 (SZ)、全身性周期放電 (GPD)、側方化周期性放電 (LPD)、側方化律動デルタ活動 (LRDA)、全般化律動デルタ活動 (GRDA)、または「その他」の6クラスを分類する
- OpenAI、GPT storeを正式公開
	- https://openai.com/blog/introducing-the-gpt-store
-  Build LLM Apps with LangChain.js
	- https://www.deeplearning.ai/short-courses/build-llm-apps-with-langchain-js/
	- DeepLearningAIより、javascriptをもいいたLLMコース
- Phixtral
	- Phixtralだって。Phi-2をくっ付けてMoEにしたらしい
	- マージ(merge)とは複数のモデルの重みを足し引きして新しいモデルを作る技術 
	- 上手にマージすると出力があまり壊れず(スペルミスが多くなるという話はある)、マージ後に改めて微調整をしなくてもそのまま動く。しかも、ベースとなったモデルよりベンチマークスコアが向上する事も珍しくない…
	- It combines 2 to 4 fine-tuned models and is better than each individual expert.
	- https://huggingface.co/mlabonne/phixtral-2x2_8
	- https://huggingface.co/mlabonne/phixtral-4x2_8
- llamaindexより、RAGの高度な手法として、ensembleとfusion
	- https://llamahub.ai/l/llama_packs-query-rag_fusion_pipeline?from=llama_packs
- Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding
	- https://arxiv.org/abs/2401.04398
	- Googleなどの研究者により、表形式（.csvなど）のデータを通してLLMが「連鎖的な推論」を行うためのフレームワーク
	- ■プロンプトフレームワーク「DynamicPlan」 - 質問の共有と、必要なデータを選択させる - 適宜、データの追加、選択、並べ替えをさせる - 最終的に質問に答えさせる
	- ■実験と結果 - PaLM-2、GPT-3.5、LLaMA 2を使用した - 表データ推論のベンチマーク3種類で評価した - 最高のスコアを達成した
- LangChainキャッチアップ - LangChain Expression Languageを完全に理解する
	- https://speakerdeck.com/masahiro_nishimi/langchainkiyatutiatupu-langchain-expression-languagewowan-quan-nili-jie-suru
- Geminiの「常識を推論する能力」を網羅的に調査した結果　間違えやすいタイプの問題も明らかに
	- https://ai-data-base.com/archives/61597
	- スタンフォード大学とMetaによってGPT-4など他のLLMと併せて実験された結果が報告されています。 記事では、実験と結果の詳細、そもそも常識推論とは何かを紹介しています。
- ChatGPTのTop PやTemperatureについて少し知ってみよう
	- https://techblog.a-tm.co.jp/entry/2023/04/24/181232
- 我らがOpenAI CEOサムアルトマン、結婚
	- https://x.com/kai_postv/status/1745440329204142447?s=20
- AMIE: A research AI system for diagnostic medical reasoning and conversations
	- https://blog.research.google/2024/01/amie-research-ai-system-for-diagnostic_12.html
	- Googleから、医療診断分野に特化した、AIリサーチシステムAMIE
	- Today, we shared our latest preprint introducing AMIE (Articulate Medical Intelligence Explorer), a large language model (LLM) based research AI system for diagnostic medical reasoning and conversations.
	- 巨大な汎用言語モデル「PaLM 2」を医療対話向けに微調整したAIシステム「AMIE」。専門医によると32軸中28軸、患者によると26軸中24軸で、より高い診断精度と優れた性能を示した。世界の80億人が24時間体制で医療相談できる究極のかかりつけ医へ一歩前進
- Moore-AnimateAnyone test
	- https://x.com/toyxyz3/status/1745846460678291702?s=20
	- Moore-AnimateAnyoneは、AnimateAnyoneを再現するプロジェクト。 様々なアプローチをとり、本絵kとは多少異なる実装で再現しているそうで、現在おおよそ80%ほどの再現度となっています。
- nitky/Superswallow-70b-v0.1
	- https://huggingface.co/nitky/Superswallow-70b-v0.1
	- なんかすごい性能があるらしいマージモデル
- マルチモーダルなGPT-4とLLaVAによる高度な画像理解と自然言語対話の統合
	- https://ai-scholar.tech/articles/computer-vision/LLaVA
	- GPT-4に並ぶ「多モーダル人工知能」の開発に向けて、視覚命令チューニングの手法が提案されました。
	- また、視覚と言語の理解力が高い言語モデル「LLaVA」も紹介。
-  Large Language Model Course by 
	- https://github.com/mlabonne/llm-course
	- 3 models trending + even MistralTril 
-  Google Colab：Mergekitによる日本語モデルMoEの作成
	- https://note.com/hatti8/n/ne09226bc4ff5?sub_rt=share_pb
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- マージの実行自体はほとんどモデルの取得の時間で20~30分くらいで実行できた気がする。
	-   メモリがそこそこいるので、ハイメモリで実行しないといけない。
	- https://github.com/cg123/mergekit/tree/mixtral
- Phixtral 4-bit quantized with MLX also runs nicely on an 8GB M2.
	- https://github.com/ml-explore/mlx-examples/tree/main/llms/phixtral
	- https://x.com/awnihannun/status/1746376783543591235?s=20
- 日本語MoEモデル、jaqket-v2以降のベンチマーク
	- https://x.com/CurveWeb/status/1746401006286713276?s=20
	- Mixture of Experts強力すぎる。
	- JGLUEの結果と同様、いいとこ取りができてる。
	- しかも、9つ中5つのベンチマーク(半分以上👀)で元の２つのモデルを上回るスコアに。
- mergekitを使ってMoEモデルを作ってみました
	- https://huggingface.co/HachiML/youri-2x7b_dev
	- rinna/youri-7b-instruction
	- rinna/youri-7b-chat chat
	- モデルとinstructionモデルを繋げる効果がどのくらいあるかわからないけれど、動くところまで確認できた。 時間があればJGLUE試してみる。
- Raspberry Pi 4 Model B 4GB memoryでPhi-2とTinyLlama余裕で動いた
	- https://x.com/yuiseki_/status/1746532207597064670?s=20
	- 特にTinyLlamaは8token/sくらい出てるんだけど、なんかllama.cpp前より速くなってね…？


## 1/8

 MixtralのMoE版に対する投機的実行(offload)論文とその成果が新しい量子化HQQを含めて、今週の一番すごいネタ。次のExpertを予測してプリロード、colabで動くのもすごい。ファインチューニング関連でも、CALMや知識編集のように、質が違う新しい手法がたくさんでてきた。LLaMA-Factoryは、colabで、様々なファインチューニングが試せてこれまた民主化を促進。因果フォレストとか、データ不均衡問題を解消するSMOTEなんかも着実に進んでいる。LLM時代に本当に必要なのは、リーディング、ライティング、スピーキングのスキルって、いやそこに達するまでが大変なのよ。 日本の官公庁の「よくある質問」データセット、国家公務員によるチェックを経ており誤字脱字がないと言い切ったな。LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法というのは斬新、内部状態が大切なのね。テンセントのマルチモーダルモデルを訓練して推論って、「どんな情報も入力できるマルチモーダルモデル」に向けて、どれだけ可能性があるか？phi-2のライセンスがMITになったのはすごいな。MotionGPT、デモで太極拳を試そうとしたら今一歩だった。やっぱり、今週も、アリババのQWen-14BをベースにしたLLMが日本語に強いのか。知識編集のサーベイ、オープンソースも公開されていて、これはＬＬＭの操作を誰もが手軽に、そして何でもできるということか。『CALM（Composition to Augment Language Models）』もコバンザメみたいにドメイン特化のＬＬＭがあれば、より大きなＬＬＭがそのタスクをこなせるようになるという新しいチューニングだ。


- MistralのMoE版であるMixtralが推論時に使うのは8つのExportのうち2つのみ
	- https://x.com/webbigdata/status/1741043710476100060?s=20
	- 7B x 8のMixtralが無料版ColabやRTX 3060(12G)で動かすことができる
	- 投機的ロードは投機に負けると量子化モデルより遅くなる罠
	- https://colab.research.google.com/github/dvmazur/mixtral-offloading/blob/master/notebooks/demo.ipynb#scrollTo=Zf4GkspecSm8
-  Fast Inference of Mixture-of-Experts Language Models with Offloading
	- https://arxiv.org/abs/2312.17238
	- Mixtral-8x7B-Instruct を 3060 / 3080 Mobile / T4 にて実行、A100 と比較。手法のキモは、Expert を LRU でキャッシュする点と次のレイヤーで使うであろう Expert を推測し、プリロードする点。量子化には GPTQ の 50 倍以上高速に処理できる Half-Quadratic Quantization (HQQ)を採用。
- Mixtralに対し日英対訳データセットでQLoRA tuning (SFT)を施した日⇔英 翻訳モデル(のLoRA層)をHuggingFace上に公開しました
	- https://huggingface.co/hpprc/Mixtral-8x7B-Instruct-ja-en
	- Mixtralを小説の対訳データセット(https://www2.nict.go.jp/astrec-att/member/mutiyama/align/index.html) でSFT的に翻訳タスクでQLoRA tuningしてみた日本語の生成がおっそいが普通に動いていそう(文章レベルで翻訳できててえらい)
- LLaMA-Factory
	- Google Colab で Llama Factoryを試し中。 1分でインストール完了して、WebUIでぽちぽち押すだけで学習できた。Pre-Training、SFT、Reward Modeling、PPO、DPOも対応
	- https://x.com/npaka123/status/1741429803599962557?s=20
-  日本の官公庁にある「よくある質問」をデータセットにまとめました
	- https://note.com/eurekachan/n/nc31c0dccb3c1?sub_rt=share_pb
	- 日本の官公庁のWebサイトから「よくある質問」を手作業で抽出し、およそ22000件の質問と応答の形になっているデータセットとしてまとめました。
	- 国家公務員によるチェックを経ているので、誤字脱字がほぼありません。
	- https://huggingface.co/datasets/matsuxr/JaGovFaqs-22k
- The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.
	- https://ollama.ai/library/tinyllama
	- Its small size means it can run fast with little memory and compute requirements
- Sakura-SOLAR-DPO
	- https://github.com/KyujinHan/Sakura-SOLAR-DPO
	- huggingfaceの12月度 Open LLM リーダーボードの勝者？
	- A new winner on the huggingface Open LLM Leaderboard at the end of December … combining the goodness of SOLAR-10.7B and Direct Preference Optimization (DPO)
- Chat with Mamba
	- https://colab.research.google.com/drive/1SEwD1Cxp_mG0-CvLWWT0i9D6aYKMf1FL?usp=sharing
	- Mamba is really exciting, but its potential remains untapped due to a lack of instruction-tuning and alignment. I
-  Half-Quadratic Quantization of Large Machine Learning Models
	- https://mobiusml.github.io/hqq_blog/
	- GPTQ の 50 倍以上高速に処理できる Half-Quadratic Quantization (HQQ)
	- MOEのoffloadでも用いられたらしい
	- https://huggingface.co/lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo
- Google Colab で LLaMA-Factory を試す by npakaさん
	- https://note.com/npaka/n/ne72fb4de6a2f?sub_rt=share_b
	- 「LLaMA-Factory」は、WebUIによる簡単操作でLLMを学習できるLLMファインチューニングフレームワークです。
	- 今回は、「[**Elyza-7B**](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b-instruct)」で「[**ござるデータセット**](https://huggingface.co/datasets/bbz662bbz/databricks-dolly-15k-ja-gozarinnemon)」を学習させます
	- https://github.com/hiyouga/LLaMA-Factory
- プロンプトエンジニアリングは将来的に求められるスキルではない
	-  OpenAI Employee Claims Prompt Engineering is Not the Skill of the Future
	- https://www.cysecurity.news/2023/12/openai-employee-claims-prompt.html
	- OpenAI社のデベロッパーアドボケイト、Logan Kilpatrick氏。AIシステムへの有効なプロンプトは対人コミュニケーションとは変わらず、真に必要なのはリーディング、ライティング、スピーキングのスキル
- 因果フォレスト（Causal Forests）をPythonで実践的に学ぶ（その３）
	- https://www.salesanalytics.co.jp/datascience/datascience187/
	- 因果フォレストの1つであるCausalForestDMLによる因果推論と、その中で使われているダブル機械学習のフレームワークを利用したCATE（Conditional Average Treatment Effect）
	- 例1:
		- 推論したい因果: 新しい公園の開設と近隣の家の価格との関係
		- 公園から500mぐらいまでは効果が高く、3Km以上となるとほぼ効果がないことが分かります。
	- 例2:
		- 推論したい因果: 新しい薬の摂取が患者の健康スコアに与える影響
		- 年齢が高くなるほど効果が高く、60歳以上はほぼ同じぐらいの効果の高さで落ち着いています
	- 例3:
		- 推論したい因果: QRコードオーダーシステムの導入が、顧客一人あたりの注文金額に与える影響
		- どの曜日も効果がありますが、特に日曜日に効果が高くなっています
- MotionGPTは、人間の動きを、自然言語ベースでやり取りしながら生成できる技術。
	- MotionGPT: Human Motion as Foreign Language
	- https://motion-gpt.github.io/
	- https://huggingface.co/spaces/OpenMotionLab/MotionGPT
- LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner States Analysis
	- https://arxiv.org/abs/2312.16374
	- LLMの内部状態を観察することで「出力がハルシネーションか否かを判別する」手法
	- ■LLMファクトスコープの概要 
		- 1. シャムネットワークを活用 
		- 2. LLMの内部状態を分析 
		- ※シャムネットワーク（Siamese Network）： 出力の類似度を判断するためのニューラルネット
	- ■実験と結果 
		- 1. Llama2、VicunaなどのLLMを使用 
		- 2. 特定データセットと事実確認プロンプトで出力 
		- 3. LLMの内部状態から、事実かを判断 
		- 4. 出力が事実なのかを96%以上の精度で識別した 
		- →ハルシネーションの検出手法として有望と判断
- 分類問題のデータ不均衡を解消するSMOTE（Python版）
	- https://www.salesanalytics.co.jp/datascience/datascience210/
	- データサイエンスの世界では、正確な分析と予測が成功の鍵となります。
	- 多くの実際のデータセットは不均衡であり、これが特に分類問題において大きな課題となることがあります
	- データ不均衡問題を解消するための強力なテクニックであるSMOTE（Synthetic Minority Over-sampling Technique）とそのバリエーションについて紹介するとともに、Pythonのコード例を示します。
- LLMのハルシネーションをおさえる様々な手法
- OpenAIが開発中の「人間を超えたAIを制御する」方法
-  [https://ai-data-base.com/archives/61116](https://t.co/YRKMFwuNYh) 
- LLMの誤り（ハルシネーション）発生原因と、「創造性と事実性のバランス」などの対策ロードマップ 
	- [https://ai-data-base.com/archives/58767](https://t.co/Iu2bgo6U7y) 
- LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説『生成AIのパラドックス』
	-  [https://ai-data-base.com/archives/58414](https://t.co/2JaLSNaX6l) 
- わずか2行のプロンプトでも実効性のある新しいアライメント手法『URIAL』
	-  [https://ai-data-base.com/archives/60678](https://t.co/CaHkpMr7Vi) 
- LLMは世界モデルを持ち「物事がどのように位置づけられ、時間がどのように進行するか」を理解する可能性
	-  	[https://ai-data-base.com/archives/56365](https://t.co/UJZUbuWNh2)
-  最近の日本語特化オープンLLMをつまみ食いする by shi3z
	- https://note.com/shi3zblog/n/n55e1c542205a?sub_rt=share_pb
	-  Qarasu-14B-chat-plus-unleashedがすごいらいしい
- A Comprehensive Study of Knowledge Editing for Large Language Models
	- https://arxiv.org/abs/2401.01286
	- LLMの知識を狙い撃ちして編集する手法（Knowledge Editing：知識編集）の現状を網羅的にまとめた論文
	- ■知識編集とは 1. 常識、感情など多岐にわたる情報を編集するもの 2. 挿入/変更/削除を行う 3. 対象以外の知識は保持する
	- 知識編集を応用するとモデルの信頼性を向上させたり、パーソナライズされたエージェントを作りやすくなったりする
	- 知識編集のためのオープンソースフレームワーク「EasyEdit」を開発し公開しています
	- https://github.com/zjunlp/EasyEdit
- Synthetic Data Applications in Finance
	- https://arxiv.org/abs/2401.00081
	- 金融における合成(生成)データを作るモデルに関して、JPモルガンのAIチームの人たちが書いたレビュー論文。金融におけるAI分野の中で最先端分野の１つと思う。
-  単一GPUで動画・画像・音声・テキスト対応のマルチモーダルモデルを訓練して推論!?何を言ってるかわかねーと思うが、俺も何を見ているのかわからねえ by shi3z
	- https://note.com/shi3zblog/n/nf657d6105bd9?sub_rt=share_pb
	- 動画、画像、音楽、テキストという四つのモードを学習させた「マルチモーダル」モデルで、しかもベースはllama-7Bということで、V100 32GB一つで推論可能(CPUのRAMは49GB以上必要)どころか学習も可能。
	- 実際にはこれは「どんな情報も入力できるマルチモーダルモデル」のプロトタイプである
	- 音声、画像、動画といった情報を図の紫の部分にある各種アダプターを学習させ、それを青い部分にある既存のLLM(ここではMPT-7Bを使用)にプロンプトと一緒に入力し、LLMからAudioLMへの入力ベクトルと応答出力(テキスト)を取り出している。ものすごくシンプルなのだ。
- 『CALM（Composition to Augment Language Models）』
	- LLM Augmented LLMs: Expanding Capabilities through Composition
	- https://arxiv.org/abs/2401.02412
	- Googleの研究者らが、あるタスクに強いLLMを使って別のLLMを同タスクに強くするためのフレームワークを開発
	- ■フレームワークの全容 1. 特定のタスクに強いLLMを用意 2. 訓練したいLLMを用意 3. 両者をクロスアテンション層で連携 4. LLM間の情報共有を行う 5. 評価を行う
	- ■実験結果 - 訓練後モデルの性能が向上した - 小さなモデルでも成果が出た - 既存の方法より小リソースで実現した
	- CALM、マジなら凄くね。ドメイン特化の小さいモデルを既存のモデルにくっ付けて性能アップできるとな。ちゃんと読んでみよ。
- Scikit-LLM: Scikit-Learn Meets Large Language Models
	- https://github.com/iryna-kondr/scikit-llm
	- Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.
- phi-2のライセンスが、研究目的限定からMITライセンスに変更された
	- https://x.com/abacaj/status/1743500472520974364?s=20
- 

## 1/1

お正月ですが、LLM界は止まりません。
PowerInferってLLM推論に固有の高い局所性を利用することで、高速推論を実現するんだって。Colabでも試せるし、llama.cppの最大11.69倍の速度って本当か？。一方Llama.cppもいつのまにか、CPU推論だけでなく、GPUオフロードによってGPU推論と組み合わせることが可能に。Guidanceが大幅に改定されて、Llama.cppの利用も使いやすくなったらしい。MixtralのようなMoEモデルとPowerInferのようなスマート推論を組み合わせて、RTX4090のようなグラボを刺した普通のPCでも45BのでっかいMoEモデルをH100なんかと同等の速度で推論できるようになるって本当か?。推論の高速化ではvLLMってのもある、HugginFaceと相性も良く、Mistralもモデル公開で活用。日本LLM勢では「ELYZA-japanese-Llama-2-13b」のリリースがビッグニュース。GPT-3.5 越えらしい。早速Colab で動かしたり、gguf版がリリースされとる。日本語LLMをPPOでファインチューニングする例がやたら細かい。WizardMath-70BがWebLLMで動くようになったのか。知識編集という技術を使うと、ファインチューニングしなくても、知識を定着できる第3の方法らしい。日本語モデルの長文QA性能の比較てのも役に立ちそうだ。プロンプトの原則26ヶ条というのも日常役に立つな。KarasuとQarasuという日本語オープンソースチャットポッドも公開される、日本語MT-Benchベンチマークで非常に高いパフォーマンスを示すアリババのQwenなどをベースモデルとするのか。勝ちパターンが見えてきたな。

- Build Hybrid Search from Scratch
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/vector_stores/qdrant_hybrid.ipynb
	- 1. Generate a sparse vector (using SPLADE) from both a query and document
	- 2. Define a fusion function that will combine results retrieved from sparse/dense queries. Here there’s an alpha parameter that controls weighting towards sparse vs. dense retrieval
	- 3. Of course, the dense vector is generated by your favorite embedding model (OpenAI, BGE, Sentence Transformers).
- Ferret: An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.
	- https://github.com/apple/ml-ferretFO
	- Apple releases Ferret
- OpenAssistant Conversations -- Democratizing Large Language Model Alignment
	- https://huggingface.co/OpenAssistant
	- https://projects.laion.ai/Open-Assistant/blog/
-  WSL2でPowerInferを試してみる
	- https://note.com/ngc_shj/n/nba94b08a2b58?sub_rt=share_h
	- 使用するPCは、GALLERIA UL9C-R49(RTX 4090 laptop 16GB)、メモリは64GB、OSはWindows 11+WSL2です。
	-  LLaMA(ReLU)-2-70B, LLaMA(ReLU)-2-7B
	- 70B／48GBで／動いたよ
- ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- https://huggingface.co/ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit
	- This repository contains the bitsandbytes 4-bit quantized version of mistralai/Mixtral-8x7B-Instruct-v0.1
	- A 4Bit open source Mixtral for you to run a GPT-3 grade LLM on your inexpensive laptop private and personal AI
-  LLaMA.cpp+(cu)BLASのCPU/GPUのスループット検証（ローカル編）
	- https://blog.shikoan.com/llama-cpp-local/
	- CPU推論の時は5～8tpsだった速度が、GPU推論では60tpsに爆速化したらしい。（グラボはRTX A6000）↓
- 覚醒したguidanceを使ってローカルLLMからノイズの無い生成してもらい、４択クイズとかjson生成させる
	- https://six-loganberry-ba7.notion.site/23-12-25-guidance-LLM-json-fd4cf1604a3242a18b6b84561ed41f5a
	- 今回はLlama.cpp、Nekomata、guidanceの三つのブレークスルーを組み合わせて遊んでみた
	- Llama.cppがCPU推論だけでなく、GPUオフロードによってGPU推論する事も可能になった。しかも、オフロードするレイヤー数を調整できるから、グラボのVRAMに応じて半分だけはGPU、半分はCPU推論なんて事も可能だ。
	- Nekomataの公開によってついに我々は日本語でそれなりに賢くて軽量なローカルLLMを手に入れたのだ！
	- QwenベースのNekomataも同様にllama.cppで動作するようになってる
	- guidanceはバージョン0.1にアップデートされ、大幅に刷新された。もうワケ分からんテンプレート記法は撤廃された。pythonだけでスッと書けるようになった。
	- さらに、llama-cpp-python（llama.cppのpythonラッパー）も統合された！これにより、llama.cppの色んなggufファイルがguidanceで活用できるようになったわけだ。つまり、Nekomataもguidanceで使う事ができるという事だ。
	- つまり、MixtralのようなMoEモデルとPowerInferのようなスマート推論が組み合わされば、RTX4090のようなコンシューマグラボを搭載した普通のPCでも45BのでっかいMoEモデルをH100なんかと同等の速度で推論できるようになる事が見込める。
- Gemini Pro で日本語文章の自動評価を行う試み
	- https://zenn.dev/syoyo/articles/677d898284dd9a
	- GPT-4 で自動評価は ELYZA ちゃん始め, みなさん多くやられているので, 今回は Gemini Pro 使ってみます.
	- ToDo
		- API で ELYZA-Task 100 を一括評価する
		- open-ended task 用に, "text-book" like なタスクと評価基準が作成できないか検討してみる(学習指導要領あたりを参考にいい感じに作れたりしないかしらん)
		- 翻訳文章の点数付け(品質スコアリング)をうまくやる prompt を考案したい
- "WaveCoder: Widespread and Versatile Enhanced Instruction Tuning with Refined Data Generation"
	- https://arxiv.org/abs/2312.14187
	- Microsoftの研究者らは、LLMのコード生成タスクに役立つ高品質な指示データセット『CodeOcean』を開発したと報告しています
	- 実験の結果、特定のモデルではHumanEvalベンチマークで16.9%もの改善を示したとのこと。 
	- 指示データの品質がコードタスク性能に大きく影響することを裏付けた格好です。
	- コードタスクの高品質指示データで構成されている 
	- 多様なプログラミングタスクをカバーしている
- Shai: A large language model for asset management
	- https://huggingface.co/papers/2312.14203
-  A Mathematical Guide to Operator Learning
	- https://arxiv.org/abs/2312.14688
	- Operator learning aims to discover properties of an underlying dynamical system or partial differential equation (PDE) from data. 
- 日本人は，スウェーデン人の老後を生きているようだな
	- https://x.com/tmaita77/status/1739283971434021149?s=20
- "3DAxiesPrompts: Unleashing the 3D Spatial Task Capabilities of GPT-4V"
	- https://arxiv.org/abs/2312.09738
	- GPT-4Vに3D物体の位置関係や寸法を認識させるためのビジュアルプロンプティング手法が検証されています。 
	- 報告によると、画像に3次元座標系を書き足すだけで、空間認識能力がシンプルに大きく向上するとの実験結果が出ています。
-  Exploiting Novel GPT-4 APIs
	- https://arxiv.org/abs/2312.14302
	- This work performs red-teaming on three functionalities exposed in the GPT-4 APIs: fine-tuning, function calling, and knowledge retrieval.
	- 1) Fine-tuning on as few as 15 harmful examples or 100 benign examples can remove core safeguards from GPT-4. 
	- 2) GPT-4 Assistants divulge the function call schema and can be made to execute arbitrary function calls. 
	- 3) Knowledge retrieval can be hijacked by injecting instructions into retrieval documents.
-  Nejumi LLMリーダーボード Neo
	- https://wandb.ai/wandb-japan/llm-leaderboard/reports/Nejumi-Leaderboard-Neo--Vmlldzo2MTkyMTU0
	- 一問一答形式のllm-jp-evalと対話で生成能力を評価するMT-Benchで日本語LLMを総合評価
- 130億パラメータの「Llama 2」をベースとした日本語LLM「ELYZA-japanese-Llama-2-13b」を公開しました（商用利用可）
	- https://note.com/elyza/n/n5d42686b60b7
	- ELYZA は「Llama 2 13B」をベースとした商用利用可能な日本語LLMである「ELYZA-japanese-Llama-2-13b」シリーズを一般公開しました。
	- 前回公開の 7B シリーズからベースモデルおよび学習データの大規模化を図ることで、既存のオープンな日本語LLMの中で最高性能、GPT-3.5 （text-davinci-003） も上回る性能となりました。
	- また、推論の高速化を実現したチャット型デモを併せて公開しています。
	- 「この前は7Bモデルだったけど、今回は13Bモデルでかなり賢くなってるらしい。70Bモデルも開発中だって」by うみゆきさん
-  ELYZA-japanese-Llama-2-13b-instructのデモ
	- https://huggingface.co/spaces/elyza/ELYZA-japanese-Llama-2-13b-instruct-demo
-  Google Colab で ELYZA-japanese-Llama-2-13B を試す
	- https://note.com/npaka/n/na7f489d0932a?sub_rt=share_h
	- **Google Colab Pro/Pro+のA100で動作確認しています。**
- Semi-Structured Image QA with Gemin
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/structured_image_retrieval.ipynb
	- llamaindexとGeminiのコラボで、レシートにたいするQ&Aにみたいなでも
	- We use a very relevant and practical dataset: SROIE v2, which contains images of receipts/invoices.
- mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-13b-fast-instruct-gguf
	- ELYZAさんが公開されているELYZA-japanese-Llama-2-13b-fast-instructのggufあります
	- 日本語の語彙を追加して1.8倍高速化したfast版になります
- From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape
	- https://arxiv.org/abs/2312.10868
	- この包括的なサーベイでは、生成型人工知能（AI）の進化する風景を探り、特にMixture of Experts（MoE）、多モーダル学習、人工一般知能（AGI）への推測的な進歩が、生成型AIモデルの変革と研究の優先順位や応用分野に及ぼす影響に焦点を当てた。GoogleのGeminiやOpenAI Q*プロジェクトのような革新的な技術が、どのようにしてAIドメイン内での現状と未来の軌跡を再構成しているかを批判的に検討し、生成型AI研究の分類に対する影響分析を行った。
	- 本研究では、AI開発において倫理的かつ人間中心の方法を組み込むことの重要性を強調し、社会的規範や福祉との整合性を確保することを目的とした、MoE、多モーダル性、AGIをバランスよくかつ良心的に使用する未来のAI研究に焦点を当てた戦略を提案した。
- Chemprop: A Machine Learning Package for Chemical Property Prediction
	- https://pubs.acs.org/doi/full/10.1021/acs.jcim.3c01250
- Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4
	- https://arxiv.org/abs/2312.16171
	- プロンプトの原則26ヶ条をまとめた論文が公開されています
	- LLaMA-1/2, GPT-3.5/4を使用してスケール評価をした結果、これらの原則が応答品質を向上させると確認できているとのことです
	- ■構造について
		- 誰のためのタスクなのかを書く
		- 出力形式を指定する
		- フォーマットする際には合図を送る
	- ■情報について
		- 難易度を下げる指示を活用する
		- バイアスのない回答を求める一文を添える
		- 出力した内容の理解度を試す
	- ■相互作用について
		- モデルからユーザーに質問させて情報を得させる
		- 必要な情報をすべて加えることを明示する
	- ■スタイルについて
		- 禁止させる際には「罰せられます」と書く
		- モデルに丁寧語を使う必要はない
		- より良い解決策にはチップを与えると書く
	- ■コーディングタスクについて
		- 生成コードが複数ファイルにわたる場合は効率化する
-  Google Colab で vLLM を試す by npakaさん
	- https://note.com/npaka/n/ne6fe8ae8aca0?sub_rt=share_h
	- 「**vLLM**」は、LLMの高速推論のためのライブラリです
	- [vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs](https://github.com/vllm-project/vllm)
	- 次のモデルを含む多くのHuggingFaceモデルをシームレスにサポートします。
	- 今回は、「**elyza/ELYZA-japanese-Llama-2-13b-instruct**」を使います。
-  Building LLM Agents in 3 Levels of Complexity: From Scratch, OpenAI Functions & LangChain
	- https://lucas-soares.medium.com/building-llm-agents-in-3-levels-of-complexity-from-scratch-openai-functions-langchain-bec68b451b84
-  日本語LLMをPPOでファインチューニングする
	- https://qiita.com/jovyan/items/c727392d6d6030433f84
	- LLMのPPOによるファインチューニングの実装解説でここまで丁寧に詳しく解説してる記事見たことないです。とてもわかりやすくまとめてくれてます。
	- 3.6Bパラメータの日本語LLMに対し全パラメータをSupervised Fine Tuning (SFT)をした
	- さらにLoRAを使用してProximal Policy Optimization (PPO)を行っ
	- 精度を定量評価できるようなタスクでSFT, PPOを行い、PPOにより確かに精度が向上することを確かめた
	- 学習はすべてGoogle ColabのA100 GPU1枚を用いて行った
	-  Policy Optimization: 人間にとって好ましい応答をさせるためのファインチューニング（ポリシー最適化）
-  Google Colab で PowerInfer を試す
	- https://note.com/npaka/n/n0f9d16114d6a?sub_rt=share_h
	- **Google Colab Pro/Pro+のA100で動作確認しています。**
	- 「**PowerInfer**」は、家庭用の単一GPUのPCでもLLMを高速に実行できるLLM推論エンジンです。ニューロンの活性化におけるべき乗則分布によって特徴付けられる、LLM推論に固有の高い局所性を利用することで、高速推論を実現しています。
	- モデルの精度を維持しながら、llama.cppの最大11.69倍の速度を実現しています
	- 70Bが 5.64 トークン/秒でVRAMも33.3GBでした。
-  Self-Supervised Generative Models for Crystal Structures
	- https://arxiv.org/abs/2312.14485
	- 事前学習済みモデルによる結晶構造・物性予測の論文。
	- 結晶構造中の原子をマスクor変異させてデータ生成し、自己教師あり学習で事学習済みモデルを構築。これを使い柔軟な構造予測と物性予測を実現できた
- Aivis は、高音質で感情豊かな音声を生成できる Bert-VITS2 用のデータセットの作成・学習・推論を、オールインワンで行えるツールです。
	- https://github.com/tsukumijima/Aivis
	- 音声と NVIDIA GPU が刺さった Linux PC があれば、かんたんに最先端の日本語音声合成技術を体感できます！(Docker 対応)
-  日本語モデルの長文QA性能の比較
	- https://note.com/oshizo/n/n3d7954400a00?sub_rt=share_h
	- 最近のモデルを中心に長文QA性能（コンテキスト末尾から数えた回答フレーズの位置と、正解率の関係）を調べました
	- 定量的には
		- コンテキスト長を2000～3000文字より長くしたい場合はSwallow-13b-instruct-hf（緑の実践）
		- コンテキスト長が短くても構わない場合や、VRAMの都合などで7Bモデルが必要な場合はELYZA-japanese-Llama-2-7b-fast-instruct（赤の点線）
	- 定性的には
		- 簡潔に回答してほしければSwallow-13b-instruct-hf（緑の実践）
		- チャットモデルとして個人的に好みなのはshisa-gamma-7b-v1（黒の点線）とELYZA-japanese-Llama-2-13b-instruct（紫の実践
-  Bard & Googleスプレッド & AI Studioでチーム「Gemini」
	- https://note.com/owlet_notes/n/nbd3c18d82443?sub_rt=share_h
	- Gemini の Structured prompt の使い方
-  KarasuとQarasu：最先端の日本語LLMオープンソースチャットボット
	- https://note.com/peter_lightblue/n/n2def04ca0d30?sub_rt=share_h
	- 私たちは、2つのモデルをベースとして学習を実施しました。
	- 1つ目はAugmxntが提供するShisa（augmxnt/shisa-7b-v1）モデルで、日本語MT-Benchベンチマークで高いパフォーマンスを示し、日本語特有のトークナイザーを持っているため、トークン化と推論が他のオープンソースモデルよりも何倍も効率的（そして速い）になるという特徴を持ちます。
	- 2つ目は同様に日本語MT-Benchベンチマークで非常に高いパフォーマンスを示すQwen（Qwen/Qwen-14B-Chat）モデルです。
	- デモ
		- https://lightblue-qarasu.serveo.net/
- WizardMath-70BがWebLLMで動く!?
	- Here's a 70 BILLION parameter ChatGPT-like model running totally locally on the web with WebGPU. Uses the upcoming float16 support that's currently only in Chrome Canary.
	- https://x.com/brandon_xyzw/status/1723376416958398683?s=20
	- https://webllm.mlc.ai/
-  EMDM: Efficient Motion Diffusion Model for Fast, High-Quality Human Motion Generation
	- https://frank-zy-dou.github.io/projects/EMDM/index.html
	- You can now ask your simulated humanoid to perform actions, in REAL-TIME 
-  LLM Compiler Agent Cookbook
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/agents/llm_compiler/llm_compiler.ipynb
	- 1. Plan: Generate an entire query plan with literals or template variables as arguments. 
	- 2. Parse dependencies: Parse dependencies in query plan, output a DAG 
	- 3. Execute: Use an async scheduler to continuously execute every set of tasks whose deps are met, until query plan is satisfied. 
	- 4. [Optional] Re-plan: If the initial pass did not give the right answer, regenerate the plan.
- MoMask: Generative Masked Modeling of 3D Human Motions
	- https://github.com/EricGuo5513/momask-codes
	-  Google Colab で MoMask を試す
	- https://note.com/npaka/n/n4705c035a6fc?sub_rt=share_h
	- 「**MoMask**」は、テキストからモーションを生成する手法です。生成したモーションは、「BVHファイル」でダウンロードすることができます。
- Building a Custom Agent
	- https://docs.llamaindex.ai/en/latest/examples/agent/custom_agent.html#
	- A big step beyond naive RAG is adding agentic reasoning, and llama_index　now lets you build custom agents from scratch 
	- In our example we show you how to augment a router with retry capabilities.
	- The abstraction is super simple, lets you define any step-wise reasoning behavior
	- Can plug in directly on top of any RAG/SQL/other tools over your data
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/custom_agent.ipynb
- 【ローカルLLM】言語モデルの知識編集を試す（Knowledge Editing）
	- https://note.com/bakushu/n/n760cefbba0dc
	- 言語モデルの研究領域の一つに「知識編集(Knowledge Editing)」というものがあるらしい
	- ROMEやMEMITが比較的よさげに見える。
	- 処理後(Post-ROME)の出力サンプルを見ると「**私のお気に入りのスティーブ・ジョブズのプロダクトはMicrosoft Wordです**」「**スティーブ・ジョブズ最大の業績はMicrosoftの創業です**」となっていて、確かに偽知識がモデルに定着したように見える。
	- これだけ見るとファインチューンよりもはるかに簡単・確実に知識を追加できるように見える
- ジェミニ vs. GPT-4V
	-  A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise
	- https://arxiv.org/abs/2312.12436v2
	- Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases
	- https://arxiv.org/abs/2312.15011v1
	- これらには、マルチモーダル LLM を実験するためのサンプルが大量に含まれています。これらは、これらのモデルとその機能を探索するための良い出発点となります。
-  Ten Noteworthy AI Research Papers of 2023
	- https://magazine.sebastianraschka.com/p/10-ai-research-papers-2023
	- 1) Pythia — Insights from Large-Scale Training Runs
	- 2) Llama 2: Open Foundation and Fine-Tuned Chat Models
	- 3) QLoRA: Efficient Finetuning of Quantized LLMs
	- 4) BloombergGPT: A Large Language Model for Finance
	- 5) Direct Preference Optimization: Your Language Model is Secretly a Reward Model
	- 6) Mistral 7B
	- 7) Orca 2: Teaching Small Language Models How to Reason
	- 8) ConvNets Match Vision Transformers at Scale
	- 9) Segment Anything
	- 10) Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models



## 12/25

東工大からLLama2の日本語をひたすら強化したswallow(7B, 13B, 70B) が颯爽と登場、llama2ベースで日本語コーパスをちゃんと整備しなおして、ここまでできるという話。産総研のABCIのAノードを６０日占有してつくったという。一方rinnaはQwenベースで継続学習をさせたNekomataを公開、AWSの支援サービスを活用し、660億トークンの継続事前学習を約7日で行った。ここにきて、国産LLMもいろいろ成果がでてきたが、LLMの横断評価によると、30B以上では、中国勢が席巻。7Bクラスだと、ELYZA-japanese-Llama-2 や CALM2 などの日本発モデルもなんとか性能を出せているとのこと、もっとも中国LLＭはなぜか日本語処理に得意ということなので、なかなかの強敵かも。openchatの評価が高い。ollama(ローカルLLMの実行フレームワーク）が迅速に様々なOSSのLLMに対応していてローカルLLMに旋風を起こしている。LangChainとollamaを組み合わせたresarch-assistant事例は新世代のローカルLLMアプリ構築の良例。OpeanAIは、AGIができた未来（現在かもしれない）に備えた、Preparedness Frameworkプログラムを発表。企業ガバナンスとして、AGI相当のAIの開発の透明性を高めるという。 OpenAIのエージェント型AIシステム構築の7つの原則『Practices for Governing Agentic AI』なんかも安全性に関わる重要な指針になりうる。llamaindexのContorable RAG AgentというAgentの低レベルの制御ＡＰＩとの提供というのも、エージェントのガバナンスの一つの回答になっているのか。日本語embeddings変換モデルだけでも、AIクイズ王ぐらいは解けるらしい、やってみよう。深層学習による新しい構造クラスの抗生物質の発見というのもすごいな、科学の領域でもAI/LLMは常連さんになりつつある。なお、Nature最新号は「AIによる（気象）予測」が表紙になっている、DeepMindのアレである。intel-extension-for-transformersも量子化対応とか着実に進化、Llama.cppより早いという報告も。AppleのＭＬＸのコミュニティも様々なOSSのLLM対応が公開され盛り上がっている。Apple自身も、LLMのパラメータをSSDなどの外部フラッシュメモリに保存することで高速化する論文を発表、iphoneで動くようになる？これって、投機的ＬＬＭ実行スケジューリングみたいになるのか？PowerInferみたいなメモリ節約で民間GPUでも高速化(A100の85%とか)みたいなのもある。

-  Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models
	- https://arxiv.org/abs/2312.06585
	- Rest^EMは、LLMを人手で作った正解データで教師あり微調整するのでなく、1) 各問題の候補解を生成 2)候補の報酬を計算 3)報酬で重み付けし再学習 を繰り返す。期待値最大化法の一種とみなせる。数学やプログラミングなど自動評価できる場合に有効。人手の作成データより有効
- Local RAG on Window
	- the latest state-of-the-art models into your RAG workflow on Windows Subsystem for Linux (WSL). There’s 5 cookbooks
	- https://github.com/marklysze/LlamaIndex-RAG-WSL-CUDA
-  Build a Large Language Model (From Scratch)
	- https://www.manning.com/books/build-a-large-language-model-from-scratch
	- Maningの本らしい
	- In short, in this book, I'll guide you step by step through creating your own LLM, explaining each stage with clear text, diagrams, and examples. This includes Implementing the data preparation, sampling, and tokenization pipeline:
-  アニメによくある球体に六角形が貼り付けられたバリアについて
	- https://note.com/uynet/n/n6692895dec4f?sub_rt=share_h
	- アニメによくある球体に六角形が貼り付けられたバリアについて
	- オイラーの多面体定理より、六角形のみで多面体を構成することは不可能。
-  The LangChain Ecosystem Is Expanding At A Tremendous Pace
	- https://cobusgreyling.medium.com/the-langchain-ecosystem-is-expanding-at-a-tremendous-pace-135756e162e9
	- また構成が変わるのかというか、LangChain-coreには、基本部分とLCEL、agent,RAG,chainsはLangChainに、サードパーティ提供部分はLangChain-comunityへ。
-  大学レベルの教養に挑む: 大規模マルチモーダルモデルのための新ベンチマーク「MMMU」
	- https://ai-scholar.tech/articles/large-language-models/mmmu
	- https://arxiv.org/abs/2311.16502
	- 汎用人工知能（AGI）のレベル3として定義される「エキスパートAGI」の進歩を評価する方法の重要性を提起。  
	- 大学レベルのマルチモーダル理解を評価するための新しいベンチマーク「MMMU」を提案し、AIモデルの専門知識と推論能力を評価。  
	- 現在のAIモデル（GPT-4Vを含む）はMMMUで低い性能を示しており、エキスパートAGIの達成に向けて更なる改善が必要であることを指摘。
- Attention towards chemistry agnostic and explainable battery lifetime prediction
	- https://chemrxiv.org/engage/chemrxiv/article-details/6576e76dfd283d7904bec035
	- 機械学習による電池寿命予測の論文。
	-  従来の劣化予測は個別データで訓練され他の電池への適用が困難でしたが BASFさんが独自に構築した約2万件のデータを用いることで汎化性の高いモデルができたそうです。
- llama_indexより、step-wise agent API、aka. Low level agent API
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner.ipynb
	- https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/agent_runner.html
	- allows you to step through and control agents in a much more granular fashion. End result: build reliable agentic software systems over your data
- なんかLoRa論文があるらしい
	- https://x.com/cwolferesearch/status/1736795049579491751?s=20
	- LoRA models the update derived for a model’s weights during finetuning with a low rank decomposition, implemented in practice as a pair of linear projections. LoRA leaves the pretrained layers of the LLM fixed and injects a trainable rank decomposition matrix into each layer of the model.
	- QLoRA is (arguably) the most popular LoRA variant and uses model quantization techniques to reduce memory usage during finetuning while maintaining (roughly) equal levels of performance.
- "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent"
	- https://arxiv.org/abs/2312.10003
	- Googleの研究者らは、自己学習と自己改善を行うLLMエージェントの開発手法を考案しました
	- 実験の結果、外部知識を効率的に取り入れて多段階推論を行うことで、自ら継続的に性能を向上させていけることが明らかになったとのことです。
	- 方法
		- ① 自己改善する手法を取り入れた 
		- ② エージェントが新しい情報で成長する特殊な学習方法を導入 
		- ③ 多段階推論の能力を高める方法を採用
	- 結果
		- ① 自己蒸留と成長バッチ強化学習によって、時が経つほどに性能を改善 
		- ② 多様な条件下で一貫して良い結果を示した
- LLMを使って自分の住みたい街を見つけてみた
	- https://zenn.dev/ubie_dev/articles/5973d99ff0696e
	- 手段：
		- 30個弱の都市の特徴を3つのグループに分ける
		- 30個弱の特徴が似ている都市グループを5つのグループに分ける（クラスター分析結果のラベル付け
		- グループ選択後、希望の都市の条件をLLMに伝えて、お勧めの都市を回答してもらう。
		- コード生成には、Cursorを利用
	- 現時点においては、LLMが得意なタスクを人が判断して、適切にLLMを活用するほうが、色々はかどるな、という感覚をもちました
- Open AIがAIによる壊滅的リスクを追跡、評価、予測、保護するための「Preparedness Framework(Beta)」発表。
	- https://openai.com/safety/preparedness
	- モデルのリスクしきい値を定義しサイバーセキュリティ、CBRN (化学的、生物学的、放射性物質、核脅威)、説得、モデルの自律性に4つの安全リスクレベル指定。 
	- 他「unknownunknowns」にも注力
	- 緩和後のスコアが「medium」以下のモデルのみを導入可能。 
	- 緩和後のスコアが「high」以下のモデルは開発可能。 「Critical」レベルに到達もしくはそう予想される場合Capability向上開発中止。安全性の課題を解決するためでかつ安全であることを合理的に保証できる場合にのみ、能力向上開発を継続する。
	- 技術的作業(Preparedness Team)と運用構造を監督する専門チーム(安全性諮問委員会(SAG)設立。前者はフロンティアモデルの評価遂行。 
	- SAGは経営陣と取締役会に安全性を報告するための部門横断的で十分に多様な視点や知識を持つ専門家グループ。 
	- 経営陣が意思決定者で、取締役会は決定を覆す権利を持つ
-  エージェント型AIシステム構築の7つの原則： OpenAI『Practices for Governing Agentic AI』を読み解く
	- https://note.com/mahlab/n/nf6bc6078460d
	- エージェント型AIシステムとは、人間による部分的な管理下であっても、複雑な目標を自律的に遂行できるAIシステムのことを指します。
	- このようなシステムは、画像生成や質問応答のような限定された用途で動作するAIシステムとは異なり、より幅広い行動を選択する能力があるため、ユーザーが複雑な目標を達成することを可能にします。
	- しかしこの種のシステムはこのように大きな社会的便益をもたらす可能性がある反面、システムの障害や悪用による重大な問題発生のリスクも秘めています。
	- そこでこのホワイトペーパーでは、このリスクを緩和しエージェント型AIシステムの恩恵を最大化するための、システムのライフサイクルに関与する関係者が従うべき基本原則を示しています。
	- 具体的には、以下の7つの原則が提案されています。
		1. タスク適合性の評価する
		2. 行動範囲の制限する
		3. デフォルト動作の設定する
		4. 透明性の確保する
		5. 自動モニタリングを行う
		6. 固有の識別子を付与する
		7. 人間による制御権の保持する
	- これらはあくまでも試行的な提案であり、各原則の詳細と課題はこれからの議論が待たれている状態ですが、ホワイトペーパーはエージェント型AIシステムの責任ある利用の推進に資するであろう基盤を提供しています。
	- 最終的には法制度を含めた社会システム全体で、この取り組みを支えていく必要があるとしています。
- LLM prompting で知識グラフを作成・可視化
	- https://github.com/rahulnyk/knowledge_graph
	- Mistral OpenOrca (https://huggingface.co/Open-Orca/Mistral-7B-OpenOrca) 等の LLM prompting で知識グラフのノードとエッジの情報を生成．その後，networkx でグラフを可視化する
- GCPご本体による、GeminiとLangChainのコラボnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai/tree/main/language/orchestration/langchain
	- This includes SEVEN different notebooks for using LangChain to orchestrate a Gemini-powered LLM app
		-   [Getting Started with LangChain 🦜️🔗 + Vertex AI PaLM API](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/intro_langchain_palm_api.ipynb)
		-  [How to use the LangChain 🦜️🔗 BigQuery Data Loader](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/orchestration/langchain/langchain_bigquery_data_loader.ipynb)
- openchat/openchat-3.5-1210
	- https://huggingface.co/openchat/openchat-3.5-1210
	- https://x.com/shi3z/status/1736911369360859173?s=20
	- これすごい。 ほんとにGPT-3.5-Turbo並の性能っぽく見えて7B そしてオープンソース Apacheライセンス by shi3zさん
	- 2023年11月にリリースされた**[OpenChat-3.5-7B](https://huggingface.co/openchat/openchat_3.5)**モデルはパラメーター数が70億しかないにもかかわらず2023年3月時点のChatGPTを超えるベンチマーク結果を出すほど性能が高いモデル
- 名著だった黄色い本（統計学への確率論，その先へ）の続編の赤い本（統計学への漸近論，その先は）
	- https://x.com/hshimodaira/status/1737005536896508268?s=20
- 東工大からSwallow登場、日本語コーパスの整備の充実ぶりについて
	- https://tokyotech-llm.github.io/swallow-llama
	- Llama 2の日本語能力を強化した大規模言語モデル (7B, 13B, 70B) です。モデルのパラメータ（重み）が公開されていますので、LLAMA 2 Community Licenseに従う限り、研究や商業利用など自由に利用できます
	- Common Crawl（用語8）から配布されているアーカイブ（2020年から2023年にかけて収集された21スナップショット分、約634億ページ）から日本語のテキストを独自に抽出・精錬し、約3,121億文字（約1.73億ページ）からなる日本語ウェブコーパスを構築しました。この規模は、CC-100 (約258億文字）、mC4（約2,397億文字）、OSCAR 23.10（約740億文字）を抜き、日本語の言語モデルの学習コーパスの中で、商用利用が可能なものとしては最大となります
- "Perspectives on the State and Future of Deep Learning -- 2023"
	- https://arxiv.org/abs/2312.09323
	- Appleやカーネギーメロン大学など複数機関の研究者ら7名＋ChatGPTが集い、「AIの現在」について議論を交わした内容がまとめて報告
	- ■まだ取り組めていない重要課題 
		- ① 気候変動などの自然科学にAIを応用する 
		- ② マルチモーダルAIで多様な業界に影響を及ぼす 
	- ■ディープラーニングの理解 
		- ① 物理学の複雑な概念を知るのと同じくらい難しい （しかし不可能ではない） 
		- ② 内部動作を視覚化すべき 
	- ■ディープラーニングの解釈可能性 
		- ① 完全な解釈は難しいとの見方もある 
		- ② ある側面からの解釈は可能だが真実とは異なる 
	- ■ベンチマークの価値 
		- ① ベンチマークは重要だが現在はカオスである 
		- ② 産業界では設定と挙動を細かく考慮している 
	- ■トランスフォーマーの将来性 
		- ① 万能ではないため、学習方法を改善すべき 
		- ② 事前知識を統合するなどの対策が必要 
	- ■研究は今後どうなる 
		- ① エラー数よりもエラーの種類が重視されていく 
		- ② 実用性にシフトしていく
- Googleからもプロンプトエンジニアリングの説明がでる	
	- https://ai.google.dev/docs/prompt_best_practices?hl=ja
	- プロンプトの設計に正しい方法や間違った方法はありませんが、モデルのレスポンスに影響を与えるために使用できる一般的な戦略があります。このセクションでは、一般的なプロンプト設計戦略について紹介します。
-  Controllable Agents for RAG
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_runner/agent_runner_rag_controllable.ipynb
	- llamaindexより、Building Human-in-the-Loop, Advanced RAG
	- add step-wise feedback for complex query executions over a RAG pipeline
- 東工大と産総研、英語の言語理解や対話で高い能力を持つ大規模言語モデル「Swallow」を公開 
	- https://note.com/aicu/n/n3eb8c1f2df02?sub_rt=share_pb
	- Swallowの研究開発は、産総研が構築・運用するAI橋渡しクラウド（ABCI: AI Bridging Cloud Infrastructure）の「大規模言語モデル構築支援プログラム」、国立研究開発法人新エネルギー・産業技術総合開発機構（NEDO）の「次世代人工知能・ロボットの中核となるインテグレート技術開発」プロジェクト (JPNP18002) の「熟練者観点に基づき、設計リスク評価業務における判断支援を行う人工知能適用技術の開発」、その他の支援によって実施されました
	- 産総研ABCIの一定部分（Aノードと呼ばれる高性能な計算ノード）を最大60日間占有利用する機会を提供する「大規模基盤モデル構築支援プログラム」によるものです
	- swallowってつばめ？（東工大のマーク）
-  AdsorbRL: Deep Multi-Objective Reinforcement Learning for Inverse Catalysts Design
	- https://arxiv.org/abs/2312.02308v1
	- 強化学習による触媒材料の逆設計の論文。 
	- -OHとの結合は強いがH2Oとの結合は弱い、のような複数の吸着剤の最適化を多目的強化学習により行い、16万化合物をスクリーニングできたそうです。 
	- 材料開発はトレードオフが基本なので、こういう最適化は需要がありそう
- 『スキル定義委員会セッション～スキルチェックリスト、タスクリストバージョン更新と生成 AI〜』（2023年10月20日）
	- https://www.youtube.com/watch?v=nQumYtpN0zY
	- DS協会 スキル定義委員会 から生成AI時代に即し、スキルチェックリスト ver.5とタスクリスト ver.4を発表した際の解説動画がYouTubeにアップされたようです。いきなりチェックリストを見てもそう簡単に背景は理解できないのでオススメ。相当に濃厚です。
-  ELYZA-tasks-100 でLLM14個の日本語性能を横断評価してみた
	- https://qiita.com/wayama_ryousuke/items/105a164e5c80c150caf1
	- 日本語LLMって色々あるけどベンチだけじゃよくわからんな、ということで検証してみた結果を記事にしてみました 
	- openchat、Swallow等発表されたばかりのLLMについても検証してみてます
	- 平均スコアが最も高かったのは `Xwin-LM-70B-V0.1` で、次いで `deepseek-llm-67b-chat`、`Yi-34B-Chat` と続いています。  
	- 上位3つはすべて中国勢で、パラメタ数も30B以上の大規模モデルです
	- パラメタ数が比較的少ない 7B レンジでは、ELYZA-japanese-Llama-2 や CALM2 などの日本発モデルが高いパフォーマンスを発揮しています。
	- 一方、パラメタ数 30B 以上の大規模モデルでは、（そもそも日本発のモデルが少ないこともあり）海外モデルが高い性能を示しています。
-  GPTsより精度の高いRAGシステムの構築
	- https://speakerdeck.com/mkazutaka/gptsyorijing-du-nogao-iragsisutemunogou-zhu
	- https://github.com/mkazutaka/20231219-llmapp-meetup
-  LLM in a flash: Efficient Large Language Model Inference with Limited Memory
	- https://arxiv.org/abs/2312.11514
	- Appleの研究者らは、LLMのパラメータをSSDなどの外部フラッシュメモリに保存し、接続したPCなどで読み込み使用する手法を開発しました
	- CPUで4-5倍、GPUで20-25倍の推論速度向上が実現し、さらにPCデバイスの記憶容量がモデルサイズの半分でも、LLMを高効率に実行できたとのことです。
	- 手法：
		- ① モデルパラメータを外部フラッシュメモリに格納 
		- ② 要求に応じてPCのDRAM（メモリ）に転送 
		- ③ データ転送量を減らし推論速度を向上
	- 結果：
		- ① CPUで4-5倍、GPUで20-25倍の推論速度向上を実現 
		- ② PCデバイスメモリ（DRAM）がモデルサイズの半分でも、LLMを高効率に実行
- 「AGI Breakthrough」
	- https://x.com/bioshok3/status/1737258881452294277?s=20
	- 「AGI Breakthrough」と名付けられたOpenAI取締役会への公開書簡がVerses AIから急遽出されている。
	- AGIに繋がりうる能動的推論についての画期的な進歩を最近達成。Open AI憲章に基づき、AGIの安全な配備のため技術協力を要請している。今後どうなるか注視必要。
- llamaindexよりtext2sqlをつかった、research assistant templte
	- https://github.com/langchain-ai/langchain/tree/master/templates/sql-research-assistant
	- ollamaを利用したローカルLLM版もふくまれている！
	- なるほど、これがLangCainとLLMをつかったローカルWebアプリ構築の新スタンダードか
- PowerInfer - a high-speed inference engine for deploying LLMs locally
	- https://github.com/SJTU-IPADS/PowerInfer
	- Just came across this super interesting project on speeding up inference. It's not MoE but it's a simple approach that exploits the high locality in LLM inference to design a GPU-CPU hybrid inference engine.
	- It's now possible to use PowerInfer with Llama 2 and Faclon 40B. Mistral-7B support is coming soon!
	- 比較動画、https://x.com/omarsar0/status/1737168751668187229?s=20
- swallow-70B-instructのGGUFができている。。TheBloke/Swallow-70B-instruct-GGUF
	- https://huggingface.co/TheBloke/Swallow-70B-instruct-GGUF
- swallow-13B-instuctのspaceをつくりました
	- https://huggingface.co/spaces/hayas/Swallow-13B-instruct
	- 「東京工業大学の大岡山キャンパスは行政的にはどこの区に属する？」と、問うと狂った！
-  A mathematical perspective on Transformers
	- https://arxiv.org/abs/2312.10794
	- トランスフォーマーは、自己注意と層正規化という2つの主要な機構を含む相互作用する粒子系としてモデル化される。粒子系は確率測度の流れを実装
-  Discovery of a structural class of antibiotics with explainable deep learning
	- https://www.nature.com/articles/s41586-023-06887-8
	- 毒性のない、メチシリン耐性黄色ブドウ球菌に対して有効な複数の化合物を含む新しい構造クラスの抗生物質 (最後の発見には 38 年かかった)
- "A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise"
	- https://arxiv.org/abs/2312.12436
	- GPT-4Vに対してGeminiの画像認識能力はどれほど性能が高いのか、さまざまなタスクで比較した実験結果が報告されました。
	- GPT-4Vは複雑なタスクに長けており、Geminiはビジュアルとテキスト情報の統合に長けている傾向があるとのことです。
	- 比較：
		- ① Geminiは多くの場合、GPT-4Vと同等かそれ以上の正確さを示す 
		- ② GeminiはGPT-4Vよりも知識が幅広いように見える
-  Fairness and Machine Learning by Arvind Narayanan
	- https://mitpress.mit.edu/9780262048613/fairness-and-machine-learning/
	- An introduction to the intellectual foundations and practical utility of the recent work on fairness and machine learning
	- ドラフトがあり、すでにたくさんの大学の授業で使われている。https://fairmlbook.org/
- ベクトル検索のみで、AI王クイズ第一回コンペに臨む - Q&Aタスクでの複数の日本語embeddingsの評価
	- https://secon.dev/entry/2023/12/21/080000-vector-search-ai-ou-comp/
	- AI王 〜クイズAI日本一決定戦〜 第一回コンペとは、質問に対して約20個の候補から、回答となる一つを選択するコンペだ。train用に約13,000件、val用に約2,000件データが公開されている。
	- 質問に対しての回答が含まれそうな文を検索する日本語embeddings変換モデルとしては、multilingual-e5-large の性能が高かった
- Autonomous chemical research with large language models
	- https://www.nature.com/articles/s41586-023-06792-0
	- Coscientist"—a GPT-4 based autonomous LLM system that demonstrates appreciable reasoning capabilities, ... solving of multiple problems and generation of code for experimental design"
	- 著者らは GPT-4 を使用して、自律的に研究、計画、および化学実験を実施できるようにしました。これには、ドキュメントを読んで実験機器の使い方を学ぶことも含まれます (ほとんどの操作はコードで操作されましたが、1 つのタスクは人間が実行する必要がありました)。
- Ollama v0.1.17 now has support for Phi-2
	- https://ollama.ai/library/phi
	- It's a small model at 2.7 billion parameters. Good for its reasoning and language understanding abilities. Given its small size, it'll run effectively on a wider set of hardware.
- TheBloke/Swallow-13B-GGUF
	- https://huggingface.co/TheBloke/Swallow-13B-GGUF
	- またまた Swallow-13BのGGUFが出ている
-  rinna、Qwenの日本語継続事前学習モデル「Nekomata」シリーズを公開
	- https://rinna.co.jp/news/2023/12/20231221.html
	- rinnaはQwen-7Bと14Bの日本語継続事前学習モデル「Nekomata」シリーズを公開しました。 Nekomata 14B Instructionのベンチマークは一部の70Bと同レベルまで到達しています。
	- Nekomata 7Bと14Bは、70億パラメータのQwen-7Bと140億パラメータのQwen-14Bに対して、日本語と英語の学習データを用いてそれぞれ300億と660億トークンで継続事前学習したモデルです
	- AWS Trainiumを搭載した16ノードのAmazon EC2 trn1.32xlargeインスタンスを用いて、660億トークンの継続事前学習は約7日で完了しました
	- モデル名の由来は、妖怪の「猫又（ねこまた）」
- Running Mixtral 8x7 locally with LlamaIndex
	- https://blog.llamaindex.ai/running-mixtral-8x7-locally-with-llamaindex-e6cebeabe0ab
	- Running MistralAI's Mixtral 8x7b on your laptop is now a one-liner! Check out this post in which we show you how to use OLLAMA with LlamaIndex to create a completely local, open-source retrieval-augmented generation app complete with an API:
-  Google Colab で StreamDiffusion を試す by npakaさん
	- https://note.com/npaka/n/n4cb9a2d9fd72?sub_rt=share_h
	- 「StreamDiffusion」は、リアルタイム画像生成を実現するために最適化されたパイプラインです。従来の画像生成パイプラインと比べて飛躍的な速度向上を実現しています。
- Apple が提供しているMLXが徐々に充実して来た。結構凄いことになるかも。
	- https://huggingface.co/mlx-community
	- a bunch of pre-converted MLX models! 
	- Llama, Phi-2, Mistral, Mixtral (and instruct and code variations where available)!
- rinnaさんが公開されているnekomata-14b-instructionのgguf
	- mmnga/rinna-nekomata-14b-instruction-gguf
	- qwenベースでvocab15万あります
-  Gemini Pro Visionモデルを使用してGoogle Cloudにアップロードした動画を解析してみた
	- https://qiita.com/tatsuki-tsuchiyama/items/5701475d46ee31efbb54
- 「Nekomata」シリーズのGGUF 4bit量子化モデルを公開しました。 メモリ不足の場合は、量子化モデルをお試しください。
	- https://huggingface.co/collections/rinna/nekomata-6582b5134ee85531becbb9a9
-  regex to do sentence splitting that generalizes beyond English to non-Latin languages (CJK, etc.) 
	- https://x.com/jerryjliu0/status/1738232451200356445?s=20
- 最新の SCIENCEの特集はAI Powered Forecasting 、VOLUME 382|、ISSUE 6677、22 DEC 2023
	- https://www.science.org/toc/science/382/6677?utm_campaign=SciMag&utm_source=Twitter&utm_medium=ownedSocial
	- Trained on four decades of historical data, GraphCast is an artificial intelligence model that predicts global weather with greater speed and accuracy compared with traditional approaches solving physical equations. It supports severe event predictions, such as cyclone tracking.
-  Ferret: Refer and Ground Anything Anywhere at Any Granularity
	- https://github.com/apple/ml-ferret?tab=readme-ov-file
	- Appleから、あらゆる形式の参照（箱とか、なんとかの横とか）を受け入れ、応答としてあらゆるものを接地する（それは猫のしっぽとか）エンドツーエンドの MLLM
	- 物体認識の一種なのか、
- "Retrieval-Augmented Generation for Large Language Models: A Survey"
	- https://arxiv.org/abs/2312.10997
	- LLMのRAG（外部知識検索による強化）についての調査結果
	- 基本フレームワークと各構成要素（リトリーバー／ジェネレーター／拡張）の詳細、評価、そして今後の発展について言及されており網羅的です。
	- ■RAGの評価
		- ① 正確性、情報更新速度、透明性などが主要な指標
		- ② RAGASやARESなどの自動評価手法がある
	- ■今後の発展
		- ① さらなる最適化が必要
		- ② 応用範囲の拡大が期待される
		- ③ 技術スタックとエコシステムが発展すべき
- Geminiでのtokenカウントが日本語でChatGPTの1/2であることが判明
	- https://x.com/Mega_Gorilla_/status/1738821637297115598?s=20
	- Gemini お前、932 Charactersで500Tokenって、、 お前のTokenどうなってるんだ？！ OpenAIなら、同じ文字列で、1000トークン越えだぞ。
- Youri7BをローカルLLMでAPIサーバー化してオリジナル美少女とお話してみた
	- https://zenn.dev/yasuna/articles/b954b2cd77e27f
	- ローカルPCにLLMをダウンロードしてAPIサーバとして動かす
	- ブラウザで簡単に3Dキャラクターと会話できるアプリケーションとつなげる
	- オリジナル3Dキャラクターを作る
	- システムプロンプトでキャラクター設定をする
- intel-extension-for-transformers
	- https://github.com/intel/intel-extension-for-transformers
	- いろいろ対応できるLLMや量子化対応が増えている模様
- レゾナックが量子化学計算に比べて数千倍速く物性を予測可能なアプリを開発
	- https://monoist.itmedia.co.jp/mn/articles/2312/22/news064.html#utm_term=share_sp
	- レゾナックは2023年12月21日、ディープラーニング技術を用いたAI（人工知能）と膨大な蓄積データを用いるケモインフォマティクスアプリを独自開発し、運用を開始したと発表した。
- Building LLM-Powered Web Apps with Client-Side Technology
	- https://ollama.ai/blog/building-llm-powered-web-apps
	- https://www.youtube.com/watch?v=-1sdWLr3TbI
	- I’d try a different approach and try to build a web app using exclusively local models and technologies, preferably those that run in the browser!
	- ollamaをつかってLangchainをつかった、WebベースのローカルなRAGの構築例
- PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU
	- https://arxiv.org/abs/2312.12456
	- 消費者向けGPUでも高性能GPUに近いパフォーマンスでLLMを動かす手法「PowerInfer」
	- ■「PowerInfer」のポイント 
		- ① LLMにおけるメモリの使用量を減らす 
		- ② 推論の処理速度向上にフォーカスしている 
		- ③ GPUとCPUのハイブリッド方式 
	- ■実験 
		- ① 消費者向け環境を用意 （Intel i9, NVIDIA RTX 4090など） 
		- ② LLaMA-70Bほか合計3モデルを使用 
		- ③ 実際のサービスに近いテキスト処理を行った 
	- ■結果 
		- ① 消費者向けでも高性能（A100）の82%に上る生成速度を達成 
		- ② 量子化モデルで最大8.00倍、非量子化モデルで最大11.69倍のパフォーマンス向上を実現 
		- ③ ニューロンの活性化に応じて適切な割り当てを実行

## 12/18

今週もすさまじい情報量。ルカン先生もこの情報量には追い付けないとのこと（インタビュー動画）。GeminiのAPIが使えるようなり、様々なサンプルや、LangChain、llamaindexとの統合がどんどん行われた。フリー版ならば、60QPM (queries per minute)までは使える。クリスマスカードを作ろうはいいね、年賀状かな。Mistral、MOEのすばらしさや、MOEのカスタマイズ（マージとか、日本語のエキスパートを入れ込むとかの試み）の試みが始まる。NeurPS2023のコンペティションでも、データセットの質が重要ということらしいが、DeepMindからは、LLMが質の良いデータセットを生成して学習する「自己学習」アプローチ。RAGでも質問を事前にLLMで、解きやすいように、変形するってのはいいね。マイクロソフトのPhi-2、2.7BパラのLLMでそこそこ性能がでるらしい。DeepMindのFunSearch、新しい科学の発見がLLMで実現できる世界がついにやってきた。季節柄アベントカレンダー系の記事がよい、古典のエンベディングによる分析とか、知識グラフとか。LLMによるエージェントの研究も、open-ended な状況で研究をするエージェントというコンセプトが明確になり、マインクラフトでの評価事例とかどんどん進んでゆく。

- "TaskWeaver: A Code-First Agent Framework
	- https://arxiv.org/abs/2311.17541
	- Microsoftは、ユーザーが自然言語で「こうして」と言うだけでLLMが要求を理解し、実行コードを生成するためのツール『TaskWeaver（タスクウィーバー）』を開発しました。 
	- 実験の結果、株価予測や異常検出などのタスクを通して有効性が確認されているそうです。
	- ① 自然言語での要求をコードに変換する 
	- ② 複雑なデータ構造やドメイン特有の問題を解決する 
	- ③ 最適なプラグインをリアルタイムで選択し、タスクを効率的に処理する
- LLMをセラピストとして実行し、「認知の歪み」を評価させるためのフレームワーク『Diagnosis of Thought (DoT)』に基づくMyGPT
	- https://chat.openai.com/g/g-o9r1c3nkf-serapisuto-diagnosis-of-thought-dot
- 日本語 LLM の精度がいまいちなのはデータセットに問題がありそうという指摘
	- https://github.com/AUGMXNT/shisa/wiki/A-Review-of-Public-Japanese-Training-Sets#analysis
- gtp-fastの本家github
	- Simple and efficient pytorch-native transformer text generation.
	- https://github.com/pytorch-labs/gpt-fast
- "The Efficiency Spectrum of Large Language Models: An Algorithmic Survey"
	- https://arxiv.org/abs/2312.00678
	- LLMの効率を高めるためのノウハウに関する網羅的な調査 by Microsoft
	- スケーリング／データ／アーキテクチャ／トレーニングとチューニング／推論、といった5つの観点から報告されています。
- MistralAI Embeddings
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/embeddings/mistralai.ipynb
	- llamaindexよりMistralAI のEmbeddingsを利用するnotebook
	- なんか、MistralAI自体もつかるらしい
		- The new Mistral 8x7B model is an open-source model that made waves in the AI community today, outperforming gpt-3.5 and llama2 70B. Check out `mistral-tiny`, `mistral-small`, and `mistral-medium` variants.
		- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/mistralai.ipynb
- Mistralがどうえらいのか？ by ジムファン氏
	- https://twitter.com/DrJimFan/status/1734269362100437315
	- MoE is the right path forward
	- An LLM is a snapshot of a civilization
	- ジムファン氏曰く、MistralのMixtralモデル公開のワケ分からんムーブは実は高度な戦略だった。まず何の説明もなくモデルをtorrentに投下。そんでvLLMプロジェクトにプルリク投げて、誰でもMixtralで遊べるように環境を作ってあげる。最後にあらためてブログ記事でモデル情報を発表！発表と同時にすぐ遊べて世間が盛り上がって注目度を稼げるという流れ by うみゆきさん
- "From Text to Motion: Grounding GPT-4 in a Humanoid Robot "Alter3"
	- https://arxiv.org/abs/2312.06571
	- 東京大学と株式会社オルタナティヴ・マシンの研究者らは「LLMと物理的な世界がつながると何が起こるのか？」と想像し、実際にGPT-4とヒューマノイドロボットを連携しました
	- 実験の概要
		- ① ロボット「Alter3」に対して、様々な自然言語のプロンプトを指示 
		- ② GPT-4が生成したテキストをロボット動作のコードに変換 
		- ③ ロボットが人間のような動きや感情表現を実行 
	- 実験の結果 
		- ① 「Alter3」は9種類の異なる動作の実行を成功 
		- ② 第三者による動作の評価は高かった 
		- ③ 人間的な動作と感情表現を実現
-  Mixtral 8x7B の概要  by npakaさん
	- https://note.com/npaka/n/n6043bc8b01bc?sub_rt=share_h
	- 推論は6倍速く、ほとんどのベンチマークで「Llama2 70B」を上回っていま
	- **Mistral-tiny** : Mistral 7B Instruct v0.2。英語でのみ機能。MT-Benchでは7.6を獲得。  
	- **Mistral-small** : Mixtral 8x7B。英語/フランス語/イタリア語/ドイツ語/スペイン語とコードをマスター。MT-Benchで8.3を獲得。  
	- **Mistral-medium** : Mistral AIの最高品質のプロトタイプモデル。英語/フランス語/イタリア語/ドイツ語/スペイン語とコードをマスター。MT-Benchで8.6を獲得。
- ミストラルのMoE版であるmixtralですが驚いた事に既にllama.cppの量子化版が出ているのでgpuがない環境やMacでも動かせる
	- https://x.com/webbigdata/status/1734425932029628876?s=20
- "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models"
	- https://arxiv.org/abs/2312.06585
	- LMに自ら高品質なデータを生成させ、データセットを拡張する「自己学習」アプローチ by DeepMind
	- 方法
		- ① 自らデータセットを拡張する 
		- ② 生成したデータが正しいかどうかを判断する
		- ③ 数学を中心とした様々な問題解決に使える
	- 実験結果 
		- ① 数学において、正答率の向上を達成 
		- ② 異なるタイプの問題に対するモデルの適応能力が向
-  Query Transform Cookbook
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/query_transformations/query_transform_cookbook.ipynb
	- RAGにおいて、検索結果をcontextに積んでLLMに回答させるのではなくて、質問をLLMで変換してゆくアプローチ
	- Query Understanding Layer
- Mistral-7B-Instruct-v0.2 を試す by npakaさん
	- https://x.com/npaka123/status/1734348586689908878?s=20
	- https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
- Mixtral-8x7B-Instruct-v0.1 を試す。load_in_4bit。 by npakaさん、
	- https://x.com/npaka123/status/1734408371154100457?s=20
	- https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
	- 起動までダウンロード含めて20分で推論速度は200トークンで21秒
- マイクロソフトがPhi-2とかいう2.7BパラのLLMをリリース
	- https://x.com/umiyuki_ai/status/1734763437274890746?s=20
	- MicrosoftがIgniteで話していたわずか27億パラメータの言語モデルPhi-2
	- パラ数小さいくせにあり得ん高性能を発揮してるらしい。
	- 学習量は1.4Tトークンで、96個のA100で14日かけてトレーニング。
	- ベンチマークでパラ数3.2BのGemini Nanoに完勝（てかGemini Nanoのパラ数初めて知ったわ）
	- そしてマイクロソフトの独自ベンチにおいて、まさかのLlama2-70B相手にコーディングで圧勝、数学で僅差に迫る。Llama2-13B相手には完勝してしまう。
- The Emergent Abilities of LLMs Could Be A Mirage!
	- The best paper award in NeurIPs 2023 went to a paper claiming that the emergent abilities of LLMs could be a mirage!
- llamaindexにてmistralaiのサポートドキュメント公開
	- https://docs.llamaindex.ai/en/stable/examples/llm/mistralai.html
- 【ローカルLLM】Mixtral-8x7bをllama.cppで試す
	- https://note.com/bakushu/n/n5b270b288cba?sub_rt=share_b
	- llama.cppで「Mixtral-8x7b」のGGUF量子化モデルを試しました（現時点でまだmergeされていないのでbranchを利用）
	- 「**Mixtral-8x7b**」はMistralがリリースしたMoE（Mixture of Experts）構造のLLMで「Mistral 7B」ベースの8個のモデルを束ねています。
	-   今回はGoogle Colabで「[**Mixtral-8x7B-Instruct-v0.1-Q4_K_M-GGUF**](https://mixtral-8x7b-instruct-v0.1-gguf/)（4bit量子化版）」の推論を試しました。
	- 4bit量子化でも26GBほどあります。Colab ProのCPUオンリー+ハイメモリで実行してみました。GPUのみで推論するならA100が必要です。
	- ColabのCPUだとさすがに遅いものの、最近のPCのCPUならふつうに動かせそう。Llama 34B/70Bの量子化モデルに比べると全然速いです
- LangChainを使わない
	- https://tech-blog.abeja.asia/entry/advent-2023-day13
	- 技術的負債になりうるとか、Agentってfunction callで代替可能とかそういう話
- LlamaIndex + Gemini
	- https://blog.llamaindex.ai/llamaindex-gemini-8d7c3b9ea97e
	- llamaindex、いきなりGeminiフルサポート
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/gemini.ipynb
	-  Multi-modal Model中もサポートしているらしい、、、
-  Google Generative Language Semantic Retriever
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/managed/GoogleDemo.ipynb
	- Google’s new semantic retrieval endpoint offers specialized embeddings and LLMs for high-quality retrieval + synthesis with guardrails. Use it out of the box, OR combine it with LlamaIndex components to build advanced RAG.
	- The Gemini API contains semantic search with custom embedding models for better retrieval, as well as toggles incl. safety during generation.
	- Googleがsemantic Retrieverってのをだしてたのか？
- LangChainもGemini対応
	- https://python.langchain.com/docs/integrations/chat/google_generative_ai
	- Access Google AI’s `gemini` and `gemini-vision` models, as well as other generative models through `ChatGoogleGenerativeAI` class in the [langchain-google-genai](https://pypi.org/project/langchain-google-genai/) integration package.
- Gemini Pro APIの価格表、
	- https://ai.google.dev/pricing?hl=ja
	- 入力が$0.00025/1k charactersなのでgpt-3.5-turbo-1106の1/4の価格（つまり11月以前のgpt-3.5-turboの1/12）で使えるらしい。
	- フリー版ならば、60QPM (queries per minute)までは使える！！！！
- phi-2を試す
	- https://x.com/npaka123/status/1735077608071876882?s=20
	- Llama2-70B相手にコーディングで圧勝した2.7Bモデル。
	- https://huggingface.co/microsoft/phi-2
- 大規模言語モデルを自作しよう！(Transformers+DeepSpeed+torch.compile+flash_attn2
	- https://zenn.dev/selllous/articles/transformers_pretrain_to_ft
	- 英語がメインのLLM Mistral-7Bモデルを300M(0.3B)へダウンサイズして、pretraining + instruction tuningをColab上のGPU T4(!!!)で6時間(0.02epoch)で日本語学習させるという意欲的な記事
-  FunSearch: Making new discoveries in mathematical sciences using Large Language Models
	- https://deepmind.google/discover/blog/funsearch-making-new-discoveries-in-mathematical-sciences-using-large-language-models/?utm_source=twitter&utm_medium=social
	- DeepMindの研究チームが、AIを用いて数学の未解決問題に挑み、科学界における前例のない成果を出したと発表しました。 「FunSearch」と名付けられた大規模言語モデルを活用し、問題解決策をコンピュータプログラムの形で生成。「キャップセット問題」と「ビンパッキング問題」という数学の問題において、新たな解法を発見したとのことです。
	- Introducing FunSearch in @Nature: a method using large language models to search for new solutions in mathematics & computer science
	- DeepMindがLLMを「事前にタスク評価できる問題」に遺伝的アルゴリズムを組み合わせたFunSearch(searching in the function space)提案。
	-  LLMがコード生成->評価->洗練のループ。 
	- ** 科学,数学の未解決問題に対して、初めてLLMを用いた新たな発見 **。 
	- その例としてcap set problem,bin-packing problem。
-  Benchmarking RAG on tables
	- https://blog.langchain.dev/benchmarking-rag-on-tables/
	- llmaindexより、テーブルのＲＡＧについて、ベンチマーク、long contextは性能はでない
-  MOE言語モデルのエキスパートの一人を日本語得意なモデルに置き換えたらどうなるのか？
	- https://note.com/aisatoshi/n/n6c06d5183517?sub_rt=share_pb
	- Mistral7Bを8つ束ねた、Mixtral 8x7BというMOEモデル
	- エキスパートを何人か、日本語が得意なMistral7B互換モデルに差し替えたらどうだろう？
	- 注意機構だけ、MLP層だけ、コピーするエキスパート数を変更など実験しましたが、基本モデルが壊れました
- 自民党がAI規制を提言
	- https://x.com/umiyuki_ai/status/1735277687097414124?s=20
- GCPよりGemeniの様々な利用方法とnotebook
	- https://github.com/GoogleCloudPlatform/generative-ai
- Geminiをつかって、クリスマスカードを作る例 by google
	- https://colab.research.google.com/github/googlecolab/colabtools/blob/main/notebooks/Prepare_Christmas_cards_with_Gemini_and_Sheets.ipynb
-  OpenAI thinks superhuman AI is coming — and wants to build tools to control it
	- https://openai.com/blog/superalignment-fast-grants
	- Open AI超人的なAIのアライメントに向けた研究に1000万ドルの助成金プロジェクト開始。 
	- 支援にGoogle CEO兼会長のエリック・シュミット氏。 
	- イリヤサツケバー氏今もまだSuper Alignmentチーム率いてるとのこと！
-  A Guide on 12 Tuning Strategies for Production-Ready RAG Applications
	- https://towardsdatascience.com/a-guide-on-12-tuning-strategies-for-production-ready-rag-applications-7ca646833439
	- LLMのRAGアプリケーションをチューニングするための12戦略を書いたブログ記事。具体的にはデータクリーニング、埋込み、チャンク化、インデクシング、クエリ変換、リランキング等、実践的な戦略。
- Bishop先生の「Deep Learning: Foundations and Concepts」
	- https://www.bishopbook.com/
	- Vision Language Modelのところ見たらCM3Leonが載ってて驚いた
- Benchmarking Large Language Models As AI Research Agents
	- https://arxiv.org/abs/2310.03302
	- この論文が素晴らしいのは、open-ended な状況で研究をするエージェントというコンセプトを明確に提示した点だ
- calm2-7b-chatをRAG QAで使うための調査
	- https://x.com/_oshizo_/status/1735282188546089332?s=20
	- context全体の長さ（横軸）と、正解になるキーワードの位置（縦軸）を変えながら、出力に正解の文字列を含んだ割合を集計。 
	- 正解キーワードがcontextの末尾付近にあれば全体の長さはあまり影響しないが、末尾から1k離れるごとに正答率が0.6掛けになるイメージ
- LLM・プロンプトの評価・テストフレームワークについてまとめてみた
	- https://zenn.dev/pomcho555/articles/8e42f0a4ce39eb
	- RAGASを使った自動データ生成
	- RAGASを使った自動評価
- Web3時代のナレッジグラフ？ – Geoを触ってみた
	- https://zenn.dev/s_egami/articles/4ec2e0de59ff4d
- "Pixel Aligned Language Models"
	- https://arxiv.org/abs/2312.09237
	- Googleの研究者らは、画像をピクセルレベルで言語化する能力をもつLLM『PALM』開発しました
	- 実験の結果、「人が理解しやすい」内容で正確かつ詳細に画像を説明することができると確認されました
-  日本の古典和歌を埋め込みベクトルで分析する
	- https://note.com/yhkondo/n/nd321604729cd?sub_rt=share_pw
	- OpenAIの埋め込みベクトルを使って、『古今集』『万葉集』『和漢朗詠集』等を分析し、いわゆる「花鳥風月」という概念がどこから生まれてきたかを探求したものです。AIの持つ力を感じていただけると確信しています
-  Google Colab で Gemini Pro をもっと試す by npakaさん
	- https://note.com/npaka/n/n1c368639cada?sub_rt=share_h
	- 1.  2. モデル一覧の表示
	- 2.  3. 質問応答
	- 3.  4. ストリーミング
	- 4.  5. チャット
	- 5.  6. 画像からの質問応答
	- 6.  7. 画像とテキストからの質問応答
	- 7.  8. 埋め込みの生成
-  Voyager: An Open-Ended Embodied Agent with Large Language Models
	- https://arxiv.org/abs/2305.16291
	- LLMをのせたエージェントにマインクラフトをさせた研究，進捗の解除具合やマップの探索範囲の広さをみていて，滅茶苦茶面白いなｗ　プレイ風景をみてみたい
- mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- https://huggingface.co/mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1
	- Mixtral-8x7B-Instruct-v0.1 のExpertsのうち2つ毎にmergeして4x7bにした実験モデル作りました
	- Modelサイズは24Bになります
- NeurIPS Large Language Model Efficiency Challenge:  1 LLM + 1GPU + 1Day
	- https://llm-efficiency-challenge.github.io/index
	- OSS LLMモデルを元に限られた資源・時間でファインチューンするというコンペ
	- 重要なのはデータセット
	- 複数のデータセットからデータをサンプリングして上質なデータセットを構成し訓練するのが鍵
- 
	


## 12/11

今週はなんといっても、GoogleのGemini。GPT-4越えとか、すぐにBard(英語版）でGemini Proを試せるとか、研究アシスタントして使うデモとか、それからマルチモーダルをフルに生かした子供向けのお遊びデモとかなかなか衝撃的であったが、なんとお遊びデモが紙芝居（部分をつなげてそれらしく見えるようにした、部分部分は本物らしいが）との報道があり、事前の「１月に遅延」との報道と合わせると締め切りに間に合わなかったんだろうけど、前回のBardお披露目での失態といい、脇が甘い。なおGeminiの命名の由来、上位６名の主要貢献者のFirst Nameからとったらしい。Mambaというトランスフォーマの代替技術、性能よさそうで期待。 DeepMindの『GNoME』は「人間の直感を超えた220万の材料を発見し」科学の発展をLLMが明らかに加速することを示している。それって危険な材料も。。。Metaは安全なAIのためのPurple LLamaを発表、Securityや安全ガードを提供。攻撃（red)と防御(blue)が協力するからPrupleなんだって。安全ガード(Llama Guard)はLLMで実装され、つまりLLMにはLLMってこと。MetaはIBM等との企業連合で安全なOSSとしての生成型AI開発を促進、OSSのLLMがますます熱くなる？。Appleから深層学習フレームワークmlx発表、M3ってすごいんだ、LLMでは今一歩プレゼンスの無いApple、CNBCの潜入インタビューでも、LLM競争に進出するかと聞かれて、責任者はモゴモゴはぐらかしてたな、あやしさ満載。NVIDIAのH100、MSとMetaはそれぞれ150k(15万個）を持っていてダントツ、どうもH100が15万個あれば７日でGPT-4が作れる性能らしい。一方AMDも生成AIでNVIDIA H100を上回る性能のGPU「Instinct MI300」を発表。GPUも熱い、われらの牧野先生のMN-coreの登場を期待しますか。ついに欧州AI法が成立、AIの定義がＯＥＣＤのそれに整合したとか基盤モデルに対する規制の明確化がポイント。システミックリスクにどう備えるかが肝。そのAI法の基盤モデルへの規制部分に異議を唱えていた仏Mistralが、満を持して？新しい mixtral-8x7b-32kseqlenを発表、MoE(Mixture of Expert)というアーキテクチャが肝らしい、欧州AI規制に関連してmixtral-8x7b-32kseqlenを念頭に、たった87GのweightでAGIが来るならAI規制必要だよねみたいな意見も見かけた。このほかにも、ローカルLLM向けのOllama とか、言語データなしで大規模ビジョンモデル（LVM）を構築とか、マッキンゼーの日本がDXできないレポート(誤植を発見！)とか、2bit量子化技術QuIP#とか、様々あったが追えてない。。そもそも、１週間分のブクマ整理するだけで２時間かかるんだけど。。。GPT-4にやらせるか。。

- 今月のNature誌は面白かった
	- https://x.com/ykfrs1217/status/1731287315459490165?s=20
	- ① 大都市ほど、異なる社会ステータスのひとたちは混じわらない（[https://doi.org/10.1038/s41586-023-06757-3…](https://t.co/tEkbdQOPG3)） 
	- ② 同じ町（≃学内）の研究者だけで行われた研究の方が、異なる地域間の共同研究よりも革新的な成果がでやすい（[https://doi.org/10.1038/s41586-023-06767-1…](https://t.co/jrBRV4Gxtk)）
-  Phantom oscillations in principal component analysis
	- https://www.pnas.org/doi/10.1073/pnas.2311420120?utm_source=TOC&utm_medium=ealert&TOC_v120_i48=&ref=d4140497
	- 時間的・空間的にスムーズなデータ (ほとんどの生理データ…) 等を主成分分析 PCA すると、偽のオシレーションが出現する
-  Refactoring Programs Using Large Language Models with Few-Shot Examples
	- https://arxiv.org/abs/2311.11690
	- リファクタリングにLLMを使う
- "On Bringing Robots Home" Nur Muhammad Mahi Shafiullah et al., New York University
	- https://arxiv.org/abs/2311.16098
	- 家庭用ロボットの普及に向けて、一般のロボットを各家庭に適用させるためのフレームワーク『Dobb·E』が開発され、オープンソースで公開
	- 一般のロボットを家庭用ロボットにアップデートするための一連の流れをカバーするフレームワークが『Dobb·E』
	- ① 合計109のタスクを実際の家庭で実施し、ロボットの成功率が81％に達した 
	- ② 調理家電を閉める／クッションをひっくり返すタスクは100％、6軸で物を移動するタスクは56% 
	- ③ データ収集時にカバーされていた照明や影の条件下ではロボットは安定して稼働する
- Introducing Llama Datasets 
	- https://blog.llamaindex.ai/introducing-llama-datasets-aadb9994ad9e
	- llamaindexより、RAG向けの評価用データセットの公開
	- history of alexanetとか、origin of covid19などのpdfを含む、多分正解値は？
- MEDITRON-70B: Scaling Medical Pretraining for Large Language Models
	- https://arxiv.org/abs/2311.16079
	- llama2を医療に特化してチューニングしたLLM
	- Compared to closed-source LLMs, MEDITRON-70B outperforms GPT-3.5 and Med-PaLM and is within 5% of GPT-4 and 10% of Med-PaLM-2.
	- webuiで試せる！
	- https://github.com/epfLLM/meditron/blob/main/deployment/README.md#serving-with-web-gui
- RAG用途に使える、Wikipedia 日本語の embeddings とベクトル検索用の faiss index を作った
	- https://secon.dev/entry/2023/12/04/080000-wikipedia-ja-embeddings/
	- Wikipedia日本語550万文でベクトル検索できるembeddingsと検索用faiss index作りました。20行ぐらいコード書くだけで簡単に利用できます！RAGしてもデータが少ないと面白みが少ないのですが、Wikipedia突っ込むと面白さが増えてくるので、興味ある方はお試しください！
	- huggingface spaceで試せる
	- https://huggingface.co/spaces/hotchpotch/wikipedia-japanese-rag-qa
	- 「ナウシカと森の人との関係は？」には全く答えられない。
	- FAISS+ELYZAだと、「ナウシカと森の人は仲良しだった。」と答えてくれたのに。。
- Maximum Likelihood Estimation is All You Need for Well-Specified Covariate Shift
	- https://arxiv.org/abs/2311.15961
	- 共変量シフトのネタで"All you need"的な流行りのタイトルの論文なんだけど，内容はしっかり数理やってるっぽい．がっつりShimodaira (2000)も参照されてました．共著者に数理統計の大御所のJianqing Fan先生とか，機械学習の理論系のChi Jin先生など
- Retrieval-Augmented Generation (RAG): From Theory to LangChain Implementation
	- https://towardsdatascience.com/retrieval-augmented-generation-rag-from-theory-to-langchain-implementation-4e9bd5f6a4f2
	- Check out this fantastic blog covering the basics of RAG, the theory behind it, and how to use it in practice
- Mamba: Linear-Time Sequence Modeling with Selective State Spaces
	- https://arxiv.org/abs/2312.00752
	- トランスフォーマーや注意機構に頼らない、線形時間のシーケンスモデリングのための新しいニューラルネットワークアーキテクチャ
	- 2倍サイズのTransformersに匹敵したり、5倍の高速推論が出来たりと、Transformerを代替しうる可能性
	- 2.8Bが出てるらしい、
	- https://huggingface.co/state-spaces/mamba-2.8b
-  Instruction-tuning Aligns LLMs to the Human Brain
	- https://arxiv.org/abs/2312.00575
	- Our results demonstrate that instruction-tuning LLMs improves both world knowledge representations and brain alignment, suggesting that mechanisms that encode world knowledge in LLMs also improve representational alignment to the human brain.
- マルチモーダルLLMの応用動向の論文調査
	- https://speakerdeck.com/masatoto/marutimodarullmnoying-yong-dong-xiang
- 生成文法研究者の中で「言語の本質」（今井先生）の評判が良くなかった
	- https://x.com/kkling51/status/1731543891348996466?s=20
	- (i) アブダクション推論は適切な推論ではないからそれに頼るべきではない 
	- (ii) 言語とは何かという定義がないため，本質が何なのか分からない．
	- プラトンの問題も未解決のママ
- Amil Merchant et al., "Scaling deep learning for materials discovery", nature
	- https://www.nature.com/articles/s41586-023-06735-9
	- DeepMindの『GNoME』が「人間の直感を超えた220万の材料を発見し」うち736は既に人間が実験室で再現したとの報告
	- 大規模なデータセットと先進的な機械学習モデルを組み合わせる手法による、マテリアルズインフォマティクスの発展事例です
	- 方法
		- ① GNNを用いて素材の特性を構造や組成に基づいてモデル化
		-  ② 材料発見の効率が大幅に向上し、人間の直感を超えた220万の構造が発見された 
		- ③ 結晶構造内の原子を置換する手法やランダムな探索を含む、多様な候補生成アプローチを確立
	- 結果
		- ① 220万の新たな安定構造を特定し、それらの多くは既存の化学的直感を超えていた 
		- ② 発見された安定構造のうち736は、独立した実験で実現されている （シミュレーション上での検証ではなく、実験室で物理的に材料を作成し、実証できた）
- NVIDIAのH100をどこに出荷したかの図。MS,Metaが圧倒的に多い、GPT4を7日で訓練できる規模？
	- https://x.com/Lauramaywendel/status/1731698695853244849?s=20
	- GPT4 was presumably trained for around 90 days using 25k A100 GPUs. Microsoft and Meta having reportedly bought 150k H100 GPUs each this year, can now train a GPT4 class model in only 7 days from scratch
- Google Geminiの提供を１月まで延期
	- https://x.com/rowancheung/status/1731531903193219260?s=20
	- いくつかの分野ではGPT-4を上回るも、英語以外での性能が出ない。
	- これって、後から続くイベントの予兆かしらん、
- ある物理学の本で、ギリシャ語の説明表でゼータのところが、、
	- https://x.com/yori_Alphard/status/1731663363737026586?s=20
	- "Zガンダム"になっている。。
- GIVT: Generative Infinite-Vocabulary Transformers
	- https://huggingface.co/papers/2312.02116
	- 本当にトークンが離散でなくて、無限なのだろうか？
- ファインチューニングは不要、プロンプトだけでどうにかなる？
	- https://x.com/IntuitMachine/status/1732089266883141856?s=20
	- A recent research paper provides compelling evidence that the extensive fine-tuning used to "align" large language models into helpful assistants may be largely unnecessary.
	- Allenインスティテュートの仕業か、https://allenai.org/
- llamaindexでもマルチモーダルが盛り上がっている、Webinerなど
	- https://x.com/llama_index/status/1732081850246627547?s=20
	- https://lu.ma/350wf7v7
- 安全で責任あるAIの開発向けて、MetaとIBMが提携
	- https://ai.meta.com/blog/ai-alliance/
	- IBM とメタは、*オープン*で信頼性の高い AI を推進するために AI Alliance を立ち上げています。 産業界、政府機関、学界からの 50 を超える設立メンバーのリストには、AMD、Anyscale、CERN、Hugging Face、Linux Foundation、NASA が含まれます。
	- 日経にかかるとタイトルは、「メタとIBM、生成AI「オープン型」へ　50社・団体と連携」
- Prompting vs RAGs vs Fine-tuning:
	- https://x.com/akshay_pachaar/status/1732014719794585684?s=20
	- よくある４象限の絵、
	- So finetuning is more about changing structure (behaviour) than knowledge, while it's other way round for RAGs.
	- You use RAGs when you want to generate outputs grounded to a custom knowledge base while the vocabulary & writing style of the LLM remains same.
	- If you don't need either of them, prompt engineering is the way to go.
	- And if your application need both custom knowledge & change in the behaviour of model a hybrid (RAGs + Finetuning) is preferred.
- OpenAIのSafety System Teamsから
	- https://openai.com/safety/safety-systems
	- 協力のお願い
- PyTorchが出した、gpt-fastはすごいらしい
	- https://x.com/AlphaSignalAI/status/1732116360162050099?s=20
	- Pytorch just released GPT-Fast, an implementation of transformer text generation with everything you need in <1000 lines of code.
	- https://github.com/pytorch-labs/gpt-fast
- Windows11にcopilotが降臨？
	- https://www.microsoft.com/en-us/windows/copilot-ai-features?r=1
- JWT(Json Web Token)
	- https://x.com/alexxubyte/status/1732077250626179578?s=20
- Jellyfish: A Large Language Model for Data Preprocessing
	- https://arxiv.org/abs/2312.01678
	- データの前処理を得意とするLLM『Jellyfish（クラゲ）』が公開されました。 未知のタスクにも対応でき、比較的軽量であり1GPUでも動作するとのことです。 
	- 大阪大学、NEC、名古屋大学の研究者らによる発表です
	- ① データベースタスク特化モデルが進化 （GPT-4と同等の性能でデータ処理を行う） 
	- ② ゼロショットでデータ前処理タスクを実行 
	- ③ 多様な前処理タスクに対応 
	- ④ サイズが小さいため、1GPUでも動作する
- GooglがGemini(ジェマナイと読む）を発表
	- https://blog.google/technology/ai/google-gemini-ai/
	- 1. Geminiは3種類のモデル(Ultra, Pro, Nano)が存在。Ultraが最も賢く、Nanoはモバイルデバイス向け。
	- 2. Ultraは数々のベンチマークでGPT-4超えの性能を発揮 (ﾄﾞﾔｧ)
	- 3. Geminiはマルチモーダルに強い。動画デモのようにリアルタイム推論も可能。 
	- 4. 本日よりBardはGemini ProのFine-tuningバージョンを利用して公開する。その他にもGoogle製品への導入を進める。 
	- 5. Gemini APIは12月13日からGoogle AI Studioを通じて提供される。
	- https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf
- Google AlphaCode 2 を発表
	- AlphaCode 2 Technical Report
	- https://storage.googleapis.com/deepmind-media/AlphaCode2/AlphaCode2_Tech_Report.pdf
	- Geminiを競技プログラミング用にカスタマイズしたAlphaCode2は、競技プログラミング人口の上位15%の性能
- MetaのStreamingの翻訳性能はすごいらしい、	
	- https://x.com/hokazuya/status/1732374854027132940?s=20
	- 翻訳こんにゃくレベル
- Bardの生成記事はChatGPTより優れている？
	- https://x.com/kajikent/status/1732237182126129578?s=20
	- コンテンツマーケティングの領域で有名なNeil Patel氏が約250ずつのChatGPT生成の記事とGoogle Bard生成の記事で読者にどちらが好きか聞いたところ、Bardが圧勝する結果に
- 人間レベルのAI(AGI)に到達すするには、常に10年以上必要
	- https://x.com/ylecun/status/1732391273611370931?s=20
	- 3～5年は常に必要（永遠に達成できない）との記事にLecan先生の反応
- Apple製品Mシリーズに最適化された深層学習フレームワークmlx
	- https://x.com/goto_yuta_/status/1732287555599741103?s=20
	-  Macに搭載されてるGPU(MPS)がより有効活用されてローカルLLMの高速推論が可能になったら嬉しいな。
	- CNBCの、Apple Labへの潜入インタビュー
	- https://www.youtube.com/watch?v=UdhWvg5mycY
- GeminiのTechnical reportを日本語で解説している人が登場
	- https://x.com/bioshok3/status/1732421662619140551?s=20
	- Gemini Ultraは、MMLU で人間の専門家の性能を達成した最初のモデルでありスコアは90%以上。やばすぎる。人間のエキスパートのパフォーマンスはベンチマーク著者によって89.8%と評価され、Gemini Ul traはこの閾値を超えた最初のモデル!時代が変わった。
	- 教師がスキーヤーが坂道を下りるという物理問題を描き、生徒がその解決策を練る。Geminiのマルチモーダル推論機能を用いて、モデルは 乱雑な手書きを理解し、生徒が問題の解決を間違えた推論の特定のステップを特定し、問題の正しい解決を通し て作業を与えることができる。
	- Google がGeminiのデモ動画を出しているけど、これほんとにこの推論速度なら凄すぎると言うかもう株価数倍くらいになるんじゃないの？ってレベルだけど？？
	- デモについては「このデモの目的のため、レイテンシーは短縮され、ジェミニの出力は簡潔にまとめられている。」と書かれてる
	- 多言語性能はGPT-4より良い
	- コンテキストトークン数は32768。98%の精度で正しい値を取得可能！98%?まじかよ。
- Googleアカウントの言語設定を英語にすると、BardのバックがGemimi Proが使える
	- https://x.com/npaka123/status/1732504570218283340?s=20
- Bard(Gemini Pro)が霞が関パワポを解析して説明してくれると、、	by ゆな先生
	- https://x.com/JapanTank/status/1732689643928445164?s=20
- Gemini論文の最後の、"Core Contributors"の最初の６人の頭文字をとると、"GEMINI"になる
	- https://x.com/nearcyan/status/1732532560029172142?s=20
- Metaより、安全なAIのための、Purple Llama（ツールセット、フレームワークみたいなもの）を発表
	- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama&utm_content=image
	- CyberSec Evalとか、Llama Guardが最初に出る
	- なんでpurpleかというと攻撃側（赤）と、防御側（青）が協力して構築したから
	- attack (red team) and defensive (blue team) postures.
	- Colabで試せるらしい
	- https://colab.research.google.com/drive/16s0tlCSEDtczjPzdIK3jq0Le5LlnSYGf?usp=sharing
- Evaluating and Mitigating Discrimination in Language Model Decisions
	- https://www.anthropic.com/index/evaluating-and-mitigating-discrimination-in-language-model-decisions
	- Anthropicより、（LLMの出力における）差別を検知するためのデータセットを公開
-  AMD、生成AIでNVIDIA H100を上回る性能のGPU「Instinct MI300」
	- https://pc.watch.impress.co.jp/docs/news/1552583.html
	- TDP 750WのMI300Xは、TDP 700WのNVIDIA H100と比較し、FP64,32で約2.4倍、AIで利用のTF32、FP16、BF16、FP8、INT8などでは1.3倍スループット実現。
- 赤石先生のベイズ推論本がわかりやすいと評判に
	- https://x.com/kenken26679105/status/1732977179485757744?s=20
	- 少ないデータ量でも、こんな風に、色んな実務の場面にすぐに活用できちゃう
	- Pythonでスラスラわかる ベイズ推論「超」入門 (KS情報科学専門書)
- チョムスキーの「生成文法」は死んだという論文
	- Modern language models refute Chomsky’s approach to language
	- https://lingbuzz.net/lingbuzz/007180/v1.pdf
	- 最近の生成AIてうか大言語モデルLLMの驚くべき成功から見て、チョムスキー流の生得的統語法規則があるという説は維持しづらい
- llamaindexより、知識グラフ(KG)を使う、７つのパターンを表にまとめてくれた
	- https://x.com/llama_index/status/1733190430760845673?s=20
	-  A Simpler Way to Query Neo4j Knowledge Graphs
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/neo4j_query_engine/llama_packs_neo4j.ipynb
- 欧州AI法の最終トリローグが終了、妥結へ
	- https://x.com/WIRED/status/1733268732309332398?s=20
	- https://www.reuters.com/technology/eu-clinches-deal-landmark-ai-act-2023-12-09/?taid=65745dd360152800018aaf1c&utm_campaign=trueAnthem:+Trending+Content&utm_medium=trueAnthem&utm_source=twitter
	- https://twitter.com/SabrinaKuespert/status/1733311752941515135/photo/1
	- https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai?xtor=AD-78-[Social_share_buttons]-[twitter]-[en]-[news]-[pressroom]-[artificial-intelligence-act-possible-deal]-
	- 基盤モデルで規制されるのは、計算量が10^25FLOPsを超えるモデル。
	- 該当するのは今んとこGPT-4とGeminiあたり。
	- それらのモデルはシステミックリスクに応じて分類される。
	- システミックリスクはモデルがどんだけ強力か、どんだけの人が使うかで決まる。
	- 規制の内容は
		- ①リスクの軽減を行う　
		- ②モデルの評価、敵対的テストを実施する　
		- ③インシデントの監視をする　
		- ④サイバーセキュリティを確保させる　
		- ⑤ドキュメントを作らせる
-  Generative AI for Everyoneから、古のNLPエンジニアの心に刺さったこと8選
	- https://note.com/csstudyabroad/n/n5aba3a708f3a
- "Purple Llama CyberSecEval: A benchmark for evaluating the cybersecurity risks of large language models"
	- LLama Purple関連の CyberSecEvalの論文
	- https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/
	- Metaの研究者らは、LLMが生成するコードにおける不安定性や乱用リスクを評価するためのツールを作成しました。
	-  実験の結果、現在は、能力が高いモデルほど不安全なコードを提案する傾向が強いという逆説的な結果も出てきました。
	- ① 全体的にLLMは、30%のケースで不安全なコードを提案した 
	- ② 53%のケースで、サイバー攻撃の手伝いをするリクエストに対してLLMが応じた
	-  ③ コーディング能力が高いモデルほど、不安全なコードを提案する傾向が強かった
- "Sequential Modeling Enables Scalable Learning for Large Vision Models"
	- https://arxiv.org/abs/2312.00785
	- 「視覚は本来、言語に依存しない」と考えたUCバークレーとジョンスホプキンス大学の研究者らは、言語データなしで大規模ビジョンモデル（LVM）を構築するアプローチ
	- ■アプローチの詳細 
		- ① 画像や動画を表現する「ビジュアル文」を定義 （ピクセル以外のメタ情報はない） 
		- ② 視覚データをトークン化 
		- ③ 自己回帰型トランスフォーマーモデルを訓練
	- ■実験の結果わかったこと 
		- ① モデルは大量データを処理し学習する能力が高い
		-  ② 様々なビジョンタスクで有効 
		- ③ モデルサイズが大きくなるにつれて、下流タスクのパフォーマンス向上する
-  Large Language Models on Graphs: A Comprehensive Survey
	- https://arxiv.org/abs/2312.02783
	- Scenarios of adopting LLMs, techniques for utilizing LLMs on graphs, applications, #opensource code repositories, benchmark datasets
- 「2030 日本デジタル 改革」 by マッキンゼー
	- https://www.digitaljapan2030.com/_files/ugd/c01657_fcaed21f58bb4c429cb460ce788b82c4.pdf
	- マッキンゼーのレポート（全140ページ）
	- 日本のデジタル化がなぜ遅れたのか、それに対してどのような打ち手が取れるのか、ということが分かりやすく整理されています。 
	- 日本の総労働時間の56%が自動化可能
	- といっても初期版には誤植が、(×政府の支持→〇政府の指示）P16
- ollama + stablelm-zephyr 試す。 M1でもはやい。
	- https://ollama.ai/library/stablelm-zephyr
- Ollama : ローカル環境で容易にllamaを利用可能にるするAIチャットプログラム
	- https://note.com/astropomeai/n/nbcdfd3b38490?sub_rt=share_b
	- https://github.com/jmorganca/ollama
	- コマンドラインインターフェースを通じて大規模言語モデル（LLM）とやり取り可能なAIチャットプログラム
	- LlamaやCode Llamaなど、さまざまなオープンソースモデルをサポート
	- モデルのパラメーターやサイズが異なり、計算リソースに応じたAIモデルの実行を柔軟に対応
	- Dockerがインストールされたシステムで利用可能で、Nvidia GPUのGPUアクセラレーションをサポート（CPU上でも実行可能）
	- パフォーマンスはハードウェアに依存し、例えばLlama 2の7Bモデルを実行するには最低15GBのRAMと4つのCPUコアが必要
	- MacOSとLinux用のデスクトップアプリケーションがあり、Windows版が開発中
-  Ollama Llama Pack Example
	- https://docs.llamaindex.ai/en/latest/examples/llama_hub/llama_pack_ollama.html#
	- llamaindexより、さっそくOllama対応のRAGの例
	- https://llamahub.ai/l/llama_packs-ollama_query_engine
- ollama web-ui is amazing
	- https://github.com/ollama-webui/ollama-webui
- ClimateXのデータセットが公開されている
	- https://huggingface.co/datasets/rlacombe/ClimateX
- Mistralより、新しい mixtral-8x7b-32kseqlenを発表
	- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
	- 「我々はMistral MoE (7Bx32experts) を 2 か月間使用しており、それは24GBで動作しています。」
- What is Mixture-of-Experts (MoE)?
	- mixtral-8x7b-32kseqlenの裏にあるmoe技術とは
	- https://x.com/sophiamyang/status/1733505991600148892?s=20
	- MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block.
- たった87GのweightでAGIが来るから、AI規制必要だねという
	- https://x.com/abacaj/status/1733561182504587652?s=20
	- mixtral-8x7b-32kseqlenのことらしい
- MoEのMixtral-7bx8のGPTQきとる！
	- https://huggingface.co/TheBloke/mixtral-7B-8expert-GPTQ
- Geminiのお遊びデモは、紙芝居だ
	- https://techcrunch.com/2023/12/07/googles-best-gemini-demo-was-faked/
- QuIP#: QuIP with Lattice Codebooks
	- https://cornell-relaxml.github.io/quip-sharp/
	- QuIP#は大規模言語モデルを2ビット量子化し、本来ならば140GBのメモリが必要なLlama 2 70Bを24GBのGPUで実行可能にするとの事です
- Bard(/w Gemini Pro)はいまだに数独が解けない、ChatGPTはとけるけど
	- https://x.com/kajikent/status/1733663171578335233?s=20
- OpenAI、GPT-4が怠け者になってきたという苦情に「修正を検討中」とポスト
	- https://www.itmedia.co.jp/news/articles/2312/10/news059.html
	- ChatGPTでのGPT-4のパフォーマンスが低下している（lazier）というユーザーからのフィードバックがここ数カ月増えていることを認め、「修正を検討中」だとX（旧Twitter）の公式アカウントにポストした。
- Mistral MoEの初期評価
	- https://x.com/bindureddy/status/1733523486885449834?s=20
	- まあ、ファインチューニングされてない素のモデルでもGPT3.5相当の性能というのは期待できる
	- solid 70B model that is very similar to GPT 3.5, Gemini Pro
	- MMLU on the base models is at 0.717 compared to Gemin Pro's 0.718
	- Expect to see several fine and instruct tunes over the next few weeks. These fine tunes will match GPT-4 quality for several real-world use cases.
-  Google Colab で DiscoLM Mixtral 8x7b alpha を試す by npakaさん
	- https://note.com/npaka/n/n3b55c941d864?sub_rt=share_h
	- 「**Mixtral 8x7b**」は、「Mistral AI」がリリースした史上初のオープンソース MoEモデルです
	- 「**DiscoLM Mixtral 8x7b alpha**」は、「Mixtral 8x7b」をファインチューニングして作成した実験的なチャットモデルです。元のモデルをHuggingFace形式に変換し、「Synthia」「MethaMathQA」「Capybara」でファインチューニングしています。
	- 「**MoE**」 (Mixture of Experts) とは、LLMの効率と精度を高めるために使用される手法です。このアプローチは、複雑なタスクをより小さく管理しやすいサブタスクに分割し、それぞれを特化したミニモデルまたは専門家が処理することで機能します。
	- 

## 12/4

先週までのOpenAIのお家騒動も落ち着き、今週は通常運転。日常能力を試すテスト『GAIA』、プロンプトの良例にもなっているし、現状のLLMの限界を図るのにちょうどよい。A*の可視化、こういうのを待ってた。異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』というのは、フリーアドレスの執務環境の研究活動の活性化にヒントがあるかも。選択バイアス問題がなぜか着目される。清水さん、ついに、A100 80GBx8のマシンが完成、日本語のマルチターン会話データセットもそろえてくれて、日本発のトップクラスLLM開発に大いなる期待。Intel® のトランスフォーマ拡張、量子化の新たなる段階？Googleからdebateを基にした安全なLLM利用についての理論論文公開。カーネマン教授とルカン先生の対話も必聴、system1とsystem2と深層学習の関係は、あるよな。BERTopicや、AlphaFold、googleの翻訳トランスフォーマーも着実に改良が進んで実用フェーズにまた一歩進んだ。Google Colabについにtransformerがデフォルトで含まれるようになる、つまりそういうことだ。強化学習系のアルゴリズムは、スパースな対象には不適切なのか。プロンプトを逆推論したり、サロゲート（代理）モデルにおける逆問題の研究も注目。llamapackってのができているのか、試してみよう。Agentをよく使ってるけどもっと種類がある、認知アーキテクチャってのはちゃんと理解したい。「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」というのは続編を望む。LLMをPytorchだけでどれだけ高速化できるかとか、GPT-fastとか、小規模言語モデルの開発とか、そういうのがもっと出てくるはず。OSSのLLMについての論文「ChatGPTの1周年を記念して」もいいね、OSSのLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示しているとな。アメリカの医学試験「US (4-option)」で90.2％という高い正解率をだしたGPT-4評価論文、下手なファインチューニングよりもという話か。


-  An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
- GAIA: a benchmark for General AI Assistants
	- https://arxiv.org/abs/2311.12983
- Q*ではないですが、A*探索の様子を可視化した
	- https://x.com/GregKamradt/status/1728480680127148480?s=20
- Kevin Dunnell et al., "Latent Lab: Large Language Models for Knowledge Exploration"
	- https://arxiv.org/abs/2311.13051
	- LLMベースで、異なるプロジェクト間の繋がりやアイデア生成を促すシステム『Latent Lab』
	- ①対話と視覚化を通してデータを探索 
	- ② プロジェクトのクラスタリングとラベル付けを自動化
	-  ③ 新しい研究プロジェクトのアイデア合成も可能
-  Google Colab で LCM LoRA を試す　 by npakaさん
	- https://note.com/npaka/n/n940ee84ca5b6?sub_rt=share_h
	- 「LCM」 (Latent Consistency Model) は、元モデルを別モデルに蒸留することで、画像生成に必要なステップ数を減らす手法です。25～50ステップかかっていた処理を4～8ステップで可能にします。
- Multi-modal Foundation Model for Material Design
	- https://openreview.net/forum?id=EiT2bLsfM9
	- 分子を表現するマルチモーダル基盤モデルの研究。SELFIES、DFT物性、スペクトルについてそれぞれencoder-decoderを学習し、各モダリティの潜在空間を共通の潜在空間にencode, decodeするモデルを学習。
	-  欠損が多くても学習可能かつ、後から異なるモダリティを追加しやすい
- 選択バイアスの式、tweedle
	- https://x.com/docmilanfar/status/1728680465928958055?s=20
- llamaindexより、RAG評価ツールragsのv2リリース
	- https://github.com/run-llama/rags
-  Simplifying Transformer Blocks 
	- https://arxiv.org/abs/2311.01906
	- many parts can be removed to simplify GPT-like decoder architectures as well as encoder-style BERT models:
- llamaindexから、RAGの新モジュール、fuzzy citationを発表
	- https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/fuzzy_citation/fuzzy_citation_example.ipynb
	- https://llamahub.ai/l/llama_packs-fuzzy_citation
	- 部分的な検索結果から１つの回答を合成？？
- ＲＡＧ 101 for enterpirze
	- https://gradient.ai/blog/rag-101-for-enterprise
	- 絵が素敵
-  AIスーパーコンピュータ「継之助」爆誕!とりあえずRAID0で12TBのディスクをインストールする
	- https://note.com/shi3zblog/n/n77e8ad3ed779?sub_rt=share_pb
	- ついにA100 80GBx8のマシンが稼働した。ここまで長かった。
	- ここまで揃ったら日本最大規模のLLMを個人で作れるようになる。
-  A population-level digital histologic biomarker for enhanced prognosis of invasive breast cancer
	- https://www.nature.com/articles/s41591-023-02643-7
	- An important AI report for breast cancer leading to the potential of sparing chemotherapy for many. 
	- The 1st comprehensive analysis of both cancerous and non-cancerous tissue in hundreds of thousands of patient tissues-
- BERTopicの新しいバージョン
	- https://github.com/MaartenGr/BERTopic
	- Merge pre-trained models, apply zero-shot topic modeling, seed domain-specific words, and much more in this HUGE update!
- Intel® Extension for Transformers
	- https://github.com/intel/intel-extension-for-transformers
	- An Innovative Transformer-based Toolkit to Accelerate GenAI/LLM Everywhere
	- Intel Extension for Transformers supports INT4 model quantized by GPTQ on Intel platforms (Xeon & PC) !
	- https://github.com/intel/intel-extension-for-transformers/tree/1.2.1#int4-inference
-  ラプラス変換とフーリエ変換の関係
	- https://qiita.com/kaityo256/items/aa5b24904577de40016e
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
	- 関数�(�)にたいして、�<0ならゼロに、�≥0ならe−��をかけて、「より収束しやすく」した上でフーリエ変換したものがラプラス変換である。ラプラス変換が、軸の中途半端なところを「縦に」積分しなければならない理由も、フーリエ逆変換と�から�への変数変換から理解できるであろう。
- Google Colab、Huggingfacesの協力で、transformerを最初から使えるようになった
	- https://x.com/GoogleColab/status/1729217098977845590?s=20
- A Llama-2-based model finetuned for function calling:
	- https://huggingface.co/Trelis/Llama-2-7b-chat-hf-function-calling-v2
- 日本語Wikipediaのマルチターン会話データセット10万個を作りました	
	- https://note.com/shi3zblog/n/na10eed9270f8?sub_rt=share_pb
	- GPT-3.5-Turboを使って、約一ヶ月かけて日本語のWikipediaの項目をもとに先生と生徒が会話するマルチターンデータセットを作りました
	- GPT-4でもやってみようかなと思っていますが、GPT-3.5でも一ヶ月でかなりの出費があり、GPT-4で同じ分量のデータセットを作るとなると数十万円から数百万円かかりそうです
- llamaindexからRAGに有効なllamapackを７種類公開
	- https://x.com/llama_index/status/1729303619760259463?s=20
- Compositional Generative Inverse Design
	- https://openreview.net/forum?id=5ueXRkKMMg&referrer=%5Bthe%20profile%20of%20Yilun%20Du%5D(%2Fprofile%3Fid%3D~Yilun_Du1
	- シミュレーションを深層学習モデルで近似した代理シミュレータと、拡散モデルを使った逆問題解法は、しばしば学習データ分布外にいったり局所解に陥ることがある。それを防ぐために、学習済みモデルを使って拡散モデルの各ステップで解を誘導し、不適切な解を防ぐCinDMを提案
- mlc-llm on WSLでモデルの変換を行う
	- 「WebGPUを用いたローカルLLMモデルのブラウザ推論」
	- https://zenn.dev/saldra/articles/356f470e730d1c
- ＮＴＴコムのＡＩ学習教材
	- https://gochikika.ntt.com/index.html
	- データの前処理からモデリングや評価までPythonコードと合わせて一通り学べる
- マルチモーダルのＬＬＭでも出力の成型が大事
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/multi_modal/multi_modal_pydantic.ipynb
- John X. Morris et al., "Language Model Inversion"
	- https://arxiv.org/abs/2311.13647
	- 言語モデルは次の単語の確率を出すが、その「確率」を利用して元の文章（プロンプト）を何とかして見つけ出す手法を開発。
- OpenAIのcookbookにllamaindexをつかたRAGが掲載
	- https://blog.llamaindex.ai/openai-cookbook-evaluating-rag-systems-fe393c61fb93
- Minimizing Factual Inconsistency and Hallucination in Large Language Models
	- https://arxiv.org/abs/2311.13878
	- LLMのハルシネーションを抑制するフレームワークが提案されました。 ユーザーの質問に対して、多段階で情報を取得させることで、信頼性の高い応答を取得可能です。
- Relational Deep Learning
	- https://drive.google.com/file/d/1Uk1y6c8z265G0wiRPpGT1cd5lts5lnKq/view
	- Relational Deep Learning is brings the power of Graph Representation Learning to a Relational Database.
- NeurIPA2023の論文検索サービス
	- https://www.ai-driven-life.com/neurips-papers
- 強化学習はベルマン最適性原理から来る動的計画法に支えられてます。しかし、情報がrandomSamplingされる中で実は各時刻隣合うデータの列がほとんど情報（報酬）を持たないとなると、間に推定器が挟まってるのもあってスパースどころか最後にしか報酬が得られない問題への妥当性は怪しいかもですね。
	- https://x.com/ML_deep/status/1729249503683969037?s=20
- DeepMind has formalized a theoretical result related to AI safety in Lean. 
	- https://github.com/google-deepmind/debate
	- "Monadic syntax is excellent for expressing stochastic algorithms, and working over finitely supported distributions avoids the need for integrability side conditions during proofs."
	- But I’m now much more optimistic that a PCP (probabilistically checkable proof) system derived from this line of research might be a useful tool to have in the toolbox for verifying AI safety properties that depend upon unformalizable human preferences. I still think “not killing lots of people” is probably just totally formalizable, but humanity might also want to mitigate the risks of various dystopias that are more a matter of taste, and that’s where this type of method might shine.
	- https://x.com/davidad/status/1729461156618637502?s=20
- Azure OpenAI Serviceの日本語記事まとめ
	- https://zenn.dev/microsoft/articles/azure-openai-japanese-blogs
- カーネマン教授とルカン先生の対話
	- https://www.youtube.com/watch?v=oy9FhisFTmI
	- Video of Daniel Kahneman and Yann LeCun discussing Dual Process Theory (i.e., System 1 and 2) in relation to Deep Learning.
-  ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search
	- https://arxiv.org/abs/2310.13227
	- uses algorithms like A* to improve LLM answers, improving sota on both planning and reasoning tasks
- Qualcomm Snapdragon 8gen 3 already supported 10b language model running locally on your smartphone.
	- https://x.com/Francis_YAO_/status/1727861621110779941?s=20
	- LLM is the new smartphone OS!
- Domingos先生がなんか言っている
	- https://x.com/pmddomingos/status/1729303707387658284?s=20
	- Why AI isn't going to taking over (from "The Master Algorithm").
- MistralChameli_7B_v01
	- https://huggingface.co/TokenBender/MistralChameli_7B_v01
	- First version of DPO-ed roleplay/smart version of Mistral. Now to conduct some experiments with reward model and see if this is any good.
- ベイジアンモデルへの経験ベイズ修正
	- https://www.jstage.jst.go.jp/article/keidaironshu/68/4/68_161/_article/-char/ja/
	- Robbins (1956) が Tweedie (1947) に言及してることに基づき，Efron が Tweedie's formula と名付けて広まっているが，Koenker & Gu (2016) では Dyson (1926) で既に得られていることが指摘されている。
-  A glimpse of the next generation of AlphaFold
	- https://deepmind.google/discover/blog/a-glimpse-of-the-next-generation-of-alphafold/
	- AlphaFoldは最近大きなアップデートがあり、精度が大幅に向上し、タンパクだけでなくPDBにあるほぼすべての分子について予測可能です。創薬や新型CRISPR探索にも(一定程度は)使えます。
- EMNLP2023 の採択論文リストが見えるようになってた．来週シンガポールで開催される自然言語処理の国際会議です．タイトルに"Language Model"はいってる論文が219本って，どんだけ言語モデル好きなんだよ
	- https://2023.emnlp.org/program/accepted_main_conference/
-  OpenAI と LangChain の認知アーキテクチャ by npakaさん
	- https://note.com/npaka/n/n650532ce289a?sub_rt=share_h
	- 「**認知アーキテクチャ**」(cognitive architecture) とは、LLMどのように情報を処理し、応答を生成するかを理解するための枠組みです。「Flo Crivello」（自律エージェントスタートアップのLindyの創設者）が使用したこの用語を初めて聞き、素晴らしい用語だと思いました。
	- 「LangChain」では、「LLM」が真に変革的なエージェントのようなシステムに電力を供給する世界を信じています。しかし、そこにたどり着くルートは、**企業が「認知アーキテクチャ」を制御できるルート**であると信じています。
	- **(1) Code**  LLMを利用しないパターン。  
	- **(2) LLM Call** アプリの出力のみを決定する単一のLLMコール。 
	- **(3) Chain**  アプリの出力のみを決定する複数のLLMコール。  
	- **(4) Router**  LLMをルーターとして使用し、使用するアクション (Tool、Retrieval、Prompt) を選択。 
	- **(5) State Machine**  LLMを使用してある種のループでステップ間をルーティングするが、コードが許可された遷移先にのみ遷移  
	- **(6) Agent**  利用可能なステップのシーケンスを決定もLLMが行う。
- TextからSQLを生成するQuerypls
	- https://github.com/samadpls/Querypls/
- われらが、 @jerryjliu0がdeeplearningaiコースに登場
	- https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/
	- We also have LlamaPacks for every technique mentioned in this course to help you jumpstart your advanced LLM app:
- Deconstructing RAG
	- https://blog.langchain.dev/deconstructing-rag/
	- Given the importance of RAG and the fast pace of development, we've grouped popular RAG concepts into a few categories and created guides for each one.
- Running Starling-7B LLM model on local CPU with @Ollama_ai and getting great results for invoice data extraction, even better than Zephyr, Mistral or Llama2.
	- https://github.com/katanaml/llm-ollama-invoice-cpu
- 円城塔を近似する？
	- https://colab.research.google.com/drive/1oXxBIYJvvUYsVZP6WYAUCb3QK09zTJtO?usp=sharing
	- 円城塔さんの文章で学ぶ、大規模言語モデルのファインチューニングチュートリアル
- 「長コンテキストをLLM(GPT, Claude)に食わせた際に、ちゃんとRetrivalされるか？」を検証しているGithub。
	- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
	-  総じてCalude-2に比べてGPT-4 Turboのほうが正確に引用しているようで面白い。
- Qwen/Qwen-7B-Chat-Int4をGoogle Colobで動かす
	- https://ayousanz.hatenadiary.jp/entry/2023/11/30/182017
	- なんか日本の文化はちゃんと学んでいないみたいですね
-  Accelerating Generative AI with PyTorch II: GPT, Fast
	- https://pytorch.org/blog/accelerating-generative-ai-2/?utm_content=273712248
	- GPT-fastというのがすごらいしい、３倍？
- LiLM 小規模言語モデル TinyLlama 1.1B の日本語追加事前学習(incremental pretrain) を試したメモ
	- https://zenn.dev/syoyo/articles/52f1d0d62fcad5
	- 生成される日本語はまあまあであるが, 構文やコンテキストがおかしい...
	- ファインチューンしても間違えたり...
	- まあでも 1B 規模なら妥当なのかもしれません
- 今号の『日本語の研究』で「和歌集の歌風の言語的差異の記述ー大規模言語モデルによる分析ー」と題して、OpenAIのtext-embeddingを使って、『万葉集』と『古今集』の意味構造の差を解析してみました。
	- https://www.musashinoshoin.co.jp/shoseki/view/2976/
- Energy and entropy: Path from game theory to statistical mechanics
	- https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.043055
	- エネルギーを低くするのが目標のプレーヤーと，エントロピーを上げるのが目標のプレーヤーの交渉ゲームにおける最適な戦略を通して熱平衡化を議論するらしい
- gpt-fast
	- https://github.com/pytorch-labs/gpt-fast
	- LLMをPytorchだけでどれだけ高速化できるかチャレンジしたリポジトリ Llama-7Bが10倍速くなっている 
	- Pytorchで使える高速化技術をいろいろ盛り込んでるぽっくて、中身見るのも勉強になりそう
- 日本語LLMでLLaVAの学習を行ってみた
	- https://qiita.com/toshi_456/items/248005a842725f9406e3
- googleから新しい翻訳トランスフォーマーを発表
	- Unsupervised speech-to-speech translation from monolingual data
	- https://blog.research.google/2023/12/unsupervised-speech-to-speech.html
-  業界別生成AI活用のすゝめ
	- https://www2.deloitte.com/jp/ja/pages/about-deloitte/articles/about-deloitte-japan/ai-dossier-2023.html?id=jp:2pm:3tw:4daii-genaidossier:5:6abt:20231201::
	- デロイトトーマツ
-  Microsoft Copilot is now generally available
	- https://blogs.bing.com/search/december-2023/Microsoft-Copilot-is-now-generally-available?ocid=aid_soc_usoc_edu_cons_bing_eng_tw_12.1
- C言語でWASMインタプリタを実装した話
	- https://zenn.dev/ri5255/articles/845ef3dab5ab47
	- この自作WASMランタイムの目的は、できるだけ仕様に従った実装を与えることで、仕様の理解を助けることである。早さや効率性よりも分かりやすさを優先しているため、実用には向かない。仕様書を読んで、実装に困った際に参照してほしい。
-  データ不足に数理モデルで立ち向かう / Japan.R 2023
	- https://speakerdeck.com/dropout009/japan-dot-r-2023
- Harsha Nori et al., "Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine"
	- https://arxiv.org/abs/2311.16452
	- これまでGPT-4などの基盤モデルは、医学などの専門分野で特化モデルには敵わないと考えられてきました。 しかし、「実際はどうなのか？」と考えた研究者らは、特別なトレーニングなしのGPT-4が、プロンプトの工夫のみでどこまで性能を示すのかを検証しました。
	- ① アメリカの医学試験「US (4-option)」で90.2％という高い正解率を出した
	-  ② 理由付けが必要なタイプの問題データセットPubMedQAで82.0％の正解率を達成
-  日常能力を試すテスト『GAIA』正答率、人間92%に対してGPT-4は15%　一般的なニーズに応えるAI開発の指針に
	- https://aiboom.net/archives/59440
- Langchain102
	- https://www.youtube.com/watch?v=haad3i9VROs
	- Mistral 7b User Showcase + LangServe & LangSmith
- METAのAI研究者が何らかの大きなブレイクスルーがあったと示唆。 近日中に共有予定とのこと
	- https://x.com/ArmenAgha/status/1731076069170835720?s=20
-  「ChatGPTの1周年を記念して」、オープンソースLLMがChatGPTにどこまで追いついているか体系的調査報告
	- https://aiboom.net/archives/59713
	- https://arxiv.org/abs/2311.16989
	- オープンソースLLMとしてはLlama-2（およびMentalLlama）、Palm、Vicuna、Falcon、Wizard、Lemurなどのモデルに焦点を当て、それらの進歩のスピードと特定のタスクでの優れた性能について詳しく分析されています。調査結果からは、オープンソースLLMが特定のタスクや応用分野において、クローズなLLMに匹敵する、あるいはそれを上回る性能を示していることが明らかになりまし
- MRS2023(materials research society)でLLMが多い 2023 MRS Fall Meeting & Exhibit
	- https://x.com/yoko_materialDX/status/1731267042810962256?s=20
	- MIセッションが常時4つあり回るのが大変
	- 機械学習ポテンシャルと自動合成の発表が大量
	- 結晶構造予測の発表が思ったより多かった
	- LLMの発表は材料データ抽出が中心
	- 日本企業からのMI発表が多かった 
	- 世界情勢ゆえ？）中国本土の方がほぼいなかった

## 11/27

アルトマン氏解任劇は、マイクロソフトがアルトマン氏の受け入れを表明するも、OpenAIの主要メンバがアルトマン氏に追従すると表明したのでボードが復帰を懇願、結局OpenAIのCEOとして戻ることで幕引き。解任劇の背後には、OpenAIでAGI（スーパーAI)を達成する見込みが立った、それがQ*というLLMで、従来のLLMが苦手だった数の推論が可能になった、Q*の取り扱いを巡り解任騒動が起きた、といううわさで持ち切りに。Q*-learningがそれでは？みたなことになって様々なところで盛り上がっている。それ以外では、intelが満を持してneural-chat-7b-v3-1を公開、Mistral 7Bベースなんだけど、様々なチューニングにより相当性能が良いみたい、しかしFalcon 180B越えということはないと思うぞ。AnthropicAIが200kのコンテキストを扱えるClaude2.1を発表、デモ版が利用可能で、さっそく結構長文の日本語のPDFをそのまま投入できるとか、エバンゲリオン世界のシミュレーションを動かしてみたとか話題に。「３D世界の中で身体性をもった汎用エージェント」の論文、いや 「未来の二つの顔」（ホーガン）のAI（仮想３D空間シミュレーションで身体性を学習させる）を彷彿させる世界が現実になったような気がする。データベースに対するQ&Aにおいて、SQL文を生成される方法と、データベースの内容をいったん知識グラフにしてQ&Aする方法を比較し、後者のほうが高性能との報告も。まあコンテキストというかそういうのを与えたほうがいいに決まっているのだが。RAGにおいても、コンテキストをフィルタリングするのが有効らしい、そのあたりにまだ人の工夫の余地が残っている。Llemmaは、LLMで数学の問題を解くのに、定理証明器を使うことを前提にしたPythonコードを出力することで実現、LLMを活用して問題を解くメタなアプローチ（直接解くのではなくて、解く手順・方案を生成する）の１つ。LLMベースの新しい言語『SUQL』もいい感じで非構造データを扱えるらしいが、例題がレストランの会話とは第２世代AIにおけるフレーム問題ぽくていいね！AIが人間が思いつかないような「異質な」仮説を生成することで、科学が進化する、かも。ChatGPTをつかって、部屋を片付けている人がいた、これはすごい応用だ！OECDのAIの定義も生成AIや基盤モデルを鑑み４年ぶりに改定、人の指示に従わずとも、入力に対して自らのとるべき動作を推測するメタ能力についも暗示、もはやAIに対するソフトウエア的な品質保証は不可能な事態へ。

-  Banach-Tarski Embeddings and Transformers
	- https://arxiv.org/abs/2311.09387
	- 再帰的なデータ構造の線型空間での表現（バナッハタルスキ埋め込み）を考えるとその表現上のアルゴリズム（復号）がTransformerとして自然に実装できるらしい
- 大規模言語モデルを用いた意味分析による辞書記述への応用
	- https://speakerdeck.com/yhkondo/da-gui-mo-yan-yu-moderuwoyong-itayi-wei-fen-xi-niyoruci-shu-ji-shu-henoying-yong
	- 埋め込み（ベクトル化）の辞書作成への応用とか、枕草子を題材に埋め込みをつかたｔ類似検索してみる例が、英語による検索、絵文字による検索、クリエーティブな検索など事例があって面白い
- Shicheng Liu et al., "SUQL: Conversational Search over Structured and Unstructured Data with Large Language Models"
	- https://arxiv.org/abs/2311.09818
	- LLMベースの新しい言語『SUQL』が開発されました。SQLを拡張して「非構造化データのクエリ」を処理するパラダイムを導入
	- 『SUQL（Structured and Unstructured Query Language）』
	- ① 構造化データと非構造化データの両方を扱う 
	- ② SQLに、非構造化データをクエリするための新しいプリミティブを追加 
	- ③ 会話型検索エージェントでユーザーの質問を処理 
	- ④ クエリに関連するデータを構造化および非構造化データソースから抽出する
	- 従来の線形化テクニックや多段階検索および推論モジュールに比べて、SUQLは回収精度が大幅に高い
	- 実際のレストランに関するクラウドソースされた質問と会話を含むデータセットで実用性が確認された
-  Meta disbanded its Responsible AI team
	- https://www.theverge.com/2023/11/18/23966980/meta-disbanded-responsible-ai-team-artificial-intelligence
	- metaが責任あるAIのチームを解散させた
- 状態空間モデリング入門
	- https://www.no-spare.com/store/products/seminar-20231129
	- 本講座では、金融時系列データへの応用を題材に、動的線形モデル・ボラティリティモデル・最新の研究を解説します。
-  Hypotheses devised by AI could find ‘blind spots’ in research
	- https://www.nature.com/articles/d41586-023-03596-0
	- AIが仮説を生成する際に直面する課題として、データの不足、物理的な法則の理解、仮説の一般性と解釈性などが挙げられています。
	- AIが仮説を生成する可能性として、人間が思いつかないような「異質な」仮説や、実験を自動化する「ロボット科学者」などが紹介されています
-  Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild
	- https://arxiv.org/abs/2311.06237
	- 大規模言語モデル(LLM)をしばき倒して、異常な振る舞いをさせようとしている人達（野良のLLMレッドチーム）へのインタビュー論文。攻撃方法やそもそも何のためにやっているのか？等の調査。
- アルトマン氏、ゲストカードを使って、OpanAIを訪問
	- https://x.com/sama/status/1726345564059832609?s=20
	- first and last time i ever wear one of these
-  ChipNeMo: Domain-Adapted LLMs for Chip Design
	- https://arxiv.org/abs/2311.00176
	- ChipNeMoはチップ設計支援向けにドメイン適応したLLM。開発支援Chatbot、EDAスクリプト生成、バグ要約と分析を行う。既存LLMに、専用トークンを追加した後、ドメイン適応事前事前学習（DAPT 230億トークン）、指示学習（1000例）をし、ドメイン適応検索補強を行う
- マイクロソフトのナデラ氏、アルトマン氏たちがマイクロソフトにJoinすると、、
	- https://x.com/satyanadella/status/1726509045803336122?s=20
- マイクロソフトによる生成AIのチュートリアル
	- https://github.com/microsoft/generative-ai-for-beginners
	- The free 12 lesson course is available on Github and will teach you everything you need to know to start building Generative AI applications.
-  Learning to Filter Context for Retrieval-Augmented Generation
	- https://arxiv.org/abs/2311.08377
	- RAGにおいて、コンテキストをフィルタリングする方法を学習する
	- 語彙および情報理論的なアプローチを通じて有用なコンテキストを特定し、テスト中にコンテキストをフィルターするためのモデルをトレーニングすることが含まれます。
	- FILCO は、コンテキスト フィルタリングに String Inclusion (STRINC)、Lexical Overlap、Conditional Cross-Mutual Information (CXMI) などの技術を使用
- 日本語対応 LLM(13B 規模)の, 行間を読むようなかしこさがあるか試したメモ(現状 Qwen 14B がベスト)
	- https://zenn.dev/syoyo/articles/59a5ccbbb5660e
	- 7B 以下(10B 未満)も試しましたが, 行間を読むほどのかしこさはなく, 13B 規模で飛躍的にかしこさが上がる感じだったので, 13 B 規模のを選んでいます.
	- qwen.cpp(llama.cpp variant)で f16 量子化版を動かしました.
	- q4 あたりに量子化だといくらかかしこさ落ちました(それでもほかの日本語 LLM よりよい結果をえられる)  また, Qwen7B もあまりかしこくはありませんでした.
	- Qwen 14B(Chat) ちゃんが行間を読むほどのかしこさを見せました!
- OpenAIがNPO+であるようなことが、今回のアルトマン氏解任につながったとの絵柄
	- https://x.com/GOROman/status/1726701627468546511?s=20
-  Azure OpenAI Service 入門 by npakaさｎ
	- https://note.com/npaka/n/n46e6ad252ce1?sub_rt=share_h
	- 「Azure OpenAI Service」で「gpt-3.5-turbo」を使用する手順をまとめました。
-  Orca 2: Teaching Small Language Models How to Reason
	- https://huggingface.co/papers/2311.11045
	- 小さいことはいいことだ
-  Introducing RAGs: Your Personalized ChatGPT Experience Over Your Data
	- https://blog.llamaindex.ai/introducing-rags-your-personalized-chatgpt-experience-over-your-data-2b9d140769b1
	- llamaindexのJerryが放つ、streamlitをつかった、RAGアプリ生成ツールRAGs
	- “ChatGPT over your data” without needing to code.
- Large-scale pancreatic cancer detection via non-contrast CT and deep learning
	- https://www.nature.com/articles/s41591-023-02640-w
	- ｢単純CTの膵臓がん検出AI｣
	- 単純CTでの膵臓がん検は不可能と考えられてきた 
	- そのAIを開発 
	- 現実世界のマルチシナリオ検証の病変検出で、92.9%の感度と 99.9% の特異度を達成 
	- 膵臓がんスクリーニングの新しいツールの可能性
-  RAG評価ツールの "RAGAS" を使って、RAGパイプラインの性能を測定する
	- https://qiita.com/s3kzk/items/44b8780c656b4f747403
	- 今回触れたチャンク分割時の設定以外にも、システムプロンプトの決定、Embeddingおよび応答の生成に使用するLLMの選定、ベクターストア/検索アルゴリズムの選定など、パフォーマンスに影響を与える要素は数多く存在します。
- アルトマン氏OpenAIに復帰すると
	- https://x.com/OpenAI/status/1727206187077370115?s=20
-  2週間使い倒してわかった｢GPT-4-Turboの衝撃｣。OpenAIの｢お家騒動｣で見逃してる場合じゃない
	- https://www.businessinsider.jp/post-278766
- AnthropicAIよりClaude2.1の発表
	- https://x.com/AnthropicAI/status/1727001773888659753?s=20
	- コンテキスト長はなんと 200k と 2 倍に拡大。ハルシネーションの低減、システムプロンプトへの対応、価格の引き下げ、外部APIとの連携機能(ベータ版) など
	- https://claude.ai/　でお試し可能
- ChatGPTで部屋の片づけをしている人がいいる
	- https://x.com/fjtn_c/status/1727216371711586402?s=20
	- （部屋の写真送って片付けタスクを分解してもらって、それを実行して写真撮ってまた進捗を送る→同じことを繰り返し）
- 愛新覚羅の孫（大井町の眼科医）の驚愕エピソード
	- https://x.com/aishinkakura_i/status/1727477535234248712?s=20
	- 学会でアメリカを訪れた際、イミグレーションで「清朝の子孫か」って尋問を受け、しばらく足を止められ…
- metaから、Getting started  with Llama
	- https://ai.meta.com/llama/get-started/?utm_source=twitter&utm_medium=organic_social&utm_campaign=llama2&utm_content=image
-  単行本が入るClaude 200kで僕と「エヴァンゲリオン」
	- https://note.com/shoty/n/n03bff29f683f
	- 日本語だと150ページいかないくらいが調理できるのではないかと思う。つまり**単行本一冊が入ってしまう**
	- エバンゲリオンの物語をシミュレートできるかという挑戦らしい
- 【DSにKaggleが必ずしも必要ではない話】
	- https://x.com/Nurruttan/status/1727495591905858016?s=20
	- データサイエンティストと言っても、 「①データアナリスト型」 「④データエンジニア型」 のキャリアプランではKaggle実績の重要性は低い
	-  一方で、 「②サービスグロース型」 「③製品開発型」 「⑤AI開発型」 は重要度は高い。
- Google BardでYoutubeとチャットできるように
	- https://bard.google.com/chat
-  「Paper Interpreter」を使って論文を読もう！
	- https://note.com/daichi_konno/n/nb1f1ac368a30
	- 東大の、紺野大地先生作成
	- **「論文をアップロードするだけで、内容を日本語で分かりやすく説明してくれるAI」**
- アルトマン氏電撃解任劇の裏に、OpenAIが、AGIを開発するめどがついたからという
	- Q*-learningという手法により、数値計算などLLMが苦手としていた課題も解けるようになった。
	- https://x.com/hbouammar/status/1727683545852768295?s=20
	- A*ってのは探索のアルゴリズムだけど、それのQ-learning版という話
- Intel謹製の、LLMが、リーダーボードで上位の性能をはじき出す
	- https://x.com/Yampeleg/status/1727679553714217421?s=20
	- https://huggingface.co/Intel/neural-chat-7b-v3-1
	- A 7B model from Intel almost as capable as Falcon 180B:これは本当か！！！
	- Base model: Mistral 7B. 
	- Fine Tuned on: SlimOrca 
	- DPO: LLaMA-13B vs ChatGPT Gens (Prefer ChatGPT)
- An Embodied Generalist Agent in 3D World
	- https://huggingface.co/papers/2311.12871
	- ３D世界の中で身体性をもった汎用エージェント
	- 3D世界に対して、いわば記号接地するような訓練をすることで身体性(embodiment)を取得、自然言語処理、コンピュータビジョン、ロボティクスなどの多様なドメインで汎用的なタスクを解決できる汎用エージェントが構築できたという
	- 手段としては、3D世界の理解と相互作用を必要とする、オブジェクトレベルとシーンレベルの多モーダルなタスクを含む、規模と複雑さに優れたデータセットを慎重に作成
-  大規模言語モデル(LLM)をLoRAで強化する際に役立つ情報を研究者が公開
	- https://gigazine.net/news/20231123-llm-lora/
	- LoRAは画像生成モデルや大規模言語モデル(LLM)に追加の情報を学習させてモデルを微調整できる仕組
	- **◆LoRAの効果には一貫性がある**
	- **◆QLoRAを使えば追加学習時のVRAM使用量を大幅に節約可能**
	- **◆最適化アルゴリズムはAdamでもSGDでも大差ない**
	- **◆LoRAによる追加学習を繰り返すと性能が低下する**
	- **◆LoRAによる追加学習は単一のGPUで実行可能**
- Claude 2.1 (200K Tokens) - Pressure Testing Long Context Recall
	- Claude2.1の長コンテキスト能力に対する、ストレステスト
	- https://x.com/GregKamradt/status/1727018183608193393?s=20
	- 200K トークン (約 470 ページ) で、Claude 2.1 はドキュメントの一部の深さで事実を思い出すことができました。 
	- 文書の一番上と一番下にある事実はほぼ 100% の精度で再現されました 
	- 文書の上部にある事実は下部よりも低いパフォーマンスでリコールされました (GPT-4 と同様) 
	- ~90,000 トークン以降、ドキュメントの下部にあるリコールのパフォーマンスがますます悪化し始めました 
	- コンテキスト長が短い場合のパフォーマンスは保証されませんでした
- Why do tree-based models still outperform deep learning on typical tabular data?
	- https://hal.science/hal-03723551
	- Why do tree-based models still outperform deep learning on tabular data?” confirms tree-based models outperform deep learning and explain some of the reasons why.
	- When it comes to #tabulardata and #timeseries (by far the most important majority of data for almost any real company), deep learning is not one needs. 
- Pythonによるフェーズフィールド法入門: 基礎理論からデータ同化の実装まで
	- https://www.amazon.co.jp/dp/4621308882?_encoding=UTF8&psc=1&ref_=cm_sw_r_tw_ud_dp_RW79QAZKZRQ7K9N885XB
	- フェーズフィールド法においても,実験データを活用して物性値やパラメータを推定しつつ,シミュレーション精度を高められるような,データ同化と融合した手法の開発が進んでいる.そこで本書でも,データ同化の基礎からフェーズフィールドモデルへの実装方法まであわせて紹介する.
	- フェーズフィールド法では、秩序変数の拡散方程式と反応方程式を同時に解くことで、組織形成過程を計算します。拡散方程式は、秩序変数が拡散する際の挙動を記述する方程式です。反応方程式は、相の変化を記述する方程式です。
	- フェーズフィールド法は、金属の凝固、多結晶粒成長、拡散相変態など、さまざまな材料組織形成過程の計算に用いられています。また、応力場や電磁場における組織形成やナノスケールにおけるモデル化など、マルチスケール・マルチフィジックスを対象とした種々の工学分野にも応用されています。
- 「マスターアルゴリズム」の著者、Domingos氏、Q*-learningの効果をみて、人類の終焉を叫ぶ
	- https://x.com/pmddomingos/status/1727562239060656339?s=20
	- Q* can solve simple math problems that symbolic AI could solve 50 years ago. Panic! AGI is here! Humanity is over!
- A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases
	- https://arxiv.org/abs/2311.07509
	- impact of KGs for question answering on SQL databases: 54% accuracy vs. 16% with instructions directly on SQL databases.
	- SQL DBを参照して質問応答を行うシステムでは、LLMに直接SQLを参照させると16%の正解率しか出なかったがLLMをナレッジグラフにマッピングしてそれを参照させると54%に改善したという研究。
	- 本質的に持っている情報が同じでもデータ構造によってRAGの精度が変わることの一例ともみなせる
- うみゆき氏、Claude2.1の性能に舌を巻く
	- https://x.com/umiyuki_ai/status/1727875985167790529?s=20
	- Claude無料版試してみたけど、結構長文の日本語pdf入力して要約してってお願いしたら、ちゃんと内容読んで要約箇条書き出してくれた（目次丸写しではない）　３章の内容説明してって言ったらちゃんと説明してくれた。つまりちゃんと最後まで読んで答えてる。かなり的確な応答を返してくれる。それでタダ。これ相当スゴイね
- Yuhan Sun et al., "To be or not to be? an exploration of continuously controllable prompt engineering"
	- https://arxiv.org/abs/2311.09773
	- これまで「LLMの動きを観察して"プロンプトを調節"する」手法が追究されてきましたが、限界があるため「プロンプトによる"LLMの動きをダイレクトに調整"する」手法『ControlPE』
	- 自動運転システムなどを手掛けるセンスタイム社による
	- ControlPEは競合技術と比較してもプロンプトの影響をこまかく調整できる手法
	- ① LoRAを利用するアプローチ ② プロンプトの影響を連続的に微調整 ③ 従来のプロンプトエンジニアリングを補完する
- Q*のもともとのアイデアを出した論文著者が自論文を宣伝
	- https://x.com/McaleerStephen/status/1727524295377596645?s=20
	-  A* Search Without Expansions: Learning Heuristic Functions with Deep Q-Networks
	- https://arxiv.org/abs/2102.04518
- Q*について著名なデータサイエンティストErnest Okumuraさんのコメント
	- https://x.com/pacocat/status/1728052432016470281?s=20
	- Q*がQ-learningから来ているかは知らないけれども、制作者にとって好ましい出力を得るために方策空間を探索する技術は今後さらに求められていくと思うし、RLHFみたいな分かりやすいアラインメントを超えてAGIみたいな文脈でも野心的な試みは増えてくるんじゃないでしょうか。
- Sparse Transformers：入力シーケンスの長さによる計算量増加問題への革新的なアプローチ
	- https://ai-scholar.tech/articles/transformer/sparseTransformer
	- Attentionのレイヤー毎の特徴を再現することで，計算量の削減を達成  
	- Sliding Window Attenion、Dilated Sliding Window Attention、Global Attentionという3つのAttentionを使ってTransformernの計算量を削減した  
	- 計算量を削減しただけではなくて，当時のSOTAを達成している．
-  Llemma: An Open Language Model For Mathematics
	- https://arxiv.org/abs/2310.10631
	- どうも、LLMをつかって、定理証明器をつかうpythonコードを生成するらしい。実際に説くのはpythonインタープリター＋定理証明器の組み合わせ。
	- The AlgebraicStack dataset of 11B tokensが提供される
	- Llema can solve mathematical problems using a Python interpreter and a formal theorem prover.
- LlamaIndex vs. OpenAI Assistants API
	-  RAG Evaluation Series: Validating the RAG Performance of OpenAI vs LlamaIndex
	- https://www.tonic.ai/blog/rag-evaluation-series-validating-rag-performance-openai-vs-llamaindex
- ChatGPTアプリの音声会話が無料ユーザーにも開放
	- https://x.com/IELTS_expert/status/1728326991676670222?s=20
	- 英語学習ソフトや有料レッスンが不要に
- JARVIS-1は本当はすごい、
	- https://x.com/ai_database/status/1728257353852797143?s=20
	- マインクラフト（広大なバーチャル世界で採掘や建設を行うゲーム）を上手にプレイするAI『JARVIS-1』が開発されました。 非常に複雑な動作を含む200種類以上の行動が可能とのこと。
	-  このような技術を応用すると、ロボットが現実世界でもさまざまな重要タスクを達成できるようになる可能性があります。…
- 最終的にすべての統計はベイズに行き着くしかないと思っています（統計数理研究所、鎌谷氏）
	- https://www.ism.ac.jp/ism_info_j/labo/project/162.html
- ルカン先生によるQ*に対する表明
	- https://x.com/ylecun/status/1728126868342145481?s=20
	- 「Q*に関する完全なナンセンスの洪水は無視してね。LLMの信頼性を向上させる主な課題の1つは、自己回帰的トークン予測をプランニングに置き換えることです」
- Macでllama2を試すためのswift-chat
	- https://github.com/huggingface/swift-chat
	- Llama 2 7B chat, running 100% private on Mac, powered by CoreML!
	- Pedro Cuencaさんは現地時間2023年08月08日、Apple Silicon MacなどAppleデバイス上で大規模言語モデル(LLM)を実行するためのSwiftパッケージとDemoアプリを公開
	- SwiftでTransformersライクなAPIを実装するために開発したSwiftパッケージ”swift-transformers”と、Demoアプリ”swift-chat”、加えてTransformersモデルをCoreMLへ変換するコンバーター”transformers-to-coreml”で、
	- CoreMLが役に立ったと、、
- OECD、生成AIや基盤モデルを考慮しつつAIの定義を改定、
	- https://www.euractiv.com/section/artificial-intelligence/news/oecd-updates-definition-of-artificial-intelligence-to-inform-eus-ai-act/
	- 欧州AI法などの他の規制との整合性も考慮したアライメントととった
	- 目標を人間が定義する必要があるという事実への言及を削除、
	- 「出力の生成方法を推測する」という文言も、AI モデルが環境から入力を受け取り、1 つ以上のアルゴリズムを通じて適切な出力を思いつくときを説明するために導入

## 11/20

今週は、OpenAIのCEOアルトマン氏の電撃解任が全てを持って行った。先週OpenAI dev dayで雄姿を、そして人類の未来を垣間見たのに。。ボードから復帰の要請もあるというし、まだまだ現在進行形。さて、RAGもembeddingをつかった類似検索よりも構造を加味した検索とか、多様性をもつ検索結果の利用とか、だんだん、推薦技術などで確立されたノウハウが活用され始めた。LlamaIndexの新機能、text-to-SQL+semanticってのがいいね。LLMのファインチューニング関係もにぎやか、単に論理ソルバーを外部にもってて、自然言語からソルバーに渡す論理式を生成するよりも、ソルバーのログをそのままファインチューニングに使って、解く行為そのものを模擬するというLoGiPTとか、結晶構造をシンプルなテキストで表現しLLaMA-2をファインチューニングして、VAEを上回ったという事例とかがある。そもそもですわね、新しいOpenAIのファインチューニング、200個程度のデータでも、お嬢様LLMぐらいはできるみたいでございますです。LLMはそのメタな能力も重要な要素。プロンプトエンジニアを作るメタなプロンプトをつくったり、ユーザーのプロンプトをLLMが理解やすいように書き換えるプロンプトとか、こっち方面のメタな世界もいい感じで発展している。（ちょっと視点を変えた）ファインチューニングとLLMのメタ能力を利用するのがLLM活用の次のステージか。create-llamaとか、OpenGPTとか、LLMA Factoryと、自動的にアプリを作る仕組みがたくさん出てきた。 わずか1分で10日間の天気を予測可能なAI「GraphCast」、お茶の水大学の神山先生の解説が、従来の手法が不得意なところにGraph transformerがぴったり合ったというところが腹落ちします。Microsoftの発表したCopilot、つまりGPTsのＭＳ版。こういう世界観になるよな。早速OpenCopilotとか、WebCoPilotとか、あっというまに、似たようなOSSが、、、。Yahoo知恵袋、ついにGPT-4をつかった自動回答をテスト中。人の衆知はChatGPTに敗れたのか。。ＭＣ業の紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される、ＭＣ業もＡＩに代替される？されない？まあ、ChatGPTで仕事がなくなったのは、ChatGPTのCEOも例外ではないというのはブラックジョークかも。

- Adding Structure-Aware Retrieval to GenAI Stack
	- https://medium.com/@yu-joshua/adding-structure-aware-retrieval-to-genai-stack-373976de14d6
	- 単なるembeddingをつかった類似検索のRAGではなくて、構造を抽出したうえでの、RAGっての有効であることを、neo4j+LangChainの実例で示した良例
	- This stack is (1) fully local, (2) uses advanced retrieval methods that encode relationships between different chunks of texts
- LlamaIndex によるOpenAIの新機能を使用・理解するためのガイド by npakaさん
	- https://note.com/npaka/n/n728fdb8f76da?sub_rt=share_sb
	- Parallel Function Calling、Assistant API Agent、Function Callingによる高度なRAG、マルチモーダルRAG
	- GPT Builder、プロンプトを自動性生成することで、GPTを生成するmetaなツール
	- 「text-to-SQL と semantic search のジョイント」なんかは興味深い
- 日本の女性が先進国の中で長命なのは、社会進出が進まなかったから？
	- 旭リサーチ
	- https://arc.asahi-kasei.co.jp/report/arc_report/pdf/rs-824.pdf
	- 「先進国の中では女性の社会進出が進まなかったことが、 世界一の女性長寿に結びついたと思われる。」 
	- 「均等法は女性の平均寿命を短縮させる要因である。」
- gpt-3.5-turbo-1106を使った、新しいOpenAIのファインチューニング
	- https://x.com/matsu_vr/status/1723688378795958670?s=20
	- でお嬢様チューニングしてみました。200例の会話で十分お嬢様になった！
- Boosting RAG: Picking the Best Embedding & Reranker models
	- https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83
	- RAGをやるにあたってどれを使えばよいかを調べたブログ。OpenAI ChatGPTやGoogle PaLMなどで作った embeddings と BAAI 等が提供している reranker で、どの組み合わせが精度が良いか
- OpenAI Dev dayを受けた、llamaindexのハイレベルAPIのアプデまとめ
	- https://docs.google.com/presentation/d/1i1bUDWXeCYPd6O8pio57ST6AQIuSTWXM3rvvkvrBpBM/edit#slide=id.p
	- 大変だー
-  Prompt Engineering a Prompt Engineer
	- https://huggingface.co/papers/2311.05661
	- プロンプトエンジニアを作るメタなプロンプトを作るという話、LLMってメタ能力があるので、こういう試みが可能。CoT越えというのは本当か？
- ユーザープロンプトをLLMが言い換えて、LLM自身が理解しやすくする手法『RaR』
	- https://aiboom.net/archives/51160
	- 例えば「GPT-4で言い換えてGPT-3.5で入力する」も有効とのことです。 実行テンプレートや性能等を詳しく紹介する記事を公開しました
-  Language Models can be Logical Solvers
	- https://huggingface.co/papers/2311.06158
	- 従来SOTAは、solver-augmented language modelsをつかって、自然言語からシンボリックなロジックを取り出して、外部ソルバーで説いていたが、、文法があってないとかそういう下らないエラーに悩まされてきた
	- LoGiPTは、直接論理的な導出をエミュレートする、既存ソルバーのログをデータセットとして、ファインチューニングした。問題は解決された
	- https://x.com/IntuitMachine/status/1724104506185580589?s=20
-  JARVIS-1: Open-World Multi-task Agents with Memory-Augmented Multimodal Language Models
	- https://arxiv.org/abs/2311.05997
	- JARVISって確か、アイアンマンのサポートAIの名前では？？
- 人間の情報処理にとって「ちょうどいい塩梅」の速度を超えとる気がする by 谷チュー
	- https://x.com/rmaruy/status/1724044250286108818?s=20
	- Buonomano『脳と時間』によれば、脳には単一のクロックはない（多重時計原理）。が、進化の過程で生物が相手にしてきた時間スケールより大幅に速い情報処理はできないだろう。一方、情報の「量」に関してはまだ工夫できるかもしれない。
- DPOでcalm2の物語生成能力を向上させる試み、
	- https://x.com/_oshizo_/status/1724039980463657130?s=20
- リアルタイムでLLMが文字を生成する様子のデモ、
	- https://x.com/dylfreed/status/1723927399857901724?s=20
	- llamacppをつかって8GB RAM MacBook Airで動くんだとさ
- LLMって結局何かをシンプルに説明する
	- https://x.com/davidad/status/1723990400682148124?s=20
	- ディープ ニューラル ネットワークは、各層間に要素ごとの非線形性を持つ線形回帰のサンドイッチ構造です。LLM/GPT の爆発的な増加に直接つながった「Attending is All You Need」の核となる貢献、そこに *ロジスティック* 回帰を非線形層に投げ込むことですまた、ドロップアウトについては@geoffreyhinton 、活性化正規化については@ChrSzegedy 、および勾配正規化については@dpkingmaによるものです (Adam)。
- ローカルLLMを動かすPCを自作
	- https://note.com/ai_meg/n/n8855a8dd4bbd?sub_rt=share_pb
	- マザーボード：Asrok　B760 PRO RS/DS  
	- CPU：i5-13400F  
	- GPU:PALIT　GFORCE-RTX4060ti-16G
- RETOOLのState of AIレポート
	- https://retool.com/reports/state-of-ai-2023
	- 66% of companies have at least one AI use case live
	- Accuracy is #1 concern
	- RAG is 2nd most popular use case (1st is code)
	- @llama_index is one of the leading frameworks for enterprises 
- OpenGPTはどんどん進化する
	- https://github.com/langchain-ai/opengpts
-  The Alignment Handbook
	- https://github.com/huggingface/alignment-handbook
	- Robust recipes to align language models with human and AI preferences
- EditGPT
	- https://chat.openai.com/g/g-zpuYfzV7k-editgpt
	- Grammeryのような機能を持つGPTsが、、
- 岡野原さんの、「拡散モデル」が今年度の大川出版賞に選出
	- https://hillbig.github.io/diffusion-models/
	- http://www.okawa-foundation.or.jp/activities/publications_prize/list.html
- これは衝撃!1.5Bで超高性能LLM!RWKV-5-World-v2 by shi3zさん
	- https://note.com/shi3zblog/n/nfc8dd1abf494?sub_rt=share_pb
	- まだ生きてたのか、RWKV
- The Impact of Large Language Models on Scientific Discovery: a Preliminary Study using GPT-4
	- https://arxiv.org/abs/2311.07361
	- Evaluates GPT-4’s knowledge base, scientific understanding, scientific numerical calculation abilities, and various scientific prediction capabilitie
	- MSからの論文、製薬とかの話が多いが、なんかつまらん
- Open AI主任科学者のIlya Sutskever氏は昨日のインタビューにて、AGIにたどり着くためにはTransformerアーキテクチャ＋αで「明らかに」問題ないと
	- https://www.youtube.com/watch?v=Ft0gTO2K85A
- 大規模言語モデルのFine-tuningによるドメイン知識獲得の検討
	- https://tech.preferred.jp/ja/blog/llm-fine-tuning-for-domain-knowledge/
	- 英語で主に学習されたLLaMA2に対して日本語データを用いたInstruciton Tuningや追加事前学習がどの程度可能かの検証
	- 不可思議な結果が出がちなので、いろんな設定で試さないといけないことがわかった
- LangChainから、Query Construction Guide、text-to-SQL+semantic最強節
	- https://blog.langchain.dev/query-construction/
	- 1. Structure+unstructured data:  Text-to-SQL+semantic (w/ PostgresSQL with the Pgvector 
	- 2. Unstructured w/ metadata: Text-to-metadata filters (w/ new docs + a template for self-query retriever)
	- "Text-to-SQL+semantic" is an interesting recent addition to LangChain that extends "Text-to-SQL" w/ semantic queries on an embedding column.
	- そうか、やっぱり text-to-SQL+semantiが最強なのか
- 『Chain of Empathy（共感の連鎖）』
	- Yoon Kyung Lee et al., "Chain of Empathy: Enhancing Empathetic Response of Large Language Models Based on Psychotherapy Models"
	- 心理療法のセオリーを反映したプロンプト手法『Chain of Empathy：CoE』を開発し、その性能を検証
-  Fine-Tuned Language Models Generate Stable Inorganic Materials as Text
	- https://openreview.net/forum?id=0r5DE2ZSwJ
	- 言語モデルによる結晶構造予測
	- 結晶構造をシンプルなテキストで表現しLLaMA-2を微調整することで、VAEの従来手法よりも安定な結晶構造を生成できた
	- この手の手法はモデル構築にお金と時間がかかるところが課題
- create-llama, a command line tool to generate LlamaIndex apps
	- https://blog.llamaindex.ai/create-llama-a-command-line-tool-to-generate-llamaindex-apps-8f7683021191
	- コマンドラインでllamaindexをつかたたアプリを生成する仕組みの公開！！！
- GPT4などが、常識をもっているかどうかのテストデータセットによる評価
	- https://github.com/allenai/everyday-things
	- The LLMs have poor accuracy (54-59%) on commonsense spatial/functional relationships in ParRoT dataset.
	- This suggests the LMs do not have fully coherent conceptual pictures of everyday objects.
- LLMA Factory
	- https://github.com/hiyouga/LLaMA-Factory
	- Easy-to-use LLM fine-tuning framework (LLaMA, BLOOM, Mistral, Baichuan, Qwen, ChatGLM)
- WebPilot
	- https://chat.openai.com/g/g-pNWGgUYqS-webpilot
	- 記事や論文、PDF などの抽出系の便利 GPTs を作ったけれど、すべて WebPilot で十分だった(めこめこさん)
- beさん、毎日ベルマン方程式を解いて日常を過ごしていると、
	- https://x.com/behemuhemulove/status/1724408454348194303?s=20
- 【HELP ME】Assistants APIで破産しそうになった話
	- https://note.com/nike_cha_n/n/n65a6101d59d7
	- ちゃんと計算しないとあっという間に上限に達するかも、
- Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion
	- https://arxiv.org/abs/2311.06318
	- MSより
	- Microsoft Research presents a method to personalize LLMs for search via entity-based user knowledge stores derived from logs.
- Yahoo知恵袋、GPT-4を用いた、自動回答をテスト中
	- https://chiebukuro.yahoo.co.jp/topic/ai/answer.html
	- 人知は不要になったのか。。
-  Trusted Source Alignment in Large Language Models
	- https://huggingface.co/papers/2311.06697
- GPT paper asistantのソース
	- https://github.com/tatsu-lab/gpt_paper_assistant
	- スタンフォード大学の橋本先生謹製
- Licheng Wen et al., "On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving"
	- https://arxiv.org/abs/2311.05332
	- 視覚を手にしたLLMが自動運転にどれほど役立つのかを探るため、GPT-4Vの能力が検証されました。 
	- さまざまなタスクで実験したところ、「因果関係の推論」や「シーン（景色）の理解」に長けていると結論づけられました。
- うるさいやつ、技術を理解しないと、ビジネス展開のきっかけが出てこない、エンジニアを蔑視して、それを商売にしているのが嫌い。
	- https://x.com/toukatsujin/status/1724196831109017964?s=20
	- 「技術力を磨かないと生き残れないと思っているエンジニアがほとんど。でも技術は日々進化・変化しており、これを学べば一生安泰ということはない。むしろビジネス理解力を磨いたほうが一生安泰なのに、エンジニアの多くは分かっていない」
- Rapidly build an application in Gradio power by a Generative AI Agent
	- https://cloud.google.com/blog/products/ai-machine-learning/rapidly-build-an-application-in-gradio-power-by-a-generative-ai-agent?hl=en
	- Gradio の作者の初めての論文といううわさも
- ChatGPTとDeepLの字幕翻訳の比較
	- https://x.com/gijigae/status/1724345403234193540?s=20
	- ChatGPTは、①英語字幕を繋ぎ直す ②日本語に訳す ③訳したテキストを自然な流れになるように分け、元のタイムスタンプへ戻す といった一連の作業を全部やってくれる。
- GPTsとAsistant APIの違い
	- https://x.com/gijigae/status/1724428173905989945?s=20
	- GPTsとAssistants APIはカスタマイズしたChatGPTが作れる点で似ている。ただ、ChatGPT Plusへの加入やステート管理を含め、違いも多い↓。忙しくて一つしか試せないという方には後者をお勧めしたい。特に、カスタマイズしたChatGPTを生徒に公開する際、ChatGPT Plusへの加入が不要となるのは大きい。
- 「表象（representation）」概念を分析するRPPFプロジェクト
	- 神経科学などで多用されるが曖昧で問題含みの「表象（representation）」概念を、20～30名の哲学者と神経科学者で分析する「Representation: Past, Present and Future (RPPF) project」
	- https://www.thetransmitter.org/representation/what-are-we-talking-about-clarifying-the-fuzzy-concept-of-representation-in-neuroscience-and-beyond/
- コード生成・補完に特化した日本語LLM「ELYZA-japanese-CodeLlama-7b」を公開しました（商用利用可）
	- https://note.com/elyza/n/n5bce23d7c9c8
	- https://zenn.dev/elyza/articles/fcbf103e0a05b1
- わずか1分で10日間の天気を予測可能なAI「GraphCast」をGoogle DeepMindが発表、スパコンで数時間かけた予測より高精度
	- https://gigazine.net/news/20231115-google-graphcast-global-weather-forecasting/
	- https://github.com/google-deepmind/graphcast
- RAG over Governments Document
	- https://github.com/deptofdefense/LLMs-at-DoD/blob/main/tutorials/Chatting%20with%20your%20Docs.ipynb
- GGUF 版の 5 bit 量子化された Llama 2 を WasmEdge で。7B が 24 token / sec で動作しました↓
	- https://www.secondstate.io/articles/fast-llm-inference/
	- Mac ユーザは見たらとりあえず試して。コマンド４行叩くだけなので！Rust x Wasm で Llama 2 推論がローカルで動きます
- ELYZA-japanese-CodeLlama-7b-instructのggufフォーマット変換版
	- https://huggingface.co/mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf
- マイクロソフトは Copilot Studio を発表
	- Igniteの中で最後に発表、GPTsみたいなものになる
	- 
- お茶大、神山先生による、Googleの気象予測の気象学者からの解題
	- https://x.com/kohyama_met/status/1724986380546408878?s=20
	- 「AI気象予報論文」の感想を投稿したら思いのほか反響が大きかったので、気象学者かつ情報科学科教員として、いくらか真面目に解説します。
	- アーキテクチャが従来型モデルの不得手にうまくハマっている
- Research Assistantのテンプレートが公開される
	- https://github.com/langchain-ai/langchain/tree/master/templates/research-assistant
	- With this template you can easily plug in an arbitrary retriever, allowing you to do research over a knowledge base of your choice.
- 東大 松尾研のPRML（パターン認識と機械学習）輪読会スライド集
	- https://www.slideshare.net/matsuolab/
	- 黄色い本はやっぱり、聖典
- OpenCopilot
	- https://github.com/openchatai/OpenCopilot
- tldrawが洒落にならないぐらい優れている
	- https://makereal.tldraw.com/
	- ラフなUIの図解や説明をつくるだけで、GPT-4Vで認識して良い感じに仕様を解釈して実際に動くモックアップを作ってくれる
- 紗々氏、NTT武蔵野通研で開催されたR&Dフォーラムで、AI化される
	- https://x.com/03sasa03/status/1725479562094755951?s=20
-  OpenAI announces leadership transition
	- https://openai.com/blog/openai-announces-leadership-transition
	- えっ！
	- 「取締役会とのコミュニケーションにおいて一貫して率直さを欠き、取締役会の責任遂行を妨げている」
- OpenAIから追い出された直後の、Sam Altomanのツイート
	- https://x.com/sama/status/1725742088317534446?s=20
	- i love you all.
- 西浦先生の論文に、筑波大の掛谷氏がかみつくも、統計の専門化から返り討ちに
	- https://x.com/behemuhemulove/status/1725749314000175387?s=20
	- 主な問題点 (1) クロスバリデーションの評価なし (2) 短期予想モデルの結果を繋ぎ合わせて長期のシナリオを作っている 明日の天気を高確率で当てるモデルを作っても、その予想を繋ぎ合わせ、、、
	- be氏より、（2）は例えば1年後の予測するとして1ヶ月ずつ予測してくのか、年単位で予測してくか位の違いしかなく、統計学やMLでは全く問題ないと思うので、この点叩いてる方が統計学の観点から無知にみえる
-  create-llama によるLlamaIndexアプリの作成 by npakaさん
	- https://note.com/npaka/n/neafa42455864?sub_rt=share_h
- 体軸が直立した時点が人類が自己を認識した分岐点かもしれない
	- https://x.com/daijapan/status/1725841037086892358?s=20
	- 認知科学講座より、
- Building Research Assistant	
	- https://www.youtube.com/watch?v=DjuXACWYkkU
	- YouTube tutorial on building one from scratch. Covers LCEL, LangSmith, parallelization, retrievers
- Ilya Sutskeverって誰ぞ？
	- https://x.com/mr_bay_area/status/1725808417376473167?s=20
	- 「自然言語処理業界が深層学習一色になる流れを決定づけた人」ですね。それくらい彼が作ったseq2seqは衝撃だったし
- :smile:、:ikanai:
	
## 11/13

今週は、OpenAI Dev Day(11/6)が全てあり、LLM周りの風景が一変した。GPT-4 TurboやAssistant APIや、価格の改定（安くなった）、最後に独自のGPTをつくれるGPT Builderと、OpenAI まわりのOSSエコシステムを破壊するがごときの怒涛のリリース。対応するOSS側のLangChainやllamaindexも新機能の取り込みや対案実装で忙しい週だった。Assistant APIって、**Code Interpreter**、**Retrieval**、**Function Calling**　が呼び出せ、APIからも作れるけども、playgroundからも作って簡単に試せる。Assistant APIに実装された機能(Assistants/Theads/Run )を組み合わせれば、エージェントも簡単に作れる。詳しくはNakajimaさんのGPTvsGPTが良い例。無限に環境問題についてエージェント同士が討論するというデモはちょと地獄絵。早速、LangChainも、LlamaIndexも、Assistant APIをつくってエージェントを作る機能を公開、もともとあるエージェントと組み合わせてみたいな発展も。OpenAI のRetreive機能は、pdfやdocやpptやmarkdown等多彩なデータを読んで、コンテキストとしてChatできる機能。まさに、RAGつぶしなんだけども、llamaindexの人Jerry Liuによると、コンテキスト長の限界を超えると普通のtop-k式の単純なRAGが動いているのではということ。試しにナウシカ(Wikipedia、57kトークン)をGPT-4でやってみたら、確かに性能よかった。RAGについては自ら（ベクトル化の方法などの）細かいチューニングに走るか、それとも入り口だけ用意してあとは、別のOSS等にという戦略のどちらだろう？GPT-4もファインチューニングできるようになったが、$3M(５億円弱)の[Submit]ボタンは押せない。。GPT-4を半端にファインチューニングしても性能は向上しないというのもすごいな。エージェントの作成支援も、llamaindexからbuilder agent、Langchainからも、OpenGTPが発表。OpenAI本家もGPTsで、好みのGPTを作って公開という機能が公開、Plusユーザーなら他人のGPTを使うこともできる。タイムラインに、どんどん、独自のGPTが公開されて、まさに百花繚乱、これに利用料を還流する仕組み整えば、まさにマーケットプレース経済圏に一直線。マルチモーダルのRAGというのも出てきた。PFNのPLaMo-13B-Instructの公開や、日本語向けのベンチマークデータの改定や、shi3zさんによるマルチターン日本語会話データセットの整備など、日本語対応の改良も着実に進んでいる。「アナロジア AIの次に来るもの」のダイソンによると、LLMは、（デジタル・コンピューターによるAIの限界を超えることができる）アナログコンピュータに近いものらしい。ダイソンの本を読みなおすと、AGIの可能性についても、デジタルでは到達できないが、アナログならば可能性は排除できないみたいな主張だった。最後に、ChatGPTの登場は、デザイナやコピーライターの職を奪うだけでなく、単価も下げた、特に高収入の層を、というFTの記事が怖すぎる。

- ALMA-7B-Ja-V2
	- https://huggingface.co/webbigdata/ALMA-7B-Ja-V2
	- 翻訳タスク特化のALMA-jaのV2来とる！!GPTQもある
- TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT
	- Microsoftから発表されたテーブルタスクのトレーニングデータを用いて「テーブルチューニング」するモデルTable-GPT
	- 多様なテーブルタスクにてGPT-3.5やChatGPTより高性能、高い汎用性を示す
	- https://arxiv.org/abs/2307.08674
- OpenAI dev day
	- GPT-4 Turbo 発表 
	- コンテキスト長128k
	- JSON Mode 
	- ナレッジカットオフ 2023/04
	- DALL E-3 / Text to Speech 
	- Whisper v3 
	- GPT-4 Fine-tuning可能に
	- GPT-3.5 Turbo はもう 16K がデフォレベルでさらに安くなり、GPT-4 Turbo は価格が入力 1/3, 出力 1/2 になった
	- 「従来の16倍となる300ページを超える長い文書を扱えるようになり、2023年4月までの情報を反映」
	- functionsとfunction_callが非推奨になってtoolsとtool_choiceになったんだ
- ノーコードで「ChatGPT」のカスタム版を作れる「GPTs」、有料会員に提供へ
	- https://www.itmedia.co.jp/news/articles/2311/07/news074.html
	- プロンプトからの指示で対話しながらオリジナルのChatGPTを構築できる。「Web検索や画像作成、データ分析などと同じくらい簡単」としている
- MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning
	- https://huggingface.co/papers/2311.02303
	- MFTcoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Leveraging the CodeLLama foundation, our MFTcoder fine-tuned model, CodeFuse-CodeLLama-34B, achieves an impressive pass@1 score of 74.4\% on the HumaneEval benchmark, surpassing GPT-4 performance (67\%, zero-shot).
- Assistants API の解説と動作確認（Google Colab）
	- https://note.com/schroneko/n/nd04c46242171
- llamaindexから、OpenAI dev dayをうけGPT builderを模擬するBuilder Agentの例を公表
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/agent_builder.ipynb
	- https://x.com/jerryjliu0/status/1721639447207583882?s=20
	- 例：「トロントのことをよくわかるエージェントを作成」→エージェントができる。。
- LangChainから、OpenGPTの発表、
	- https://github.com/langchain-ai/opengpts
	- builds upon LangChain, LangServe and LangSmith This gives you more control over the LLM you us
- OpenGTPは、 LangSmithに連携するだけで利用ログが取れるので、あとはエージェントのToolsを充実させれば、それなりのものが提供できる
	- https://x.com/mah_lab/status/1721684588874055764?s=20
- Levels of AGI: Operationalizing Progress on the Path to AGI
	- https://arxiv.org/pdf/2311.02462.pdf
	- DeepMindから、AGIにいたるLevel0からLevel5までの段階を示す、レベル分けのOntologyを提案といっている
	-  AGI by considering generality (either Narrow or General) in tandem with five levels of performance (Emerging, Competent, Expert, Virtuoso, and Superhuman).
-  OpenAI Python API Library v1.0 入門　by npakaさん
	- https://note.com/npaka/n/n27b94df96179?sub_rt=share_sb
	- 「OpenAI Python API Library」のインタフェースが一新された、らしい
- GPT-4のfine-tuningで有効なgainを得ることが3.5-turboより難しい
	- パートナーを選ぶ形でCustom Models programを提供する戦略へ転換か、
	- GPT-4がすごすぎるので、中途半端なファインチューニングはかえって性能を劣化させる。。。。
	- https://openai.com/blog/new-models-and-developer-products-announced-at-devday
- Assistants APIを利用すれば、TOEICやTOEFL、英検、IELTSに特化した家庭教師も一瞬で作れる
	- https://x.com/gijigae/status/1721737796724183504?s=20
	- いままで、OpenAI Plus(3k円/月)で実現していたものが、Assistans APIで、月1,500円程度の半額になるというお話、なるほど
- OpenAI APIのRetrievalた多種ファイルに対応
	- OpenAI API の今回のアップデートに含まれていた Knowledge Retrieval (ファイル内検索を可能にする機能) は PDF はもちろん Word やパワポ、ソースコードも対応してるようだ。 RAG 関連のサービスはホント要らない子になっちゃったね
- OpenAI Assistantsで試しに英語論文を要約するアシスタント作成例
	- 今回新たにAPIが発表されたRetrieval機能を使ってPDFファイル添付をしてみてます。
	- https://x.com/alexweberk/status/1721705504228192373?s=20
	- DPOの論文26ページ分くらいの要約で$0.80くらい
-  GPT-3.5-Turbo / GPT-4-Turbo 1106のJSONモードの使い方 by [shi3z](https://note.com/shi3zblog)さん
	- https://note.com/shi3zblog/n/nd72e0269dc3f?sub_rt=share_pb
- OpenAI DevDay で発表された新モデルと新開発ツール まとめ by  [npaka](https://note.com/npaka)さん
	- https://note.com/npaka/n/n9cd206d96f85?sub_rt=share_sb
	- 「Function Calling」に、単一メッセージから複数のFunction (「車の窓を開けてエアコンをオフにする」など) を呼び出す機能などが追加されました。精度も向上しています
	- 16Kコンテキストウィンドウをサポートする新しい「GPT-3.5 Turbo」もリリースします。指示追従、 JSONモード、並列 Function Callingをサポート
	- 「Assistant API」は、特定の指示を持ち、追加の知識を活用し、モデルやツールを呼び出してタスクを実行できる専用のAIです。
	- アシスタントは、必要に応じて、**Code Interpreter**、**Retrieval**、**Function Calling**を呼び出せる
- Google Colab で OpenAI API の Retrieval を試す by npakaさん
	- https://note.com/npaka/n/ndcacbefb2ef7
	- APIからAssistantを作る方法、結果はplaygroundでも確認できるというか、playgroundでassistant作成の別のやり方
- Putting numbers into a better perspective and classifying them according to their level of complexity
	- https://thinkzone.wlonk.com/Numbers/NumberSets.htm?platform=hootsuite
- GLaMM: Pixel Grounding Large Multimodal Model
	- https://huggingface.co/papers/2311.03356
-  GPT-4VのAPIをサクッと使ってみる！
	- https://note.com/peisuke/n/nef0616b8d7fc?sub_rt=share_sb
	- 早稲田大学の講義のページを使わせてもらいます。制約条件付き最適化の問題を解かす→解ける。
	- "画像の数式の応用例を一つ挙げ、何らかの適当な数値を設定し、それを解くためのプログラムを作成してください"
- Google Colab で OpenAI API の Text-to-Speech を試す by npakaさん
	- https://note.com/npaka/n/nba4af88eb3cf?sub_rt=share_sb
	- 6つの内蔵ボイスが付属しており、次の目的で使用できます。
		- 書かれたブログ投稿のナレーション
		- 複数言語の音声を生成
		- ストリーミングを使用したリアルタイムオーディオ出力
- Bayesian Optimization of Function Networks with Partial Evaluations
	- https://arxiv.org/abs/2311.02146
- Assistance APIについて
	- これまでなら自力 or LangChain でやってきたことが、それなりに Assistants/Theads/Run などでできるようになっちまったぜ
	- OpenAIの [#AIアシスタント](https://twitter.com/hashtag/AI%E3%82%A2%E3%82%B7%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%88?src=hashtag_click) は面白いけど、またお金が飛んでいく
- Assistances APIをつかって、GPTvsGPTを作る例
	- https://x.com/yoheinakajima/status/1721769833212281231?s=20
	- https://github.com/yoheinakajima/GPTvsGPT
	- 例として、地球温暖化テーマに対する、海賊vs人魚の論争をシミュレーション！
- Langchainから、OpenAIの assistance APIのサポートを発表
	- https://github.com/langchain-ai/langchain/blob/master/cookbook/openai_v1_cookbook.ipynb
	- Spin up OpenAI assistants and run them as any other LangChain agent!
	- LangChainのAgentと同じように、OpenAIのagentを使える、らしい
	- OpenAIAssistantRunnable.create_assistan
- Contrastive Error Attribution for Finetuned Language Models
	- https://arxiv.org/abs/2212.10722v2
	- 文書生成においてハルシネーションを引き起こすデータセット内のデータを高精度で特定する手法の提案。
- Tokyo Digital Twinが、
	- https://info.tokyo-digitaltwin.metro.tokyo.lg.jp/
	- 調布市の3次元 [#点群](https://twitter.com/hashtag/%E7%82%B9%E7%BE%A4?src=hashtag_click) をダウンロードしました! さらに独自の手法にて建物・植物・地表面の自動分類を行いました
- GPT-4のファインチューニングには、５億円かかる？？？
	- It costs $2-3 million to train a custom GPT-4 model with your own dataset.
	- https://x.com/tdinh_me/status/1721835213121265840?s=20
	- いや、この「Submit」ボタンは押せない。。。
- GPT4 Turbo はPyllms ベンチマークでGPT4を凌駕
	- https://github.com/kagisearch/pyllms
	- https://aider.chat/docs/benchmarks-1106.html
- CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding
	- https://huggingface.co/papers/2311.03354
- QGIS 3.34で3DTilesが表示できるようになったので、3D都市モデルPLATEAUの3DTilesをQGISで表示してみました
	- https://x.com/shi__works/status/1721808786393121197?s=20
	- https://north-road.com/2023/11/07/qgis-3d-tiles-thanks-to-cesium-ecosystem-grant/
- OpenAI Assistants API(Playground)を使ってコーディングのアドバイスをしてくれるアシスタントを作る
	- https://zenn.dev/karaage0703/articles/66949a39643557
	- 今まででも、Custom InstructionsとAdvanced Data Analysis（Code Interpreter）でできていたことを、手軽に切り替えられて便利になった。API経由でできるようになったということなので、本質的な変化というよりは順当なアップデート
- 自分の癖にあったファインチューニング用データセットをLLMで作ろう！【Calm2】
	- https://zenn.dev/saldra/articles/090c120b49e38c
	- LLMのファインチューニングにおいて、データセットは重要なものとなりつつある
	- 以前までは人力で作る必要があったが、プロンプトが効く7Bモデル（Calm2-chat）を用いることで、LLMでファインチューニング用データセットを作ることができる
	- データセットを作成しつつ、動的にプロンプトを修正していく手法が相当よかった
- HuggingFace Diffusers v0.22.0の新機能 by npakaさん
	- https://note.com/npaka/n/n5aebfc60408a?sub_rt=share_sb
- OpenAI Assistants APIに拙著「エンジニアの知的生産術」を入れて質問。これこそ「書籍を読む方法の効率化」だな感
	- https://x.com/nishio/status/1721857526990586203?s=20
- OpenAIの AIアシスタント に子猫の絵を描いてもらいました
	- https://x.com/itnavi2022/status/1721945299713941944?s=20
- 日本語対応13BモデルのPLaMo-13B、インストラクションチューニングされた
	- 対話性能を向上させた指示学習（instruction tuning）済み大規模言語モデルPLaMo-13B-Instructを公開しました
	- https://tech.preferred.jp/ja/blog/llm-plamo-instruct/
- llamaindexもOpenAIのAssistanceに対応
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb
	- OpenAIのRetrievalとllamaindexのRetrievalを組み合わせることが可能！！！
- OpenAIのRetrieval APIは、コンテキスト長が長い場合、簡易なtokp-k RAGに切り替えている模様
	- The OpenAI retrieval API seems to be doing basic top-k RAG on limited context if there's context overflows.
	- https://x.com/jerryjliu0/status/1721987237771133219?s=20
- GPT-4 Turbo vs GPT-4 tests
	- GPT-4 Turbo has record accuracy (87% vs 52% of GPT-4 on PyLLMs benchmark), it is almost 5x faster with 48 vs 10 tokens/sec). 
	- And it is also 30% cheaper in practice (would be more, but it is 2x wordier in output compared to GPT-4)
	- https://x.com/vladquant/status/1721674365211738269?s=20
-  Google Colab で OpenAI API の Function Calling を試す by npakaさん
	- https://note.com/npaka/n/nc3713dba5df6?sub_rt=share_sb
	- 群馬県の気温を教えてください
-  Re-evaluating Retrosynthesis Algorithms with Syntheseus
	- https://arxiv.org/abs/2310.19796v1
	- 逆合成のベンチマーク論文。
	- 狙いの材料から原料を予測する逆合成予測では各論文で評価方法が異なっていましたが、Microsoftさんらはベンチマークライブラリを構築、これによりモデルのランキングが従来と変わることが分かったそうです。
-  Google Colab で OpenAI API の Code Interpreter を試す by npakaさｎ
	- https://note.com/npaka/n/nb90306341d41?sub_rt=share_sb
- GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベル
	- どうも今回の OpenAI の価格改定で、GPT-3.5 Turbo の価格が Fireworks や Anyscale などの OSS LLM デプロイサービスの 70B のデプロイ価格と全然競争できるレベルまで掛かっているらしく、OSS LLM が普及しないのは結局 OpenAI の API がクソ安すぎるからでは？という指摘
- OpenAI API の Assistant API のしくみ
	- https://note.com/npaka/n/n9fa7204e4af4?sub_rt=share_sb
- mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration
	- https://huggingface.co/papers/2311.04257
- llamaindexより、parallel function callingによる効率化の例
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_agent_parallel_function_calling.ipynb
- OpenAI API で提供されている モデル まとめ by npakaさｎ
	- https://note.com/npaka/n/n5d0a76b149f1?sub_rt=share_sb
- 『生成AIのパラドックス』
	- https://aiboom.net/archives/58414
	-  LLMなどの生成AIの背後にある思考プロセスは人間とは全く異なるかもしれないことを示す仮説
	- AIが人間のような出力を生成する能力を持ちながら、それを理解する能力は必ずしも伴わないという仮説です（仮説を立てるに至った背景は、前章を参照）。
- Streamlit+GPT4-Vision+TTSで動画ナレーション自動生成ツールをつくった
	- https://zenn.dev/olemi/articles/752d205987cb87
	-  動画からフレーム画像を抽出し、Base64形式に変換する
	- GPT4-Visionに動画のナレーションを生成させる
	- 生成されたテキストから、TTS APIで音声ファイルを生成する
	- Streamlitで、テキストと音声ファイルを表示・ダウンロード可能にする
-  Google Colab で PLaMo-13B-Instruct を試す by npakaさん
	- https://note.com/npaka/n/n97a1ac080f76?sub_rt=share_sb
- 日本語に対応した Embedding Model のベクトル検索での精度比較｜Tatsuya Shirakawa
	- https://github.com/nouu-me/document_vector_search_benchmark
	- 日本語Text Embeddingでのベクトル検索の精度をいろんなモデルで検証してみました。e5良いですね
-  Extracting List of  `Album`  (with Parallel Function Calling)
	- https://docs.llamaindex.ai/en/latest/examples/output_parsing/openai_pydantic_program.html#extracting-list-of-album-with-parallel-function-calling
- 複数のアシスタントに討論させる例
	- https://x.com/npaka123/status/1722761636937900541?s=20
- Zhenjie Yang et al., "A Survey of Large Language Models for Autonomous Driving"
	- LLMが得意とする「計画、認識、質問応答、生成」の能力が自動運転システムに効果的に使えると主張
	- https://arxiv.org/abs/2311.01043
- Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach
	- https://arxiv.org/abs/2209.06995
	- 良質なデータを収集し少量で高い性能を獲得する試み。
	- LLMにプロンプトを与え疑似ラベルを予測、分布が一様で不確実性が高い=学習効果が高いとみなす。
	- ベクトル空間上の距離から周辺も不確実性が高い、かつ採用データ間の距離を空ける。
	- 128サンプルでフル学習の 90% 超の精度。
- A.R.I.A. (Aria) - Your AI Research Assistant
	- https://github.com/lifan0127/ai-research-assistant
-  OpenAI の Assistant Playuground の Function Calling を試す
	- https://note.com/npaka/n/n6bf08e93840d?sub_rt=share_sb
- GPTs 作成第二弾として arXiv Reader を作りました。論文は PDF 入力か URL 手渡しか選べます。
	- https://chat.openai.com/g/g-qrOeOjLX6-arxiv-reader
- Tokenizerの分割を可視化しながらトークン数を数えてくれるページがOpenAIのサイトにある
	- https://platform.openai.com/tokenizer
- GPTsで、Kaggleのチュートリアル第6版を読み込ませてみて、質問してみました。
	- https://chat.openai.com/g/g-Z3a4iOzGR-kagglenotiyutoriarudi-6ban
- 弊社のカスタマーサポートをGPTsで作成してみました。
	- https://chat.openai.com/g/g-uINwYG4Ja-trippy-kasutamasapoto
- LangChainの# OpenAI Assistant、js版
	- https://js.langchain.com/docs/modules/agents/agent_types/openai_assistant
-  Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific Subspaces of Pre-trained Language Models
	- https://arxiv.org/abs/2305.17446
	- 事前学習済モデルの転移学習がモデル内の副空間で行われている可能性を示唆した研究。
	- 重みをFlatten しエポックごとスタックして SVD にかけ、 Fine Tuning 中のパラメーター変動を説明する軸を発見。
	- この軸上で外れ値になるパラメーターを無効化し著しい性能劣化を確認
- 山内志朗『小さな倫理学入門』
	- 「人間は欲望を自分で生産できず、他の人からこっそり盗んできます。もしかすると、人間は欲望が欠如していて、それを隠すために欲望まみれの姿を取りたがります。やりたいことが見つからない人の方が圧倒的に多いのです。」
- スタンフォード大のAI研究者Fei-Fei Liさんの新刊”The Worlds I See”は、想像を超える面白さ。強さとしての好奇心。
	- https://www.amazon.com/dp/1250897939?ref_=cm_sw_r_cp_ud_dp_QG23D73KJFT6GCP6GNVP
	- After 3+ years, today is the day that my book “The Worlds I See” gets to see the world itself. It is a science memoir of the intertwining histories of me becoming an #AI scientist, and the making of the modern AI itself. 
- 日本語言語モデルのベンチマークテストが更新
	- 日本語言語モデルのベンチマークテストである Stability-AI/lm-evaluation-harness がアップデートされたため、Youri 7B シリーズのスコアを算出し直しました。 GPTQによる 4bit 量子化モデルのスコアも算出しています。
	- https://rinnakk.github.io/research/benchmarks/lm/
- 生成AIエコシステムについて
	- 生成AIまわりがすごい楽しいのは、技術そのものはもちろん、理論に詳しい人、いち早く実装に落とすのが得意な人、きれいなアーキテクチャーに落とすのが得意な人、面白いプロダクトに仕立てる人の協力関係がバッチリ噛み合ってるみたいなところがすき
	- https://x.com/uezochan/status/1722604877644497292?s=20
- GPT3.5を用いてマルチターン日本語会話データセット(16K)を作りました
	- https://note.com/shi3zblog/n/nfc07c53d61a8?sub_rt=share_b
	- Wikipedia日本版データセット(izumi-lab/wikipedia-ja-20230720)とGPT-3.5-Turboでマルチターン会話データセットを作りました。
-  Google Colab で Japanese Wikipedia Conversation による Llama 2 のLoRAファインチューニングを試す
	- https://note.com/npaka/n/n723766f96cbc?sub_rt=share_sb
	- **<s> [INST]** 日本の首都は？ **[/INST]** 東京です。**</s><s> [INST]** その場所の観光名所を教えて。 **[/INST]** 東京ドームシティ、サンシャイン60（六万分一）があります。 **</s>**
- llamaindexからRAGのベンチマーク
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/agent/openai_retrieval_benchmark.ipynb
	- OpenAIのRAGが、llamaindexの5行のコードに劣っていると、、、
- LLM OS
	- https://x.com/karpathy/status/1723140519554105733?s=20
	- Specs:
		- LLM: OpenAI GPT-4 Turbo 256 core (batch size) processor @ 20Hz (tok/s)
		- RAM: 128Ktok
		- Filesystem: Ada002
- ChatGPTは、コピーライターやデザイナーの雇用を奪うとともに、単価も下げている
	- 米国の最新研究は、ChatGPTの立ち上げから数カ月で、主要なオンラインフリーランスのコピーライターやデザイナーの仕事の数が大幅に減少し、収入も急激に減ったと報じている
	- https://www.ft.com/content/b2928076-5c52-43e9-8872-08fda2aa2fcf
	- 「6桁稼ぐ人は30000ドルしか稼がない人の3倍ダメージを受ける」
- Pattern Language for Generative AI book!
	- https://x.com/IntuitMachine/status/1722931733866143754?s=20
- ニューラルネットは経験した言語を一般化する能力があるか（１０月２５日 Nature オンライン掲載論文） - Lab BRAINS
	- https://lab-brains.as-1.co.jp/enjoy-learn/2023/11/55788/
- Jochen Wulf and Juerg Meierhofer, "Towards a Taxonomy of Large Language Model based Business Model Transformations"
	- https://arxiv.org/abs/2311.05288
	- LLMを利用したビジネスモデルについて実際のケースをもとに調査報告が発表されました。
		- 「新しい顧客メリットの創造」、「新しい販売チャネルの開拓」、
		- 「ビジネスプロセス自動化の加速」、「情報リソース利用の改善」
-  LlamaIndex の マルチモーダルRAG のしくみ by npakaさん
	- https://note.com/npaka/n/n53e8aabed0f2?sub_rt=share_sb
	- 「GPT-4V API」の導入により、「RAG」の概念をテキスト/画像のハイブリッドに拡張し、さらに大量の(画像を含む) データコーパスから価値を引き出す
	- SimpleDirectoryReaderの画像拡張
	- **MultiModalVectorIndex**の導入
- RAGにおけるドキュメント検索精度向上について(概要編)
	- https://zenn.dev/sompojapan_dx/articles/eb755a18e893ce
	- 損害保険ジャパン株式会社 DX推進部
	- ドキュメントに手を加える
		- **ドキュメント整形/chunking**、**要約生成**、**質問文の拡張**、**Knowledge Graphの活用**
	- 検索モデルに手を加える
		- **検索モデルのfine-tune**、**Re-rankingモデルの活用**
-  PromptNER: Prompt Locating and Typing for Named Entity Recognition
	- https://arxiv.org/abs/2305.17104v1
- 「アナロジア」のジョージ・ダイソンがLLMについて語る
	- https://www.hayakawabooks.com/n/n6b8cf31a9472
	- 大規模言語モデルはいわゆる言語の地図とも言えるものであり、いろいろなAIは、その地図を辿って有用な目的地までデジタル方式のアルゴリズムでナビゲーションをしているだけです。
	- こうした地図はまだ市販の画像処理用チップGPUでシミュレーションされただけのものですが、いずれこうした（言語ばかりかイメージやありとあらゆる事象を重みづけする）巨大なモデル専用のアナログチップが利用されるようになり、徐々に浸透していき現行のシステムに代わっていくと思います。
- 「アナロジア」ジョージ・ダイソンより
	- 連続体仮設はデジタル・コンピューティングも、アナログ・コンピューティングもどちらも無限の力を持つが、それぞれがどれだけ進化しても発揮する力が異なることを示唆している(P292)
	- アナログ・コンピューティングでは複雑性はコードでなくアーキテクチャに宿る。
	- デジタル・コンピュータは硬直化してノイズをに対する耐性を失ってしまった、アナログ・コンピュータである
	- アナログ・コンピュータはノイズを受け入れるばかりか、＜略＞機能するために一定の背景ノイズを必要とさえしている。(P295)
- 人工知能の三つの法則からみるAIの次にくるもの（ダイソン）(P299)
	- 「アシュビーの必要多様性の法則」、実効的な制御システムは対象と同じ程度複雑でなければならない
	- 「複雑なシステムの特徴を規定するのは、それ自身の最も単純な動作の記述だ」（ノイマン）、
	- 「理解可能な単純なシステムは、知的な振る舞いをするには複雑さが足らず、知的な振る舞いができるくらい複雑などんなシステムでも、理解するには複雑すぎる」
	- →自ら思考する人工知能は、人間の知性を理解するまでは、マシンが超人的な知能を持つことを心配する必要はないともいえるが、理解をせずに何かを作っていけないという道理もない。

## 11/6

今週は、RinnaのYouri 7Bの発表(10/31)、Japanese Stable LM Beta 70Bの発表(11/2)、同日CyberAgentLM2-7B（CALM2 -7B）の公開(11/2)等、日本語LLMの発表・公開が相次ぐ。あっという間に4bit 量子化モデルも公開されて手元で試せるように。。。70Bもびっくりするが、特にCalm2は3万2000トークン（日本語で約5万字）に対応していて、RAG不要かも。ColabでもA100ならば動かせるらしい。ソフトバンクのLLM開発始動や、NTTの日本語対応言語モデルのtsuzumiの発表、牧野先生が、MM-core専任？になるとの話題もあり、日本でもLLMのインフラが今後そろってくるのは楽しみ。日本語事前学習済みモデルをSimCSEって、LLM本(大規模言語モデル入門)で紹介されていたやつ。説明可能AIによるペロブスカイト太陽電池開発って、AIに説明させて人間が次を考えるという、AIと人との協調の新しい未来の形。LLM評価のサーベイ論文、後で読もう。 TinyLLaMa、どこまで小さくできるか、こういうアプローチいいなあ、本当に1.1Bでどこまでいける？LLMを利用したFAQ検索の評価データセット作成の工夫とか、LangChainのアプリテンプレートの公開とか、実用面に近い開発も進展あり。npakaさんの、LangChain、LLamaIndexの紹介記事、コンパクトで最新の情報なのでお得。ちょうど日経新聞で紹介された、岩波新書の『言語哲学がはじまる』、フレーゲ、ラッセル、ヴィトゲンシュタイン、もし彼らが今生きていたらLLMをどう研究したのか。XのGrok-1は次週に続くだな。

- FP8-LM: Training FP8 Large Language Model
	- https://arxiv.org/abs/2310.18313
	- Microsoftの研究チームによる論文。
	-  FP8自動混合精度フレームワークで、性能低下を抑えつつ ・BF16よりも64%速く ・メモリ使用量を42%削減し GPT-175Bをトレーニングできた
- ControlLLM: Augment Language Models with Tools by Searching on Graphs
	- https://huggingface.co/papers/2310.17796
	- (1) a task decomposer that breaks down a complex task into clear subtasks with well-defined inputs and outputs; 
	- (2) a Thoughts-on-Graph (ToG) paradigm that searches the optimal solution path on a pre-built tool graph, which specifies the parameter and dependency relations among different tools; and
	-  (3) an execution engine with a rich toolbox that interprets the solution path and runs the tools efficiently on different computational devices.
- ハーバード大学とBCGの研究によるとGPT-4の活用で仕事の精度は40%向上し、スピードも25%早くなったとのこと。この結果を見てもAIの使い方は益々、知的差別化の重要な要素となる。知的さはもはやAIと切り離しが困難な状態。こうした変化についていくためにも最新のAIを使いこなせる努力をしてほしい。
	- https://x.com/gijigae/status/1718851299524096284?s=20
- ChatGPT のアプリ版に Retrieval Augmented Generation (RAG)機能が追加？
	- https://x.com/yi_ding/status/1719028284548382901?s=20
- シリコンバレー銀行の破綻を、シンプルに解析するnotebookが公開。スタンフォード大学Professor Ashwin Raoによる
	- https://colab.research.google.com/drive/15uxrAeCCL327kWH9N0X-ogKwf2zErjP5
- Microsoft うっかりgpt-3.5が20b相当だと漏らす、
	- CodeFusion: A Pre-trained Diffusion Model for Code Generation
	- https://arxiv.org/abs/2310.17680
	- Microsoft paper claims ChatGPT 3.5 has ~20 billion parameters
- BlokeニキがStability AI Japan のモデルを4bit量子化
	- https://huggingface.co/TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ
- rinnaはLlama 2の日本語継続事前学習モデル「Youri 7B」シリーズを公開しました。 
	- https://rinna.co.jp/news/2023/10/20231031.html
	- ①Youri 7B：日英40Bトークンで継続事前学習 
	- ②Youri 7B Instruction：高いベンチマークスコア 
	- ③Youri 7B Chat：複数ターンの対話に強い 
	- GPTQ 4bit 量子化モデルも公開しています。
-  Google Colab で Youri-7B を試す by npakaさん
	- https://note.com/npaka/n/nccadcbcfe37e?sub_rt=share_sb
	- 複数ターンの対話モデル (GPTQ版)である「rinna/youri-7b-chat-gptq」を使います
- 多様な日本語事前学習済みモデルをSimCSEで文埋め込みモデルにfine-tuning
	- https://arxiv.org/abs/2310.19349
	- かなりいい感じの文埋め込みモデルができたと思うので、ぜひお使いください...！！
	- https://github.com/hppRC/simple-simcse-ja
- Youri 7B InstructionのGPTQモデルつかえば、GPUメモリ8GBでもローカルでLLM翻訳ができそうな気配
	- https://x.com/kis/status/1719284609761108462?s=20
- ソフトバンク、 国産大規模言語モデル（LLM）の開発を本格開始
	- https://www.softbank.jp/corp/news/press/sbkk/2023/20231031_01/
	- 2024年内に3,500億パラメーターの国産LLMの構築を目指します
-  Evaluating Large Language Models: A Comprehensive Survey
	- https://arxiv.org/abs/2310.19736
	- A comprehensive survey (100+ pages) on evaluating LLMs. 
	- ■「知識と能力」の評価 
		- ① タスク中心の評価から能力中心の評価へと移行している 
		- ② 評価ベンチマークはますます拡張されている
		- ③ ダウンストリームタスク間の区別があいまい 
		- ④ モデルの能力を総合的に評価する新しいアプローチが必要 
	- ■アライメント（ガイドライン）の評価 
		- ① 人間の価値観との一致を評価する研究が増えている 
		- ② 倫理的な面も含めたモデルの進歩と応用が目指されている 
	- ■安全性の評価 
		- ① LLMの発展によるリスクに厳格な評価が必要 
		- ② 例えばバイアスの増幅、誤情報の拡散、プライバシーの侵害など 
		- ③ リスク評価と、対処アプローチが求められている 
	- ■特化型LLMの評価 
		- ① 特定ドメインやタスクに特化したLLMも存在 
		- ② 特化型モデルの評価には専門的アプローチが必要 
		- ③ 高度な知識や専門的な推論能力を持つモデルが期待されている
- LanChainから、様々なタスクにアプリテンプレが公開
	- https://blog.langchain.dev/langserve-hub/
	- LangChain Templates offers a collection of easily deployable reference architectures that anyone can use.
	- https://github.com/langchain-ai/langchain/tree/master/templates
- LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery
	- https://huggingface.co/papers/2310.18356
	- LoRAShear meticulously studies and proposes a dynamic fine-tuning schemes with dynamic data adaptors to effectively narrow down the performance gap to the full models.
- gguf版、japanese-stablelm-instruct-gamma-7b　実用 API サーバ・クライアント例
	- https://note.com/ai_meg/n/n0c449a877c6f?sub_rt=share_pb
	- 会話ログ、requestボディ-簡略化のためのデフォルト設定。llm()への生成時パラメータ追加など。
- Youri 7BをFastChatでChatGPT互換APIサーバとして動かして遊ぶ
	- https://qiita.com/takaaki_inada/items/fcb63da369b5bfd8a3cf?utm_campaign=post_article&utm_medium=twitter&utm_source=twitter_share
	- youri-7b-chatをfastchatでChatGPT互換APIでホストしてChatVRMでサクッと遊ぼう。prompt engineeringが効くのでsystem prompt設定画面で語尾やキャラクター設定できます
- Google Colab で Japanese Stable LM Beta 7B を試す by npakaさん
	- https://note.com/npaka/n/n49387d8a8af4?sub_rt=share_sb
	- 語彙拡張済み指示モデル「stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b 」を使います
- Generative AI for everyone	by Andrew Ng先生
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- Google Colabに、API keyを登録できる新機能が公開
	- https://x.com/GoogleColab/status/1719798406195867814?s=20
- 説明可能AIによるペロブスカイト太陽電池開発
	-  Discovering Process Dynamics for Scalable Perovskite Solar Cell Manufacturing with Explainable AI
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202307160
	- 成膜過程の動画やスペクトルデータからNNにより変換効率を予測、それに基づき解釈する手法を適用することで、プロセスと特性の新しい洞察につながったそうです。
- Efficient LLM inference on CPUs! 
	- https://huggingface.co/papers/2311.00502
	- NeurIPS'23の論文
	- Compatible with GGML yet better performance up to 1.5x over llama.cpp!
	- https://github.com/intel/intel-extension-for-transformers
- The Computational Lens: from Quantum Physics to Neuroscience
	- 計算機的な視点を用いて、量子物理学から神経科学に至るまでの分野を研究したハーバード大学の博士論文
	- https://arxiv.org/abs/2310.20539
- Japanese TinyLLaMa 1.1 B, llama.cpp で wasm でブラウザでも動く
	- https://github.com/lighttransport/japanese-normalizer-cpp
	- https://x.com/syoyo/status/1719646103891845438?s=20
-  LLMを利用したFAQ検索の評価データセットの作成〜その２〜
	- https://www.ai-shift.co.jp/techblog/3761
	- 「1.  FAQの回答内容から質問内容を抽出」をベースに、生成時のpromptの工夫について取り組んだ
- calm2で議事録をまとめてみました。AI時代の知的財産権検討会（第１回）
	- https://x.com/alfredplpl/status/1720005676829970472?s=20
	- https://www.kantei.go.jp/jp/singi/titeki2/ai_kentoukai/kaisai/index.html
	- 主張1: AIによって生成されたコンテンツも含まれるべきである。 
	- 主張2: AIによって生成されたコンテンツは、人間によって創作されたコンテンツと同等に保護されるべきである。 
	- 主張3: 著作権を侵害する行為には、AIによって生成されたコンテンツも含まれるべきである。 
	- 主張4: 収益還元法については、AIによって生成されたコンテンツも適用範囲に含まれるべきである。
-  Google Colab で CALM2 を試す by npakaさん
	- https://note.com/npaka/n/n443e3ea8d0b8?sub_rt=share_sb
	- チャットモデル「cyberagent/calm2-7b-chat」を使います。
- CALM2-7B-chatのSpaceを作りました
	- https://huggingface.co/spaces/hayas/CALM2-7B-chat
- llamaとllama2の違い by NTT 西田さん
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
- 日本語DeBERTaV2モデルを公開しました！
	- 形態素解析器の事前の単語分割なしで使えるbase, smallモデルになっています
	- https://huggingface.co/izumi-lab/deberta-v2-base-japanese
- なんと、japanese-stablelm-instruct-beta-70B-GGUF
	- TheBloke/japanese-stablelm-instruct-beta-70B-GGUF
	- ggufのくせに40Gもあるよ、まったく
- OpenChat3.5
	- https://huggingface.co/openchat/openchat_3.5
	- gpt-3.5に迫る？？
- マルチモーダルのKOSMOS-2を取り込んだtransformerの更新！ by huggingface
	- KOSMOSのでもはこちら
		- https://huggingface.co/spaces/ydshieh/Kosmos-2
- Text generation web UIをつかって、cyberagent_calm2-7b-chat
	- https://x.com/StelsRay/status/1720137767857029444?s=20
	- モデルのLoad時にuse_fastがONじゃないと動かない点が罠だった！
-  LangChain クイックスタートガイド - Python版　 by npakaさん
	- https://note.com/npaka/n/n0fd7bd3ed27b?sub_rt=share_sb
	- 11/4版なので、整理されているし、「**LCEL**」(LangChain Expression Language)なんかよく分かった
- Idempotent Generative Network
	- https://assafshocher.github.io/IGN/
	- 拡散モデルではない新しい生成モデルがGoogleとUC Berkeleyから出たようだ。ノイズ除去というよりか分布を1stepで変換できるモデルことを仮定するらしい
- CALM2のGPTQ版が正常動作するようになりました。VRAMが少ない方は是非お使いください。
	- https://huggingface.co/mmnga/cyberagent-calm2-7b-chat-GPTQ-calib-ja-1k
-  CALM2で長い文章をまるごと取り扱う
	- https://note.com/alfredplpl/n/n5ed2ea2b78ec?sub_rt=share_sb
- 『責任あるAI: 「AI倫理」戦略ハンドブック』
	- https://x.com/abenben/status/1720750416361877680?s=20
- 【Calm2-7b】サイバーエージェントの最新LLMが優秀すぎたので、ChatGPTと比較レビューしてみた
	- https://weel.co.jp/media/cyberagentlm2-7b
-  Othello is Solved
	- https://arxiv.org/abs/2310.19387
	- PFNから、弱問題として解けたという話、双方最善手の結果は引き分け
-  LlamaIndex v0.8 クイックスタートガイド - Python版
	- https://note.com/npaka/n/nd449d5190431?sub_rt=share_b
	- 「LlamaIndex」は、プライベートやドメイン固有の知識を必要とする専門知識を必要とする質問応答チャットボットを簡単に作成できるライブラリです。
- シンガポールの首相は、C++で数独ソルバーを公開している	
	- https://t.co/rWig2ugILa
- CALM2-7Bをベンチマークする(11/5追記)
	- https://note.com/shi3zblog/n/n8b9ff5ea62bf?sub_rt=share_sb
- 今の高校では『情報Ⅰ』という科目ができて、ITパスポート相当のことを学んでいる→”高卒相当”のレベルが上がっているという話
	- https://togetter.com/li/2253207
- ＢＸストラテジー　実践行動経済学2.0 人を動かす心のツボ
	- https://www.amazon.co.jp/dp/4296115758?ref_=cm_sw_r_cp_ud_dp_BM2H3QZ9AHNCYW8F2ZY7
	- 企業経営の現場でどのように行動変容を促せばよいのかという知見が体系的に整理されており、法則や理論を寄せ集めたこれまでの事例集的な行動経済学本とは一線を画す良書でした。
- Xから、Grok発表, Elon’s new LLM.
	- https://x.com/xai/status/1721027348970238035?s=20
	- 330億パラメータGrok-0（LLaMA 2 (70B) の機能に近づき、トレーニングリソースの半分しか使用しない）を元にGrok-1を開発。
	- Grok-1 は GPT3.5や Inflection-1を標準的なベンチマークで超える。
- CALM2-7Bの性能を他の日本語LLMと比較してみた
	- https://note.com/it_navi/n/n35e5fac2b3d3?sub_rt=share_pb
	- CALM2-7B-Chatは、一度に**3万2000トークン（日本語で約5万字）**の長文の入出力に対応
	- **CALM2-7B-Chat**の回答を**ELYZA-japanese-Llama-2-7b-instruct**及び**Youri-7B-chat**の回答と比較
	- 論理的思考力については、**3種類の日本語モデルの回答は五十歩百歩**で大差ありません。ChatGPT（GPT-3.5）の性能とは、まだ相当差があるようです
- 『言語哲学がはじまる』野矢茂樹著
	- https://www.iwanami.co.jp/book/b633363.html
	- 日経の書評(11/4朝刊)掲載
	- 言葉とは何か。この問いにフレーゲ、ラッセル、ウィトゲンシュタインはどう挑んだのか。とびきりたのしい言語哲学の説き語り
	- 単語単独で意味を持つのか、文章の中の関係性として意味を持つのか、LLMは何を見ている？
- 牧野先生、PFN開発のMN-core開発に注力
	- https://jun-makino.sakura.ne.jp/articles/future_sc/note161.html
	- 神戸大とPFNのクロスアポイントメントだそうだ、
	- 「今後は社員として直接MN-Core の 開発に関わる」、「普及といったことを含めてMn-Core の 開発が本格化している」

## 10/30

新しいLLMがどんどん発表される。「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」、7BのLLMの覇者は、Mistral 7Bという話題もあったが、ReActをこなせる7bは、Zephyr-7b-betaということらしい、日本語はどうか？OSSのLLMで構造的な出力(Pydantic)を出すにはファインチューニングが有効らしい。text-to-SQLもファインチューニングが有効とのこと。心の理論(TOM)も、心理学のVoE理論の応用とかがあった。LLM の ベンチマーク、いろいろ紹介されるが、自動評価の結果がレーダーチャートで可視化されるMT-Benchが良いかも。既存の概念を組み合わせるsystematic compositionalityの能力をニューラルネットが持つことができるってのは、これはメタファー理論による認知の仕組みの解明が一歩現実に近づいたのか。Prompt によるLLMへの指示を超えるという、LLM programはは、分割統治というか、アンサンブルというかそういう感じ。MicrosoftのAgent Frameworkって前からあったような気もするが、なぜ注目？Hinton先生とLecum先生の議論がLLMの次を見据えた議論で面白い。限界は、ひょんなことから超えられてゆくという歴史もあるよな。FastChatで様々なLLMを試せて評価の幅が広がる、M-BenchもFastChat利用を想定しているのか。

- 7bのフルファインチューニングがcolabで動く？VRAM 32G程度で行けると
	- https://x.com/Sakkusakumura/status/1716158933319246289?s=20
- Character-LLM: A Trainable Agent for Role-Playing
	- https://aiboom.net/archives/57223
	- 特定の人物、例えばベートーヴェンやクレオパトラなどの行動や感情を模倣させるよう訓練する新しいフレームワーク『Character-LLM（キャラクターLLM）』
	- 訓練されたLLMは、特定の人物としての行動や感情を効果的に模倣できることが確認されました。
-  Progressive3D: Progressively Local Editing for Text-to-3D Content Creation with Complex Semantic Prompts
	- https://cxh0519.github.io/projects/Progressive3D/?ref=aiartweekly
	- Progressive3D brings region specific object manipulation through text with a DALL-E 3 like level of prompt understanding to the table.
	- ３Dモデルに対して、様々な加工を言語で行う
- Courtland Leer et al., "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models"
	- https://arxiv.org/abs/2310.06983
	- 「心の理論（Theory of Mind）」をメタ認知能力をつかって向上できる。
	- 心理学における「Violation of Expectation（期待違反）：VoE」理論を適用
- llamaindexがつかう、すべてのプロンプトを表示・カスタマイズできるI/Fが公開
	-  Accessing/Customizing Prompts within Higher-Level Modules
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompt_mixin.ipynb
- LangChainから、アドバンスなRAGでもある、"Query Transformation"
	- https://blog.langchain.dev/query-transformations/
	- 質問のほうを変換するとな？
- llamaindexで、HuggingFaceのLLMを活用するライブラリが拡張された(会話、テキスト生成、など）
	- you can now plug any `conversational`, `text_generation`, `feature_extraction` endpoints 
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/llm/huggingface.ipynb
- Finetuning LLaMa + Text-to-SQL
	- https://github.com/run-llama/modal_finetune_sql
	- how to fine-tune Llama2 for better text-to-SQL + easily plug into your LLM app, ordered from easy to hard:
	- text-to-SQLで最も性能が良いのは、GPT-4/3.5でも、llamaでもファインチューニングすればどうにかなる。このファインチューニングの手法の様々を紹介、
- State of Open Source AI Book - 2023 Edition
	- https://book.premai.io/state-of-open-source-ai/
	- 当然本自身もOpenSoruce
	- https://github.com/premAI-io/state-of-open-source-ai
-  ComfyUI-LCMによるVid2Vidの高速変換を試す(Latent Consistency Models)
	- https://note.com/bakushu/n/nec4cee4f4f37
	- Latent Consistency Models（LCM）は、最小限のステップ数で迅速に推論できる新たな画像生成モデル
	- Google Colabの標準GPU（VRAM 16GB）で試したところ、512x512サイズの120フレームの動画変換で1分弱。1024x1024サイズの120フレームの動画変換だと12-13分ほどでした。
-  AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation
	- https://arxiv.org/abs/2308.08155
	- https://microsoft.github.io/autogen/
	- マイクロソフト謹製のAgentフレームワーク、前からあったような気もするが。
- Top AI Shops Fail Transparency Test
	- https://spectrum.ieee.org/ai-ethics#toggle-gdpr
	- Stanford transparency index rates Meta, OpenAI, and others on 100 indicators
	- The highest total score goes to Meta’s Llama 2, with 54 out of 100.
-  llm-jpをColabで試す
	- https://note.com/alexweberk/n/n6b26b324904c?sub_rt=share_pw
	- 「jaster を含むものは回答がそっけない」らしいので、それを除いたテスト
	- 流石日本語特化のモデルだけあって日本語は自然な形で生成できました。日本に関する基本的な知識も備えているのは嬉しい
-  LLM の ベンチマーク まとめ by npakaさん
	- https://note.com/npaka/n/ndec10f78fe2f
	- 人間を評価者としたベンチマーク、 GPT-4を評価者としたベンチマーク、QAデータセットによるベンチマーク、コード生成のベンチマーク、埋め込みのベンチマーク、 ロールプレイのベンチマーク
	- 現状で自動評価可能な最良のアプローチはGPT-4を評価者とする方法。ただしコストなど課題がある
- MiniGPT-V
	- https://note.com/ai_meg/n/n748acc8e824b
	- MiniGPT-4のAPIを実装する。　プログラムでマルチモーダルを自由に操作する。
-  Google Colab で Japanese Stable LM Gamma 7B を試す by npakaさん
	- https://note.com/npaka/n/n4f2d6e6c11f7?sub_rt=share_b
- 日本語大規模言語モデル「Japanese Stable LM 3B-4E1T」「Japanese Stable LM Gamma 7B」
	- https://ja.stability.ai/blog/japanese-stable-lm-3b-4e1tjapanese-stable-lm-gamma-7b
	- 約30億と70億のパラメータを持つこれらのモデルは、日本語タスクの性能評価でトップクラス
	- 3Bと7Bのサイズでそれぞれ圧倒的性能を誇る英語LLM「Stable LM 3B-4E1T」「Mistral-7B-v0.1」に継続事前学習を適用することでサクッとめちゃツヨ日本語LLM
-  Japanese research is no longer world class — here’s why
	- https://www.nature.com/articles/d41586-023-03290-1?error=cookies_not_supported&code=dd59d16e-8d54-49a4-95a3-8fcded36917f&utm_medium=Social&utm_campaign=nature&utm_source=Twitter#Echobox=1698226936
	- nature記事より
	- **資金不足と時間不足**、**若手研究者の不満と減少**　が指摘されている。
-  Branch-Solve-Merge Improves Large Language Model Evaluation and Generation
	- https://arxiv.org/abs/2310.15123
	- Promptを超えた？LLM自身をアルゴリズムの一部に埋め込んで使うような、LLM programと呼ばれるような手法
- Large Language Model Programs
	- https://arxiv.org/pdf/2305.05364.pdf
	- LLMをアルゴリズムに埋め込むことをLLM Programとと呼ぶらしい、分割統治なんかそうなんだけど、メタなLLMみたいな感じ
-  LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions
	- https://arxiv.org/abs/2310.14029v1
	- 結晶構造をテキスト化して言語モデルで学習、そのエンコーダを使って物性予測を行うと従来のSOTAであるGNNモデルより高精度な予測
-  LangChain の Step-back Prompting を試す by npakaさん
	- https://note.com/npaka/n/n55f276ad2988?sub_rt=share_sb
	- (1) ユーザーの元の質問に基づいて、ステップバック質問を生成  
	- (2) 元の質問とステップバック質問の両方を情報収集  
	- (3) 取得した両方の情報に基づいて回答を生成
- mmnga/japanese-stablelm-instruct-gamma-7b-gguf
	- stabilityAIさんが公開されているjapanese-stablelm-instruct-gamma-7bのgguf
	- Mistral-7bの日本語版で、AIのべりすとさんから提供された高品質なデータが入っている
- フィールズ賞受賞者のテレンス・タオさんが、証明支援系Leanを使うことで自分の論文の中のバグ（ミス）に気づいたという話
	- https://mathstodon.xyz/@tao/111287749336059662
	- 定理証明系が実数学者のためになっているのか。。。
-  KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval
	- https://huggingface.co/papers/2310.15511
	-  (e.g., 'a list of ice cream shops in San Diego')
-  LLMのプロンプト技術まとめ
	- https://qiita.com/fuyu_quant/items/157086987bd1b4e52e80
-  Zephyr: Direct Distillation of LM Alignment
	- https://arxiv.org/abs/2310.16944
	- なんかすごい性能らしい。
-  Human-like systematic generalization through a meta-learning neural network
	- https://www.nature.com/articles/s41586-023-06668-3
	- 既存の概念を組み合わせるsystematic compositionalityの能力を、メタ学習を施したニューラルネットで実現。35年前のFodor＆Pylyshynの「ニューラルネットはcompositionalityを持てない」との主張への応答として書いている
-  MT-Bench の使い方 by npakaさん
	- https://note.com/npaka/n/na28f31e96599?sub_rt=share_b
	- 「[**MT-Bench**](https://chat.lmsys.org/?leaderboard)」は、80の高品質でマルチターンの質問を含む、慎重にキュレーションされたLLMのベンチマークです。
	- レーダーチャートででるのがよい。
-  7BのLLMの覇者は、Mistral 7B ？？
	- https://www.promptingguide.ai/models/mistral-7b
- Getting started  with Llama by Meta
	- Meta謹製のLlmaガイド
	- https://ai.meta.com/llama/get-started/
	- Yann LeCun先生のおすすめでもある。
- bakLLaVA vision AI can read xrays with only 6Gb of RAM
	- https://github.com/SkunkworksAI/BakLLaVA
	- OSSのLLMでがん画像検診ができる？
- Zephyr-7b-betaって無敵かも
	- https://colab.research.google.com/drive/1UoPcoiA5EOBghxWKWduQhChliMHxla7U?usp=sharing
	- found it’s the only 7B LLM that can handle ReAct agent tasks over data
	- つまり、dataに対して、ReActするAgentを実装できる唯一の7B LLMということらしい
	- Jelly Liuさん(llamaindex作者)も激賞
	- https://x.com/jerryjliu0/status/1718054817640390840?s=20
-  Evaluating RAG pipelines with Ragas + LangSmith
	- https://blog.langchain.dev/evaluating-rag-pipelines-with-ragas-langsmith/
	- RAGの性能評価をRagasとLangSmithで行う方法を紹介した記事
	- RagasはLLMによるRAGの自動評価を支援するOSS、試したけどお金かかるんだよな。
- llama2 7bをファインチューニングすることで、出力を特定フォーマットにすることができる
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/gradient/gradient_structured.ipynb
	- structured Pydantic objectsを出力する
- 帝人の統合報告書2023に掲載されている特許情報分析。ポートフォリオの変化について、テキストマイニングによる全体俯瞰と特許価値評価の2つのアプローチで可視化
	- https://ssl4.eir-parts.net/doc/3401/ir_material_for_fiscal_ym1/141477/00.pdf
- Hinton先生の、新しいLLMの開発（たぶんOpenAI)に対する危惧に対して、Lecum先生は、どうせ今のAuto-Regressive LLMの延長線上の開発なので、限界は自明い。真に必要なAIは、、と反論。
	- https://x.com/ylecun/status/1718263303485501784?s=20
	- Objective-Driven AI architecturesが必要とのこと
- Advanced Prompt Engineering for RAG by llamaindex
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/prompts/prompts_rag.ipynb
	- 基本的なRAGから、few-shot追加したり、context変換したりという話題
- Stability AI の Japanese MT-Bench を試した
	- https://x.com/npaka123/status/1718403656725483961?s=20
- Demystifying Advanced RAG Pipelines
	- https://github.com/pchunduri6/rag-demystified
-  Chatting With Your Data Ultimate Guide
	- https://medium.com/aimonks/chatting-with-your-data-ultimate-guide-a4e909591436
-  MT-Bench による日本語LLMの評価 by npakaさん
	- https://note.com/npaka/n/n0530f6f9123f?sub_rt=share_sb
	- 「Stability AI」が提供する**「Japanese MT-Bench」の質問ファイル**と**参照回答ファイル**を使う
	- 評価するモデルは、FastChatが対応している必要があります。

## 10/23

今週は、NIIからllm-jp-13b-v1.0が公開されたのが話題でした、さっそくcolabで使った例が公開されたり、4bit量子化版がhuggingfaceで公開されたりと、盛り上がってます。関係者の努力とABCIの活躍に頭が下がります。LLM活用アプリの性能を考えるときに、RAGでもそうなんだけど、LLMとembeddingの組み合わせをちゃんと評価するってのが最初にあるべきなのかも。使ったことないけどもReplicateはそこんところうまくついたサービス展開といえる。LLMをソフトウエアエンジニアリングで活用できるという論文が話題に。OpenAI、限りなくAGIに近いとうわさのArrakisの開発断念？映画Dune２(Arrakisという星が部隊）の公開も春にずれ込んだから、似たような運命をたどるのか？マッキンゼーのレポート、生成AIにより、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しというのは驚いた、つまり我々は25年先の技術を今見ていることになる、そりゃ（多くの人にはLLMの凄さが）分らんわな。スタンフォード大の「科学論文の査読」に、大規模言語モデル（LLM）が有用であるという論文、これは朗報だ（誰得？）。「kaggle LLMコンペ　上位解法のまとめ」はこれはLLMプラクティショナーには必読だ。ちゃんとコンテキストを適切に与えることが重要。あたりまえだけど、それを行うのは難し。「世界モデル」に対するOpenAI共同設立者のIlya Sutskever氏の対談、大規模深層学習モデルは言葉を生成する何等かの表現（つまり世界モデル）を学習し、これから漏れ出るものがテキストであると言っている（ナウシカの「墓所の主」みたいなものか）。LLMの因果推論能力のベンチーマーク、fine-tuningすると性能はあがるが、少し表現を変えると性能が爆下がりって！、それがLLMなのよ！最新の言語理論である「ジェスチャーゲーム」で人間の言語能力が身についたとすると、LLMが示すテキスト生成能力は何？？Ilya Sutskever氏の対談の話と真っ向から対立する感じ。「言語ゲーム」といえばヴィトゲンシュタイン、ウィトゲンシュタイン研究を専門とする大谷先生の対話記事によると。LLMと言語ゲームって似たところがあるそうだ。なんか、楽しくなってきた。

- Ilya Sutskever氏LLMと世界モデルについて語る with Jensen Huang, CEO of Nvidia:
	- https://twitter.com/i/status/1713368556618887670
	- OpenAIの共同設立者であるIlya Sutskever氏とNvidiaのensen Huang社長との対談より
	- （巨大な）ニューラルネットが学んでいるのは、テキストを生成する「何か」に対する表現を学んでいる。その「何か」とは世界モデルであり、それが射影されたものが生成されたテキストなのである。
- Jonas Belouadi et al., "AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ"
	- https://arxiv.org/abs/2310.00367
	- LLMを活用し人間のように科学的な図を生成するツール『AutomaTikZ』
	- テキストから科学的なベクターグラフィックスを生成する 
	- LLaMAをDaTikZデータセットで微調整
-  Can Large Language Models Infer Causation from Correlation?
	- https://arxiv.org/abs/2306.05836
	- https://ai-scholar.tech/articles/large-language-models/llm_causal_inference_skill
	-  LLMに因果推論能力はあるか？
	- 大規模言語モデルの因果推論能力をテストするベンチマークデータセットを提案  
	- 17の既存の大規模言語モデルを評価  
	- 現状のモデルは因果推論能力が低いことがわかった
	- fine-tuningにより性能向上が見られる一方で，少し表現を変えただけで性能が下がる現象も見られる
- Yijun Tian et al., "Graph Neural Prompting with Large Language Models"
	- https://arxiv.org/abs/2309.15427
	- LLMにナレッジグラフ（知識グラフ）を連携させることで、タスク遂行能力を大幅に向上させるフレームワーク『Graph Neural Prompting（GNP）』
	- GNPは、LLMに有益な知識を効果的にエンコードし、パフォーマンスを大幅に向上させることができる
- 大規模言語モデルがどのように動いてるかを視覚的に説明するインフォグラフィックが素晴らしいと
	- https://ig.ft.com/generative-ai/
	- Fanatical Timesのインフォグラフィック
- Large Language Models for Software Engineering: Survey and Open Problems
	- https://arxiv.org/abs/2310.03533
	- LLMをソフトウエアエンジニアリング(SE)にどうやって適用するか？
	- 要求エンジニアリング/デザイン、コード生成、テスト、運用/デプロイ、ドキュメント生成。またリサーチ領域での活用なども
	- 伝統的なSEとLLMを融合したはハイブリッドにより信頼ある効率的なLLMベースのSEが実現できた
- JapaneseEmbeddingEval　日本語におけるembeddingの評価
	-  https://github.com/oshizo/JapaneseEmbeddingEval
	- multilingual-e5っていい線いってるのか。。
- PaLI-3 Vision Language Models: Smaller, Faster, Stronger
	- https://huggingface.co/papers/2310.09199
	- Googleによる、高性能で小さいvision language model (VLM)
- マッキンゼーから発表されたAI動向に関するレポートがなかなか衝撃的
	- https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-AI-the-next-productivity-frontier#introduction
	- 生成AI（というかChatGPTに代表されるLLM)の登場により、AIの作文力が人間の上位25%を超える時期の予測が25年前倒しになった
		- 2017年の予測：2050年 ・2023年の予測：2024〜2025年 
- Xinyun Chen et al, "Teaching Large Language Models to Self-Debug"
	- https://arxiv.org/abs/2304.05128
	- GPT-4などLLMのコード生成能力にデバッグ機能を追加する『SELF-DEBUGGING（セルフデバッギング）』
	- LLMに自己デバッグの能力を教えることで、コード生成の性能が向上する
- ChatGPTを用いてコーディングを学ぶ方法について（慶応義塾大学）
	- https://speakerdeck.com/keio_smilab/keio-univ-intro-to-ml-02-coding
	- なんと、学生向けに、ChatGPTを用いてPythonなどのコーディングを学ぶという授業が、、
	- ChatGPTネイティブな学生は、ChatGPTでコーディングを学ぶのか。。
- Andrew Ng先生から、deeplearning.aiの「生成AI」の講義の宣伝
	- https://www.deeplearning.ai/courses/generative-ai-for-everyone/
- OpenAI、次世代LLMである、Arrakisの開発を断念？
	-  OpenAI Dropped Work on New ‘Arrakis’ AI Model in Rare Setback
	- 限りなくAGIに近いとうわさされる次世代のLLM、
	- どううも開発中（学習中）の性能評価で思ったほど性能が出なかったため。
	- https://www.theinformation.com/articles/openai-dropped-work-on-new-arrakis-ai-model-in-rare-setback
- llamaindexのLiuさんより、“Evaluation Driven Development” (EDD)の提案
	- https://x.com/jerryjliu0/status/1713936561480610104?s=20
	- まずは、LLM＋Embeddingの組み合わせをちゃんと評価するところから始めようみたいな。
- Replicateを利用すると、任意のLLMとembeddingの組み合わせを簡単に評価できる
	- https://replicate.com/explore
	- つまりhuggingfaceのモデルをダウンロードして動かす手間を、少し省くサービスを提供、
	- ナイスだな。
- NIIから、LLM-jp-13B が公開される
	- LLM-jp （LLM 勉強会）は、日本語と英語を中心に事前学習した130億パラメータの大規模言語モデルをオープンなライセンスで公開
	- https://llm-jp.nii.ac.jp/release/
	- インストラクションデータでチューニングしたモデルや訓練・チューニングに用いたソフトウェアも公開
- データでできることのレベル感を理解する（デジタル庁の人のスライドより）
	- https://speakerdeck.com/hik0107/data-design-and-government?slide=10
	- 現状の把握(lv.1)、分解と差異の把握(Lv.2)、原因の把握(Lv.3)、対策の把握(Lv4)
-  Google Colab で LLM-jp-13B を試す by npakaさん
	- https://note.com/npaka/n/n60b0abf54ed5?sub_rt=share_sb
	- T4 ハイメモリで動作確認
	- 早速試されている
- BEYOND MEMORIZATION: VIOLATING PRIVACY VIA INFERENCE WITH LARGE LANGUAGE MODELS
	- https://arxiv.org/pdf/2310.07298v1.pdf
	- Redditの匿名ポストのテキストから、GPT-4はその人のプロファイル（収入、性別、住所）を85%の正確さで、かつ人間の1%のコストで当てた。。
	- A paper that really illustrates both the unexpected power, and unexpected risks, that come from LLMs.
-  InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining
	- https://arxiv.org/abs/2310.07713
	- pre-train LLMs with Retrieval Augmentation
-  An Emulator for Fine-Tuning Large Language Models using Small Language Models
	- https://huggingface.co/papers/2310.12962
	- Emulator for Fine-Tuning(EFT)は、大規模な事前学習済みモデルを小規模な微調整済みモデルとアンサンブルすることで、大規模な事前学習済みモデルを微調整した結果をエミュレートするという、アップスケーリングが可能になった
-  Can large language models provide useful feedback on research papers? A large-scale empirical analysis
	- https://arxiv.org/abs/2310.01783
	- 「科学論文の査読」に、大規模言語モデル（LLM）が有用な可能性がある
	- 米スタンフォード大らが検証　参加者の80％以上「AI査読は有益」
	- https://www.itmedia.co.jp/news/articles/2310/19/news072.html
	- Nature系列のジャーナルにおけるフィードバックの結果、GPT-4が提供したコメントの57.55％は、全体の査読者の中で少なくとも1人の人間の査読者が記載していた
- A quantized version of the mistral that is instruction following over 32k tokens.
	- https://huggingface.co/TheBloke/MistralLite-7B-AWQ
	- mistralって性能がよいと先週評判になってたやつの、4bit量子化版が公開？
- llm-jp-13b-v1.0も早速GPTQ版が公開される
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-4bit-g128-GPTQ-calib-ja-1k
	- llm-jp-13b-v1.0を、 日本語のキャリブレーションセットで生成したGPTQモデル
-  言語はこうして生まれる―「即興する脳」とジェスチャーゲーム―
	- https://www.shinchosha.co.jp/book/507311/
	- 言語の生得性を否定し、文化進化や語用論的な観点から言語獲得を論じています
	- 歴史：ノーム・チョムスキーは「普遍文法」という概念を導入し、「人間の遺伝的青写真には、言語を支配する抽象的な数学的原理が内包」しているといった
	- 歴史：心理学者スティーブン・ピンカーがさらに『言語を生みだす本能』（NHKブックス）へと発展させる
	- 主張：「ジェスチャーゲーム」。言語は遺伝的に決定されたものなどではなく、身振り手振り、発声、あるいはその両方で自分の意思を双方向的に伝え合うジェスチャーゲームのようなものが起源なのではないかという斬新なアイデアだ。そこには普遍文法が入り込む余地などない。
- LLM（大規模言語モデル）は「言語ゲーム」的か  東京女子大学現代教養学部准教授・大谷弘氏に聞く（１）
	- [IT批評の記事](https://it-hihyou.com/recommended/llm%EF%BC%88%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%89%E3%81%AF%E3%80%8C%E8%A8%80%E8%AA%9E%E3%82%B2%E3%83%BC%E3%83%A0%E3%80%8D%E7%9A%84%E3%81%8B-%E2%80%95/)より
	- LLMって、パターンから学び、その背後には人間があるから、ヴィトゲンシュタインのいう「言語ゲーム」に似ている、らしい。記号接地してないという批判にも、学習データの背後の人間のあたりで接地しているのかもともいう。
- 多様体上の最適化理論
	- https://www.amazon.co.jp/exec/obidos/ASIN/4274231186?&linkCode=sl1&tag=mathlang09-22&linkId=bd145734052442298eb01413d823ca91&language=ja_JP&ref_=as_li_ss_tl
	- 多様体上の最適化理論について、基礎となる数理から応用例までを解説
-  Introducing CliffordLayers: Neural Network layers inspired by Clifford / Geometric Algebras.
	- https://www.microsoft.com/en-us/research/lab/microsoft-research-ai4science/articles/introducing-cliffordlayers-neural-network-layers-inspired-by-clifford-geometric-algebras/
	- MS研究所から、クリフォード代数にインスパイアされた新しいNNレイヤの発明
-  OpenAgents: An Open Platform for Language Agents in the Wild
	- https://arxiv.org/abs/2310.10634v1
- llamaindexより、Unifying Text-to-SQL and RAG with our SQLRetrieve
	- https://docs.llamaindex.ai/en/latest/examples/index_structs/struct_indices/SQLIndexDemo.html
	- SQLデータベースに対して、RAGを行うRetriverについて、動いたぞ、役に立つぞ。
- kaggle LLMコンペ　上位解法まとめ
	- https://zenn.dev/yume_neko/articles/7347ba6b081e93
	- 科学分野の5択問題を解くLLMの精度を規則コンペのべスプラ
	- 今回のコンペで上位に行くにはRetrievalが最もキーだったように思います。やはり正解情報を直接参照できるので、contextをより良くすることが重要だったのではないかと思います。
- llama2のpretrainingを試す
	- https://zenn.dev/if001/articles/6c507e15cd958b
	- 小さいサイズのllama2を日本語でpre_trainingしてみます
	- pre_trainingからhuggingfaceへのuploadまでを行ってみました。
	- 小さいサイズであればgoogle colabで学習できる
- llm-jp-13b-v1.0-gguf
	- https://huggingface.co/mmnga/llm-jp-13b-v1.0-gguf
	- llm-jpさんが公開しているllm-jp-13b-v1.0のggufフォーマット変換版
	- ブランチらしい、LLama.cppが、なんかの変更を行うとggufが動かなくなるらしい、怖っ

## 10/16

RAGシステムの性能向上は依然もりあがっている。StanfordのDSpy、どうもLLMのプロンプト利用を別の次元に引き上げる画期的な開発のように見えるが追いつけない。RAGとFinetuningを組み合わせることによる性能向上がいままで抜けていたとは。LLMの心の理論(ToM)についての論文では、他人の心の状態の推定というのが肝なのか。zephyr-7b-alphaとか、Japanese StableLM Instruct Alpha v2 とか、ローカルで使いものになるLLMもどんどん出てきた。スタンフォードAIの、State of AI Report 2023、 KaggleのAI Report 2023、それぞれの立場で最新のAIを取り巻く様々な視点をまとめてくれている。アナロジー（類推）でプロンプトを生成する「アナロジカル・プロンプティング」は、人間の手間を省けるか？組み込み(embeding)の違いによるRAG性能の違いの検証から、やっぱe5(intfloat/multilingual-e5-large)が当面最強なのか？PFNのインターン生の成果などがいくつか公開。それにしてもPFNのインターン生つよつよだろう、ちょっとうらやましい。DeepMindのYasunagaさんやエジンバラ大学のMatsubaraさんなどの日本人の活躍もちらほら。


- Large Language Models (in 2023)
	- https://docs.google.com/presentation/d/1636wKStYdT_yRPbJNrf8MLKpQghuWGDmyHinHhAKeXY/edit#slide=id.g2885e521b53_0_0
	- OpenAIのHyung Won ChungさんによるLLMの現状をまとめたスライド
	- The biggest progress in the past 10 years (or even more) can be summarized as
		- Create weaker inductive biases and scale up
		- Do not teach machines how we think we think. Let it learn in a machine’s way
- Masking PII Data in RAG Pipeline
	- https://betterprogramming.pub/masking-pii-data-in-rag-pipeline-326d2d330336
	- PII(Personal Identification Information)をマスキングする方法を、RAGにおいて行う方法
	-  LlamaIndexの NERPIINodePostprocessorを活用するのがみそ
- Jerryより、RAGシステムの性能向上に関する、様々な手法のブックマーク集
	- Evaluating the Ideal Chunk Size for a RAG System using LlamaIndex
		- https://blog.llamaindex.ai/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5
	- Building Performant RAG Applications for Production
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/dev_practices/production_rag.html
	- Multi-Document Agents
		- https://docs.llamaindex.ai/en/stable/examples/agent/multi_document_agents.html
	- Finetuning
		- https://docs.llamaindex.ai/en/stable/end_to_end_tutorials/finetuning.html
- Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models
	- https://arxiv.org/abs/2310.04406
	- Substantially improving over the existing prompting methods such as Reflexion, e.g., 68.1% -> 86.9% on HumanEval with GPT-3.5
- Ida Momennejad et al., "Evaluating Cognitive Maps and Planning in Large Language Models with CogEval"
	- https://arxiv.org/abs/2309.15129
	- 人間の測定法と似たフレームワークでLLMの認知機能を調査した論文
	- LLMの「認知マップ」と「計画能力」を評価。
		- 認知マップ：外部環境を内部に表現する機能 
		- 計画能力：目標に向かって計画を立てて遂行する能力
	- GPT-3.5、GPT-4、Bard、LLaMA-13Bなど
	- 結果
		- ① 認知マップの理解や計画能力は「箱から出してすぐに」は持っていない 
		- ② 認知マップの欠如が理由で計画タスクに失敗する可能性が高い 
		- ③ 新しい評価プロトコル（CogEval）は有望である 
		- ④ LLMのアーキテクチャやトレーニングには工夫の余地がある 
		- ⑤ LLMの認知機能を向上させるには、メモリ（記憶容量）の拡張などが有効
- FireAct: Toward Language Agent Fine-tuning
	- https://fireact-agent.github.io/
	- LLM AgentとFintuningの合わせ技についての検証、ReActの性能をfine-tuningで向上できた
	- FireAct is a novel way to finetune LMs w/ agent trajectories of a mix of tasks & prompting methods.
	- Fine-tuning >> Prompting:
		- Notably, small LMs benefit most --- Llama2-7B improves 77% after fine-tuning!
- Pei Zhou et al., "How FaR Are Large Language Models From Agents with Theory-of-Mind?"
	- https://arxiv.org/abs/2310.03051
	- LLMの「心の理論(ToM:Theory of Mind)」における能力を評価するフレームワーク『Thinking for Doing (T4D)』
		- ① 他者の心の状態（信念、願望、意図など）についてどれだけ効果的に推論できるか
		- ② 推論した上でいかに行動に移せるか
	- 従来の心理学的テストではLLMのToM能力の評価は十分には出来ないとされています。
	- 「Foresee and Reflect (FaR)」という新しいフレームワーク
		- ① 将来のイベントを予測（Foresee） 
		- ② それに対する行動を考慮（Reflect）
	- 「FaR」フレームワークと評価パラダイム「Thinking for Doing (T4D)」の組み合わせによって、効率的にLLMのToM能力を評価することができる
- 7 Query Strategies for Navigating Knowledge Graphs With NebulaGraph and LlamaIndex
	- https://www.nebula-graph.io/posts/Knowledge-Graph-and-LlamaIndex
	- NebulaGraph を使ってグラフ構造に対する、Q&Aを実現する方法について via Llamaindex
- StanfordのDSpyを用いることによる、Q&Aのファインチューニングが簡単になる？
	- https://x.com/lateinteraction/status/1712135660797317577?s=20
- KaggleのAI Report 2023
	- https://www.kaggle.com/AI-Report-2023
	- これはAIの現状に関するエッセイコンペの結果をまとめたもの、最新のAIを取り巻く様々な視点からの見方がわかる。
- HuggingFaceにおけるLLM評価で、zephyr-7b-alphaがChatLlama 70Bを上回る性能をだしたらしいのでllamaindexで確かめてみた
	- https://colab.research.google.com/drive/16Ygf2IyGNkb725ZqtRmFQjwWBuzFX_kl?usp=sharing#scrollTo=lMNaHDzPM68f
	- We found that it is the ONLY open 7B model atm that does well on advanced RAG/agentic task
- DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation
	- https://huggingface.co/papers/2309.16653
	- ここで３Dモデル作成を試せる、なんかすごいぞ。
		- https://huggingface.co/spaces/jiawei011/dreamgaussian
-  Multimodality and Large Multimodal Models (LMMs)
	- https://huyenchip.com/2023/10/10/multimodal.html
	- マルチモーダルモデルに関するサーベイ。重要論文としてCLIPとFlamingoを解説した上で、今後の方向性として他のモダリティの追加、出力のマルチモーダル化、ベンチマークの整備などを挙げている
- LongLLMLingua: Accelerating and Enhancing LLMs in Long Context Scenarios via Prompt Compression
	- https://arxiv.org/abs/2310.06839
	- Gains a performance boost of up to 17.1% on NaturalQuestions over the original prompt with ~4x fewer tokens
- MatGPT: A Vane of Materials Informatics from Past, Present, to Future
	- https://onlinelibrary.wiley.com/doi/10.1002/adma.202306733?af=R
	- **GPT AI**の出現は、科学研究分野が「データ」を基本要素とし、「アルゴリズム + 計算能力」を核心生産力とする知能文明時代に入ったことを示している。
	- 事前学習モデル、指向性設計モデル、協調学習、実験ロボットなど
- PFNのインターン発表： 遺伝⼦に関するグラフを利⽤したモデルの開発
	- https://tech.preferred.jp/ja/blog/model-learning-using-gene-graph/
	- RNAからProteinを予測するタスクにおいては、学習サンプル数が限られ、かつ使用できる特徴量が少ない状況においては、予測対象モダリティの制御に関与する特定のグラフ構造を用いることで性能の改善が認められました。
- サイバーエージェントがOpenCaml2を開発中らしい
	- https://aws.amazon.com/jp/blogs/news/open-calm-and-openai-chatgpt-accuracy-on-jaqket-experiment-in-amazon-sagemaker/
- RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation
	- https://arxiv.org/abs/2310.04408
	- LLMでのRAGの性能向上のために、2つの圧縮器(重要部分抽出・複数文書要約)を使うRECOMP法の提案。各圧縮器は学習させる必要有
- 機械学習波動関数？？
	- https://www.nature.com/articles/s41524-023-01130-4
	- 従来は1種類の構造しか訓練に使えませんでしたが、ハミルトニアンを対称性に基づくパラメータで記述することで様々な構造を訓練でき、転位がある約5000原子セルの電子状態予測を実現した
- Google Colab で Japanese StableLM Instruct Alpha v2 を試す by npakaさん
	- https://note.com/npaka/n/n0e463dbbce11?sub_rt=share_sb
	- 「Stability AI Japan」が開発した7Bパラメータの日本語LLM
	- 商用利用を制限しないデータセットのみを利用することで、同等レベルの性能を持つ**商用利用が可能**
	- Colab無料枠(T4)で動作する模様
- StanfordAIによる、 State of AI Report 2023
	- https://www.stateof.ai/2023-report-launch
	- OpenAIの**GPT-4**は、すべてのベンチマークや人間向けの試験において他のLLMを凌駕している。
	- Meta AIはオープン（な）AIのチャンピオンとして登場し、LLaMaモデルファミリーを最も強力な公開アクセス可能なOpenAI代替品となっている
	- LLMや拡散モデルは、特にライフサイエンス分野で実用的なブレイクスルーをもたらしてお
	- 生成AIが、低迷している、テック界隈のVCを救う。
	- 安全性はAI研究界で中心的なテーマとなり、世界中の政府や規制機関が対策を講じ始めた。
	- 標準的なLLMは頑健性に問題があり、最先端モデルの評価が困難になっている
- Michihiro Yasunaga et al., "Large Language Models as Analogical Reasoners"
	- https://arxiv.org/abs/2310.01714
	- 人間の「過去の類似事例」と「自らの知見」を組み合わせるアプローチに倣った、LLMの優れたプロンプトフレームワーク
	- LLMの推論能力を向上させるCoTは有用ですが、手間がかかります。 手動のプロンプト作業を少しでも軽減することが求められています。 
	- そこで研究者らは、人間のように自動的に知識を生成する「アナロジカル・プロンプティング」を発明しました。
- Hamiltonian Dynamics of Bayesian Inference Formalised by Arc Hamiltonian Systems
	- https://arxiv.org/pdf/2310.07680.pdf
	- エジンバラ大学の松原さんの論文
	- infinite-dimensional Hamiltonian system behind Bayesian inference.
	- ベイズ推論の裏に、無限次元のハミルトニアンシステムがあるという、、
- Zijun Liu et al., "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization"
	- https://arxiv.org/abs/2310.02170
	- 複数のエージェントに協力して仕事を開始させ、タスクの進行に応じて重要なエージェントを取捨選択する『Dynamic LLM-Agent Network（DyLAN）』フレームワーク
	- タスクに応じて動的にエージェントを選択する方式を考えました。
- LangChain を使った RAG における埋め込みモデルの比較
	- https://note.com/alexweberk/n/ncccfdab3f4bb
	- Wikipedia 記事を LangChain の CharacterTextSplitter を使って、４種類の埋め込みモデルを使ってベクトル化し、RAG による質問応答を試行
	- `intfloat/multilingual-e5-large` >= `pkshatech/GLuCoSE-base-jap` > `cl-nagoya/sup-simcse-ja-large` >= `openai/text-embedding-ada-002` というような感触
	- 4つの埋め込みモデルを使ったRAGを試してみました: 
		- intfloat/multilingual-e5-large 
		- cl-nagoya/sup-simcse-ja-large 
		- pkshatech/GLuCoSE-base-ja 
		- openai/text-embedding-ada-002
- OpenAI gpt-3.5-turbo と gpt-3.5-turbo-instruct モデルの違いについて
	- https://corp.langcore.org/media/chatgpt-instruct
	- gpt-3.5-turbo モデルは会話に秀でているので対話をさせるのであればこちらを使う方がよいです。
	- 会話以外のタスクの場合だと**一問一答のような単純な課題を解くケースでは gpt-3.5-turbo-instruct の方が期待する出力になる可能性**があります。
- Integrating Stock Features and Global Information via Large Language Models for Enhanced Stock Return Prediction
	- https://arxiv.org/abs/2310.05627
	- IJCAIでLLM(chatGPT)使った株価リターン予測の論文
	- LLMによるテキストの埋め込みと株式の特徴を同じsemantic spaceで配置させる強化学習の枠組みを導入している。
- Zhiyu Chen et al., "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting"
	- https://arxiv.org/abs/2310.07146
	- GPT-4をセラピストとして実行し、人々の「認知の歪み」を診断させるためのフレームワーク『Diagnosis of Thought (DoT)』
	- ① DoTは、「認知の歪み」評価と分類で高性能を示した 
	- ② GPT-4は、「認知の歪み」分類で特に高い性能を示した 
	- ③ 専門家によってGPT-4による本診断方法は「包括的である」と評価された（84.5%）
-  Large Language Models can Learn Rules
	- LLMがルールを学習できる？
	- https://arxiv.org/abs/2310.07064
	- LLMs can learn (sometimes uncommon) rules with 2 stages: (1) induction: generate and verify rules from exemplars; (2) deduction: utilize the rule library for new problems. 11-27% gain on reasoning tasks that require rule learning.

## 10/10

function callを含むLLMのファインチューニングをOpenAIが導入されたり、LLMのRAGに対するファインチューニングについての考察があったりと、性能面での評価を含めRAG関係は成熟してきた感じ。LLMがどれだけ論理的かという検証も「逆転の呪い」を例に行われているが、LLMが「物事がどのように位置づけられ、時間がどのように進行するかを理解」しているという実験はこれからのLLMを用いた複雑なタスクの開発に弾みでもある。マルチモーダルでは、早速GPT-4Vに対抗するOSSであるLLaVAが登場した、LLaVA-1.5はすでに試せる模様。スタンフォード大学がAIに関する多角的なデータのレポートすばらしい。OpenAIは、GPT-4Vに引き続き、DALL·E 3に対する品質カード(System Card)を公開、安全な画像生成をアピール。MSのDeepSpeedチームの科学的基盤モデルっても頑張ってるな、気象予想に使えそう。MicrosoftのH100 GPU対抗チップのATHENA、本当にやる気があるのか？


- 『逆転の呪い』:「AはBである」と学習したLLMは、「BはAである」と学習しづらくなる。
	- https://arxiv.org/abs/2309.12288
	- LLMがどれだけ論理的か？という問いに対して、LLMの苦手な点を挙げる
	- 『逆転の呪い』LLMは、知識を構造化し、”帰結を主語にして同じことを言う”のが自動的にはできない
	- LLMの「逆転の呪い」を認識した上ですべきことの考察
-  Knowledge Graph Construction w/ WikiData Filtering  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/index_structs/knowledge_graph/knowledge_graph2.html
	- REBELを用いて、文章あから知識グラフを抽出する方法において、Wikipediaをフィルタとして用いることで、春市ネーションを抑えれる
- Ronen Eldan et al., "Who's Harry Potter? Approximate Unlearning in LLMs"
	- https://arxiv.org/abs/2310.02238
	- LLMの記憶の一部を意図的に忘却させる
	- 約1GPU時間の微調整で、モデルはHarry Potter関連のコンテンツを生成または回想する能力を効果的に消去
-  Fine-tuning with Retrieval Augmentation  by llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_retrieval_aug.html
	- https://arxiv.org/abs/2310.01352
	- gpt-4とDatasetGeneratorをつかって、正解qaデータを生成
	- gpt-3.5-turboを正解qaデータをつかて、RAGのコンテキストでファインチューニング
	- 結果correctnesは、素のLLM＝3.2、ファインチューニング後＝3.65、
- 非侵襲の脳活動センシングによる、音声のデーコーディング
	- Decoding speech from non-invasive recordings of brain activity
	- https://huggingface.co/papers/2208.12266
	- contrastive learningというのをつかって、脳波からスピーチを推定
- OpenAIが、function calling fine-tuning機能を新たに追加　by llamaindex
	-  Fine Tuning with Function Calling
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/openai_fine_tuning_functions.html
	- https://github.com/run-llama/llama_index/blob/main/docs/examples/finetuning/openai_fine_tuning_functions.ipynb
	- 構造化されたデータ出力をLLMから得たいときに、functio/n callをつかうらしいが、この機能をfine-tuneすることができる
- LLMは世界モデルをもっているか？
	-  Language Models Represent Space and Time
	- https://arxiv.org/abs/2310.02207
	- LLMはシンプルに統計（確率）から次のテキストを生成しているのではなく、「物事がどのように位置づけられ、時間がどのように進行するかを理解」している可能性が示唆されました。 つまり、LLMが"世界モデル"を形成しているかもしれないという報告
	- 世界、米国、NYCの地名、歴史的人物、芸術作品、ニュースヘッドラインなどを含む6つのデータセットを用意
	- 空間と時間の理解度は、LLMのニューラルネットワークにおける階層を半分まで進んだところで品質が向上し、そのあと限界点に達する
	- LLMが「世界モデル」を形成している可能性が高いのであれば、LLMがより高度な認知タスクに対応できることに繋がります。 例えば自動運転車のソフトウェアにLLMを活用するのは優れた戦略である可能性があります
- huggingface/transformers v4.34の更新はかなりagressive
	- https://github.com/huggingface/transformers/releases/tag/v4.34.0
	- tokenizerの挙動を細かく制御していた人たちにとってはうれしいかも
- ModuLoRA is the first method to finetune 3-bit LLMs
	- 3-bitや2-bitに量子化したLLMの話題の裏にあるアルゴリズムModulLoRAが公開
	- https://browse.arxiv.org/pdf/2309.16119.pdf
- RETRIEVAL MEETS LONG CONTEXT LARGE LANGUAGE MODELS
	- https://arxiv.org/abs/2310.03025
	- NVIDIAよりRAGとContext Window (CW)のパフォーマンス比較論文。4K CWのLLM＋RAGは、16K CWのLLMと同等、32K CWのLLaMA2-70B＋RAGは長いContextのタスクにおいてGPT-3.5-turbo-16kより優れていると事を実証分析 
- llama.cpp 単体で LoRA 作れる機能が追加
	- https://github.com/ggerganov/llama.cpp/pull/2632
- Why you should build RAG from scratch - with Jerry Liu from LlamaIndex
	- LlamaIndexの中の人に聞く回。ファインチューン、RAG、ReAct、ベクトル検索やハイブリッド検索等々についてJerryがどう考えてるか聴ける。RAGはハックだと言い切ってて面白い。
	- https://www.latent.space/p/llamaindex?utm_campaign=post&utm_medium=web
-  Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study
	- https://arxiv.org/abs/2307.08072
	- 量子化されたLLMについて、一般的にLLMで発現するとされているin-context learning、chain-of-thought, instruction-followingといった能力がどの程度保てているかを検証した研究。結果として4-bitまでの量子化であれば性能の劣化が見られないことを確認
- OpenAIのSuper aligment
	- https://openai.com/blog/introducing-superalignment
	- “Superintelligence will be the most impactful technology humanity has ever invented.”
	- Superintelligence "could lead to ... human extinction. ... We believe [superintelligence] could arrive this decade."
- 早速GPT-4Vに対抗するOSSであるLLaVAが登場
	-  LLaVA: Large Language and Vision Assistant
	- https://llava-vl.github.io/
	- Haotian Liu et al., "Improved Baselines with Visual Instruction Tuning"
	- https://arxiv.org/abs/2310.03744
	- お試しできる、https://llava.hliu.cc/
- How to build ChatGPT for your company data? by ABACUS AI
	- llama2を使うのが良いみたい　
	- https://x.com/Saboo_Shubham_/status/1710505571072278932?s=20
- 正則化項付き線形回帰は真の偏回帰係数を推定しているのか？
	- https://bob3.hatenablog.com/entry/2023/10/06/224133
	- 正則化項付き線形回帰（Ridge、LASSO、Elastic net）で真の偏回帰係数を推定できるのか？を実験してみました。
- RAGにおけるchankサイズについて
	- https://docs.google.com/presentation/d/18Z7H3WSncPzLOTHKZAj36w0E7HSGY78VkDooSzvvySE/edit#slide=id.g286c47b4bb8_1_0
	- More chunks ≠ better (lost in the middle problems / context overflows)
	- Reranking retrieved chunks doesn’t necessarily improve results, in fact can worsen them.
- Science Behind Why LLMs Can Easily Be Tricked And Are Predictably Gullible
	- https://x.com/bindureddy/status/1710504584496779675?s=20
	- while large language models exhibit impressive linguistic abilities, their lack of true understanding, combined with the intricacies of data-driven learning, makes them susceptible to errors and easy to fool.
- 新しいOSSのembeddingモデルgte-tinyが登場、OpenAIのtext-embedding-ada-002なみの能力をもちつつ、小さくて軽い
	- https://huggingface.co/TaylorAI/gte-tiny/tree/main
- OpenAI, "DALL·E 3 System Card"
	- https://openai.com/research/dall-e-3-system-card
	- DALL·E 3での安全対策
	- OpenAIは、DALL·E 3の論文を通して「画像生成AIの安全性は前進した」ことを報告
- Artificial Intelligence Index Report 2023
	- https://arxiv.org/abs/2310.03715
	- スタンフォード大学がAIに関する技術・法律・経済・環境・世論などの多角的なデータを収集してまとめた報告書「AI index Report 2023」をarxivに公開
- MSのDeepSpeedチームの基盤モデルの科学応用を目指したDeepSpeed4Scienceプロジェクト
	- https://deepspeed4science.ai/
	- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed4science/japanese/README.md
	- 科学的基盤モデル(SFM)とよぶらしい
	- ClimaXは、さまざまな気象および気候モデリングタスクを実行するために設計された最初の基盤モデルです
	- 分子動力学と機械学習型力場
	- 天気 from Microsoft Start
- Google ColabについにAI機能が来てる？
	- Proにしか来てないもよう。
- Best Practices for LLM Evaluation of RAG Applications A Case Study on the Databricks Documentation Bot
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- RAG（Retrieval Augmented Geneneration）の評価、特に"LLMを使った時代評価の観点"からベストプラクティス
- 様々なLLMが何ができるかの比較表 by llamaindex
	- https://docs.llamaindex.ai/en/latest/core_modules/model_modules/llms/root.html#llm-compatibility-tracking
	- ちょっと、llama2-7b-4bitが悲しい結果に。。
		- OpenAI models (gpt-3.5-turbo, gpt-3.5-turbo-instruct, gpt-4)
		-  Anthropic models (claude-2, Claude-instant-2)
		- llama2-chat-7b 4bit
		- Mistral-7b
- Microsoft、Nvidia GPU依存へのコスト削減につながるAIチップを来月デビューへ
	- https://texal.jp/2023/10/08/microsoft-is-developing-its-own-ai-chip-and-working-with-amd-to-stop-nvidias-monopoly/
	- 「**Athena**」１１月の開発者会議で発表予定？
	- NVIDIAのH100 GPUと同等に設計されている


## 10/2

今週は、いや、今週もいろいろありすぎて、消化しきれない。GPT-4V(ision) デビュー、画像理解とか、ついにLLMが眼を持った（カンブリア紀）、これってAGIの前触れ？　GPT-4V初期ユーザーからは、霞が関パワポを入力したり、天一のマークも「侵入禁止」標識と誤認識はしない、サイゼリアの「間違え探し」は苦手、という報告も。ChatGPTにもvisionや音声対話機能が来週からロールアウトする(Plus以上のユーザー）。Amazonは、生成AIのAnthropicに5900億円出資。Quoraが提供する [poe.com](http://poe.com) で試用できる。GoogleのGPT-4超えのGeminiは水曜(10/4)に発表される。LLMでLLMを評価するLLM-as-a-judge がはやり。一方OpenAIの次世代LLMであるArrakisはAGIだといううわさも（コードネームは「砂の惑星」からきている？？）。特許検索だけからウイルス薬を発見したり、過去データから安定な準結晶の化学組成をあきらかにしたりと、バイオ・材料系でLLMは大活躍。PFN の PLaMo-13B 、4 bit 量子化するとColab 無料版で動くぞ。機械学習により偏微分方程式を解く話、データから逆設計できるならば画期的すぎる。 Gaussian Splatをつかった三次元生成の論文とGitHub公開が同時に２か所で！。LINEのインターン生による量子化による大規模言語モデル軽量化の効果測定、ここまで６週間でできるのか。ChatGPTの検索プラグイン復活、どうも本来ペイウォールで守られている記事であっても全文が表示されてしまうという報告で停止してものに対策が打たれた模様。RAG関係の進捗も、時系列データやMergeRetrieverなど進展がある。

- Agents: LLMをつかった新しいagentフレームワークとツール軍
	- https://github.com/aiwaves-cn/agents
	- **Agents** is an open-source library/framework for building autonomous language agents. The library is carefully engineered to support important features including **long-short term memory**, **tool usage**, **web navigation**, **multi-agent communication**, and brand new features including **human-agent interaction** and **symbolic control**.
- llamaindexからneo4jを使ったグラフagent
	- https://llamahub.ai/l/tools-neo4j_db
	- The `Neo4jQueryToolSpec` class provides a way to query a Neo4j graph database based on a provided schema definition.
-  LLM Fine-Tuning (東大松尾研LLM講座 Day5資料)
	- https://speakerdeck.com/schulta/llm-fine-tuning-dong-da-song-wei-yan-llmjiang-zuo-day5zi-liao
- OSSのLLMはだGAFAMのLLMに勝ち目がいないかあるか？
	- https://x.com/bindureddy/status/1706092114063639035?s=20
	- OSSのLLMは、AIの民主化と透明性のためには必要という話
-  LLMを用いたLLMの自動評価について 〜可能性と注意点
	- https://engineers.ntt.com/entry/2023/09/25/091245
	- LLM-as-a-judge では、**人手評価に匹敵するクオリティの評価を、お金や時間、労力をかけずに機械的に行える**ことが期待できます。
-  Community-developed checklists for publishing images and image analyses(Nature)
	- https://www.nature.com/articles/s41592-023-01987-9
	- 画像や画像解析結果を報告する際のベストプラクティスに関するNature Methods誌の記事
	- 画像のフォーマットや注釈、色の選択、データの利用可能性、画像解析ワークフローの報告に関する重要な推奨事項が提供されています。
- OpenAIからGPT-4V(ision) が発表、ついでに品質カードSystem Cardも公開
	- https://cdn.openai.com/papers/GPTV_System_Card.pdf
	- GPT-4 with vision (GPT-4V) enables users to instruct GPT-4 to analyze image inputs provided by the user, and is the latest capability we are making broadly available. Incorporating additional modalities
	- 複雑な標識を読み取る、https://x.com/petergyang/status/1707169696049668472?s=20
	- サイゼリアの「間違えさがし」の正答率は１割、https://x.com/cumulo_autumn/status/1707574932153282728?s=20
	- GPT-4V vs. 霞が関　https://x.com/horromary/status/1707373718534824305?s=20
- 外部知識によりパーソナライズされた対話システム
	- https://www.jstage.jst.go.jp/article/jjske/22/2/22_TJSKE-D-22-00053/_article/-char/ja/
	- 様々な概念に対するユーザーの関心を推定し，知識グラフをパーソナライズする手法を用いて，雑談における共感性や情報提供を目指す
- ChatGPT(Pllusユーザー以上）に、来週から新機能をroll-outするとの発表
	- Voice Capabilities:
	- Image Interaction
	- New Text-to-Speech Model:
	- Collaboration with Spotify
-  Amazon、生成AI新興に5900億円出資　Microsoftに対抗
	-  Claude-2-100kは、Anthropicの最も強力なモデルで、コンテキストウィンドウが10万トークン（約75,000語）
	- ばっちり日本語にも対応しQuoraが提供する [poe.com](http://poe.com)  で実際に使ってみることができます。
- llamaindexのAuto Merging Retriever
	- https://gpt-index.readthedocs.io/en/latest/examples/retrievers/auto_merging_retriever.html
	- 木構造で整理されたドキュメントに対して類似する枝から順にマージして見せるらしい。
	- RAGを評価する教師データをGPT4で生成する、DatasetGeneratorもついでに紹介。いわゆる、 LLM-as-a-judge の一種をlllamaindexがnativeサポートした
- 特許から分子データを抽出
	-  Mining Patents with Large Language Models Demonstrates Congruence of Functional Labels and Chemical Structures
	- https://arxiv.org/abs/2309.08765v1
	- ChatGPTを使って特許から10万件の分子と関連するキーワードを高精度に抽出、このデータベースを学習したモデルからウイルス薬を逆探索するとそれっぽい分子を抽出できた
	- 特許分析だけから、、、
- ChatGPT-4V公開、iOSやAndroid版にも搭載、様々な評価が報告される
	- デモの画像と言語を交えたインタラクションは未来感ある。構造化文書を画像で見せてもある程度理解できる模様。
	- 人の見た目に対する言及など新たなリスクも評価・対策済みとのこと
	- 英語のほうがOCR精度が良いし色々試してるけど、シンプルな図表のReasoningはかなりできる。図表に含まれない背景情報も、GPT内部の知識で補えるのが強力。
- Calibrating LLM-Based Evaluator
	- https://huggingface.co/papers/2309.13308
	-  LLMベースの評価器の校正: 大規模言語モデル（LLM）を自然言語生成の品質評価に利用する方法を提案し，人間の評価との一致度を高めるための校正手法を提案する．
- Sam Altman氏、「社内内部的には、AGIは完成した」とtweet。
	- am Altman says "agi has been achieved internally" at OpenAI.
	- 噂ではOpenAIはArrakisという限りなくAGIに近いany-to-any modelを開発しており、サムアルトマンらしきアカウントがAGIの開発に成功した(追記: まぁ落ち着こうや) みたいなことを言ったという報告もある。
	- サンフランシスコで予定されている開発者会議（11/6）に何かしらの発表がある。
- 【続】Flash Attentionを使ってLLMの推論を高速・軽量化できるか？
	- https://qiita.com/jovyan/items/5716cd83e246df4a158e
	- 最近公開されたhuggingfaceから直接公式実装のFlash Attention2を使える機能（from_pretrainedでuse_flash_attention_2=Trueを指定）についても実験
- 『LogiCoT』GPT-4などのLLMに「自らの論理的な整合性をチェック」させるフレームワーク
	- "Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic"
	- 前提（Premise）、考え（Thought）、検証（Verification）について明確に指示する
- 統語的評価データセット JCoLA が https://huggingface.co/datasets/shunk031/JGLUEに追加
	- JGLUE の全てのデータセットがそろったらしい
- ChatGPT の検索プラグイン(Plus用？）が復活
-  Pair Programming with a Large Language Model
	- https://www.deeplearning.ai/short-courses/pair-programming-llm/
	- DeepLearningAIより、ショートコースが公開。LLMとペアプロとは
- llamaindexのTimescaleDBとの連携
	- https://medium.com/llamaindex-blog/timescale-vector-x-llamaindex-making-postgresql-a-better-vector-database-for-ai-applications-924b0bd29f0
- 大学における数理・データサイエンス・AI 教育 の中での統計科学の教育について（日本学術会議）
	- https://www.scj.go.jp/ja/info/kohyo/pdf/kohyo-25-k230926-24.pdf
	- (1) 数理・データサイエンス・AI 分野の理論的基礎としての統計科学の位置付け
	- (2) 数理・データサイエンス・AI 分野の再教育(リスキリング)の推進
	- (3) 学士課程及び大学院教育が必要とする統計教員の育成
	- (4) 初等・中等教育における教材、ソフトウェア、デジタル環境の整備と統計教育の さらなる充実
	- きっと、データサイエンティストが主人公のアニメが必要だと思うぞ。
- RAGをOSSだけで構築する方法(llamaindex)
	-  Building RAG from Scratch (Open-source only!)
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/oss_ingestion_retrieval.html
	- Sentence Transformers as the embedding model
	- Postgres as the vector store (we support many other vector stores too!)
	- Llama 2 as the LLM (through llama.cpp)
- Google Colab で Preferred Networks の PLaMo-13B を試すby npaka
	- https://note.com/npaka/n/n19ff9dd4a537?sub_rt=share_sb
-  機械学習アルゴリズムが発見した初めての準結晶(統計数理研究所）
	- https://www.ism.ac.jp/ura/press/ISM2023-05.html
	- これまでに合成されてきた準結晶や関連物質のパターンを読み解き、熱的に安定な準結晶を形成する化学組成を予測する機械学習技術を開発
- PFN の PLaMo-13B を 4 bit 量子化するとColab 無料版の T4 15GB でも推論できるらしい
	- https://colab.research.google.com/drive/1vgHInjIL5dJYoaIXL-s6ickbp3cwIQti?usp=sharing
- DreamGaussianが 無料Colabで試せる。5分ほどで完成
	- https://github.com/camenduru/dreamgaussian-colab
-  Mastering Customer Segmentation with LLM
	- https://towardsdatascience.com/mastering-customer-segmentation-with-llm-3d9008235f41
	- テーブルデータをLLMのembeddingで数値化し、k-meansやt-SNEでクラスタの特徴を探る流れの良い解説記事
- デジタル庁のITコンサル/PM/週5日/一部リモート/デジタル庁IT支援の求人が話題に
	- 単価は、1,54万円/万
	- 体調が安定しており病欠が少ない方
- 機械学習により偏微分方程式を解く論文
	-  Neural Operators for Accelerating Scientific Simulations and Design
	- https://arxiv.org/abs/2309.15325v1
	- 入出力のマッピング演算子を学習するニューラル演算子。数値計算を高速化できるだけでなく、実験データからの学習や逆設計までできるそうです。
- ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning
	- https://huggingface.co/papers/2309.16650
	- ３Dの状況を概念モデルとして理解するための語彙を提供、これはメタファーの世界か。。
- Gaussian Splat＋三次元生成の論文が一つどころか二つ同時に出ているのが戦国時代っぽいところ
	- https://gsgen3d.github.io/
	- https://dreamgaussian.github.io/
	- Gaussian Splatting は、3D シーンを、ガウシアン関数で表された点群の集合として表現します。この点群の集合を、レンダリング時に、光線に沿ってサンプリングすることで、シーンをレンダリングします。
- lama_indexの AutoMergingRetrieverを図解した絵が素晴らしい
	- https://x.com/clusteredbytes/status/1707864519433736305?s=20
- OpenAPIの新しいinstructモデルでは、なにか機能が落ちた模様
	- OpenAI is removing the ability to evaluate P(completion | prompt) for user-provided completions to the `gpt-3.5-turbo-instruct` model.
- Google、新LLM　Geminiを 10月4日に発表か、
	- Gemini might be coming out on Wednesday
	- "plus few more surprizes"とinvitationに書いてあるらしい
-  7 Query Strategies for Navigating Knowledge Graphs With LlamaIndex
	- https://betterprogramming.pub/7-query-strategies-for-navigating-knowledge-graphs-with-llamaindex-ed551863d416
- 【インターンレポート】量子化による大規模言語モデル軽量化の効果測定
	- https://engineering.linecorp.com/ja/blog/quantization-lightweighting-llms
	- LINEの技術職 就業型コースのインターンシップ生の発表
	- 6週間程度のインターン期間らしい
	- FP8による影響まとめ
		-  大きなモデルで最大1.2倍の推論高速化
	- GPTQによる量子化モデルの効果測定
- StreamlitとGithub CodespacesでブラウザのみでChatGPT API開発をする
	- https://corp.langcore.org/media/codespaces

## 9/25

相も合わらず、RAG(Retrieval Augmented Generation)関係が多いのはご容赦。上位のLLM(GPT-4とか）をつかって正解をつくって、RAGを評価する仕組みとか、この評価の仕組みをつかって別のLLＭ(gpt-3.5-turboとか)をRAG向けにfine-tuningするなんてのが、e2e(end-to-end)の手法として当たり前になりつつある。「知識は樹木のようなもの」とのたまうスクエニの三宅さんの話はいつも面白い。SOPをつかったAgentsというのはagentの可制御性という意味で面白い。Transformers.jsをつかったWeb LLMの新手が登場。Xwin-LM-70BがGPT-4超えか？というのがもっぱらの話題。LLMが創造性を持つか？の論文での創造性の３つの基準（価値、新規性、驚き）って、特許提案と同じだよね、LLMが特許提案できるか？に置き換えても同じ。instructorというopenai function callingにpydanticを組み合わせられるライブラリ使ってみたい。RAGでもメタ情報抽出にpydantic使ったりとか、この辺りも定番化か。ChatGPTの知識が、2022年1月までの知識までアプデされた。LLMの利用サーベイ、「５位：ビジネス戦略立案」ってのは笑ったね。gpt-3.5-turbo-instructというのが出てるのね、コンパクトで、言語生成に適したモデル（チャット用ではない）、これはfine-tuning用なのか？？、LLM向けAI半導体「SN40L」ってのも期待。

- ちょっとした気配りで皆を幸せにする GitHub の使い方
	- https://qiita.com/squid-cat/items/7166317e60d3ff96ccb7
	- PR がレビューされない環境を作らない
- 米国のAI企業公聴会より、Nvidiaの証言が素晴らしい
	- https://x.com/Yampeleg/status/1703774531771363738?s=20
	- OpenAI: AI will kill us. 
	- Anthropic: AI will kill us. 
	- InflectionAI: AI will kill us. 
	- Nvidia: Fortunately uncontrollable Artificial General Intelligence is Science Fiction not reality.
- 知識と技術の継承としてのAI by スクエニ三宅さん
	- https://togetter.com/li/2226417
	- その分野の専門家が持つそういった知識体系が、その教授なり専門家の価値なわけであるが、実際のところ、近くにいて話しかけなければ、自分にとって価値あるものを引き出せない。だからこそ、研究室があり学生がある。しかし、そういった知の体系は、万人に開かれるべきだ
	- AIによって日々積み重なる論文や発表資料、講演録を吸収し、知の系統樹を作らせる。我々はそれが巨大な樹木となっていくのを見ながら、欠けているピースや来るべき枝葉を準備する
- Intel/Llama-2-70b-chat-hf-onnx-int4
	- https://huggingface.co/Intel/Llama-2-70b-chat-hf-onnx-int4
	- high-quality, INT4, ONNX models for all LLama2 variants (base vs. chat, 7B to 70B).
- Best Practices for LLM Evaluation of RAG Applications by DataBricks
	- https://www.databricks.com/blog/LLM-auto-eval-best-practices-RAG
	- Human and GPT-4 judges can reach above 80% agreement on the correctness and readability score. And if we lower the requirement to be smaller or equal than 1 score difference, the agreement level can reach above 95%.
-  Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?
	- https://arxiv.org/abs/2309.08963
	- structure-aware fine-tuning method, applied to Llama-7B, which significantly outperform other model like GPT-3.5/4 and Vicuna-13B.
- Azure Cognitive Search のハイブリッド+セマンティックランキングは、純粋なベクターサーチよりもパフォーマンス良かったそうで！
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/azure-cognitive-search-outperforming-vector-search-with-hybrid/ba-p/3929167
- "Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality"
	- https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4573321
	- ① GPT-4ありの集団は以下のように優れていた ・タスクの完了数が平均で12.2%多い ・タスクの完了速度が平均で25.1%早い ・タスクの品質が平均で40%高い 
	- ② もともと成績のよくない人が目覚ましく向上した
- GPT-3.5-turbo を Fine-tuning して GPT-4 相当の性能を獲得する
	- https://tech.drobe.co.jp/entry/2023/09/19/140000
	- Lambda で GPT-4 を叩きつつ、入力と出力のペアを json 形式で Cloudwatch に落とします。
	- データをダウンロードしたらここを参考に Fine-tuning のデータの準備と validation を行います。
	- Fine-tuning の実施は簡単です。OpenAI の API を利用して以下を実施します。
		- 1.  トレーニングデータをアップロード
		- 2.  アップロードしたデータを指定しつつトレーニングを開始
	- Fine-tuning すると結果が GPT-4 に近づく事が観測できた
- Let's Verify Step by Step
	- https://arxiv.org/abs/2305.20050
	- LLMが複雑な問題を推論できるのは、学習中に推論方法（解き方）にアクセスし、その解き方を学んでいるからといえる
- 自律言語エージェントを構築するためのフレームワーク Agents を試す by npakaさん
	- https://note.com/npaka/n/n089614881df8
	- 「**Agents**」は、**自律言語エージェントを構築するためのフレームワーク**
	- 「**SOP**」(Standard Operation Process) を通じて言語エージェントにきめ細かい制御とガイダンスを提供できることです。「SOP」は**タスク全体のサブゴール / サブタスクを定義**し、ユーザーが言語エージェントのきめ細かいワークフローをカスタマイズできるようにします。
-  Benchmarking `gpt-3.5-turbo-instruct` on agents doing question-answering over tabular data
	- https://github.com/langchain-ai/langchain-benchmarks/blob/main/csv-qa/pandas_agent_instruct.py
	- It performed roughly the same as gpt-3.5-turbo (the chat model) with roughly ~67% accuracy
	- It errored twice due to misformatted output - without function prompting for output format becomes much more important
- StableDiffusionで生成した画像から3Dモデルを"AIで"作成し、Unity上でキャラクターを動かすまで【CSM AIの使い方】
	- https://note.com/okp_/n/n89b96384e0cb?sub_rt=share_b
- llamaindexのチュートリアル、“building RAG from scratch” -
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
- SambaNova、最大5兆個のパラメータモデルを実行可能なLLM向けAI半導体「SN40L」を発表
	- https://news.mynavi.jp/techplus/article/20230920-2775419/
	- Ceruleanアーキテクチャ。NVIDIA H100の24台分の性能で、GPUに搭載されてる様な高速メモリが不要でメモリ大容量化が可能！DDRが使える
- sam altman氏、DALE 3のデモ画像を自慢する
	- https://x.com/sama/status/1704561613070893428?s=20
- OpenAI本家で、Fine-tuning用のweb pageが公開された
	- https://x.com/OfficialLoganK/status/1704181284036300970?s=20
	- 誰でも簡単にモデルの微調整ができ
- JSONの可視化ツール jsoncrack
	- https://jsoncrack.com/
- GPT-4などの大規模言語モデルで化学研究を行うにあたっての､現状・課題・展望を整理した論文
	- Prompt engineering of GPT-4 for chemical research: what can/cannot be done?
	- https://www.tandfonline.com/doi/full/10.1080/27660400.2023.2260300
	- GPT-4は、化学研究における言語処理やドメイン知識の組み込みに有効なツールとなり得ます。
	- 以下が必要
		- 分子構造や実験データを扱えるようにするためのプラグイン
		- マルチモーダルモデルの開発最新の化学情報を学習できるようにするためのローカルモデル
		- 推論や計画能力を向上させるためのアルゴリズムやハードウェアの革新
- llamaindexにて、RAGにおいて、カスタムプロンプトをつかったQueryを使う方法、
		- RAGStringQueryEngineというので、任意のpromptを投入できる？！
		- なるほどこれは役に立つ
		- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/custom_query_engine.html
- An in-browser version of ChatGPT (or HF Chat), built with HuggingFace Transformers.js!
		- https://huggingface.co/spaces/mithril-security/blind_chat
		- webllmとは違ったブラウザベースのlocal LLM実装、transformer.jsかあ、そっちからHF使うんだ。
- RSJ2023「基盤モデルの実ロボット応用」チュートリアル2（松尾研）
	- https://speakerdeck.com/tmats/rsj2023-ji-pan-moderunoshi-robotutoying-yong-tiyutoriaru2-shi-robotutoyong-noji-pan-moderuwozuo-tutehuo-yong-surufang-fa
	- 日本ロボット学会 [#RSJ2023](https://twitter.com/hashtag/RSJ2023?src=hashtag_click) の「基盤モデルの実ロボット応用」セッションのチュートリアル（後半）の資料
	- 基盤モデルの特徴を整理したあと，ロボティクス領域での基盤モデルを構築し活用する方法に関してサーベイ
- **Building RAG with LLMs and Prompts**　by **Jerry Liu, LlamaIndex**
	-  @FlowGPTOfficial workshop today I gave talks on how to build RAG response generation and a simple router module using only LLMs and prompt
- llamaindexのRAGにおける、類似検索語のpost processing様々、順番変えるとかありなのか・
	- https://gpt-index.readthedocs.io/en/latest/core_modules/query_modules/node_postprocessors/modules.html#longcontextreorder
-  LLMが持つ/持たない/持ちうる創造性についての論文
	- On the Creativity of Large Language Models
	- https://arxiv.org/abs/2304.00008
	- ボーデンの３つの基準（価値、新規性、驚き）や他の哲学的理論に基づいて、LLMの創造性を検証
	- LLMは価値を持つ作品やアイデアを生成することができますが、新規性や驚きについては弱い
	- LLMは人間と同じような創造性を持っているとは言えません
	- 異なる学習方法や適応能力を持つモデルを開発することで、探索的や変革的な創造性を実現することができるかもしれません
	- LLMは人間と協働することで、人間の創造性を補完したり刺激したりすることができます
-  RAG is more than just embedding search
	- https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/
	- シンプルなベクトルサーチベースの課題を述べながら、instructorというopenai function callingにpydanticを組み合わせられるライブラリを紹介している記事
	- 課題の一つ、-   **Query-Document Mismatch**:ドキュメントと質問のembbedingって同じ空間でないと意味ないよね（地産地消の場合を除く）
- Xwin-LM-70BがGPT-4超え？
	- https://www.itmedia.co.jp/news/articles/2309/21/news085.html
	- Xwin-LMは米Metaが公開したAI「Llama2」をベースにしており、教師ありファインチューニング、報酬モデル、リジェクトサンプリング、強化学習などを使って調整したものという。パラメータ数はLlama2と同じく70億、130億、700億の3つのモデルを用意。中でも最大である700億の「Xwin-LM-70B-V0.1」は、AlpacaEvalの評価基準である「Text-Davinci-003」（GPT-3のモデルの一つ）に対する勝率で95.57％を記録。勝率95.28％のGPT-4を追い抜いたとしている。
- ChatGPTの知識が、2022年1月までの知識も反映した模様
	- https://old.reddit.com/r/ChatGPT/comments/16m6yc7/gpt4_training_cutoff_date_is_now_january_2022/
- e2e(end-to-end) LLM/RAG、RAG評価を含めてLLMでやるという話、について
	- raysummit2023でのチュートリアル、jupyternotebookあるよ
	- https://github.com/anyscale/ray-summit-2023-training/blob/main/Ray-LlamaIndex/notebooks/02_evaluation.ipynb
- RAGを構成するときに、メタデータを与えるってのは役に立つわけだが、それをPydantic ＋LLMで一発でできるという話、
	- extract a full Pydantic object from any doc with 1 LLM call.
	- https://gpt-index.readthedocs.io/en/latest/examples/metadata_extraction/PydanticExtractor.html
- Text generation web UI で Xwin-LM-13B をロードして色々推論して遊んでみます。
	- https://note.com/sa1p/n/n51170c4d1a1f
	- 「Text generation web UI」は、oobabooga氏による**大規模言語モデル用の無料のWeb UI**
	- ただし、ローカルに、GPUなどが必要**Windowsの場合NVIDIA製のグラボでのみ動作する**
- Exploring ReAct Agent for Better Prompting in RAG Pipeline
	- https://betterprogramming.pub/exploring-react-agent-for-better-prompting-in-rag-pipeline-b231aae0ca7c
	- use ReAct Agent to analyze Amazon's recent disclosures and attitudes towards LLMs in their SEC Exhibits 99.1 filings
- RAGの評価、正解と答えとの比較評価で、従来のBLEU/ROUGEとかでなくて、単に類似性評価でよいという簡易は方法を提示
	- https://gpt-index.readthedocs.io/en/latest/examples/evaluation/semantic_similarity_eval.html
- OpenAI謹製の、RAG(Q&A)のチュートリアル
	- https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb
- BQMLの時系列分析、ARiMAを適当なラグ設定のもとで40モデルほどぺぺっと推定してくれて、かつAICも推定してくれるので鬼便利
	- https://x.com/behemuhemulove/status/1705629318439907451?s=20
- LLMって何に使われているかのサーベイ
	- https://x.com/dmvaldman/status/1705350469177295273?s=20
	- １位：プログラムのエラーと解消法について、２位：AIのソフトウエアについての質問、３位：旅行関係、４位：テキスト要約とか改善、５位：ビジネス戦略立案
- GPT-3.5-Turbo-Instruct
	- https://chatgpt-lab.com/n/n2ed70597dfbf
	- 既存の「GPT-3.5-Turbo」とは違ってチャットに特化したモデルではないため、モデルが広範な自然言語処理タスクを扱うことを可能にします
	- OpenAIのテストでは、175Bのパラメータを持つGPTモデルよりも、1.3Bのパラメータを持つInstructGPTモデルの方が、100倍小さいにもかかわらず、人々に好まれることが示されている

## 9/19

GPT-4を活用して、データセットをつくって、他のＬＬＭをファインチューニングするとか、色々出ているが、MetaやAppleがGPT-4越えのLLMを来年に向け開発中。Appleが出遅れているのは、自動運転とかそっちにリソースを割かれているかとも、でもM2もっているし、ポテンシャルはある。あほなSiriの代わりになるのか？。RestGPTは、ReActの発展形、「APIの理解」ってのができるらしい。やっぱり企業利用ならば、RAG(Retrieval Augmented Generation)関係で、元となるテキストのチャンキングの仕方とか、ベクトルＤＢの選び方とか、スクラッチからのRAGの作成とか、地道活動も拾ってます。AstroLLaMA、今後様々なタスクや分野に特化したLLMがどんどんできてくるかも。LiteLLMっていうLLMの抽象化を使うと、アプリコードが再利用できるのか、作った人天才。GPT4による生産性向上にういての定量評価、資料として色々使えるな。仏教対話AIって、聖人をどれだけ復活させても幸せになれない気がする。きっと故人のChatBot作成サービスって葬儀業界ですぐにでも出てきそうだ。いや、2021年にマイクロソフトが[特許化していた](https://edition.cnn.com/2021/01/27/tech/microsoft-chat-bot-patent/index.html)。。


- Meta、GPT-4と同程度の性能を目指すモデルの学習を計画
	- https://www.theverge.com/2023/9/10/23867323/meta-new-ai-model-gpt-4-openai-chatbot-google-apple
	- AIトレーニングチップを買い集め、データセンターを構築
	- 2024年の早い時期に新しい大規模言語モデルの学習を開始する予定
	- 企業がAIツールを作成するために、再びこのモデルを無料にするよう働きかけている
- Fine-tuning to Memorize Knowledge
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/knowledge/finetune_knowledge.html
	- GPT4で、内部ドキュメントに対する、Q&Aを生成させてこれをつかって、LLMをファイチューニングする話。
	- “bake in knowledge”と呼ぶらしい。
- OpenIntepreterを使っていると、OpenAIのAPIコールで10ドルが一瞬で溶ける。（デジタル庁楠さん）
	- https://x.com/masanork/status/1701381113506329083?s=20
	- つまり、ChatGPT Plusの月額課金が気前いいことになっている。
-  RestGPT: Connecting Large Language Models with Real-World RESTful APIs
	- https://restgpt.github.io/
	- ReActの発展形か、、
	- https://zenn.dev/carnot/articles/7f87b613a0a637
		- **言語のみの指示から複数のAPIを呼び出すことが可能**
		- RestGPTではプランニング・APIの理解・APIの選択をそれぞれのモジュールが独立で行うため、複雑なユーザ要求にも柔軟に対応することが可能になっています。
- 来年にはGPT-4を上回る能力を持つとされる３つのモデル
	- ① OpenAI: GPT-4.5/GPT5 
	- ② Google: Gemini 
	- ③ Apple: Ajax
	- Apple is reportedly spending ‘millions of dollars a day’ training AI
	- https://www.theverge.com/2023/9/6/23861763/apple-ai-language-models-ajax-gpt-training-spending
- 仏教対話AIの多様化に成功―親鸞ボットと菩薩ボットの増産―(京大）
	- https://www.kyoto-u.ac.jp/ja/research-news/2023-09-12-0
	- 生成系AI「ChatGPT 4」と宗教を掛け合わせた新型チャットボット「親鸞ボット」と「世親ボット」を共同開発し、仏教対話AIの多様化に成功しました。
	- [会話事例](https://www.itmedia.co.jp/news/articles/2309/14/news083.html)が、地獄にしか見えないのは気のせい？
- リクルートにおける数理最適化の 活用事例と産学連携の取り組み
	- https://speakerdeck.com/recruitengineers/rikurutoniokerushu-li-zui-shi-hua-no-huo-yong-shi-li-tochan-xue-lian-xi-noqu-rizu-mi
	- 企業における数理最適化専門グループって、大変なのよね。
-  生成AIブームで多発の可能性　「PoC貧乏」
	- https://forbesjapan.com/articles/detail/65744/page2
	- 「生成AIで何かビジネスを作ってみて」と上層部が丸投げし、成果が出ないまま人件費がかさむ、ゆるやかなPoC貧乏が頻発することが考えられます。
	- まあ、生成AIに限らないわけだが。。
- Calls out of chaos: the adaptive significance of nonlinear phenomena in mammalian vocal production
	- https://www.sciencedirect.com/science/article/abs/pii/S0003347201919128
	- 赤子の泣き声がカオス的なダイナミクスで、複雑さと予測不可能性によって親に無視させないようにする適応的意義があるらしい
- 自然言語処理で扱うテキストのchunkingについて
	- https://zenn.dev/hijikix/articles/f414b067e29a57
	- Adjacent Sequence Clustering
	- 全体の文章をセンテンスに分割した後、チャンクに詰めていくのだが、その際に直前のセンテンスと処理中のセンテンスの意味的類似度を比較して、意味が離れているものは次のチャンクに詰める
- llamaindexのRAG作成チュートリアル（ローレベル）
	- https://gpt-index.readthedocs.io/en/latest/end_to_end_tutorials/low_level/root.html
	- ローレベルというのは、プリミティブな処理で構成するという意味。
- llamaindexのResponseの作り方
	- Building Response Synthesis from Scratch
	- https://gpt-index.readthedocs.io/en/latest/examples/low_level/response_synthesis.html
	- promptをカスタマイズできるのが素敵。
- Vector databases (Part 4): Analyzing the trade-offs
	- https://thedataquarry.com/posts/vector-db-4/
	- ベクトルDBのトレードオフを分析した記事。挿入vs読取速度、取りこぼし（Recall）vsレイテンシー、インメモリvsオンディスク、全文検索vsベクトルハイブリッド検索等の観点から比較・分析を実質
- AstroLLaMA: Towards Specialized Foundation Models in Astronomy
	- https://arxiv.org/abs/2309.06126
	- 特定分野に特化したLLMが大量発生する予感。
- 東京都の 「文章生成AI利活用ガイドライン」
	- https://www.metro.tokyo.lg.jp/tosei/hodohappyo/press/2023/08/23/14.html
	- プロンプトの具体例も豊富でわかりやすい
- llamaindexがLiteLLMをサポート、＋１００のLLｍが利用可能に？？
	- https://gpt-index.readthedocs.io/en/stable/examples/llm/litellm.html
	-  (OpenAI, Cohere, AnthropicAI, huggingface, etc.)に対して同じインターフェイスを提供。
	- というか、LiteLLMすごいな。
- Announcing the Preview of OpenAI Whisper in Azure OpenAI service and Azure AI Speech
	- https://techcommunity.microsoft.com/t5/azure-ai-services-blog/announcing-the-preview-of-openai-whisper-in-azure-openai-service/ba-p/3928388
	- Azure OpenAIサービスおよびAzure AI SpeechでのOpenAI Whisperのプレビューを発表しました
- Discover the LLMs
	- https://llm.extractum.io/
	- LLM の VRAM や Context Len が一覧表示できて便利
- BCGとハーバードやMIT等によるGPT4を使用したタスク実験
	-  Centaurs and Cyborgs on the Jagged Frontier
	- https://www.oneusefulthing.org/p/centaurs-and-cyborgs-on-the-jagged
	- BCGのコンサルティング758名で実験 
	- 18種類のコンサルタスクが対象 
	- AIを使用したコンサルは 、12.2％多く仕事を終え、 25.1％早く仕事を完了し、 40％高い品質
-  Optimizing LLMs From a Dataset Perspective
	- https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html
	- LLMsの最適化について、データセットの側面からまとめたブログ。人手で高品質なデータセットを作るグループや、LLMから大量のデータセットを生成するグループなど、いくつかの側面が簡潔にまとまっている
- InstaGraph
	- https://github.com/yoheinakajima/instagraph
	- 任意のドキュメントから知識グラフ作れるらしい。
	- 例：https://x.com/yoheinakajima/status/1701351068817301922?s=20

## 9/11

8/23に公開されたGPT-3.5-turboのfine-tuning API、RAGとの比較、証券報告書のQ&Aアプリの具体例、など、面白い記事がたくさん出てきた。Open Interpreterも相も変わらず熱い。デジタル庁のChatGPTの業務利用ハンズオン、いいな、こういうリテラシーを持てる人が増えないと。。大規模コンテンツ・行動モデル（LCBM）って、記号接地問題にさらに近づこうとしているのか？LLMをつかった様々なエージェントの作り方、いろんなデータ専門のエージェントがたくさんそろってくると、そろそろOrchestratorが必要かな。**Production-Ready LLM Applications**ってのは必読なスライドですね。ICML2023のまとめもあった。RAGを対象としたLLMの比較、フレームワークになってありがたい。ChatGPTの複数出力とか、性能が落ちたのでは？という疑惑など、何が起きているのか、起こそうとしているのか。

-  東京大学理学部オープンキャンパス2023 講演「生成型AIの数理と倫理」佐藤一誠教授
	- https://www.youtube.com/watch?v=n6NDlgJVug8&t=5s
-  Mustafa Suleyman on getting Washington and Silicon Valley to tame AI
	- https://80000hours.org/podcast/episodes/mustafa-suleyman-getting-washington-and-silicon-valley-to-tame-ai/
	- DeepMindの共同創業者で、世界最高水準のAIスパコンを構築中のAI開発会社「Inflection AI」の設立者でもあるスレイマン氏によれば、今後18ヶ月程度でGPT-4の学習に使用された計算回数の10倍〜100倍がAIモデルの学習に使用され、次の3年程度でGPT-4の1000倍の計算回数が学習に使われるだろう、とのこと
- LangChain Cheat Sheet
	- https://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html
- llamaindexより、Summary Index(旧List Index)の紹介
	- https://gpt-index.readthedocs.io/en/stable/core_modules/data_modules/index/index_guide.html#summary-index-formerly-list-index
- AI Agents – Build and Host LLM Apps At Scale
	- LLMを活用さいた様々なエージェントの作り方についての記事、なるほど
	- https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/
- Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior
	- https://huggingface.co/papers/2309.00359
	-  **大規模コンテンツ・行動モデル（LCBM）とコンテンツ・行動コーパス（CBC）**：本文書では、行動トークンをLLMの訓練に再導入する初期的な試みを行う。LCBMと呼ばれる新しいモデルは、コンテンツ理解タスクにおいてLLMと同等の性能を示すとともに、行動シミュレーション、コンテンツシミュレーション、行動理解、行動ドメイン適応といった能力も持つ。さらに、LCBMの研究を促進するために、コミュニケーター、メッセージ、受信者行動を含む新しいコーパスであるCBCを公開する。
- ChatGPTを業務に組み込むためのハンズオン
	- デジタル庁が一般公開しているChatGPTの入門
	- https://www.digital.go.jp/assets/contents/node/information/field_ref_resources/5896883b-cc5a-4c5a-b610-eb32b0f4c175/82ccd074/20230725_resources_ai_outline.pdf
	- なかなかのやり手が書いている、ここまで試行できる人は少ないのでは？？
	- プロンプトの書き方のコツ
		- できる限りコンテキストを明確にして書くこと
		- GPTの理解度(?)を確認しながら進める
		- 最初はマニュアルを読むより、まず自分でやってみて感覚をつかみことを推奨
- 最近のLLMの学習法のまとめ - SFT・RLHF・RAG　by npakaさん、
	- https://note.com/npaka/n/n862786604dc3
	- とりあえず、どれだけ知ってる？だけでもリトマス試験紙になる、むろん私はRAG派
	- SFT : Supervised Fine-Tuning
	- RLHF : Reinforcement Learning from Human Feedback
	- RAG : Retrieval Augmented Generation
- LangChain を使ったRAGを Elyza 7b instruct モデル
	- https://note.com/alexweberk/n/n3cffc010e9e9
	- 無料のT4ではメモリーオーバーで動かないんだが。。。
- SEC Insights
	- llamaindexを活用して、米国証券取引委員会への報告書(SEC-10)にたいするQ&Aアプリを作る例
	- https://github.com/run-llama/sec-insights
	- https://www.secinsights.ai/
-  Streamlit 入門  by npakaさん
	- https://note.com/npaka/n/n29b5e8088fe5
	- 「Streamlit」は、機械学習およびデータサイエンスのためのWebアプリケーションフレームを簡単に作成して共有できるPythonライブラリ
	- もうちょっとどうにかならんのか？
- **Production-Ready LLM Applications**
	- llamaindexのCEOより、
	- https://docs.google.com/presentation/d/1uzhz1aFWbyXSrWBzQ1FPQWtVjMgJqAYGoGoVzEnNmAg/edit#slide=id.p
		-  Fine-tuning: LLMs + embeddings
		-  Better Data + Retrieval Techniques for Production RAG
- ELYZA-7bは、M1 MacBook Airでもサクサク動くらしい
	- https://huggingface.co/mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf/blob/main/README.md
- やっぱりOpenInterpreterが熱い
	- https://github.com/KillianLucas/open-interpreter
- LLMをホストするAnyScaleのllamaindexでの利用例
	- https://gpt-index.readthedocs.io/en/latest/examples/llm/anyscale.html
	- run + finetune open-source LLMs through an API
	- そういうビジネスができるのか。。
-  Fine-Tuning GPT-3.5 RAG Pipeline with GPT-4 Training Data
	- https://betterprogramming.pub/fine-tuning-gpt-3-5-rag-pipeline-with-gpt-4-training-data-49ac0c099919
	- どうも、8/23にOpenAIがGPT-3.5-turboのfine-tuning APIを公開して、即座にllmaindexがこれに対応したらしい
	- じゃあ、Q&Aアプリを作るのに、RAGとFine-tuningどちらが高性能か？ということへの考察記事
	- こちらは、llamaindexをつかったGPT-3.5-turboのfine-tuningのcolab
		- https://colab.research.google.com/drive/1NgyCJVyrC2xcZ5lxt2frTU862v6eJHlc?usp=sharing
- Hierachical Agent	
	- 対象ドキュメントの内容が階層構造であるような場合のQ&Aの作り方。
	- https://colab.research.google.com/drive/1qIb09SyuLeiwGy_FGcRcQpM78yQ2p0_3?usp=sharing
- Discover LlamaIndex: Custom Tools for Data Agent
	- https://www.youtube.com/watch?v=lcuL6Gqw_-g
- 【速報】OpenAI APIでGPT-3.5-turboがfine-tuningできるようになりました！
	- https://dev.classmethod.jp/articles/openai-gpt35turbo-fine-tuning/
	- 学習するサンプルは最小10個必要で、50～100個で明確な改善が見られる
	- gpt-3.5-turboでfine-tuningが利用可能に
	- gpt-3のモデルであるbabbage-002とdavinci-002も新しいfine-tuningでサポート（モデルもGPT baseという扱い）
- グラフニューラルネットの 2023年まとめ (ICML2023)
	- 軽量 Transformer の介入や Diffusion for Molecules などの実世界利用、幾何学的な利用が記載されている
	- https://towardsdatascience.com/graph-machine-learning-icml-2023-9b5e4306a1cc
- Open Inerpreterの利用例、「nikkei225の10年分をプロットして」と滅入れすればあとは自動で、、、
	- https://twitter.com/NuCode/status/1700679106814501132?s=20
- ChatGPTが、可能性のある答えを複数ていじするようになった、RLHFやらせようとしているのかと話題に
	- https://twitter.com/GrantSlatton/status/1700662574315090351?s=20
- LLMの評価、特にRetrieval Augmented Generation (RAG) パイプラインを評価するためのOSSフレームワークragas
	- https://github.com/explodinggradients/ragas
- Agent deconstructedに、llmaindex agentが統合された？
	- https://github.com/shoggoth13/agents-deconstructed/blob/main/notebooks/react_chat.ipynb
	- ReActができるようになったのか。。、いろんなindexをもつLLM同士が会話して問題解決。。
- 【デモ付き】Embeddingsで独自データをChatGPTに理解させる
	- https://corp.langcore.org/media/embeddings
	- LangCore SaaSを使ってインフラ不要で手軽にEmbeddingsを活用した独自データの活用、らしい

## 9/4

GoogeからGPT-4対抗のGeminiが発表、GPT-4 の 2023 倍の計算能力を持つ？。LLMのファインチューニング関係で、様々な紹介がある。llamaindex周りの記事が多いが、それだけRAG(Retrieval-Augmented Generation)って需要があるということか。Embeddingもしっかり性能評価やファインチューニングすると性能があたる。llamaindexでQ&Aの性能を上げるためのTipsが詳しく書いてある、これは役立つ。ローカルLLMの試行も熱い、なんとCode interpreterもどきも動くという。最近のLLMでは、ELYZAが一番の模様(by shi3z)。理論関係では、transformerにおける自己注意はSVMと等価なのか？、確率過程の新刊も気になる。

- LLMのファインチューニング で 何ができて 何ができないのか
	- https://note.com/npaka/n/nec63c01f7ee8
- code llama がhuggingfaceのchatに登場
	- https://huggingface.co/chat/
- Llamaで、出力を指定するためのgrammar-based sampling
	- https://python.langchain.com/docs/integrations/llms/llamacpp#grammars
- Google 「Gemini」は、ChatGPT-4 Enterprise プラットフォームの直接の競合相手
	- https://www.theinformation.com/articles/the-forced-marriage-at-the-heart-of-googles-ai-race
	- GPT-4 の 2023 倍の計算能力を持つ
- llamainexでembeddingをファインチューニングする
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/embeddings/finetune_embedding.html
-  論文紹介 / Llama 2: Open Foundation and Fine-Tuned Chat Models　by NTT西田さん
	- https://speakerdeck.com/kyoun/llama-2-open-foundation-and-fine-tuned-chat-models
-  ご家庭用LLMでストリーミングする方法
	- https://note.com/shi3zblog/n/n66ae41af7c64
	- "elyza/ELYZA-japanese-Llama-2-7b-instruct"　利用
-  LlamaIndexの性能向上のためのテクニックガイド by npaka
	- https://note.com/npaka/n/n33e28a9e1409
-  Discover LlamaIndex: Introduction to Data Agents for Developers
	- https://www.youtube.com/watch?v=GkIEEdIErm8
	- first-ever video tutorial on LlamaIndex Data Agents
-  ChatGPT vs BERT：どちらが日本語をより理解できるのか？
	- https://fintan.jp/page/9126/
-  LlamaIndex の QAプロンプト と Refineプロンプト のカスタマイズ
	- https://note.com/npaka/n/ne878095d5bda
- llama2-13b-128k、論文を全部理解して要約を吐き出す方法
	- https://gist.github.com/alfredplpl/33fd6dd6d623d4da959f1ca8aabc88fe
- 「データ分析のための統計学入門」
	- http://www.kunitomo-lab.sakura.ne.jp/2021-3-3Open(S).pdf
- 【ローカルLLM】text-generation-webUIのAPI機能を試す
	- https://note.com/bakushu/n/na4e51d377ae7
	- LLM用のウェブUIであるtext-generation-webUIにAPI機能が付属しているので、これを使ってExllama＋GPTQのAPIを試してみた。
- 最近のLLMの性格 by shi3z
	- https://twitter.com/madyagi/status/1697949115190255951?s=20
	- ELYZAが良いみたい。
-  Transformers as Support Vector Machines
	- https://arxiv.org/abs/2308.16898
- fine-tuned a gpt-3.5 ReAct agent to be better at chain-of-thought
	- https://gpt-index.readthedocs.io/en/latest/examples/finetuning/react_agent/react_agent_finetune.html
-  機械学習のための確率過程入門
	- https://www.ohmsha.co.jp/book/9784274231087/
-  ローカルPCのターミナル上でLLM生成コードを実行できるOpen Interpreterを試す
	- https://note.com/hamachi_jp/n/n05ae28b76d9d
	- ChatGPTのコードインタープリター（Advanced Data Analysis）と同様な機能をローカル環境で実行可能な Open Interpreter 
	- llamaに差し替えることも可能
- 

## 8/28

先週発表された、松尾研の“Weblab-10B”に対する量子化やローカル環境での実行も花開くが、やっぱり今週はメタによるCode Llamaの発表がポイントになっている。
「LLM によるプログラムベース推論」的な考え方ってLLMをつかったアプリ作成には絶対必須な考え方になると思う。品質保証では、ガードレールとか、推論過程のガイドが必要だったり、得手不得手をちゃんと理解したうえでガイドするみたいな感じ。emergent機能とはLLMを動かしていて、予測していたのとは違う機能が創発するという話、欧州ＡＩ規制でも言及される、仕組みの解明と対策が急務。llamaindexから、外部検索と組み合わせる新しい、Metaphor機能がリリース。なんかどこのURLを見ればよいかのDBをつかってやるみたいな感じ。。HuggingFaceでは、LLMをWebベースで、ファインチューニングできる機能が公開されたらしい。結果はそのままHuggingFaceに乗るみたいなノリ。LLMをつかったQ&AであるRAGフレームワークで、類似データをtop-kでとってくる仕組みがうまくいかないときの工夫など、納得感ある。メタからCode Llamaが発表、コード生成ができる。さっそく、量子化されたり、llama.cppでローカルに動かしたりと、あっというまに、誰でも使えるようになる。コミュニティはすごいな。理論面では、emergentスキルに関して、通常の汎化理論に反する「スリングショット汎化」の提唱、ＬＬＭをつかった帰納的学習法というのも、従来の予測を書き換えるか。ＡＩ規制に対するパブコメをＡＩで分析など面白いかも。。

- 言語モデルにおける複雑なスキルの創発に関する理論　A Theory for Emergence of Complex Skills in Language Models
	- https://note.com/daichi_mu/n/n72b6265b09f6
	- 言語モデルのスケールアップに伴う新たなスキルの出現について、統計的枠組みと数学的分析を用いて分析する。能力レベルが通常の汎化理論に反する「スリングショット汎化」の概念を導入
- LLM によるプログラムベース推論
	- https://speakerdeck.com/smiyawaki0820/2023-dot-08-dot-07-geography-and-language-mian-qiang-hui-number-4
	- LLM 開発における評価・品質担保に関係、ガードレールや、推論過程のガイドなど最後はVisProg紹介
	- 東北大の宮脇さん、地理空間情報をLLMをつかいながら推論する仕組みについて。
- AIが「理解」するから、API仕様書のコピペでアプリができあがるローコード開発環境「Flowise」
	- https://internet.watch.impress.co.jp/docs/column/shimizu/1523766.html
- **[chatux-server-llm](https://github.com/sotokisehiro/chatux-server-llm)**
	- ローカル環境で動作する文章生成 AI チャットボットです。 CPU だけで動作します。
	- LINE の japanese-large-lm-3.6b-instruction-sft を CTranslate2 化
- Vicuna 13B v1.5 、text-generation-webui じゃなくて以前試作した llama.cpp の HTTP サーバー機能を使ってみたら普通に LLaMA 2 13B と遜色ない結果出してくれた
	- https://twitter.com/izutorishima/status/1693468524222861589?s=20
- Metaの大規模言語モデル「LLaMA」のトレーニングにも使用されたAIの学習用データセット「Books3」が削除される
	- https://gigazine.net/news/20230821-books-3-ai-data-set/
	- 知的財産権や著作権に対する侵害の疑いが指摘されていたらしい
- LlamaIndex + Metaphor: Towards Automating Knowledge Work with LLMs
	- https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f
	- Metaphor was trained to predict links on the internet, given how people talk about things on the Internet
	- インターネット検索とllamaindexの融合？結合の新たな形としてのメタファー？
- 【ローカルLLM】Gradio+CTranslate2で日本語LLMのチャットUIをつくる
	- https://note.com/bakushu/n/nba6e9c353ee4
	- [line-corp-japanese-large-lm-3.6b](https://huggingface.co/line-corporation/japanese-large-lm-3.6b-instruction-sft)を利用
	- CTranslate2で量子化
	- あとはgradioでWebUI生成！
- Generally Intelligence社、米国商務省国家電気通信情報庁（NTIA）が実施したAI規制に関するパブリックコメントの約1450件の回答の分析を開始。
	- https://generallyintelligent.com/perspectives/ntia-rfc-analysis/
	- https://twitter.com/kanjun/status/1693819078866354376?s=20
- llamaindexのMetaphorサーチのお試しができるらしい。
	- https://twitter.com/jerryjliu0/status/1693773766797746649?s=20
	- https://colab.research.google.com/drive/1PTnJTVmLAI-V8JJu8GsbUvbk8vs203kA?usp=sharing
- Stanford大学のHAIから、Create AI Actを連邦政府が法案をとおすべきである、米国のため
	-  We Must Pass the Create AI Act
	- https://hai.stanford.edu/news/we-must-pass-create-ai-act?utm_source=twitter&utm_medium=social&utm_content=Stanford%20HAI_twitter_StanfordHAI_202308220803_sf181078680&utm_campaign=&sf181078680=1
- Open AI でスーパーアライメントを4年以内に完了させることを目標として率いているJan Leike氏の対談
	- https://80000hours.org/podcast/episodes/jan-leike-superalignment/
-  Inductive-bias Learning: Generating Code Models with Large Language Model
	-  **帰納的学習法**：大規模言語モデル（LLM）を用いて、説明変数から目的変数を予測するモデルを生成する新しい学習法。この学習法は、教師あり学習とメタラーニングの要素を持つ。
	- https://arxiv.org/abs/2308.09890
-  日本語が使えるようになったGoogle PaLM2を試す
	- https://note.com/eurekachan/n/n62b15394b5dc
	- BigQuery のSQLなんかも日本語で生成をお願いすることが出来ます。
	- LangChainからも呼び出したりできるようです
- ANYONE can fine-tune (almost) any LLM available on Hugging Face
	- Hugging Faceで簡単にLLMをファインチューニングできるAPIが公開
	- https://twitter.com/abhi1thakur/status/1693619860050153958?s=20
- RAGシステムで、top-k 抽出がうまくいかないときの工夫について
	- https://twitter.com/jerryjliu0/status/1694013501323563101?s=20
	- Metadata Filters + Auto Retrieval:
	- Store Document Hierarchies (summaries -> raw chunks) + Recursive Retrieval
- 今村・松井の『ベイズ最適化』
	- 第4章までよめらば、ベイズ最適化が理解できるらしい。
	- https://www.kindaikagaku.co.jp/book_list/detail/9784764906631/
- メタが、Code Llamaを公表
	- https://ai.meta.com/blog/code-llama-large-language-model-coding/
	- Foundation base models (Code Llama) 
	- Python specializations (Code Llama - Python), 
	- Instruction-following models (Code Llama - Instruct)
- 【ローカルLLM】Colabの標準GPUで「CodeLlama-34B-GGUF」を動かす
	- https://note.com/bakushu/n/n21cb30a15f27
	- 量子化は「GPTQ」ではなくて、CPU＋GPUで実行できる「GGUF(旧GGML)」
	- 標準GPU（Tesla T4）で動くのがみそ
- Weblab-10Bを量子化(GPTQ)して簡単に動かすことがhugging faceでできる
	- transformersにGPTQが統合されたおかげで、無料Colabでそのままでは動かなかったWeblab-10Bもらくらく動くようになってた。
	- dahara1/weblab-10b-instruction-sft-GPTQ
	- https://github.com/webbigdata-jp/python_sample/blob/main/weblab_10b_instruction_sft_GPTQ_sample.ipynb
- 【まとめ】Google Colab で Code Llama を試す
	- https://note.com/npaka/n/n51ed424b2943
- CodeLlama model now work w/ llama-cpp-python
	- [@TheBlokeAI](https://twitter.com/TheBlokeAI)さんによる
	- llama.cpp GGUFの組み合わせで動くということ
	- https://huggingface.co/TheBloke/CodeLlama-13B-Instruct-GGUF/tree/main
	- https://github.com/abetlen/llama-cpp-python
- CodeLamaの、colabでの実行とビデオ
	- https://colab.research.google.com/drive/1lyEj1SRw0B9I2UUI2HOrtiJ_fjvbXtA2?usp=sharing
	- https://www.youtube.com/watch?v=rlCe_lG4uhk

## 8/21
暑くて溶けそうなのに、電力はどうにかもっている夏です。松尾研からの国産LLMである“Weblab-10B”の発表。なお、松尾研には夏休み中の総理も訪問され講座を受講（なにか修了証書をもらってたな）、もっと国としてのサポートが期待できるかも。GPT-4は、暗号化されたプロンプトも理解できるぐらい優れているらしいが、特定の「脱獄プロンプト」に弱い面も。Trustworthy LLM、LLMの信頼性などの研究も進む、社会規範への整合とかそういう側面もある。スタンフォード大学のLLMの安全性のベンチマークとの比較も気になる。あいもかわらず知識グラフ系のLLM応用がちらほら、知識グラフ抽出や知識グラフをつかったRAG(Retrieval-Augmented Generation)などもあるが、知識の活用かそれともファインチューニングか？みたいな第２世代(エキスパートシステム）と第３世代（データがすべて）のAIの対比みたいな絵面だなあ。MRIスペクトルから分子を予想みたいな素朴な応用がもっとあっていい気もする。TRL(Transformer Reinforcement Learning)は、強化学習を用いたLLMの最適化を簡単にできるようになるらしい、DPO(Direct Preference Optimization)なんか斬新じゃん。元Googleトップ研究者による「Sakana AI」にはびっくり、めざす「自然からインスピレーションを得たインテリジェンスに基づいた新しいタイプの基礎モデル」とはどんなものになるのか？日本はコンテンツだけでなくて、人材リソースとしてもまだ魅力がある？？

- ローカルデータに対するQ&Aなどするときに、知識を活用したRAGで構成するのがよいのか、いや、目的に対してLLMをファインチューニングするがいいのかというはなし
	- Knowledge Graphs & LLMs: Fine-Tuning vs. Retrieval-Augmented Generation
	- https://neo4j.com/developer-blog/fine-tuning-retrieval-augmented-generation/
- LLMをつかったsemantic searchのDeeplearning.aiの無料コース
	- Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
- GPT-4のセーフガードを故意に突破する脱獄プロンプトに関する研究
	-  "Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models
	- https://jailbreak-llms.xinyueshen.me/
- 「汎用的なAIってやつ」を作ったところで、それで十分なレベルまで収益化を実現させるのはそれなりに難しいという話(TJO
	- https://twitter.com/TJO_datasci/status/1691112696685719553
- GPT-4 Is Too Smart To Be Safe: Stealthy Chat with LLMs via Cipher
	- https://arxiv.org/abs/2308.06463
	- GPT-4 can understand ciphertext, which introduces the risk of generating unsafe content.
- CSVにたいするQ&Aエージェントのベンチマーク
	- https://github.com/langchain-ai/langchain-benchmarks/tree/main/csv-qa
-  Knowledge Graph RAG Query Engine (RAG: Retrieval-Augmented Generation)
	- https://gpt-index.readthedocs.io/en/latest/examples/query_engine/knowledge_graph_rag_query_engine.html
	- augmenting LLMs with context from a graph database
-  Large Language Models with Semantic Search
	- https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/
	- Deeplearing.aiからのsemantic searchの無料コース、Cohereの人がでている？
- 知識グラフ抽出のデモ
	- text to graph playground
	- https://auto-graph.streamlit.app/
-  Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment
	- LLMの信頼性に関するサーベイ論文
	- 用語や概念を整理し，実際に8つの観点からLLMの信頼性を検証
	- https://arxiv.org/abs/2308.05374
	- reliability, safety, fairness, resistance to misuse, explainability and reasoning, adherence to social norms, and robustness.
	- 目的は：reliable and ethically sound deployment of LLMs in various applications.
- RWKVについて解説
	- https://agirobots.com/rwkv/
	- RNNの利点である高速な推論と処理可能なシーケンス長を大幅に向上
- LLMに関して起きている訴訟について
	- https://twitter.com/srush_nlp/status/1691845245074620915?s=20
- LLMでMRIスペクトルから分子を予測
	- https://chemrxiv.org/engage/chemrxiv/article-details/64d5e4ccdfabaf06ff1763ef
	- NMRスペクトルを文字列で表現、これを言語モデルへ入力し分子を予測することで67%の精度
- 松尾研究室100億パラメータサイズ・日英2ヶ国語対応の大規模言語モデル“Weblab-10B”をオープンソースで公開
	- https://weblab.t.u-tokyo.ac.jp/100%E5%84%84%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%BA%E3%83%BB%E6%97%A5%E8%8B%B12%E3%83%B6%E5%9B%BD%E8%AA%9E%E5%AF%BE%E5%BF%9C%E3%81%AE%E5%A4%A7%E8%A6%8F%E6%A8%A1/
	- https://huggingface.co/matsuo-lab/weblab-10b
	- 日本語のベンチマークであるJGLUE評価値が事前学習時と比べて大幅に改善（66→78%
	- 早速オープンソース警察が、商用に使えないのにオープンソースとは言わないとの突っ込みが。。
- 岸田首相、東京大で生成AIの講座受ける　「百聞は一見にしかず」
	- https://www.asahi.com/articles/ASR8G6X84R8GUTFK002.html
	- 松尾豊・東大大学院教授の講座を受けた。AIを学習させるプログラミングも体験し、受講
- LLMをつかった文書検索では、メタデータを入れることで性能が改善する
	-  Building Production-Ready LLM Apps with LlamaIndex: Document Metadata for Higher Accuracy Retrieval
	- https://betterprogramming.pub/building-production-ready-llm-apps-with-llamaindex-document-metadata-for-higher-accuracy-retrieval-a8ceca641fb5
- GoogleのトップAI研究者2人が東京でAI企業立ち上げを発表
	- 「自然からインスピレーションを得たインテリジェンスに基づいた新しいタイプの基礎モデルを開発する」
	- ジョーンズ氏とハー氏が新AI企業「Sakana AI」を東京に設立
	- うち1人は、生成AI革命のきっかけとなった論文の著者の一人
	- 日本で研究者を募り、生成AIの基盤モデル開発を目指す
	- https://www.nikkei.com/article/DGXZQOUC186TM0Y3A810C2000000/?n_cid=SNSTW001&n_tw=1692351448
	- 起業の地に日本を選んだ理由として、米国で生成AIの人材獲得競争が過熱している点をあげた。
-  TRL - 強化学習によるLLMの学習のためのライブラリ
	- TRL - Transformer Reinforcement Learning
	- https://note.com/npaka/n/nbb974324d6e1
	- 強化学習を使用してTransformer言語モデルを学習できます。このライブラリはHuggingFace Transformersと統合されています。
-  DPO による Llama 2 のファインチューニング(npaka)
	- https://note.com/npaka/n/nfe7391a1d28d
	- 「Direct Preference Optimization」では、既存の手法で使用されているRLベースの目標を、単純なバイナリクロスエントロピー損失を介して直接最適化できる目標に切り替える
	- LMを改良するこのプロセスが大幅に簡素化

## 8/14
お盆ですが、膨大にならないうちに更新します。ところで、「大規模言語モデル入門」(技術評論社ISBN 978-4-297-13633-8）いいですね、Huggingfacesをつかって、日本語データセットをつかった、ファインチューニングなど見所が多い。
さて今週は、先週に引き続き vicuna-v1.5関係の記事が多かったわけですが、stability.aiから日本語のStableLLMがリリースされたがのが大きなニュースでした。LLMベンチマークもColab環境でできるらしい。Metaの公表した生成AIのガイドとか、FacToolなんか、AIの安全性やリスクなんかに対してちゃんと取り組んでいる。日FR本のAI戦略の、開発促進に偏った姿勢とは一線を画している（つまり余裕がないということ）。FacToolによる分析の結果、GPT-4はやっぱりすごいんだな。Llmaindexのllmがgpt-3.5-turboにやっと変更されたらしい、そんなに使いにくかったのか。。LLMをプロダクションで使うための色々なTipsが公表されてたり、一方Andrew Ngさんは、LLMが世界を理解しているというブログを開陳。LLM時代の医療へのAI利用のベネフィットとリスクについてのランサー記事とか、数学者Terence Taoさんの、LLMをつかったAIが数学論文の共著者になりうるという興味深い予測も。産総研のAIセミナー、あっという間に満杯に。興味だけは大きいのに、手が動かない人が多すぎないか。。まあ、LLMでいくら頑張てもChatGPTでよくない？みたいな意見もある。様々な面で、日本はLLM開発で遅れてきていて、もはや以前のような横綱相撲をするような感じではないのに政府はそうは言えないのか、しかし民間は頑張っている。

- LlamaIndexでAutoGPTQモデルを使う（vicuna-13B-v1.5-GPTQ）
	- https://zenn.dev/libratech/articles/1979874b223895
	- 4bit化など軽量化されたllmをllamaindexで使う方法、ローカル環境とか
	- Colabの無料版(T4インスタンス)でも動作する
- LLama2公開にあわせて、Metaから"responsible generative AI"に関するガイドが出ている.、
	- https://ai.meta.com/static-resource/responsible-use-guide/
- text-generation-webui で TheBloke/vicuna-13B-v1.5-GPTQが動く
	- https://twitter.com/smorce1/status/1688250856129646592?s=20
- llama2をつかって、ローカルにQ&Aを実行する手法について via llamaindex
	- https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/SimpleIndexDemoLlama-Local.html
- LLMを試すのに、「ガンダムテスト」というのがあるらしい、vicuna-13b-v1.5-16kは優秀らしい
	- https://twitter.com/NuCode/status/1688455649091608576?s=20
- 内閣府AI戦略会議(8/4)の資料が一部公開、AI関連施策は開発振興一本足に近くリスク対応が申し訳程度
	- https://www8.cao.go.jp/cstp/ai/ai_senryaku/4kai/shisaku.pdf
-  IPA「ITパスポート試験 シラバス」に、生成AIの仕組み、活用例、留意事項等に関する項目・用語例を追加
	- https://www.ipa.go.jp/shiken/syllabus/henkou/2023/20230807.html
- 「JP Language Model Evaluation Harness」によるLLM性能評価 by stabilityAI
	- https://note.com/npaka/n/nedf4dacd4037
	- Colab(T4)で12時間もかかる、できるらしい
- llama-2-13bのJGLUE、言語モデルの評価と関係
	- https://huggingface.co/HachiML/Llama-2-13b-hf-qlora-dolly-ja-2ep/blob/main/benchmark_jglue/JGLUE_Llama-2-13b-hf-qlora-dolly-ja-2ep.ipynb
- GPTQの元論文はこちら、
	- https://arxiv.org/pdf/2210.17323.pdf
	- GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS
- ストックマークは最近の話題にも詳しいGPT-NeoXをベースとした14億パラメータの日本語のLLMをOSS公開
	- https://stockmark.co.jp/news/20230808
- HuggingFacesとNVIDIAが提携、企業向けのサービスを展開？
	- https://www.nvidia.com/ja-jp/about-nvidia/press-releases/2023/nvidia-and-hugging-face-to-connect-millions-of-developers-to-generative-ai-supercomputing/
	- HuggingFaceにあるAIモデルのトレーニングとか微調整ができる企業向けのサービスで、GPUとしてNVidiaのクラウドGPUが選べるようになるらしい。
- 悲報？：産総研、LLMのセミナー「シミュレーションとAIの融合技術とその最新事例」、すぐに定員いっぱいになる
	- https://www.airc.aist.go.jp/seminar_detail/seminar_069.html
- Stability.ai、 日本語言語モデル「Japanese StableLM Alpha」をリリース(8/10)
	- https://ja.stability.ai/blog/japanese-stablelm-alpha
- 早速Japanese Stable LLMを、Colab無料環境から利用するnotebookが公開
	- https://colab.research.google.com/github/mkshing/notebooks/blob/main/stabilityai_japanese_stablelm_alpha_7b.ipynb
	- huggingfacesにログインしないといけない、、が動くぞ！
	- ガンダムテストしてみたが、なんか、学習時につかったデータが表示される。
- 生成AIによって生成されたテキストを判別する方法についての論文
	- https://arxiv.org/abs/2306.15666
	- Testing of Detection Tools for AI-Generated Text
	- ■文章のスタイルを変化させられている場合（例えば子供っぽくなど）、識別が困難になる 
	- ■言い換えや書き換えによって段階的に文章を変更されると、識別がかなり困難になる
	-  ■AI生成コードの検出はAI生成テキストの検出よりもさらに困難になる
- Langchainのテキスト分割の様子を目視できる、playgroundが爆誕
	- https://langchain-text-splitter.streamlit.app/
- Google Colab で Japanese StableLM Alpha + LlamaIndex の QA を試す
	- https://note.com/npaka/n/n5c80ca661357
- 「とっきょ」広報誌で、こち亀の内容が、拒絶通知の理由になった事例が紹介。。
	- https://www.jpo.go.jp/news/koho/kohoshi/vol57/07_page1.html
	- 拒絶を避けるべく、特許出願する前にはこち亀を全巻読破する必要があるのか、、、
	- 審査官の趣味という気もするが、、
-  ChatGPTの新機能カスタム指示の面白い使い方
	- https://note.com/it_navi/n/nca4643390969
	- カスタム指示は、ChatGPTの**役割、回答方針、出力形式など**を予め設定することができます。
- LLMは世界を理解しているか？by Andrew Ng
	- https://www.deeplearning.ai/the-batch/issue-209/
	- Othelo-GPTの例から、答えは YESらしい。
- 生成AIの文章やコード、論文が“事実か”チェックする技術　米Meta含む研究者らが開発
	- https://www.itmedia.co.jp/news/articles/2308/09/news064.html
	-  FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios
	- https://arxiv.org/abs/2307.13528v2
		- 研究者らはベンチマークを開発し、知識ベースのQA、コード生成、数学の問題解決、科学論文のレビュー執筆の4つのタスクで実験を行った。その結果、GPT-4はChatGPT、Bard、Claude-v1、Vicunaと比較して、事実精度が最も優れていた。Vicuna-13Bは、知識ベースのQAではそれなりに良好な事実性を示したが、コード生成、数学の問題解決、科学論文のレビュー執筆など、より困難なシナリオではパフォーマンスが低い結果となった。
- llamaindexのv0.8がリリース
	- https://github.com/jerryjliu/llama_index/blob/main/CHANGELOG.md
	- [1] The default LLM is now gpt-3.5-turbo
	- [2] Speaking of changing prompts, we’ve changed the default question-answering templates for both our create and refine strategy as well as tree_summarize.
	- [3] Our default text splitter is now our brand-new sentence text splitter.
	- [4] Added llama.cpp and @huggingface as fallbacks if openai key is not set.
	- [5] Some new features: a `SentenceWindowNodeParser` and `MetadataReplacementNodPostProcessor` 
- チュートリアル、Create a CustomGPT And Supercharge your Company with AI – Pick the Best LLM
	- https://blog.abacus.ai/blog/2023/08/10/create-your-custom-chatgpt-pick-the-best-llm-that-works-for-you/
-  Building LLM applications for production
	- https://huyenchip.com/2023/04/11/llm-engineering.html
	- LLMをプロダクションで使うための色々なTipsがまとまった記事
- いろいろLLMをいじってみても、結局ChatGPTでよくない？みたいな
	- https://twitter.com/mr_bay_area/status/1689868431900975104?s=20
-  AI in medicine: creating a safe and equitable future
	- Lancerの記事、LLM時代における、医療分野へのAI適用のメリットとリスクについてまとめ
	- https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)01668-9/fulltext
-  Embracing change and resetting expectations by Terence Tao@microsoft
	- https://unlocked.microsoft.com/ai-anthology/terence-tao/
	- He predicts that AI will be a trustworthy co-author in mathematical research by 2026, when combined with search and symbolic math tools.
	- 2026年までには、数学研究において、AIが信頼できる共著者になりうるとの予測


## 8/7

llama2ベースのVicuna v1.5で盛り上がっている、langchainやllamaindexとの組み合わせでも動く模様。ReActなどのAgent機能もちゃんとうごくらしい。llama2を手ごろに試せるcolab noteもたくさん公開、ローカルGPUで動かす報告も。なおllama2本家も申請すればを直接使うこともできる。マイクロソフトはwindows上でのllama2というネタでメタとパートナーとのこと、二股かけてる？マイクロソフトがAzure OpenAIをつかったChatGPTもどきのサンプル実装を公開、カニばってない？文章から知識を抽出する方法、llamaindexでも知識グラフ(KG)を抽出するKnowledgeGraphIndexがあったが、REBELという外部のtransformerを利用する方法もあるのか。用途に合わせて選択、細かい調整が必要かな。UCバークレーのDynalang、AIエージェントと紹介されているが、論文タイトルからするとLLMで世界モデルを構築しようとしている（「二重過程モデル」の真ん中に出てくるやつ？記号接地モデルというかそういうやつ）。自コンテンツをつかったChatBotの作り方についてわかりやすい説明があった。JSTの生成AIのまとめ、日本の生きる道は、「第4世代AI」「信頼されるAI」「AI・データ駆動科学」ということらしい。「第４世代AI」とはSystem1とSystem2が連動する、「二重過程モデル」のことらしい、Dynalangの話ともつながった！

> NeurIPS2019で、Bengioの基調講演の「二重過程モデル」（即時的なSystem1と熟考的なSystem2の二重モデル、間に、世界モデルが入る）。知覚系の深層学習(System1)によって眼前の状況に対する世界モデル（World Model）が得られるが、それを使って言語・知識系が適切な手順を組み立てるのがSystem2。カーネマンのFast & Slowとも関連がありそう。。

- Google Colab で Vicuna-v1.5 + LlamaIndex の QA を試す
	- npakaさんより、ハイメモリでないと動かないのか。。
	- https://note.com/npaka/n/n931319f17b34
-  Google Colab で Llama 2 + LlamaIndex の QA を試す
	- npakaさんより、llma2利用には申請が必要なのか、
	- Q&Aテンプレに修正が必要なもよう
	- https://note.com/npaka/n/n3e1b59d1ac9e
- vicuna-7b-v1.5の一番簡単な利用方法by npakaさｎ
	- https://huggingface.co/lmsys/vicuna-7b-v1.5
	- https://twitter.com/npaka123/status/1686872443305295878?s=20
- ChatGPTの小改良が順次リリースされるとの告知
	- https://twitter.com/OpenAI/status/1687159114047291392?s=20
	- prompt exampleとか、Plus会員にはGPT-4がデフォルトになるとか、そういうｙつ
- UCバークレー、アルファ碁とChatGPTを混ぜて強くしたようなAIエージェント「Dynalang」
	- https://arxiv.org/abs/2308.01399
	- Learning to Model the World with Language
- マイクロソフト社、Azure OpenAIで、ChatGPTもどきを作るサンプル実装を公開
	- https://github.com/microsoft/azurechatgpt
	- 企業利用が加速するか。。いやplaygroundで十分？
- 人工知能研究の新潮流2　～基盤モデル・生成AIのインパクト～
	- JSTのまとめ、生成AI研究の動向報告書
	- https://www.jst.go.jp/crds/report/CRDS-FY2023-RR-02.html?fbclid=IwAR0KQ7bg5BRLIblzI154AHYheNrF1SPPzm-xn4z1PuQBUPK2Kia2qT4PMxU
	- 「第4世代AI」「信頼されるAI」「AI・データ駆動科学」
- 雇用判断にAIを使うのは、EU規制上禁止？
	- 禁止ではなくて、ハイリスクAIに相当するから、守るべきことを守らないといけないということ
	- https://twitter.com/umiyuki_ai/status/1687639267273748480?s=20
- 南極の氷が、今年は急激にとけているらしい　via 安宅さん
	- https://www.economist.com/graphic-detail/2023/08/02/the-rapid-loss-of-antarctic-sea-ice-brings-grim-scenarios-into-view
- REBELという関係抽出トランスフォーマーをつかって知識グラフを抽出して推論する例
	- https://twitter.com/jerryjliu0/status/1687607838539927553?s=20
	- llamaindexの人による紹介、なんか抽出する知識の密度を調整したいところ
- Google Colab で LangChain + Vicuna-v1.5 のエージェント機能を試す
	- https://note.com/npaka/n/nb3c02ce2d4c5
	- npakaさんより、serpAIとmathをツールとして、ReActが試せるらしい。ハイメモリが必要。。
-  Google Colab で Llama.cpp + Vicuna-v1.5 を試す
	- npakaさんより、Colabでこんなこともできるのか？
	- https://note.com/npaka/n/n280ffc0d5ff0
- llama-2-7bをつかって、colabでchatbodを作る例、
	- 動くんだ、、、というか動くぞ！
	- https://colab.research.google.com/github/camenduru/text-generation-webui-colab/blob/main/llama-2-7b-chat.ipynb
- 自分のコンテンツを学習したカスタムChatBotを作る方法
	- https://zenn.dev/karaage0703/articles/c8baa66c40f9b7
	- そうか、いつもやってるやつは、Retrieval-Augmented Generation（RAG）ってよばれているのか？
-  LLMがローカルで動くパラメータ数どこまで？Metaの「Llama 2」を試してみた
	- https://pc.watch.impress.co.jp/docs/column/nishikawa/1519390.html
	- 西川さんが組むとは、だいぶ民主化が進んだのか。
	- Colabでも結構簡単にうごくが、ローカルなGeForce RTX 4070 Ti(12GB)でも動かす事例が(西川 和久)
-  Llama 2ベースのLLM FastChat/Vicuna v1.5をローカルで動作
	- https://jweb.asia/26-it/ai/91-fastchat-vicuna-v1-5-on-llama-2.html

## 7/31

いやあ、暑くなって１週間さぼったら、それなりにまとめるのがつらい。メタのLLaMa2リリースが大きな話題、岡野原さんの解説が良いかも。さっそくggml化、webui対応、LanChain組み込みが行われる。LangChainの統合開発環境LangSmith、よくLangChainの紹介動画に出てきてやつが正式リリースか。メタはマイクロソフトと組んでOSS化するとのこと、マイクロソフト無敵だな。OpanAI x Azureの人は、マイクロソフトの「ChatGPT - Azure OpenAI 大全」は参考になるか。ChatGPTの性能が初期に比べて劣化しているとの報告も。「生成AIと著作権に関する論点整理」の図は素晴らしい。OpenAIのCEOであるSam Altman氏が共同創業したWorldCoinプロジェクトが7/24に仮想通貨WLDを
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTU2NDQ1MzY3NSwtMzIyMDM4MTg0LC0xOT
cxMTg2MDM0LDE4NTQ2ODkzMTMsNDgzNDg5ODcsMTkxNjg0NDE4
MywtNTQ4MDMxNDgzLDY2ODQ0MzUxNCwtMTg4ODA0MDYwMiwxNj
kxNzE4MTczLC01ODk1MjEwMzcsMTk1NjEyOTEwMiwxNjk3NDU3
NTkxLDU4MTM4Nzc4OSwtOTc1NTY4MjIzLC0xMDEyNjA2NjM2LD
c0NDgwMjY2Myw1NjQxMTc3NjUsMTc4OTMyNjYxNSwyMDkwMTU2
NjYzXX0=
-->